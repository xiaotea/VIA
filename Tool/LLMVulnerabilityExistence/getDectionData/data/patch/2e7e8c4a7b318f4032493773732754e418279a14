{
    "pygments/lexers/archetype.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "             (r'P((\\d*(\\.\\d+)?[YyMmWwDd]){1,3}(T(\\d*(\\.\\d+)?[HhMmSs]){,3})?|'"
            },
            "1": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "              r'T(\\d*(\\.\\d+)?[HhMmSs]){,3})', Literal.Date),"
            },
            "2": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "             (r'[+-]?(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+', Number.Float),"
            },
            "3": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'[+-]?(\\d+)*\\.\\d+%?', Number.Float),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+            (r'[+-]?\\d*\\.\\d+%?', Number.Float),"
            },
            "5": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "             (r'0x[0-9a-fA-F]+', Number.Hex),"
            },
            "6": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "             (r'[+-]?\\d+%?', Number.Integer),"
            },
            "7": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         ],"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.archetype",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexer for Archetype-related syntaxes, including:",
            "",
            "    - ODIN syntax <https://github.com/openEHR/odin>",
            "    - ADL syntax <http://www.openehr.org/releases/trunk/architecture/am/adl2.pdf>",
            "    - cADL sub-syntax of ADL",
            "",
            "    For uses of this syntax, see the openEHR archetypes <http://www.openEHR.org/ckm>",
            "",
            "    Contributed by Thomas Beale <https://github.com/wolandscat>,",
            "    <https://bitbucket.org/thomas_beale>.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, default",
            "from pygments.token import Text, Comment, Name, Literal, Number, String, \\",
            "    Punctuation, Keyword, Operator, Generic",
            "",
            "__all__ = ['OdinLexer', 'CadlLexer', 'AdlLexer']",
            "",
            "",
            "class AtomsLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for Values used in ADL and ODIN.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        # ----- pseudo-states for inclusion -----",
            "        'whitespace': [",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'[ \\t]*--.*$', Comment),",
            "        ],",
            "        'archetype_id': [",
            "            (r'[ \\t]*([a-zA-Z]\\w+(\\.[a-zA-Z]\\w+)*::)?[a-zA-Z]\\w+(-[a-zA-Z]\\w+){2}'",
            "             r'\\.\\w+[\\w-]*\\.v\\d+(\\.\\d+){,2}((-[a-z]+)(\\.\\d+)?)?', Name.Decorator),",
            "        ],",
            "        'date_constraints': [",
            "            # ISO 8601-based date/time constraints",
            "            (r'[Xx?YyMmDdHhSs\\d]{2,4}([:-][Xx?YyMmDdHhSs\\d]{2}){2}', Literal.Date),",
            "            # ISO 8601-based duration constraints + optional trailing slash",
            "            (r'(P[YyMmWwDd]+(T[HhMmSs]+)?|PT[HhMmSs]+)/?', Literal.Date),",
            "        ],",
            "        'ordered_values': [",
            "            # ISO 8601 date with optional 'T' ligature",
            "            (r'\\d{4}-\\d{2}-\\d{2}T?', Literal.Date),",
            "            # ISO 8601 time",
            "            (r'\\d{2}:\\d{2}:\\d{2}(\\.\\d+)?([+-]\\d{4}|Z)?', Literal.Date),",
            "            # ISO 8601 duration",
            "            (r'P((\\d*(\\.\\d+)?[YyMmWwDd]){1,3}(T(\\d*(\\.\\d+)?[HhMmSs]){,3})?|'",
            "             r'T(\\d*(\\.\\d+)?[HhMmSs]){,3})', Literal.Date),",
            "            (r'[+-]?(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+', Number.Float),",
            "            (r'[+-]?(\\d+)*\\.\\d+%?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[+-]?\\d+%?', Number.Integer),",
            "        ],",
            "        'values': [",
            "            include('ordered_values'),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            (r'\"', String, 'string'),",
            "            (r\"'(\\\\.|\\\\[0-7]{1,3}|\\\\x[a-fA-F0-9]{1,2}|[^\\\\\\'\\n])'\", String.Char),",
            "            (r'[a-z][a-z0-9+.-]*:', Literal, 'uri'),",
            "            # term code",
            "            (r'(\\[)(\\w[\\w-]*(?:\\([^)\\n]+\\))?)(::)(\\w[\\w-]*)(\\])',",
            "             bygroups(Punctuation, Name.Decorator, Punctuation, Name.Decorator,",
            "                      Punctuation)),",
            "            (r'\\|', Punctuation, 'interval'),",
            "            # list continuation",
            "            (r'\\.\\.\\.', Punctuation),",
            "        ],",
            "        'constraint_values': [",
            "            (r'(\\[)(\\w[\\w-]*(?:\\([^)\\n]+\\))?)(::)',",
            "             bygroups(Punctuation, Name.Decorator, Punctuation), 'adl14_code_constraint'),",
            "            # ADL 1.4 ordinal constraint",
            "            (r'(\\d*)(\\|)(\\[\\w[\\w-]*::\\w[\\w-]*\\])((?:[,;])?)',",
            "             bygroups(Number, Punctuation, Name.Decorator, Punctuation)),",
            "            include('date_constraints'),",
            "            include('values'),",
            "        ],",
            "",
            "        # ----- real states -----",
            "        'string': [",
            "            ('\"', String, '#pop'),",
            "            (r'\\\\([\\\\abfnrtv\"\\']|x[a-fA-F0-9]{2,4}|'",
            "             r'u[a-fA-F0-9]{4}|U[a-fA-F0-9]{8}|[0-7]{1,3})', String.Escape),",
            "            # all other characters",
            "            (r'[^\\\\\"]+', String),",
            "            # stray backslash",
            "            (r'\\\\', String),",
            "        ],",
            "        'uri': [",
            "            # effective URI terminators",
            "            (r'[,>\\s]', Punctuation, '#pop'),",
            "            (r'[^>\\s,]+', Literal),",
            "        ],",
            "        'interval': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            include('ordered_values'),",
            "            (r'\\.\\.', Punctuation),",
            "            (r'[<>=] *', Punctuation),",
            "            # handle +/-",
            "            (r'\\+/-', Punctuation),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'any_code': [",
            "            include('archetype_id'),",
            "            # if it is a code",
            "            (r'[a-z_]\\w*[0-9.]+(@[^\\]]+)?', Name.Decorator),",
            "            # if it is tuple with attribute names",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            # if it is an integer, i.e. Xpath child index",
            "            (r'[0-9]+', Text),",
            "            (r'\\|', Punctuation, 'code_rubric'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "            # handle use_archetype statement",
            "            (r'\\s*,\\s*', Punctuation),",
            "        ],",
            "        'code_rubric': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            (r'[^|]+', String),",
            "        ],",
            "        'adl14_code_constraint': [",
            "            (r'\\]', Punctuation, '#pop'),",
            "            (r'\\|', Punctuation, 'code_rubric'),",
            "            (r'(\\w[\\w-]*)([;,]?)', bygroups(Name.Decorator, Punctuation)),",
            "            include('whitespace'),",
            "        ],",
            "    }",
            "",
            "",
            "class OdinLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for ODIN syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "    name = 'ODIN'",
            "    aliases = ['odin']",
            "    filenames = ['*.odin']",
            "    mimetypes = ['text/odin']",
            "",
            "    tokens = {",
            "        'path': [",
            "            (r'>', Punctuation, '#pop'),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'/', Punctuation),",
            "            (r'\\[', Punctuation, 'key'),",
            "            (r'\\s*,\\s*', Punctuation, '#pop'),",
            "            (r'\\s+', Text, '#pop'),",
            "        ],",
            "        'key': [",
            "            include('values'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "        ],",
            "        'type_cast': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r'[^)]+',  Name.Class),",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            include('values'),",
            "            # x-ref path",
            "            (r'/', Punctuation, 'path'),",
            "            # x-ref path starting with key",
            "            (r'\\[', Punctuation, 'key'),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'=', Operator),",
            "            (r'\\(', Punctuation, 'type_cast'),",
            "            (r',', Punctuation),",
            "            (r'<', Punctuation),",
            "            (r'>', Punctuation),",
            "            (r';', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class CadlLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for cADL syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "    name = 'cADL'",
            "    aliases = ['cadl']",
            "    filenames = ['*.cadl']",
            "",
            "    tokens = {",
            "        'path': [",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'/', Punctuation),",
            "            (r'\\[', Punctuation, 'any_code'),",
            "            (r'\\s+', Punctuation, '#pop'),",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            (r'(cardinality|existence|occurrences|group|include|exclude|'",
            "             r'allow_archetype|use_archetype|use_node)\\W', Keyword.Type),",
            "            (r'(and|or|not|there_exists|xor|implies|for_all)\\W', Keyword.Type),",
            "            (r'(after|before|closed)\\W', Keyword.Type),",
            "            (r'(not)\\W', Operator),",
            "            (r'(matches|is_in)\\W', Operator),",
            "            # is_in / not is_in char",
            "            ('(\\u2208|\\u2209)', Operator),",
            "            # there_exists / not there_exists / for_all / and / or",
            "            ('(\\u2203|\\u2204|\\u2200|\\u2227|\\u2228|\\u22BB|\\223C)',",
            "             Operator),",
            "            # regex in slot or as string constraint",
            "            (r'(\\{)(\\s*/[^}]+/\\s*)(\\})',",
            "             bygroups(Punctuation, String.Regex, Punctuation)),",
            "            # regex in slot or as string constraint",
            "            (r'(\\{)(\\s*\\^[^}]+\\^\\s*)(\\})',",
            "             bygroups(Punctuation, String.Regex, Punctuation)),",
            "            (r'/', Punctuation, 'path'),",
            "            # for cardinality etc",
            "            (r'(\\{)((?:\\d+\\.\\.)?(?:\\d+|\\*))'",
            "             r'((?:\\s*;\\s*(?:ordered|unordered|unique)){,2})(\\})',",
            "             bygroups(Punctuation, Number, Number, Punctuation)),",
            "            # [{ is start of a tuple value",
            "            (r'\\[\\{', Punctuation),",
            "            (r'\\}\\]', Punctuation),",
            "            (r'\\{', Punctuation),",
            "            (r'\\}', Punctuation),",
            "            include('constraint_values'),",
            "            # type name",
            "            (r'[A-Z]\\w+(<[A-Z]\\w+([A-Za-z_<>]*)>)?',  Name.Class),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'\\[', Punctuation, 'any_code'),",
            "            (r'(~|//|\\\\\\\\|\\+|-|/|\\*|\\^|!=|=|<=|>=|<|>]?)', Operator),",
            "            (r'\\(', Punctuation),",
            "            (r'\\)', Punctuation),",
            "            # for lists of values",
            "            (r',', Punctuation),",
            "            (r'\"', String, 'string'),",
            "            # for assumed value",
            "            (r';', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class AdlLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for ADL syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    name = 'ADL'",
            "    aliases = ['adl']",
            "    filenames = ['*.adl', '*.adls', '*.adlf', '*.adlx']",
            "",
            "    tokens = {",
            "        'whitespace': [",
            "            # blank line ends",
            "            (r'\\s*\\n', Text),",
            "            # comment-only line",
            "            (r'^[ \\t]*--.*$', Comment),",
            "        ],",
            "        'odin_section': [",
            "            # repeating the following two rules from the root state enable multi-line",
            "            # strings that start in the first column to be dealt with",
            "            (r'^(language|description|ontology|terminology|annotations|'",
            "             r'component_terminologies|revision_history)[ \\t]*\\n', Generic.Heading),",
            "            (r'^(definition)[ \\t]*\\n', Generic.Heading, 'cadl_section'),",
            "            (r'^([ \\t]*|[ \\t]+.*)\\n', using(OdinLexer)),",
            "            (r'^([^\"]*\")(>[ \\t]*\\n)', bygroups(String, Punctuation)),",
            "            # template overlay delimiter",
            "            (r'^----------*\\n', Text, '#pop'),",
            "            (r'^.*\\n', String),",
            "            default('#pop'),",
            "        ],",
            "        'cadl_section': [",
            "            (r'^([ \\t]*|[ \\t]+.*)\\n', using(CadlLexer)),",
            "            default('#pop'),",
            "        ],",
            "        'rules_section': [",
            "            (r'^[ \\t]+.*\\n', using(CadlLexer)),",
            "            default('#pop'),",
            "        ],",
            "        'metadata': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r';', Punctuation),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            # numbers and version ids",
            "            (r'\\d+(\\.\\d+)*', Literal),",
            "            # Guids",
            "            (r'(\\d|[a-fA-F])+(-(\\d|[a-fA-F])+){3,}', Literal),",
            "            (r'\\w+', Name.Class),",
            "            (r'\"', String, 'string'),",
            "            (r'=', Operator),",
            "            (r'[ \\t]+', Text),",
            "            default('#pop'),",
            "        ],",
            "        'root': [",
            "            (r'^(archetype|template_overlay|operational_template|template|'",
            "             r'speciali[sz]e)', Generic.Heading),",
            "            (r'^(language|description|ontology|terminology|annotations|'",
            "             r'component_terminologies|revision_history)[ \\t]*\\n',",
            "             Generic.Heading, 'odin_section'),",
            "            (r'^(definition)[ \\t]*\\n', Generic.Heading, 'cadl_section'),",
            "            (r'^(rules)[ \\t]*\\n', Generic.Heading, 'rules_section'),",
            "            include('archetype_id'),",
            "            (r'[ \\t]*\\(', Punctuation, 'metadata'),",
            "            include('whitespace'),",
            "        ],",
            "    }"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.archetype",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexer for Archetype-related syntaxes, including:",
            "",
            "    - ODIN syntax <https://github.com/openEHR/odin>",
            "    - ADL syntax <http://www.openehr.org/releases/trunk/architecture/am/adl2.pdf>",
            "    - cADL sub-syntax of ADL",
            "",
            "    For uses of this syntax, see the openEHR archetypes <http://www.openEHR.org/ckm>",
            "",
            "    Contributed by Thomas Beale <https://github.com/wolandscat>,",
            "    <https://bitbucket.org/thomas_beale>.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, default",
            "from pygments.token import Text, Comment, Name, Literal, Number, String, \\",
            "    Punctuation, Keyword, Operator, Generic",
            "",
            "__all__ = ['OdinLexer', 'CadlLexer', 'AdlLexer']",
            "",
            "",
            "class AtomsLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for Values used in ADL and ODIN.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        # ----- pseudo-states for inclusion -----",
            "        'whitespace': [",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'[ \\t]*--.*$', Comment),",
            "        ],",
            "        'archetype_id': [",
            "            (r'[ \\t]*([a-zA-Z]\\w+(\\.[a-zA-Z]\\w+)*::)?[a-zA-Z]\\w+(-[a-zA-Z]\\w+){2}'",
            "             r'\\.\\w+[\\w-]*\\.v\\d+(\\.\\d+){,2}((-[a-z]+)(\\.\\d+)?)?', Name.Decorator),",
            "        ],",
            "        'date_constraints': [",
            "            # ISO 8601-based date/time constraints",
            "            (r'[Xx?YyMmDdHhSs\\d]{2,4}([:-][Xx?YyMmDdHhSs\\d]{2}){2}', Literal.Date),",
            "            # ISO 8601-based duration constraints + optional trailing slash",
            "            (r'(P[YyMmWwDd]+(T[HhMmSs]+)?|PT[HhMmSs]+)/?', Literal.Date),",
            "        ],",
            "        'ordered_values': [",
            "            # ISO 8601 date with optional 'T' ligature",
            "            (r'\\d{4}-\\d{2}-\\d{2}T?', Literal.Date),",
            "            # ISO 8601 time",
            "            (r'\\d{2}:\\d{2}:\\d{2}(\\.\\d+)?([+-]\\d{4}|Z)?', Literal.Date),",
            "            # ISO 8601 duration",
            "            (r'P((\\d*(\\.\\d+)?[YyMmWwDd]){1,3}(T(\\d*(\\.\\d+)?[HhMmSs]){,3})?|'",
            "             r'T(\\d*(\\.\\d+)?[HhMmSs]){,3})', Literal.Date),",
            "            (r'[+-]?(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+', Number.Float),",
            "            (r'[+-]?\\d*\\.\\d+%?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[+-]?\\d+%?', Number.Integer),",
            "        ],",
            "        'values': [",
            "            include('ordered_values'),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            (r'\"', String, 'string'),",
            "            (r\"'(\\\\.|\\\\[0-7]{1,3}|\\\\x[a-fA-F0-9]{1,2}|[^\\\\\\'\\n])'\", String.Char),",
            "            (r'[a-z][a-z0-9+.-]*:', Literal, 'uri'),",
            "            # term code",
            "            (r'(\\[)(\\w[\\w-]*(?:\\([^)\\n]+\\))?)(::)(\\w[\\w-]*)(\\])',",
            "             bygroups(Punctuation, Name.Decorator, Punctuation, Name.Decorator,",
            "                      Punctuation)),",
            "            (r'\\|', Punctuation, 'interval'),",
            "            # list continuation",
            "            (r'\\.\\.\\.', Punctuation),",
            "        ],",
            "        'constraint_values': [",
            "            (r'(\\[)(\\w[\\w-]*(?:\\([^)\\n]+\\))?)(::)',",
            "             bygroups(Punctuation, Name.Decorator, Punctuation), 'adl14_code_constraint'),",
            "            # ADL 1.4 ordinal constraint",
            "            (r'(\\d*)(\\|)(\\[\\w[\\w-]*::\\w[\\w-]*\\])((?:[,;])?)',",
            "             bygroups(Number, Punctuation, Name.Decorator, Punctuation)),",
            "            include('date_constraints'),",
            "            include('values'),",
            "        ],",
            "",
            "        # ----- real states -----",
            "        'string': [",
            "            ('\"', String, '#pop'),",
            "            (r'\\\\([\\\\abfnrtv\"\\']|x[a-fA-F0-9]{2,4}|'",
            "             r'u[a-fA-F0-9]{4}|U[a-fA-F0-9]{8}|[0-7]{1,3})', String.Escape),",
            "            # all other characters",
            "            (r'[^\\\\\"]+', String),",
            "            # stray backslash",
            "            (r'\\\\', String),",
            "        ],",
            "        'uri': [",
            "            # effective URI terminators",
            "            (r'[,>\\s]', Punctuation, '#pop'),",
            "            (r'[^>\\s,]+', Literal),",
            "        ],",
            "        'interval': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            include('ordered_values'),",
            "            (r'\\.\\.', Punctuation),",
            "            (r'[<>=] *', Punctuation),",
            "            # handle +/-",
            "            (r'\\+/-', Punctuation),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'any_code': [",
            "            include('archetype_id'),",
            "            # if it is a code",
            "            (r'[a-z_]\\w*[0-9.]+(@[^\\]]+)?', Name.Decorator),",
            "            # if it is tuple with attribute names",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            # if it is an integer, i.e. Xpath child index",
            "            (r'[0-9]+', Text),",
            "            (r'\\|', Punctuation, 'code_rubric'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "            # handle use_archetype statement",
            "            (r'\\s*,\\s*', Punctuation),",
            "        ],",
            "        'code_rubric': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            (r'[^|]+', String),",
            "        ],",
            "        'adl14_code_constraint': [",
            "            (r'\\]', Punctuation, '#pop'),",
            "            (r'\\|', Punctuation, 'code_rubric'),",
            "            (r'(\\w[\\w-]*)([;,]?)', bygroups(Name.Decorator, Punctuation)),",
            "            include('whitespace'),",
            "        ],",
            "    }",
            "",
            "",
            "class OdinLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for ODIN syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "    name = 'ODIN'",
            "    aliases = ['odin']",
            "    filenames = ['*.odin']",
            "    mimetypes = ['text/odin']",
            "",
            "    tokens = {",
            "        'path': [",
            "            (r'>', Punctuation, '#pop'),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'/', Punctuation),",
            "            (r'\\[', Punctuation, 'key'),",
            "            (r'\\s*,\\s*', Punctuation, '#pop'),",
            "            (r'\\s+', Text, '#pop'),",
            "        ],",
            "        'key': [",
            "            include('values'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "        ],",
            "        'type_cast': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r'[^)]+',  Name.Class),",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            include('values'),",
            "            # x-ref path",
            "            (r'/', Punctuation, 'path'),",
            "            # x-ref path starting with key",
            "            (r'\\[', Punctuation, 'key'),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'=', Operator),",
            "            (r'\\(', Punctuation, 'type_cast'),",
            "            (r',', Punctuation),",
            "            (r'<', Punctuation),",
            "            (r'>', Punctuation),",
            "            (r';', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class CadlLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for cADL syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "    name = 'cADL'",
            "    aliases = ['cadl']",
            "    filenames = ['*.cadl']",
            "",
            "    tokens = {",
            "        'path': [",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'/', Punctuation),",
            "            (r'\\[', Punctuation, 'any_code'),",
            "            (r'\\s+', Punctuation, '#pop'),",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            (r'(cardinality|existence|occurrences|group|include|exclude|'",
            "             r'allow_archetype|use_archetype|use_node)\\W', Keyword.Type),",
            "            (r'(and|or|not|there_exists|xor|implies|for_all)\\W', Keyword.Type),",
            "            (r'(after|before|closed)\\W', Keyword.Type),",
            "            (r'(not)\\W', Operator),",
            "            (r'(matches|is_in)\\W', Operator),",
            "            # is_in / not is_in char",
            "            ('(\\u2208|\\u2209)', Operator),",
            "            # there_exists / not there_exists / for_all / and / or",
            "            ('(\\u2203|\\u2204|\\u2200|\\u2227|\\u2228|\\u22BB|\\223C)',",
            "             Operator),",
            "            # regex in slot or as string constraint",
            "            (r'(\\{)(\\s*/[^}]+/\\s*)(\\})',",
            "             bygroups(Punctuation, String.Regex, Punctuation)),",
            "            # regex in slot or as string constraint",
            "            (r'(\\{)(\\s*\\^[^}]+\\^\\s*)(\\})',",
            "             bygroups(Punctuation, String.Regex, Punctuation)),",
            "            (r'/', Punctuation, 'path'),",
            "            # for cardinality etc",
            "            (r'(\\{)((?:\\d+\\.\\.)?(?:\\d+|\\*))'",
            "             r'((?:\\s*;\\s*(?:ordered|unordered|unique)){,2})(\\})',",
            "             bygroups(Punctuation, Number, Number, Punctuation)),",
            "            # [{ is start of a tuple value",
            "            (r'\\[\\{', Punctuation),",
            "            (r'\\}\\]', Punctuation),",
            "            (r'\\{', Punctuation),",
            "            (r'\\}', Punctuation),",
            "            include('constraint_values'),",
            "            # type name",
            "            (r'[A-Z]\\w+(<[A-Z]\\w+([A-Za-z_<>]*)>)?',  Name.Class),",
            "            # attribute name",
            "            (r'[a-z_]\\w*', Name.Class),",
            "            (r'\\[', Punctuation, 'any_code'),",
            "            (r'(~|//|\\\\\\\\|\\+|-|/|\\*|\\^|!=|=|<=|>=|<|>]?)', Operator),",
            "            (r'\\(', Punctuation),",
            "            (r'\\)', Punctuation),",
            "            # for lists of values",
            "            (r',', Punctuation),",
            "            (r'\"', String, 'string'),",
            "            # for assumed value",
            "            (r';', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class AdlLexer(AtomsLexer):",
            "    \"\"\"",
            "    Lexer for ADL syntax.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    name = 'ADL'",
            "    aliases = ['adl']",
            "    filenames = ['*.adl', '*.adls', '*.adlf', '*.adlx']",
            "",
            "    tokens = {",
            "        'whitespace': [",
            "            # blank line ends",
            "            (r'\\s*\\n', Text),",
            "            # comment-only line",
            "            (r'^[ \\t]*--.*$', Comment),",
            "        ],",
            "        'odin_section': [",
            "            # repeating the following two rules from the root state enable multi-line",
            "            # strings that start in the first column to be dealt with",
            "            (r'^(language|description|ontology|terminology|annotations|'",
            "             r'component_terminologies|revision_history)[ \\t]*\\n', Generic.Heading),",
            "            (r'^(definition)[ \\t]*\\n', Generic.Heading, 'cadl_section'),",
            "            (r'^([ \\t]*|[ \\t]+.*)\\n', using(OdinLexer)),",
            "            (r'^([^\"]*\")(>[ \\t]*\\n)', bygroups(String, Punctuation)),",
            "            # template overlay delimiter",
            "            (r'^----------*\\n', Text, '#pop'),",
            "            (r'^.*\\n', String),",
            "            default('#pop'),",
            "        ],",
            "        'cadl_section': [",
            "            (r'^([ \\t]*|[ \\t]+.*)\\n', using(CadlLexer)),",
            "            default('#pop'),",
            "        ],",
            "        'rules_section': [",
            "            (r'^[ \\t]+.*\\n', using(CadlLexer)),",
            "            default('#pop'),",
            "        ],",
            "        'metadata': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r';', Punctuation),",
            "            (r'([Tt]rue|[Ff]alse)', Literal),",
            "            # numbers and version ids",
            "            (r'\\d+(\\.\\d+)*', Literal),",
            "            # Guids",
            "            (r'(\\d|[a-fA-F])+(-(\\d|[a-fA-F])+){3,}', Literal),",
            "            (r'\\w+', Name.Class),",
            "            (r'\"', String, 'string'),",
            "            (r'=', Operator),",
            "            (r'[ \\t]+', Text),",
            "            default('#pop'),",
            "        ],",
            "        'root': [",
            "            (r'^(archetype|template_overlay|operational_template|template|'",
            "             r'speciali[sz]e)', Generic.Heading),",
            "            (r'^(language|description|ontology|terminology|annotations|'",
            "             r'component_terminologies|revision_history)[ \\t]*\\n',",
            "             Generic.Heading, 'odin_section'),",
            "            (r'^(definition)[ \\t]*\\n', Generic.Heading, 'cadl_section'),",
            "            (r'^(rules)[ \\t]*\\n', Generic.Heading, 'rules_section'),",
            "            include('archetype_id'),",
            "            (r'[ \\t]*\\(', Punctuation, 'metadata'),",
            "            include('whitespace'),",
            "        ],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "61": [
                "AtomsLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/factor.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "             (r'(?:<PRIVATE|PRIVATE>)\\s', Keyword.Namespace),"
            },
            "1": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 266,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": 267,
                "PatchRowcode": "             # strings"
            },
            "3": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'\"\"\"\\s+(?:.|\\n)*?\\s+\"\"\"', String),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+            (r'\"\"\"\\s(?:.|\\n)*?\\s\"\"\"', String),"
            },
            "5": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "             (r'\"(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),"
            },
            "6": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 270,
                "PatchRowcode": "             (r'\\S+\"\\s+(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),"
            },
            "7": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 271,
                "PatchRowcode": "             (r'CHAR:\\s+(?:\\\\[\\\\abfnrstv]|[^\\\\]\\S*)\\s', String.Char),"
            },
            "8": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 322,
                "PatchRowcode": "         'slots': ["
            },
            "9": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": 323,
                "PatchRowcode": "             (r'\\s+', Text),"
            },
            "10": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 324,
                "PatchRowcode": "             (r';\\s', Keyword, '#pop'),"
            },
            "11": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\{\\s+)(\\S+)(\\s+[^}]+\\s+\\}\\s)',"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 325,
                "PatchRowcode": "+            (r'(\\{\\s+)(\\S+)(\\s[^}]+\\s\\}\\s)',"
            },
            "13": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": 326,
                "PatchRowcode": "              bygroups(Text, Name.Variable, Text)),"
            },
            "14": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 327,
                "PatchRowcode": "             (r'\\S+', Name.Variable),"
            },
            "15": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 328,
                "PatchRowcode": "         ],"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.factor",
            "    ~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for the Factor language.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import RegexLexer, bygroups, default, words",
            "from pygments.token import Text, Comment, Keyword, Name, String, Number",
            "",
            "__all__ = ['FactorLexer']",
            "",
            "",
            "class FactorLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for the `Factor <http://factorcode.org>`_ language.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Factor'",
            "    aliases = ['factor']",
            "    filenames = ['*.factor']",
            "    mimetypes = ['text/x-factor']",
            "",
            "    flags = re.MULTILINE | re.UNICODE",
            "",
            "    builtin_kernel = words((",
            "        '-rot', '2bi', '2bi@', '2bi*', '2curry', '2dip', '2drop', '2dup', '2keep', '2nip',",
            "        '2over', '2tri', '2tri@', '2tri*', '3bi', '3curry', '3dip', '3drop', '3dup', '3keep',",
            "        '3tri', '4dip', '4drop', '4dup', '4keep', '<wrapper>', '=', '>boolean', 'clone',",
            "        '?', '?execute', '?if', 'and', 'assert', 'assert=', 'assert?', 'bi', 'bi-curry',",
            "        'bi-curry@', 'bi-curry*', 'bi@', 'bi*', 'boa', 'boolean', 'boolean?', 'both?',",
            "        'build', 'call', 'callstack', 'callstack>array', 'callstack?', 'clear', '(clone)',",
            "        'compose', 'compose?', 'curry', 'curry?', 'datastack', 'die', 'dip', 'do', 'drop',",
            "        'dup', 'dupd', 'either?', 'eq?', 'equal?', 'execute', 'hashcode', 'hashcode*',",
            "        'identity-hashcode', 'identity-tuple', 'identity-tuple?', 'if', 'if*',",
            "        'keep', 'loop', 'most', 'new', 'nip', 'not', 'null', 'object', 'or', 'over',",
            "        'pick', 'prepose', 'retainstack', 'rot', 'same?', 'swap', 'swapd', 'throw',",
            "        'tri', 'tri-curry', 'tri-curry@', 'tri-curry*', 'tri@', 'tri*', 'tuple',",
            "        'tuple?', 'unless', 'unless*', 'until', 'when', 'when*', 'while', 'with',",
            "        'wrapper', 'wrapper?', 'xor'), suffix=r'\\s')",
            "",
            "    builtin_assocs = words((",
            "        '2cache', '<enum>', '>alist', '?at', '?of', 'assoc', 'assoc-all?',",
            "        'assoc-any?', 'assoc-clone-like', 'assoc-combine', 'assoc-diff',",
            "        'assoc-diff!', 'assoc-differ', 'assoc-each', 'assoc-empty?',",
            "        'assoc-filter', 'assoc-filter!', 'assoc-filter-as', 'assoc-find',",
            "        'assoc-hashcode', 'assoc-intersect', 'assoc-like', 'assoc-map',",
            "        'assoc-map-as', 'assoc-partition', 'assoc-refine', 'assoc-size',",
            "        'assoc-stack', 'assoc-subset?', 'assoc-union', 'assoc-union!',",
            "        'assoc=', 'assoc>map', 'assoc?', 'at', 'at+', 'at*', 'cache', 'change-at',",
            "        'clear-assoc', 'delete-at', 'delete-at*', 'enum', 'enum?', 'extract-keys',",
            "        'inc-at', 'key?', 'keys', 'map>assoc', 'maybe-set-at', 'new-assoc', 'of',",
            "        'push-at', 'rename-at', 'set-at', 'sift-keys', 'sift-values', 'substitute',",
            "        'unzip', 'value-at', 'value-at*', 'value?', 'values', 'zip'), suffix=r'\\s')",
            "",
            "    builtin_combinators = words((",
            "        '2cleave', '2cleave>quot', '3cleave', '3cleave>quot', '4cleave',",
            "        '4cleave>quot', 'alist>quot', 'call-effect', 'case', 'case-find',",
            "        'case>quot', 'cleave', 'cleave>quot', 'cond', 'cond>quot', 'deep-spread>quot',",
            "        'execute-effect', 'linear-case-quot', 'no-case', 'no-case?', 'no-cond',",
            "        'no-cond?', 'recursive-hashcode', 'shallow-spread>quot', 'spread',",
            "        'to-fixed-point', 'wrong-values', 'wrong-values?'), suffix=r'\\s')",
            "",
            "    builtin_math = words((",
            "        '-', '/', '/f', '/i', '/mod', '2/', '2^', '<', '<=', '<fp-nan>', '>',",
            "        '>=', '>bignum', '>fixnum', '>float', '>integer', '(all-integers?)',",
            "        '(each-integer)', '(find-integer)', '*', '+', '?1+',",
            "        'abs', 'align', 'all-integers?', 'bignum', 'bignum?', 'bit?', 'bitand',",
            "        'bitnot', 'bitor', 'bits>double', 'bits>float', 'bitxor', 'complex',",
            "        'complex?', 'denominator', 'double>bits', 'each-integer', 'even?',",
            "        'find-integer', 'find-last-integer', 'fixnum', 'fixnum?', 'float',",
            "        'float>bits', 'float?', 'fp-bitwise=', 'fp-infinity?', 'fp-nan-payload',",
            "        'fp-nan?', 'fp-qnan?', 'fp-sign', 'fp-snan?', 'fp-special?',",
            "        'if-zero', 'imaginary-part', 'integer', 'integer>fixnum',",
            "        'integer>fixnum-strict', 'integer?', 'log2', 'log2-expects-positive',",
            "        'log2-expects-positive?', 'mod', 'neg', 'neg?', 'next-float',",
            "        'next-power-of-2', 'number', 'number=', 'number?', 'numerator', 'odd?',",
            "        'out-of-fixnum-range', 'out-of-fixnum-range?', 'power-of-2?',",
            "        'prev-float', 'ratio', 'ratio?', 'rational', 'rational?', 'real',",
            "        'real-part', 'real?', 'recip', 'rem', 'sgn', 'shift', 'sq', 'times',",
            "        'u<', 'u<=', 'u>', 'u>=', 'unless-zero', 'unordered?', 'when-zero',",
            "        'zero?'), suffix=r'\\s')",
            "",
            "    builtin_sequences = words((",
            "        '1sequence', '2all?', '2each', '2map', '2map-as', '2map-reduce', '2reduce',",
            "        '2selector', '2sequence', '3append', '3append-as', '3each', '3map', '3map-as',",
            "        '3sequence', '4sequence', '<repetition>', '<reversed>', '<slice>', '?first',",
            "        '?last', '?nth', '?second', '?set-nth', 'accumulate', 'accumulate!',",
            "        'accumulate-as', 'all?', 'any?', 'append', 'append!', 'append-as',",
            "        'assert-sequence', 'assert-sequence=', 'assert-sequence?',",
            "        'binary-reduce', 'bounds-check', 'bounds-check?', 'bounds-error',",
            "        'bounds-error?', 'but-last', 'but-last-slice', 'cartesian-each',",
            "        'cartesian-map', 'cartesian-product', 'change-nth', 'check-slice',",
            "        'check-slice-error', 'clone-like', 'collapse-slice', 'collector',",
            "        'collector-for', 'concat', 'concat-as', 'copy', 'count', 'cut', 'cut-slice',",
            "        'cut*', 'delete-all', 'delete-slice', 'drop-prefix', 'each', 'each-from',",
            "        'each-index', 'empty?', 'exchange', 'filter', 'filter!', 'filter-as', 'find',",
            "        'find-from', 'find-index', 'find-index-from', 'find-last', 'find-last-from',",
            "        'first', 'first2', 'first3', 'first4', 'flip', 'follow', 'fourth', 'glue', 'halves',",
            "        'harvest', 'head', 'head-slice', 'head-slice*', 'head*', 'head?',",
            "        'if-empty', 'immutable', 'immutable-sequence', 'immutable-sequence?',",
            "        'immutable?', 'index', 'index-from', 'indices', 'infimum', 'infimum-by',",
            "        'insert-nth', 'interleave', 'iota', 'iota-tuple', 'iota-tuple?', 'join',",
            "        'join-as', 'last', 'last-index', 'last-index-from', 'length', 'lengthen',",
            "        'like', 'longer', 'longer?', 'longest', 'map', 'map!', 'map-as', 'map-find',",
            "        'map-find-last', 'map-index', 'map-integers', 'map-reduce', 'map-sum',",
            "        'max-length', 'member-eq?', 'member?', 'midpoint@', 'min-length',",
            "        'mismatch', 'move', 'new-like', 'new-resizable', 'new-sequence',",
            "        'non-negative-integer-expected', 'non-negative-integer-expected?',",
            "        'nth', 'nths', 'pad-head', 'pad-tail', 'padding', 'partition', 'pop', 'pop*',",
            "        'prefix', 'prepend', 'prepend-as', 'produce', 'produce-as', 'product', 'push',",
            "        'push-all', 'push-either', 'push-if', 'reduce', 'reduce-index', 'remove',",
            "        'remove!', 'remove-eq', 'remove-eq!', 'remove-nth', 'remove-nth!', 'repetition',",
            "        'repetition?', 'replace-slice', 'replicate', 'replicate-as', 'rest',",
            "        'rest-slice', 'reverse', 'reverse!', 'reversed', 'reversed?', 'second',",
            "        'selector', 'selector-for', 'sequence', 'sequence-hashcode', 'sequence=',",
            "        'sequence?', 'set-first', 'set-fourth', 'set-last', 'set-length', 'set-nth',",
            "        'set-second', 'set-third', 'short', 'shorten', 'shorter', 'shorter?',",
            "        'shortest', 'sift', 'slice', 'slice-error', 'slice-error?', 'slice?',",
            "        'snip', 'snip-slice', 'start', 'start*', 'subseq', 'subseq?', 'suffix',",
            "        'suffix!', 'sum', 'sum-lengths', 'supremum', 'supremum-by', 'surround', 'tail',",
            "        'tail-slice', 'tail-slice*', 'tail*', 'tail?', 'third', 'trim',",
            "        'trim-head', 'trim-head-slice', 'trim-slice', 'trim-tail', 'trim-tail-slice',",
            "        'unclip', 'unclip-last', 'unclip-last-slice', 'unclip-slice', 'unless-empty',",
            "        'virtual-exemplar', 'virtual-sequence', 'virtual-sequence?', 'virtual@',",
            "        'when-empty'), suffix=r'\\s')",
            "",
            "    builtin_namespaces = words((",
            "        '+@', 'change', 'change-global', 'counter', 'dec', 'get', 'get-global',",
            "        'global', 'inc', 'init-namespaces', 'initialize', 'is-global', 'make-assoc',",
            "        'namespace', 'namestack', 'off', 'on', 'set', 'set-global', 'set-namestack',",
            "        'toggle', 'with-global', 'with-scope', 'with-variable', 'with-variables'),",
            "        suffix=r'\\s')",
            "",
            "    builtin_arrays = words((",
            "        '1array', '2array', '3array', '4array', '<array>', '>array', 'array',",
            "        'array?', 'pair', 'pair?', 'resize-array'), suffix=r'\\s')",
            "",
            "    builtin_io = words((",
            "        '(each-stream-block-slice)', '(each-stream-block)',",
            "        '(stream-contents-by-block)', '(stream-contents-by-element)',",
            "        '(stream-contents-by-length-or-block)',",
            "        '(stream-contents-by-length)', '+byte+', '+character+',",
            "        'bad-seek-type', 'bad-seek-type?', 'bl', 'contents', 'each-block',",
            "        'each-block-size', 'each-block-slice', 'each-line', 'each-morsel',",
            "        'each-stream-block', 'each-stream-block-slice', 'each-stream-line',",
            "        'error-stream', 'flush', 'input-stream', 'input-stream?',",
            "        'invalid-read-buffer', 'invalid-read-buffer?', 'lines', 'nl',",
            "        'output-stream', 'output-stream?', 'print', 'read', 'read-into',",
            "        'read-partial', 'read-partial-into', 'read-until', 'read1', 'readln',",
            "        'seek-absolute', 'seek-absolute?', 'seek-end', 'seek-end?',",
            "        'seek-input', 'seek-output', 'seek-relative', 'seek-relative?',",
            "        'stream-bl', 'stream-contents', 'stream-contents*', 'stream-copy',",
            "        'stream-copy*', 'stream-element-type', 'stream-flush',",
            "        'stream-length', 'stream-lines', 'stream-nl', 'stream-print',",
            "        'stream-read', 'stream-read-into', 'stream-read-partial',",
            "        'stream-read-partial-into', 'stream-read-partial-unsafe',",
            "        'stream-read-unsafe', 'stream-read-until', 'stream-read1',",
            "        'stream-readln', 'stream-seek', 'stream-seekable?', 'stream-tell',",
            "        'stream-write', 'stream-write1', 'tell-input', 'tell-output',",
            "        'with-error-stream', 'with-error-stream*', 'with-error>output',",
            "        'with-input-output+error-streams',",
            "        'with-input-output+error-streams*', 'with-input-stream',",
            "        'with-input-stream*', 'with-output-stream', 'with-output-stream*',",
            "        'with-output>error', 'with-output+error-stream',",
            "        'with-output+error-stream*', 'with-streams', 'with-streams*',",
            "        'write', 'write1'), suffix=r'\\s')",
            "",
            "    builtin_strings = words((",
            "        '1string', '<string>', '>string', 'resize-string', 'string',",
            "        'string?'), suffix=r'\\s')",
            "",
            "    builtin_vectors = words((",
            "        '1vector', '<vector>', '>vector', '?push', 'vector', 'vector?'),",
            "        suffix=r'\\s')",
            "",
            "    builtin_continuations = words((",
            "        '<condition>', '<continuation>', '<restart>', 'attempt-all',",
            "        'attempt-all-error', 'attempt-all-error?', 'callback-error-hook',",
            "        'callcc0', 'callcc1', 'cleanup', 'compute-restarts', 'condition',",
            "        'condition?', 'continuation', 'continuation?', 'continue',",
            "        'continue-restart', 'continue-with', 'current-continuation',",
            "        'error', 'error-continuation', 'error-in-thread', 'error-thread',",
            "        'ifcc', 'ignore-errors', 'in-callback?', 'original-error', 'recover',",
            "        'restart', 'restart?', 'restarts', 'rethrow', 'rethrow-restarts',",
            "        'return', 'return-continuation', 'thread-error-hook', 'throw-continue',",
            "        'throw-restarts', 'with-datastack', 'with-return'), suffix=r'\\s')",
            "",
            "    tokens = {",
            "        'root': [",
            "            # factor allows a file to start with a shebang",
            "            (r'#!.*$', Comment.Preproc),",
            "            default('base'),",
            "        ],",
            "        'base': [",
            "            (r'\\s+', Text),",
            "",
            "            # defining words",
            "            (r'((?:MACRO|MEMO|TYPED)?:[:]?)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'(M:[:]?)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Function)),",
            "            (r'(C:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Class)),",
            "            (r'(GENERIC:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'(HOOK:|GENERIC#)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Function)),",
            "            (r'\\(\\s', Name.Function, 'stackeffect'),",
            "            (r';\\s', Keyword),",
            "",
            "            # imports and namespaces",
            "            (r'(USING:)(\\s+)',",
            "             bygroups(Keyword.Namespace, Text), 'vocabs'),",
            "            (r'(USE:|UNUSE:|IN:|QUALIFIED:)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace)),",
            "            (r'(QUALIFIED-WITH:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace, Text, Name.Namespace)),",
            "            (r'(FROM:|EXCLUDE:)(\\s+)(\\S+)(\\s+=>\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace, Text), 'words'),",
            "            (r'(RENAME:)(\\s+)(\\S+)(\\s+)(\\S+)(\\s+=>\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Namespace, Text, Name.Function)),",
            "            (r'(ALIAS:|TYPEDEF:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Function)),",
            "            (r'(DEFER:|FORGET:|POSTPONE:)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function)),",
            "",
            "            # tuples and classes",
            "            (r'(TUPLE:|ERROR:)(\\s+)(\\S+)(\\s+<\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class), 'slots'),",
            "            (r'(TUPLE:|ERROR:|BUILTIN:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class), 'slots'),",
            "            (r'(MIXIN:|UNION:|INTERSECTION:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class)),",
            "            (r'(PREDICATE:)(\\s+)(\\S+)(\\s+<\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class)),",
            "            (r'(C:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Class)),",
            "            (r'(INSTANCE:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class)),",
            "            (r'(SLOT:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Function)),",
            "            (r'(SINGLETON:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Class)),",
            "            (r'SINGLETONS:', Keyword, 'classes'),",
            "",
            "            # other syntax",
            "            (r'(CONSTANT:|SYMBOL:|MAIN:|HELP:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'SYMBOLS:\\s', Keyword, 'words'),",
            "            (r'SYNTAX:\\s', Keyword),",
            "            (r'ALIEN:\\s', Keyword),",
            "            (r'(STRUCT:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Class)),",
            "            (r'(FUNCTION:)(\\s+\\S+\\s+)(\\S+)(\\s+\\(\\s+[^)]+\\)\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text)),",
            "            (r'(FUNCTION-ALIAS:)(\\s+)(\\S+)(\\s+\\S+\\s+)(\\S+)(\\s+\\(\\s+[^)]+\\)\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Function, Text)),",
            "",
            "            # vocab.private",
            "            (r'(?:<PRIVATE|PRIVATE>)\\s', Keyword.Namespace),",
            "",
            "            # strings",
            "            (r'\"\"\"\\s+(?:.|\\n)*?\\s+\"\"\"', String),",
            "            (r'\"(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),",
            "            (r'\\S+\"\\s+(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),",
            "            (r'CHAR:\\s+(?:\\\\[\\\\abfnrstv]|[^\\\\]\\S*)\\s', String.Char),",
            "",
            "            # comments",
            "            (r'!\\s+.*$', Comment),",
            "            (r'#!\\s+.*$', Comment),",
            "            (r'/\\*\\s+(?:.|\\n)*?\\s\\*/\\s', Comment),",
            "",
            "            # boolean constants",
            "            (r'[tf]\\s', Name.Constant),",
            "",
            "            # symbols and literals",
            "            (r'[\\\\$]\\s+\\S+', Name.Constant),",
            "            (r'M\\\\\\s+\\S+\\s+\\S+', Name.Constant),",
            "",
            "            # numbers",
            "            (r'[+-]?(?:[\\d,]*\\d)?\\.(?:\\d([\\d,]*\\d)?)?(?:[eE][+-]?\\d+)?\\s', Number),",
            "            (r'[+-]?\\d(?:[\\d,]*\\d)?(?:[eE][+-]?\\d+)?\\s', Number),",
            "            (r'0x[a-fA-F\\d](?:[a-fA-F\\d,]*[a-fA-F\\d])?(?:p\\d([\\d,]*\\d)?)?\\s', Number),",
            "            (r'NAN:\\s+[a-fA-F\\d](?:[a-fA-F\\d,]*[a-fA-F\\d])?(?:p\\d([\\d,]*\\d)?)?\\s', Number),",
            "            (r'0b[01]+\\s', Number.Bin),",
            "            (r'0o[0-7]+\\s', Number.Oct),",
            "            (r'(?:\\d([\\d,]*\\d)?)?\\+\\d(?:[\\d,]*\\d)?/\\d(?:[\\d,]*\\d)?\\s', Number),",
            "            (r'(?:\\-\\d([\\d,]*\\d)?)?\\-\\d(?:[\\d,]*\\d)?/\\d(?:[\\d,]*\\d)?\\s', Number),",
            "",
            "            # keywords",
            "            (r'(?:deprecated|final|foldable|flushable|inline|recursive)\\s',",
            "             Keyword),",
            "",
            "            # builtins",
            "            (builtin_kernel, Name.Builtin),",
            "            (builtin_assocs, Name.Builtin),",
            "            (builtin_combinators, Name.Builtin),",
            "            (builtin_math, Name.Builtin),",
            "            (builtin_sequences, Name.Builtin),",
            "            (builtin_namespaces, Name.Builtin),",
            "            (builtin_arrays, Name.Builtin),",
            "            (builtin_io, Name.Builtin),",
            "            (builtin_strings, Name.Builtin),",
            "            (builtin_vectors, Name.Builtin),",
            "            (builtin_continuations, Name.Builtin),",
            "",
            "            # everything else is text",
            "            (r'\\S+', Text),",
            "        ],",
            "        'stackeffect': [",
            "            (r'\\s+', Text),",
            "            (r'\\(\\s+', Name.Function, 'stackeffect'),",
            "            (r'\\)\\s', Name.Function, '#pop'),",
            "            (r'--\\s', Name.Function),",
            "            (r'\\S+', Name.Variable),",
            "        ],",
            "        'slots': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'(\\{\\s+)(\\S+)(\\s+[^}]+\\s+\\}\\s)',",
            "             bygroups(Text, Name.Variable, Text)),",
            "            (r'\\S+', Name.Variable),",
            "        ],",
            "        'vocabs': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Namespace),",
            "        ],",
            "        'classes': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Class),",
            "        ],",
            "        'words': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Function),",
            "        ],",
            "    }"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.factor",
            "    ~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for the Factor language.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import RegexLexer, bygroups, default, words",
            "from pygments.token import Text, Comment, Keyword, Name, String, Number",
            "",
            "__all__ = ['FactorLexer']",
            "",
            "",
            "class FactorLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for the `Factor <http://factorcode.org>`_ language.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Factor'",
            "    aliases = ['factor']",
            "    filenames = ['*.factor']",
            "    mimetypes = ['text/x-factor']",
            "",
            "    flags = re.MULTILINE | re.UNICODE",
            "",
            "    builtin_kernel = words((",
            "        '-rot', '2bi', '2bi@', '2bi*', '2curry', '2dip', '2drop', '2dup', '2keep', '2nip',",
            "        '2over', '2tri', '2tri@', '2tri*', '3bi', '3curry', '3dip', '3drop', '3dup', '3keep',",
            "        '3tri', '4dip', '4drop', '4dup', '4keep', '<wrapper>', '=', '>boolean', 'clone',",
            "        '?', '?execute', '?if', 'and', 'assert', 'assert=', 'assert?', 'bi', 'bi-curry',",
            "        'bi-curry@', 'bi-curry*', 'bi@', 'bi*', 'boa', 'boolean', 'boolean?', 'both?',",
            "        'build', 'call', 'callstack', 'callstack>array', 'callstack?', 'clear', '(clone)',",
            "        'compose', 'compose?', 'curry', 'curry?', 'datastack', 'die', 'dip', 'do', 'drop',",
            "        'dup', 'dupd', 'either?', 'eq?', 'equal?', 'execute', 'hashcode', 'hashcode*',",
            "        'identity-hashcode', 'identity-tuple', 'identity-tuple?', 'if', 'if*',",
            "        'keep', 'loop', 'most', 'new', 'nip', 'not', 'null', 'object', 'or', 'over',",
            "        'pick', 'prepose', 'retainstack', 'rot', 'same?', 'swap', 'swapd', 'throw',",
            "        'tri', 'tri-curry', 'tri-curry@', 'tri-curry*', 'tri@', 'tri*', 'tuple',",
            "        'tuple?', 'unless', 'unless*', 'until', 'when', 'when*', 'while', 'with',",
            "        'wrapper', 'wrapper?', 'xor'), suffix=r'\\s')",
            "",
            "    builtin_assocs = words((",
            "        '2cache', '<enum>', '>alist', '?at', '?of', 'assoc', 'assoc-all?',",
            "        'assoc-any?', 'assoc-clone-like', 'assoc-combine', 'assoc-diff',",
            "        'assoc-diff!', 'assoc-differ', 'assoc-each', 'assoc-empty?',",
            "        'assoc-filter', 'assoc-filter!', 'assoc-filter-as', 'assoc-find',",
            "        'assoc-hashcode', 'assoc-intersect', 'assoc-like', 'assoc-map',",
            "        'assoc-map-as', 'assoc-partition', 'assoc-refine', 'assoc-size',",
            "        'assoc-stack', 'assoc-subset?', 'assoc-union', 'assoc-union!',",
            "        'assoc=', 'assoc>map', 'assoc?', 'at', 'at+', 'at*', 'cache', 'change-at',",
            "        'clear-assoc', 'delete-at', 'delete-at*', 'enum', 'enum?', 'extract-keys',",
            "        'inc-at', 'key?', 'keys', 'map>assoc', 'maybe-set-at', 'new-assoc', 'of',",
            "        'push-at', 'rename-at', 'set-at', 'sift-keys', 'sift-values', 'substitute',",
            "        'unzip', 'value-at', 'value-at*', 'value?', 'values', 'zip'), suffix=r'\\s')",
            "",
            "    builtin_combinators = words((",
            "        '2cleave', '2cleave>quot', '3cleave', '3cleave>quot', '4cleave',",
            "        '4cleave>quot', 'alist>quot', 'call-effect', 'case', 'case-find',",
            "        'case>quot', 'cleave', 'cleave>quot', 'cond', 'cond>quot', 'deep-spread>quot',",
            "        'execute-effect', 'linear-case-quot', 'no-case', 'no-case?', 'no-cond',",
            "        'no-cond?', 'recursive-hashcode', 'shallow-spread>quot', 'spread',",
            "        'to-fixed-point', 'wrong-values', 'wrong-values?'), suffix=r'\\s')",
            "",
            "    builtin_math = words((",
            "        '-', '/', '/f', '/i', '/mod', '2/', '2^', '<', '<=', '<fp-nan>', '>',",
            "        '>=', '>bignum', '>fixnum', '>float', '>integer', '(all-integers?)',",
            "        '(each-integer)', '(find-integer)', '*', '+', '?1+',",
            "        'abs', 'align', 'all-integers?', 'bignum', 'bignum?', 'bit?', 'bitand',",
            "        'bitnot', 'bitor', 'bits>double', 'bits>float', 'bitxor', 'complex',",
            "        'complex?', 'denominator', 'double>bits', 'each-integer', 'even?',",
            "        'find-integer', 'find-last-integer', 'fixnum', 'fixnum?', 'float',",
            "        'float>bits', 'float?', 'fp-bitwise=', 'fp-infinity?', 'fp-nan-payload',",
            "        'fp-nan?', 'fp-qnan?', 'fp-sign', 'fp-snan?', 'fp-special?',",
            "        'if-zero', 'imaginary-part', 'integer', 'integer>fixnum',",
            "        'integer>fixnum-strict', 'integer?', 'log2', 'log2-expects-positive',",
            "        'log2-expects-positive?', 'mod', 'neg', 'neg?', 'next-float',",
            "        'next-power-of-2', 'number', 'number=', 'number?', 'numerator', 'odd?',",
            "        'out-of-fixnum-range', 'out-of-fixnum-range?', 'power-of-2?',",
            "        'prev-float', 'ratio', 'ratio?', 'rational', 'rational?', 'real',",
            "        'real-part', 'real?', 'recip', 'rem', 'sgn', 'shift', 'sq', 'times',",
            "        'u<', 'u<=', 'u>', 'u>=', 'unless-zero', 'unordered?', 'when-zero',",
            "        'zero?'), suffix=r'\\s')",
            "",
            "    builtin_sequences = words((",
            "        '1sequence', '2all?', '2each', '2map', '2map-as', '2map-reduce', '2reduce',",
            "        '2selector', '2sequence', '3append', '3append-as', '3each', '3map', '3map-as',",
            "        '3sequence', '4sequence', '<repetition>', '<reversed>', '<slice>', '?first',",
            "        '?last', '?nth', '?second', '?set-nth', 'accumulate', 'accumulate!',",
            "        'accumulate-as', 'all?', 'any?', 'append', 'append!', 'append-as',",
            "        'assert-sequence', 'assert-sequence=', 'assert-sequence?',",
            "        'binary-reduce', 'bounds-check', 'bounds-check?', 'bounds-error',",
            "        'bounds-error?', 'but-last', 'but-last-slice', 'cartesian-each',",
            "        'cartesian-map', 'cartesian-product', 'change-nth', 'check-slice',",
            "        'check-slice-error', 'clone-like', 'collapse-slice', 'collector',",
            "        'collector-for', 'concat', 'concat-as', 'copy', 'count', 'cut', 'cut-slice',",
            "        'cut*', 'delete-all', 'delete-slice', 'drop-prefix', 'each', 'each-from',",
            "        'each-index', 'empty?', 'exchange', 'filter', 'filter!', 'filter-as', 'find',",
            "        'find-from', 'find-index', 'find-index-from', 'find-last', 'find-last-from',",
            "        'first', 'first2', 'first3', 'first4', 'flip', 'follow', 'fourth', 'glue', 'halves',",
            "        'harvest', 'head', 'head-slice', 'head-slice*', 'head*', 'head?',",
            "        'if-empty', 'immutable', 'immutable-sequence', 'immutable-sequence?',",
            "        'immutable?', 'index', 'index-from', 'indices', 'infimum', 'infimum-by',",
            "        'insert-nth', 'interleave', 'iota', 'iota-tuple', 'iota-tuple?', 'join',",
            "        'join-as', 'last', 'last-index', 'last-index-from', 'length', 'lengthen',",
            "        'like', 'longer', 'longer?', 'longest', 'map', 'map!', 'map-as', 'map-find',",
            "        'map-find-last', 'map-index', 'map-integers', 'map-reduce', 'map-sum',",
            "        'max-length', 'member-eq?', 'member?', 'midpoint@', 'min-length',",
            "        'mismatch', 'move', 'new-like', 'new-resizable', 'new-sequence',",
            "        'non-negative-integer-expected', 'non-negative-integer-expected?',",
            "        'nth', 'nths', 'pad-head', 'pad-tail', 'padding', 'partition', 'pop', 'pop*',",
            "        'prefix', 'prepend', 'prepend-as', 'produce', 'produce-as', 'product', 'push',",
            "        'push-all', 'push-either', 'push-if', 'reduce', 'reduce-index', 'remove',",
            "        'remove!', 'remove-eq', 'remove-eq!', 'remove-nth', 'remove-nth!', 'repetition',",
            "        'repetition?', 'replace-slice', 'replicate', 'replicate-as', 'rest',",
            "        'rest-slice', 'reverse', 'reverse!', 'reversed', 'reversed?', 'second',",
            "        'selector', 'selector-for', 'sequence', 'sequence-hashcode', 'sequence=',",
            "        'sequence?', 'set-first', 'set-fourth', 'set-last', 'set-length', 'set-nth',",
            "        'set-second', 'set-third', 'short', 'shorten', 'shorter', 'shorter?',",
            "        'shortest', 'sift', 'slice', 'slice-error', 'slice-error?', 'slice?',",
            "        'snip', 'snip-slice', 'start', 'start*', 'subseq', 'subseq?', 'suffix',",
            "        'suffix!', 'sum', 'sum-lengths', 'supremum', 'supremum-by', 'surround', 'tail',",
            "        'tail-slice', 'tail-slice*', 'tail*', 'tail?', 'third', 'trim',",
            "        'trim-head', 'trim-head-slice', 'trim-slice', 'trim-tail', 'trim-tail-slice',",
            "        'unclip', 'unclip-last', 'unclip-last-slice', 'unclip-slice', 'unless-empty',",
            "        'virtual-exemplar', 'virtual-sequence', 'virtual-sequence?', 'virtual@',",
            "        'when-empty'), suffix=r'\\s')",
            "",
            "    builtin_namespaces = words((",
            "        '+@', 'change', 'change-global', 'counter', 'dec', 'get', 'get-global',",
            "        'global', 'inc', 'init-namespaces', 'initialize', 'is-global', 'make-assoc',",
            "        'namespace', 'namestack', 'off', 'on', 'set', 'set-global', 'set-namestack',",
            "        'toggle', 'with-global', 'with-scope', 'with-variable', 'with-variables'),",
            "        suffix=r'\\s')",
            "",
            "    builtin_arrays = words((",
            "        '1array', '2array', '3array', '4array', '<array>', '>array', 'array',",
            "        'array?', 'pair', 'pair?', 'resize-array'), suffix=r'\\s')",
            "",
            "    builtin_io = words((",
            "        '(each-stream-block-slice)', '(each-stream-block)',",
            "        '(stream-contents-by-block)', '(stream-contents-by-element)',",
            "        '(stream-contents-by-length-or-block)',",
            "        '(stream-contents-by-length)', '+byte+', '+character+',",
            "        'bad-seek-type', 'bad-seek-type?', 'bl', 'contents', 'each-block',",
            "        'each-block-size', 'each-block-slice', 'each-line', 'each-morsel',",
            "        'each-stream-block', 'each-stream-block-slice', 'each-stream-line',",
            "        'error-stream', 'flush', 'input-stream', 'input-stream?',",
            "        'invalid-read-buffer', 'invalid-read-buffer?', 'lines', 'nl',",
            "        'output-stream', 'output-stream?', 'print', 'read', 'read-into',",
            "        'read-partial', 'read-partial-into', 'read-until', 'read1', 'readln',",
            "        'seek-absolute', 'seek-absolute?', 'seek-end', 'seek-end?',",
            "        'seek-input', 'seek-output', 'seek-relative', 'seek-relative?',",
            "        'stream-bl', 'stream-contents', 'stream-contents*', 'stream-copy',",
            "        'stream-copy*', 'stream-element-type', 'stream-flush',",
            "        'stream-length', 'stream-lines', 'stream-nl', 'stream-print',",
            "        'stream-read', 'stream-read-into', 'stream-read-partial',",
            "        'stream-read-partial-into', 'stream-read-partial-unsafe',",
            "        'stream-read-unsafe', 'stream-read-until', 'stream-read1',",
            "        'stream-readln', 'stream-seek', 'stream-seekable?', 'stream-tell',",
            "        'stream-write', 'stream-write1', 'tell-input', 'tell-output',",
            "        'with-error-stream', 'with-error-stream*', 'with-error>output',",
            "        'with-input-output+error-streams',",
            "        'with-input-output+error-streams*', 'with-input-stream',",
            "        'with-input-stream*', 'with-output-stream', 'with-output-stream*',",
            "        'with-output>error', 'with-output+error-stream',",
            "        'with-output+error-stream*', 'with-streams', 'with-streams*',",
            "        'write', 'write1'), suffix=r'\\s')",
            "",
            "    builtin_strings = words((",
            "        '1string', '<string>', '>string', 'resize-string', 'string',",
            "        'string?'), suffix=r'\\s')",
            "",
            "    builtin_vectors = words((",
            "        '1vector', '<vector>', '>vector', '?push', 'vector', 'vector?'),",
            "        suffix=r'\\s')",
            "",
            "    builtin_continuations = words((",
            "        '<condition>', '<continuation>', '<restart>', 'attempt-all',",
            "        'attempt-all-error', 'attempt-all-error?', 'callback-error-hook',",
            "        'callcc0', 'callcc1', 'cleanup', 'compute-restarts', 'condition',",
            "        'condition?', 'continuation', 'continuation?', 'continue',",
            "        'continue-restart', 'continue-with', 'current-continuation',",
            "        'error', 'error-continuation', 'error-in-thread', 'error-thread',",
            "        'ifcc', 'ignore-errors', 'in-callback?', 'original-error', 'recover',",
            "        'restart', 'restart?', 'restarts', 'rethrow', 'rethrow-restarts',",
            "        'return', 'return-continuation', 'thread-error-hook', 'throw-continue',",
            "        'throw-restarts', 'with-datastack', 'with-return'), suffix=r'\\s')",
            "",
            "    tokens = {",
            "        'root': [",
            "            # factor allows a file to start with a shebang",
            "            (r'#!.*$', Comment.Preproc),",
            "            default('base'),",
            "        ],",
            "        'base': [",
            "            (r'\\s+', Text),",
            "",
            "            # defining words",
            "            (r'((?:MACRO|MEMO|TYPED)?:[:]?)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'(M:[:]?)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Function)),",
            "            (r'(C:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Class)),",
            "            (r'(GENERIC:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'(HOOK:|GENERIC#)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Function)),",
            "            (r'\\(\\s', Name.Function, 'stackeffect'),",
            "            (r';\\s', Keyword),",
            "",
            "            # imports and namespaces",
            "            (r'(USING:)(\\s+)',",
            "             bygroups(Keyword.Namespace, Text), 'vocabs'),",
            "            (r'(USE:|UNUSE:|IN:|QUALIFIED:)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace)),",
            "            (r'(QUALIFIED-WITH:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace, Text, Name.Namespace)),",
            "            (r'(FROM:|EXCLUDE:)(\\s+)(\\S+)(\\s+=>\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace, Text), 'words'),",
            "            (r'(RENAME:)(\\s+)(\\S+)(\\s+)(\\S+)(\\s+=>\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Namespace, Text, Name.Function)),",
            "            (r'(ALIAS:|TYPEDEF:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Function)),",
            "            (r'(DEFER:|FORGET:|POSTPONE:)(\\s+)(\\S+)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function)),",
            "",
            "            # tuples and classes",
            "            (r'(TUPLE:|ERROR:)(\\s+)(\\S+)(\\s+<\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class), 'slots'),",
            "            (r'(TUPLE:|ERROR:|BUILTIN:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class), 'slots'),",
            "            (r'(MIXIN:|UNION:|INTERSECTION:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class)),",
            "            (r'(PREDICATE:)(\\s+)(\\S+)(\\s+<\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class)),",
            "            (r'(C:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function, Text, Name.Class)),",
            "            (r'(INSTANCE:)(\\s+)(\\S+)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Class, Text, Name.Class)),",
            "            (r'(SLOT:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Function)),",
            "            (r'(SINGLETON:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Class)),",
            "            (r'SINGLETONS:', Keyword, 'classes'),",
            "",
            "            # other syntax",
            "            (r'(CONSTANT:|SYMBOL:|MAIN:|HELP:)(\\s+)(\\S+)',",
            "             bygroups(Keyword, Text, Name.Function)),",
            "            (r'SYMBOLS:\\s', Keyword, 'words'),",
            "            (r'SYNTAX:\\s', Keyword),",
            "            (r'ALIEN:\\s', Keyword),",
            "            (r'(STRUCT:)(\\s+)(\\S+)', bygroups(Keyword, Text, Name.Class)),",
            "            (r'(FUNCTION:)(\\s+\\S+\\s+)(\\S+)(\\s+\\(\\s+[^)]+\\)\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text)),",
            "            (r'(FUNCTION-ALIAS:)(\\s+)(\\S+)(\\s+\\S+\\s+)(\\S+)(\\s+\\(\\s+[^)]+\\)\\s)',",
            "             bygroups(Keyword.Namespace, Text, Name.Function, Text, Name.Function, Text)),",
            "",
            "            # vocab.private",
            "            (r'(?:<PRIVATE|PRIVATE>)\\s', Keyword.Namespace),",
            "",
            "            # strings",
            "            (r'\"\"\"\\s(?:.|\\n)*?\\s\"\"\"', String),",
            "            (r'\"(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),",
            "            (r'\\S+\"\\s+(?:\\\\\\\\|\\\\\"|[^\"])*\"', String),",
            "            (r'CHAR:\\s+(?:\\\\[\\\\abfnrstv]|[^\\\\]\\S*)\\s', String.Char),",
            "",
            "            # comments",
            "            (r'!\\s+.*$', Comment),",
            "            (r'#!\\s+.*$', Comment),",
            "            (r'/\\*\\s+(?:.|\\n)*?\\s\\*/\\s', Comment),",
            "",
            "            # boolean constants",
            "            (r'[tf]\\s', Name.Constant),",
            "",
            "            # symbols and literals",
            "            (r'[\\\\$]\\s+\\S+', Name.Constant),",
            "            (r'M\\\\\\s+\\S+\\s+\\S+', Name.Constant),",
            "",
            "            # numbers",
            "            (r'[+-]?(?:[\\d,]*\\d)?\\.(?:\\d([\\d,]*\\d)?)?(?:[eE][+-]?\\d+)?\\s', Number),",
            "            (r'[+-]?\\d(?:[\\d,]*\\d)?(?:[eE][+-]?\\d+)?\\s', Number),",
            "            (r'0x[a-fA-F\\d](?:[a-fA-F\\d,]*[a-fA-F\\d])?(?:p\\d([\\d,]*\\d)?)?\\s', Number),",
            "            (r'NAN:\\s+[a-fA-F\\d](?:[a-fA-F\\d,]*[a-fA-F\\d])?(?:p\\d([\\d,]*\\d)?)?\\s', Number),",
            "            (r'0b[01]+\\s', Number.Bin),",
            "            (r'0o[0-7]+\\s', Number.Oct),",
            "            (r'(?:\\d([\\d,]*\\d)?)?\\+\\d(?:[\\d,]*\\d)?/\\d(?:[\\d,]*\\d)?\\s', Number),",
            "            (r'(?:\\-\\d([\\d,]*\\d)?)?\\-\\d(?:[\\d,]*\\d)?/\\d(?:[\\d,]*\\d)?\\s', Number),",
            "",
            "            # keywords",
            "            (r'(?:deprecated|final|foldable|flushable|inline|recursive)\\s',",
            "             Keyword),",
            "",
            "            # builtins",
            "            (builtin_kernel, Name.Builtin),",
            "            (builtin_assocs, Name.Builtin),",
            "            (builtin_combinators, Name.Builtin),",
            "            (builtin_math, Name.Builtin),",
            "            (builtin_sequences, Name.Builtin),",
            "            (builtin_namespaces, Name.Builtin),",
            "            (builtin_arrays, Name.Builtin),",
            "            (builtin_io, Name.Builtin),",
            "            (builtin_strings, Name.Builtin),",
            "            (builtin_vectors, Name.Builtin),",
            "            (builtin_continuations, Name.Builtin),",
            "",
            "            # everything else is text",
            "            (r'\\S+', Text),",
            "        ],",
            "        'stackeffect': [",
            "            (r'\\s+', Text),",
            "            (r'\\(\\s+', Name.Function, 'stackeffect'),",
            "            (r'\\)\\s', Name.Function, '#pop'),",
            "            (r'--\\s', Name.Function),",
            "            (r'\\S+', Name.Variable),",
            "        ],",
            "        'slots': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'(\\{\\s+)(\\S+)(\\s[^}]+\\s\\}\\s)',",
            "             bygroups(Text, Name.Variable, Text)),",
            "            (r'\\S+', Name.Variable),",
            "        ],",
            "        'vocabs': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Namespace),",
            "        ],",
            "        'classes': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Class),",
            "        ],",
            "        'words': [",
            "            (r'\\s+', Text),",
            "            (r';\\s', Keyword, '#pop'),",
            "            (r'\\S+', Name.Function),",
            "        ],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "268": [
                "FactorLexer"
            ],
            "325": [
                "FactorLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/jvm.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 981,
                "afterPatchRowNumber": 981,
                "PatchRowcode": "             (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),"
            },
            "1": {
                "beforePatchRowNumber": 982,
                "afterPatchRowNumber": 982,
                "PatchRowcode": "             (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),"
            },
            "2": {
                "beforePatchRowNumber": 983,
                "afterPatchRowNumber": 983,
                "PatchRowcode": "             (r\"'\\\\.'|'[^\\\\]'|'\\\\\\{#[0-9a-fA-F]{4}\\}'\", String.Char),"
            },
            "3": {
                "beforePatchRowNumber": 984,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'\".*``.*``.*\"', String.Interpol),"
            },
            "4": {
                "beforePatchRowNumber": 985,
                "afterPatchRowNumber": 984,
                "PatchRowcode": "             (r'(\\.)([a-z_]\\w*)',"
            },
            "5": {
                "beforePatchRowNumber": 986,
                "afterPatchRowNumber": 985,
                "PatchRowcode": "              bygroups(Operator, Name.Attribute)),"
            },
            "6": {
                "beforePatchRowNumber": 987,
                "afterPatchRowNumber": 986,
                "PatchRowcode": "             (r'[a-zA-Z_]\\w*:', Name.Label),"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.jvm",
            "    ~~~~~~~~~~~~~~~~~~~",
            "",
            "    Pygments lexers for JVM languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import Lexer, RegexLexer, include, bygroups, using, \\",
            "    this, combined, default, words",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation",
            "from pygments.util import shebang_matches",
            "from pygments import unistring as uni",
            "",
            "__all__ = ['JavaLexer', 'ScalaLexer', 'GosuLexer', 'GosuTemplateLexer',",
            "           'GroovyLexer', 'IokeLexer', 'ClojureLexer', 'ClojureScriptLexer',",
            "           'KotlinLexer', 'XtendLexer', 'AspectJLexer', 'CeylonLexer',",
            "           'PigLexer', 'GoloLexer', 'JasminLexer', 'SarlLexer']",
            "",
            "",
            "class JavaLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Java <https://www.oracle.com/technetwork/java/>`_ source code.",
            "    \"\"\"",
            "",
            "    name = 'Java'",
            "    aliases = ['java']",
            "    filenames = ['*.java']",
            "    mimetypes = ['text/x-java']",
            "",
            "    flags = re.MULTILINE | re.DOTALL | re.UNICODE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            # keywords: go before method names to avoid lexing \"throw new XYZ\"",
            "            # as a method signature",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while)\\b',",
            "             Keyword),",
            "            # method names",
            "            (r'((?:(?:[^\\W\\d]|\\$)[\\w.\\[\\]$<>]*\\s+)+?)'  # return arguments",
            "             r'((?:[^\\W\\d]|\\$)[\\w$]*)'                  # method name",
            "             r'(\\s*)(\\()',                              # signature start",
            "             bygroups(using(this), Name.Function, Text, Punctuation)),",
            "            (r'@[^\\W\\d][\\w.]*', Name.Decorator),",
            "            (r'(abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(var)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'var'),",
            "            (r'(import(?:\\s+static)?)(\\s+)', bygroups(Keyword.Namespace, Text),",
            "             'import'),",
            "            (r'\"', String, 'string'),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r'(\\.)((?:[^\\W\\d]|\\$)[\\w$]*)', bygroups(Punctuation,",
            "                                                     Name.Attribute)),",
            "            (r'^\\s*([^\\W\\d]|\\$)[\\w$]*:', Name.Label),",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name),",
            "            (r'([0-9][0-9_]*\\.([0-9][0-9_]*)?|'",
            "             r'\\.[0-9][0-9_]*)'",
            "             r'([eE][+\\-]?[0-9][0-9_]*)?[fFdD]?|'",
            "             r'[0-9][eE][+\\-]?[0-9][0-9_]*[fFdD]?|'",
            "             r'[0-9]([eE][+\\-]?[0-9][0-9_]*)?[fFdD]|'",
            "             r'0[xX]([0-9a-fA-F][0-9a-fA-F_]*\\.?|'",
            "             r'([0-9a-fA-F][0-9a-fA-F_]*)?\\.[0-9a-fA-F][0-9a-fA-F_]*)'",
            "             r'[pP][+\\-]?[0-9][0-9_]*[fFdD]?', Number.Float),",
            "            (r'0[xX][0-9a-fA-F][0-9a-fA-F_]*[lL]?', Number.Hex),",
            "            (r'0[bB][01][01_]*[lL]?', Number.Bin),",
            "            (r'0[0-7_]+[lL]?', Number.Oct),",
            "            (r'0|[1-9][0-9_]*[lL]?', Number.Integer),",
            "            (r'[~^*!%&\\[\\]<>|+=/?-]', Operator),",
            "            (r'[{}();:.,]', Punctuation),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name.Class, '#pop')",
            "        ],",
            "        'var': [",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'string': [",
            "            (r'[^\\\\\"]+', String),",
            "            (r'\\\\\\\\', String),  # Escaped backslash",
            "            (r'\\\\\"', String),  # Escaped quote",
            "            (r'\\\\', String),  # Bare backslash",
            "            (r'\"', String, '#pop'),  # Closing quote",
            "        ],",
            "    }",
            "",
            "",
            "class AspectJLexer(JavaLexer):",
            "    \"\"\"",
            "    For `AspectJ <http://www.eclipse.org/aspectj/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'AspectJ'",
            "    aliases = ['aspectj']",
            "    filenames = ['*.aj']",
            "    mimetypes = ['text/x-aspectj']",
            "",
            "    aj_keywords = {",
            "        'aspect', 'pointcut', 'privileged', 'call', 'execution',",
            "        'initialization', 'preinitialization', 'handler', 'get', 'set',",
            "        'staticinitialization', 'target', 'args', 'within', 'withincode',",
            "        'cflow', 'cflowbelow', 'annotation', 'before', 'after', 'around',",
            "        'proceed', 'throwing', 'returning', 'adviceexecution', 'declare',",
            "        'parents', 'warning', 'error', 'soft', 'precedence', 'thisJoinPoint',",
            "        'thisJoinPointStaticPart', 'thisEnclosingJoinPointStaticPart',",
            "        'issingleton', 'perthis', 'pertarget', 'percflow', 'percflowbelow',",
            "        'pertypewithin', 'lock', 'unlock', 'thisAspectInstance'",
            "    }",
            "    aj_inter_type = {'parents:', 'warning:', 'error:', 'soft:', 'precedence:'}",
            "    aj_inter_type_annotation = {'@type', '@method', '@constructor', '@field'}",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        for index, token, value in JavaLexer.get_tokens_unprocessed(self, text):",
            "            if token is Name and value in self.aj_keywords:",
            "                yield index, Keyword, value",
            "            elif token is Name.Label and value in self.aj_inter_type:",
            "                yield index, Keyword, value[:-1]",
            "                yield index, Operator, value[-1]",
            "            elif token is Name.Decorator and value in self.aj_inter_type_annotation:",
            "                yield index, Keyword, value",
            "            else:",
            "                yield index, token, value",
            "",
            "",
            "class ScalaLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Scala <http://www.scala-lang.org>`_ source code.",
            "    \"\"\"",
            "",
            "    name = 'Scala'",
            "    aliases = ['scala']",
            "    filenames = ['*.scala']",
            "    mimetypes = ['text/x-scala']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    # don't use raw unicode strings!",
            "    op = ('[-~\\\\^\\\\*!%&\\\\\\\\<>\\\\|+=:/?@\\u00a6-\\u00a7\\u00a9\\u00ac\\u00ae\\u00b0-\\u00b1'",
            "          '\\u00b6\\u00d7\\u00f7\\u03f6\\u0482\\u0606-\\u0608\\u060e-\\u060f\\u06e9'",
            "          '\\u06fd-\\u06fe\\u07f6\\u09fa\\u0b70\\u0bf3-\\u0bf8\\u0bfa\\u0c7f\\u0cf1-\\u0cf2'",
            "          '\\u0d79\\u0f01-\\u0f03\\u0f13-\\u0f17\\u0f1a-\\u0f1f\\u0f34\\u0f36\\u0f38'",
            "          '\\u0fbe-\\u0fc5\\u0fc7-\\u0fcf\\u109e-\\u109f\\u1360\\u1390-\\u1399\\u1940'",
            "          '\\u19e0-\\u19ff\\u1b61-\\u1b6a\\u1b74-\\u1b7c\\u2044\\u2052\\u207a-\\u207c'",
            "          '\\u208a-\\u208c\\u2100-\\u2101\\u2103-\\u2106\\u2108-\\u2109\\u2114\\u2116-\\u2118'",
            "          '\\u211e-\\u2123\\u2125\\u2127\\u2129\\u212e\\u213a-\\u213b\\u2140-\\u2144'",
            "          '\\u214a-\\u214d\\u214f\\u2190-\\u2328\\u232b-\\u244a\\u249c-\\u24e9\\u2500-\\u2767'",
            "          '\\u2794-\\u27c4\\u27c7-\\u27e5\\u27f0-\\u2982\\u2999-\\u29d7\\u29dc-\\u29fb'",
            "          '\\u29fe-\\u2b54\\u2ce5-\\u2cea\\u2e80-\\u2ffb\\u3004\\u3012-\\u3013\\u3020'",
            "          '\\u3036-\\u3037\\u303e-\\u303f\\u3190-\\u3191\\u3196-\\u319f\\u31c0-\\u31e3'",
            "          '\\u3200-\\u321e\\u322a-\\u3250\\u3260-\\u327f\\u328a-\\u32b0\\u32c0-\\u33ff'",
            "          '\\u4dc0-\\u4dff\\ua490-\\ua4c6\\ua828-\\ua82b\\ufb29\\ufdfd\\ufe62\\ufe64-\\ufe66'",
            "          '\\uff0b\\uff1c-\\uff1e\\uff5c\\uff5e\\uffe2\\uffe4\\uffe8-\\uffee\\ufffc-\\ufffd]+')",
            "",
            "    letter = ('[a-zA-Z\\\\$_\\u00aa\\u00b5\\u00ba\\u00c0-\\u00d6\\u00d8-\\u00f6'",
            "              '\\u00f8-\\u02af\\u0370-\\u0373\\u0376-\\u0377\\u037b-\\u037d\\u0386'",
            "              '\\u0388-\\u03f5\\u03f7-\\u0481\\u048a-\\u0556\\u0561-\\u0587\\u05d0-\\u05f2'",
            "              '\\u0621-\\u063f\\u0641-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5'",
            "              '\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5'",
            "              '\\u07b1\\u07ca-\\u07ea\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961'",
            "              '\\u0972-\\u097f\\u0985-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09e1\\u09f0-\\u09f1'",
            "              '\\u0a05-\\u0a39\\u0a59-\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0ab9\\u0abd'",
            "              '\\u0ad0-\\u0ae1\\u0b05-\\u0b39\\u0b3d\\u0b5c-\\u0b61\\u0b71\\u0b83-\\u0bb9'",
            "              '\\u0bd0\\u0c05-\\u0c3d\\u0c58-\\u0c61\\u0c85-\\u0cb9\\u0cbd\\u0cde-\\u0ce1'",
            "              '\\u0d05-\\u0d3d\\u0d60-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0dc6\\u0e01-\\u0e30'",
            "              '\\u0e32-\\u0e33\\u0e40-\\u0e45\\u0e81-\\u0eb0\\u0eb2-\\u0eb3\\u0ebd-\\u0ec4'",
            "              '\\u0edc-\\u0f00\\u0f40-\\u0f6c\\u0f88-\\u0f8b\\u1000-\\u102a\\u103f'",
            "              '\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070'",
            "              '\\u1075-\\u1081\\u108e\\u10a0-\\u10fa\\u1100-\\u135a\\u1380-\\u138f'",
            "              '\\u13a0-\\u166c\\u166f-\\u1676\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u1711'",
            "              '\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u1770\\u1780-\\u17b3\\u17dc'",
            "              '\\u1820-\\u1842\\u1844-\\u18a8\\u18aa-\\u191c\\u1950-\\u19a9\\u19c1-\\u19c7'",
            "              '\\u1a00-\\u1a16\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf'",
            "              '\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c77\\u1d00-\\u1d2b\\u1d62-\\u1d77'",
            "              '\\u1d79-\\u1d9a\\u1e00-\\u1fbc\\u1fbe\\u1fc2-\\u1fcc\\u1fd0-\\u1fdb'",
            "              '\\u1fe0-\\u1fec\\u1ff2-\\u1ffc\\u2071\\u207f\\u2102\\u2107\\u210a-\\u2113'",
            "              '\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u212f-\\u2139'",
            "              '\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c7c'",
            "              '\\u2c80-\\u2ce4\\u2d00-\\u2d65\\u2d80-\\u2dde\\u3006-\\u3007\\u3021-\\u3029'",
            "              '\\u3038-\\u303a\\u303c\\u3041-\\u3096\\u309f\\u30a1-\\u30fa\\u30ff-\\u318e'",
            "              '\\u31a0-\\u31b7\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\ua014\\ua016-\\ua48c'",
            "              '\\ua500-\\ua60b\\ua610-\\ua61f\\ua62a-\\ua66e\\ua680-\\ua697\\ua722-\\ua76f'",
            "              '\\ua771-\\ua787\\ua78b-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822'",
            "              '\\ua840-\\ua873\\ua882-\\ua8b3\\ua90a-\\ua925\\ua930-\\ua946\\uaa00-\\uaa28'",
            "              '\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uac00-\\ud7a3\\uf900-\\ufb1d\\ufb1f-\\ufb28'",
            "              '\\ufb2a-\\ufd3d\\ufd50-\\ufdfb\\ufe70-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a'",
            "              '\\uff66-\\uff6f\\uff71-\\uff9d\\uffa0-\\uffdc]')",
            "",
            "    upper = ('[A-Z\\\\$_\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108'",
            "             '\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c'",
            "             '\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130'",
            "             '\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145'",
            "             '\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a'",
            "             '\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e'",
            "             '\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182'",
            "             '\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194'",
            "             '\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7'",
            "             '\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc'",
            "             '\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9'",
            "             '\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee'",
            "             '\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204'",
            "             '\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218'",
            "             '\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c'",
            "             '\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246'",
            "             '\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038f'",
            "             '\\u0391-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0'",
            "             '\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7'",
            "             '\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a'",
            "             '\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e'",
            "             '\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a'",
            "             '\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae'",
            "             '\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1'",
            "             '\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6'",
            "             '\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea'",
            "             '\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe'",
            "             '\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512'",
            "             '\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0531-\\u0556'",
            "             '\\u10a0-\\u10c5\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e'",
            "             '\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22'",
            "             '\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36'",
            "             '\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a'",
            "             '\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e'",
            "             '\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72'",
            "             '\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86'",
            "             '\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2'",
            "             '\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6'",
            "             '\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca'",
            "             '\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede'",
            "             '\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2'",
            "             '\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d'",
            "             '\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59-\\u1f5f'",
            "             '\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb'",
            "             '\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112'",
            "             '\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133'",
            "             '\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67'",
            "             '\\u2c69\\u2c6b\\u2c6d-\\u2c6f\\u2c72\\u2c75\\u2c80\\u2c82\\u2c84\\u2c86'",
            "             '\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a'",
            "             '\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae'",
            "             '\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2'",
            "             '\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6'",
            "             '\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\ua640\\ua642\\ua644\\ua646'",
            "             '\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a'",
            "             '\\ua65c\\ua65e\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682'",
            "             '\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696'",
            "             '\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736'",
            "             '\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a'",
            "             '\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e'",
            "             '\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b'",
            "             '\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\uff21-\\uff3a]')",
            "",
            "    idrest = '%s(?:%s|[0-9])*(?:(?<=_)%s)?' % (letter, letter, op)",
            "    letter_letter_digit = '%s(?:%s|\\\\d)*' % (letter, letter)",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'(class|trait|object)(\\s+)', bygroups(Keyword, Text), 'class'),",
            "            (r'[^\\S\\n]+', Text),",
            "            include('comments'),",
            "            (r'@%s' % idrest, Name.Decorator),",
            "            (r'(abstract|ca(?:se|tch)|d(?:ef|o)|e(?:lse|xtends)|'",
            "             r'f(?:inal(?:ly)?|or(?:Some)?)|i(?:f|mplicit)|'",
            "             r'lazy|match|new|override|pr(?:ivate|otected)'",
            "             r'|re(?:quires|turn)|s(?:ealed|uper)|'",
            "             r't(?:h(?:is|row)|ry)|va[lr]|w(?:hile|ith)|yield)\\b|'",
            "             r'(<[%:-]|=>|>:|[#=@_\\u21D2\\u2190])\\b', Keyword),",
            "            (r':(?!%s)' % op, Keyword, 'type'),",
            "            (r'%s%s\\b' % (upper, idrest), Name.Class),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(import|package)(\\s+)', bygroups(Keyword, Text), 'import'),",
            "            (r'(type)(\\s+)', bygroups(Keyword, Text), 'type'),",
            "            (r'\"\"\".*?\"\"\"(?!\")', String),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r\"'%s\" % idrest, Text.Symbol),",
            "            (r'[fs]\"\"\"', String, 'interptriplestring'),  # interpolated strings",
            "            (r'[fs]\"', String, 'interpstring'),  # interpolated strings",
            "            (r'raw\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),  # raw strings",
            "            # (r'(\\.)(%s|%s|`[^`]+`)' % (idrest, op), bygroups(Operator,",
            "            # Name.Attribute)),",
            "            (idrest, Name),",
            "            (r'`[^`]+`', Name),",
            "            (r'\\[', Operator, 'typeparam'),",
            "            (r'[(){};,.#]', Operator),",
            "            (op, Operator),",
            "            (r'([0-9][0-9]*\\.[0-9]*|\\.[0-9]+)([eE][+-]?[0-9]+)?[fFdD]?',",
            "             Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'(%s|%s|`[^`]+`)(\\s*)(\\[)' % (idrest, op),",
            "             bygroups(Name.Class, Text, Operator), ('#pop', 'typeparam')),",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r'\\{', Operator, '#pop'),",
            "            (r'\\(', Operator, '#pop'),",
            "            (r'%s|%s|`[^`]+`' % (idrest, op), Name.Class, '#pop'),",
            "        ],",
            "        'type': [",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r'<[%:]|>:|[#_]|\\bforSome\\b|\\btype\\b', Keyword),",
            "            (r'([,);}]|=>|=|\\u21d2)(\\s*)', bygroups(Operator, Text), '#pop'),",
            "            (r'[({]', Operator, '#push'),",
            "            (r'((?:%s|%s|`[^`]+`)(?:\\.(?:%s|%s|`[^`]+`))*)(\\s*)(\\[)' %",
            "             (idrest, op, idrest, op),",
            "             bygroups(Keyword.Type, Text, Operator), ('#pop', 'typeparam')),",
            "            (r'((?:%s|%s|`[^`]+`)(?:\\.(?:%s|%s|`[^`]+`))*)(\\s*)$' %",
            "             (idrest, op, idrest, op),",
            "             bygroups(Keyword.Type, Text), '#pop'),",
            "            (r'\\.|%s|%s|`[^`]+`' % (idrest, op), Keyword.Type)",
            "        ],",
            "        'typeparam': [",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r',+', Punctuation),",
            "            (r'<[%:]|=>|>:|[#_\\u21D2]|\\bforSome\\b|\\btype\\b', Keyword),",
            "            (r'([\\])}])', Operator, '#pop'),",
            "            (r'[(\\[{]', Operator, '#push'),",
            "            (r'\\.|%s|%s|`[^`]+`' % (idrest, op), Keyword.Type)",
            "        ],",
            "        'comments': [",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "        ],",
            "        'comment': [",
            "            (r'[^/*]+', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "        'import': [",
            "            (r'(%s|\\.)+' % idrest, Name.Namespace, '#pop')",
            "        ],",
            "        'interpstringcommon': [",
            "            (r'[^\"$\\\\]+', String),",
            "            (r'\\$\\$', String),",
            "            (r'\\$' + letter_letter_digit, String.Interpol),",
            "            (r'\\$\\{', String.Interpol, 'interpbrace'),",
            "            (r'\\\\.', String),",
            "        ],",
            "        'interptriplestring': [",
            "            (r'\"\"\"(?!\")', String, '#pop'),",
            "            (r'\"', String),",
            "            include('interpstringcommon'),",
            "        ],",
            "        'interpstring': [",
            "            (r'\"', String, '#pop'),",
            "            include('interpstringcommon'),",
            "        ],",
            "        'interpbrace': [",
            "            (r'\\}', String.Interpol, '#pop'),",
            "            (r'\\{', String.Interpol, '#push'),",
            "            include('root'),",
            "        ],",
            "    }",
            "",
            "",
            "class GosuLexer(RegexLexer):",
            "    \"\"\"",
            "    For Gosu source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Gosu'",
            "    aliases = ['gosu']",
            "    filenames = ['*.gs', '*.gsx', '*.gsp', '*.vark']",
            "    mimetypes = ['text/x-gosu']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # modifiers etc.",
            "             r'([a-zA-Z_]\\w*)'                       # method name",
            "             r'(\\s*)(\\()',                           # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(in|as|typeof|statictypeof|typeis|typeas|if|else|foreach|for|'",
            "             r'index|while|do|continue|break|return|try|catch|finally|this|'",
            "             r'throw|new|switch|case|default|eval|super|outer|classpath|'",
            "             r'using)\\b', Keyword),",
            "            (r'(var|delegate|construct|function|private|internal|protected|'",
            "             r'public|abstract|override|final|static|extends|transient|'",
            "             r'implements|represents|readonly)\\b', Keyword.Declaration),",
            "            (r'(property\\s+)(get|set)?', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void|block)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null|NaN|Infinity)\\b', Keyword.Constant),",
            "            (r'(class|interface|enhancement|enum)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Class)),",
            "            (r'(uses)(\\s+)([\\w.]+\\*?)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace)),",
            "            (r'\"', String, 'string'),",
            "            (r'(\\??[.#])([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'(:)([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'and|or|not|[\\\\~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'[0-9]+', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'templateText': [",
            "            (r'(\\\\<)|(\\\\\\$)', String),",
            "            (r'(<%@\\s+)(extends|params)',",
            "             bygroups(Operator, Name.Decorator), 'stringTemplate'),",
            "            (r'<%!--.*?--%>', Comment.Multiline),",
            "            (r'(<%)|(<%=)', Operator, 'stringTemplate'),",
            "            (r'\\$\\{', Operator, 'stringTemplateShorthand'),",
            "            (r'.', String)",
            "        ],",
            "        'string': [",
            "            (r'\"', String, '#pop'),",
            "            include('templateText')",
            "        ],",
            "        'stringTemplate': [",
            "            (r'\"', String, 'string'),",
            "            (r'%>', Operator, '#pop'),",
            "            include('root')",
            "        ],",
            "        'stringTemplateShorthand': [",
            "            (r'\"', String, 'string'),",
            "            (r'\\{', Operator, 'stringTemplateShorthand'),",
            "            (r'\\}', Operator, '#pop'),",
            "            include('root')",
            "        ],",
            "    }",
            "",
            "",
            "class GosuTemplateLexer(Lexer):",
            "    \"\"\"",
            "    For Gosu templates.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Gosu Template'",
            "    aliases = ['gst']",
            "    filenames = ['*.gst']",
            "    mimetypes = ['text/x-gosu-template']",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        lexer = GosuLexer()",
            "        stack = ['templateText']",
            "        yield from lexer.get_tokens_unprocessed(text, stack)",
            "",
            "",
            "class GroovyLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Groovy <http://groovy.codehaus.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Groovy'",
            "    aliases = ['groovy']",
            "    filenames = ['*.groovy','*.gradle']",
            "    mimetypes = ['text/x-groovy']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # Groovy allows a file to start with a shebang",
            "            (r'#!(.*?)$', Comment.Preproc, 'base'),",
            "            default('base'),",
            "        ],",
            "        'base': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                      # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while|in|as)\\b',",
            "             Keyword),",
            "            (r'(abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(def|boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"\"\".*?\"\"\"', String.Double),",
            "            (r\"'''.*?'''\", String.Single),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'\\$/((?!/\\$).)*/\\$', String),",
            "            (r'/(\\\\\\\\|\\\\[^\\\\]|[^/\\\\])*/', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r'(\\.)([a-zA-Z_]\\w*)', bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        return shebang_matches(text, r'groovy')",
            "",
            "",
            "class IokeLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Ioke <http://ioke.org/>`_ (a strongly typed, dynamic,",
            "    prototype based programming language) source.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Ioke'",
            "    filenames = ['*.ik']",
            "    aliases = ['ioke', 'ik']",
            "    mimetypes = ['text/x-iokesrc']",
            "    tokens = {",
            "        'interpolatableText': [",
            "            (r'(\\\\b|\\\\e|\\\\t|\\\\n|\\\\f|\\\\r|\\\\\"|\\\\\\\\|\\\\#|\\\\\\Z|\\\\u[0-9a-fA-F]{1,4}'",
            "             r'|\\\\[0-3]?[0-7]?[0-7])', String.Escape),",
            "            (r'#\\{', Punctuation, 'textInterpolationRoot')",
            "        ],",
            "",
            "        'text': [",
            "            (r'(?<!\\\\)\"', String, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\"]', String)",
            "        ],",
            "",
            "        'documentation': [",
            "            (r'(?<!\\\\)\"', String.Doc, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\"]', String.Doc)",
            "        ],",
            "",
            "        'textInterpolationRoot': [",
            "            (r'\\}', Punctuation, '#pop'),",
            "            include('root')",
            "        ],",
            "",
            "        'slashRegexp': [",
            "            (r'(?<!\\\\)/[im-psux]*', String.Regex, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'\\\\/', String.Regex),",
            "            (r'[^/]', String.Regex)",
            "        ],",
            "",
            "        'squareRegexp': [",
            "            (r'(?<!\\\\)][im-psux]*', String.Regex, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'\\\\]', String.Regex),",
            "            (r'[^\\]]', String.Regex)",
            "        ],",
            "",
            "        'squareText': [",
            "            (r'(?<!\\\\)]', String, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\\]]', String)",
            "        ],",
            "",
            "        'root': [",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "",
            "            # Comments",
            "            (r';(.*?)\\n', Comment),",
            "            (r'\\A#!(.*?)\\n', Comment),",
            "",
            "            # Regexps",
            "            (r'#/', String.Regex, 'slashRegexp'),",
            "            (r'#r\\[', String.Regex, 'squareRegexp'),",
            "",
            "            # Symbols",
            "            (r':[\\w!:?]+', String.Symbol),",
            "            (r'[\\w!:?]+:(?![\\w!?])', String.Other),",
            "            (r':\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Symbol),",
            "",
            "            # Documentation",
            "            (r'((?<=fn\\()|(?<=fnx\\()|(?<=method\\()|(?<=macro\\()|(?<=lecro\\()'",
            "             r'|(?<=syntax\\()|(?<=dmacro\\()|(?<=dlecro\\()|(?<=dlecrox\\()'",
            "             r'|(?<=dsyntax\\())\\s*\"', String.Doc, 'documentation'),",
            "",
            "            # Text",
            "            (r'\"', String, 'text'),",
            "            (r'#\\[', String, 'squareText'),",
            "",
            "            # Mimic",
            "            (r'\\w[\\w!:?]+(?=\\s*=.*mimic\\s)', Name.Entity),",
            "",
            "            # Assignment",
            "            (r'[a-zA-Z_][\\w!:?]*(?=[\\s]*[+*/-]?=[^=].*($|\\.))',",
            "             Name.Variable),",
            "",
            "            # keywords",
            "            (r'(break|cond|continue|do|ensure|for|for:dict|for:set|if|let|'",
            "             r'loop|p:for|p:for:dict|p:for:set|return|unless|until|while|'",
            "             r'with)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # Origin",
            "            (r'(eval|mimic|print|println)(?![\\w!:?])', Keyword),",
            "",
            "            # Base",
            "            (r'(cell\\?|cellNames|cellOwner\\?|cellOwner|cells|cell|'",
            "             r'documentation|hash|identity|mimic|removeCell\\!|undefineCell\\!)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # Ground",
            "            (r'(stackTraceAsText)(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehaviour Literals",
            "            (r'(dict|list|message|set)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Case",
            "            (r'(case|case:and|case:else|case:nand|case:nor|case:not|case:or|'",
            "             r'case:otherwise|case:xor)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Reflection",
            "            (r'(asText|become\\!|derive|freeze\\!|frozen\\?|in\\?|is\\?|kind\\?|'",
            "             r'mimic\\!|mimics|mimics\\?|prependMimic\\!|removeAllMimics\\!|'",
            "             r'removeMimic\\!|same\\?|send|thaw\\!|uniqueHexId)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehaviour Aspects",
            "            (r'(after|around|before)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour",
            "            (r'(kind|cellDescriptionDict|cellSummary|genSym|inspect|notice)'",
            "             r'(?![\\w!:?])', Keyword),",
            "            (r'(use|destructuring)', Keyword.Reserved),",
            "",
            "            # DefaultBehavior BaseBehavior",
            "            (r'(cell\\?|cellOwner\\?|cellOwner|cellNames|cells|cell|'",
            "             r'documentation|identity|removeCell!|undefineCell)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehavior Internal",
            "            (r'(internal:compositeRegexp|internal:concatenateText|'",
            "             r'internal:createDecimal|internal:createNumber|'",
            "             r'internal:createRegexp|internal:createText)'",
            "             r'(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Conditions",
            "            (r'(availableRestarts|bind|error\\!|findRestart|handle|'",
            "             r'invokeRestart|rescue|restart|signal\\!|warn\\!)'",
            "             r'(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # constants",
            "            (r'(nil|false|true)(?![\\w!:?])', Name.Constant),",
            "",
            "            # names",
            "            (r'(Arity|Base|Call|Condition|DateTime|Aspects|Pointcut|'",
            "             r'Assignment|BaseBehavior|Boolean|Case|AndCombiner|Else|'",
            "             r'NAndCombiner|NOrCombiner|NotCombiner|OrCombiner|XOrCombiner|'",
            "             r'Conditions|Definitions|FlowControl|Internal|Literals|'",
            "             r'Reflection|DefaultMacro|DefaultMethod|DefaultSyntax|Dict|'",
            "             r'FileSystem|Ground|Handler|Hook|IO|IokeGround|Struct|'",
            "             r'LexicalBlock|LexicalMacro|List|Message|Method|Mixins|'",
            "             r'NativeMethod|Number|Origin|Pair|Range|Reflector|Regexp Match|'",
            "             r'Regexp|Rescue|Restart|Runtime|Sequence|Set|Symbol|'",
            "             r'System|Text|Tuple)(?![\\w!:?])', Name.Builtin),",
            "",
            "            # functions",
            "            ('(generateMatchMethod|aliasMethod|\\u03bb|\\u028E|fnx|fn|method|'",
            "             'dmacro|dlecro|syntax|macro|dlecrox|lecrox|lecro|syntax)'",
            "             '(?![\\\\w!:?])', Name.Function),",
            "",
            "            # Numbers",
            "            (r'-?0[xX][0-9a-fA-F]+', Number.Hex),",
            "            (r'-?(\\d+\\.?\\d*|\\d*\\.\\d+)([eE][+-]?[0-9]+)?', Number.Float),",
            "            (r'-?\\d+', Number.Integer),",
            "",
            "            (r'#\\(', Punctuation),",
            "",
            "            # Operators",
            "            (r'(&&>>|\\|\\|>>|\\*\\*>>|:::|::|\\.\\.\\.|===|\\*\\*>|\\*\\*=|&&>|&&=|'",
            "             r'\\|\\|>|\\|\\|=|\\->>|\\+>>|!>>|<>>>|<>>|&>>|%>>|#>>|@>>|/>>|\\*>>|'",
            "             r'\\?>>|\\|>>|\\^>>|~>>|\\$>>|=>>|<<=|>>=|<=>|<\\->|=~|!~|=>|\\+\\+|'",
            "             r'\\-\\-|<=|>=|==|!=|&&|\\.\\.|\\+=|\\-=|\\*=|\\/=|%=|&=|\\^=|\\|=|<\\-|'",
            "             r'\\+>|!>|<>|&>|%>|#>|\\@>|\\/>|\\*>|\\?>|\\|>|\\^>|~>|\\$>|<\\->|\\->|'",
            "             r'<<|>>|\\*\\*|\\?\\||\\?&|\\|\\||>|<|\\*|\\/|%|\\+|\\-|&|\\^|\\||=|\\$|!|~|'",
            "             r'\\?|#|\\u2260|\\u2218|\\u2208|\\u2209)', Operator),",
            "            (r'(and|nand|or|xor|nor|return|import)(?![\\w!?])',",
            "             Operator),",
            "",
            "            # Punctuation",
            "            (r'(\\`\\`|\\`|\\'\\'|\\'|\\.|\\,|@@|@|\\[|\\]|\\(|\\)|\\{|\\})', Punctuation),",
            "",
            "            # kinds",
            "            (r'[A-Z][\\w!:?]*', Name.Class),",
            "",
            "            # default cellnames",
            "            (r'[a-z_][\\w!:?]*', Name)",
            "        ]",
            "    }",
            "",
            "",
            "class ClojureLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for `Clojure <http://clojure.org/>`_ source code.",
            "",
            "    .. versionadded:: 0.11",
            "    \"\"\"",
            "    name = 'Clojure'",
            "    aliases = ['clojure', 'clj']",
            "    filenames = ['*.clj']",
            "    mimetypes = ['text/x-clojure', 'application/x-clojure']",
            "",
            "    special_forms = (",
            "        '.', 'def', 'do', 'fn', 'if', 'let', 'new', 'quote', 'var', 'loop'",
            "    )",
            "",
            "    # It's safe to consider 'ns' a declaration thing because it defines a new",
            "    # namespace.",
            "    declarations = (",
            "        'def-', 'defn', 'defn-', 'defmacro', 'defmulti', 'defmethod',",
            "        'defstruct', 'defonce', 'declare', 'definline', 'definterface',",
            "        'defprotocol', 'defrecord', 'deftype', 'defproject', 'ns'",
            "    )",
            "",
            "    builtins = (",
            "        '*', '+', '-', '->', '/', '<', '<=', '=', '==', '>', '>=', '..',",
            "        'accessor', 'agent', 'agent-errors', 'aget', 'alength', 'all-ns',",
            "        'alter', 'and', 'append-child', 'apply', 'array-map', 'aset',",
            "        'aset-boolean', 'aset-byte', 'aset-char', 'aset-double', 'aset-float',",
            "        'aset-int', 'aset-long', 'aset-short', 'assert', 'assoc', 'await',",
            "        'await-for', 'bean', 'binding', 'bit-and', 'bit-not', 'bit-or',",
            "        'bit-shift-left', 'bit-shift-right', 'bit-xor', 'boolean', 'branch?',",
            "        'butlast', 'byte', 'cast', 'char', 'children', 'class',",
            "        'clear-agent-errors', 'comment', 'commute', 'comp', 'comparator',",
            "        'complement', 'concat', 'conj', 'cons', 'constantly', 'cond', 'if-not',",
            "        'construct-proxy', 'contains?', 'count', 'create-ns', 'create-struct',",
            "        'cycle', 'dec',  'deref', 'difference', 'disj', 'dissoc', 'distinct',",
            "        'doall', 'doc', 'dorun', 'doseq', 'dosync', 'dotimes', 'doto',",
            "        'double', 'down', 'drop', 'drop-while', 'edit', 'end?', 'ensure',",
            "        'eval', 'every?', 'false?', 'ffirst', 'file-seq', 'filter', 'find',",
            "        'find-doc', 'find-ns', 'find-var', 'first', 'float', 'flush', 'for',",
            "        'fnseq', 'frest', 'gensym', 'get-proxy-class', 'get',",
            "        'hash-map', 'hash-set', 'identical?', 'identity', 'if-let', 'import',",
            "        'in-ns', 'inc', 'index', 'insert-child', 'insert-left', 'insert-right',",
            "        'inspect-table', 'inspect-tree', 'instance?', 'int', 'interleave',",
            "        'intersection', 'into', 'into-array', 'iterate', 'join', 'key', 'keys',",
            "        'keyword', 'keyword?', 'last', 'lazy-cat', 'lazy-cons', 'left',",
            "        'lefts', 'line-seq', 'list*', 'list', 'load', 'load-file',",
            "        'locking', 'long', 'loop', 'macroexpand', 'macroexpand-1',",
            "        'make-array', 'make-node', 'map', 'map-invert', 'map?', 'mapcat',",
            "        'max', 'max-key', 'memfn', 'merge', 'merge-with', 'meta', 'min',",
            "        'min-key', 'name', 'namespace', 'neg?', 'new', 'newline', 'next',",
            "        'nil?', 'node', 'not', 'not-any?', 'not-every?', 'not=', 'ns-imports',",
            "        'ns-interns', 'ns-map', 'ns-name', 'ns-publics', 'ns-refers',",
            "        'ns-resolve', 'ns-unmap', 'nth', 'nthrest', 'or', 'parse', 'partial',",
            "        'path', 'peek', 'pop', 'pos?', 'pr', 'pr-str', 'print', 'print-str',",
            "        'println', 'println-str', 'prn', 'prn-str', 'project', 'proxy',",
            "        'proxy-mappings', 'quot', 'rand', 'rand-int', 'range', 're-find',",
            "        're-groups', 're-matcher', 're-matches', 're-pattern', 're-seq',",
            "        'read', 'read-line', 'reduce', 'ref', 'ref-set', 'refer', 'rem',",
            "        'remove', 'remove-method', 'remove-ns', 'rename', 'rename-keys',",
            "        'repeat', 'replace', 'replicate', 'resolve', 'rest', 'resultset-seq',",
            "        'reverse', 'rfirst', 'right', 'rights', 'root', 'rrest', 'rseq',",
            "        'second', 'select', 'select-keys', 'send', 'send-off', 'seq',",
            "        'seq-zip', 'seq?', 'set', 'short', 'slurp', 'some', 'sort',",
            "        'sort-by', 'sorted-map', 'sorted-map-by', 'sorted-set',",
            "        'special-symbol?', 'split-at', 'split-with', 'str', 'string?',",
            "        'struct', 'struct-map', 'subs', 'subvec', 'symbol', 'symbol?',",
            "        'sync', 'take', 'take-nth', 'take-while', 'test', 'time', 'to-array',",
            "        'to-array-2d', 'tree-seq', 'true?', 'union', 'up', 'update-proxy',",
            "        'val', 'vals', 'var-get', 'var-set', 'var?', 'vector', 'vector-zip',",
            "        'vector?', 'when', 'when-first', 'when-let', 'when-not',",
            "        'with-local-vars', 'with-meta', 'with-open', 'with-out-str',",
            "        'xml-seq', 'xml-zip', 'zero?', 'zipmap', 'zipper')",
            "",
            "    # valid names for identifiers",
            "    # well, names can only not consist fully of numbers",
            "    # but this should be good enough for now",
            "",
            "    # TODO / should divide keywords/symbols into namespace/rest",
            "    # but that's hard, so just pretend / is part of the name",
            "    valid_name = r'(?!#)[\\w!$%*+<=>?/.#|-]+'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # the comments - always starting with semicolon",
            "            # and going to the end of the line",
            "            (r';.*$', Comment.Single),",
            "",
            "            # whitespaces - usually not relevant",
            "            (r'[,\\s]+', Text),",
            "",
            "            # numbers",
            "            (r'-?\\d+\\.\\d+', Number.Float),",
            "            (r'-?\\d+', Number.Integer),",
            "            (r'0x-?[abcdef\\d]+', Number.Hex),",
            "",
            "            # strings, symbols and characters",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\" + valid_name, String.Symbol),",
            "            (r\"\\\\(.|[a-z]+)\", String.Char),",
            "",
            "            # keywords",
            "            (r'::?#?' + valid_name, String.Symbol),",
            "",
            "            # special operators",
            "            (r'~@|[`\\'#^~&@]', Operator),",
            "",
            "            # highlight the special forms",
            "            (words(special_forms, suffix=' '), Keyword),",
            "",
            "            # Technically, only the special forms are 'keywords'. The problem",
            "            # is that only treating them as keywords means that things like",
            "            # 'defn' and 'ns' need to be highlighted as builtins. This is ugly",
            "            # and weird for most styles. So, as a compromise we're going to",
            "            # highlight them as Keyword.Declarations.",
            "            (words(declarations, suffix=' '), Keyword.Declaration),",
            "",
            "            # highlight the builtins",
            "            (words(builtins, suffix=' '), Name.Builtin),",
            "",
            "            # the remaining functions",
            "            (r'(?<=\\()' + valid_name, Name.Function),",
            "",
            "            # find the remaining variables",
            "            (valid_name, Name.Variable),",
            "",
            "            # Clojure accepts vector notation",
            "            (r'(\\[|\\])', Punctuation),",
            "",
            "            # Clojure accepts map notation",
            "            (r'(\\{|\\})', Punctuation),",
            "",
            "            # the famous parentheses!",
            "            (r'(\\(|\\))', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class ClojureScriptLexer(ClojureLexer):",
            "    \"\"\"",
            "    Lexer for `ClojureScript <http://clojure.org/clojurescript>`_",
            "    source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'ClojureScript'",
            "    aliases = ['clojurescript', 'cljs']",
            "    filenames = ['*.cljs']",
            "    mimetypes = ['text/x-clojurescript', 'application/x-clojurescript']",
            "",
            "",
            "class TeaLangLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Tea <http://teatrove.org/>`_ source code. Only used within a",
            "    TeaTemplateLexer.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w\\.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                       # method name",
            "             r'(\\s*)(\\()',                           # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w\\.]*', Name.Decorator),",
            "            (r'(and|break|else|foreach|if|in|not|or|reverse)\\b',",
            "             Keyword),",
            "            (r'(as|call|define)\\b', Keyword.Declaration),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(template)(\\s+)', bygroups(Keyword.Declaration, Text), 'template'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'(\\.)([a-zA-Z_]\\w*)', bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_\\$]\\w*', Name),",
            "            (r'(isa|[.]{3}|[.]{2}|[=#!<>+-/%&;,.\\*\\\\\\(\\)\\[\\]\\{\\}])', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'template': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }",
            "",
            "",
            "class CeylonLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Ceylon <http://ceylon-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Ceylon'",
            "    aliases = ['ceylon']",
            "    filenames = ['*.ceylon']",
            "    mimetypes = ['text/x-ceylon']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    #: optional Comment or Whitespace",
            "    _ws = r'(?:\\s|//.*?\\n|/[*].*?[*]/)+'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                      # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "            (r'(shared|abstract|formal|default|actual|variable|deprecated|small|'",
            "             r'late|literal|doc|by|see|throws|optional|license|tagged|final|native|'",
            "             r'annotation|sealed)\\b', Name.Decorator),",
            "            (r'(break|case|catch|continue|else|finally|for|in|'",
            "             r'if|return|switch|this|throw|try|while|is|exists|dynamic|'",
            "             r'nonempty|then|outer|assert|let)\\b', Keyword),",
            "            (r'(abstracts|extends|satisfies|'",
            "             r'super|given|of|out|assign)\\b', Keyword.Declaration),",
            "            (r'(function|value|void|new)\\b',",
            "             Keyword.Type),",
            "            (r'(assembly|module|package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface|object|alias)(\\s+)',",
            "             bygroups(Keyword.Declaration, Text), 'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\\\{#[0-9a-fA-F]{4}\\}'\", String.Char),",
            "            (r'\".*``.*``.*\"', String.Interpol),",
            "            (r'(\\.)([a-z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'\\d{1,3}(_\\d{3})+\\.\\d{1,3}(_\\d{3})+[kMGTPmunpf]?', Number.Float),",
            "            (r'\\d{1,3}(_\\d{3})+\\.[0-9]+([eE][+-]?[0-9]+)?[kMGTPmunpf]?',",
            "             Number.Float),",
            "            (r'[0-9][0-9]*\\.\\d{1,3}(_\\d{3})+[kMGTPmunpf]?', Number.Float),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][+-]?[0-9]+)?[kMGTPmunpf]?',",
            "             Number.Float),",
            "            (r'#([0-9a-fA-F]{4})(_[0-9a-fA-F]{4})+', Number.Hex),",
            "            (r'#[0-9a-fA-F]+', Number.Hex),",
            "            (r'\\$([01]{4})(_[01]{4})+', Number.Bin),",
            "            (r'\\$[01]+', Number.Bin),",
            "            (r'\\d{1,3}(_\\d{3})+[kMGTP]?', Number.Integer),",
            "            (r'[0-9]+[kMGTP]?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[A-Za-z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[a-z][\\w.]*',",
            "             Name.Namespace, '#pop')",
            "        ],",
            "        'comment': [",
            "            (r'[^*/]', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "    }",
            "",
            "",
            "class KotlinLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Kotlin <http://kotlinlang.org/>`_",
            "    source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Kotlin'",
            "    aliases = ['kotlin']",
            "    filenames = ['*.kt', '*.kts']",
            "    mimetypes = ['text/x-kotlin']",
            "",
            "    flags = re.MULTILINE | re.DOTALL | re.UNICODE",
            "",
            "    kt_name = ('@?[_' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl') + ']' +",
            "               '[' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl', 'Nd', 'Pc', 'Cf',",
            "                                 'Mn', 'Mc') + ']*')",
            "",
            "    kt_space_name = ('@?[_' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl') + ']' +",
            "               '[' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl', 'Nd', 'Pc', 'Cf',",
            "                                 'Mn', 'Mc', 'Zs') + ',-]*')",
            "",
            "    kt_id = '(' + kt_name + '|`' + kt_space_name + '`)'",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'^\\s*\\[.*?\\]', Name.Attribute),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'\\s+', Text),",
            "            (r'\\\\\\n', Text),  # line continuation",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'^#!/.+?\\n', Comment.Single),  # shebang for kotlin scripts",
            "            (r'/[*].*?[*]/', Comment.Multiline),",
            "            (r'\"\"\".*?\"\"\"', String),",
            "            (r'\\n', Text),",
            "            (r'::|!!|\\?[:.]', Operator),",
            "            (r'[~!%^&*()+=|\\[\\]:;,.<>/?-]', Punctuation),",
            "            (r'[{}]', Punctuation),",
            "            (r'@\"(\"\"|[^\"])*\"', String),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\\\n])*[\"\\n]', String),",
            "            (r\"'\\\\.'|'[^\\\\]'\", String.Char),",
            "            (r\"[0-9](\\.[0-9]*)?([eE][+-][0-9]+)?[flFL]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r'(object)(\\s+)(:)(\\s+)', bygroups(Keyword, Text, Punctuation, Text), 'class'),",
            "            (r'(companion)(\\s+)(object)', bygroups(Keyword, Text, Keyword)),",
            "            (r'(class|interface|object)(\\s+)', bygroups(Keyword, Text), 'class'),",
            "            (r'(package|import)(\\s+)', bygroups(Keyword, Text), 'package'),",
            "            (r'(val|var)(\\s+)([(])', bygroups(Keyword, Text, Punctuation), 'property_dec'),",
            "            (r'(val|var)(\\s+)', bygroups(Keyword, Text), 'property'),",
            "            (r'(fun)(\\s+)', bygroups(Keyword, Text), 'function'),",
            "            (r'(inline fun)(\\s+)', bygroups(Keyword, Text), 'function'),",
            "            (r'(abstract|annotation|as|break|by|catch|class|companion|const|'",
            "             r'constructor|continue|crossinline|data|do|dynamic|else|enum|'",
            "             r'external|false|final|finally|for|fun|get|if|import|in|infix|'",
            "             r'inline|inner|interface|internal|is|lateinit|noinline|null|'",
            "             r'object|open|operator|out|override|package|private|protected|'",
            "             r'public|reified|return|sealed|set|super|tailrec|this|throw|'",
            "             r'true|try|val|var|vararg|when|where|while)\\b', Keyword),",
            "            (kt_id, Name),",
            "        ],",
            "        'package': [",
            "            (r'\\S+', Name.Namespace, '#pop')",
            "        ],",
            "        'class': [",
            "            (kt_id, Name.Class, '#pop')",
            "        ],",
            "        'property': [",
            "            (kt_id, Name.Property, '#pop')",
            "        ],",
            "        'property_dec': [",
            "            (r'(,)(\\s*)', bygroups(Punctuation, Text)),",
            "            (r'(:)(\\s*)', bygroups(Punctuation, Text)),",
            "            (r'<', Punctuation, 'generic'),",
            "            (r'([)])', Punctuation, '#pop'),",
            "            (kt_id, Name.Property)",
            "        ],",
            "        'function': [",
            "            (r'<', Punctuation, 'generic'),",
            "            (r''+kt_id+'([.])'+kt_id, bygroups(Name.Class, Punctuation, Name.Function), '#pop'),",
            "            (kt_id, Name.Function, '#pop')",
            "        ],",
            "        'generic': [",
            "            (r'(>)(\\s*)', bygroups(Punctuation, Text), '#pop'),",
            "            (r':',Punctuation),",
            "            (r'(reified|out|in)\\b', Keyword),",
            "            (r',',Text),",
            "            (r'\\s+',Text),",
            "            (kt_id,Name)",
            "        ]",
            "    }",
            "",
            "",
            "class XtendLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Xtend <http://xtend-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Xtend'",
            "    aliases = ['xtend']",
            "    filenames = ['*.xtend']",
            "    mimetypes = ['text/x-xtend']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_$][\\w$]*)'                  # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while|IF|'",
            "             r'ELSE|ELSEIF|ENDIF|FOR|ENDFOR|SEPARATOR|BEFORE|AFTER)\\b',",
            "             Keyword),",
            "            (r'(def|abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r\"(''')\", String, 'template'),",
            "            (r'(\\u00BB)', String, 'template'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>\\|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'template': [",
            "            (r\"'''\", String, '#pop'),",
            "            (r'\\u00AB', String, '#pop'),",
            "            (r'.', String)",
            "        ],",
            "    }",
            "",
            "",
            "class PigLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Pig Latin <https://pig.apache.org/>`_ source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Pig'",
            "    aliases = ['pig']",
            "    filenames = ['*.pig']",
            "    mimetypes = ['text/x-pig']",
            "",
            "    flags = re.MULTILINE | re.IGNORECASE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'--.*', Comment),",
            "            (r'/\\*[\\w\\W]*?\\*/', Comment.Multiline),",
            "            (r'\\\\\\n', Text),",
            "            (r'\\\\', Text),",
            "            (r'\\'(?:\\\\[ntbrf\\\\\\']|\\\\u[0-9a-f]{4}|[^\\'\\\\\\n\\r])*\\'', String),",
            "            include('keywords'),",
            "            include('types'),",
            "            include('builtins'),",
            "            include('punct'),",
            "            include('operators'),",
            "            (r'[0-9]*\\.[0-9]+(e[0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-f]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text),",
            "            (r'([a-z_]\\w*)(\\s*)(\\()',",
            "             bygroups(Name.Function, Text, Punctuation)),",
            "            (r'[()#:]', Text),",
            "            (r'[^(:#\\'\")\\s]+', Text),",
            "            (r'\\S+\\s+', Text)   # TODO: make tests pass without \\s+",
            "        ],",
            "        'keywords': [",
            "            (r'(assert|and|any|all|arrange|as|asc|bag|by|cache|CASE|cat|cd|cp|'",
            "             r'%declare|%default|define|dense|desc|describe|distinct|du|dump|'",
            "             r'eval|exex|explain|filter|flatten|foreach|full|generate|group|'",
            "             r'help|if|illustrate|import|inner|input|into|is|join|kill|left|'",
            "             r'limit|load|ls|map|matches|mkdir|mv|not|null|onschema|or|order|'",
            "             r'outer|output|parallel|pig|pwd|quit|register|returns|right|rm|'",
            "             r'rmf|rollup|run|sample|set|ship|split|stderr|stdin|stdout|store|'",
            "             r'stream|through|union|using|void)\\b', Keyword)",
            "        ],",
            "        'builtins': [",
            "            (r'(AVG|BinStorage|cogroup|CONCAT|copyFromLocal|copyToLocal|COUNT|'",
            "             r'cross|DIFF|MAX|MIN|PigDump|PigStorage|SIZE|SUM|TextLoader|'",
            "             r'TOKENIZE)\\b', Name.Builtin)",
            "        ],",
            "        'types': [",
            "            (r'(bytearray|BIGINTEGER|BIGDECIMAL|chararray|datetime|double|float|'",
            "             r'int|long|tuple)\\b', Keyword.Type)",
            "        ],",
            "        'punct': [",
            "            (r'[;(){}\\[\\]]', Punctuation),",
            "        ],",
            "        'operators': [",
            "            (r'[#=,./%+\\-?]', Operator),",
            "            (r'(eq|gt|lt|gte|lte|neq|matches)\\b', Operator),",
            "            (r'(==|<=|<|>=|>|!=)', Operator),",
            "        ],",
            "    }",
            "",
            "",
            "class GoloLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Golo <http://golo-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Golo'",
            "    filenames = ['*.golo']",
            "    aliases = ['golo']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^\\S\\n]+', Text),",
            "",
            "            (r'#.*$', Comment),",
            "",
            "            (r'(\\^|\\.\\.\\.|:|\\?:|->|==|!=|=|\\+|\\*|%|/|<=|<|>=|>|=|\\.)',",
            "                Operator),",
            "            (r'(?<=[^-])(-)(?=[^-])', Operator),",
            "",
            "            (r'(?<=[^`])(is|isnt|and|or|not|oftype|in|orIfNull)\\b', Operator.Word),",
            "            (r'[]{}|(),[]', Punctuation),",
            "",
            "            (r'(module|import)(\\s+)',",
            "                bygroups(Keyword.Namespace, Text),",
            "                'modname'),",
            "            (r'\\b([a-zA-Z_][\\w$.]*)(::)',  bygroups(Name.Namespace, Punctuation)),",
            "            (r'\\b([a-zA-Z_][\\w$]*(?:\\.[a-zA-Z_][\\w$]*)+)\\b', Name.Namespace),",
            "",
            "            (r'(let|var)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'varname'),",
            "            (r'(struct)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'structname'),",
            "            (r'(function)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'funcname'),",
            "",
            "            (r'(null|true|false)\\b', Keyword.Constant),",
            "            (r'(augment|pimp'",
            "             r'|if|else|case|match|return'",
            "             r'|case|when|then|otherwise'",
            "             r'|while|for|foreach'",
            "             r'|try|catch|finally|throw'",
            "             r'|local'",
            "             r'|continue|break)\\b', Keyword),",
            "",
            "            (r'(map|array|list|set|vector|tuple)(\\[)',",
            "                bygroups(Name.Builtin, Punctuation)),",
            "            (r'(print|println|readln|raise|fun'",
            "             r'|asInterfaceInstance)\\b', Name.Builtin),",
            "            (r'(`?[a-zA-Z_][\\w$]*)(\\()',",
            "                bygroups(Name.Function, Punctuation)),",
            "",
            "            (r'-?[\\d_]*\\.[\\d_]*([eE][+-]?\\d[\\d_]*)?F?', Number.Float),",
            "            (r'0[0-7]+j?', Number.Oct),",
            "            (r'0[xX][a-fA-F0-9]+', Number.Hex),",
            "            (r'-?\\d[\\d_]*L', Number.Integer.Long),",
            "            (r'-?\\d[\\d_]*', Number.Integer),",
            "",
            "            (r'`?[a-zA-Z_][\\w$]*', Name),",
            "            (r'@[a-zA-Z_][\\w$.]*', Name.Decorator),",
            "",
            "            (r'\"\"\"', String, combined('stringescape', 'triplestring')),",
            "            (r'\"', String, combined('stringescape', 'doublestring')),",
            "            (r\"'\", String, combined('stringescape', 'singlestring')),",
            "            (r'----((.|\\n)*?)----', String.Doc)",
            "",
            "        ],",
            "",
            "        'funcname': [",
            "            (r'`?[a-zA-Z_][\\w$]*', Name.Function, '#pop'),",
            "        ],",
            "        'modname': [",
            "            (r'[a-zA-Z_][\\w$.]*\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'structname': [",
            "            (r'`?[\\w.]+\\*?', Name.Class, '#pop')",
            "        ],",
            "        'varname': [",
            "            (r'`?[a-zA-Z_][\\w$]*', Name.Variable, '#pop'),",
            "        ],",
            "        'string': [",
            "            (r'[^\\\\\\'\"\\n]+', String),",
            "            (r'[\\'\"\\\\]', String)",
            "        ],",
            "        'stringescape': [",
            "            (r'\\\\([\\\\abfnrtv\"\\']|\\n|N\\{.*?\\}|u[a-fA-F0-9]{4}|'",
            "             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)",
            "        ],",
            "        'triplestring': [",
            "            (r'\"\"\"', String, '#pop'),",
            "            include('string'),",
            "            (r'\\n', String),",
            "        ],",
            "        'doublestring': [",
            "            (r'\"', String.Double, '#pop'),",
            "            include('string'),",
            "        ],",
            "        'singlestring': [",
            "            (r\"'\", String, '#pop'),",
            "            include('string'),",
            "        ],",
            "        'operators': [",
            "            (r'[#=,./%+\\-?]', Operator),",
            "            (r'(eq|gt|lt|gte|lte|neq|matches)\\b', Operator),",
            "            (r'(==|<=|<|>=|>|!=)', Operator),",
            "        ],",
            "    }",
            "",
            "",
            "class JasminLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Jasmin <http://jasmin.sourceforge.net/>`_ assembly code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Jasmin'",
            "    aliases = ['jasmin', 'jasminxt']",
            "    filenames = ['*.j']",
            "",
            "    _whitespace = r' \\n\\t\\r'",
            "    _ws = r'(?:[%s]+)' % _whitespace",
            "    _separator = r'%s:=' % _whitespace",
            "    _break = r'(?=[%s]|$)' % _separator",
            "    _name = r'[^%s]+' % _separator",
            "    _unqualified_name = r'(?:[^%s.;\\[/]+)' % _separator",
            "",
            "    tokens = {",
            "        'default': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r\"'\", String.Single, ('#pop', 'quote')),",
            "            (r'\"', String.Double, 'string'),",
            "            (r'=', Punctuation),",
            "            (r':', Punctuation, 'label'),",
            "            (_ws, Text),",
            "            (r';.*', Comment.Single),",
            "            (r'(\\$[-+])?0x-?[\\da-fA-F]+%s' % _break, Number.Hex),",
            "            (r'(\\$[-+]|\\+)?-?\\d+%s' % _break, Number.Integer),",
            "            (r'-?(\\d+\\.\\d*|\\.\\d+)([eE][-+]?\\d+)?[fFdD]?'",
            "             r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]*%s' % _break, Number.Float),",
            "            (r'\\$%s' % _name, Name.Variable),",
            "",
            "            # Directives",
            "            (r'\\.annotation%s' % _break, Keyword.Reserved, 'annotation'),",
            "            (r'(\\.attribute|\\.bytecode|\\.debug|\\.deprecated|\\.enclosing|'",
            "             r'\\.interface|\\.line|\\.signature|\\.source|\\.stack|\\.var|abstract|'",
            "             r'annotation|bridge|class|default|enum|field|final|fpstrict|'",
            "             r'interface|native|private|protected|public|signature|static|'",
            "             r'synchronized|synthetic|transient|varargs|volatile)%s' % _break,",
            "             Keyword.Reserved),",
            "            (r'\\.catch%s' % _break, Keyword.Reserved, 'caught-exception'),",
            "            (r'(\\.class|\\.implements|\\.inner|\\.super|inner|invisible|'",
            "             r'invisibleparam|outer|visible|visibleparam)%s' % _break,",
            "             Keyword.Reserved, 'class/convert-dots'),",
            "            (r'\\.field%s' % _break, Keyword.Reserved,",
            "             ('descriptor/convert-dots', 'field')),",
            "            (r'(\\.end|\\.limit|use)%s' % _break, Keyword.Reserved,",
            "             'no-verification'),",
            "            (r'\\.method%s' % _break, Keyword.Reserved, 'method'),",
            "            (r'\\.set%s' % _break, Keyword.Reserved, 'var'),",
            "            (r'\\.throws%s' % _break, Keyword.Reserved, 'exception'),",
            "            (r'(from|offset|to|using)%s' % _break, Keyword.Reserved, 'label'),",
            "            (r'is%s' % _break, Keyword.Reserved,",
            "             ('descriptor/convert-dots', 'var')),",
            "            (r'(locals|stack)%s' % _break, Keyword.Reserved, 'verification'),",
            "            (r'method%s' % _break, Keyword.Reserved, 'enclosing-method'),",
            "",
            "            # Instructions",
            "            (words((",
            "                'aaload', 'aastore', 'aconst_null', 'aload', 'aload_0', 'aload_1', 'aload_2',",
            "                'aload_3', 'aload_w', 'areturn', 'arraylength', 'astore', 'astore_0', 'astore_1',",
            "                'astore_2', 'astore_3', 'astore_w', 'athrow', 'baload', 'bastore', 'bipush',",
            "                'breakpoint', 'caload', 'castore', 'd2f', 'd2i', 'd2l', 'dadd', 'daload', 'dastore',",
            "                'dcmpg', 'dcmpl', 'dconst_0', 'dconst_1', 'ddiv', 'dload', 'dload_0', 'dload_1',",
            "                'dload_2', 'dload_3', 'dload_w', 'dmul', 'dneg', 'drem', 'dreturn', 'dstore', 'dstore_0',",
            "                'dstore_1', 'dstore_2', 'dstore_3', 'dstore_w', 'dsub', 'dup', 'dup2', 'dup2_x1',",
            "                'dup2_x2', 'dup_x1', 'dup_x2', 'f2d', 'f2i', 'f2l', 'fadd', 'faload', 'fastore', 'fcmpg',",
            "                'fcmpl', 'fconst_0', 'fconst_1', 'fconst_2', 'fdiv', 'fload', 'fload_0', 'fload_1',",
            "                'fload_2', 'fload_3', 'fload_w', 'fmul', 'fneg', 'frem', 'freturn', 'fstore', 'fstore_0',",
            "                'fstore_1', 'fstore_2', 'fstore_3', 'fstore_w', 'fsub', 'i2b', 'i2c', 'i2d', 'i2f', 'i2l',",
            "                'i2s', 'iadd', 'iaload', 'iand', 'iastore', 'iconst_0', 'iconst_1', 'iconst_2',",
            "                'iconst_3', 'iconst_4', 'iconst_5', 'iconst_m1', 'idiv', 'iinc', 'iinc_w', 'iload',",
            "                'iload_0', 'iload_1', 'iload_2', 'iload_3', 'iload_w', 'imul', 'ineg', 'int2byte',",
            "                'int2char', 'int2short', 'ior', 'irem', 'ireturn', 'ishl', 'ishr', 'istore', 'istore_0',",
            "                'istore_1', 'istore_2', 'istore_3', 'istore_w', 'isub', 'iushr', 'ixor', 'l2d', 'l2f',",
            "                'l2i', 'ladd', 'laload', 'land', 'lastore', 'lcmp', 'lconst_0', 'lconst_1', 'ldc2_w',",
            "                'ldiv', 'lload', 'lload_0', 'lload_1', 'lload_2', 'lload_3', 'lload_w', 'lmul', 'lneg',",
            "                'lookupswitch', 'lor', 'lrem', 'lreturn', 'lshl', 'lshr', 'lstore', 'lstore_0',",
            "                'lstore_1', 'lstore_2', 'lstore_3', 'lstore_w', 'lsub', 'lushr', 'lxor',",
            "                'monitorenter', 'monitorexit', 'nop', 'pop', 'pop2', 'ret', 'ret_w', 'return', 'saload',",
            "                'sastore', 'sipush', 'swap'), suffix=_break), Keyword.Reserved),",
            "            (r'(anewarray|checkcast|instanceof|ldc|ldc_w|new)%s' % _break,",
            "             Keyword.Reserved, 'class/no-dots'),",
            "            (r'invoke(dynamic|interface|nonvirtual|special|'",
            "             r'static|virtual)%s' % _break, Keyword.Reserved,",
            "             'invocation'),",
            "            (r'(getfield|putfield)%s' % _break, Keyword.Reserved,",
            "             ('descriptor/no-dots', 'field')),",
            "            (r'(getstatic|putstatic)%s' % _break, Keyword.Reserved,",
            "             ('descriptor/no-dots', 'static')),",
            "            (words((",
            "                'goto', 'goto_w', 'if_acmpeq', 'if_acmpne', 'if_icmpeq',",
            "                'if_icmpge', 'if_icmpgt', 'if_icmple', 'if_icmplt', 'if_icmpne',",
            "                'ifeq', 'ifge', 'ifgt', 'ifle', 'iflt', 'ifne', 'ifnonnull',",
            "                'ifnull', 'jsr', 'jsr_w'), suffix=_break),",
            "             Keyword.Reserved, 'label'),",
            "            (r'(multianewarray|newarray)%s' % _break, Keyword.Reserved,",
            "             'descriptor/convert-dots'),",
            "            (r'tableswitch%s' % _break, Keyword.Reserved, 'table')",
            "        ],",
            "        'quote': [",
            "            (r\"'\", String.Single, '#pop'),",
            "            (r'\\\\u[\\da-fA-F]{4}', String.Escape),",
            "            (r\"[^'\\\\]+\", String.Single)",
            "        ],",
            "        'string': [",
            "            (r'\"', String.Double, '#pop'),",
            "            (r'\\\\([nrtfb\"\\'\\\\]|u[\\da-fA-F]{4}|[0-3]?[0-7]{1,2})',",
            "             String.Escape),",
            "            (r'[^\"\\\\]+', String.Double)",
            "        ],",
            "        'root': [",
            "            (r'\\n+', Text),",
            "            (r\"'\", String.Single, 'quote'),",
            "            include('default'),",
            "            (r'(%s)([ \\t\\r]*)(:)' % _name,",
            "             bygroups(Name.Label, Text, Punctuation)),",
            "            (_name, String.Other)",
            "        ],",
            "        'annotation': [",
            "            (r'\\n', Text, ('#pop', 'annotation-body')),",
            "            (r'default%s' % _break, Keyword.Reserved,",
            "             ('#pop', 'annotation-default')),",
            "            include('default')",
            "        ],",
            "        'annotation-body': [",
            "            (r'\\n+', Text),",
            "            (r'\\.end%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            (_name, String.Other, ('annotation-items', 'descriptor/no-dots'))",
            "        ],",
            "        'annotation-default': [",
            "            (r'\\n+', Text),",
            "            (r'\\.end%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            default(('annotation-items', 'descriptor/no-dots'))",
            "        ],",
            "        'annotation-items': [",
            "            (r\"'\", String.Single, 'quote'),",
            "            include('default'),",
            "            (_name, String.Other)",
            "        ],",
            "        'caught-exception': [",
            "            (r'all%s' % _break, Keyword, '#pop'),",
            "            include('exception')",
            "        ],",
            "        'class/convert-dots': [",
            "            include('default'),",
            "            (r'(L)((?:%s[/.])*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'((?:%s[/.])*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class), '#pop')",
            "        ],",
            "        'class/no-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation, ('#pop', 'descriptor/no-dots')),",
            "            (r'(L)((?:%s/)*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'((?:%s/)*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class), '#pop')",
            "        ],",
            "        'descriptor/convert-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation),",
            "            (r'(L)((?:%s[/.])*)(%s?)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'[^%s\\[)L]+' % _separator, Keyword.Type, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'descriptor/no-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation),",
            "            (r'(L)((?:%s/)*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'[^%s\\[)L]+' % _separator, Keyword.Type, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'descriptors/convert-dots': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            default('descriptor/convert-dots')",
            "        ],",
            "        'enclosing-method': [",
            "            (_ws, Text),",
            "            (r'(?=[^%s]*\\()' % _separator, Text, ('#pop', 'invocation')),",
            "            default(('#pop', 'class/convert-dots'))",
            "        ],",
            "        'exception': [",
            "            include('default'),",
            "            (r'((?:%s[/.])*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Exception), '#pop')",
            "        ],",
            "        'field': [",
            "            (r'static%s' % _break, Keyword.Reserved, ('#pop', 'static')),",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s]*[/.]))*)(%s[/.])?(%s)' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Variable.Instance),",
            "             '#pop')",
            "        ],",
            "        'invocation': [",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s(]*[/.]))*)(%s[/.])?(%s)(\\()' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Function, Punctuation),",
            "             ('#pop', 'descriptor/convert-dots', 'descriptors/convert-dots',",
            "              'descriptor/convert-dots'))",
            "        ],",
            "        'label': [",
            "            include('default'),",
            "            (_name, Name.Label, '#pop')",
            "        ],",
            "        'method': [",
            "            include('default'),",
            "            (r'(%s)(\\()' % _name, bygroups(Name.Function, Punctuation),",
            "             ('#pop', 'descriptor/convert-dots', 'descriptors/convert-dots',",
            "              'descriptor/convert-dots'))",
            "        ],",
            "        'no-verification': [",
            "            (r'(locals|method|stack)%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default')",
            "        ],",
            "        'static': [",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s]*[/.]))*)(%s[/.])?(%s)' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Variable.Class), '#pop')",
            "        ],",
            "        'table': [",
            "            (r'\\n+', Text),",
            "            (r'default%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            (_name, Name.Label)",
            "        ],",
            "        'var': [",
            "            include('default'),",
            "            (_name, Name.Variable, '#pop')",
            "        ],",
            "        'verification': [",
            "            include('default'),",
            "            (r'(Double|Float|Integer|Long|Null|Top|UninitializedThis)%s' %",
            "             _break, Keyword, '#pop'),",
            "            (r'Object%s' % _break, Keyword, ('#pop', 'class/no-dots')),",
            "            (r'Uninitialized%s' % _break, Keyword, ('#pop', 'label'))",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        score = 0",
            "        if re.search(r'^\\s*\\.class\\s', text, re.MULTILINE):",
            "            score += 0.5",
            "            if re.search(r'^\\s*[a-z]+_[a-z]+\\b', text, re.MULTILINE):",
            "                score += 0.3",
            "        if re.search(r'^\\s*\\.(attribute|bytecode|debug|deprecated|enclosing|'",
            "                     r'inner|interface|limit|set|signature|stack)\\b', text,",
            "                     re.MULTILINE):",
            "            score += 0.6",
            "        return score",
            "",
            "",
            "class SarlLexer(RegexLexer):",
            "    \"\"\"",
            "    For `SARL <http://www.sarl.io>`_ source code.",
            "",
            "    .. versionadded:: 2.4",
            "    \"\"\"",
            "",
            "    name = 'SARL'",
            "    aliases = ['sarl']",
            "    filenames = ['*.sarl']",
            "    mimetypes = ['text/x-sarl']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_$][\\w$]*)'                      # method name",
            "             r'(\\s*)(\\()',                             # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(as|break|case|catch|default|do|else|extends|extension|finally|'",
            "             r'fires|for|if|implements|instanceof|new|on|requires|return|super|'",
            "             r'switch|throw|throws|try|typeof|uses|while|with)\\b',",
            "             Keyword),",
            "            (r'(abstract|def|dispatch|final|native|override|private|protected|'",
            "             r'public|static|strictfp|synchronized|transient|val|var|volatile)\\b',",
            "             Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(false|it|null|occurrence|this|true|void)\\b', Keyword.Constant),",
            "            (r'(agent|annotation|artifact|behavior|capacity|class|enum|event|'",
            "             r'interface|skill|space)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>\\|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.jvm",
            "    ~~~~~~~~~~~~~~~~~~~",
            "",
            "    Pygments lexers for JVM languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import Lexer, RegexLexer, include, bygroups, using, \\",
            "    this, combined, default, words",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation",
            "from pygments.util import shebang_matches",
            "from pygments import unistring as uni",
            "",
            "__all__ = ['JavaLexer', 'ScalaLexer', 'GosuLexer', 'GosuTemplateLexer',",
            "           'GroovyLexer', 'IokeLexer', 'ClojureLexer', 'ClojureScriptLexer',",
            "           'KotlinLexer', 'XtendLexer', 'AspectJLexer', 'CeylonLexer',",
            "           'PigLexer', 'GoloLexer', 'JasminLexer', 'SarlLexer']",
            "",
            "",
            "class JavaLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Java <https://www.oracle.com/technetwork/java/>`_ source code.",
            "    \"\"\"",
            "",
            "    name = 'Java'",
            "    aliases = ['java']",
            "    filenames = ['*.java']",
            "    mimetypes = ['text/x-java']",
            "",
            "    flags = re.MULTILINE | re.DOTALL | re.UNICODE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            # keywords: go before method names to avoid lexing \"throw new XYZ\"",
            "            # as a method signature",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while)\\b',",
            "             Keyword),",
            "            # method names",
            "            (r'((?:(?:[^\\W\\d]|\\$)[\\w.\\[\\]$<>]*\\s+)+?)'  # return arguments",
            "             r'((?:[^\\W\\d]|\\$)[\\w$]*)'                  # method name",
            "             r'(\\s*)(\\()',                              # signature start",
            "             bygroups(using(this), Name.Function, Text, Punctuation)),",
            "            (r'@[^\\W\\d][\\w.]*', Name.Decorator),",
            "            (r'(abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(var)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'var'),",
            "            (r'(import(?:\\s+static)?)(\\s+)', bygroups(Keyword.Namespace, Text),",
            "             'import'),",
            "            (r'\"', String, 'string'),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r'(\\.)((?:[^\\W\\d]|\\$)[\\w$]*)', bygroups(Punctuation,",
            "                                                     Name.Attribute)),",
            "            (r'^\\s*([^\\W\\d]|\\$)[\\w$]*:', Name.Label),",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name),",
            "            (r'([0-9][0-9_]*\\.([0-9][0-9_]*)?|'",
            "             r'\\.[0-9][0-9_]*)'",
            "             r'([eE][+\\-]?[0-9][0-9_]*)?[fFdD]?|'",
            "             r'[0-9][eE][+\\-]?[0-9][0-9_]*[fFdD]?|'",
            "             r'[0-9]([eE][+\\-]?[0-9][0-9_]*)?[fFdD]|'",
            "             r'0[xX]([0-9a-fA-F][0-9a-fA-F_]*\\.?|'",
            "             r'([0-9a-fA-F][0-9a-fA-F_]*)?\\.[0-9a-fA-F][0-9a-fA-F_]*)'",
            "             r'[pP][+\\-]?[0-9][0-9_]*[fFdD]?', Number.Float),",
            "            (r'0[xX][0-9a-fA-F][0-9a-fA-F_]*[lL]?', Number.Hex),",
            "            (r'0[bB][01][01_]*[lL]?', Number.Bin),",
            "            (r'0[0-7_]+[lL]?', Number.Oct),",
            "            (r'0|[1-9][0-9_]*[lL]?', Number.Integer),",
            "            (r'[~^*!%&\\[\\]<>|+=/?-]', Operator),",
            "            (r'[{}();:.,]', Punctuation),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name.Class, '#pop')",
            "        ],",
            "        'var': [",
            "            (r'([^\\W\\d]|\\$)[\\w$]*', Name, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'string': [",
            "            (r'[^\\\\\"]+', String),",
            "            (r'\\\\\\\\', String),  # Escaped backslash",
            "            (r'\\\\\"', String),  # Escaped quote",
            "            (r'\\\\', String),  # Bare backslash",
            "            (r'\"', String, '#pop'),  # Closing quote",
            "        ],",
            "    }",
            "",
            "",
            "class AspectJLexer(JavaLexer):",
            "    \"\"\"",
            "    For `AspectJ <http://www.eclipse.org/aspectj/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'AspectJ'",
            "    aliases = ['aspectj']",
            "    filenames = ['*.aj']",
            "    mimetypes = ['text/x-aspectj']",
            "",
            "    aj_keywords = {",
            "        'aspect', 'pointcut', 'privileged', 'call', 'execution',",
            "        'initialization', 'preinitialization', 'handler', 'get', 'set',",
            "        'staticinitialization', 'target', 'args', 'within', 'withincode',",
            "        'cflow', 'cflowbelow', 'annotation', 'before', 'after', 'around',",
            "        'proceed', 'throwing', 'returning', 'adviceexecution', 'declare',",
            "        'parents', 'warning', 'error', 'soft', 'precedence', 'thisJoinPoint',",
            "        'thisJoinPointStaticPart', 'thisEnclosingJoinPointStaticPart',",
            "        'issingleton', 'perthis', 'pertarget', 'percflow', 'percflowbelow',",
            "        'pertypewithin', 'lock', 'unlock', 'thisAspectInstance'",
            "    }",
            "    aj_inter_type = {'parents:', 'warning:', 'error:', 'soft:', 'precedence:'}",
            "    aj_inter_type_annotation = {'@type', '@method', '@constructor', '@field'}",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        for index, token, value in JavaLexer.get_tokens_unprocessed(self, text):",
            "            if token is Name and value in self.aj_keywords:",
            "                yield index, Keyword, value",
            "            elif token is Name.Label and value in self.aj_inter_type:",
            "                yield index, Keyword, value[:-1]",
            "                yield index, Operator, value[-1]",
            "            elif token is Name.Decorator and value in self.aj_inter_type_annotation:",
            "                yield index, Keyword, value",
            "            else:",
            "                yield index, token, value",
            "",
            "",
            "class ScalaLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Scala <http://www.scala-lang.org>`_ source code.",
            "    \"\"\"",
            "",
            "    name = 'Scala'",
            "    aliases = ['scala']",
            "    filenames = ['*.scala']",
            "    mimetypes = ['text/x-scala']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    # don't use raw unicode strings!",
            "    op = ('[-~\\\\^\\\\*!%&\\\\\\\\<>\\\\|+=:/?@\\u00a6-\\u00a7\\u00a9\\u00ac\\u00ae\\u00b0-\\u00b1'",
            "          '\\u00b6\\u00d7\\u00f7\\u03f6\\u0482\\u0606-\\u0608\\u060e-\\u060f\\u06e9'",
            "          '\\u06fd-\\u06fe\\u07f6\\u09fa\\u0b70\\u0bf3-\\u0bf8\\u0bfa\\u0c7f\\u0cf1-\\u0cf2'",
            "          '\\u0d79\\u0f01-\\u0f03\\u0f13-\\u0f17\\u0f1a-\\u0f1f\\u0f34\\u0f36\\u0f38'",
            "          '\\u0fbe-\\u0fc5\\u0fc7-\\u0fcf\\u109e-\\u109f\\u1360\\u1390-\\u1399\\u1940'",
            "          '\\u19e0-\\u19ff\\u1b61-\\u1b6a\\u1b74-\\u1b7c\\u2044\\u2052\\u207a-\\u207c'",
            "          '\\u208a-\\u208c\\u2100-\\u2101\\u2103-\\u2106\\u2108-\\u2109\\u2114\\u2116-\\u2118'",
            "          '\\u211e-\\u2123\\u2125\\u2127\\u2129\\u212e\\u213a-\\u213b\\u2140-\\u2144'",
            "          '\\u214a-\\u214d\\u214f\\u2190-\\u2328\\u232b-\\u244a\\u249c-\\u24e9\\u2500-\\u2767'",
            "          '\\u2794-\\u27c4\\u27c7-\\u27e5\\u27f0-\\u2982\\u2999-\\u29d7\\u29dc-\\u29fb'",
            "          '\\u29fe-\\u2b54\\u2ce5-\\u2cea\\u2e80-\\u2ffb\\u3004\\u3012-\\u3013\\u3020'",
            "          '\\u3036-\\u3037\\u303e-\\u303f\\u3190-\\u3191\\u3196-\\u319f\\u31c0-\\u31e3'",
            "          '\\u3200-\\u321e\\u322a-\\u3250\\u3260-\\u327f\\u328a-\\u32b0\\u32c0-\\u33ff'",
            "          '\\u4dc0-\\u4dff\\ua490-\\ua4c6\\ua828-\\ua82b\\ufb29\\ufdfd\\ufe62\\ufe64-\\ufe66'",
            "          '\\uff0b\\uff1c-\\uff1e\\uff5c\\uff5e\\uffe2\\uffe4\\uffe8-\\uffee\\ufffc-\\ufffd]+')",
            "",
            "    letter = ('[a-zA-Z\\\\$_\\u00aa\\u00b5\\u00ba\\u00c0-\\u00d6\\u00d8-\\u00f6'",
            "              '\\u00f8-\\u02af\\u0370-\\u0373\\u0376-\\u0377\\u037b-\\u037d\\u0386'",
            "              '\\u0388-\\u03f5\\u03f7-\\u0481\\u048a-\\u0556\\u0561-\\u0587\\u05d0-\\u05f2'",
            "              '\\u0621-\\u063f\\u0641-\\u064a\\u066e-\\u066f\\u0671-\\u06d3\\u06d5'",
            "              '\\u06ee-\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5'",
            "              '\\u07b1\\u07ca-\\u07ea\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961'",
            "              '\\u0972-\\u097f\\u0985-\\u09b9\\u09bd\\u09ce\\u09dc-\\u09e1\\u09f0-\\u09f1'",
            "              '\\u0a05-\\u0a39\\u0a59-\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0ab9\\u0abd'",
            "              '\\u0ad0-\\u0ae1\\u0b05-\\u0b39\\u0b3d\\u0b5c-\\u0b61\\u0b71\\u0b83-\\u0bb9'",
            "              '\\u0bd0\\u0c05-\\u0c3d\\u0c58-\\u0c61\\u0c85-\\u0cb9\\u0cbd\\u0cde-\\u0ce1'",
            "              '\\u0d05-\\u0d3d\\u0d60-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0dc6\\u0e01-\\u0e30'",
            "              '\\u0e32-\\u0e33\\u0e40-\\u0e45\\u0e81-\\u0eb0\\u0eb2-\\u0eb3\\u0ebd-\\u0ec4'",
            "              '\\u0edc-\\u0f00\\u0f40-\\u0f6c\\u0f88-\\u0f8b\\u1000-\\u102a\\u103f'",
            "              '\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065-\\u1066\\u106e-\\u1070'",
            "              '\\u1075-\\u1081\\u108e\\u10a0-\\u10fa\\u1100-\\u135a\\u1380-\\u138f'",
            "              '\\u13a0-\\u166c\\u166f-\\u1676\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u1711'",
            "              '\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u1770\\u1780-\\u17b3\\u17dc'",
            "              '\\u1820-\\u1842\\u1844-\\u18a8\\u18aa-\\u191c\\u1950-\\u19a9\\u19c1-\\u19c7'",
            "              '\\u1a00-\\u1a16\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae-\\u1baf'",
            "              '\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c77\\u1d00-\\u1d2b\\u1d62-\\u1d77'",
            "              '\\u1d79-\\u1d9a\\u1e00-\\u1fbc\\u1fbe\\u1fc2-\\u1fcc\\u1fd0-\\u1fdb'",
            "              '\\u1fe0-\\u1fec\\u1ff2-\\u1ffc\\u2071\\u207f\\u2102\\u2107\\u210a-\\u2113'",
            "              '\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u212f-\\u2139'",
            "              '\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c7c'",
            "              '\\u2c80-\\u2ce4\\u2d00-\\u2d65\\u2d80-\\u2dde\\u3006-\\u3007\\u3021-\\u3029'",
            "              '\\u3038-\\u303a\\u303c\\u3041-\\u3096\\u309f\\u30a1-\\u30fa\\u30ff-\\u318e'",
            "              '\\u31a0-\\u31b7\\u31f0-\\u31ff\\u3400-\\u4db5\\u4e00-\\ua014\\ua016-\\ua48c'",
            "              '\\ua500-\\ua60b\\ua610-\\ua61f\\ua62a-\\ua66e\\ua680-\\ua697\\ua722-\\ua76f'",
            "              '\\ua771-\\ua787\\ua78b-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822'",
            "              '\\ua840-\\ua873\\ua882-\\ua8b3\\ua90a-\\ua925\\ua930-\\ua946\\uaa00-\\uaa28'",
            "              '\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uac00-\\ud7a3\\uf900-\\ufb1d\\ufb1f-\\ufb28'",
            "              '\\ufb2a-\\ufd3d\\ufd50-\\ufdfb\\ufe70-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a'",
            "              '\\uff66-\\uff6f\\uff71-\\uff9d\\uffa0-\\uffdc]')",
            "",
            "    upper = ('[A-Z\\\\$_\\u00c0-\\u00d6\\u00d8-\\u00de\\u0100\\u0102\\u0104\\u0106\\u0108'",
            "             '\\u010a\\u010c\\u010e\\u0110\\u0112\\u0114\\u0116\\u0118\\u011a\\u011c'",
            "             '\\u011e\\u0120\\u0122\\u0124\\u0126\\u0128\\u012a\\u012c\\u012e\\u0130'",
            "             '\\u0132\\u0134\\u0136\\u0139\\u013b\\u013d\\u013f\\u0141\\u0143\\u0145'",
            "             '\\u0147\\u014a\\u014c\\u014e\\u0150\\u0152\\u0154\\u0156\\u0158\\u015a'",
            "             '\\u015c\\u015e\\u0160\\u0162\\u0164\\u0166\\u0168\\u016a\\u016c\\u016e'",
            "             '\\u0170\\u0172\\u0174\\u0176\\u0178-\\u0179\\u017b\\u017d\\u0181-\\u0182'",
            "             '\\u0184\\u0186-\\u0187\\u0189-\\u018b\\u018e-\\u0191\\u0193-\\u0194'",
            "             '\\u0196-\\u0198\\u019c-\\u019d\\u019f-\\u01a0\\u01a2\\u01a4\\u01a6-\\u01a7'",
            "             '\\u01a9\\u01ac\\u01ae-\\u01af\\u01b1-\\u01b3\\u01b5\\u01b7-\\u01b8\\u01bc'",
            "             '\\u01c4\\u01c7\\u01ca\\u01cd\\u01cf\\u01d1\\u01d3\\u01d5\\u01d7\\u01d9'",
            "             '\\u01db\\u01de\\u01e0\\u01e2\\u01e4\\u01e6\\u01e8\\u01ea\\u01ec\\u01ee'",
            "             '\\u01f1\\u01f4\\u01f6-\\u01f8\\u01fa\\u01fc\\u01fe\\u0200\\u0202\\u0204'",
            "             '\\u0206\\u0208\\u020a\\u020c\\u020e\\u0210\\u0212\\u0214\\u0216\\u0218'",
            "             '\\u021a\\u021c\\u021e\\u0220\\u0222\\u0224\\u0226\\u0228\\u022a\\u022c'",
            "             '\\u022e\\u0230\\u0232\\u023a-\\u023b\\u023d-\\u023e\\u0241\\u0243-\\u0246'",
            "             '\\u0248\\u024a\\u024c\\u024e\\u0370\\u0372\\u0376\\u0386\\u0388-\\u038f'",
            "             '\\u0391-\\u03ab\\u03cf\\u03d2-\\u03d4\\u03d8\\u03da\\u03dc\\u03de\\u03e0'",
            "             '\\u03e2\\u03e4\\u03e6\\u03e8\\u03ea\\u03ec\\u03ee\\u03f4\\u03f7'",
            "             '\\u03f9-\\u03fa\\u03fd-\\u042f\\u0460\\u0462\\u0464\\u0466\\u0468\\u046a'",
            "             '\\u046c\\u046e\\u0470\\u0472\\u0474\\u0476\\u0478\\u047a\\u047c\\u047e'",
            "             '\\u0480\\u048a\\u048c\\u048e\\u0490\\u0492\\u0494\\u0496\\u0498\\u049a'",
            "             '\\u049c\\u049e\\u04a0\\u04a2\\u04a4\\u04a6\\u04a8\\u04aa\\u04ac\\u04ae'",
            "             '\\u04b0\\u04b2\\u04b4\\u04b6\\u04b8\\u04ba\\u04bc\\u04be\\u04c0-\\u04c1'",
            "             '\\u04c3\\u04c5\\u04c7\\u04c9\\u04cb\\u04cd\\u04d0\\u04d2\\u04d4\\u04d6'",
            "             '\\u04d8\\u04da\\u04dc\\u04de\\u04e0\\u04e2\\u04e4\\u04e6\\u04e8\\u04ea'",
            "             '\\u04ec\\u04ee\\u04f0\\u04f2\\u04f4\\u04f6\\u04f8\\u04fa\\u04fc\\u04fe'",
            "             '\\u0500\\u0502\\u0504\\u0506\\u0508\\u050a\\u050c\\u050e\\u0510\\u0512'",
            "             '\\u0514\\u0516\\u0518\\u051a\\u051c\\u051e\\u0520\\u0522\\u0531-\\u0556'",
            "             '\\u10a0-\\u10c5\\u1e00\\u1e02\\u1e04\\u1e06\\u1e08\\u1e0a\\u1e0c\\u1e0e'",
            "             '\\u1e10\\u1e12\\u1e14\\u1e16\\u1e18\\u1e1a\\u1e1c\\u1e1e\\u1e20\\u1e22'",
            "             '\\u1e24\\u1e26\\u1e28\\u1e2a\\u1e2c\\u1e2e\\u1e30\\u1e32\\u1e34\\u1e36'",
            "             '\\u1e38\\u1e3a\\u1e3c\\u1e3e\\u1e40\\u1e42\\u1e44\\u1e46\\u1e48\\u1e4a'",
            "             '\\u1e4c\\u1e4e\\u1e50\\u1e52\\u1e54\\u1e56\\u1e58\\u1e5a\\u1e5c\\u1e5e'",
            "             '\\u1e60\\u1e62\\u1e64\\u1e66\\u1e68\\u1e6a\\u1e6c\\u1e6e\\u1e70\\u1e72'",
            "             '\\u1e74\\u1e76\\u1e78\\u1e7a\\u1e7c\\u1e7e\\u1e80\\u1e82\\u1e84\\u1e86'",
            "             '\\u1e88\\u1e8a\\u1e8c\\u1e8e\\u1e90\\u1e92\\u1e94\\u1e9e\\u1ea0\\u1ea2'",
            "             '\\u1ea4\\u1ea6\\u1ea8\\u1eaa\\u1eac\\u1eae\\u1eb0\\u1eb2\\u1eb4\\u1eb6'",
            "             '\\u1eb8\\u1eba\\u1ebc\\u1ebe\\u1ec0\\u1ec2\\u1ec4\\u1ec6\\u1ec8\\u1eca'",
            "             '\\u1ecc\\u1ece\\u1ed0\\u1ed2\\u1ed4\\u1ed6\\u1ed8\\u1eda\\u1edc\\u1ede'",
            "             '\\u1ee0\\u1ee2\\u1ee4\\u1ee6\\u1ee8\\u1eea\\u1eec\\u1eee\\u1ef0\\u1ef2'",
            "             '\\u1ef4\\u1ef6\\u1ef8\\u1efa\\u1efc\\u1efe\\u1f08-\\u1f0f\\u1f18-\\u1f1d'",
            "             '\\u1f28-\\u1f2f\\u1f38-\\u1f3f\\u1f48-\\u1f4d\\u1f59-\\u1f5f'",
            "             '\\u1f68-\\u1f6f\\u1fb8-\\u1fbb\\u1fc8-\\u1fcb\\u1fd8-\\u1fdb'",
            "             '\\u1fe8-\\u1fec\\u1ff8-\\u1ffb\\u2102\\u2107\\u210b-\\u210d\\u2110-\\u2112'",
            "             '\\u2115\\u2119-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u212d\\u2130-\\u2133'",
            "             '\\u213e-\\u213f\\u2145\\u2183\\u2c00-\\u2c2e\\u2c60\\u2c62-\\u2c64\\u2c67'",
            "             '\\u2c69\\u2c6b\\u2c6d-\\u2c6f\\u2c72\\u2c75\\u2c80\\u2c82\\u2c84\\u2c86'",
            "             '\\u2c88\\u2c8a\\u2c8c\\u2c8e\\u2c90\\u2c92\\u2c94\\u2c96\\u2c98\\u2c9a'",
            "             '\\u2c9c\\u2c9e\\u2ca0\\u2ca2\\u2ca4\\u2ca6\\u2ca8\\u2caa\\u2cac\\u2cae'",
            "             '\\u2cb0\\u2cb2\\u2cb4\\u2cb6\\u2cb8\\u2cba\\u2cbc\\u2cbe\\u2cc0\\u2cc2'",
            "             '\\u2cc4\\u2cc6\\u2cc8\\u2cca\\u2ccc\\u2cce\\u2cd0\\u2cd2\\u2cd4\\u2cd6'",
            "             '\\u2cd8\\u2cda\\u2cdc\\u2cde\\u2ce0\\u2ce2\\ua640\\ua642\\ua644\\ua646'",
            "             '\\ua648\\ua64a\\ua64c\\ua64e\\ua650\\ua652\\ua654\\ua656\\ua658\\ua65a'",
            "             '\\ua65c\\ua65e\\ua662\\ua664\\ua666\\ua668\\ua66a\\ua66c\\ua680\\ua682'",
            "             '\\ua684\\ua686\\ua688\\ua68a\\ua68c\\ua68e\\ua690\\ua692\\ua694\\ua696'",
            "             '\\ua722\\ua724\\ua726\\ua728\\ua72a\\ua72c\\ua72e\\ua732\\ua734\\ua736'",
            "             '\\ua738\\ua73a\\ua73c\\ua73e\\ua740\\ua742\\ua744\\ua746\\ua748\\ua74a'",
            "             '\\ua74c\\ua74e\\ua750\\ua752\\ua754\\ua756\\ua758\\ua75a\\ua75c\\ua75e'",
            "             '\\ua760\\ua762\\ua764\\ua766\\ua768\\ua76a\\ua76c\\ua76e\\ua779\\ua77b'",
            "             '\\ua77d-\\ua77e\\ua780\\ua782\\ua784\\ua786\\ua78b\\uff21-\\uff3a]')",
            "",
            "    idrest = '%s(?:%s|[0-9])*(?:(?<=_)%s)?' % (letter, letter, op)",
            "    letter_letter_digit = '%s(?:%s|\\\\d)*' % (letter, letter)",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'(class|trait|object)(\\s+)', bygroups(Keyword, Text), 'class'),",
            "            (r'[^\\S\\n]+', Text),",
            "            include('comments'),",
            "            (r'@%s' % idrest, Name.Decorator),",
            "            (r'(abstract|ca(?:se|tch)|d(?:ef|o)|e(?:lse|xtends)|'",
            "             r'f(?:inal(?:ly)?|or(?:Some)?)|i(?:f|mplicit)|'",
            "             r'lazy|match|new|override|pr(?:ivate|otected)'",
            "             r'|re(?:quires|turn)|s(?:ealed|uper)|'",
            "             r't(?:h(?:is|row)|ry)|va[lr]|w(?:hile|ith)|yield)\\b|'",
            "             r'(<[%:-]|=>|>:|[#=@_\\u21D2\\u2190])\\b', Keyword),",
            "            (r':(?!%s)' % op, Keyword, 'type'),",
            "            (r'%s%s\\b' % (upper, idrest), Name.Class),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(import|package)(\\s+)', bygroups(Keyword, Text), 'import'),",
            "            (r'(type)(\\s+)', bygroups(Keyword, Text), 'type'),",
            "            (r'\"\"\".*?\"\"\"(?!\")', String),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r\"'%s\" % idrest, Text.Symbol),",
            "            (r'[fs]\"\"\"', String, 'interptriplestring'),  # interpolated strings",
            "            (r'[fs]\"', String, 'interpstring'),  # interpolated strings",
            "            (r'raw\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),  # raw strings",
            "            # (r'(\\.)(%s|%s|`[^`]+`)' % (idrest, op), bygroups(Operator,",
            "            # Name.Attribute)),",
            "            (idrest, Name),",
            "            (r'`[^`]+`', Name),",
            "            (r'\\[', Operator, 'typeparam'),",
            "            (r'[(){};,.#]', Operator),",
            "            (op, Operator),",
            "            (r'([0-9][0-9]*\\.[0-9]*|\\.[0-9]+)([eE][+-]?[0-9]+)?[fFdD]?',",
            "             Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'(%s|%s|`[^`]+`)(\\s*)(\\[)' % (idrest, op),",
            "             bygroups(Name.Class, Text, Operator), ('#pop', 'typeparam')),",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r'\\{', Operator, '#pop'),",
            "            (r'\\(', Operator, '#pop'),",
            "            (r'%s|%s|`[^`]+`' % (idrest, op), Name.Class, '#pop'),",
            "        ],",
            "        'type': [",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r'<[%:]|>:|[#_]|\\bforSome\\b|\\btype\\b', Keyword),",
            "            (r'([,);}]|=>|=|\\u21d2)(\\s*)', bygroups(Operator, Text), '#pop'),",
            "            (r'[({]', Operator, '#push'),",
            "            (r'((?:%s|%s|`[^`]+`)(?:\\.(?:%s|%s|`[^`]+`))*)(\\s*)(\\[)' %",
            "             (idrest, op, idrest, op),",
            "             bygroups(Keyword.Type, Text, Operator), ('#pop', 'typeparam')),",
            "            (r'((?:%s|%s|`[^`]+`)(?:\\.(?:%s|%s|`[^`]+`))*)(\\s*)$' %",
            "             (idrest, op, idrest, op),",
            "             bygroups(Keyword.Type, Text), '#pop'),",
            "            (r'\\.|%s|%s|`[^`]+`' % (idrest, op), Keyword.Type)",
            "        ],",
            "        'typeparam': [",
            "            (r'\\s+', Text),",
            "            include('comments'),",
            "            (r',+', Punctuation),",
            "            (r'<[%:]|=>|>:|[#_\\u21D2]|\\bforSome\\b|\\btype\\b', Keyword),",
            "            (r'([\\])}])', Operator, '#pop'),",
            "            (r'[(\\[{]', Operator, '#push'),",
            "            (r'\\.|%s|%s|`[^`]+`' % (idrest, op), Keyword.Type)",
            "        ],",
            "        'comments': [",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "        ],",
            "        'comment': [",
            "            (r'[^/*]+', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "        'import': [",
            "            (r'(%s|\\.)+' % idrest, Name.Namespace, '#pop')",
            "        ],",
            "        'interpstringcommon': [",
            "            (r'[^\"$\\\\]+', String),",
            "            (r'\\$\\$', String),",
            "            (r'\\$' + letter_letter_digit, String.Interpol),",
            "            (r'\\$\\{', String.Interpol, 'interpbrace'),",
            "            (r'\\\\.', String),",
            "        ],",
            "        'interptriplestring': [",
            "            (r'\"\"\"(?!\")', String, '#pop'),",
            "            (r'\"', String),",
            "            include('interpstringcommon'),",
            "        ],",
            "        'interpstring': [",
            "            (r'\"', String, '#pop'),",
            "            include('interpstringcommon'),",
            "        ],",
            "        'interpbrace': [",
            "            (r'\\}', String.Interpol, '#pop'),",
            "            (r'\\{', String.Interpol, '#push'),",
            "            include('root'),",
            "        ],",
            "    }",
            "",
            "",
            "class GosuLexer(RegexLexer):",
            "    \"\"\"",
            "    For Gosu source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Gosu'",
            "    aliases = ['gosu']",
            "    filenames = ['*.gs', '*.gsx', '*.gsp', '*.vark']",
            "    mimetypes = ['text/x-gosu']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # modifiers etc.",
            "             r'([a-zA-Z_]\\w*)'                       # method name",
            "             r'(\\s*)(\\()',                           # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(in|as|typeof|statictypeof|typeis|typeas|if|else|foreach|for|'",
            "             r'index|while|do|continue|break|return|try|catch|finally|this|'",
            "             r'throw|new|switch|case|default|eval|super|outer|classpath|'",
            "             r'using)\\b', Keyword),",
            "            (r'(var|delegate|construct|function|private|internal|protected|'",
            "             r'public|abstract|override|final|static|extends|transient|'",
            "             r'implements|represents|readonly)\\b', Keyword.Declaration),",
            "            (r'(property\\s+)(get|set)?', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void|block)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null|NaN|Infinity)\\b', Keyword.Constant),",
            "            (r'(class|interface|enhancement|enum)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Class)),",
            "            (r'(uses)(\\s+)([\\w.]+\\*?)',",
            "             bygroups(Keyword.Namespace, Text, Name.Namespace)),",
            "            (r'\"', String, 'string'),",
            "            (r'(\\??[.#])([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'(:)([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'and|or|not|[\\\\~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'[0-9]+', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'templateText': [",
            "            (r'(\\\\<)|(\\\\\\$)', String),",
            "            (r'(<%@\\s+)(extends|params)',",
            "             bygroups(Operator, Name.Decorator), 'stringTemplate'),",
            "            (r'<%!--.*?--%>', Comment.Multiline),",
            "            (r'(<%)|(<%=)', Operator, 'stringTemplate'),",
            "            (r'\\$\\{', Operator, 'stringTemplateShorthand'),",
            "            (r'.', String)",
            "        ],",
            "        'string': [",
            "            (r'\"', String, '#pop'),",
            "            include('templateText')",
            "        ],",
            "        'stringTemplate': [",
            "            (r'\"', String, 'string'),",
            "            (r'%>', Operator, '#pop'),",
            "            include('root')",
            "        ],",
            "        'stringTemplateShorthand': [",
            "            (r'\"', String, 'string'),",
            "            (r'\\{', Operator, 'stringTemplateShorthand'),",
            "            (r'\\}', Operator, '#pop'),",
            "            include('root')",
            "        ],",
            "    }",
            "",
            "",
            "class GosuTemplateLexer(Lexer):",
            "    \"\"\"",
            "    For Gosu templates.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Gosu Template'",
            "    aliases = ['gst']",
            "    filenames = ['*.gst']",
            "    mimetypes = ['text/x-gosu-template']",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        lexer = GosuLexer()",
            "        stack = ['templateText']",
            "        yield from lexer.get_tokens_unprocessed(text, stack)",
            "",
            "",
            "class GroovyLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Groovy <http://groovy.codehaus.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Groovy'",
            "    aliases = ['groovy']",
            "    filenames = ['*.groovy','*.gradle']",
            "    mimetypes = ['text/x-groovy']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # Groovy allows a file to start with a shebang",
            "            (r'#!(.*?)$', Comment.Preproc, 'base'),",
            "            default('base'),",
            "        ],",
            "        'base': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                      # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while|in|as)\\b',",
            "             Keyword),",
            "            (r'(abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(def|boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"\"\".*?\"\"\"', String.Double),",
            "            (r\"'''.*?'''\", String.Single),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'\\$/((?!/\\$).)*/\\$', String),",
            "            (r'/(\\\\\\\\|\\\\[^\\\\]|[^/\\\\])*/', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\u[0-9a-fA-F]{4}'\", String.Char),",
            "            (r'(\\.)([a-zA-Z_]\\w*)', bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        return shebang_matches(text, r'groovy')",
            "",
            "",
            "class IokeLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Ioke <http://ioke.org/>`_ (a strongly typed, dynamic,",
            "    prototype based programming language) source.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Ioke'",
            "    filenames = ['*.ik']",
            "    aliases = ['ioke', 'ik']",
            "    mimetypes = ['text/x-iokesrc']",
            "    tokens = {",
            "        'interpolatableText': [",
            "            (r'(\\\\b|\\\\e|\\\\t|\\\\n|\\\\f|\\\\r|\\\\\"|\\\\\\\\|\\\\#|\\\\\\Z|\\\\u[0-9a-fA-F]{1,4}'",
            "             r'|\\\\[0-3]?[0-7]?[0-7])', String.Escape),",
            "            (r'#\\{', Punctuation, 'textInterpolationRoot')",
            "        ],",
            "",
            "        'text': [",
            "            (r'(?<!\\\\)\"', String, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\"]', String)",
            "        ],",
            "",
            "        'documentation': [",
            "            (r'(?<!\\\\)\"', String.Doc, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\"]', String.Doc)",
            "        ],",
            "",
            "        'textInterpolationRoot': [",
            "            (r'\\}', Punctuation, '#pop'),",
            "            include('root')",
            "        ],",
            "",
            "        'slashRegexp': [",
            "            (r'(?<!\\\\)/[im-psux]*', String.Regex, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'\\\\/', String.Regex),",
            "            (r'[^/]', String.Regex)",
            "        ],",
            "",
            "        'squareRegexp': [",
            "            (r'(?<!\\\\)][im-psux]*', String.Regex, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'\\\\]', String.Regex),",
            "            (r'[^\\]]', String.Regex)",
            "        ],",
            "",
            "        'squareText': [",
            "            (r'(?<!\\\\)]', String, '#pop'),",
            "            include('interpolatableText'),",
            "            (r'[^\\]]', String)",
            "        ],",
            "",
            "        'root': [",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "",
            "            # Comments",
            "            (r';(.*?)\\n', Comment),",
            "            (r'\\A#!(.*?)\\n', Comment),",
            "",
            "            # Regexps",
            "            (r'#/', String.Regex, 'slashRegexp'),",
            "            (r'#r\\[', String.Regex, 'squareRegexp'),",
            "",
            "            # Symbols",
            "            (r':[\\w!:?]+', String.Symbol),",
            "            (r'[\\w!:?]+:(?![\\w!?])', String.Other),",
            "            (r':\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Symbol),",
            "",
            "            # Documentation",
            "            (r'((?<=fn\\()|(?<=fnx\\()|(?<=method\\()|(?<=macro\\()|(?<=lecro\\()'",
            "             r'|(?<=syntax\\()|(?<=dmacro\\()|(?<=dlecro\\()|(?<=dlecrox\\()'",
            "             r'|(?<=dsyntax\\())\\s*\"', String.Doc, 'documentation'),",
            "",
            "            # Text",
            "            (r'\"', String, 'text'),",
            "            (r'#\\[', String, 'squareText'),",
            "",
            "            # Mimic",
            "            (r'\\w[\\w!:?]+(?=\\s*=.*mimic\\s)', Name.Entity),",
            "",
            "            # Assignment",
            "            (r'[a-zA-Z_][\\w!:?]*(?=[\\s]*[+*/-]?=[^=].*($|\\.))',",
            "             Name.Variable),",
            "",
            "            # keywords",
            "            (r'(break|cond|continue|do|ensure|for|for:dict|for:set|if|let|'",
            "             r'loop|p:for|p:for:dict|p:for:set|return|unless|until|while|'",
            "             r'with)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # Origin",
            "            (r'(eval|mimic|print|println)(?![\\w!:?])', Keyword),",
            "",
            "            # Base",
            "            (r'(cell\\?|cellNames|cellOwner\\?|cellOwner|cells|cell|'",
            "             r'documentation|hash|identity|mimic|removeCell\\!|undefineCell\\!)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # Ground",
            "            (r'(stackTraceAsText)(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehaviour Literals",
            "            (r'(dict|list|message|set)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Case",
            "            (r'(case|case:and|case:else|case:nand|case:nor|case:not|case:or|'",
            "             r'case:otherwise|case:xor)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Reflection",
            "            (r'(asText|become\\!|derive|freeze\\!|frozen\\?|in\\?|is\\?|kind\\?|'",
            "             r'mimic\\!|mimics|mimics\\?|prependMimic\\!|removeAllMimics\\!|'",
            "             r'removeMimic\\!|same\\?|send|thaw\\!|uniqueHexId)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehaviour Aspects",
            "            (r'(after|around|before)(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour",
            "            (r'(kind|cellDescriptionDict|cellSummary|genSym|inspect|notice)'",
            "             r'(?![\\w!:?])', Keyword),",
            "            (r'(use|destructuring)', Keyword.Reserved),",
            "",
            "            # DefaultBehavior BaseBehavior",
            "            (r'(cell\\?|cellOwner\\?|cellOwner|cellNames|cells|cell|'",
            "             r'documentation|identity|removeCell!|undefineCell)'",
            "             r'(?![\\w!:?])', Keyword),",
            "",
            "            # DefaultBehavior Internal",
            "            (r'(internal:compositeRegexp|internal:concatenateText|'",
            "             r'internal:createDecimal|internal:createNumber|'",
            "             r'internal:createRegexp|internal:createText)'",
            "             r'(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # DefaultBehaviour Conditions",
            "            (r'(availableRestarts|bind|error\\!|findRestart|handle|'",
            "             r'invokeRestart|rescue|restart|signal\\!|warn\\!)'",
            "             r'(?![\\w!:?])', Keyword.Reserved),",
            "",
            "            # constants",
            "            (r'(nil|false|true)(?![\\w!:?])', Name.Constant),",
            "",
            "            # names",
            "            (r'(Arity|Base|Call|Condition|DateTime|Aspects|Pointcut|'",
            "             r'Assignment|BaseBehavior|Boolean|Case|AndCombiner|Else|'",
            "             r'NAndCombiner|NOrCombiner|NotCombiner|OrCombiner|XOrCombiner|'",
            "             r'Conditions|Definitions|FlowControl|Internal|Literals|'",
            "             r'Reflection|DefaultMacro|DefaultMethod|DefaultSyntax|Dict|'",
            "             r'FileSystem|Ground|Handler|Hook|IO|IokeGround|Struct|'",
            "             r'LexicalBlock|LexicalMacro|List|Message|Method|Mixins|'",
            "             r'NativeMethod|Number|Origin|Pair|Range|Reflector|Regexp Match|'",
            "             r'Regexp|Rescue|Restart|Runtime|Sequence|Set|Symbol|'",
            "             r'System|Text|Tuple)(?![\\w!:?])', Name.Builtin),",
            "",
            "            # functions",
            "            ('(generateMatchMethod|aliasMethod|\\u03bb|\\u028E|fnx|fn|method|'",
            "             'dmacro|dlecro|syntax|macro|dlecrox|lecrox|lecro|syntax)'",
            "             '(?![\\\\w!:?])', Name.Function),",
            "",
            "            # Numbers",
            "            (r'-?0[xX][0-9a-fA-F]+', Number.Hex),",
            "            (r'-?(\\d+\\.?\\d*|\\d*\\.\\d+)([eE][+-]?[0-9]+)?', Number.Float),",
            "            (r'-?\\d+', Number.Integer),",
            "",
            "            (r'#\\(', Punctuation),",
            "",
            "            # Operators",
            "            (r'(&&>>|\\|\\|>>|\\*\\*>>|:::|::|\\.\\.\\.|===|\\*\\*>|\\*\\*=|&&>|&&=|'",
            "             r'\\|\\|>|\\|\\|=|\\->>|\\+>>|!>>|<>>>|<>>|&>>|%>>|#>>|@>>|/>>|\\*>>|'",
            "             r'\\?>>|\\|>>|\\^>>|~>>|\\$>>|=>>|<<=|>>=|<=>|<\\->|=~|!~|=>|\\+\\+|'",
            "             r'\\-\\-|<=|>=|==|!=|&&|\\.\\.|\\+=|\\-=|\\*=|\\/=|%=|&=|\\^=|\\|=|<\\-|'",
            "             r'\\+>|!>|<>|&>|%>|#>|\\@>|\\/>|\\*>|\\?>|\\|>|\\^>|~>|\\$>|<\\->|\\->|'",
            "             r'<<|>>|\\*\\*|\\?\\||\\?&|\\|\\||>|<|\\*|\\/|%|\\+|\\-|&|\\^|\\||=|\\$|!|~|'",
            "             r'\\?|#|\\u2260|\\u2218|\\u2208|\\u2209)', Operator),",
            "            (r'(and|nand|or|xor|nor|return|import)(?![\\w!?])',",
            "             Operator),",
            "",
            "            # Punctuation",
            "            (r'(\\`\\`|\\`|\\'\\'|\\'|\\.|\\,|@@|@|\\[|\\]|\\(|\\)|\\{|\\})', Punctuation),",
            "",
            "            # kinds",
            "            (r'[A-Z][\\w!:?]*', Name.Class),",
            "",
            "            # default cellnames",
            "            (r'[a-z_][\\w!:?]*', Name)",
            "        ]",
            "    }",
            "",
            "",
            "class ClojureLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for `Clojure <http://clojure.org/>`_ source code.",
            "",
            "    .. versionadded:: 0.11",
            "    \"\"\"",
            "    name = 'Clojure'",
            "    aliases = ['clojure', 'clj']",
            "    filenames = ['*.clj']",
            "    mimetypes = ['text/x-clojure', 'application/x-clojure']",
            "",
            "    special_forms = (",
            "        '.', 'def', 'do', 'fn', 'if', 'let', 'new', 'quote', 'var', 'loop'",
            "    )",
            "",
            "    # It's safe to consider 'ns' a declaration thing because it defines a new",
            "    # namespace.",
            "    declarations = (",
            "        'def-', 'defn', 'defn-', 'defmacro', 'defmulti', 'defmethod',",
            "        'defstruct', 'defonce', 'declare', 'definline', 'definterface',",
            "        'defprotocol', 'defrecord', 'deftype', 'defproject', 'ns'",
            "    )",
            "",
            "    builtins = (",
            "        '*', '+', '-', '->', '/', '<', '<=', '=', '==', '>', '>=', '..',",
            "        'accessor', 'agent', 'agent-errors', 'aget', 'alength', 'all-ns',",
            "        'alter', 'and', 'append-child', 'apply', 'array-map', 'aset',",
            "        'aset-boolean', 'aset-byte', 'aset-char', 'aset-double', 'aset-float',",
            "        'aset-int', 'aset-long', 'aset-short', 'assert', 'assoc', 'await',",
            "        'await-for', 'bean', 'binding', 'bit-and', 'bit-not', 'bit-or',",
            "        'bit-shift-left', 'bit-shift-right', 'bit-xor', 'boolean', 'branch?',",
            "        'butlast', 'byte', 'cast', 'char', 'children', 'class',",
            "        'clear-agent-errors', 'comment', 'commute', 'comp', 'comparator',",
            "        'complement', 'concat', 'conj', 'cons', 'constantly', 'cond', 'if-not',",
            "        'construct-proxy', 'contains?', 'count', 'create-ns', 'create-struct',",
            "        'cycle', 'dec',  'deref', 'difference', 'disj', 'dissoc', 'distinct',",
            "        'doall', 'doc', 'dorun', 'doseq', 'dosync', 'dotimes', 'doto',",
            "        'double', 'down', 'drop', 'drop-while', 'edit', 'end?', 'ensure',",
            "        'eval', 'every?', 'false?', 'ffirst', 'file-seq', 'filter', 'find',",
            "        'find-doc', 'find-ns', 'find-var', 'first', 'float', 'flush', 'for',",
            "        'fnseq', 'frest', 'gensym', 'get-proxy-class', 'get',",
            "        'hash-map', 'hash-set', 'identical?', 'identity', 'if-let', 'import',",
            "        'in-ns', 'inc', 'index', 'insert-child', 'insert-left', 'insert-right',",
            "        'inspect-table', 'inspect-tree', 'instance?', 'int', 'interleave',",
            "        'intersection', 'into', 'into-array', 'iterate', 'join', 'key', 'keys',",
            "        'keyword', 'keyword?', 'last', 'lazy-cat', 'lazy-cons', 'left',",
            "        'lefts', 'line-seq', 'list*', 'list', 'load', 'load-file',",
            "        'locking', 'long', 'loop', 'macroexpand', 'macroexpand-1',",
            "        'make-array', 'make-node', 'map', 'map-invert', 'map?', 'mapcat',",
            "        'max', 'max-key', 'memfn', 'merge', 'merge-with', 'meta', 'min',",
            "        'min-key', 'name', 'namespace', 'neg?', 'new', 'newline', 'next',",
            "        'nil?', 'node', 'not', 'not-any?', 'not-every?', 'not=', 'ns-imports',",
            "        'ns-interns', 'ns-map', 'ns-name', 'ns-publics', 'ns-refers',",
            "        'ns-resolve', 'ns-unmap', 'nth', 'nthrest', 'or', 'parse', 'partial',",
            "        'path', 'peek', 'pop', 'pos?', 'pr', 'pr-str', 'print', 'print-str',",
            "        'println', 'println-str', 'prn', 'prn-str', 'project', 'proxy',",
            "        'proxy-mappings', 'quot', 'rand', 'rand-int', 'range', 're-find',",
            "        're-groups', 're-matcher', 're-matches', 're-pattern', 're-seq',",
            "        'read', 'read-line', 'reduce', 'ref', 'ref-set', 'refer', 'rem',",
            "        'remove', 'remove-method', 'remove-ns', 'rename', 'rename-keys',",
            "        'repeat', 'replace', 'replicate', 'resolve', 'rest', 'resultset-seq',",
            "        'reverse', 'rfirst', 'right', 'rights', 'root', 'rrest', 'rseq',",
            "        'second', 'select', 'select-keys', 'send', 'send-off', 'seq',",
            "        'seq-zip', 'seq?', 'set', 'short', 'slurp', 'some', 'sort',",
            "        'sort-by', 'sorted-map', 'sorted-map-by', 'sorted-set',",
            "        'special-symbol?', 'split-at', 'split-with', 'str', 'string?',",
            "        'struct', 'struct-map', 'subs', 'subvec', 'symbol', 'symbol?',",
            "        'sync', 'take', 'take-nth', 'take-while', 'test', 'time', 'to-array',",
            "        'to-array-2d', 'tree-seq', 'true?', 'union', 'up', 'update-proxy',",
            "        'val', 'vals', 'var-get', 'var-set', 'var?', 'vector', 'vector-zip',",
            "        'vector?', 'when', 'when-first', 'when-let', 'when-not',",
            "        'with-local-vars', 'with-meta', 'with-open', 'with-out-str',",
            "        'xml-seq', 'xml-zip', 'zero?', 'zipmap', 'zipper')",
            "",
            "    # valid names for identifiers",
            "    # well, names can only not consist fully of numbers",
            "    # but this should be good enough for now",
            "",
            "    # TODO / should divide keywords/symbols into namespace/rest",
            "    # but that's hard, so just pretend / is part of the name",
            "    valid_name = r'(?!#)[\\w!$%*+<=>?/.#|-]+'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # the comments - always starting with semicolon",
            "            # and going to the end of the line",
            "            (r';.*$', Comment.Single),",
            "",
            "            # whitespaces - usually not relevant",
            "            (r'[,\\s]+', Text),",
            "",
            "            # numbers",
            "            (r'-?\\d+\\.\\d+', Number.Float),",
            "            (r'-?\\d+', Number.Integer),",
            "            (r'0x-?[abcdef\\d]+', Number.Hex),",
            "",
            "            # strings, symbols and characters",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\" + valid_name, String.Symbol),",
            "            (r\"\\\\(.|[a-z]+)\", String.Char),",
            "",
            "            # keywords",
            "            (r'::?#?' + valid_name, String.Symbol),",
            "",
            "            # special operators",
            "            (r'~@|[`\\'#^~&@]', Operator),",
            "",
            "            # highlight the special forms",
            "            (words(special_forms, suffix=' '), Keyword),",
            "",
            "            # Technically, only the special forms are 'keywords'. The problem",
            "            # is that only treating them as keywords means that things like",
            "            # 'defn' and 'ns' need to be highlighted as builtins. This is ugly",
            "            # and weird for most styles. So, as a compromise we're going to",
            "            # highlight them as Keyword.Declarations.",
            "            (words(declarations, suffix=' '), Keyword.Declaration),",
            "",
            "            # highlight the builtins",
            "            (words(builtins, suffix=' '), Name.Builtin),",
            "",
            "            # the remaining functions",
            "            (r'(?<=\\()' + valid_name, Name.Function),",
            "",
            "            # find the remaining variables",
            "            (valid_name, Name.Variable),",
            "",
            "            # Clojure accepts vector notation",
            "            (r'(\\[|\\])', Punctuation),",
            "",
            "            # Clojure accepts map notation",
            "            (r'(\\{|\\})', Punctuation),",
            "",
            "            # the famous parentheses!",
            "            (r'(\\(|\\))', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class ClojureScriptLexer(ClojureLexer):",
            "    \"\"\"",
            "    Lexer for `ClojureScript <http://clojure.org/clojurescript>`_",
            "    source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'ClojureScript'",
            "    aliases = ['clojurescript', 'cljs']",
            "    filenames = ['*.cljs']",
            "    mimetypes = ['text/x-clojurescript', 'application/x-clojurescript']",
            "",
            "",
            "class TeaLangLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Tea <http://teatrove.org/>`_ source code. Only used within a",
            "    TeaTemplateLexer.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w\\.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                       # method name",
            "             r'(\\s*)(\\()',                           # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w\\.]*', Name.Decorator),",
            "            (r'(and|break|else|foreach|if|in|not|or|reverse)\\b',",
            "             Keyword),",
            "            (r'(as|call|define)\\b', Keyword.Declaration),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(template)(\\s+)', bygroups(Keyword.Declaration, Text), 'template'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'(\\.)([a-zA-Z_]\\w*)', bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_\\$]\\w*', Name),",
            "            (r'(isa|[.]{3}|[.]{2}|[=#!<>+-/%&;,.\\*\\\\\\(\\)\\[\\]\\{\\}])', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'template': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }",
            "",
            "",
            "class CeylonLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Ceylon <http://ceylon-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Ceylon'",
            "    aliases = ['ceylon']",
            "    filenames = ['*.ceylon']",
            "    mimetypes = ['text/x-ceylon']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    #: optional Comment or Whitespace",
            "    _ws = r'(?:\\s|//.*?\\n|/[*].*?[*]/)+'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_]\\w*)'                      # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "            (r'(shared|abstract|formal|default|actual|variable|deprecated|small|'",
            "             r'late|literal|doc|by|see|throws|optional|license|tagged|final|native|'",
            "             r'annotation|sealed)\\b', Name.Decorator),",
            "            (r'(break|case|catch|continue|else|finally|for|in|'",
            "             r'if|return|switch|this|throw|try|while|is|exists|dynamic|'",
            "             r'nonempty|then|outer|assert|let)\\b', Keyword),",
            "            (r'(abstracts|extends|satisfies|'",
            "             r'super|given|of|out|assign)\\b', Keyword.Declaration),",
            "            (r'(function|value|void|new)\\b',",
            "             Keyword.Type),",
            "            (r'(assembly|module|package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface|object|alias)(\\s+)',",
            "             bygroups(Keyword.Declaration, Text), 'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String),",
            "            (r\"'\\\\.'|'[^\\\\]'|'\\\\\\{#[0-9a-fA-F]{4}\\}'\", String.Char),",
            "            (r'(\\.)([a-z_]\\w*)',",
            "             bygroups(Operator, Name.Attribute)),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>|+=:;,./?-]', Operator),",
            "            (r'\\d{1,3}(_\\d{3})+\\.\\d{1,3}(_\\d{3})+[kMGTPmunpf]?', Number.Float),",
            "            (r'\\d{1,3}(_\\d{3})+\\.[0-9]+([eE][+-]?[0-9]+)?[kMGTPmunpf]?',",
            "             Number.Float),",
            "            (r'[0-9][0-9]*\\.\\d{1,3}(_\\d{3})+[kMGTPmunpf]?', Number.Float),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][+-]?[0-9]+)?[kMGTPmunpf]?',",
            "             Number.Float),",
            "            (r'#([0-9a-fA-F]{4})(_[0-9a-fA-F]{4})+', Number.Hex),",
            "            (r'#[0-9a-fA-F]+', Number.Hex),",
            "            (r'\\$([01]{4})(_[01]{4})+', Number.Bin),",
            "            (r'\\$[01]+', Number.Bin),",
            "            (r'\\d{1,3}(_\\d{3})+[kMGTP]?', Number.Integer),",
            "            (r'[0-9]+[kMGTP]?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[A-Za-z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[a-z][\\w.]*',",
            "             Name.Namespace, '#pop')",
            "        ],",
            "        'comment': [",
            "            (r'[^*/]', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "    }",
            "",
            "",
            "class KotlinLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Kotlin <http://kotlinlang.org/>`_",
            "    source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    name = 'Kotlin'",
            "    aliases = ['kotlin']",
            "    filenames = ['*.kt', '*.kts']",
            "    mimetypes = ['text/x-kotlin']",
            "",
            "    flags = re.MULTILINE | re.DOTALL | re.UNICODE",
            "",
            "    kt_name = ('@?[_' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl') + ']' +",
            "               '[' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl', 'Nd', 'Pc', 'Cf',",
            "                                 'Mn', 'Mc') + ']*')",
            "",
            "    kt_space_name = ('@?[_' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl') + ']' +",
            "               '[' + uni.combine('Lu', 'Ll', 'Lt', 'Lm', 'Nl', 'Nd', 'Pc', 'Cf',",
            "                                 'Mn', 'Mc', 'Zs') + ',-]*')",
            "",
            "    kt_id = '(' + kt_name + '|`' + kt_space_name + '`)'",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'^\\s*\\[.*?\\]', Name.Attribute),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'\\s+', Text),",
            "            (r'\\\\\\n', Text),  # line continuation",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'^#!/.+?\\n', Comment.Single),  # shebang for kotlin scripts",
            "            (r'/[*].*?[*]/', Comment.Multiline),",
            "            (r'\"\"\".*?\"\"\"', String),",
            "            (r'\\n', Text),",
            "            (r'::|!!|\\?[:.]', Operator),",
            "            (r'[~!%^&*()+=|\\[\\]:;,.<>/?-]', Punctuation),",
            "            (r'[{}]', Punctuation),",
            "            (r'@\"(\"\"|[^\"])*\"', String),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\\\n])*[\"\\n]', String),",
            "            (r\"'\\\\.'|'[^\\\\]'\", String.Char),",
            "            (r\"[0-9](\\.[0-9]*)?([eE][+-][0-9]+)?[flFL]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r'(object)(\\s+)(:)(\\s+)', bygroups(Keyword, Text, Punctuation, Text), 'class'),",
            "            (r'(companion)(\\s+)(object)', bygroups(Keyword, Text, Keyword)),",
            "            (r'(class|interface|object)(\\s+)', bygroups(Keyword, Text), 'class'),",
            "            (r'(package|import)(\\s+)', bygroups(Keyword, Text), 'package'),",
            "            (r'(val|var)(\\s+)([(])', bygroups(Keyword, Text, Punctuation), 'property_dec'),",
            "            (r'(val|var)(\\s+)', bygroups(Keyword, Text), 'property'),",
            "            (r'(fun)(\\s+)', bygroups(Keyword, Text), 'function'),",
            "            (r'(inline fun)(\\s+)', bygroups(Keyword, Text), 'function'),",
            "            (r'(abstract|annotation|as|break|by|catch|class|companion|const|'",
            "             r'constructor|continue|crossinline|data|do|dynamic|else|enum|'",
            "             r'external|false|final|finally|for|fun|get|if|import|in|infix|'",
            "             r'inline|inner|interface|internal|is|lateinit|noinline|null|'",
            "             r'object|open|operator|out|override|package|private|protected|'",
            "             r'public|reified|return|sealed|set|super|tailrec|this|throw|'",
            "             r'true|try|val|var|vararg|when|where|while)\\b', Keyword),",
            "            (kt_id, Name),",
            "        ],",
            "        'package': [",
            "            (r'\\S+', Name.Namespace, '#pop')",
            "        ],",
            "        'class': [",
            "            (kt_id, Name.Class, '#pop')",
            "        ],",
            "        'property': [",
            "            (kt_id, Name.Property, '#pop')",
            "        ],",
            "        'property_dec': [",
            "            (r'(,)(\\s*)', bygroups(Punctuation, Text)),",
            "            (r'(:)(\\s*)', bygroups(Punctuation, Text)),",
            "            (r'<', Punctuation, 'generic'),",
            "            (r'([)])', Punctuation, '#pop'),",
            "            (kt_id, Name.Property)",
            "        ],",
            "        'function': [",
            "            (r'<', Punctuation, 'generic'),",
            "            (r''+kt_id+'([.])'+kt_id, bygroups(Name.Class, Punctuation, Name.Function), '#pop'),",
            "            (kt_id, Name.Function, '#pop')",
            "        ],",
            "        'generic': [",
            "            (r'(>)(\\s*)', bygroups(Punctuation, Text), '#pop'),",
            "            (r':',Punctuation),",
            "            (r'(reified|out|in)\\b', Keyword),",
            "            (r',',Text),",
            "            (r'\\s+',Text),",
            "            (kt_id,Name)",
            "        ]",
            "    }",
            "",
            "",
            "class XtendLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Xtend <http://xtend-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Xtend'",
            "    aliases = ['xtend']",
            "    filenames = ['*.xtend']",
            "    mimetypes = ['text/x-xtend']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_$][\\w$]*)'                  # method name",
            "             r'(\\s*)(\\()',                          # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(assert|break|case|catch|continue|default|do|else|finally|for|'",
            "             r'if|goto|instanceof|new|return|switch|this|throw|try|while|IF|'",
            "             r'ELSE|ELSEIF|ENDIF|FOR|ENDFOR|SEPARATOR|BEFORE|AFTER)\\b',",
            "             Keyword),",
            "            (r'(def|abstract|const|enum|extends|final|implements|native|private|'",
            "             r'protected|public|static|strictfp|super|synchronized|throws|'",
            "             r'transient|volatile)\\b', Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(class|interface)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r\"(''')\", String, 'template'),",
            "            (r'(\\u00BB)', String, 'template'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>\\|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'template': [",
            "            (r\"'''\", String, '#pop'),",
            "            (r'\\u00AB', String, '#pop'),",
            "            (r'.', String)",
            "        ],",
            "    }",
            "",
            "",
            "class PigLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Pig Latin <https://pig.apache.org/>`_ source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Pig'",
            "    aliases = ['pig']",
            "    filenames = ['*.pig']",
            "    mimetypes = ['text/x-pig']",
            "",
            "    flags = re.MULTILINE | re.IGNORECASE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'--.*', Comment),",
            "            (r'/\\*[\\w\\W]*?\\*/', Comment.Multiline),",
            "            (r'\\\\\\n', Text),",
            "            (r'\\\\', Text),",
            "            (r'\\'(?:\\\\[ntbrf\\\\\\']|\\\\u[0-9a-f]{4}|[^\\'\\\\\\n\\r])*\\'', String),",
            "            include('keywords'),",
            "            include('types'),",
            "            include('builtins'),",
            "            include('punct'),",
            "            include('operators'),",
            "            (r'[0-9]*\\.[0-9]+(e[0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-f]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text),",
            "            (r'([a-z_]\\w*)(\\s*)(\\()',",
            "             bygroups(Name.Function, Text, Punctuation)),",
            "            (r'[()#:]', Text),",
            "            (r'[^(:#\\'\")\\s]+', Text),",
            "            (r'\\S+\\s+', Text)   # TODO: make tests pass without \\s+",
            "        ],",
            "        'keywords': [",
            "            (r'(assert|and|any|all|arrange|as|asc|bag|by|cache|CASE|cat|cd|cp|'",
            "             r'%declare|%default|define|dense|desc|describe|distinct|du|dump|'",
            "             r'eval|exex|explain|filter|flatten|foreach|full|generate|group|'",
            "             r'help|if|illustrate|import|inner|input|into|is|join|kill|left|'",
            "             r'limit|load|ls|map|matches|mkdir|mv|not|null|onschema|or|order|'",
            "             r'outer|output|parallel|pig|pwd|quit|register|returns|right|rm|'",
            "             r'rmf|rollup|run|sample|set|ship|split|stderr|stdin|stdout|store|'",
            "             r'stream|through|union|using|void)\\b', Keyword)",
            "        ],",
            "        'builtins': [",
            "            (r'(AVG|BinStorage|cogroup|CONCAT|copyFromLocal|copyToLocal|COUNT|'",
            "             r'cross|DIFF|MAX|MIN|PigDump|PigStorage|SIZE|SUM|TextLoader|'",
            "             r'TOKENIZE)\\b', Name.Builtin)",
            "        ],",
            "        'types': [",
            "            (r'(bytearray|BIGINTEGER|BIGDECIMAL|chararray|datetime|double|float|'",
            "             r'int|long|tuple)\\b', Keyword.Type)",
            "        ],",
            "        'punct': [",
            "            (r'[;(){}\\[\\]]', Punctuation),",
            "        ],",
            "        'operators': [",
            "            (r'[#=,./%+\\-?]', Operator),",
            "            (r'(eq|gt|lt|gte|lte|neq|matches)\\b', Operator),",
            "            (r'(==|<=|<|>=|>|!=)', Operator),",
            "        ],",
            "    }",
            "",
            "",
            "class GoloLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Golo <http://golo-lang.org/>`_ source code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Golo'",
            "    filenames = ['*.golo']",
            "    aliases = ['golo']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^\\S\\n]+', Text),",
            "",
            "            (r'#.*$', Comment),",
            "",
            "            (r'(\\^|\\.\\.\\.|:|\\?:|->|==|!=|=|\\+|\\*|%|/|<=|<|>=|>|=|\\.)',",
            "                Operator),",
            "            (r'(?<=[^-])(-)(?=[^-])', Operator),",
            "",
            "            (r'(?<=[^`])(is|isnt|and|or|not|oftype|in|orIfNull)\\b', Operator.Word),",
            "            (r'[]{}|(),[]', Punctuation),",
            "",
            "            (r'(module|import)(\\s+)',",
            "                bygroups(Keyword.Namespace, Text),",
            "                'modname'),",
            "            (r'\\b([a-zA-Z_][\\w$.]*)(::)',  bygroups(Name.Namespace, Punctuation)),",
            "            (r'\\b([a-zA-Z_][\\w$]*(?:\\.[a-zA-Z_][\\w$]*)+)\\b', Name.Namespace),",
            "",
            "            (r'(let|var)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'varname'),",
            "            (r'(struct)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'structname'),",
            "            (r'(function)(\\s+)',",
            "                bygroups(Keyword.Declaration, Text),",
            "                'funcname'),",
            "",
            "            (r'(null|true|false)\\b', Keyword.Constant),",
            "            (r'(augment|pimp'",
            "             r'|if|else|case|match|return'",
            "             r'|case|when|then|otherwise'",
            "             r'|while|for|foreach'",
            "             r'|try|catch|finally|throw'",
            "             r'|local'",
            "             r'|continue|break)\\b', Keyword),",
            "",
            "            (r'(map|array|list|set|vector|tuple)(\\[)',",
            "                bygroups(Name.Builtin, Punctuation)),",
            "            (r'(print|println|readln|raise|fun'",
            "             r'|asInterfaceInstance)\\b', Name.Builtin),",
            "            (r'(`?[a-zA-Z_][\\w$]*)(\\()',",
            "                bygroups(Name.Function, Punctuation)),",
            "",
            "            (r'-?[\\d_]*\\.[\\d_]*([eE][+-]?\\d[\\d_]*)?F?', Number.Float),",
            "            (r'0[0-7]+j?', Number.Oct),",
            "            (r'0[xX][a-fA-F0-9]+', Number.Hex),",
            "            (r'-?\\d[\\d_]*L', Number.Integer.Long),",
            "            (r'-?\\d[\\d_]*', Number.Integer),",
            "",
            "            (r'`?[a-zA-Z_][\\w$]*', Name),",
            "            (r'@[a-zA-Z_][\\w$.]*', Name.Decorator),",
            "",
            "            (r'\"\"\"', String, combined('stringescape', 'triplestring')),",
            "            (r'\"', String, combined('stringescape', 'doublestring')),",
            "            (r\"'\", String, combined('stringescape', 'singlestring')),",
            "            (r'----((.|\\n)*?)----', String.Doc)",
            "",
            "        ],",
            "",
            "        'funcname': [",
            "            (r'`?[a-zA-Z_][\\w$]*', Name.Function, '#pop'),",
            "        ],",
            "        'modname': [",
            "            (r'[a-zA-Z_][\\w$.]*\\*?', Name.Namespace, '#pop')",
            "        ],",
            "        'structname': [",
            "            (r'`?[\\w.]+\\*?', Name.Class, '#pop')",
            "        ],",
            "        'varname': [",
            "            (r'`?[a-zA-Z_][\\w$]*', Name.Variable, '#pop'),",
            "        ],",
            "        'string': [",
            "            (r'[^\\\\\\'\"\\n]+', String),",
            "            (r'[\\'\"\\\\]', String)",
            "        ],",
            "        'stringescape': [",
            "            (r'\\\\([\\\\abfnrtv\"\\']|\\n|N\\{.*?\\}|u[a-fA-F0-9]{4}|'",
            "             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)",
            "        ],",
            "        'triplestring': [",
            "            (r'\"\"\"', String, '#pop'),",
            "            include('string'),",
            "            (r'\\n', String),",
            "        ],",
            "        'doublestring': [",
            "            (r'\"', String.Double, '#pop'),",
            "            include('string'),",
            "        ],",
            "        'singlestring': [",
            "            (r\"'\", String, '#pop'),",
            "            include('string'),",
            "        ],",
            "        'operators': [",
            "            (r'[#=,./%+\\-?]', Operator),",
            "            (r'(eq|gt|lt|gte|lte|neq|matches)\\b', Operator),",
            "            (r'(==|<=|<|>=|>|!=)', Operator),",
            "        ],",
            "    }",
            "",
            "",
            "class JasminLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Jasmin <http://jasmin.sourceforge.net/>`_ assembly code.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Jasmin'",
            "    aliases = ['jasmin', 'jasminxt']",
            "    filenames = ['*.j']",
            "",
            "    _whitespace = r' \\n\\t\\r'",
            "    _ws = r'(?:[%s]+)' % _whitespace",
            "    _separator = r'%s:=' % _whitespace",
            "    _break = r'(?=[%s]|$)' % _separator",
            "    _name = r'[^%s]+' % _separator",
            "    _unqualified_name = r'(?:[^%s.;\\[/]+)' % _separator",
            "",
            "    tokens = {",
            "        'default': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r\"'\", String.Single, ('#pop', 'quote')),",
            "            (r'\"', String.Double, 'string'),",
            "            (r'=', Punctuation),",
            "            (r':', Punctuation, 'label'),",
            "            (_ws, Text),",
            "            (r';.*', Comment.Single),",
            "            (r'(\\$[-+])?0x-?[\\da-fA-F]+%s' % _break, Number.Hex),",
            "            (r'(\\$[-+]|\\+)?-?\\d+%s' % _break, Number.Integer),",
            "            (r'-?(\\d+\\.\\d*|\\.\\d+)([eE][-+]?\\d+)?[fFdD]?'",
            "             r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]*%s' % _break, Number.Float),",
            "            (r'\\$%s' % _name, Name.Variable),",
            "",
            "            # Directives",
            "            (r'\\.annotation%s' % _break, Keyword.Reserved, 'annotation'),",
            "            (r'(\\.attribute|\\.bytecode|\\.debug|\\.deprecated|\\.enclosing|'",
            "             r'\\.interface|\\.line|\\.signature|\\.source|\\.stack|\\.var|abstract|'",
            "             r'annotation|bridge|class|default|enum|field|final|fpstrict|'",
            "             r'interface|native|private|protected|public|signature|static|'",
            "             r'synchronized|synthetic|transient|varargs|volatile)%s' % _break,",
            "             Keyword.Reserved),",
            "            (r'\\.catch%s' % _break, Keyword.Reserved, 'caught-exception'),",
            "            (r'(\\.class|\\.implements|\\.inner|\\.super|inner|invisible|'",
            "             r'invisibleparam|outer|visible|visibleparam)%s' % _break,",
            "             Keyword.Reserved, 'class/convert-dots'),",
            "            (r'\\.field%s' % _break, Keyword.Reserved,",
            "             ('descriptor/convert-dots', 'field')),",
            "            (r'(\\.end|\\.limit|use)%s' % _break, Keyword.Reserved,",
            "             'no-verification'),",
            "            (r'\\.method%s' % _break, Keyword.Reserved, 'method'),",
            "            (r'\\.set%s' % _break, Keyword.Reserved, 'var'),",
            "            (r'\\.throws%s' % _break, Keyword.Reserved, 'exception'),",
            "            (r'(from|offset|to|using)%s' % _break, Keyword.Reserved, 'label'),",
            "            (r'is%s' % _break, Keyword.Reserved,",
            "             ('descriptor/convert-dots', 'var')),",
            "            (r'(locals|stack)%s' % _break, Keyword.Reserved, 'verification'),",
            "            (r'method%s' % _break, Keyword.Reserved, 'enclosing-method'),",
            "",
            "            # Instructions",
            "            (words((",
            "                'aaload', 'aastore', 'aconst_null', 'aload', 'aload_0', 'aload_1', 'aload_2',",
            "                'aload_3', 'aload_w', 'areturn', 'arraylength', 'astore', 'astore_0', 'astore_1',",
            "                'astore_2', 'astore_3', 'astore_w', 'athrow', 'baload', 'bastore', 'bipush',",
            "                'breakpoint', 'caload', 'castore', 'd2f', 'd2i', 'd2l', 'dadd', 'daload', 'dastore',",
            "                'dcmpg', 'dcmpl', 'dconst_0', 'dconst_1', 'ddiv', 'dload', 'dload_0', 'dload_1',",
            "                'dload_2', 'dload_3', 'dload_w', 'dmul', 'dneg', 'drem', 'dreturn', 'dstore', 'dstore_0',",
            "                'dstore_1', 'dstore_2', 'dstore_3', 'dstore_w', 'dsub', 'dup', 'dup2', 'dup2_x1',",
            "                'dup2_x2', 'dup_x1', 'dup_x2', 'f2d', 'f2i', 'f2l', 'fadd', 'faload', 'fastore', 'fcmpg',",
            "                'fcmpl', 'fconst_0', 'fconst_1', 'fconst_2', 'fdiv', 'fload', 'fload_0', 'fload_1',",
            "                'fload_2', 'fload_3', 'fload_w', 'fmul', 'fneg', 'frem', 'freturn', 'fstore', 'fstore_0',",
            "                'fstore_1', 'fstore_2', 'fstore_3', 'fstore_w', 'fsub', 'i2b', 'i2c', 'i2d', 'i2f', 'i2l',",
            "                'i2s', 'iadd', 'iaload', 'iand', 'iastore', 'iconst_0', 'iconst_1', 'iconst_2',",
            "                'iconst_3', 'iconst_4', 'iconst_5', 'iconst_m1', 'idiv', 'iinc', 'iinc_w', 'iload',",
            "                'iload_0', 'iload_1', 'iload_2', 'iload_3', 'iload_w', 'imul', 'ineg', 'int2byte',",
            "                'int2char', 'int2short', 'ior', 'irem', 'ireturn', 'ishl', 'ishr', 'istore', 'istore_0',",
            "                'istore_1', 'istore_2', 'istore_3', 'istore_w', 'isub', 'iushr', 'ixor', 'l2d', 'l2f',",
            "                'l2i', 'ladd', 'laload', 'land', 'lastore', 'lcmp', 'lconst_0', 'lconst_1', 'ldc2_w',",
            "                'ldiv', 'lload', 'lload_0', 'lload_1', 'lload_2', 'lload_3', 'lload_w', 'lmul', 'lneg',",
            "                'lookupswitch', 'lor', 'lrem', 'lreturn', 'lshl', 'lshr', 'lstore', 'lstore_0',",
            "                'lstore_1', 'lstore_2', 'lstore_3', 'lstore_w', 'lsub', 'lushr', 'lxor',",
            "                'monitorenter', 'monitorexit', 'nop', 'pop', 'pop2', 'ret', 'ret_w', 'return', 'saload',",
            "                'sastore', 'sipush', 'swap'), suffix=_break), Keyword.Reserved),",
            "            (r'(anewarray|checkcast|instanceof|ldc|ldc_w|new)%s' % _break,",
            "             Keyword.Reserved, 'class/no-dots'),",
            "            (r'invoke(dynamic|interface|nonvirtual|special|'",
            "             r'static|virtual)%s' % _break, Keyword.Reserved,",
            "             'invocation'),",
            "            (r'(getfield|putfield)%s' % _break, Keyword.Reserved,",
            "             ('descriptor/no-dots', 'field')),",
            "            (r'(getstatic|putstatic)%s' % _break, Keyword.Reserved,",
            "             ('descriptor/no-dots', 'static')),",
            "            (words((",
            "                'goto', 'goto_w', 'if_acmpeq', 'if_acmpne', 'if_icmpeq',",
            "                'if_icmpge', 'if_icmpgt', 'if_icmple', 'if_icmplt', 'if_icmpne',",
            "                'ifeq', 'ifge', 'ifgt', 'ifle', 'iflt', 'ifne', 'ifnonnull',",
            "                'ifnull', 'jsr', 'jsr_w'), suffix=_break),",
            "             Keyword.Reserved, 'label'),",
            "            (r'(multianewarray|newarray)%s' % _break, Keyword.Reserved,",
            "             'descriptor/convert-dots'),",
            "            (r'tableswitch%s' % _break, Keyword.Reserved, 'table')",
            "        ],",
            "        'quote': [",
            "            (r\"'\", String.Single, '#pop'),",
            "            (r'\\\\u[\\da-fA-F]{4}', String.Escape),",
            "            (r\"[^'\\\\]+\", String.Single)",
            "        ],",
            "        'string': [",
            "            (r'\"', String.Double, '#pop'),",
            "            (r'\\\\([nrtfb\"\\'\\\\]|u[\\da-fA-F]{4}|[0-3]?[0-7]{1,2})',",
            "             String.Escape),",
            "            (r'[^\"\\\\]+', String.Double)",
            "        ],",
            "        'root': [",
            "            (r'\\n+', Text),",
            "            (r\"'\", String.Single, 'quote'),",
            "            include('default'),",
            "            (r'(%s)([ \\t\\r]*)(:)' % _name,",
            "             bygroups(Name.Label, Text, Punctuation)),",
            "            (_name, String.Other)",
            "        ],",
            "        'annotation': [",
            "            (r'\\n', Text, ('#pop', 'annotation-body')),",
            "            (r'default%s' % _break, Keyword.Reserved,",
            "             ('#pop', 'annotation-default')),",
            "            include('default')",
            "        ],",
            "        'annotation-body': [",
            "            (r'\\n+', Text),",
            "            (r'\\.end%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            (_name, String.Other, ('annotation-items', 'descriptor/no-dots'))",
            "        ],",
            "        'annotation-default': [",
            "            (r'\\n+', Text),",
            "            (r'\\.end%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            default(('annotation-items', 'descriptor/no-dots'))",
            "        ],",
            "        'annotation-items': [",
            "            (r\"'\", String.Single, 'quote'),",
            "            include('default'),",
            "            (_name, String.Other)",
            "        ],",
            "        'caught-exception': [",
            "            (r'all%s' % _break, Keyword, '#pop'),",
            "            include('exception')",
            "        ],",
            "        'class/convert-dots': [",
            "            include('default'),",
            "            (r'(L)((?:%s[/.])*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'((?:%s[/.])*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class), '#pop')",
            "        ],",
            "        'class/no-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation, ('#pop', 'descriptor/no-dots')),",
            "            (r'(L)((?:%s/)*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'((?:%s/)*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class), '#pop')",
            "        ],",
            "        'descriptor/convert-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation),",
            "            (r'(L)((?:%s[/.])*)(%s?)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'[^%s\\[)L]+' % _separator, Keyword.Type, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'descriptor/no-dots': [",
            "            include('default'),",
            "            (r'\\[+', Punctuation),",
            "            (r'(L)((?:%s/)*)(%s)(;)' % (_unqualified_name, _name),",
            "             bygroups(Keyword.Type, Name.Namespace, Name.Class, Punctuation),",
            "             '#pop'),",
            "            (r'[^%s\\[)L]+' % _separator, Keyword.Type, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'descriptors/convert-dots': [",
            "            (r'\\)', Punctuation, '#pop'),",
            "            default('descriptor/convert-dots')",
            "        ],",
            "        'enclosing-method': [",
            "            (_ws, Text),",
            "            (r'(?=[^%s]*\\()' % _separator, Text, ('#pop', 'invocation')),",
            "            default(('#pop', 'class/convert-dots'))",
            "        ],",
            "        'exception': [",
            "            include('default'),",
            "            (r'((?:%s[/.])*)(%s)' % (_unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Exception), '#pop')",
            "        ],",
            "        'field': [",
            "            (r'static%s' % _break, Keyword.Reserved, ('#pop', 'static')),",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s]*[/.]))*)(%s[/.])?(%s)' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Variable.Instance),",
            "             '#pop')",
            "        ],",
            "        'invocation': [",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s(]*[/.]))*)(%s[/.])?(%s)(\\()' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Function, Punctuation),",
            "             ('#pop', 'descriptor/convert-dots', 'descriptors/convert-dots',",
            "              'descriptor/convert-dots'))",
            "        ],",
            "        'label': [",
            "            include('default'),",
            "            (_name, Name.Label, '#pop')",
            "        ],",
            "        'method': [",
            "            include('default'),",
            "            (r'(%s)(\\()' % _name, bygroups(Name.Function, Punctuation),",
            "             ('#pop', 'descriptor/convert-dots', 'descriptors/convert-dots',",
            "              'descriptor/convert-dots'))",
            "        ],",
            "        'no-verification': [",
            "            (r'(locals|method|stack)%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default')",
            "        ],",
            "        'static': [",
            "            include('default'),",
            "            (r'((?:%s[/.](?=[^%s]*[/.]))*)(%s[/.])?(%s)' %",
            "             (_unqualified_name, _separator, _unqualified_name, _name),",
            "             bygroups(Name.Namespace, Name.Class, Name.Variable.Class), '#pop')",
            "        ],",
            "        'table': [",
            "            (r'\\n+', Text),",
            "            (r'default%s' % _break, Keyword.Reserved, '#pop'),",
            "            include('default'),",
            "            (_name, Name.Label)",
            "        ],",
            "        'var': [",
            "            include('default'),",
            "            (_name, Name.Variable, '#pop')",
            "        ],",
            "        'verification': [",
            "            include('default'),",
            "            (r'(Double|Float|Integer|Long|Null|Top|UninitializedThis)%s' %",
            "             _break, Keyword, '#pop'),",
            "            (r'Object%s' % _break, Keyword, ('#pop', 'class/no-dots')),",
            "            (r'Uninitialized%s' % _break, Keyword, ('#pop', 'label'))",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        score = 0",
            "        if re.search(r'^\\s*\\.class\\s', text, re.MULTILINE):",
            "            score += 0.5",
            "            if re.search(r'^\\s*[a-z]+_[a-z]+\\b', text, re.MULTILINE):",
            "                score += 0.3",
            "        if re.search(r'^\\s*\\.(attribute|bytecode|debug|deprecated|enclosing|'",
            "                     r'inner|interface|limit|set|signature|stack)\\b', text,",
            "                     re.MULTILINE):",
            "            score += 0.6",
            "        return score",
            "",
            "",
            "class SarlLexer(RegexLexer):",
            "    \"\"\"",
            "    For `SARL <http://www.sarl.io>`_ source code.",
            "",
            "    .. versionadded:: 2.4",
            "    \"\"\"",
            "",
            "    name = 'SARL'",
            "    aliases = ['sarl']",
            "    filenames = ['*.sarl']",
            "    mimetypes = ['text/x-sarl']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            # method names",
            "            (r'^(\\s*(?:[a-zA-Z_][\\w.\\[\\]]*\\s+)+?)'  # return arguments",
            "             r'([a-zA-Z_$][\\w$]*)'                      # method name",
            "             r'(\\s*)(\\()',                             # signature start",
            "             bygroups(using(this), Name.Function, Text, Operator)),",
            "            (r'[^\\S\\n]+', Text),",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*.*?\\*/', Comment.Multiline),",
            "            (r'@[a-zA-Z_][\\w.]*', Name.Decorator),",
            "            (r'(as|break|case|catch|default|do|else|extends|extension|finally|'",
            "             r'fires|for|if|implements|instanceof|new|on|requires|return|super|'",
            "             r'switch|throw|throws|try|typeof|uses|while|with)\\b',",
            "             Keyword),",
            "            (r'(abstract|def|dispatch|final|native|override|private|protected|'",
            "             r'public|static|strictfp|synchronized|transient|val|var|volatile)\\b',",
            "             Keyword.Declaration),",
            "            (r'(boolean|byte|char|double|float|int|long|short|void)\\b',",
            "             Keyword.Type),",
            "            (r'(package)(\\s+)', bygroups(Keyword.Namespace, Text)),",
            "            (r'(false|it|null|occurrence|this|true|void)\\b', Keyword.Constant),",
            "            (r'(agent|annotation|artifact|behavior|capacity|class|enum|event|'",
            "             r'interface|skill|space)(\\s+)', bygroups(Keyword.Declaration, Text),",
            "             'class'),",
            "            (r'(import)(\\s+)', bygroups(Keyword.Namespace, Text), 'import'),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*:', Name.Label),",
            "            (r'[a-zA-Z_$]\\w*', Name),",
            "            (r'[~^*!%&\\[\\](){}<>\\|+=:;,./?-]', Operator),",
            "            (r'[0-9][0-9]*\\.[0-9]+([eE][0-9]+)?[fd]?', Number.Float),",
            "            (r'0x[0-9a-fA-F]+', Number.Hex),",
            "            (r'[0-9]+L?', Number.Integer),",
            "            (r'\\n', Text)",
            "        ],",
            "        'class': [",
            "            (r'[a-zA-Z_]\\w*', Name.Class, '#pop')",
            "        ],",
            "        'import': [",
            "            (r'[\\w.]+\\*?', Name.Namespace, '#pop')",
            "        ],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "984": [
                "CeylonLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/matlab.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "             (r'.', Comment.Multiline),"
            },
            "1": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "         ],"
            },
            "2": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "         'deffunc': ["
            },
            "3": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "5": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "              bygroups(Whitespace, Text, Whitespace, Punctuation,"
            },
            "6": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "                       Whitespace, Name.Function, Punctuation, Text,"
            },
            "7": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "                       Punctuation, Whitespace), '#pop'),"
            },
            "8": {
                "beforePatchRowNumber": 638,
                "afterPatchRowNumber": 638,
                "PatchRowcode": "             (r\"[^']*'\", String, '#pop'),"
            },
            "9": {
                "beforePatchRowNumber": 639,
                "afterPatchRowNumber": 639,
                "PatchRowcode": "         ],"
            },
            "10": {
                "beforePatchRowNumber": 640,
                "afterPatchRowNumber": 640,
                "PatchRowcode": "         'deffunc': ["
            },
            "11": {
                "beforePatchRowNumber": 641,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 641,
                "PatchRowcode": "+            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "13": {
                "beforePatchRowNumber": 642,
                "afterPatchRowNumber": 642,
                "PatchRowcode": "              bygroups(Whitespace, Text, Whitespace, Punctuation,"
            },
            "14": {
                "beforePatchRowNumber": 643,
                "afterPatchRowNumber": 643,
                "PatchRowcode": "                       Whitespace, Name.Function, Punctuation, Text,"
            },
            "15": {
                "beforePatchRowNumber": 644,
                "afterPatchRowNumber": 644,
                "PatchRowcode": "                       Punctuation, Whitespace), '#pop'),"
            },
            "16": {
                "beforePatchRowNumber": 710,
                "afterPatchRowNumber": 710,
                "PatchRowcode": "             (r'.', String, '#pop'),"
            },
            "17": {
                "beforePatchRowNumber": 711,
                "afterPatchRowNumber": 711,
                "PatchRowcode": "         ],"
            },
            "18": {
                "beforePatchRowNumber": 712,
                "afterPatchRowNumber": 712,
                "PatchRowcode": "         'deffunc': ["
            },
            "19": {
                "beforePatchRowNumber": 713,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 713,
                "PatchRowcode": "+            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',"
            },
            "21": {
                "beforePatchRowNumber": 714,
                "afterPatchRowNumber": 714,
                "PatchRowcode": "              bygroups(Whitespace, Text, Whitespace, Punctuation,"
            },
            "22": {
                "beforePatchRowNumber": 715,
                "afterPatchRowNumber": 715,
                "PatchRowcode": "                       Whitespace, Name.Function, Punctuation, Text,"
            },
            "23": {
                "beforePatchRowNumber": 716,
                "afterPatchRowNumber": 716,
                "PatchRowcode": "                       Punctuation, Whitespace), '#pop'),"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.matlab",
            "    ~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Matlab and related languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import Lexer, RegexLexer, bygroups, default, words, \\",
            "    do_insertions",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation, Generic, Whitespace",
            "",
            "from pygments.lexers import _scilab_builtins",
            "",
            "__all__ = ['MatlabLexer', 'MatlabSessionLexer', 'OctaveLexer', 'ScilabLexer']",
            "",
            "",
            "class MatlabLexer(RegexLexer):",
            "    \"\"\"",
            "    For Matlab source code.",
            "",
            "    .. versionadded:: 0.10",
            "    \"\"\"",
            "    name = 'Matlab'",
            "    aliases = ['matlab']",
            "    filenames = ['*.m']",
            "    mimetypes = ['text/matlab']",
            "",
            "    #",
            "    # These lists are generated automatically.",
            "    # Run the following in bash shell:",
            "    #",
            "    # for f in elfun specfun elmat; do",
            "    #   echo -n \"$f = \"",
            "    #   matlab -nojvm -r \"help $f;exit;\" | perl -ne \\",
            "    #   'push(@c,$1) if /^    (\\w+)\\s+-/; END {print q{[\"}.join(q{\",\"},@c).qq{\"]\\n};}'",
            "    # done",
            "    #",
            "    # elfun: Elementary math functions",
            "    # specfun: Special Math functions",
            "    # elmat: Elementary matrices and matrix manipulation",
            "    #",
            "    # taken from Matlab version 9.4 (R2018a)",
            "    #",
            "    elfun = (\"sin\", \"sind\", \"sinh\", \"asin\", \"asind\", \"asinh\", \"cos\", \"cosd\", \"cosh\",",
            "             \"acos\", \"acosd\", \"acosh\", \"tan\", \"tand\", \"tanh\", \"atan\", \"atand\", \"atan2\",",
            "             \"atan2d\", \"atanh\", \"sec\", \"secd\", \"sech\", \"asec\", \"asecd\", \"asech\", \"csc\", \"cscd\",",
            "             \"csch\", \"acsc\", \"acscd\", \"acsch\", \"cot\", \"cotd\", \"coth\", \"acot\", \"acotd\",",
            "             \"acoth\", \"hypot\", \"deg2rad\", \"rad2deg\", \"exp\", \"expm1\", \"log\", \"log1p\", \"log10\", \"log2\", \"pow2\",",
            "             \"realpow\", \"reallog\", \"realsqrt\", \"sqrt\", \"nthroot\", \"nextpow2\", \"abs\",",
            "             \"angle\", \"complex\", \"conj\", \"imag\", \"real\", \"unwrap\", \"isreal\", \"cplxpair\",",
            "             \"fix\", \"floor\", \"ceil\", \"round\", \"mod\", \"rem\", \"sign\")",
            "    specfun = (\"airy\", \"besselj\", \"bessely\", \"besselh\", \"besseli\", \"besselk\", \"beta\",",
            "               \"betainc\", \"betaincinv\", \"betaln\", \"ellipj\", \"ellipke\", \"erf\", \"erfc\", \"erfcx\",",
            "               \"erfinv\", \"erfcinv\", \"expint\", \"gamma\", \"gammainc\", \"gammaincinv\", \"gammaln\", \"psi\", \"legendre\",",
            "               \"cross\", \"dot\", \"factor\", \"isprime\", \"primes\", \"gcd\", \"lcm\", \"rat\",",
            "               \"rats\", \"perms\", \"nchoosek\", \"factorial\", \"cart2sph\", \"cart2pol\",",
            "               \"pol2cart\", \"sph2cart\", \"hsv2rgb\", \"rgb2hsv\")",
            "    elmat = (\"zeros\", \"ones\", \"eye\", \"repmat\", \"repelem\", \"linspace\", \"logspace\",",
            "             \"freqspace\", \"meshgrid\", \"accumarray\", \"size\", \"length\", \"ndims\", \"numel\",",
            "             \"disp\", \"isempty\", \"isequal\", \"isequaln\", \"cat\", \"reshape\",",
            "             \"diag\", \"blkdiag\", \"tril\", \"triu\", \"fliplr\", \"flipud\", \"flip\", \"rot90\",",
            "             \"find\", \"end\", \"sub2ind\", \"ind2sub\", \"bsxfun\", \"ndgrid\", \"permute\",",
            "             \"ipermute\", \"shiftdim\", \"circshift\", \"squeeze\", \"isscalar\", \"isvector\",",
            "             \"isrow\", \"iscolumn\", \"ismatrix\", \"eps\", \"realmax\", \"realmin\", \"intmax\", \"intmin\", \"flintmax\", \"pi\", \"i\", \"inf\", \"nan\", \"isnan\",",
            "             \"isinf\", \"isfinite\", \"j\", \"true\", \"false\", \"compan\", \"gallery\", \"hadamard\", \"hankel\",",
            "             \"hilb\", \"invhilb\", \"magic\", \"pascal\", \"rosser\", \"toeplitz\", \"vander\",",
            "             \"wilkinson\")",
            "",
            "    _operators = r'-|==|~=|<=|>=|<|>|&&|&|~|\\|\\|?|\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\./|/|\\\\'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # line starting with '!' is sent as a system command.  not sure what",
            "            # label to use...",
            "            (r'^!.*', String.Other),",
            "            (r'%\\{\\s*\\n', Comment.Multiline, 'blockcomment'),",
            "            (r'%.*$', Comment),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            # from 'iskeyword' on version 9.4 (R2018a):",
            "            # Check that there is no preceding dot, as keywords are valid field",
            "            # names.",
            "            (words(('break', 'case', 'catch', 'classdef', 'continue', 'else',",
            "                    'elseif', 'end', 'for', 'function',",
            "                    'global', 'if', 'otherwise', 'parfor',",
            "                    'persistent', 'return', 'spmd', 'switch',",
            "                    'try', 'while'),",
            "                   prefix=r'(?<!\\.)', suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (\"(\" + \"|\".join(elfun + specfun + elmat) + r')\\b',  Name.Builtin),",
            "",
            "            # line continuation with following comment:",
            "            (r'(\\.\\.\\.)(.*)$', bygroups(Keyword, Comment)),",
            "",
            "            # command form:",
            "            # \"How MATLAB Recognizes Command Syntax\" specifies that an operator",
            "            # is recognized if it is either surrounded by spaces or by no",
            "            # spaces on both sides; only the former case matters for us.  (This",
            "            # allows distinguishing `cd ./foo` from `cd ./ foo`.)",
            "            (r'(?:^|(?<=;))(\\s*)(\\w+)(\\s+)(?!=|\\(|(?:%s)\\s+)' % _operators,",
            "             bygroups(Text, Name, Text), 'commandargs'),",
            "",
            "            # operators:",
            "            (_operators, Operator),",
            "",
            "            # numbers (must come before punctuation to handle `.5`; cannot use",
            "            # `\\b` due to e.g. `5. + .5`).",
            "            (r'(?<!\\w)((\\d+\\.\\d*)|(\\d*\\.\\d+))([eEf][+-]?\\d+)?(?!\\w)', Number.Float),",
            "            (r'\\b\\d+[eEf][+-]?[0-9]+\\b', Number.Float),",
            "            (r'\\b\\d+\\b', Number.Integer),",
            "",
            "            # punctuation:",
            "            (r'\\[|\\]|\\(|\\)|\\{|\\}|:|@|\\.|,', Punctuation),",
            "            (r'=|:|;', Punctuation),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "",
            "            (r'\"(\"\"|[^\"])*\"', String),",
            "",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'blockcomment': [",
            "            (r'^\\s*%\\}', Comment.Multiline, '#pop'),",
            "            (r'^.*\\n', Comment.Multiline),",
            "            (r'.', Comment.Multiline),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "        ],",
            "        'commandargs': [",
            "            # If an equal sign or other operator is encountered, this",
            "            # isn't a command. It might be a variable assignment or",
            "            # comparison operation with multiple spaces before the",
            "            # equal sign or operator",
            "            (r\"=\", Punctuation, '#pop'),",
            "            (_operators, Operator, '#pop'),",
            "            (r\"[ \\t]+\", Text),",
            "            (\"'[^']*'\", String),",
            "            (r\"[^';\\s]+\", String),",
            "            (\";\", Punctuation, '#pop'),",
            "            default('#pop'),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        # function declaration.",
            "        first_non_comment = next((line for line in text.splitlines()",
            "                                  if not re.match(r'^\\s*%', text)), '').strip()",
            "        if (first_non_comment.startswith('function')",
            "                and '{' not in first_non_comment):",
            "            return 1.",
            "        # comment",
            "        elif re.search(r'^\\s*%', text, re.M):",
            "            return 0.2",
            "        # system cmd",
            "        elif re.search(r'^!\\w+', text, re.M):",
            "            return 0.2",
            "",
            "",
            "line_re  = re.compile('.*?\\n')",
            "",
            "",
            "class MatlabSessionLexer(Lexer):",
            "    \"\"\"",
            "    For Matlab sessions.  Modeled after PythonConsoleLexer.",
            "    Contributed by Ken Schutte <kschutte@csail.mit.edu>.",
            "",
            "    .. versionadded:: 0.10",
            "    \"\"\"",
            "    name = 'Matlab session'",
            "    aliases = ['matlabsession']",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        mlexer = MatlabLexer(**self.options)",
            "",
            "        curcode = ''",
            "        insertions = []",
            "        continuation = False",
            "",
            "        for match in line_re.finditer(text):",
            "            line = match.group()",
            "",
            "            if line.startswith('>> '):",
            "                insertions.append((len(curcode),",
            "                                   [(0, Generic.Prompt, line[:3])]))",
            "                curcode += line[3:]",
            "",
            "            elif line.startswith('>>'):",
            "                insertions.append((len(curcode),",
            "                                   [(0, Generic.Prompt, line[:2])]))",
            "                curcode += line[2:]",
            "",
            "            elif line.startswith('???'):",
            "",
            "                idx = len(curcode)",
            "",
            "                # without is showing error on same line as before...?",
            "                # line = \"\\n\" + line",
            "                token = (0, Generic.Traceback, line)",
            "                insertions.append((idx, [token]))",
            "            elif continuation:",
            "                # line_start is the length of the most recent prompt symbol",
            "                line_start = len(insertions[-1][-1][-1])",
            "                # Set leading spaces with the length of the prompt to be a generic prompt",
            "                # This keeps code aligned when prompts are removed, say with some Javascript",
            "                if line.startswith(' '*line_start):",
            "                    insertions.append((len(curcode),",
            "                                    [(0, Generic.Prompt, line[:line_start])]))",
            "                    curcode += line[line_start:]",
            "                else:",
            "                    curcode += line",
            "            else:",
            "                if curcode:",
            "                    yield from do_insertions(",
            "                        insertions, mlexer.get_tokens_unprocessed(curcode))",
            "                    curcode = ''",
            "                    insertions = []",
            "",
            "                yield match.start(), Generic.Output, line",
            "",
            "            # Does not allow continuation if a comment is included after the ellipses.",
            "            # Continues any line that ends with ..., even comments (lines that start with %)",
            "            if line.strip().endswith('...'):",
            "                continuation = True",
            "            else:",
            "                continuation = False",
            "",
            "        if curcode:  # or item:",
            "            yield from do_insertions(",
            "                insertions, mlexer.get_tokens_unprocessed(curcode))",
            "",
            "",
            "class OctaveLexer(RegexLexer):",
            "    \"\"\"",
            "    For GNU Octave source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Octave'",
            "    aliases = ['octave']",
            "    filenames = ['*.m']",
            "    mimetypes = ['text/octave']",
            "",
            "    # These lists are generated automatically.",
            "    # Run the following in bash shell:",
            "    #",
            "    # First dump all of the Octave manual into a plain text file:",
            "    #",
            "    #   $ info octave --subnodes -o octave-manual",
            "    #",
            "    # Now grep through it:",
            "",
            "    # for i in \\",
            "    #     \"Built-in Function\" \"Command\" \"Function File\" \\",
            "    #     \"Loadable Function\" \"Mapping Function\";",
            "    # do",
            "    #     perl -e '@name = qw('\"$i\"');",
            "    #              print lc($name[0]),\"_kw = [\\n\"';",
            "    #",
            "    #     perl -n -e 'print \"\\\"$1\\\",\\n\" if /-- '\"$i\"': .* (\\w*) \\(/;' \\",
            "    #         octave-manual | sort | uniq ;",
            "    #     echo \"]\" ;",
            "    #     echo;",
            "    # done",
            "",
            "    # taken from Octave Mercurial changeset 8cc154f45e37 (30-jan-2011)",
            "",
            "    builtin_kw = (",
            "        \"addlistener\", \"addpath\", \"addproperty\", \"all\",",
            "        \"and\", \"any\", \"argnames\", \"argv\", \"assignin\",",
            "        \"atexit\", \"autoload\",",
            "        \"available_graphics_toolkits\", \"beep_on_error\",",
            "        \"bitand\", \"bitmax\", \"bitor\", \"bitshift\", \"bitxor\",",
            "        \"cat\", \"cell\", \"cellstr\", \"char\", \"class\", \"clc\",",
            "        \"columns\", \"command_line_path\",",
            "        \"completion_append_char\", \"completion_matches\",",
            "        \"complex\", \"confirm_recursive_rmdir\", \"cputime\",",
            "        \"crash_dumps_octave_core\", \"ctranspose\", \"cumprod\",",
            "        \"cumsum\", \"debug_on_error\", \"debug_on_interrupt\",",
            "        \"debug_on_warning\", \"default_save_options\",",
            "        \"dellistener\", \"diag\", \"diff\", \"disp\",",
            "        \"doc_cache_file\", \"do_string_escapes\", \"double\",",
            "        \"drawnow\", \"e\", \"echo_executing_commands\", \"eps\",",
            "        \"eq\", \"errno\", \"errno_list\", \"error\", \"eval\",",
            "        \"evalin\", \"exec\", \"exist\", \"exit\", \"eye\", \"false\",",
            "        \"fclear\", \"fclose\", \"fcntl\", \"fdisp\", \"feof\",",
            "        \"ferror\", \"feval\", \"fflush\", \"fgetl\", \"fgets\",",
            "        \"fieldnames\", \"file_in_loadpath\", \"file_in_path\",",
            "        \"filemarker\", \"filesep\", \"find_dir_in_path\",",
            "        \"fixed_point_format\", \"fnmatch\", \"fopen\", \"fork\",",
            "        \"formula\", \"fprintf\", \"fputs\", \"fread\", \"freport\",",
            "        \"frewind\", \"fscanf\", \"fseek\", \"fskipl\", \"ftell\",",
            "        \"functions\", \"fwrite\", \"ge\", \"genpath\", \"get\",",
            "        \"getegid\", \"getenv\", \"geteuid\", \"getgid\",",
            "        \"getpgrp\", \"getpid\", \"getppid\", \"getuid\", \"glob\",",
            "        \"gt\", \"gui_mode\", \"history_control\",",
            "        \"history_file\", \"history_size\",",
            "        \"history_timestamp_format_string\", \"home\",",
            "        \"horzcat\", \"hypot\", \"ifelse\",",
            "        \"ignore_function_time_stamp\", \"inferiorto\",",
            "        \"info_file\", \"info_program\", \"inline\", \"input\",",
            "        \"intmax\", \"intmin\", \"ipermute\",",
            "        \"is_absolute_filename\", \"isargout\", \"isbool\",",
            "        \"iscell\", \"iscellstr\", \"ischar\", \"iscomplex\",",
            "        \"isempty\", \"isfield\", \"isfloat\", \"isglobal\",",
            "        \"ishandle\", \"isieee\", \"isindex\", \"isinteger\",",
            "        \"islogical\", \"ismatrix\", \"ismethod\", \"isnull\",",
            "        \"isnumeric\", \"isobject\", \"isreal\",",
            "        \"is_rooted_relative_filename\", \"issorted\",",
            "        \"isstruct\", \"isvarname\", \"kbhit\", \"keyboard\",",
            "        \"kill\", \"lasterr\", \"lasterror\", \"lastwarn\",",
            "        \"ldivide\", \"le\", \"length\", \"link\", \"linspace\",",
            "        \"logical\", \"lstat\", \"lt\", \"make_absolute_filename\",",
            "        \"makeinfo_program\", \"max_recursion_depth\", \"merge\",",
            "        \"methods\", \"mfilename\", \"minus\", \"mislocked\",",
            "        \"mkdir\", \"mkfifo\", \"mkstemp\", \"mldivide\", \"mlock\",",
            "        \"mouse_wheel_zoom\", \"mpower\", \"mrdivide\", \"mtimes\",",
            "        \"munlock\", \"nargin\", \"nargout\",",
            "        \"native_float_format\", \"ndims\", \"ne\", \"nfields\",",
            "        \"nnz\", \"norm\", \"not\", \"numel\", \"nzmax\",",
            "        \"octave_config_info\", \"octave_core_file_limit\",",
            "        \"octave_core_file_name\",",
            "        \"octave_core_file_options\", \"ones\", \"or\",",
            "        \"output_max_field_width\", \"output_precision\",",
            "        \"page_output_immediately\", \"page_screen_output\",",
            "        \"path\", \"pathsep\", \"pause\", \"pclose\", \"permute\",",
            "        \"pi\", \"pipe\", \"plus\", \"popen\", \"power\",",
            "        \"print_empty_dimensions\", \"printf\",",
            "        \"print_struct_array_contents\", \"prod\",",
            "        \"program_invocation_name\", \"program_name\",",
            "        \"putenv\", \"puts\", \"pwd\", \"quit\", \"rats\", \"rdivide\",",
            "        \"readdir\", \"readlink\", \"read_readline_init_file\",",
            "        \"realmax\", \"realmin\", \"rehash\", \"rename\",",
            "        \"repelems\", \"re_read_readline_init_file\", \"reset\",",
            "        \"reshape\", \"resize\", \"restoredefaultpath\",",
            "        \"rethrow\", \"rmdir\", \"rmfield\", \"rmpath\", \"rows\",",
            "        \"save_header_format_string\", \"save_precision\",",
            "        \"saving_history\", \"scanf\", \"set\", \"setenv\",",
            "        \"shell_cmd\", \"sighup_dumps_octave_core\",",
            "        \"sigterm_dumps_octave_core\", \"silent_functions\",",
            "        \"single\", \"size\", \"size_equal\", \"sizemax\",",
            "        \"sizeof\", \"sleep\", \"source\", \"sparse_auto_mutate\",",
            "        \"split_long_rows\", \"sprintf\", \"squeeze\", \"sscanf\",",
            "        \"stat\", \"stderr\", \"stdin\", \"stdout\", \"strcmp\",",
            "        \"strcmpi\", \"string_fill_char\", \"strncmp\",",
            "        \"strncmpi\", \"struct\", \"struct_levels_to_print\",",
            "        \"strvcat\", \"subsasgn\", \"subsref\", \"sum\", \"sumsq\",",
            "        \"superiorto\", \"suppress_verbose_help_message\",",
            "        \"symlink\", \"system\", \"tic\", \"tilde_expand\",",
            "        \"times\", \"tmpfile\", \"tmpnam\", \"toc\", \"toupper\",",
            "        \"transpose\", \"true\", \"typeinfo\", \"umask\", \"uminus\",",
            "        \"uname\", \"undo_string_escapes\", \"unlink\", \"uplus\",",
            "        \"upper\", \"usage\", \"usleep\", \"vec\", \"vectorize\",",
            "        \"vertcat\", \"waitpid\", \"warning\", \"warranty\",",
            "        \"whos_line_format\", \"yes_or_no\", \"zeros\",",
            "        \"inf\", \"Inf\", \"nan\", \"NaN\")",
            "",
            "    command_kw = (\"close\", \"load\", \"who\", \"whos\")",
            "",
            "    function_kw = (",
            "        \"accumarray\", \"accumdim\", \"acosd\", \"acotd\",",
            "        \"acscd\", \"addtodate\", \"allchild\", \"ancestor\",",
            "        \"anova\", \"arch_fit\", \"arch_rnd\", \"arch_test\",",
            "        \"area\", \"arma_rnd\", \"arrayfun\", \"ascii\", \"asctime\",",
            "        \"asecd\", \"asind\", \"assert\", \"atand\",",
            "        \"autoreg_matrix\", \"autumn\", \"axes\", \"axis\", \"bar\",",
            "        \"barh\", \"bartlett\", \"bartlett_test\", \"beep\",",
            "        \"betacdf\", \"betainv\", \"betapdf\", \"betarnd\",",
            "        \"bicgstab\", \"bicubic\", \"binary\", \"binocdf\",",
            "        \"binoinv\", \"binopdf\", \"binornd\", \"bitcmp\",",
            "        \"bitget\", \"bitset\", \"blackman\", \"blanks\",",
            "        \"blkdiag\", \"bone\", \"box\", \"brighten\", \"calendar\",",
            "        \"cast\", \"cauchy_cdf\", \"cauchy_inv\", \"cauchy_pdf\",",
            "        \"cauchy_rnd\", \"caxis\", \"celldisp\", \"center\", \"cgs\",",
            "        \"chisquare_test_homogeneity\",",
            "        \"chisquare_test_independence\", \"circshift\", \"cla\",",
            "        \"clabel\", \"clf\", \"clock\", \"cloglog\", \"closereq\",",
            "        \"colon\", \"colorbar\", \"colormap\", \"colperm\",",
            "        \"comet\", \"common_size\", \"commutation_matrix\",",
            "        \"compan\", \"compare_versions\", \"compass\",",
            "        \"computer\", \"cond\", \"condest\", \"contour\",",
            "        \"contourc\", \"contourf\", \"contrast\", \"conv\",",
            "        \"convhull\", \"cool\", \"copper\", \"copyfile\", \"cor\",",
            "        \"corrcoef\", \"cor_test\", \"cosd\", \"cotd\", \"cov\",",
            "        \"cplxpair\", \"cross\", \"cscd\", \"cstrcat\", \"csvread\",",
            "        \"csvwrite\", \"ctime\", \"cumtrapz\", \"curl\", \"cut\",",
            "        \"cylinder\", \"date\", \"datenum\", \"datestr\",",
            "        \"datetick\", \"datevec\", \"dblquad\", \"deal\",",
            "        \"deblank\", \"deconv\", \"delaunay\", \"delaunayn\",",
            "        \"delete\", \"demo\", \"detrend\", \"diffpara\", \"diffuse\",",
            "        \"dir\", \"discrete_cdf\", \"discrete_inv\",",
            "        \"discrete_pdf\", \"discrete_rnd\", \"display\",",
            "        \"divergence\", \"dlmwrite\", \"dos\", \"dsearch\",",
            "        \"dsearchn\", \"duplication_matrix\", \"durbinlevinson\",",
            "        \"ellipsoid\", \"empirical_cdf\", \"empirical_inv\",",
            "        \"empirical_pdf\", \"empirical_rnd\", \"eomday\",",
            "        \"errorbar\", \"etime\", \"etreeplot\", \"example\",",
            "        \"expcdf\", \"expinv\", \"expm\", \"exppdf\", \"exprnd\",",
            "        \"ezcontour\", \"ezcontourf\", \"ezmesh\", \"ezmeshc\",",
            "        \"ezplot\", \"ezpolar\", \"ezsurf\", \"ezsurfc\", \"factor\",",
            "        \"factorial\", \"fail\", \"fcdf\", \"feather\", \"fftconv\",",
            "        \"fftfilt\", \"fftshift\", \"figure\", \"fileattrib\",",
            "        \"fileparts\", \"fill\", \"findall\", \"findobj\",",
            "        \"findstr\", \"finv\", \"flag\", \"flipdim\", \"fliplr\",",
            "        \"flipud\", \"fpdf\", \"fplot\", \"fractdiff\", \"freqz\",",
            "        \"freqz_plot\", \"frnd\", \"fsolve\",",
            "        \"f_test_regression\", \"ftp\", \"fullfile\", \"fzero\",",
            "        \"gamcdf\", \"gaminv\", \"gampdf\", \"gamrnd\", \"gca\",",
            "        \"gcbf\", \"gcbo\", \"gcf\", \"genvarname\", \"geocdf\",",
            "        \"geoinv\", \"geopdf\", \"geornd\", \"getfield\", \"ginput\",",
            "        \"glpk\", \"gls\", \"gplot\", \"gradient\",",
            "        \"graphics_toolkit\", \"gray\", \"grid\", \"griddata\",",
            "        \"griddatan\", \"gtext\", \"gunzip\", \"gzip\", \"hadamard\",",
            "        \"hamming\", \"hankel\", \"hanning\", \"hggroup\",",
            "        \"hidden\", \"hilb\", \"hist\", \"histc\", \"hold\", \"hot\",",
            "        \"hotelling_test\", \"housh\", \"hsv\", \"hurst\",",
            "        \"hygecdf\", \"hygeinv\", \"hygepdf\", \"hygernd\",",
            "        \"idivide\", \"ifftshift\", \"image\", \"imagesc\",",
            "        \"imfinfo\", \"imread\", \"imshow\", \"imwrite\", \"index\",",
            "        \"info\", \"inpolygon\", \"inputname\", \"interpft\",",
            "        \"interpn\", \"intersect\", \"invhilb\", \"iqr\", \"isa\",",
            "        \"isdefinite\", \"isdir\", \"is_duplicate_entry\",",
            "        \"isequal\", \"isequalwithequalnans\", \"isfigure\",",
            "        \"ishermitian\", \"ishghandle\", \"is_leap_year\",",
            "        \"isletter\", \"ismac\", \"ismember\", \"ispc\", \"isprime\",",
            "        \"isprop\", \"isscalar\", \"issquare\", \"isstrprop\",",
            "        \"issymmetric\", \"isunix\", \"is_valid_file_id\",",
            "        \"isvector\", \"jet\", \"kendall\",",
            "        \"kolmogorov_smirnov_cdf\",",
            "        \"kolmogorov_smirnov_test\", \"kruskal_wallis_test\",",
            "        \"krylov\", \"kurtosis\", \"laplace_cdf\", \"laplace_inv\",",
            "        \"laplace_pdf\", \"laplace_rnd\", \"legend\", \"legendre\",",
            "        \"license\", \"line\", \"linkprop\", \"list_primes\",",
            "        \"loadaudio\", \"loadobj\", \"logistic_cdf\",",
            "        \"logistic_inv\", \"logistic_pdf\", \"logistic_rnd\",",
            "        \"logit\", \"loglog\", \"loglogerr\", \"logm\", \"logncdf\",",
            "        \"logninv\", \"lognpdf\", \"lognrnd\", \"logspace\",",
            "        \"lookfor\", \"ls_command\", \"lsqnonneg\", \"magic\",",
            "        \"mahalanobis\", \"manova\", \"matlabroot\",",
            "        \"mcnemar_test\", \"mean\", \"meansq\", \"median\", \"menu\",",
            "        \"mesh\", \"meshc\", \"meshgrid\", \"meshz\", \"mexext\",",
            "        \"mget\", \"mkpp\", \"mode\", \"moment\", \"movefile\",",
            "        \"mpoles\", \"mput\", \"namelengthmax\", \"nargchk\",",
            "        \"nargoutchk\", \"nbincdf\", \"nbininv\", \"nbinpdf\",",
            "        \"nbinrnd\", \"nchoosek\", \"ndgrid\", \"newplot\", \"news\",",
            "        \"nonzeros\", \"normcdf\", \"normest\", \"norminv\",",
            "        \"normpdf\", \"normrnd\", \"now\", \"nthroot\", \"null\",",
            "        \"ocean\", \"ols\", \"onenormest\", \"optimget\",",
            "        \"optimset\", \"orderfields\", \"orient\", \"orth\",",
            "        \"pack\", \"pareto\", \"parseparams\", \"pascal\", \"patch\",",
            "        \"pathdef\", \"pcg\", \"pchip\", \"pcolor\", \"pcr\",",
            "        \"peaks\", \"periodogram\", \"perl\", \"perms\", \"pie\",",
            "        \"pink\", \"planerot\", \"playaudio\", \"plot\",",
            "        \"plotmatrix\", \"plotyy\", \"poisscdf\", \"poissinv\",",
            "        \"poisspdf\", \"poissrnd\", \"polar\", \"poly\",",
            "        \"polyaffine\", \"polyarea\", \"polyderiv\", \"polyfit\",",
            "        \"polygcd\", \"polyint\", \"polyout\", \"polyreduce\",",
            "        \"polyval\", \"polyvalm\", \"postpad\", \"powerset\",",
            "        \"ppder\", \"ppint\", \"ppjumps\", \"ppplot\", \"ppval\",",
            "        \"pqpnonneg\", \"prepad\", \"primes\", \"print\",",
            "        \"print_usage\", \"prism\", \"probit\", \"qp\", \"qqplot\",",
            "        \"quadcc\", \"quadgk\", \"quadl\", \"quadv\", \"quiver\",",
            "        \"qzhess\", \"rainbow\", \"randi\", \"range\", \"rank\",",
            "        \"ranks\", \"rat\", \"reallog\", \"realpow\", \"realsqrt\",",
            "        \"record\", \"rectangle_lw\", \"rectangle_sw\",",
            "        \"rectint\", \"refresh\", \"refreshdata\",",
            "        \"regexptranslate\", \"repmat\", \"residue\", \"ribbon\",",
            "        \"rindex\", \"roots\", \"rose\", \"rosser\", \"rotdim\",",
            "        \"rref\", \"run\", \"run_count\", \"rundemos\", \"run_test\",",
            "        \"runtests\", \"saveas\", \"saveaudio\", \"saveobj\",",
            "        \"savepath\", \"scatter\", \"secd\", \"semilogx\",",
            "        \"semilogxerr\", \"semilogy\", \"semilogyerr\",",
            "        \"setaudio\", \"setdiff\", \"setfield\", \"setxor\",",
            "        \"shading\", \"shift\", \"shiftdim\", \"sign_test\",",
            "        \"sinc\", \"sind\", \"sinetone\", \"sinewave\", \"skewness\",",
            "        \"slice\", \"sombrero\", \"sortrows\", \"spaugment\",",
            "        \"spconvert\", \"spdiags\", \"spearman\", \"spectral_adf\",",
            "        \"spectral_xdf\", \"specular\", \"speed\", \"spencer\",",
            "        \"speye\", \"spfun\", \"sphere\", \"spinmap\", \"spline\",",
            "        \"spones\", \"sprand\", \"sprandn\", \"sprandsym\",",
            "        \"spring\", \"spstats\", \"spy\", \"sqp\", \"stairs\",",
            "        \"statistics\", \"std\", \"stdnormal_cdf\",",
            "        \"stdnormal_inv\", \"stdnormal_pdf\", \"stdnormal_rnd\",",
            "        \"stem\", \"stft\", \"strcat\", \"strchr\", \"strjust\",",
            "        \"strmatch\", \"strread\", \"strsplit\", \"strtok\",",
            "        \"strtrim\", \"strtrunc\", \"structfun\", \"studentize\",",
            "        \"subplot\", \"subsindex\", \"subspace\", \"substr\",",
            "        \"substruct\", \"summer\", \"surf\", \"surface\", \"surfc\",",
            "        \"surfl\", \"surfnorm\", \"svds\", \"swapbytes\",",
            "        \"sylvester_matrix\", \"symvar\", \"synthesis\", \"table\",",
            "        \"tand\", \"tar\", \"tcdf\", \"tempdir\", \"tempname\",",
            "        \"test\", \"text\", \"textread\", \"textscan\", \"tinv\",",
            "        \"title\", \"toeplitz\", \"tpdf\", \"trace\", \"trapz\",",
            "        \"treelayout\", \"treeplot\", \"triangle_lw\",",
            "        \"triangle_sw\", \"tril\", \"trimesh\", \"triplequad\",",
            "        \"triplot\", \"trisurf\", \"triu\", \"trnd\", \"tsearchn\",",
            "        \"t_test\", \"t_test_regression\", \"type\", \"unidcdf\",",
            "        \"unidinv\", \"unidpdf\", \"unidrnd\", \"unifcdf\",",
            "        \"unifinv\", \"unifpdf\", \"unifrnd\", \"union\", \"unique\",",
            "        \"unix\", \"unmkpp\", \"unpack\", \"untabify\", \"untar\",",
            "        \"unwrap\", \"unzip\", \"u_test\", \"validatestring\",",
            "        \"vander\", \"var\", \"var_test\", \"vech\", \"ver\",",
            "        \"version\", \"view\", \"voronoi\", \"voronoin\",",
            "        \"waitforbuttonpress\", \"wavread\", \"wavwrite\",",
            "        \"wblcdf\", \"wblinv\", \"wblpdf\", \"wblrnd\", \"weekday\",",
            "        \"welch_test\", \"what\", \"white\", \"whitebg\",",
            "        \"wienrnd\", \"wilcoxon_test\", \"wilkinson\", \"winter\",",
            "        \"xlabel\", \"xlim\", \"ylabel\", \"yulewalker\", \"zip\",",
            "        \"zlabel\", \"z_test\")",
            "",
            "    loadable_kw = (",
            "        \"airy\", \"amd\", \"balance\", \"besselh\", \"besseli\",",
            "        \"besselj\", \"besselk\", \"bessely\", \"bitpack\",",
            "        \"bsxfun\", \"builtin\", \"ccolamd\", \"cellfun\",",
            "        \"cellslices\", \"chol\", \"choldelete\", \"cholinsert\",",
            "        \"cholinv\", \"cholshift\", \"cholupdate\", \"colamd\",",
            "        \"colloc\", \"convhulln\", \"convn\", \"csymamd\",",
            "        \"cummax\", \"cummin\", \"daspk\", \"daspk_options\",",
            "        \"dasrt\", \"dasrt_options\", \"dassl\", \"dassl_options\",",
            "        \"dbclear\", \"dbdown\", \"dbstack\", \"dbstatus\",",
            "        \"dbstop\", \"dbtype\", \"dbup\", \"dbwhere\", \"det\",",
            "        \"dlmread\", \"dmperm\", \"dot\", \"eig\", \"eigs\",",
            "        \"endgrent\", \"endpwent\", \"etree\", \"fft\", \"fftn\",",
            "        \"fftw\", \"filter\", \"find\", \"full\", \"gcd\",",
            "        \"getgrent\", \"getgrgid\", \"getgrnam\", \"getpwent\",",
            "        \"getpwnam\", \"getpwuid\", \"getrusage\", \"givens\",",
            "        \"gmtime\", \"gnuplot_binary\", \"hess\", \"ifft\",",
            "        \"ifftn\", \"inv\", \"isdebugmode\", \"issparse\", \"kron\",",
            "        \"localtime\", \"lookup\", \"lsode\", \"lsode_options\",",
            "        \"lu\", \"luinc\", \"luupdate\", \"matrix_type\", \"max\",",
            "        \"min\", \"mktime\", \"pinv\", \"qr\", \"qrdelete\",",
            "        \"qrinsert\", \"qrshift\", \"qrupdate\", \"quad\",",
            "        \"quad_options\", \"qz\", \"rand\", \"rande\", \"randg\",",
            "        \"randn\", \"randp\", \"randperm\", \"rcond\", \"regexp\",",
            "        \"regexpi\", \"regexprep\", \"schur\", \"setgrent\",",
            "        \"setpwent\", \"sort\", \"spalloc\", \"sparse\", \"spparms\",",
            "        \"sprank\", \"sqrtm\", \"strfind\", \"strftime\",",
            "        \"strptime\", \"strrep\", \"svd\", \"svd_driver\", \"syl\",",
            "        \"symamd\", \"symbfact\", \"symrcm\", \"time\", \"tsearch\",",
            "        \"typecast\", \"urlread\", \"urlwrite\")",
            "",
            "    mapping_kw = (",
            "        \"abs\", \"acos\", \"acosh\", \"acot\", \"acoth\", \"acsc\",",
            "        \"acsch\", \"angle\", \"arg\", \"asec\", \"asech\", \"asin\",",
            "        \"asinh\", \"atan\", \"atanh\", \"beta\", \"betainc\",",
            "        \"betaln\", \"bincoeff\", \"cbrt\", \"ceil\", \"conj\", \"cos\",",
            "        \"cosh\", \"cot\", \"coth\", \"csc\", \"csch\", \"erf\", \"erfc\",",
            "        \"erfcx\", \"erfinv\", \"exp\", \"finite\", \"fix\", \"floor\",",
            "        \"fmod\", \"gamma\", \"gammainc\", \"gammaln\", \"imag\",",
            "        \"isalnum\", \"isalpha\", \"isascii\", \"iscntrl\",",
            "        \"isdigit\", \"isfinite\", \"isgraph\", \"isinf\",",
            "        \"islower\", \"isna\", \"isnan\", \"isprint\", \"ispunct\",",
            "        \"isspace\", \"isupper\", \"isxdigit\", \"lcm\", \"lgamma\",",
            "        \"log\", \"lower\", \"mod\", \"real\", \"rem\", \"round\",",
            "        \"roundb\", \"sec\", \"sech\", \"sign\", \"sin\", \"sinh\",",
            "        \"sqrt\", \"tan\", \"tanh\", \"toascii\", \"tolower\", \"xor\")",
            "",
            "    builtin_consts = (",
            "        \"EDITOR\", \"EXEC_PATH\", \"I\", \"IMAGE_PATH\", \"NA\",",
            "        \"OCTAVE_HOME\", \"OCTAVE_VERSION\", \"PAGER\",",
            "        \"PAGER_FLAGS\", \"SEEK_CUR\", \"SEEK_END\", \"SEEK_SET\",",
            "        \"SIG\", \"S_ISBLK\", \"S_ISCHR\", \"S_ISDIR\", \"S_ISFIFO\",",
            "        \"S_ISLNK\", \"S_ISREG\", \"S_ISSOCK\", \"WCONTINUE\",",
            "        \"WCOREDUMP\", \"WEXITSTATUS\", \"WIFCONTINUED\",",
            "        \"WIFEXITED\", \"WIFSIGNALED\", \"WIFSTOPPED\", \"WNOHANG\",",
            "        \"WSTOPSIG\", \"WTERMSIG\", \"WUNTRACED\")",
            "",
            "    tokens = {",
            "        'root': [",
            "            # We should look into multiline comments",
            "            (r'[%#].*$', Comment),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            # from 'iskeyword' on hg changeset 8cc154f45e37",
            "            (words((",
            "                '__FILE__', '__LINE__', 'break', 'case', 'catch', 'classdef', 'continue', 'do', 'else',",
            "                'elseif', 'end', 'end_try_catch', 'end_unwind_protect', 'endclassdef',",
            "                'endevents', 'endfor', 'endfunction', 'endif', 'endmethods', 'endproperties',",
            "                'endswitch', 'endwhile', 'events', 'for', 'function', 'get', 'global', 'if', 'methods',",
            "                'otherwise', 'persistent', 'properties', 'return', 'set', 'static', 'switch', 'try',",
            "                'until', 'unwind_protect', 'unwind_protect_cleanup', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (words(builtin_kw + command_kw + function_kw + loadable_kw + mapping_kw,",
            "                   suffix=r'\\b'),  Name.Builtin),",
            "",
            "            (words(builtin_consts, suffix=r'\\b'), Name.Constant),",
            "",
            "            # operators in Octave but not Matlab:",
            "            (r'-=|!=|!|/=|--', Operator),",
            "            # operators:",
            "            (r'-|==|~=|<|>|<=|>=|&&|&|~|\\|\\|?', Operator),",
            "            # operators in Octave but not Matlab requiring escape for re:",
            "            (r'\\*=|\\+=|\\^=|\\/=|\\\\=|\\*\\*|\\+\\+|\\.\\*\\*', Operator),",
            "            # operators requiring escape for re:",
            "            (r'\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\.\\/|\\/|\\\\', Operator),",
            "",
            "",
            "            # punctuation:",
            "            (r'[\\[\\](){}:@.,]', Punctuation),",
            "            (r'=|:|;', Punctuation),",
            "",
            "            (r'\"[^\"]*\"', String),",
            "",
            "            (r'(\\d+\\.\\d*|\\d*\\.\\d+)([eEf][+-]?[0-9]+)?', Number.Float),",
            "            (r'\\d+[eEf][+-]?[0-9]+', Number.Float),",
            "            (r'\\d+', Number.Integer),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        \"\"\"Octave is quite hard to spot, and it looks like Matlab as well.\"\"\"",
            "        return 0",
            "",
            "",
            "class ScilabLexer(RegexLexer):",
            "    \"\"\"",
            "    For Scilab source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Scilab'",
            "    aliases = ['scilab']",
            "    filenames = ['*.sci', '*.sce', '*.tst']",
            "    mimetypes = ['text/scilab']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'//.*?$', Comment.Single),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            (words((",
            "                '__FILE__', '__LINE__', 'break', 'case', 'catch', 'classdef', 'continue', 'do', 'else',",
            "                'elseif', 'end', 'end_try_catch', 'end_unwind_protect', 'endclassdef',",
            "                'endevents', 'endfor', 'endfunction', 'endif', 'endmethods', 'endproperties',",
            "                'endswitch', 'endwhile', 'events', 'for', 'function', 'get', 'global', 'if', 'methods',",
            "                'otherwise', 'persistent', 'properties', 'return', 'set', 'static', 'switch', 'try',",
            "                'until', 'unwind_protect', 'unwind_protect_cleanup', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (words(_scilab_builtins.functions_kw +",
            "                   _scilab_builtins.commands_kw +",
            "                   _scilab_builtins.macros_kw, suffix=r'\\b'), Name.Builtin),",
            "",
            "            (words(_scilab_builtins.variables_kw, suffix=r'\\b'), Name.Constant),",
            "",
            "            # operators:",
            "            (r'-|==|~=|<|>|<=|>=|&&|&|~|\\|\\|?', Operator),",
            "            # operators requiring escape for re:",
            "            (r'\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\.\\/|\\/|\\\\', Operator),",
            "",
            "            # punctuation:",
            "            (r'[\\[\\](){}@.,=:;]', Punctuation),",
            "",
            "            (r'\"[^\"]*\"', String),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "",
            "            (r'(\\d+\\.\\d*|\\d*\\.\\d+)([eEf][+-]?[0-9]+)?', Number.Float),",
            "            (r'\\d+[eEf][+-]?[0-9]+', Number.Float),",
            "            (r'\\d+', Number.Integer),",
            "",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "            (r'.', String, '#pop'),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(.+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "    }"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.matlab",
            "    ~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Matlab and related languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import Lexer, RegexLexer, bygroups, default, words, \\",
            "    do_insertions",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation, Generic, Whitespace",
            "",
            "from pygments.lexers import _scilab_builtins",
            "",
            "__all__ = ['MatlabLexer', 'MatlabSessionLexer', 'OctaveLexer', 'ScilabLexer']",
            "",
            "",
            "class MatlabLexer(RegexLexer):",
            "    \"\"\"",
            "    For Matlab source code.",
            "",
            "    .. versionadded:: 0.10",
            "    \"\"\"",
            "    name = 'Matlab'",
            "    aliases = ['matlab']",
            "    filenames = ['*.m']",
            "    mimetypes = ['text/matlab']",
            "",
            "    #",
            "    # These lists are generated automatically.",
            "    # Run the following in bash shell:",
            "    #",
            "    # for f in elfun specfun elmat; do",
            "    #   echo -n \"$f = \"",
            "    #   matlab -nojvm -r \"help $f;exit;\" | perl -ne \\",
            "    #   'push(@c,$1) if /^    (\\w+)\\s+-/; END {print q{[\"}.join(q{\",\"},@c).qq{\"]\\n};}'",
            "    # done",
            "    #",
            "    # elfun: Elementary math functions",
            "    # specfun: Special Math functions",
            "    # elmat: Elementary matrices and matrix manipulation",
            "    #",
            "    # taken from Matlab version 9.4 (R2018a)",
            "    #",
            "    elfun = (\"sin\", \"sind\", \"sinh\", \"asin\", \"asind\", \"asinh\", \"cos\", \"cosd\", \"cosh\",",
            "             \"acos\", \"acosd\", \"acosh\", \"tan\", \"tand\", \"tanh\", \"atan\", \"atand\", \"atan2\",",
            "             \"atan2d\", \"atanh\", \"sec\", \"secd\", \"sech\", \"asec\", \"asecd\", \"asech\", \"csc\", \"cscd\",",
            "             \"csch\", \"acsc\", \"acscd\", \"acsch\", \"cot\", \"cotd\", \"coth\", \"acot\", \"acotd\",",
            "             \"acoth\", \"hypot\", \"deg2rad\", \"rad2deg\", \"exp\", \"expm1\", \"log\", \"log1p\", \"log10\", \"log2\", \"pow2\",",
            "             \"realpow\", \"reallog\", \"realsqrt\", \"sqrt\", \"nthroot\", \"nextpow2\", \"abs\",",
            "             \"angle\", \"complex\", \"conj\", \"imag\", \"real\", \"unwrap\", \"isreal\", \"cplxpair\",",
            "             \"fix\", \"floor\", \"ceil\", \"round\", \"mod\", \"rem\", \"sign\")",
            "    specfun = (\"airy\", \"besselj\", \"bessely\", \"besselh\", \"besseli\", \"besselk\", \"beta\",",
            "               \"betainc\", \"betaincinv\", \"betaln\", \"ellipj\", \"ellipke\", \"erf\", \"erfc\", \"erfcx\",",
            "               \"erfinv\", \"erfcinv\", \"expint\", \"gamma\", \"gammainc\", \"gammaincinv\", \"gammaln\", \"psi\", \"legendre\",",
            "               \"cross\", \"dot\", \"factor\", \"isprime\", \"primes\", \"gcd\", \"lcm\", \"rat\",",
            "               \"rats\", \"perms\", \"nchoosek\", \"factorial\", \"cart2sph\", \"cart2pol\",",
            "               \"pol2cart\", \"sph2cart\", \"hsv2rgb\", \"rgb2hsv\")",
            "    elmat = (\"zeros\", \"ones\", \"eye\", \"repmat\", \"repelem\", \"linspace\", \"logspace\",",
            "             \"freqspace\", \"meshgrid\", \"accumarray\", \"size\", \"length\", \"ndims\", \"numel\",",
            "             \"disp\", \"isempty\", \"isequal\", \"isequaln\", \"cat\", \"reshape\",",
            "             \"diag\", \"blkdiag\", \"tril\", \"triu\", \"fliplr\", \"flipud\", \"flip\", \"rot90\",",
            "             \"find\", \"end\", \"sub2ind\", \"ind2sub\", \"bsxfun\", \"ndgrid\", \"permute\",",
            "             \"ipermute\", \"shiftdim\", \"circshift\", \"squeeze\", \"isscalar\", \"isvector\",",
            "             \"isrow\", \"iscolumn\", \"ismatrix\", \"eps\", \"realmax\", \"realmin\", \"intmax\", \"intmin\", \"flintmax\", \"pi\", \"i\", \"inf\", \"nan\", \"isnan\",",
            "             \"isinf\", \"isfinite\", \"j\", \"true\", \"false\", \"compan\", \"gallery\", \"hadamard\", \"hankel\",",
            "             \"hilb\", \"invhilb\", \"magic\", \"pascal\", \"rosser\", \"toeplitz\", \"vander\",",
            "             \"wilkinson\")",
            "",
            "    _operators = r'-|==|~=|<=|>=|<|>|&&|&|~|\\|\\|?|\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\./|/|\\\\'",
            "",
            "    tokens = {",
            "        'root': [",
            "            # line starting with '!' is sent as a system command.  not sure what",
            "            # label to use...",
            "            (r'^!.*', String.Other),",
            "            (r'%\\{\\s*\\n', Comment.Multiline, 'blockcomment'),",
            "            (r'%.*$', Comment),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            # from 'iskeyword' on version 9.4 (R2018a):",
            "            # Check that there is no preceding dot, as keywords are valid field",
            "            # names.",
            "            (words(('break', 'case', 'catch', 'classdef', 'continue', 'else',",
            "                    'elseif', 'end', 'for', 'function',",
            "                    'global', 'if', 'otherwise', 'parfor',",
            "                    'persistent', 'return', 'spmd', 'switch',",
            "                    'try', 'while'),",
            "                   prefix=r'(?<!\\.)', suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (\"(\" + \"|\".join(elfun + specfun + elmat) + r')\\b',  Name.Builtin),",
            "",
            "            # line continuation with following comment:",
            "            (r'(\\.\\.\\.)(.*)$', bygroups(Keyword, Comment)),",
            "",
            "            # command form:",
            "            # \"How MATLAB Recognizes Command Syntax\" specifies that an operator",
            "            # is recognized if it is either surrounded by spaces or by no",
            "            # spaces on both sides; only the former case matters for us.  (This",
            "            # allows distinguishing `cd ./foo` from `cd ./ foo`.)",
            "            (r'(?:^|(?<=;))(\\s*)(\\w+)(\\s+)(?!=|\\(|(?:%s)\\s+)' % _operators,",
            "             bygroups(Text, Name, Text), 'commandargs'),",
            "",
            "            # operators:",
            "            (_operators, Operator),",
            "",
            "            # numbers (must come before punctuation to handle `.5`; cannot use",
            "            # `\\b` due to e.g. `5. + .5`).",
            "            (r'(?<!\\w)((\\d+\\.\\d*)|(\\d*\\.\\d+))([eEf][+-]?\\d+)?(?!\\w)', Number.Float),",
            "            (r'\\b\\d+[eEf][+-]?[0-9]+\\b', Number.Float),",
            "            (r'\\b\\d+\\b', Number.Integer),",
            "",
            "            # punctuation:",
            "            (r'\\[|\\]|\\(|\\)|\\{|\\}|:|@|\\.|,', Punctuation),",
            "            (r'=|:|;', Punctuation),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "",
            "            (r'\"(\"\"|[^\"])*\"', String),",
            "",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'blockcomment': [",
            "            (r'^\\s*%\\}', Comment.Multiline, '#pop'),",
            "            (r'^.*\\n', Comment.Multiline),",
            "            (r'.', Comment.Multiline),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "        ],",
            "        'commandargs': [",
            "            # If an equal sign or other operator is encountered, this",
            "            # isn't a command. It might be a variable assignment or",
            "            # comparison operation with multiple spaces before the",
            "            # equal sign or operator",
            "            (r\"=\", Punctuation, '#pop'),",
            "            (_operators, Operator, '#pop'),",
            "            (r\"[ \\t]+\", Text),",
            "            (\"'[^']*'\", String),",
            "            (r\"[^';\\s]+\", String),",
            "            (\";\", Punctuation, '#pop'),",
            "            default('#pop'),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        # function declaration.",
            "        first_non_comment = next((line for line in text.splitlines()",
            "                                  if not re.match(r'^\\s*%', text)), '').strip()",
            "        if (first_non_comment.startswith('function')",
            "                and '{' not in first_non_comment):",
            "            return 1.",
            "        # comment",
            "        elif re.search(r'^\\s*%', text, re.M):",
            "            return 0.2",
            "        # system cmd",
            "        elif re.search(r'^!\\w+', text, re.M):",
            "            return 0.2",
            "",
            "",
            "line_re  = re.compile('.*?\\n')",
            "",
            "",
            "class MatlabSessionLexer(Lexer):",
            "    \"\"\"",
            "    For Matlab sessions.  Modeled after PythonConsoleLexer.",
            "    Contributed by Ken Schutte <kschutte@csail.mit.edu>.",
            "",
            "    .. versionadded:: 0.10",
            "    \"\"\"",
            "    name = 'Matlab session'",
            "    aliases = ['matlabsession']",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        mlexer = MatlabLexer(**self.options)",
            "",
            "        curcode = ''",
            "        insertions = []",
            "        continuation = False",
            "",
            "        for match in line_re.finditer(text):",
            "            line = match.group()",
            "",
            "            if line.startswith('>> '):",
            "                insertions.append((len(curcode),",
            "                                   [(0, Generic.Prompt, line[:3])]))",
            "                curcode += line[3:]",
            "",
            "            elif line.startswith('>>'):",
            "                insertions.append((len(curcode),",
            "                                   [(0, Generic.Prompt, line[:2])]))",
            "                curcode += line[2:]",
            "",
            "            elif line.startswith('???'):",
            "",
            "                idx = len(curcode)",
            "",
            "                # without is showing error on same line as before...?",
            "                # line = \"\\n\" + line",
            "                token = (0, Generic.Traceback, line)",
            "                insertions.append((idx, [token]))",
            "            elif continuation:",
            "                # line_start is the length of the most recent prompt symbol",
            "                line_start = len(insertions[-1][-1][-1])",
            "                # Set leading spaces with the length of the prompt to be a generic prompt",
            "                # This keeps code aligned when prompts are removed, say with some Javascript",
            "                if line.startswith(' '*line_start):",
            "                    insertions.append((len(curcode),",
            "                                    [(0, Generic.Prompt, line[:line_start])]))",
            "                    curcode += line[line_start:]",
            "                else:",
            "                    curcode += line",
            "            else:",
            "                if curcode:",
            "                    yield from do_insertions(",
            "                        insertions, mlexer.get_tokens_unprocessed(curcode))",
            "                    curcode = ''",
            "                    insertions = []",
            "",
            "                yield match.start(), Generic.Output, line",
            "",
            "            # Does not allow continuation if a comment is included after the ellipses.",
            "            # Continues any line that ends with ..., even comments (lines that start with %)",
            "            if line.strip().endswith('...'):",
            "                continuation = True",
            "            else:",
            "                continuation = False",
            "",
            "        if curcode:  # or item:",
            "            yield from do_insertions(",
            "                insertions, mlexer.get_tokens_unprocessed(curcode))",
            "",
            "",
            "class OctaveLexer(RegexLexer):",
            "    \"\"\"",
            "    For GNU Octave source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Octave'",
            "    aliases = ['octave']",
            "    filenames = ['*.m']",
            "    mimetypes = ['text/octave']",
            "",
            "    # These lists are generated automatically.",
            "    # Run the following in bash shell:",
            "    #",
            "    # First dump all of the Octave manual into a plain text file:",
            "    #",
            "    #   $ info octave --subnodes -o octave-manual",
            "    #",
            "    # Now grep through it:",
            "",
            "    # for i in \\",
            "    #     \"Built-in Function\" \"Command\" \"Function File\" \\",
            "    #     \"Loadable Function\" \"Mapping Function\";",
            "    # do",
            "    #     perl -e '@name = qw('\"$i\"');",
            "    #              print lc($name[0]),\"_kw = [\\n\"';",
            "    #",
            "    #     perl -n -e 'print \"\\\"$1\\\",\\n\" if /-- '\"$i\"': .* (\\w*) \\(/;' \\",
            "    #         octave-manual | sort | uniq ;",
            "    #     echo \"]\" ;",
            "    #     echo;",
            "    # done",
            "",
            "    # taken from Octave Mercurial changeset 8cc154f45e37 (30-jan-2011)",
            "",
            "    builtin_kw = (",
            "        \"addlistener\", \"addpath\", \"addproperty\", \"all\",",
            "        \"and\", \"any\", \"argnames\", \"argv\", \"assignin\",",
            "        \"atexit\", \"autoload\",",
            "        \"available_graphics_toolkits\", \"beep_on_error\",",
            "        \"bitand\", \"bitmax\", \"bitor\", \"bitshift\", \"bitxor\",",
            "        \"cat\", \"cell\", \"cellstr\", \"char\", \"class\", \"clc\",",
            "        \"columns\", \"command_line_path\",",
            "        \"completion_append_char\", \"completion_matches\",",
            "        \"complex\", \"confirm_recursive_rmdir\", \"cputime\",",
            "        \"crash_dumps_octave_core\", \"ctranspose\", \"cumprod\",",
            "        \"cumsum\", \"debug_on_error\", \"debug_on_interrupt\",",
            "        \"debug_on_warning\", \"default_save_options\",",
            "        \"dellistener\", \"diag\", \"diff\", \"disp\",",
            "        \"doc_cache_file\", \"do_string_escapes\", \"double\",",
            "        \"drawnow\", \"e\", \"echo_executing_commands\", \"eps\",",
            "        \"eq\", \"errno\", \"errno_list\", \"error\", \"eval\",",
            "        \"evalin\", \"exec\", \"exist\", \"exit\", \"eye\", \"false\",",
            "        \"fclear\", \"fclose\", \"fcntl\", \"fdisp\", \"feof\",",
            "        \"ferror\", \"feval\", \"fflush\", \"fgetl\", \"fgets\",",
            "        \"fieldnames\", \"file_in_loadpath\", \"file_in_path\",",
            "        \"filemarker\", \"filesep\", \"find_dir_in_path\",",
            "        \"fixed_point_format\", \"fnmatch\", \"fopen\", \"fork\",",
            "        \"formula\", \"fprintf\", \"fputs\", \"fread\", \"freport\",",
            "        \"frewind\", \"fscanf\", \"fseek\", \"fskipl\", \"ftell\",",
            "        \"functions\", \"fwrite\", \"ge\", \"genpath\", \"get\",",
            "        \"getegid\", \"getenv\", \"geteuid\", \"getgid\",",
            "        \"getpgrp\", \"getpid\", \"getppid\", \"getuid\", \"glob\",",
            "        \"gt\", \"gui_mode\", \"history_control\",",
            "        \"history_file\", \"history_size\",",
            "        \"history_timestamp_format_string\", \"home\",",
            "        \"horzcat\", \"hypot\", \"ifelse\",",
            "        \"ignore_function_time_stamp\", \"inferiorto\",",
            "        \"info_file\", \"info_program\", \"inline\", \"input\",",
            "        \"intmax\", \"intmin\", \"ipermute\",",
            "        \"is_absolute_filename\", \"isargout\", \"isbool\",",
            "        \"iscell\", \"iscellstr\", \"ischar\", \"iscomplex\",",
            "        \"isempty\", \"isfield\", \"isfloat\", \"isglobal\",",
            "        \"ishandle\", \"isieee\", \"isindex\", \"isinteger\",",
            "        \"islogical\", \"ismatrix\", \"ismethod\", \"isnull\",",
            "        \"isnumeric\", \"isobject\", \"isreal\",",
            "        \"is_rooted_relative_filename\", \"issorted\",",
            "        \"isstruct\", \"isvarname\", \"kbhit\", \"keyboard\",",
            "        \"kill\", \"lasterr\", \"lasterror\", \"lastwarn\",",
            "        \"ldivide\", \"le\", \"length\", \"link\", \"linspace\",",
            "        \"logical\", \"lstat\", \"lt\", \"make_absolute_filename\",",
            "        \"makeinfo_program\", \"max_recursion_depth\", \"merge\",",
            "        \"methods\", \"mfilename\", \"minus\", \"mislocked\",",
            "        \"mkdir\", \"mkfifo\", \"mkstemp\", \"mldivide\", \"mlock\",",
            "        \"mouse_wheel_zoom\", \"mpower\", \"mrdivide\", \"mtimes\",",
            "        \"munlock\", \"nargin\", \"nargout\",",
            "        \"native_float_format\", \"ndims\", \"ne\", \"nfields\",",
            "        \"nnz\", \"norm\", \"not\", \"numel\", \"nzmax\",",
            "        \"octave_config_info\", \"octave_core_file_limit\",",
            "        \"octave_core_file_name\",",
            "        \"octave_core_file_options\", \"ones\", \"or\",",
            "        \"output_max_field_width\", \"output_precision\",",
            "        \"page_output_immediately\", \"page_screen_output\",",
            "        \"path\", \"pathsep\", \"pause\", \"pclose\", \"permute\",",
            "        \"pi\", \"pipe\", \"plus\", \"popen\", \"power\",",
            "        \"print_empty_dimensions\", \"printf\",",
            "        \"print_struct_array_contents\", \"prod\",",
            "        \"program_invocation_name\", \"program_name\",",
            "        \"putenv\", \"puts\", \"pwd\", \"quit\", \"rats\", \"rdivide\",",
            "        \"readdir\", \"readlink\", \"read_readline_init_file\",",
            "        \"realmax\", \"realmin\", \"rehash\", \"rename\",",
            "        \"repelems\", \"re_read_readline_init_file\", \"reset\",",
            "        \"reshape\", \"resize\", \"restoredefaultpath\",",
            "        \"rethrow\", \"rmdir\", \"rmfield\", \"rmpath\", \"rows\",",
            "        \"save_header_format_string\", \"save_precision\",",
            "        \"saving_history\", \"scanf\", \"set\", \"setenv\",",
            "        \"shell_cmd\", \"sighup_dumps_octave_core\",",
            "        \"sigterm_dumps_octave_core\", \"silent_functions\",",
            "        \"single\", \"size\", \"size_equal\", \"sizemax\",",
            "        \"sizeof\", \"sleep\", \"source\", \"sparse_auto_mutate\",",
            "        \"split_long_rows\", \"sprintf\", \"squeeze\", \"sscanf\",",
            "        \"stat\", \"stderr\", \"stdin\", \"stdout\", \"strcmp\",",
            "        \"strcmpi\", \"string_fill_char\", \"strncmp\",",
            "        \"strncmpi\", \"struct\", \"struct_levels_to_print\",",
            "        \"strvcat\", \"subsasgn\", \"subsref\", \"sum\", \"sumsq\",",
            "        \"superiorto\", \"suppress_verbose_help_message\",",
            "        \"symlink\", \"system\", \"tic\", \"tilde_expand\",",
            "        \"times\", \"tmpfile\", \"tmpnam\", \"toc\", \"toupper\",",
            "        \"transpose\", \"true\", \"typeinfo\", \"umask\", \"uminus\",",
            "        \"uname\", \"undo_string_escapes\", \"unlink\", \"uplus\",",
            "        \"upper\", \"usage\", \"usleep\", \"vec\", \"vectorize\",",
            "        \"vertcat\", \"waitpid\", \"warning\", \"warranty\",",
            "        \"whos_line_format\", \"yes_or_no\", \"zeros\",",
            "        \"inf\", \"Inf\", \"nan\", \"NaN\")",
            "",
            "    command_kw = (\"close\", \"load\", \"who\", \"whos\")",
            "",
            "    function_kw = (",
            "        \"accumarray\", \"accumdim\", \"acosd\", \"acotd\",",
            "        \"acscd\", \"addtodate\", \"allchild\", \"ancestor\",",
            "        \"anova\", \"arch_fit\", \"arch_rnd\", \"arch_test\",",
            "        \"area\", \"arma_rnd\", \"arrayfun\", \"ascii\", \"asctime\",",
            "        \"asecd\", \"asind\", \"assert\", \"atand\",",
            "        \"autoreg_matrix\", \"autumn\", \"axes\", \"axis\", \"bar\",",
            "        \"barh\", \"bartlett\", \"bartlett_test\", \"beep\",",
            "        \"betacdf\", \"betainv\", \"betapdf\", \"betarnd\",",
            "        \"bicgstab\", \"bicubic\", \"binary\", \"binocdf\",",
            "        \"binoinv\", \"binopdf\", \"binornd\", \"bitcmp\",",
            "        \"bitget\", \"bitset\", \"blackman\", \"blanks\",",
            "        \"blkdiag\", \"bone\", \"box\", \"brighten\", \"calendar\",",
            "        \"cast\", \"cauchy_cdf\", \"cauchy_inv\", \"cauchy_pdf\",",
            "        \"cauchy_rnd\", \"caxis\", \"celldisp\", \"center\", \"cgs\",",
            "        \"chisquare_test_homogeneity\",",
            "        \"chisquare_test_independence\", \"circshift\", \"cla\",",
            "        \"clabel\", \"clf\", \"clock\", \"cloglog\", \"closereq\",",
            "        \"colon\", \"colorbar\", \"colormap\", \"colperm\",",
            "        \"comet\", \"common_size\", \"commutation_matrix\",",
            "        \"compan\", \"compare_versions\", \"compass\",",
            "        \"computer\", \"cond\", \"condest\", \"contour\",",
            "        \"contourc\", \"contourf\", \"contrast\", \"conv\",",
            "        \"convhull\", \"cool\", \"copper\", \"copyfile\", \"cor\",",
            "        \"corrcoef\", \"cor_test\", \"cosd\", \"cotd\", \"cov\",",
            "        \"cplxpair\", \"cross\", \"cscd\", \"cstrcat\", \"csvread\",",
            "        \"csvwrite\", \"ctime\", \"cumtrapz\", \"curl\", \"cut\",",
            "        \"cylinder\", \"date\", \"datenum\", \"datestr\",",
            "        \"datetick\", \"datevec\", \"dblquad\", \"deal\",",
            "        \"deblank\", \"deconv\", \"delaunay\", \"delaunayn\",",
            "        \"delete\", \"demo\", \"detrend\", \"diffpara\", \"diffuse\",",
            "        \"dir\", \"discrete_cdf\", \"discrete_inv\",",
            "        \"discrete_pdf\", \"discrete_rnd\", \"display\",",
            "        \"divergence\", \"dlmwrite\", \"dos\", \"dsearch\",",
            "        \"dsearchn\", \"duplication_matrix\", \"durbinlevinson\",",
            "        \"ellipsoid\", \"empirical_cdf\", \"empirical_inv\",",
            "        \"empirical_pdf\", \"empirical_rnd\", \"eomday\",",
            "        \"errorbar\", \"etime\", \"etreeplot\", \"example\",",
            "        \"expcdf\", \"expinv\", \"expm\", \"exppdf\", \"exprnd\",",
            "        \"ezcontour\", \"ezcontourf\", \"ezmesh\", \"ezmeshc\",",
            "        \"ezplot\", \"ezpolar\", \"ezsurf\", \"ezsurfc\", \"factor\",",
            "        \"factorial\", \"fail\", \"fcdf\", \"feather\", \"fftconv\",",
            "        \"fftfilt\", \"fftshift\", \"figure\", \"fileattrib\",",
            "        \"fileparts\", \"fill\", \"findall\", \"findobj\",",
            "        \"findstr\", \"finv\", \"flag\", \"flipdim\", \"fliplr\",",
            "        \"flipud\", \"fpdf\", \"fplot\", \"fractdiff\", \"freqz\",",
            "        \"freqz_plot\", \"frnd\", \"fsolve\",",
            "        \"f_test_regression\", \"ftp\", \"fullfile\", \"fzero\",",
            "        \"gamcdf\", \"gaminv\", \"gampdf\", \"gamrnd\", \"gca\",",
            "        \"gcbf\", \"gcbo\", \"gcf\", \"genvarname\", \"geocdf\",",
            "        \"geoinv\", \"geopdf\", \"geornd\", \"getfield\", \"ginput\",",
            "        \"glpk\", \"gls\", \"gplot\", \"gradient\",",
            "        \"graphics_toolkit\", \"gray\", \"grid\", \"griddata\",",
            "        \"griddatan\", \"gtext\", \"gunzip\", \"gzip\", \"hadamard\",",
            "        \"hamming\", \"hankel\", \"hanning\", \"hggroup\",",
            "        \"hidden\", \"hilb\", \"hist\", \"histc\", \"hold\", \"hot\",",
            "        \"hotelling_test\", \"housh\", \"hsv\", \"hurst\",",
            "        \"hygecdf\", \"hygeinv\", \"hygepdf\", \"hygernd\",",
            "        \"idivide\", \"ifftshift\", \"image\", \"imagesc\",",
            "        \"imfinfo\", \"imread\", \"imshow\", \"imwrite\", \"index\",",
            "        \"info\", \"inpolygon\", \"inputname\", \"interpft\",",
            "        \"interpn\", \"intersect\", \"invhilb\", \"iqr\", \"isa\",",
            "        \"isdefinite\", \"isdir\", \"is_duplicate_entry\",",
            "        \"isequal\", \"isequalwithequalnans\", \"isfigure\",",
            "        \"ishermitian\", \"ishghandle\", \"is_leap_year\",",
            "        \"isletter\", \"ismac\", \"ismember\", \"ispc\", \"isprime\",",
            "        \"isprop\", \"isscalar\", \"issquare\", \"isstrprop\",",
            "        \"issymmetric\", \"isunix\", \"is_valid_file_id\",",
            "        \"isvector\", \"jet\", \"kendall\",",
            "        \"kolmogorov_smirnov_cdf\",",
            "        \"kolmogorov_smirnov_test\", \"kruskal_wallis_test\",",
            "        \"krylov\", \"kurtosis\", \"laplace_cdf\", \"laplace_inv\",",
            "        \"laplace_pdf\", \"laplace_rnd\", \"legend\", \"legendre\",",
            "        \"license\", \"line\", \"linkprop\", \"list_primes\",",
            "        \"loadaudio\", \"loadobj\", \"logistic_cdf\",",
            "        \"logistic_inv\", \"logistic_pdf\", \"logistic_rnd\",",
            "        \"logit\", \"loglog\", \"loglogerr\", \"logm\", \"logncdf\",",
            "        \"logninv\", \"lognpdf\", \"lognrnd\", \"logspace\",",
            "        \"lookfor\", \"ls_command\", \"lsqnonneg\", \"magic\",",
            "        \"mahalanobis\", \"manova\", \"matlabroot\",",
            "        \"mcnemar_test\", \"mean\", \"meansq\", \"median\", \"menu\",",
            "        \"mesh\", \"meshc\", \"meshgrid\", \"meshz\", \"mexext\",",
            "        \"mget\", \"mkpp\", \"mode\", \"moment\", \"movefile\",",
            "        \"mpoles\", \"mput\", \"namelengthmax\", \"nargchk\",",
            "        \"nargoutchk\", \"nbincdf\", \"nbininv\", \"nbinpdf\",",
            "        \"nbinrnd\", \"nchoosek\", \"ndgrid\", \"newplot\", \"news\",",
            "        \"nonzeros\", \"normcdf\", \"normest\", \"norminv\",",
            "        \"normpdf\", \"normrnd\", \"now\", \"nthroot\", \"null\",",
            "        \"ocean\", \"ols\", \"onenormest\", \"optimget\",",
            "        \"optimset\", \"orderfields\", \"orient\", \"orth\",",
            "        \"pack\", \"pareto\", \"parseparams\", \"pascal\", \"patch\",",
            "        \"pathdef\", \"pcg\", \"pchip\", \"pcolor\", \"pcr\",",
            "        \"peaks\", \"periodogram\", \"perl\", \"perms\", \"pie\",",
            "        \"pink\", \"planerot\", \"playaudio\", \"plot\",",
            "        \"plotmatrix\", \"plotyy\", \"poisscdf\", \"poissinv\",",
            "        \"poisspdf\", \"poissrnd\", \"polar\", \"poly\",",
            "        \"polyaffine\", \"polyarea\", \"polyderiv\", \"polyfit\",",
            "        \"polygcd\", \"polyint\", \"polyout\", \"polyreduce\",",
            "        \"polyval\", \"polyvalm\", \"postpad\", \"powerset\",",
            "        \"ppder\", \"ppint\", \"ppjumps\", \"ppplot\", \"ppval\",",
            "        \"pqpnonneg\", \"prepad\", \"primes\", \"print\",",
            "        \"print_usage\", \"prism\", \"probit\", \"qp\", \"qqplot\",",
            "        \"quadcc\", \"quadgk\", \"quadl\", \"quadv\", \"quiver\",",
            "        \"qzhess\", \"rainbow\", \"randi\", \"range\", \"rank\",",
            "        \"ranks\", \"rat\", \"reallog\", \"realpow\", \"realsqrt\",",
            "        \"record\", \"rectangle_lw\", \"rectangle_sw\",",
            "        \"rectint\", \"refresh\", \"refreshdata\",",
            "        \"regexptranslate\", \"repmat\", \"residue\", \"ribbon\",",
            "        \"rindex\", \"roots\", \"rose\", \"rosser\", \"rotdim\",",
            "        \"rref\", \"run\", \"run_count\", \"rundemos\", \"run_test\",",
            "        \"runtests\", \"saveas\", \"saveaudio\", \"saveobj\",",
            "        \"savepath\", \"scatter\", \"secd\", \"semilogx\",",
            "        \"semilogxerr\", \"semilogy\", \"semilogyerr\",",
            "        \"setaudio\", \"setdiff\", \"setfield\", \"setxor\",",
            "        \"shading\", \"shift\", \"shiftdim\", \"sign_test\",",
            "        \"sinc\", \"sind\", \"sinetone\", \"sinewave\", \"skewness\",",
            "        \"slice\", \"sombrero\", \"sortrows\", \"spaugment\",",
            "        \"spconvert\", \"spdiags\", \"spearman\", \"spectral_adf\",",
            "        \"spectral_xdf\", \"specular\", \"speed\", \"spencer\",",
            "        \"speye\", \"spfun\", \"sphere\", \"spinmap\", \"spline\",",
            "        \"spones\", \"sprand\", \"sprandn\", \"sprandsym\",",
            "        \"spring\", \"spstats\", \"spy\", \"sqp\", \"stairs\",",
            "        \"statistics\", \"std\", \"stdnormal_cdf\",",
            "        \"stdnormal_inv\", \"stdnormal_pdf\", \"stdnormal_rnd\",",
            "        \"stem\", \"stft\", \"strcat\", \"strchr\", \"strjust\",",
            "        \"strmatch\", \"strread\", \"strsplit\", \"strtok\",",
            "        \"strtrim\", \"strtrunc\", \"structfun\", \"studentize\",",
            "        \"subplot\", \"subsindex\", \"subspace\", \"substr\",",
            "        \"substruct\", \"summer\", \"surf\", \"surface\", \"surfc\",",
            "        \"surfl\", \"surfnorm\", \"svds\", \"swapbytes\",",
            "        \"sylvester_matrix\", \"symvar\", \"synthesis\", \"table\",",
            "        \"tand\", \"tar\", \"tcdf\", \"tempdir\", \"tempname\",",
            "        \"test\", \"text\", \"textread\", \"textscan\", \"tinv\",",
            "        \"title\", \"toeplitz\", \"tpdf\", \"trace\", \"trapz\",",
            "        \"treelayout\", \"treeplot\", \"triangle_lw\",",
            "        \"triangle_sw\", \"tril\", \"trimesh\", \"triplequad\",",
            "        \"triplot\", \"trisurf\", \"triu\", \"trnd\", \"tsearchn\",",
            "        \"t_test\", \"t_test_regression\", \"type\", \"unidcdf\",",
            "        \"unidinv\", \"unidpdf\", \"unidrnd\", \"unifcdf\",",
            "        \"unifinv\", \"unifpdf\", \"unifrnd\", \"union\", \"unique\",",
            "        \"unix\", \"unmkpp\", \"unpack\", \"untabify\", \"untar\",",
            "        \"unwrap\", \"unzip\", \"u_test\", \"validatestring\",",
            "        \"vander\", \"var\", \"var_test\", \"vech\", \"ver\",",
            "        \"version\", \"view\", \"voronoi\", \"voronoin\",",
            "        \"waitforbuttonpress\", \"wavread\", \"wavwrite\",",
            "        \"wblcdf\", \"wblinv\", \"wblpdf\", \"wblrnd\", \"weekday\",",
            "        \"welch_test\", \"what\", \"white\", \"whitebg\",",
            "        \"wienrnd\", \"wilcoxon_test\", \"wilkinson\", \"winter\",",
            "        \"xlabel\", \"xlim\", \"ylabel\", \"yulewalker\", \"zip\",",
            "        \"zlabel\", \"z_test\")",
            "",
            "    loadable_kw = (",
            "        \"airy\", \"amd\", \"balance\", \"besselh\", \"besseli\",",
            "        \"besselj\", \"besselk\", \"bessely\", \"bitpack\",",
            "        \"bsxfun\", \"builtin\", \"ccolamd\", \"cellfun\",",
            "        \"cellslices\", \"chol\", \"choldelete\", \"cholinsert\",",
            "        \"cholinv\", \"cholshift\", \"cholupdate\", \"colamd\",",
            "        \"colloc\", \"convhulln\", \"convn\", \"csymamd\",",
            "        \"cummax\", \"cummin\", \"daspk\", \"daspk_options\",",
            "        \"dasrt\", \"dasrt_options\", \"dassl\", \"dassl_options\",",
            "        \"dbclear\", \"dbdown\", \"dbstack\", \"dbstatus\",",
            "        \"dbstop\", \"dbtype\", \"dbup\", \"dbwhere\", \"det\",",
            "        \"dlmread\", \"dmperm\", \"dot\", \"eig\", \"eigs\",",
            "        \"endgrent\", \"endpwent\", \"etree\", \"fft\", \"fftn\",",
            "        \"fftw\", \"filter\", \"find\", \"full\", \"gcd\",",
            "        \"getgrent\", \"getgrgid\", \"getgrnam\", \"getpwent\",",
            "        \"getpwnam\", \"getpwuid\", \"getrusage\", \"givens\",",
            "        \"gmtime\", \"gnuplot_binary\", \"hess\", \"ifft\",",
            "        \"ifftn\", \"inv\", \"isdebugmode\", \"issparse\", \"kron\",",
            "        \"localtime\", \"lookup\", \"lsode\", \"lsode_options\",",
            "        \"lu\", \"luinc\", \"luupdate\", \"matrix_type\", \"max\",",
            "        \"min\", \"mktime\", \"pinv\", \"qr\", \"qrdelete\",",
            "        \"qrinsert\", \"qrshift\", \"qrupdate\", \"quad\",",
            "        \"quad_options\", \"qz\", \"rand\", \"rande\", \"randg\",",
            "        \"randn\", \"randp\", \"randperm\", \"rcond\", \"regexp\",",
            "        \"regexpi\", \"regexprep\", \"schur\", \"setgrent\",",
            "        \"setpwent\", \"sort\", \"spalloc\", \"sparse\", \"spparms\",",
            "        \"sprank\", \"sqrtm\", \"strfind\", \"strftime\",",
            "        \"strptime\", \"strrep\", \"svd\", \"svd_driver\", \"syl\",",
            "        \"symamd\", \"symbfact\", \"symrcm\", \"time\", \"tsearch\",",
            "        \"typecast\", \"urlread\", \"urlwrite\")",
            "",
            "    mapping_kw = (",
            "        \"abs\", \"acos\", \"acosh\", \"acot\", \"acoth\", \"acsc\",",
            "        \"acsch\", \"angle\", \"arg\", \"asec\", \"asech\", \"asin\",",
            "        \"asinh\", \"atan\", \"atanh\", \"beta\", \"betainc\",",
            "        \"betaln\", \"bincoeff\", \"cbrt\", \"ceil\", \"conj\", \"cos\",",
            "        \"cosh\", \"cot\", \"coth\", \"csc\", \"csch\", \"erf\", \"erfc\",",
            "        \"erfcx\", \"erfinv\", \"exp\", \"finite\", \"fix\", \"floor\",",
            "        \"fmod\", \"gamma\", \"gammainc\", \"gammaln\", \"imag\",",
            "        \"isalnum\", \"isalpha\", \"isascii\", \"iscntrl\",",
            "        \"isdigit\", \"isfinite\", \"isgraph\", \"isinf\",",
            "        \"islower\", \"isna\", \"isnan\", \"isprint\", \"ispunct\",",
            "        \"isspace\", \"isupper\", \"isxdigit\", \"lcm\", \"lgamma\",",
            "        \"log\", \"lower\", \"mod\", \"real\", \"rem\", \"round\",",
            "        \"roundb\", \"sec\", \"sech\", \"sign\", \"sin\", \"sinh\",",
            "        \"sqrt\", \"tan\", \"tanh\", \"toascii\", \"tolower\", \"xor\")",
            "",
            "    builtin_consts = (",
            "        \"EDITOR\", \"EXEC_PATH\", \"I\", \"IMAGE_PATH\", \"NA\",",
            "        \"OCTAVE_HOME\", \"OCTAVE_VERSION\", \"PAGER\",",
            "        \"PAGER_FLAGS\", \"SEEK_CUR\", \"SEEK_END\", \"SEEK_SET\",",
            "        \"SIG\", \"S_ISBLK\", \"S_ISCHR\", \"S_ISDIR\", \"S_ISFIFO\",",
            "        \"S_ISLNK\", \"S_ISREG\", \"S_ISSOCK\", \"WCONTINUE\",",
            "        \"WCOREDUMP\", \"WEXITSTATUS\", \"WIFCONTINUED\",",
            "        \"WIFEXITED\", \"WIFSIGNALED\", \"WIFSTOPPED\", \"WNOHANG\",",
            "        \"WSTOPSIG\", \"WTERMSIG\", \"WUNTRACED\")",
            "",
            "    tokens = {",
            "        'root': [",
            "            # We should look into multiline comments",
            "            (r'[%#].*$', Comment),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            # from 'iskeyword' on hg changeset 8cc154f45e37",
            "            (words((",
            "                '__FILE__', '__LINE__', 'break', 'case', 'catch', 'classdef', 'continue', 'do', 'else',",
            "                'elseif', 'end', 'end_try_catch', 'end_unwind_protect', 'endclassdef',",
            "                'endevents', 'endfor', 'endfunction', 'endif', 'endmethods', 'endproperties',",
            "                'endswitch', 'endwhile', 'events', 'for', 'function', 'get', 'global', 'if', 'methods',",
            "                'otherwise', 'persistent', 'properties', 'return', 'set', 'static', 'switch', 'try',",
            "                'until', 'unwind_protect', 'unwind_protect_cleanup', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (words(builtin_kw + command_kw + function_kw + loadable_kw + mapping_kw,",
            "                   suffix=r'\\b'),  Name.Builtin),",
            "",
            "            (words(builtin_consts, suffix=r'\\b'), Name.Constant),",
            "",
            "            # operators in Octave but not Matlab:",
            "            (r'-=|!=|!|/=|--', Operator),",
            "            # operators:",
            "            (r'-|==|~=|<|>|<=|>=|&&|&|~|\\|\\|?', Operator),",
            "            # operators in Octave but not Matlab requiring escape for re:",
            "            (r'\\*=|\\+=|\\^=|\\/=|\\\\=|\\*\\*|\\+\\+|\\.\\*\\*', Operator),",
            "            # operators requiring escape for re:",
            "            (r'\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\.\\/|\\/|\\\\', Operator),",
            "",
            "",
            "            # punctuation:",
            "            (r'[\\[\\](){}:@.,]', Punctuation),",
            "            (r'=|:|;', Punctuation),",
            "",
            "            (r'\"[^\"]*\"', String),",
            "",
            "            (r'(\\d+\\.\\d*|\\d*\\.\\d+)([eEf][+-]?[0-9]+)?', Number.Float),",
            "            (r'\\d+[eEf][+-]?[0-9]+', Number.Float),",
            "            (r'\\d+', Number.Integer),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        \"\"\"Octave is quite hard to spot, and it looks like Matlab as well.\"\"\"",
            "        return 0",
            "",
            "",
            "class ScilabLexer(RegexLexer):",
            "    \"\"\"",
            "    For Scilab source code.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Scilab'",
            "    aliases = ['scilab']",
            "    filenames = ['*.sci', '*.sce', '*.tst']",
            "    mimetypes = ['text/scilab']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'//.*?$', Comment.Single),",
            "            (r'^\\s*function\\b', Keyword, 'deffunc'),",
            "",
            "            (words((",
            "                '__FILE__', '__LINE__', 'break', 'case', 'catch', 'classdef', 'continue', 'do', 'else',",
            "                'elseif', 'end', 'end_try_catch', 'end_unwind_protect', 'endclassdef',",
            "                'endevents', 'endfor', 'endfunction', 'endif', 'endmethods', 'endproperties',",
            "                'endswitch', 'endwhile', 'events', 'for', 'function', 'get', 'global', 'if', 'methods',",
            "                'otherwise', 'persistent', 'properties', 'return', 'set', 'static', 'switch', 'try',",
            "                'until', 'unwind_protect', 'unwind_protect_cleanup', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "",
            "            (words(_scilab_builtins.functions_kw +",
            "                   _scilab_builtins.commands_kw +",
            "                   _scilab_builtins.macros_kw, suffix=r'\\b'), Name.Builtin),",
            "",
            "            (words(_scilab_builtins.variables_kw, suffix=r'\\b'), Name.Constant),",
            "",
            "            # operators:",
            "            (r'-|==|~=|<|>|<=|>=|&&|&|~|\\|\\|?', Operator),",
            "            # operators requiring escape for re:",
            "            (r'\\.\\*|\\*|\\+|\\.\\^|\\.\\\\|\\.\\/|\\/|\\\\', Operator),",
            "",
            "            # punctuation:",
            "            (r'[\\[\\](){}@.,=:;]', Punctuation),",
            "",
            "            (r'\"[^\"]*\"', String),",
            "",
            "            # quote can be transpose, instead of string:",
            "            # (not great, but handles common cases...)",
            "            (r'(?<=[\\w)\\].])\\'+', Operator),",
            "            (r'(?<![\\w)\\].])\\'', String, 'string'),",
            "",
            "            (r'(\\d+\\.\\d*|\\d*\\.\\d+)([eEf][+-]?[0-9]+)?', Number.Float),",
            "            (r'\\d+[eEf][+-]?[0-9]+', Number.Float),",
            "            (r'\\d+', Number.Integer),",
            "",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "            (r'.', Text),",
            "        ],",
            "        'string': [",
            "            (r\"[^']*'\", String, '#pop'),",
            "            (r'.', String, '#pop'),",
            "        ],",
            "        'deffunc': [",
            "            (r'(\\s*)(?:(\\S+)(\\s*)(=)(\\s*))?(.+)(\\()(.*)(\\))(\\s*)',",
            "             bygroups(Whitespace, Text, Whitespace, Punctuation,",
            "                      Whitespace, Name.Function, Punctuation, Text,",
            "                      Punctuation, Whitespace), '#pop'),",
            "            # function with no args",
            "            (r'(\\s*)([a-zA-Z_]\\w*)', bygroups(Text, Name.Function), '#pop'),",
            "        ],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "140": [
                "MatlabLexer"
            ],
            "641": [
                "OctaveLexer"
            ],
            "713": [
                "ScilabLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/objective.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": 261,
                "PatchRowcode": "              'logos_classname'),"
            },
            "1": {
                "beforePatchRowNumber": 262,
                "afterPatchRowNumber": 262,
                "PatchRowcode": "             (r'(%hook|%group)(\\s+)([a-zA-Z$_][\\w$]+)',"
            },
            "2": {
                "beforePatchRowNumber": 263,
                "afterPatchRowNumber": 263,
                "PatchRowcode": "              bygroups(Keyword, Text, Name.Class)),"
            },
            "3": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(%config)(\\s*\\(\\s*)(\\w+)(\\s*=\\s*)(.*?)(\\s*\\)\\s*)',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+            (r'(%config)(\\s*\\(\\s*)(\\w+)(\\s*=)(.*?)(\\)\\s*)',"
            },
            "5": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "              bygroups(Keyword, Text, Name.Variable, Text, String, Text)),"
            },
            "6": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 266,
                "PatchRowcode": "             (r'(%ctor)(\\s*)(\\{)', bygroups(Keyword, Text, Punctuation),"
            },
            "7": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": 267,
                "PatchRowcode": "              'function'),"
            },
            "8": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(%new)(\\s*)(\\()(\\s*.*?\\s*)(\\))',"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+            (r'(%new)(\\s*)(\\()(.*?)(\\))',"
            },
            "10": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "              bygroups(Keyword, Text, Keyword, String, Keyword)),"
            },
            "11": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 270,
                "PatchRowcode": "             (r'(\\s*)(%end)(\\s*)', bygroups(Text, Keyword, Text)),"
            },
            "12": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 271,
                "PatchRowcode": "             inherit,"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.objective",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Objective-C family languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, this, words, \\",
            "    inherit, default",
            "from pygments.token import Text, Keyword, Name, String, Operator, \\",
            "    Number, Punctuation, Literal, Comment",
            "",
            "from pygments.lexers.c_cpp import CLexer, CppLexer",
            "",
            "__all__ = ['ObjectiveCLexer', 'ObjectiveCppLexer', 'LogosLexer', 'SwiftLexer']",
            "",
            "",
            "def objective(baselexer):",
            "    \"\"\"",
            "    Generate a subclass of baselexer that accepts the Objective-C syntax",
            "    extensions.",
            "    \"\"\"",
            "",
            "    # Have to be careful not to accidentally match JavaDoc/Doxygen syntax here,",
            "    # since that's quite common in ordinary C/C++ files.  It's OK to match",
            "    # JavaDoc/Doxygen keywords that only apply to Objective-C, mind.",
            "    #",
            "    # The upshot of this is that we CANNOT match @class or @interface",
            "    _oc_keywords = re.compile(r'@(?:end|implementation|protocol)')",
            "",
            "    # Matches [ <ws>? identifier <ws> ( identifier <ws>? ] |  identifier? : )",
            "    # (note the identifier is *optional* when there is a ':'!)",
            "    _oc_message = re.compile(r'\\[\\s*[a-zA-Z_]\\w*\\s+'",
            "                             r'(?:[a-zA-Z_]\\w*\\s*\\]|'",
            "                             r'(?:[a-zA-Z_]\\w*)?:)')",
            "",
            "    class GeneratedObjectiveCVariant(baselexer):",
            "        \"\"\"",
            "        Implements Objective-C syntax on top of an existing C family lexer.",
            "        \"\"\"",
            "",
            "        tokens = {",
            "            'statements': [",
            "                (r'@\"', String, 'string'),",
            "                (r'@(YES|NO)', Number),",
            "                (r\"@'(\\\\.|\\\\[0-7]{1,3}|\\\\x[a-fA-F0-9]{1,2}|[^\\\\\\'\\n])'\", String.Char),",
            "                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+[lL]?', Number.Float),",
            "                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+[fF])[fF]?', Number.Float),",
            "                (r'@0x[0-9a-fA-F]+[Ll]?', Number.Hex),",
            "                (r'@0[0-7]+[Ll]?', Number.Oct),",
            "                (r'@\\d+[Ll]?', Number.Integer),",
            "                (r'@\\(', Literal, 'literal_number'),",
            "                (r'@\\[', Literal, 'literal_array'),",
            "                (r'@\\{', Literal, 'literal_dictionary'),",
            "                (words((",
            "                    '@selector', '@private', '@protected', '@public', '@encode',",
            "                    '@synchronized', '@try', '@throw', '@catch', '@finally',",
            "                    '@end', '@property', '@synthesize', '__bridge', '__bridge_transfer',",
            "                    '__autoreleasing', '__block', '__weak', '__strong', 'weak', 'strong',",
            "                    'copy', 'retain', 'assign', 'unsafe_unretained', 'atomic', 'nonatomic',",
            "                    'readonly', 'readwrite', 'setter', 'getter', 'typeof', 'in',",
            "                    'out', 'inout', 'release', 'class', '@dynamic', '@optional',",
            "                    '@required', '@autoreleasepool', '@import'), suffix=r'\\b'),",
            "                 Keyword),",
            "                (words(('id', 'instancetype', 'Class', 'IMP', 'SEL', 'BOOL',",
            "                        'IBOutlet', 'IBAction', 'unichar'), suffix=r'\\b'),",
            "                 Keyword.Type),",
            "                (r'@(true|false|YES|NO)\\n', Name.Builtin),",
            "                (r'(YES|NO|nil|self|super)\\b', Name.Builtin),",
            "                # Carbon types",
            "                (r'(Boolean|UInt8|SInt8|UInt16|SInt16|UInt32|SInt32)\\b', Keyword.Type),",
            "                # Carbon built-ins",
            "                (r'(TRUE|FALSE)\\b', Name.Builtin),",
            "                (r'(@interface|@implementation)(\\s+)', bygroups(Keyword, Text),",
            "                 ('#pop', 'oc_classname')),",
            "                (r'(@class|@protocol)(\\s+)', bygroups(Keyword, Text),",
            "                 ('#pop', 'oc_forward_classname')),",
            "                # @ can also prefix other expressions like @{...} or @(...)",
            "                (r'@', Punctuation),",
            "                inherit,",
            "            ],",
            "            'oc_classname': [",
            "                # interface definition that inherits",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Name.Class, Text, Punctuation),",
            "                 ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?',",
            "                 bygroups(Name.Class, Text, Name.Class), '#pop'),",
            "                # interface definition for a category",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Name.Label, Text, Punctuation),",
            "                 ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))',",
            "                 bygroups(Name.Class, Text, Name.Label), '#pop'),",
            "                # simple interface / implementation",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Punctuation), ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)', Name.Class, '#pop')",
            "            ],",
            "            'oc_forward_classname': [",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*,\\s*)',",
            "                 bygroups(Name.Class, Text), 'oc_forward_classname'),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*;?)',",
            "                 bygroups(Name.Class, Text), '#pop')",
            "            ],",
            "            'oc_ivars': [",
            "                include('whitespace'),",
            "                include('statements'),",
            "                (';', Punctuation),",
            "                (r'\\{', Punctuation, '#push'),",
            "                (r'\\}', Punctuation, '#pop'),",
            "            ],",
            "            'root': [",
            "                # methods",
            "                (r'^([-+])(\\s*)'                         # method marker",
            "                 r'(\\(.*?\\))?(\\s*)'                      # return type",
            "                 r'([a-zA-Z$_][\\w$]*:?)',        # begin of method name",
            "                 bygroups(Punctuation, Text, using(this),",
            "                          Text, Name.Function),",
            "                 'method'),",
            "                inherit,",
            "            ],",
            "            'method': [",
            "                include('whitespace'),",
            "                # TODO unsure if ellipses are allowed elsewhere, see",
            "                # discussion in Issue 789",
            "                (r',', Punctuation),",
            "                (r'\\.\\.\\.', Punctuation),",
            "                (r'(\\(.*?\\))(\\s*)([a-zA-Z$_][\\w$]*)',",
            "                 bygroups(using(this), Text, Name.Variable)),",
            "                (r'[a-zA-Z$_][\\w$]*:', Name.Function),",
            "                (';', Punctuation, '#pop'),",
            "                (r'\\{', Punctuation, 'function'),",
            "                default('#pop'),",
            "            ],",
            "            'literal_number': [",
            "                (r'\\(', Punctuation, 'literal_number_inner'),",
            "                (r'\\)', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_number_inner': [",
            "                (r'\\(', Punctuation, '#push'),",
            "                (r'\\)', Punctuation, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_array': [",
            "                (r'\\[', Punctuation, 'literal_array_inner'),",
            "                (r'\\]', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_array_inner': [",
            "                (r'\\[', Punctuation, '#push'),",
            "                (r'\\]', Punctuation, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_dictionary': [",
            "                (r'\\}', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "        }",
            "",
            "        def analyse_text(text):",
            "            if _oc_keywords.search(text):",
            "                return 1.0",
            "            elif '@\"' in text:  # strings",
            "                return 0.8",
            "            elif re.search('@[0-9]+', text):",
            "                return 0.7",
            "            elif _oc_message.search(text):",
            "                return 0.8",
            "            return 0",
            "",
            "        def get_tokens_unprocessed(self, text):",
            "            from pygments.lexers._cocoa_builtins import COCOA_INTERFACES, \\",
            "                COCOA_PROTOCOLS, COCOA_PRIMITIVES",
            "",
            "            for index, token, value in \\",
            "                    baselexer.get_tokens_unprocessed(self, text):",
            "                if token is Name or token is Name.Class:",
            "                    if value in COCOA_INTERFACES or value in COCOA_PROTOCOLS \\",
            "                       or value in COCOA_PRIMITIVES:",
            "                        token = Name.Builtin.Pseudo",
            "",
            "                yield index, token, value",
            "",
            "    return GeneratedObjectiveCVariant",
            "",
            "",
            "class ObjectiveCLexer(objective(CLexer)):",
            "    \"\"\"",
            "    For Objective-C source code with preprocessor directives.",
            "    \"\"\"",
            "",
            "    name = 'Objective-C'",
            "    aliases = ['objective-c', 'objectivec', 'obj-c', 'objc']",
            "    filenames = ['*.m', '*.h']",
            "    mimetypes = ['text/x-objective-c']",
            "    priority = 0.05    # Lower than C",
            "",
            "",
            "class ObjectiveCppLexer(objective(CppLexer)):",
            "    \"\"\"",
            "    For Objective-C++ source code with preprocessor directives.",
            "    \"\"\"",
            "",
            "    name = 'Objective-C++'",
            "    aliases = ['objective-c++', 'objectivec++', 'obj-c++', 'objc++']",
            "    filenames = ['*.mm', '*.hh']",
            "    mimetypes = ['text/x-objective-c++']",
            "    priority = 0.05    # Lower than C++",
            "",
            "",
            "class LogosLexer(ObjectiveCppLexer):",
            "    \"\"\"",
            "    For Logos + Objective-C source code with preprocessor directives.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Logos'",
            "    aliases = ['logos']",
            "    filenames = ['*.x', '*.xi', '*.xm', '*.xmi']",
            "    mimetypes = ['text/x-logos']",
            "    priority = 0.25",
            "",
            "    tokens = {",
            "        'statements': [",
            "            (r'(%orig|%log)\\b', Keyword),",
            "            (r'(%c)\\b(\\()(\\s*)([a-zA-Z$_][\\w$]*)(\\s*)(\\))',",
            "             bygroups(Keyword, Punctuation, Text, Name.Class, Text, Punctuation)),",
            "            (r'(%init)\\b(\\()',",
            "             bygroups(Keyword, Punctuation), 'logos_init_directive'),",
            "            (r'(%init)(?=\\s*;)', bygroups(Keyword)),",
            "            (r'(%hook|%group)(\\s+)([a-zA-Z$_][\\w$]+)',",
            "             bygroups(Keyword, Text, Name.Class), '#pop'),",
            "            (r'(%subclass)(\\s+)', bygroups(Keyword, Text),",
            "             ('#pop', 'logos_classname')),",
            "            inherit,",
            "        ],",
            "        'logos_init_directive': [",
            "            (r'\\s+', Text),",
            "            (',', Punctuation, ('logos_init_directive', '#pop')),",
            "            (r'([a-zA-Z$_][\\w$]*)(\\s*)(=)(\\s*)([^);]*)',",
            "             bygroups(Name.Class, Text, Punctuation, Text, Text)),",
            "            (r'([a-zA-Z$_][\\w$]*)', Name.Class),",
            "            (r'\\)', Punctuation, '#pop'),",
            "        ],",
            "        'logos_classname': [",
            "            (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?',",
            "             bygroups(Name.Class, Text, Name.Class), '#pop'),",
            "            (r'([a-zA-Z$_][\\w$]*)', Name.Class, '#pop')",
            "        ],",
            "        'root': [",
            "            (r'(%subclass)(\\s+)', bygroups(Keyword, Text),",
            "             'logos_classname'),",
            "            (r'(%hook|%group)(\\s+)([a-zA-Z$_][\\w$]+)',",
            "             bygroups(Keyword, Text, Name.Class)),",
            "            (r'(%config)(\\s*\\(\\s*)(\\w+)(\\s*=\\s*)(.*?)(\\s*\\)\\s*)',",
            "             bygroups(Keyword, Text, Name.Variable, Text, String, Text)),",
            "            (r'(%ctor)(\\s*)(\\{)', bygroups(Keyword, Text, Punctuation),",
            "             'function'),",
            "            (r'(%new)(\\s*)(\\()(\\s*.*?\\s*)(\\))',",
            "             bygroups(Keyword, Text, Keyword, String, Keyword)),",
            "            (r'(\\s*)(%end)(\\s*)', bygroups(Text, Keyword, Text)),",
            "            inherit,",
            "        ],",
            "    }",
            "",
            "    _logos_keywords = re.compile(r'%(?:hook|ctor|init|c\\()')",
            "",
            "    def analyse_text(text):",
            "        if LogosLexer._logos_keywords.search(text):",
            "            return 1.0",
            "        return 0",
            "",
            "",
            "class SwiftLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Swift <https://developer.apple.com/swift/>`_ source.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'Swift'",
            "    filenames = ['*.swift']",
            "    aliases = ['swift']",
            "    mimetypes = ['text/x-swift']",
            "",
            "    tokens = {",
            "        'root': [",
            "            # Whitespace and Comments",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'//', Comment.Single, 'comment-single'),",
            "            (r'/\\*', Comment.Multiline, 'comment-multi'),",
            "            (r'#(if|elseif|else|endif|available)\\b', Comment.Preproc, 'preproc'),",
            "",
            "            # Keywords",
            "            include('keywords'),",
            "",
            "            # Global Types",
            "            (words((",
            "                'Array', 'AutoreleasingUnsafeMutablePointer', 'BidirectionalReverseView',",
            "                'Bit', 'Bool', 'CFunctionPointer', 'COpaquePointer', 'CVaListPointer',",
            "                'Character', 'ClosedInterval', 'CollectionOfOne', 'ContiguousArray',",
            "                'Dictionary', 'DictionaryGenerator', 'DictionaryIndex', 'Double',",
            "                'EmptyCollection', 'EmptyGenerator', 'EnumerateGenerator',",
            "                'EnumerateSequence', 'FilterCollectionView',",
            "                'FilterCollectionViewIndex', 'FilterGenerator', 'FilterSequenceView',",
            "                'Float', 'Float80', 'FloatingPointClassification', 'GeneratorOf',",
            "                'GeneratorOfOne', 'GeneratorSequence', 'HalfOpenInterval', 'HeapBuffer',",
            "                'HeapBufferStorage', 'ImplicitlyUnwrappedOptional', 'IndexingGenerator',",
            "                'Int', 'Int16', 'Int32', 'Int64', 'Int8', 'LazyBidirectionalCollection',",
            "                'LazyForwardCollection', 'LazyRandomAccessCollection',",
            "                'LazySequence', 'MapCollectionView', 'MapSequenceGenerator',",
            "                'MapSequenceView', 'MirrorDisposition', 'ObjectIdentifier', 'OnHeap',",
            "                'Optional', 'PermutationGenerator', 'QuickLookObject',",
            "                'RandomAccessReverseView', 'Range', 'RangeGenerator', 'RawByte', 'Repeat',",
            "                'ReverseBidirectionalIndex', 'ReverseRandomAccessIndex', 'SequenceOf',",
            "                'SinkOf', 'Slice', 'StaticString', 'StrideThrough', 'StrideThroughGenerator',",
            "                'StrideTo', 'StrideToGenerator', 'String', 'UInt', 'UInt16', 'UInt32',",
            "                'UInt64', 'UInt8', 'UTF16', 'UTF32', 'UTF8', 'UnicodeDecodingResult',",
            "                'UnicodeScalar', 'Unmanaged', 'UnsafeBufferPointer',",
            "                'UnsafeBufferPointerGenerator', 'UnsafeMutableBufferPointer',",
            "                'UnsafeMutablePointer', 'UnsafePointer', 'Zip2', 'ZipGenerator2',",
            "                # Protocols",
            "                'AbsoluteValuable', 'AnyObject', 'ArrayLiteralConvertible',",
            "                'BidirectionalIndexType', 'BitwiseOperationsType',",
            "                'BooleanLiteralConvertible', 'BooleanType', 'CVarArgType',",
            "                'CollectionType', 'Comparable', 'DebugPrintable',",
            "                'DictionaryLiteralConvertible', 'Equatable',",
            "                'ExtendedGraphemeClusterLiteralConvertible',",
            "                'ExtensibleCollectionType', 'FloatLiteralConvertible',",
            "                'FloatingPointType', 'ForwardIndexType', 'GeneratorType', 'Hashable',",
            "                'IntegerArithmeticType', 'IntegerLiteralConvertible', 'IntegerType',",
            "                'IntervalType', 'MirrorType', 'MutableCollectionType', 'MutableSliceable',",
            "                'NilLiteralConvertible', 'OutputStreamType', 'Printable',",
            "                'RandomAccessIndexType', 'RangeReplaceableCollectionType',",
            "                'RawOptionSetType', 'RawRepresentable', 'Reflectable', 'SequenceType',",
            "                'SignedIntegerType', 'SignedNumberType', 'SinkType', 'Sliceable',",
            "                'Streamable', 'Strideable', 'StringInterpolationConvertible',",
            "                'StringLiteralConvertible', 'UnicodeCodecType',",
            "                'UnicodeScalarLiteralConvertible', 'UnsignedIntegerType',",
            "                '_ArrayBufferType', '_BidirectionalIndexType', '_CocoaStringType',",
            "                '_CollectionType', '_Comparable', '_ExtensibleCollectionType',",
            "                '_ForwardIndexType', '_Incrementable', '_IntegerArithmeticType',",
            "                '_IntegerType', '_ObjectiveCBridgeable', '_RandomAccessIndexType',",
            "                '_RawOptionSetType', '_SequenceType', '_Sequence_Type',",
            "                '_SignedIntegerType', '_SignedNumberType', '_Sliceable', '_Strideable',",
            "                '_SwiftNSArrayRequiredOverridesType', '_SwiftNSArrayType',",
            "                '_SwiftNSCopyingType', '_SwiftNSDictionaryRequiredOverridesType',",
            "                '_SwiftNSDictionaryType', '_SwiftNSEnumeratorType',",
            "                '_SwiftNSFastEnumerationType', '_SwiftNSStringRequiredOverridesType',",
            "                '_SwiftNSStringType', '_UnsignedIntegerType',",
            "                # Variables",
            "                'C_ARGC', 'C_ARGV', 'Process',",
            "                # Typealiases",
            "                'Any', 'AnyClass', 'BooleanLiteralType', 'CBool', 'CChar', 'CChar16',",
            "                'CChar32', 'CDouble', 'CFloat', 'CInt', 'CLong', 'CLongLong', 'CShort',",
            "                'CSignedChar', 'CUnsignedInt', 'CUnsignedLong', 'CUnsignedShort',",
            "                'CWideChar', 'ExtendedGraphemeClusterType', 'Float32', 'Float64',",
            "                'FloatLiteralType', 'IntMax', 'IntegerLiteralType', 'StringLiteralType',",
            "                'UIntMax', 'UWord', 'UnicodeScalarType', 'Void', 'Word',",
            "                # Foundation/Cocoa",
            "                'NSErrorPointer', 'NSObjectProtocol', 'Selector'), suffix=r'\\b'),",
            "             Name.Builtin),",
            "            # Functions",
            "            (words((",
            "                'abs', 'advance', 'alignof', 'alignofValue', 'assert', 'assertionFailure',",
            "                'contains', 'count', 'countElements', 'debugPrint', 'debugPrintln',",
            "                'distance', 'dropFirst', 'dropLast', 'dump', 'enumerate', 'equal',",
            "                'extend', 'fatalError', 'filter', 'find', 'first', 'getVaList', 'indices',",
            "                'insert', 'isEmpty', 'join', 'last', 'lazy', 'lexicographicalCompare',",
            "                'map', 'max', 'maxElement', 'min', 'minElement', 'numericCast', 'overlaps',",
            "                'partition', 'precondition', 'preconditionFailure', 'prefix', 'print',",
            "                'println', 'reduce', 'reflect', 'removeAll', 'removeAtIndex', 'removeLast',",
            "                'removeRange', 'reverse', 'sizeof', 'sizeofValue', 'sort', 'sorted',",
            "                'splice', 'split', 'startsWith', 'stride', 'strideof', 'strideofValue',",
            "                'suffix', 'swap', 'toDebugString', 'toString', 'transcode',",
            "                'underestimateCount', 'unsafeAddressOf', 'unsafeBitCast', 'unsafeDowncast',",
            "                'withExtendedLifetime', 'withUnsafeMutablePointer',",
            "                'withUnsafeMutablePointers', 'withUnsafePointer', 'withUnsafePointers',",
            "                'withVaList'), suffix=r'\\b'),",
            "             Name.Builtin.Pseudo),",
            "",
            "            # Implicit Block Variables",
            "            (r'\\$\\d+', Name.Variable),",
            "",
            "            # Binary Literal",
            "            (r'0b[01_]+', Number.Bin),",
            "            # Octal Literal",
            "            (r'0o[0-7_]+', Number.Oct),",
            "            # Hexadecimal Literal",
            "            (r'0x[0-9a-fA-F_]+', Number.Hex),",
            "            # Decimal Literal",
            "            (r'[0-9][0-9_]*(\\.[0-9_]+[eE][+\\-]?[0-9_]+|'",
            "             r'\\.[0-9_]*|[eE][+\\-]?[0-9_]+)', Number.Float),",
            "            (r'[0-9][0-9_]*', Number.Integer),",
            "            # String Literal",
            "            (r'\"', String, 'string'),",
            "",
            "            # Operators and Punctuation",
            "            (r'[(){}\\[\\].,:;=@#`?]|->|[<&?](?=\\w)|(?<=\\w)[>!?]', Punctuation),",
            "            (r'[/=\\-+!*%<>&|^?~]+', Operator),",
            "",
            "            # Identifier",
            "            (r'[a-zA-Z_]\\w*', Name)",
            "        ],",
            "        'keywords': [",
            "            (words((",
            "                'as', 'break', 'case', 'catch', 'continue', 'default', 'defer',",
            "                'do', 'else', 'fallthrough', 'for', 'guard', 'if', 'in', 'is',",
            "                'repeat', 'return', '#selector', 'switch', 'throw', 'try',",
            "                'where', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "            (r'@availability\\([^)]+\\)', Keyword.Reserved),",
            "            (words((",
            "                'associativity', 'convenience', 'dynamic', 'didSet', 'final',",
            "                'get', 'indirect', 'infix', 'inout', 'lazy', 'left', 'mutating',",
            "                'none', 'nonmutating', 'optional', 'override', 'postfix',",
            "                'precedence', 'prefix', 'Protocol', 'required', 'rethrows',",
            "                'right', 'set', 'throws', 'Type', 'unowned', 'weak', 'willSet',",
            "                '@availability', '@autoclosure', '@noreturn',",
            "                '@NSApplicationMain', '@NSCopying', '@NSManaged', '@objc',",
            "                '@UIApplicationMain', '@IBAction', '@IBDesignable',",
            "                '@IBInspectable', '@IBOutlet'), suffix=r'\\b'),",
            "             Keyword.Reserved),",
            "            (r'(as|dynamicType|false|is|nil|self|Self|super|true|__COLUMN__'",
            "             r'|__FILE__|__FUNCTION__|__LINE__|_'",
            "             r'|#(?:file|line|column|function))\\b', Keyword.Constant),",
            "            (r'import\\b', Keyword.Declaration, 'module'),",
            "            (r'(class|enum|extension|struct|protocol)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Class)),",
            "            (r'(func)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Function)),",
            "            (r'(var|let)(\\s+)([a-zA-Z_]\\w*)', bygroups(Keyword.Declaration,",
            "             Text, Name.Variable)),",
            "            (words((",
            "                'class', 'deinit', 'enum', 'extension', 'func', 'import', 'init',",
            "                'internal', 'let', 'operator', 'private', 'protocol', 'public',",
            "                'static', 'struct', 'subscript', 'typealias', 'var'), suffix=r'\\b'),",
            "             Keyword.Declaration)",
            "        ],",
            "        'comment': [",
            "            (r':param: [a-zA-Z_]\\w*|:returns?:|(FIXME|MARK|TODO):',",
            "             Comment.Special)",
            "        ],",
            "",
            "        # Nested",
            "        'comment-single': [",
            "            (r'\\n', Text, '#pop'),",
            "            include('comment'),",
            "            (r'[^\\n]', Comment.Single)",
            "        ],",
            "        'comment-multi': [",
            "            include('comment'),",
            "            (r'[^*/]', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "        'module': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r'[a-zA-Z_]\\w*', Name.Class),",
            "            include('root')",
            "        ],",
            "        'preproc': [",
            "            (r'\\n', Text, '#pop'),",
            "            include('keywords'),",
            "            (r'[A-Za-z]\\w*', Comment.Preproc),",
            "            include('root')",
            "        ],",
            "        'string': [",
            "            (r'\\\\\\(', String.Interpol, 'string-intp'),",
            "            (r'\"', String, '#pop'),",
            "            (r\"\"\"\\\\['\"\\\\nrt]|\\\\x[0-9a-fA-F]{2}|\\\\[0-7]{1,3}\"\"\"",
            "             r\"\"\"|\\\\u[0-9a-fA-F]{4}|\\\\U[0-9a-fA-F]{8}\"\"\", String.Escape),",
            "            (r'[^\\\\\"]+', String),",
            "            (r'\\\\', String)",
            "        ],",
            "        'string-intp': [",
            "            (r'\\(', String.Interpol, '#push'),",
            "            (r'\\)', String.Interpol, '#pop'),",
            "            include('root')",
            "        ]",
            "    }",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        from pygments.lexers._cocoa_builtins import COCOA_INTERFACES, \\",
            "            COCOA_PROTOCOLS, COCOA_PRIMITIVES",
            "",
            "        for index, token, value in \\",
            "                RegexLexer.get_tokens_unprocessed(self, text):",
            "            if token is Name or token is Name.Class:",
            "                if value in COCOA_INTERFACES or value in COCOA_PROTOCOLS \\",
            "                   or value in COCOA_PRIMITIVES:",
            "                    token = Name.Builtin.Pseudo",
            "",
            "            yield index, token, value"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.objective",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Objective-C family languages.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, this, words, \\",
            "    inherit, default",
            "from pygments.token import Text, Keyword, Name, String, Operator, \\",
            "    Number, Punctuation, Literal, Comment",
            "",
            "from pygments.lexers.c_cpp import CLexer, CppLexer",
            "",
            "__all__ = ['ObjectiveCLexer', 'ObjectiveCppLexer', 'LogosLexer', 'SwiftLexer']",
            "",
            "",
            "def objective(baselexer):",
            "    \"\"\"",
            "    Generate a subclass of baselexer that accepts the Objective-C syntax",
            "    extensions.",
            "    \"\"\"",
            "",
            "    # Have to be careful not to accidentally match JavaDoc/Doxygen syntax here,",
            "    # since that's quite common in ordinary C/C++ files.  It's OK to match",
            "    # JavaDoc/Doxygen keywords that only apply to Objective-C, mind.",
            "    #",
            "    # The upshot of this is that we CANNOT match @class or @interface",
            "    _oc_keywords = re.compile(r'@(?:end|implementation|protocol)')",
            "",
            "    # Matches [ <ws>? identifier <ws> ( identifier <ws>? ] |  identifier? : )",
            "    # (note the identifier is *optional* when there is a ':'!)",
            "    _oc_message = re.compile(r'\\[\\s*[a-zA-Z_]\\w*\\s+'",
            "                             r'(?:[a-zA-Z_]\\w*\\s*\\]|'",
            "                             r'(?:[a-zA-Z_]\\w*)?:)')",
            "",
            "    class GeneratedObjectiveCVariant(baselexer):",
            "        \"\"\"",
            "        Implements Objective-C syntax on top of an existing C family lexer.",
            "        \"\"\"",
            "",
            "        tokens = {",
            "            'statements': [",
            "                (r'@\"', String, 'string'),",
            "                (r'@(YES|NO)', Number),",
            "                (r\"@'(\\\\.|\\\\[0-7]{1,3}|\\\\x[a-fA-F0-9]{1,2}|[^\\\\\\'\\n])'\", String.Char),",
            "                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+[lL]?', Number.Float),",
            "                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+[fF])[fF]?', Number.Float),",
            "                (r'@0x[0-9a-fA-F]+[Ll]?', Number.Hex),",
            "                (r'@0[0-7]+[Ll]?', Number.Oct),",
            "                (r'@\\d+[Ll]?', Number.Integer),",
            "                (r'@\\(', Literal, 'literal_number'),",
            "                (r'@\\[', Literal, 'literal_array'),",
            "                (r'@\\{', Literal, 'literal_dictionary'),",
            "                (words((",
            "                    '@selector', '@private', '@protected', '@public', '@encode',",
            "                    '@synchronized', '@try', '@throw', '@catch', '@finally',",
            "                    '@end', '@property', '@synthesize', '__bridge', '__bridge_transfer',",
            "                    '__autoreleasing', '__block', '__weak', '__strong', 'weak', 'strong',",
            "                    'copy', 'retain', 'assign', 'unsafe_unretained', 'atomic', 'nonatomic',",
            "                    'readonly', 'readwrite', 'setter', 'getter', 'typeof', 'in',",
            "                    'out', 'inout', 'release', 'class', '@dynamic', '@optional',",
            "                    '@required', '@autoreleasepool', '@import'), suffix=r'\\b'),",
            "                 Keyword),",
            "                (words(('id', 'instancetype', 'Class', 'IMP', 'SEL', 'BOOL',",
            "                        'IBOutlet', 'IBAction', 'unichar'), suffix=r'\\b'),",
            "                 Keyword.Type),",
            "                (r'@(true|false|YES|NO)\\n', Name.Builtin),",
            "                (r'(YES|NO|nil|self|super)\\b', Name.Builtin),",
            "                # Carbon types",
            "                (r'(Boolean|UInt8|SInt8|UInt16|SInt16|UInt32|SInt32)\\b', Keyword.Type),",
            "                # Carbon built-ins",
            "                (r'(TRUE|FALSE)\\b', Name.Builtin),",
            "                (r'(@interface|@implementation)(\\s+)', bygroups(Keyword, Text),",
            "                 ('#pop', 'oc_classname')),",
            "                (r'(@class|@protocol)(\\s+)', bygroups(Keyword, Text),",
            "                 ('#pop', 'oc_forward_classname')),",
            "                # @ can also prefix other expressions like @{...} or @(...)",
            "                (r'@', Punctuation),",
            "                inherit,",
            "            ],",
            "            'oc_classname': [",
            "                # interface definition that inherits",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Name.Class, Text, Punctuation),",
            "                 ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?',",
            "                 bygroups(Name.Class, Text, Name.Class), '#pop'),",
            "                # interface definition for a category",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Name.Label, Text, Punctuation),",
            "                 ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))',",
            "                 bygroups(Name.Class, Text, Name.Label), '#pop'),",
            "                # simple interface / implementation",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*)(\\{)',",
            "                 bygroups(Name.Class, Text, Punctuation), ('#pop', 'oc_ivars')),",
            "                (r'([a-zA-Z$_][\\w$]*)', Name.Class, '#pop')",
            "            ],",
            "            'oc_forward_classname': [",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*,\\s*)',",
            "                 bygroups(Name.Class, Text), 'oc_forward_classname'),",
            "                (r'([a-zA-Z$_][\\w$]*)(\\s*;?)',",
            "                 bygroups(Name.Class, Text), '#pop')",
            "            ],",
            "            'oc_ivars': [",
            "                include('whitespace'),",
            "                include('statements'),",
            "                (';', Punctuation),",
            "                (r'\\{', Punctuation, '#push'),",
            "                (r'\\}', Punctuation, '#pop'),",
            "            ],",
            "            'root': [",
            "                # methods",
            "                (r'^([-+])(\\s*)'                         # method marker",
            "                 r'(\\(.*?\\))?(\\s*)'                      # return type",
            "                 r'([a-zA-Z$_][\\w$]*:?)',        # begin of method name",
            "                 bygroups(Punctuation, Text, using(this),",
            "                          Text, Name.Function),",
            "                 'method'),",
            "                inherit,",
            "            ],",
            "            'method': [",
            "                include('whitespace'),",
            "                # TODO unsure if ellipses are allowed elsewhere, see",
            "                # discussion in Issue 789",
            "                (r',', Punctuation),",
            "                (r'\\.\\.\\.', Punctuation),",
            "                (r'(\\(.*?\\))(\\s*)([a-zA-Z$_][\\w$]*)',",
            "                 bygroups(using(this), Text, Name.Variable)),",
            "                (r'[a-zA-Z$_][\\w$]*:', Name.Function),",
            "                (';', Punctuation, '#pop'),",
            "                (r'\\{', Punctuation, 'function'),",
            "                default('#pop'),",
            "            ],",
            "            'literal_number': [",
            "                (r'\\(', Punctuation, 'literal_number_inner'),",
            "                (r'\\)', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_number_inner': [",
            "                (r'\\(', Punctuation, '#push'),",
            "                (r'\\)', Punctuation, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_array': [",
            "                (r'\\[', Punctuation, 'literal_array_inner'),",
            "                (r'\\]', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_array_inner': [",
            "                (r'\\[', Punctuation, '#push'),",
            "                (r'\\]', Punctuation, '#pop'),",
            "                include('statement'),",
            "            ],",
            "            'literal_dictionary': [",
            "                (r'\\}', Literal, '#pop'),",
            "                include('statement'),",
            "            ],",
            "        }",
            "",
            "        def analyse_text(text):",
            "            if _oc_keywords.search(text):",
            "                return 1.0",
            "            elif '@\"' in text:  # strings",
            "                return 0.8",
            "            elif re.search('@[0-9]+', text):",
            "                return 0.7",
            "            elif _oc_message.search(text):",
            "                return 0.8",
            "            return 0",
            "",
            "        def get_tokens_unprocessed(self, text):",
            "            from pygments.lexers._cocoa_builtins import COCOA_INTERFACES, \\",
            "                COCOA_PROTOCOLS, COCOA_PRIMITIVES",
            "",
            "            for index, token, value in \\",
            "                    baselexer.get_tokens_unprocessed(self, text):",
            "                if token is Name or token is Name.Class:",
            "                    if value in COCOA_INTERFACES or value in COCOA_PROTOCOLS \\",
            "                       or value in COCOA_PRIMITIVES:",
            "                        token = Name.Builtin.Pseudo",
            "",
            "                yield index, token, value",
            "",
            "    return GeneratedObjectiveCVariant",
            "",
            "",
            "class ObjectiveCLexer(objective(CLexer)):",
            "    \"\"\"",
            "    For Objective-C source code with preprocessor directives.",
            "    \"\"\"",
            "",
            "    name = 'Objective-C'",
            "    aliases = ['objective-c', 'objectivec', 'obj-c', 'objc']",
            "    filenames = ['*.m', '*.h']",
            "    mimetypes = ['text/x-objective-c']",
            "    priority = 0.05    # Lower than C",
            "",
            "",
            "class ObjectiveCppLexer(objective(CppLexer)):",
            "    \"\"\"",
            "    For Objective-C++ source code with preprocessor directives.",
            "    \"\"\"",
            "",
            "    name = 'Objective-C++'",
            "    aliases = ['objective-c++', 'objectivec++', 'obj-c++', 'objc++']",
            "    filenames = ['*.mm', '*.hh']",
            "    mimetypes = ['text/x-objective-c++']",
            "    priority = 0.05    # Lower than C++",
            "",
            "",
            "class LogosLexer(ObjectiveCppLexer):",
            "    \"\"\"",
            "    For Logos + Objective-C source code with preprocessor directives.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'Logos'",
            "    aliases = ['logos']",
            "    filenames = ['*.x', '*.xi', '*.xm', '*.xmi']",
            "    mimetypes = ['text/x-logos']",
            "    priority = 0.25",
            "",
            "    tokens = {",
            "        'statements': [",
            "            (r'(%orig|%log)\\b', Keyword),",
            "            (r'(%c)\\b(\\()(\\s*)([a-zA-Z$_][\\w$]*)(\\s*)(\\))',",
            "             bygroups(Keyword, Punctuation, Text, Name.Class, Text, Punctuation)),",
            "            (r'(%init)\\b(\\()',",
            "             bygroups(Keyword, Punctuation), 'logos_init_directive'),",
            "            (r'(%init)(?=\\s*;)', bygroups(Keyword)),",
            "            (r'(%hook|%group)(\\s+)([a-zA-Z$_][\\w$]+)',",
            "             bygroups(Keyword, Text, Name.Class), '#pop'),",
            "            (r'(%subclass)(\\s+)', bygroups(Keyword, Text),",
            "             ('#pop', 'logos_classname')),",
            "            inherit,",
            "        ],",
            "        'logos_init_directive': [",
            "            (r'\\s+', Text),",
            "            (',', Punctuation, ('logos_init_directive', '#pop')),",
            "            (r'([a-zA-Z$_][\\w$]*)(\\s*)(=)(\\s*)([^);]*)',",
            "             bygroups(Name.Class, Text, Punctuation, Text, Text)),",
            "            (r'([a-zA-Z$_][\\w$]*)', Name.Class),",
            "            (r'\\)', Punctuation, '#pop'),",
            "        ],",
            "        'logos_classname': [",
            "            (r'([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?',",
            "             bygroups(Name.Class, Text, Name.Class), '#pop'),",
            "            (r'([a-zA-Z$_][\\w$]*)', Name.Class, '#pop')",
            "        ],",
            "        'root': [",
            "            (r'(%subclass)(\\s+)', bygroups(Keyword, Text),",
            "             'logos_classname'),",
            "            (r'(%hook|%group)(\\s+)([a-zA-Z$_][\\w$]+)',",
            "             bygroups(Keyword, Text, Name.Class)),",
            "            (r'(%config)(\\s*\\(\\s*)(\\w+)(\\s*=)(.*?)(\\)\\s*)',",
            "             bygroups(Keyword, Text, Name.Variable, Text, String, Text)),",
            "            (r'(%ctor)(\\s*)(\\{)', bygroups(Keyword, Text, Punctuation),",
            "             'function'),",
            "            (r'(%new)(\\s*)(\\()(.*?)(\\))',",
            "             bygroups(Keyword, Text, Keyword, String, Keyword)),",
            "            (r'(\\s*)(%end)(\\s*)', bygroups(Text, Keyword, Text)),",
            "            inherit,",
            "        ],",
            "    }",
            "",
            "    _logos_keywords = re.compile(r'%(?:hook|ctor|init|c\\()')",
            "",
            "    def analyse_text(text):",
            "        if LogosLexer._logos_keywords.search(text):",
            "            return 1.0",
            "        return 0",
            "",
            "",
            "class SwiftLexer(RegexLexer):",
            "    \"\"\"",
            "    For `Swift <https://developer.apple.com/swift/>`_ source.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'Swift'",
            "    filenames = ['*.swift']",
            "    aliases = ['swift']",
            "    mimetypes = ['text/x-swift']",
            "",
            "    tokens = {",
            "        'root': [",
            "            # Whitespace and Comments",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'//', Comment.Single, 'comment-single'),",
            "            (r'/\\*', Comment.Multiline, 'comment-multi'),",
            "            (r'#(if|elseif|else|endif|available)\\b', Comment.Preproc, 'preproc'),",
            "",
            "            # Keywords",
            "            include('keywords'),",
            "",
            "            # Global Types",
            "            (words((",
            "                'Array', 'AutoreleasingUnsafeMutablePointer', 'BidirectionalReverseView',",
            "                'Bit', 'Bool', 'CFunctionPointer', 'COpaquePointer', 'CVaListPointer',",
            "                'Character', 'ClosedInterval', 'CollectionOfOne', 'ContiguousArray',",
            "                'Dictionary', 'DictionaryGenerator', 'DictionaryIndex', 'Double',",
            "                'EmptyCollection', 'EmptyGenerator', 'EnumerateGenerator',",
            "                'EnumerateSequence', 'FilterCollectionView',",
            "                'FilterCollectionViewIndex', 'FilterGenerator', 'FilterSequenceView',",
            "                'Float', 'Float80', 'FloatingPointClassification', 'GeneratorOf',",
            "                'GeneratorOfOne', 'GeneratorSequence', 'HalfOpenInterval', 'HeapBuffer',",
            "                'HeapBufferStorage', 'ImplicitlyUnwrappedOptional', 'IndexingGenerator',",
            "                'Int', 'Int16', 'Int32', 'Int64', 'Int8', 'LazyBidirectionalCollection',",
            "                'LazyForwardCollection', 'LazyRandomAccessCollection',",
            "                'LazySequence', 'MapCollectionView', 'MapSequenceGenerator',",
            "                'MapSequenceView', 'MirrorDisposition', 'ObjectIdentifier', 'OnHeap',",
            "                'Optional', 'PermutationGenerator', 'QuickLookObject',",
            "                'RandomAccessReverseView', 'Range', 'RangeGenerator', 'RawByte', 'Repeat',",
            "                'ReverseBidirectionalIndex', 'ReverseRandomAccessIndex', 'SequenceOf',",
            "                'SinkOf', 'Slice', 'StaticString', 'StrideThrough', 'StrideThroughGenerator',",
            "                'StrideTo', 'StrideToGenerator', 'String', 'UInt', 'UInt16', 'UInt32',",
            "                'UInt64', 'UInt8', 'UTF16', 'UTF32', 'UTF8', 'UnicodeDecodingResult',",
            "                'UnicodeScalar', 'Unmanaged', 'UnsafeBufferPointer',",
            "                'UnsafeBufferPointerGenerator', 'UnsafeMutableBufferPointer',",
            "                'UnsafeMutablePointer', 'UnsafePointer', 'Zip2', 'ZipGenerator2',",
            "                # Protocols",
            "                'AbsoluteValuable', 'AnyObject', 'ArrayLiteralConvertible',",
            "                'BidirectionalIndexType', 'BitwiseOperationsType',",
            "                'BooleanLiteralConvertible', 'BooleanType', 'CVarArgType',",
            "                'CollectionType', 'Comparable', 'DebugPrintable',",
            "                'DictionaryLiteralConvertible', 'Equatable',",
            "                'ExtendedGraphemeClusterLiteralConvertible',",
            "                'ExtensibleCollectionType', 'FloatLiteralConvertible',",
            "                'FloatingPointType', 'ForwardIndexType', 'GeneratorType', 'Hashable',",
            "                'IntegerArithmeticType', 'IntegerLiteralConvertible', 'IntegerType',",
            "                'IntervalType', 'MirrorType', 'MutableCollectionType', 'MutableSliceable',",
            "                'NilLiteralConvertible', 'OutputStreamType', 'Printable',",
            "                'RandomAccessIndexType', 'RangeReplaceableCollectionType',",
            "                'RawOptionSetType', 'RawRepresentable', 'Reflectable', 'SequenceType',",
            "                'SignedIntegerType', 'SignedNumberType', 'SinkType', 'Sliceable',",
            "                'Streamable', 'Strideable', 'StringInterpolationConvertible',",
            "                'StringLiteralConvertible', 'UnicodeCodecType',",
            "                'UnicodeScalarLiteralConvertible', 'UnsignedIntegerType',",
            "                '_ArrayBufferType', '_BidirectionalIndexType', '_CocoaStringType',",
            "                '_CollectionType', '_Comparable', '_ExtensibleCollectionType',",
            "                '_ForwardIndexType', '_Incrementable', '_IntegerArithmeticType',",
            "                '_IntegerType', '_ObjectiveCBridgeable', '_RandomAccessIndexType',",
            "                '_RawOptionSetType', '_SequenceType', '_Sequence_Type',",
            "                '_SignedIntegerType', '_SignedNumberType', '_Sliceable', '_Strideable',",
            "                '_SwiftNSArrayRequiredOverridesType', '_SwiftNSArrayType',",
            "                '_SwiftNSCopyingType', '_SwiftNSDictionaryRequiredOverridesType',",
            "                '_SwiftNSDictionaryType', '_SwiftNSEnumeratorType',",
            "                '_SwiftNSFastEnumerationType', '_SwiftNSStringRequiredOverridesType',",
            "                '_SwiftNSStringType', '_UnsignedIntegerType',",
            "                # Variables",
            "                'C_ARGC', 'C_ARGV', 'Process',",
            "                # Typealiases",
            "                'Any', 'AnyClass', 'BooleanLiteralType', 'CBool', 'CChar', 'CChar16',",
            "                'CChar32', 'CDouble', 'CFloat', 'CInt', 'CLong', 'CLongLong', 'CShort',",
            "                'CSignedChar', 'CUnsignedInt', 'CUnsignedLong', 'CUnsignedShort',",
            "                'CWideChar', 'ExtendedGraphemeClusterType', 'Float32', 'Float64',",
            "                'FloatLiteralType', 'IntMax', 'IntegerLiteralType', 'StringLiteralType',",
            "                'UIntMax', 'UWord', 'UnicodeScalarType', 'Void', 'Word',",
            "                # Foundation/Cocoa",
            "                'NSErrorPointer', 'NSObjectProtocol', 'Selector'), suffix=r'\\b'),",
            "             Name.Builtin),",
            "            # Functions",
            "            (words((",
            "                'abs', 'advance', 'alignof', 'alignofValue', 'assert', 'assertionFailure',",
            "                'contains', 'count', 'countElements', 'debugPrint', 'debugPrintln',",
            "                'distance', 'dropFirst', 'dropLast', 'dump', 'enumerate', 'equal',",
            "                'extend', 'fatalError', 'filter', 'find', 'first', 'getVaList', 'indices',",
            "                'insert', 'isEmpty', 'join', 'last', 'lazy', 'lexicographicalCompare',",
            "                'map', 'max', 'maxElement', 'min', 'minElement', 'numericCast', 'overlaps',",
            "                'partition', 'precondition', 'preconditionFailure', 'prefix', 'print',",
            "                'println', 'reduce', 'reflect', 'removeAll', 'removeAtIndex', 'removeLast',",
            "                'removeRange', 'reverse', 'sizeof', 'sizeofValue', 'sort', 'sorted',",
            "                'splice', 'split', 'startsWith', 'stride', 'strideof', 'strideofValue',",
            "                'suffix', 'swap', 'toDebugString', 'toString', 'transcode',",
            "                'underestimateCount', 'unsafeAddressOf', 'unsafeBitCast', 'unsafeDowncast',",
            "                'withExtendedLifetime', 'withUnsafeMutablePointer',",
            "                'withUnsafeMutablePointers', 'withUnsafePointer', 'withUnsafePointers',",
            "                'withVaList'), suffix=r'\\b'),",
            "             Name.Builtin.Pseudo),",
            "",
            "            # Implicit Block Variables",
            "            (r'\\$\\d+', Name.Variable),",
            "",
            "            # Binary Literal",
            "            (r'0b[01_]+', Number.Bin),",
            "            # Octal Literal",
            "            (r'0o[0-7_]+', Number.Oct),",
            "            # Hexadecimal Literal",
            "            (r'0x[0-9a-fA-F_]+', Number.Hex),",
            "            # Decimal Literal",
            "            (r'[0-9][0-9_]*(\\.[0-9_]+[eE][+\\-]?[0-9_]+|'",
            "             r'\\.[0-9_]*|[eE][+\\-]?[0-9_]+)', Number.Float),",
            "            (r'[0-9][0-9_]*', Number.Integer),",
            "            # String Literal",
            "            (r'\"', String, 'string'),",
            "",
            "            # Operators and Punctuation",
            "            (r'[(){}\\[\\].,:;=@#`?]|->|[<&?](?=\\w)|(?<=\\w)[>!?]', Punctuation),",
            "            (r'[/=\\-+!*%<>&|^?~]+', Operator),",
            "",
            "            # Identifier",
            "            (r'[a-zA-Z_]\\w*', Name)",
            "        ],",
            "        'keywords': [",
            "            (words((",
            "                'as', 'break', 'case', 'catch', 'continue', 'default', 'defer',",
            "                'do', 'else', 'fallthrough', 'for', 'guard', 'if', 'in', 'is',",
            "                'repeat', 'return', '#selector', 'switch', 'throw', 'try',",
            "                'where', 'while'), suffix=r'\\b'),",
            "             Keyword),",
            "            (r'@availability\\([^)]+\\)', Keyword.Reserved),",
            "            (words((",
            "                'associativity', 'convenience', 'dynamic', 'didSet', 'final',",
            "                'get', 'indirect', 'infix', 'inout', 'lazy', 'left', 'mutating',",
            "                'none', 'nonmutating', 'optional', 'override', 'postfix',",
            "                'precedence', 'prefix', 'Protocol', 'required', 'rethrows',",
            "                'right', 'set', 'throws', 'Type', 'unowned', 'weak', 'willSet',",
            "                '@availability', '@autoclosure', '@noreturn',",
            "                '@NSApplicationMain', '@NSCopying', '@NSManaged', '@objc',",
            "                '@UIApplicationMain', '@IBAction', '@IBDesignable',",
            "                '@IBInspectable', '@IBOutlet'), suffix=r'\\b'),",
            "             Keyword.Reserved),",
            "            (r'(as|dynamicType|false|is|nil|self|Self|super|true|__COLUMN__'",
            "             r'|__FILE__|__FUNCTION__|__LINE__|_'",
            "             r'|#(?:file|line|column|function))\\b', Keyword.Constant),",
            "            (r'import\\b', Keyword.Declaration, 'module'),",
            "            (r'(class|enum|extension|struct|protocol)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Class)),",
            "            (r'(func)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword.Declaration, Text, Name.Function)),",
            "            (r'(var|let)(\\s+)([a-zA-Z_]\\w*)', bygroups(Keyword.Declaration,",
            "             Text, Name.Variable)),",
            "            (words((",
            "                'class', 'deinit', 'enum', 'extension', 'func', 'import', 'init',",
            "                'internal', 'let', 'operator', 'private', 'protocol', 'public',",
            "                'static', 'struct', 'subscript', 'typealias', 'var'), suffix=r'\\b'),",
            "             Keyword.Declaration)",
            "        ],",
            "        'comment': [",
            "            (r':param: [a-zA-Z_]\\w*|:returns?:|(FIXME|MARK|TODO):',",
            "             Comment.Special)",
            "        ],",
            "",
            "        # Nested",
            "        'comment-single': [",
            "            (r'\\n', Text, '#pop'),",
            "            include('comment'),",
            "            (r'[^\\n]', Comment.Single)",
            "        ],",
            "        'comment-multi': [",
            "            include('comment'),",
            "            (r'[^*/]', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline)",
            "        ],",
            "        'module': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r'[a-zA-Z_]\\w*', Name.Class),",
            "            include('root')",
            "        ],",
            "        'preproc': [",
            "            (r'\\n', Text, '#pop'),",
            "            include('keywords'),",
            "            (r'[A-Za-z]\\w*', Comment.Preproc),",
            "            include('root')",
            "        ],",
            "        'string': [",
            "            (r'\\\\\\(', String.Interpol, 'string-intp'),",
            "            (r'\"', String, '#pop'),",
            "            (r\"\"\"\\\\['\"\\\\nrt]|\\\\x[0-9a-fA-F]{2}|\\\\[0-7]{1,3}\"\"\"",
            "             r\"\"\"|\\\\u[0-9a-fA-F]{4}|\\\\U[0-9a-fA-F]{8}\"\"\", String.Escape),",
            "            (r'[^\\\\\"]+', String),",
            "            (r'\\\\', String)",
            "        ],",
            "        'string-intp': [",
            "            (r'\\(', String.Interpol, '#push'),",
            "            (r'\\)', String.Interpol, '#pop'),",
            "            include('root')",
            "        ]",
            "    }",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        from pygments.lexers._cocoa_builtins import COCOA_INTERFACES, \\",
            "            COCOA_PROTOCOLS, COCOA_PRIMITIVES",
            "",
            "        for index, token, value in \\",
            "                RegexLexer.get_tokens_unprocessed(self, text):",
            "            if token is Name or token is Name.Class:",
            "                if value in COCOA_INTERFACES or value in COCOA_PROTOCOLS \\",
            "                   or value in COCOA_PRIMITIVES:",
            "                    token = Name.Builtin.Pseudo",
            "",
            "            yield index, token, value"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "264": [
                "LogosLexer"
            ],
            "268": [
                "LogosLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/templates.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1405,
                "afterPatchRowNumber": 1405,
                "PatchRowcode": "             # see doc for handling first name arg: /directives/evoque/"
            },
            "1": {
                "beforePatchRowNumber": 1406,
                "afterPatchRowNumber": 1406,
                "PatchRowcode": "             # + minor inconsistency: the \"name\" in e.g. $overlay{name=site_base}"
            },
            "2": {
                "beforePatchRowNumber": 1407,
                "afterPatchRowNumber": 1407,
                "PatchRowcode": "             # should be using(PythonLexer), not passed out as String"
            },
            "3": {
                "beforePatchRowNumber": 1408,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\$)(evoque|overlay)(\\{(%)?)(\\s*[#\\w\\-\"\\'.]+[^=,%}]+?)?'"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1408,
                "PatchRowcode": "+            (r'(\\$)(evoque|overlay)(\\{(%)?)(\\s*[#\\w\\-\"\\'.]+)?'"
            },
            "5": {
                "beforePatchRowNumber": 1409,
                "afterPatchRowNumber": 1409,
                "PatchRowcode": "              r'(.*?)((?(4)%)\\})',"
            },
            "6": {
                "beforePatchRowNumber": 1410,
                "afterPatchRowNumber": 1410,
                "PatchRowcode": "              bygroups(Punctuation, Name.Builtin, Punctuation, None,"
            },
            "7": {
                "beforePatchRowNumber": 1411,
                "afterPatchRowNumber": 1411,
                "PatchRowcode": "                       String, using(PythonLexer), Punctuation)),"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.templates",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for various template engines' markup.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexers.html import HtmlLexer, XmlLexer",
            "from pygments.lexers.javascript import JavascriptLexer, LassoLexer",
            "from pygments.lexers.css import CssLexer",
            "from pygments.lexers.php import PhpLexer",
            "from pygments.lexers.python import PythonLexer",
            "from pygments.lexers.perl import PerlLexer",
            "from pygments.lexers.jvm import JavaLexer, TeaLangLexer",
            "from pygments.lexers.data import YamlLexer",
            "from pygments.lexer import Lexer, DelegatingLexer, RegexLexer, bygroups, \\",
            "    include, using, this, default, combined",
            "from pygments.token import Error, Punctuation, Whitespace, \\",
            "    Text, Comment, Operator, Keyword, Name, String, Number, Other, Token",
            "from pygments.util import html_doctype_matches, looks_like_xml",
            "",
            "__all__ = ['HtmlPhpLexer', 'XmlPhpLexer', 'CssPhpLexer',",
            "           'JavascriptPhpLexer', 'ErbLexer', 'RhtmlLexer',",
            "           'XmlErbLexer', 'CssErbLexer', 'JavascriptErbLexer',",
            "           'SmartyLexer', 'HtmlSmartyLexer', 'XmlSmartyLexer',",
            "           'CssSmartyLexer', 'JavascriptSmartyLexer', 'DjangoLexer',",
            "           'HtmlDjangoLexer', 'CssDjangoLexer', 'XmlDjangoLexer',",
            "           'JavascriptDjangoLexer', 'GenshiLexer', 'HtmlGenshiLexer',",
            "           'GenshiTextLexer', 'CssGenshiLexer', 'JavascriptGenshiLexer',",
            "           'MyghtyLexer', 'MyghtyHtmlLexer', 'MyghtyXmlLexer',",
            "           'MyghtyCssLexer', 'MyghtyJavascriptLexer', 'MasonLexer', 'MakoLexer',",
            "           'MakoHtmlLexer', 'MakoXmlLexer', 'MakoJavascriptLexer',",
            "           'MakoCssLexer', 'JspLexer', 'CheetahLexer', 'CheetahHtmlLexer',",
            "           'CheetahXmlLexer', 'CheetahJavascriptLexer', 'EvoqueLexer',",
            "           'EvoqueHtmlLexer', 'EvoqueXmlLexer', 'ColdfusionLexer',",
            "           'ColdfusionHtmlLexer', 'ColdfusionCFCLexer', 'VelocityLexer',",
            "           'VelocityHtmlLexer', 'VelocityXmlLexer', 'SspLexer',",
            "           'TeaTemplateLexer', 'LassoHtmlLexer', 'LassoXmlLexer',",
            "           'LassoCssLexer', 'LassoJavascriptLexer', 'HandlebarsLexer',",
            "           'HandlebarsHtmlLexer', 'YamlJinjaLexer', 'LiquidLexer',",
            "           'TwigLexer', 'TwigHtmlLexer', 'Angular2Lexer', 'Angular2HtmlLexer']",
            "",
            "",
            "class ErbLexer(Lexer):",
            "    \"\"\"",
            "    Generic `ERB <http://ruby-doc.org/core/classes/ERB.html>`_ (Ruby Templating)",
            "    lexer.",
            "",
            "    Just highlights ruby code between the preprocessor directives, other data",
            "    is left untouched by the lexer.",
            "",
            "    All options are also forwarded to the `RubyLexer`.",
            "    \"\"\"",
            "",
            "    name = 'ERB'",
            "    aliases = ['erb']",
            "    mimetypes = ['application/x-ruby-templating']",
            "",
            "    _block_re = re.compile(r'(<%%|%%>|<%=|<%#|<%-|<%|-%>|%>|^%[^%].*?$)', re.M)",
            "",
            "    def __init__(self, **options):",
            "        from pygments.lexers.ruby import RubyLexer",
            "        self.ruby_lexer = RubyLexer(**options)",
            "        Lexer.__init__(self, **options)",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        \"\"\"",
            "        Since ERB doesn't allow \"<%\" and other tags inside of ruby",
            "        blocks we have to use a split approach here that fails for",
            "        that too.",
            "        \"\"\"",
            "        tokens = self._block_re.split(text)",
            "        tokens.reverse()",
            "        state = idx = 0",
            "        try:",
            "            while True:",
            "                # text",
            "                if state == 0:",
            "                    val = tokens.pop()",
            "                    yield idx, Other, val",
            "                    idx += len(val)",
            "                    state = 1",
            "                # block starts",
            "                elif state == 1:",
            "                    tag = tokens.pop()",
            "                    # literals",
            "                    if tag in ('<%%', '%%>'):",
            "                        yield idx, Other, tag",
            "                        idx += 3",
            "                        state = 0",
            "                    # comment",
            "                    elif tag == '<%#':",
            "                        yield idx, Comment.Preproc, tag",
            "                        val = tokens.pop()",
            "                        yield idx + 3, Comment, val",
            "                        idx += 3 + len(val)",
            "                        state = 2",
            "                    # blocks or output",
            "                    elif tag in ('<%', '<%=', '<%-'):",
            "                        yield idx, Comment.Preproc, tag",
            "                        idx += len(tag)",
            "                        data = tokens.pop()",
            "                        r_idx = 0",
            "                        for r_idx, r_token, r_value in \\",
            "                                self.ruby_lexer.get_tokens_unprocessed(data):",
            "                            yield r_idx + idx, r_token, r_value",
            "                        idx += len(data)",
            "                        state = 2",
            "                    elif tag in ('%>', '-%>'):",
            "                        yield idx, Error, tag",
            "                        idx += len(tag)",
            "                        state = 0",
            "                    # % raw ruby statements",
            "                    else:",
            "                        yield idx, Comment.Preproc, tag[0]",
            "                        r_idx = 0",
            "                        for r_idx, r_token, r_value in \\",
            "                                self.ruby_lexer.get_tokens_unprocessed(tag[1:]):",
            "                            yield idx + 1 + r_idx, r_token, r_value",
            "                        idx += len(tag)",
            "                        state = 0",
            "                # block ends",
            "                elif state == 2:",
            "                    tag = tokens.pop()",
            "                    if tag not in ('%>', '-%>'):",
            "                        yield idx, Other, tag",
            "                    else:",
            "                        yield idx, Comment.Preproc, tag",
            "                    idx += len(tag)",
            "                    state = 0",
            "        except IndexError:",
            "            return",
            "",
            "    def analyse_text(text):",
            "        if '<%' in text and '%>' in text:",
            "            return 0.4",
            "",
            "",
            "class SmartyLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `Smarty <http://smarty.php.net/>`_ template lexer.",
            "",
            "    Just highlights smarty code between the preprocessor directives, other",
            "    data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Smarty'",
            "    aliases = ['smarty']",
            "    filenames = ['*.tpl']",
            "    mimetypes = ['application/x-smarty']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'(\\{)(\\*.*?\\*)(\\})',",
            "             bygroups(Comment.Preproc, Comment, Comment.Preproc)),",
            "            (r'(\\{php\\})(.*?)(\\{/php\\})',",
            "             bygroups(Comment.Preproc, using(PhpLexer, startinline=True),",
            "                      Comment.Preproc)),",
            "            (r'(\\{)(/?[a-zA-Z_]\\w*)(\\s*)',",
            "             bygroups(Comment.Preproc, Name.Function, Text), 'smarty'),",
            "            (r'\\{', Comment.Preproc, 'smarty')",
            "        ],",
            "        'smarty': [",
            "            (r'\\s+', Text),",
            "            (r'\\{', Comment.Preproc, '#push'),",
            "            (r'\\}', Comment.Preproc, '#pop'),",
            "            (r'#[a-zA-Z_]\\w*#', Name.Variable),",
            "            (r'\\$[a-zA-Z_]\\w*(\\.\\w+)*', Name.Variable),",
            "            (r'[~!%^&*()+=|\\[\\]:;,.<>/?@-]', Operator),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*', Name.Attribute)",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\{if\\s+.*?\\}.*?\\{/if\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{include\\s+file=.*?\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{foreach\\s+.*?\\}.*?\\{/foreach\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{\\$.*?\\}', text):",
            "            rv += 0.01",
            "        return rv",
            "",
            "",
            "class VelocityLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `Velocity <http://velocity.apache.org/>`_ template lexer.",
            "",
            "    Just highlights velocity directives and variable references, other",
            "    data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Velocity'",
            "    aliases = ['velocity']",
            "    filenames = ['*.vm', '*.fhtml']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    identifier = r'[a-zA-Z_]\\w*'",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{#$]+', Other),",
            "            (r'(#)(\\*.*?\\*)(#)',",
            "             bygroups(Comment.Preproc, Comment, Comment.Preproc)),",
            "            (r'(##)(.*?$)',",
            "             bygroups(Comment.Preproc, Comment)),",
            "            (r'(#\\{?)(' + identifier + r')(\\}?)(\\s?\\()',",
            "             bygroups(Comment.Preproc, Name.Function, Comment.Preproc, Punctuation),",
            "             'directiveparams'),",
            "            (r'(#\\{?)(' + identifier + r')(\\}|\\b)',",
            "             bygroups(Comment.Preproc, Name.Function, Comment.Preproc)),",
            "            (r'\\$!?\\{?', Punctuation, 'variable')",
            "        ],",
            "        'variable': [",
            "            (identifier, Name.Variable),",
            "            (r'\\(', Punctuation, 'funcparams'),",
            "            (r'(\\.)(' + identifier + r')',",
            "             bygroups(Punctuation, Name.Variable), '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'directiveparams': [",
            "            (r'(&&|\\|\\||==?|!=?|[-<>+*%&|^/])|\\b(eq|ne|gt|lt|ge|le|not|in)\\b',",
            "             Operator),",
            "            (r'\\[', Operator, 'rangeoperator'),",
            "            (r'\\b' + identifier + r'\\b', Name.Function),",
            "            include('funcparams')",
            "        ],",
            "        'rangeoperator': [",
            "            (r'\\.\\.', Operator),",
            "            include('funcparams'),",
            "            (r'\\]', Operator, '#pop')",
            "        ],",
            "        'funcparams': [",
            "            (r'\\$!?\\{?', Punctuation, 'variable'),",
            "            (r'\\s+', Text),",
            "            (r'[,:]', Punctuation),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r\"\\b[0-9]+\\b\", Number),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'\\(', Punctuation, '#push'),",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r'\\{', Punctuation, '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "            (r'\\[', Punctuation, '#push'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'#\\{?macro\\}?\\(.*?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.25",
            "        if re.search(r'#\\{?if\\}?\\(.+?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.15",
            "        if re.search(r'#\\{?foreach\\}?\\(.+?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.15",
            "        if re.search(r'\\$!?\\{?[a-zA-Z_]\\w*(\\([^)]*\\))?'",
            "                     r'(\\.\\w+(\\([^)]*\\))?)*\\}?', text):",
            "            rv += 0.01",
            "        return rv",
            "",
            "",
            "class VelocityHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `VelocityLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    \"\"\"",
            "",
            "    name = 'HTML+Velocity'",
            "    aliases = ['html+velocity']",
            "    alias_filenames = ['*.html', '*.fhtml']",
            "    mimetypes = ['text/html+velocity']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, VelocityLexer, **options)",
            "",
            "",
            "class VelocityXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `VelocityLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    \"\"\"",
            "",
            "    name = 'XML+Velocity'",
            "    aliases = ['xml+velocity']",
            "    alias_filenames = ['*.xml', '*.vm']",
            "    mimetypes = ['application/xml+velocity']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, VelocityLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = VelocityLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class DjangoLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `django <http://www.djangoproject.com/documentation/templates/>`_",
            "    and `jinja <https://jinja.pocoo.org/jinja/>`_ template lexer.",
            "",
            "    It just highlights django/jinja code between the preprocessor directives,",
            "    other data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Django/Jinja'",
            "    aliases = ['django', 'jinja']",
            "    mimetypes = ['application/x-django-templating', 'application/x-jinja']",
            "",
            "    flags = re.M | re.S",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'\\{\\{', Comment.Preproc, 'var'),",
            "            # jinja/django comments",
            "            (r'\\{#.*?#\\}', Comment),",
            "            # django comments",
            "            (r'(\\{%)(-?\\s*)(comment)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endcomment)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Comment, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # raw jinja blocks",
            "            (r'(\\{%)(-?\\s*)(raw)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endraw)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Text, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # filter blocks",
            "            (r'(\\{%)(-?\\s*)(filter)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Name.Function),",
            "             'block'),",
            "            (r'(\\{%)(-?\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword), 'block'),",
            "            (r'\\{', Other)",
            "        ],",
            "        'varnames': [",
            "            (r'(\\|)(\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Text, Name.Function)),",
            "            (r'(is)(\\s+)(not)?(\\s+)?([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword, Text, Keyword, Text, Name.Function)),",
            "            (r'(_|true|false|none|True|False|None)\\b', Keyword.Pseudo),",
            "            (r'(in|as|reversed|recursive|not|and|or|is|if|else|import|'",
            "             r'with(?:(?:out)?\\s*context)?|scoped|ignore\\s+missing)\\b',",
            "             Keyword),",
            "            (r'(loop|block|super|forloop)\\b', Name.Builtin),",
            "            (r'[a-zA-Z_][\\w-]*', Name.Variable),",
            "            (r'\\.\\w+', Name.Variable),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'([{}()\\[\\]+\\-*/%,:~]|[><=]=?|!=)', Operator),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ],",
            "        'var': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(\\}\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames')",
            "        ],",
            "        'block': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(%\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames'),",
            "            (r'.', Punctuation)",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\{%\\s*(block|extends)', text) is not None:",
            "            rv += 0.4",
            "        if re.search(r'\\{%\\s*if\\s*.*?%\\}', text) is not None:",
            "            rv += 0.1",
            "        if re.search(r'\\{\\{.*?\\}\\}', text) is not None:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class MyghtyLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `myghty templates`_ lexer. Code that isn't Myghty",
            "    markup is yielded as `Token.Other`.",
            "",
            "    .. versionadded:: 0.6",
            "",
            "    .. _myghty templates: http://www.myghty.org/",
            "    \"\"\"",
            "",
            "    name = 'Myghty'",
            "    aliases = ['myghty']",
            "    filenames = ['*.myt', 'autodelegate']",
            "    mimetypes = ['application/x-myghty']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'(?s)(<%(?:def|method))(\\s*)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Text, Name.Function, Name.Tag,",
            "                      using(this), Name.Tag)),",
            "            (r'(?s)(<%\\w+)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Name.Function, Name.Tag,",
            "                      using(PythonLexer), Name.Tag)),",
            "            (r'(<&[^|])(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PythonLexer), Name.Tag)),",
            "            (r'(?s)(<&\\|)(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PythonLexer), Name.Tag)),",
            "            (r'</&>', Name.Tag),",
            "            (r'(?s)(<%!?)(.*?)(%>)',",
            "             bygroups(Name.Tag, using(PythonLexer), Name.Tag)),",
            "            (r'(?<=^)#[^\\n]*(\\n|\\Z)', Comment),",
            "            (r'(?<=^)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Name.Tag, using(PythonLexer), Other)),",
            "            (r\"\"\"(?sx)",
            "                 (.+?)               # anything, followed by:",
            "                 (?:",
            "                  (?<=\\n)(?=[%#]) |  # an eval or comment line",
            "                  (?=</?[%&]) |      # a substitution or block or",
            "                                     # call start or end",
            "                                     # - don't consume",
            "                  (\\\\\\n) |           # an escaped newline",
            "                  \\Z                 # end of string",
            "                 )\"\"\", bygroups(Other, Operator)),",
            "        ]",
            "    }",
            "",
            "",
            "class MyghtyHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'HTML+Myghty'",
            "    aliases = ['html+myghty']",
            "    mimetypes = ['text/html+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'XML+Myghty'",
            "    aliases = ['xml+myghty']",
            "    mimetypes = ['application/xml+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Myghty'",
            "    aliases = ['js+myghty', 'javascript+myghty']",
            "    mimetypes = ['application/x-javascript+myghty',",
            "                 'text/x-javascript+myghty',",
            "                 'text/javascript+mygthy']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `CssLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'CSS+Myghty'",
            "    aliases = ['css+myghty']",
            "    mimetypes = ['text/css+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MasonLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `mason templates`_ lexer. Stolen from Myghty lexer. Code that isn't",
            "    Mason markup is HTML.",
            "",
            "    .. _mason templates: http://www.masonhq.com/",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Mason'",
            "    aliases = ['mason']",
            "    filenames = ['*.m', '*.mhtml', '*.mc', '*.mi', 'autohandler', 'dhandler']",
            "    mimetypes = ['application/x-mason']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'(?s)(<%doc>)(.*?)(</%doc>)',",
            "             bygroups(Name.Tag, Comment.Multiline, Name.Tag)),",
            "            (r'(?s)(<%(?:def|method))(\\s*)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Text, Name.Function, Name.Tag,",
            "                      using(this), Name.Tag)),",
            "            (r'(?s)(<%(\\w+)(.*?)(>))(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, None, None, None, using(PerlLexer), Name.Tag)),",
            "            (r'(?s)(<&[^|])(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PerlLexer), Name.Tag)),",
            "            (r'(?s)(<&\\|)(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PerlLexer), Name.Tag)),",
            "            (r'</&>', Name.Tag),",
            "            (r'(?s)(<%!?)(.*?)(%>)',",
            "             bygroups(Name.Tag, using(PerlLexer), Name.Tag)),",
            "            (r'(?<=^)#[^\\n]*(\\n|\\Z)', Comment),",
            "            (r'(?<=^)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Name.Tag, using(PerlLexer), Other)),",
            "            (r\"\"\"(?sx)",
            "                 (.+?)               # anything, followed by:",
            "                 (?:",
            "                  (?<=\\n)(?=[%#]) |  # an eval or comment line",
            "                  (?=</?[%&]) |      # a substitution or block or",
            "                                     # call start or end",
            "                                     # - don't consume",
            "                  (\\\\\\n) |           # an escaped newline",
            "                  \\Z                 # end of string",
            "                 )\"\"\", bygroups(using(HtmlLexer), Operator)),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        result = 0.0",
            "        if re.search(r'</%(class|doc|init)>', text) is not None:",
            "            result = 1.0",
            "        elif re.search(r'<&.+&>', text, re.DOTALL) is not None:",
            "            result = 0.11",
            "        return result",
            "",
            "",
            "class MakoLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `mako templates`_ lexer. Code that isn't Mako",
            "    markup is yielded as `Token.Other`.",
            "",
            "    .. versionadded:: 0.7",
            "",
            "    .. _mako templates: http://www.makotemplates.org/",
            "    \"\"\"",
            "",
            "    name = 'Mako'",
            "    aliases = ['mako']",
            "    filenames = ['*.mao']",
            "    mimetypes = ['application/x-mako']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'(\\s*)(%)(\\s*end(?:\\w+))(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, Keyword, Other)),",
            "            (r'(\\s*)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, using(PythonLexer), Other)),",
            "            (r'(\\s*)(##[^\\n]*)(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, Other)),",
            "            (r'(?s)<%doc>.*?</%doc>', Comment.Preproc),",
            "            (r'(<%)([\\w.:]+)',",
            "             bygroups(Comment.Preproc, Name.Builtin), 'tag'),",
            "            (r'(</%)([\\w.:]+)(>)',",
            "             bygroups(Comment.Preproc, Name.Builtin, Comment.Preproc)),",
            "            (r'<%(?=([\\w.:]+))', Comment.Preproc, 'ondeftags'),",
            "            (r'(?s)(<%(?:!?))(.*?)(%>)',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(\\$\\{)(.*?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'''(?sx)",
            "                (.+?)                # anything, followed by:",
            "                (?:",
            "                 (?<=\\n)(?=%|\\#\\#) | # an eval or comment line",
            "                 (?=\\#\\*) |          # multiline comment",
            "                 (?=</?%) |          # a python block",
            "                                     # call start or end",
            "                 (?=\\$\\{) |          # a substitution",
            "                 (?<=\\n)(?=\\s*%) |",
            "                                     # - don't consume",
            "                 (\\\\\\n) |            # an escaped newline",
            "                 \\Z                  # end of string",
            "                )",
            "            ''', bygroups(Other, Operator)),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'ondeftags': [",
            "            (r'<%', Comment.Preproc),",
            "            (r'(?<=<%)(include|inherit|namespace|page)', Name.Builtin),",
            "            include('tag'),",
            "        ],",
            "        'tag': [",
            "            (r'((?:\\w+)\\s*=)(\\s*)(\".*?\")',",
            "             bygroups(Name.Attribute, Text, String)),",
            "            (r'/?\\s*>', Comment.Preproc, '#pop'),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'attr': [",
            "            ('\".*?\"', String, '#pop'),",
            "            (\"'.*?'\", String, '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class MakoHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'HTML+Mako'",
            "    aliases = ['html+mako']",
            "    mimetypes = ['text/html+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'XML+Mako'",
            "    aliases = ['xml+mako']",
            "    mimetypes = ['application/xml+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Mako'",
            "    aliases = ['js+mako', 'javascript+mako']",
            "    mimetypes = ['application/x-javascript+mako',",
            "                 'text/x-javascript+mako',",
            "                 'text/javascript+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `CssLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'CSS+Mako'",
            "    aliases = ['css+mako']",
            "    mimetypes = ['text/css+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, MakoLexer, **options)",
            "",
            "",
            "# Genshi and Cheetah lexers courtesy of Matt Good.",
            "",
            "class CheetahPythonLexer(Lexer):",
            "    \"\"\"",
            "    Lexer for handling Cheetah's special $ tokens in Python syntax.",
            "    \"\"\"",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        pylexer = PythonLexer(**self.options)",
            "        for pos, type_, value in pylexer.get_tokens_unprocessed(text):",
            "            if type_ == Token.Error and value == '$':",
            "                type_ = Comment.Preproc",
            "            yield pos, type_, value",
            "",
            "",
            "class CheetahLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `cheetah templates`_ lexer. Code that isn't Cheetah",
            "    markup is yielded as `Token.Other`.  This also works for",
            "    `spitfire templates`_ which use the same syntax.",
            "",
            "    .. _cheetah templates: http://www.cheetahtemplate.org/",
            "    .. _spitfire templates: http://code.google.com/p/spitfire/",
            "    \"\"\"",
            "",
            "    name = 'Cheetah'",
            "    aliases = ['cheetah', 'spitfire']",
            "    filenames = ['*.tmpl', '*.spt']",
            "    mimetypes = ['application/x-cheetah', 'application/x-spitfire']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'(##[^\\n]*)$',",
            "             (bygroups(Comment))),",
            "            (r'#[*](.|\\n)*?[*]#', Comment),",
            "            (r'#end[^#\\n]*(?:#|$)', Comment.Preproc),",
            "            (r'#slurp$', Comment.Preproc),",
            "            (r'(#[a-zA-Z]+)([^#\\n]*)(#|$)',",
            "             (bygroups(Comment.Preproc, using(CheetahPythonLexer),",
            "                       Comment.Preproc))),",
            "            # TODO support other Python syntax like $foo['bar']",
            "            (r'(\\$)([a-zA-Z_][\\w.]*\\w)',",
            "             bygroups(Comment.Preproc, using(CheetahPythonLexer))),",
            "            (r'(?s)(\\$\\{!?)(.*?)(\\})',",
            "             bygroups(Comment.Preproc, using(CheetahPythonLexer),",
            "                      Comment.Preproc)),",
            "            (r'''(?sx)",
            "                (.+?)               # anything, followed by:",
            "                (?:",
            "                 (?=\\#[#a-zA-Z]*) | # an eval comment",
            "                 (?=\\$[a-zA-Z_{]) | # a substitution",
            "                 \\Z                 # end of string",
            "                )",
            "            ''', Other),",
            "            (r'\\s+', Text),",
            "        ],",
            "    }",
            "",
            "",
            "class CheetahHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Cheetah'",
            "    aliases = ['html+cheetah', 'html+spitfire', 'htmlcheetah']",
            "    mimetypes = ['text/html+cheetah', 'text/html+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, CheetahLexer, **options)",
            "",
            "",
            "class CheetahXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Cheetah'",
            "    aliases = ['xml+cheetah', 'xml+spitfire']",
            "    mimetypes = ['application/xml+cheetah', 'application/xml+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, CheetahLexer, **options)",
            "",
            "",
            "class CheetahJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Cheetah'",
            "    aliases = ['js+cheetah', 'javascript+cheetah',",
            "               'js+spitfire', 'javascript+spitfire']",
            "    mimetypes = ['application/x-javascript+cheetah',",
            "                 'text/x-javascript+cheetah',",
            "                 'text/javascript+cheetah',",
            "                 'application/x-javascript+spitfire',",
            "                 'text/x-javascript+spitfire',",
            "                 'text/javascript+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, CheetahLexer, **options)",
            "",
            "",
            "class GenshiTextLexer(RegexLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ text",
            "    templates.",
            "    \"\"\"",
            "",
            "    name = 'Genshi Text'",
            "    aliases = ['genshitext']",
            "    mimetypes = ['application/x-genshi-text', 'text/x-genshi']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^#$\\s]+', Other),",
            "            (r'^(\\s*)(##.*)$', bygroups(Text, Comment)),",
            "            (r'^(\\s*)(#)', bygroups(Text, Comment.Preproc), 'directive'),",
            "            include('variable'),",
            "            (r'[#$\\s]', Other),",
            "        ],",
            "        'directive': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r'(?:def|for|if)\\s+.*', using(PythonLexer), '#pop'),",
            "            (r'(choose|when|with)([^\\S\\n]+)(.*)',",
            "             bygroups(Keyword, Text, using(PythonLexer)), '#pop'),",
            "            (r'(choose|otherwise)\\b', Keyword, '#pop'),",
            "            (r'(end\\w*)([^\\S\\n]*)(.*)', bygroups(Keyword, Text, Comment), '#pop'),",
            "        ],",
            "        'variable': [",
            "            (r'(?<!\\$)(\\$\\{)(.+?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(?<!\\$)(\\$)([a-zA-Z_][\\w.]*)',",
            "             Name.Variable),",
            "        ]",
            "    }",
            "",
            "",
            "class GenshiMarkupLexer(RegexLexer):",
            "    \"\"\"",
            "    Base lexer for Genshi markup, used by `HtmlGenshiLexer` and",
            "    `GenshiLexer`.",
            "    \"\"\"",
            "",
            "    flags = re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^<$]+', Other),",
            "            (r'(<\\?python)(.*?)(\\?>)',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            # yield style and script blocks as Other",
            "            (r'<\\s*(script|style)\\s*.*?>.*?<\\s*/\\1\\s*>', Other),",
            "            (r'<\\s*py:[a-zA-Z0-9]+', Name.Tag, 'pytag'),",
            "            (r'<\\s*[a-zA-Z0-9:.]+', Name.Tag, 'tag'),",
            "            include('variable'),",
            "            (r'[<$]', Other),",
            "        ],",
            "        'pytag': [",
            "            (r'\\s+', Text),",
            "            (r'[\\w:-]+\\s*=', Name.Attribute, 'pyattr'),",
            "            (r'/?\\s*>', Name.Tag, '#pop'),",
            "        ],",
            "        'pyattr': [",
            "            ('(\")(.*?)(\")', bygroups(String, using(PythonLexer), String), '#pop'),",
            "            (\"(')(.*?)(')\", bygroups(String, using(PythonLexer), String), '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            (r'py:[\\w-]+\\s*=', Name.Attribute, 'pyattr'),",
            "            (r'[\\w:-]+\\s*=', Name.Attribute, 'attr'),",
            "            (r'/?\\s*>', Name.Tag, '#pop'),",
            "        ],",
            "        'attr': [",
            "            ('\"', String, 'attr-dstring'),",
            "            (\"'\", String, 'attr-sstring'),",
            "            (r'[^\\s>]*', String, '#pop')",
            "        ],",
            "        'attr-dstring': [",
            "            ('\"', String, '#pop'),",
            "            include('strings'),",
            "            (\"'\", String)",
            "        ],",
            "        'attr-sstring': [",
            "            (\"'\", String, '#pop'),",
            "            include('strings'),",
            "            (\"'\", String)",
            "        ],",
            "        'strings': [",
            "            ('[^\"\\'$]+', String),",
            "            include('variable')",
            "        ],",
            "        'variable': [",
            "            (r'(?<!\\$)(\\$\\{)(.+?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(?<!\\$)(\\$)([a-zA-Z_][\\w\\.]*)',",
            "             Name.Variable),",
            "        ]",
            "    }",
            "",
            "",
            "class HtmlGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ and",
            "    `kid <http://kid-templating.org/>`_ kid HTML templates.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Genshi'",
            "    aliases = ['html+genshi', 'html+kid']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, GenshiMarkupLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\$\\{.*?\\}', text) is not None:",
            "            rv += 0.2",
            "        if re.search(r'py:(.*?)=[\"\\']', text) is not None:",
            "            rv += 0.2",
            "        return rv + HtmlLexer.analyse_text(text) - 0.01",
            "",
            "",
            "class GenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ and",
            "    `kid <http://kid-templating.org/>`_ kid XML templates.",
            "    \"\"\"",
            "",
            "    name = 'Genshi'",
            "    aliases = ['genshi', 'kid', 'xml+genshi', 'xml+kid']",
            "    filenames = ['*.kid']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/x-genshi', 'application/x-kid']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, GenshiMarkupLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\$\\{.*?\\}', text) is not None:",
            "            rv += 0.2",
            "        if re.search(r'py:(.*?)=[\"\\']', text) is not None:",
            "            rv += 0.2",
            "        return rv + XmlLexer.analyse_text(text) - 0.01",
            "",
            "",
            "class JavascriptGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights javascript code in genshi text templates.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Genshi Text'",
            "    aliases = ['js+genshitext', 'js+genshi', 'javascript+genshitext',",
            "               'javascript+genshi']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+genshi',",
            "                 'text/x-javascript+genshi',",
            "                 'text/javascript+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, GenshiTextLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return GenshiLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class CssGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights CSS definitions in genshi text templates.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Genshi Text'",
            "    aliases = ['css+genshitext', 'css+genshi']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, GenshiTextLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return GenshiLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class RhtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the ERB lexer that highlights the unlexed data with the",
            "    html lexer.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'RHTML'",
            "    aliases = ['rhtml', 'html+erb', 'html+ruby']",
            "    filenames = ['*.rhtml']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = ErbLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            # one more than the XmlErbLexer returns",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights data outside preprocessor",
            "    directives with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Ruby'",
            "    aliases = ['xml+erb', 'xml+ruby']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/xml+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = ErbLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights unlexed data with the `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Ruby'",
            "    aliases = ['css+erb', 'css+ruby']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return ErbLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Ruby'",
            "    aliases = ['js+erb', 'javascript+erb', 'js+ruby', 'javascript+ruby']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+ruby',",
            "                 'text/x-javascript+ruby',",
            "                 'text/javascript+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return ErbLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class HtmlPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` that highlights unhandled data with the `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+PHP'",
            "    aliases = ['html+php']",
            "    filenames = ['*.phtml']",
            "    alias_filenames = ['*.php', '*.html', '*.htm', '*.xhtml',",
            "                       '*.php[345]']",
            "    mimetypes = ['application/x-php',",
            "                 'application/x-httpd-php', 'application/x-httpd-php3',",
            "                 'application/x-httpd-php4', 'application/x-httpd-php5']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = PhpLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` that highlights unhandled data with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+PHP'",
            "    aliases = ['xml+php']",
            "    alias_filenames = ['*.xml', '*.php', '*.php[345]']",
            "    mimetypes = ['application/xml+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = PhpLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` which highlights unmatched data with the `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+PHP'",
            "    aliases = ['css+php']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return PhpLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` which highlights unmatched data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+PHP'",
            "    aliases = ['js+php', 'javascript+php']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+php',",
            "                 'text/x-javascript+php',",
            "                 'text/javascript+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return PhpLexer.analyse_text(text)",
            "",
            "",
            "class HtmlSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Smarty'",
            "    aliases = ['html+smarty']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml', '*.tpl']",
            "    mimetypes = ['text/html+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = SmartyLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Smarty'",
            "    aliases = ['xml+smarty']",
            "    alias_filenames = ['*.xml', '*.tpl']",
            "    mimetypes = ['application/xml+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = SmartyLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Smarty'",
            "    aliases = ['css+smarty']",
            "    alias_filenames = ['*.css', '*.tpl']",
            "    mimetypes = ['text/css+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return SmartyLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Smarty'",
            "    aliases = ['js+smarty', 'javascript+smarty']",
            "    alias_filenames = ['*.js', '*.tpl']",
            "    mimetypes = ['application/x-javascript+smarty',",
            "                 'text/x-javascript+smarty',",
            "                 'text/javascript+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return SmartyLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class HtmlDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Django/Jinja'",
            "    aliases = ['html+django', 'html+jinja', 'htmldjango']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+django', 'text/html+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = DjangoLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Django/Jinja'",
            "    aliases = ['xml+django', 'xml+jinja']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/xml+django', 'application/xml+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = DjangoLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Django/Jinja'",
            "    aliases = ['css+django', 'css+jinja']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+django', 'text/css+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return DjangoLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Django/Jinja'",
            "    aliases = ['js+django', 'javascript+django',",
            "               'js+jinja', 'javascript+jinja']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+django',",
            "                 'application/x-javascript+jinja',",
            "                 'text/x-javascript+django',",
            "                 'text/x-javascript+jinja',",
            "                 'text/javascript+django',",
            "                 'text/javascript+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return DjangoLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JspRootLexer(RegexLexer):",
            "    \"\"\"",
            "    Base for the `JspLexer`. Yields `Token.Other` for area outside of",
            "    JSP tags.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'<%\\S?', Keyword, 'sec'),",
            "            # FIXME: I want to make these keywords but still parse attributes.",
            "            (r'</?jsp:(forward|getProperty|include|plugin|setProperty|useBean).*?>',",
            "             Keyword),",
            "            (r'[^<]+', Other),",
            "            (r'<', Other),",
            "        ],",
            "        'sec': [",
            "            (r'%>', Keyword, '#pop'),",
            "            # note: '\\w\\W' != '.' without DOTALL.",
            "            (r'[\\w\\W]+?(?=%>|\\Z)', using(JavaLexer)),",
            "        ],",
            "    }",
            "",
            "",
            "class JspLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for Java Server Pages.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "    name = 'Java Server Page'",
            "    aliases = ['jsp']",
            "    filenames = ['*.jsp']",
            "    mimetypes = ['application/x-jsp']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, JspRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = JavaLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class EvoqueLexer(RegexLexer):",
            "    \"\"\"",
            "    For files using the Evoque templating system.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'Evoque'",
            "    aliases = ['evoque']",
            "    filenames = ['*.evoque']",
            "    mimetypes = ['application/x-evoque']",
            "",
            "    flags = re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^#$]+', Other),",
            "            (r'#\\[', Comment.Multiline, 'comment'),",
            "            (r'\\$\\$', Other),",
            "            # svn keywords",
            "            (r'\\$\\w+:[^$\\n]*\\$', Comment.Multiline),",
            "            # directives: begin, end",
            "            (r'(\\$)(begin|end)(\\{(%)?)(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      String, Punctuation)),",
            "            # directives: evoque, overlay",
            "            # see doc for handling first name arg: /directives/evoque/",
            "            # + minor inconsistency: the \"name\" in e.g. $overlay{name=site_base}",
            "            # should be using(PythonLexer), not passed out as String",
            "            (r'(\\$)(evoque|overlay)(\\{(%)?)(\\s*[#\\w\\-\"\\'.]+[^=,%}]+?)?'",
            "             r'(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      String, using(PythonLexer), Punctuation)),",
            "            # directives: if, for, prefer, test",
            "            (r'(\\$)(\\w+)(\\{(%)?)(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      using(PythonLexer), Punctuation)),",
            "            # directive clauses (no {} expression)",
            "            (r'(\\$)(else|rof|fi)', bygroups(Punctuation, Name.Builtin)),",
            "            # expressions",
            "            (r'(\\$\\{(%)?)(.*?)((!)(.*?))?((?(2)%)\\})',",
            "             bygroups(Punctuation, None, using(PythonLexer),",
            "                      Name.Builtin, None, None, Punctuation)),",
            "            (r'#', Other),",
            "        ],",
            "        'comment': [",
            "            (r'[^\\]#]', Comment.Multiline),",
            "            (r'#\\[', Comment.Multiline, '#push'),",
            "            (r'\\]#', Comment.Multiline, '#pop'),",
            "            (r'[\\]#]', Comment.Multiline)",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        \"\"\"Evoque templates use $evoque, which is unique.\"\"\"",
            "        if '$evoque' in text:",
            "            return 1",
            "",
            "class EvoqueHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `EvoqueLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'HTML+Evoque'",
            "    aliases = ['html+evoque']",
            "    filenames = ['*.html']",
            "    mimetypes = ['text/html+evoque']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, EvoqueLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return EvoqueLexer.analyse_text(text)",
            "",
            "",
            "class EvoqueXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `EvoqueLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'XML+Evoque'",
            "    aliases = ['xml+evoque']",
            "    filenames = ['*.xml']",
            "    mimetypes = ['application/xml+evoque']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, EvoqueLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return EvoqueLexer.analyse_text(text)",
            "",
            "",
            "class ColdfusionLexer(RegexLexer):",
            "    \"\"\"",
            "    Coldfusion statements",
            "    \"\"\"",
            "    name = 'cfstatement'",
            "    aliases = ['cfs']",
            "    filenames = []",
            "    mimetypes = []",
            "    flags = re.IGNORECASE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*(?:.|\\n)*?\\*/', Comment.Multiline),",
            "            (r'\\+\\+|--', Operator),",
            "            (r'[-+*/^&=!]', Operator),",
            "            (r'<=|>=|<|>|==', Operator),",
            "            (r'mod\\b', Operator),",
            "            (r'(eq|lt|gt|lte|gte|not|is|and|or)\\b', Operator),",
            "            (r'\\|\\||&&', Operator),",
            "            (r'\\?', Operator),",
            "            (r'\"', String.Double, 'string'),",
            "            # There is a special rule for allowing html in single quoted",
            "            # strings, evidently.",
            "            (r\"'.*?'\", String.Single),",
            "            (r'\\d+', Number),",
            "            (r'(if|else|len|var|xml|default|break|switch|component|property|function|do|'",
            "             r'try|catch|in|continue|for|return|while|required|any|array|binary|boolean|'",
            "             r'component|date|guid|numeric|query|string|struct|uuid|case)\\b', Keyword),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(application|session|client|cookie|super|this|variables|arguments)\\b',",
            "             Name.Constant),",
            "            (r'([a-z_$][\\w.]*)(\\s*)(\\()',",
            "             bygroups(Name.Function, Text, Punctuation)),",
            "            (r'[a-z_$][\\w.]*', Name.Variable),",
            "            (r'[()\\[\\]{};:,.\\\\]', Punctuation),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'string': [",
            "            (r'\"\"', String.Double),",
            "            (r'#.+?#', String.Interp),",
            "            (r'[^\"#]+', String.Double),",
            "            (r'#', String.Double),",
            "            (r'\"', String.Double, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class ColdfusionMarkupLexer(RegexLexer):",
            "    \"\"\"",
            "    Coldfusion markup only",
            "    \"\"\"",
            "    name = 'Coldfusion'",
            "    aliases = ['cf']",
            "    filenames = []",
            "    mimetypes = []",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^<]+', Other),",
            "            include('tags'),",
            "            (r'<[^<>]*', Other),",
            "        ],",
            "        'tags': [",
            "            (r'<!---', Comment.Multiline, 'cfcomment'),",
            "            (r'(?s)<!--.*?-->', Comment),",
            "            (r'<cfoutput.*?>', Name.Builtin, 'cfoutput'),",
            "            (r'(?s)(<cfscript.*?>)(.+?)(</cfscript.*?>)',",
            "             bygroups(Name.Builtin, using(ColdfusionLexer), Name.Builtin)),",
            "            # negative lookbehind is for strings with embedded >",
            "            (r'(?s)(</?cf(?:component|include|if|else|elseif|loop|return|'",
            "             r'dbinfo|dump|abort|location|invoke|throw|file|savecontent|'",
            "             r'mailpart|mail|header|content|zip|image|lock|argument|try|'",
            "             r'catch|break|directory|http|set|function|param)\\b)(.*?)((?<!\\\\)>)',",
            "             bygroups(Name.Builtin, using(ColdfusionLexer), Name.Builtin)),",
            "        ],",
            "        'cfoutput': [",
            "            (r'[^#<]+', Other),",
            "            (r'(#)(.*?)(#)', bygroups(Punctuation, using(ColdfusionLexer),",
            "                                      Punctuation)),",
            "            # (r'<cfoutput.*?>', Name.Builtin, '#push'),",
            "            (r'</cfoutput.*?>', Name.Builtin, '#pop'),",
            "            include('tags'),",
            "            (r'(?s)<[^<>]*', Other),",
            "            (r'#', Other),",
            "        ],",
            "        'cfcomment': [",
            "            (r'<!---', Comment.Multiline, '#push'),",
            "            (r'--->', Comment.Multiline, '#pop'),",
            "            (r'([^<-]|<(?!!---)|-(?!-->))+', Comment.Multiline),",
            "        ],",
            "    }",
            "",
            "",
            "class ColdfusionHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Coldfusion markup in html",
            "    \"\"\"",
            "    name = 'Coldfusion HTML'",
            "    aliases = ['cfm']",
            "    filenames = ['*.cfm', '*.cfml']",
            "    mimetypes = ['application/x-coldfusion']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, ColdfusionMarkupLexer, **options)",
            "",
            "",
            "class ColdfusionCFCLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Coldfusion markup/script components",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'Coldfusion CFC'",
            "    aliases = ['cfc']",
            "    filenames = ['*.cfc']",
            "    mimetypes = []",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(ColdfusionHtmlLexer, ColdfusionLexer, **options)",
            "",
            "",
            "class SspLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for Scalate Server Pages.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Scalate Server Page'",
            "    aliases = ['ssp']",
            "    filenames = ['*.ssp']",
            "    mimetypes = ['application/x-ssp']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, JspRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'val \\w+\\s*:', text):",
            "            rv += 0.6",
            "        if looks_like_xml(text):",
            "            rv += 0.2",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class TeaTemplateRootLexer(RegexLexer):",
            "    \"\"\"",
            "    Base for the `TeaTemplateLexer`. Yields `Token.Other` for area outside of",
            "    code blocks.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'<%\\S?', Keyword, 'sec'),",
            "            (r'[^<]+', Other),",
            "            (r'<', Other),",
            "        ],",
            "        'sec': [",
            "            (r'%>', Keyword, '#pop'),",
            "            # note: '\\w\\W' != '.' without DOTALL.",
            "            (r'[\\w\\W]+?(?=%>|\\Z)', using(TeaLangLexer)),",
            "        ],",
            "    }",
            "",
            "",
            "class TeaTemplateLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for `Tea Templates <http://teatrove.org/>`_.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Tea'",
            "    aliases = ['tea']",
            "    filenames = ['*.tea']",
            "    mimetypes = ['text/x-tea']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, TeaTemplateRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = TeaLangLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class LassoHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested JavaScript and CSS is also highlighted.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'HTML+Lasso'",
            "    aliases = ['html+lasso']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml', '*.lasso', '*.lasso[89]',",
            "                       '*.incl', '*.inc', '*.las']",
            "    mimetypes = ['text/html+lasso',",
            "                 'application/x-httpd-lasso',",
            "                 'application/x-httpd-lasso[89]']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):  # same as HTML lexer",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class LassoXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `XmlLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'XML+Lasso'",
            "    aliases = ['xml+lasso']",
            "    alias_filenames = ['*.xml', '*.lasso', '*.lasso[89]',",
            "                       '*.incl', '*.inc', '*.las']",
            "    mimetypes = ['application/xml+lasso']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class LassoCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `CssLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'CSS+Lasso'",
            "    aliases = ['css+lasso']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+lasso']",
            "",
            "    def __init__(self, **options):",
            "        options['requiredelimiters'] = True",
            "        super().__init__(CssLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.05",
            "        if re.search(r'\\w+:[^;]+;', text):",
            "            rv += 0.1",
            "        if 'padding:' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class LassoJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `JavascriptLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Lasso'",
            "    aliases = ['js+lasso', 'javascript+lasso']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+lasso',",
            "                 'text/x-javascript+lasso',",
            "                 'text/javascript+lasso']",
            "",
            "    def __init__(self, **options):",
            "        options['requiredelimiters'] = True",
            "        super().__init__(JavascriptLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.05",
            "        return rv",
            "",
            "",
            "class HandlebarsLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `handlebars <http://handlebarsjs.com/>` template lexer.",
            "",
            "    Highlights only the Handlebars template tags (stuff between `{{` and `}}`).",
            "    Everything else is left for a delegating lexer.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"Handlebars\"",
            "    aliases = ['handlebars']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "",
            "            # Comment start {{!  }} or {{!--",
            "            (r'\\{\\{!.*\\}\\}', Comment),",
            "",
            "            # HTML Escaping open {{{expression",
            "            (r'(\\{\\{\\{)(\\s*)', bygroups(Comment.Special, Text), 'tag'),",
            "",
            "            # {{blockOpen {{#blockOpen {{/blockClose with optional tilde ~",
            "            (r'(\\{\\{)([#~/]+)([^\\s}]*)',",
            "             bygroups(Comment.Preproc, Number.Attribute, Number.Attribute), 'tag'),",
            "            (r'(\\{\\{)(\\s*)', bygroups(Comment.Preproc, Text), 'tag'),",
            "        ],",
            "",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            # HTML Escaping close }}}",
            "            (r'\\}\\}\\}', Comment.Special, '#pop'),",
            "            # blockClose}}, includes optional tilde ~",
            "            (r'(~?)(\\}\\})', bygroups(Number, Comment.Preproc), '#pop'),",
            "",
            "            # {{opt=something}}",
            "            (r'([^\\s}]+)(=)', bygroups(Name.Attribute, Operator)),",
            "",
            "            # Partials {{> ...}}",
            "            (r'(>)(\\s*)(@partial-block)', bygroups(Keyword, Text, Keyword)),",
            "            (r'(#?>)(\\s*)([\\w-]+)', bygroups(Keyword, Text, Name.Variable)),",
            "            (r'(>)(\\s*)(\\()', bygroups(Keyword, Text, Punctuation),",
            "             'dynamic-partial'),",
            "",
            "            include('generic'),",
            "        ],",
            "        'dynamic-partial': [",
            "            (r'\\s+', Text),",
            "            (r'\\)', Punctuation, '#pop'),",
            "",
            "            (r'(lookup)(\\s+)(\\.|this)(\\s+)', bygroups(Keyword, Text,",
            "                                                      Name.Variable, Text)),",
            "            (r'(lookup)(\\s+)(\\S+)', bygroups(Keyword, Text,",
            "                                             using(this, state='variable'))),",
            "            (r'[\\w-]+', Name.Function),",
            "",
            "            include('generic'),",
            "        ],",
            "        'variable': [",
            "            (r'[()/@a-zA-Z][\\w-]*', Name.Variable),",
            "            (r'\\.[\\w-]+', Name.Variable),",
            "            (r'(this\\/|\\.\\/|(\\.\\.\\/)+)[\\w-]+', Name.Variable),",
            "        ],",
            "        'generic': [",
            "            include('variable'),",
            "",
            "            # borrowed from DjangoLexer",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ]",
            "    }",
            "",
            "",
            "class HandlebarsHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `HandlebarsLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML+Handlebars\"",
            "    aliases = [\"html+handlebars\"]",
            "    filenames = ['*.handlebars', '*.hbs']",
            "    mimetypes = ['text/html+handlebars', 'text/x-handlebars-template']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, HandlebarsLexer, **options)",
            "",
            "",
            "class YamlJinjaLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `YamlLexer`.",
            "",
            "    Commonly used in Saltstack salt states.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'YAML+Jinja'",
            "    aliases = ['yaml+jinja', 'salt', 'sls']",
            "    filenames = ['*.sls']",
            "    mimetypes = ['text/x-yaml+jinja', 'text/x-sls']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(YamlLexer, DjangoLexer, **options)",
            "",
            "",
            "class LiquidLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for `Liquid templates",
            "    <http://www.rubydoc.info/github/Shopify/liquid>`_.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'liquid'",
            "    aliases = ['liquid']",
            "    filenames = ['*.liquid']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Text),",
            "            # tags and block tags",
            "            (r'(\\{%)(\\s*)', bygroups(Punctuation, Whitespace), 'tag-or-block'),",
            "            # output tags",
            "            (r'(\\{\\{)(\\s*)([^\\s}]+)',",
            "             bygroups(Punctuation, Whitespace, using(this, state = 'generic')),",
            "             'output'),",
            "            (r'\\{', Text)",
            "        ],",
            "",
            "        'tag-or-block': [",
            "            # builtin logic blocks",
            "            (r'(if|unless|elsif|case)(?=\\s+)', Keyword.Reserved, 'condition'),",
            "            (r'(when)(\\s+)', bygroups(Keyword.Reserved, Whitespace),",
            "             combined('end-of-block', 'whitespace', 'generic')),",
            "            (r'(else)(\\s*)(%\\})',",
            "             bygroups(Keyword.Reserved, Whitespace, Punctuation), '#pop'),",
            "",
            "            # other builtin blocks",
            "            (r'(capture)(\\s+)([^\\s%]+)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, using(this, state = 'variable'),",
            "                      Whitespace, Punctuation), '#pop'),",
            "            (r'(comment)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, Punctuation), 'comment'),",
            "            (r'(raw)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, Punctuation), 'raw'),",
            "",
            "            # end of block",
            "            (r'(end(case|unless|if))(\\s*)(%\\})',",
            "             bygroups(Keyword.Reserved, None, Whitespace, Punctuation), '#pop'),",
            "            (r'(end([^\\s%]+))(\\s*)(%\\})',",
            "             bygroups(Name.Tag, None, Whitespace, Punctuation), '#pop'),",
            "",
            "            # builtin tags (assign and include are handled together with usual tags)",
            "            (r'(cycle)(\\s+)(?:([^\\s:]*)(:))?(\\s*)',",
            "             bygroups(Name.Tag, Whitespace,",
            "                      using(this, state='generic'), Punctuation, Whitespace),",
            "             'variable-tag-markup'),",
            "",
            "            # other tags or blocks",
            "            (r'([^\\s%]+)(\\s*)', bygroups(Name.Tag, Whitespace), 'tag-markup')",
            "        ],",
            "",
            "        'output': [",
            "            include('whitespace'),",
            "            (r'\\}\\}', Punctuation, '#pop'),  # end of output",
            "",
            "            (r'\\|', Punctuation, 'filters')",
            "        ],",
            "",
            "        'filters': [",
            "            include('whitespace'),",
            "            (r'\\}\\}', Punctuation, ('#pop', '#pop')),  # end of filters and output",
            "",
            "            (r'([^\\s|:]+)(:?)(\\s*)',",
            "             bygroups(Name.Function, Punctuation, Whitespace), 'filter-markup')",
            "        ],",
            "",
            "        'filter-markup': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            include('end-of-tag'),",
            "            include('default-param-markup')",
            "        ],",
            "",
            "        'condition': [",
            "            include('end-of-block'),",
            "            include('whitespace'),",
            "",
            "            (r'([^\\s=!><]+)(\\s*)([=!><]=?)(\\s*)(\\S+)(\\s*)(%\\})',",
            "             bygroups(using(this, state = 'generic'), Whitespace, Operator,",
            "                      Whitespace, using(this, state = 'generic'), Whitespace,",
            "                      Punctuation)),",
            "            (r'\\b!', Operator),",
            "            (r'\\bnot\\b', Operator.Word),",
            "            (r'([\\w.\\'\"]+)(\\s+)(contains)(\\s+)([\\w.\\'\"]+)',",
            "             bygroups(using(this, state = 'generic'), Whitespace, Operator.Word,",
            "                      Whitespace, using(this, state = 'generic'))),",
            "",
            "            include('generic'),",
            "            include('whitespace')",
            "        ],",
            "",
            "        'generic-value': [",
            "            include('generic'),",
            "            include('end-at-whitespace')",
            "        ],",
            "",
            "        'operator': [",
            "            (r'(\\s*)((=|!|>|<)=?)(\\s*)',",
            "             bygroups(Whitespace, Operator, None, Whitespace), '#pop'),",
            "            (r'(\\s*)(\\bcontains\\b)(\\s*)',",
            "             bygroups(Whitespace, Operator.Word, Whitespace), '#pop'),",
            "        ],",
            "",
            "        'end-of-tag': [",
            "            (r'\\}\\}', Punctuation, '#pop')",
            "        ],",
            "",
            "        'end-of-block': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop'))",
            "        ],",
            "",
            "        'end-at-whitespace': [",
            "            (r'\\s+', Whitespace, '#pop')",
            "        ],",
            "",
            "        # states for unknown markup",
            "        'param-markup': [",
            "            include('whitespace'),",
            "            # params with colons or equals",
            "            (r'([^\\s=:]+)(\\s*)(=|:)',",
            "             bygroups(Name.Attribute, Whitespace, Operator)),",
            "            # explicit variables",
            "            (r'(\\{\\{)(\\s*)([^\\s}])(\\s*)(\\}\\})',",
            "             bygroups(Punctuation, Whitespace, using(this, state = 'variable'),",
            "                      Whitespace, Punctuation)),",
            "",
            "            include('string'),",
            "            include('number'),",
            "            include('keyword'),",
            "            (r',', Punctuation)",
            "        ],",
            "",
            "        'default-param-markup': [",
            "            include('param-markup'),",
            "            (r'.', Text)  # fallback for switches / variables / un-quoted strings / ...",
            "        ],",
            "",
            "        'variable-param-markup': [",
            "            include('param-markup'),",
            "            include('variable'),",
            "            (r'.', Text)  # fallback",
            "        ],",
            "",
            "        'tag-markup': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop')),  # end of tag",
            "            include('default-param-markup')",
            "        ],",
            "",
            "        'variable-tag-markup': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop')),  # end of tag",
            "            include('variable-param-markup')",
            "        ],",
            "",
            "        # states for different values types",
            "        'keyword': [",
            "            (r'\\b(false|true)\\b', Keyword.Constant)",
            "        ],",
            "",
            "        'variable': [",
            "            (r'[a-zA-Z_]\\w*', Name.Variable),",
            "            (r'(?<=\\w)\\.(?=\\w)', Punctuation)",
            "        ],",
            "",
            "        'string': [",
            "            (r\"'[^']*'\", String.Single),",
            "            (r'\"[^\"]*\"', String.Double)",
            "        ],",
            "",
            "        'number': [",
            "            (r'\\d+\\.\\d+', Number.Float),",
            "            (r'\\d+', Number.Integer)",
            "        ],",
            "",
            "        'generic': [  # decides for variable, string, keyword or number",
            "            include('keyword'),",
            "            include('string'),",
            "            include('number'),",
            "            include('variable')",
            "        ],",
            "",
            "        'whitespace': [",
            "            (r'[ \\t]+', Whitespace)",
            "        ],",
            "",
            "        # states for builtin blocks",
            "        'comment': [",
            "            (r'(\\{%)(\\s*)(endcomment)(\\s*)(%\\})',",
            "             bygroups(Punctuation, Whitespace, Name.Tag, Whitespace,",
            "                      Punctuation), ('#pop', '#pop')),",
            "            (r'.', Comment)",
            "        ],",
            "",
            "        'raw': [",
            "            (r'[^{]+', Text),",
            "            (r'(\\{%)(\\s*)(endraw)(\\s*)(%\\})',",
            "             bygroups(Punctuation, Whitespace, Name.Tag, Whitespace,",
            "                      Punctuation), '#pop'),",
            "            (r'\\{', Text)",
            "        ],",
            "    }",
            "",
            "",
            "class TwigLexer(RegexLexer):",
            "    \"\"\"",
            "    `Twig <http://twig.sensiolabs.org/>`_ template lexer.",
            "",
            "    It just highlights Twig code between the preprocessor directives,",
            "    other data is left untouched by the lexer.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Twig'",
            "    aliases = ['twig']",
            "    mimetypes = ['application/x-twig']",
            "",
            "    flags = re.M | re.S",
            "",
            "    # Note that a backslash is included in the following two patterns",
            "    # PHP uses a backslash as a namespace separator",
            "    _ident_char = r'[\\\\\\w-]|[^\\x00-\\x7f]'",
            "    _ident_begin = r'(?:[\\\\_a-z]|[^\\x00-\\x7f])'",
            "    _ident_end = r'(?:' + _ident_char + ')*'",
            "    _ident_inner = _ident_begin + _ident_end",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'\\{\\{', Comment.Preproc, 'var'),",
            "            # twig comments",
            "            (r'\\{\\#.*?\\#\\}', Comment),",
            "            # raw twig blocks",
            "            (r'(\\{%)(-?\\s*)(raw)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endraw)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Other, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            (r'(\\{%)(-?\\s*)(verbatim)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endverbatim)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Other, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # filter blocks",
            "            (r'(\\{%%)(-?\\s*)(filter)(\\s+)(%s)' % _ident_inner,",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Name.Function),",
            "             'tag'),",
            "            (r'(\\{%)(-?\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword), 'tag'),",
            "            (r'\\{', Other),",
            "        ],",
            "        'varnames': [",
            "            (r'(\\|)(\\s*)(%s)' % _ident_inner,",
            "             bygroups(Operator, Text, Name.Function)),",
            "            (r'(is)(\\s+)(not)?(\\s*)(%s)' % _ident_inner,",
            "             bygroups(Keyword, Text, Keyword, Text, Name.Function)),",
            "            (r'(?i)(true|false|none|null)\\b', Keyword.Pseudo),",
            "            (r'(in|not|and|b-and|or|b-or|b-xor|is'",
            "             r'if|elseif|else|import'",
            "             r'constant|defined|divisibleby|empty|even|iterable|odd|sameas'",
            "             r'matches|starts\\s+with|ends\\s+with)\\b',",
            "             Keyword),",
            "            (r'(loop|block|parent)\\b', Name.Builtin),",
            "            (_ident_inner, Name.Variable),",
            "            (r'\\.' + _ident_inner, Name.Variable),",
            "            (r'\\.[0-9]+', Number),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'([{}()\\[\\]+\\-*/,:~%]|\\.\\.|\\?|:|\\*\\*|\\/\\/|!=|[><=]=?)', Operator),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ],",
            "        'var': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(\\}\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames')",
            "        ],",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(%\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames'),",
            "            (r'.', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class TwigHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `TwigLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML+Twig\"",
            "    aliases = [\"html+twig\"]",
            "    filenames = ['*.twig']",
            "    mimetypes = ['text/html+twig']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, TwigLexer, **options)",
            "",
            "",
            "class Angular2Lexer(RegexLexer):",
            "    \"\"\"",
            "    Generic",
            "    `angular2 <http://victorsavkin.com/post/119943127151/angular-2-template-syntax>`_",
            "    template lexer.",
            "",
            "    Highlights only the Angular template tags (stuff between `{{` and `}}` and",
            "    special attributes: '(event)=', '[property]=', '[(twoWayBinding)]=').",
            "    Everything else is left for a delegating lexer.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    name = \"Angular2\"",
            "    aliases = ['ng2']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{([*#]+', Other),",
            "",
            "            # {{meal.name}}",
            "            (r'(\\{\\{)(\\s*)', bygroups(Comment.Preproc, Text), 'ngExpression'),",
            "",
            "            # (click)=\"deleteOrder()\"; [value]=\"test\"; [(twoWayTest)]=\"foo.bar\"",
            "            (r'([([]+)([\\w:.-]+)([\\])]+)(\\s*)(=)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Punctuation, Text, Operator, Text),",
            "             'attr'),",
            "            (r'([([]+)([\\w:.-]+)([\\])]+)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Punctuation, Text)),",
            "",
            "            # *ngIf=\"...\"; #f=\"ngForm\"",
            "            (r'([*#])([\\w:.-]+)(\\s*)(=)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Text, Operator, Text), 'attr'),",
            "            (r'([*#])([\\w:.-]+)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Text)),",
            "        ],",
            "",
            "        'ngExpression': [",
            "            (r'\\s+(\\|\\s+)?', Text),",
            "            (r'\\}\\}', Comment.Preproc, '#pop'),",
            "",
            "            # Literals",
            "            (r':?(true|false)', String.Boolean),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "",
            "            # Variabletext",
            "            (r'[a-zA-Z][\\w-]*(\\(.*\\))?', Name.Variable),",
            "            (r'\\.[\\w-]+(\\(.*\\))?', Name.Variable),",
            "",
            "            # inline If",
            "            (r'(\\?)(\\s*)([^}\\s]+)(\\s*)(:)(\\s*)([^}\\s]+)(\\s*)',",
            "             bygroups(Operator, Text, String, Text, Operator, Text, String, Text)),",
            "        ],",
            "        'attr': [",
            "            ('\".*?\"', String, '#pop'),",
            "            (\"'.*?'\", String, '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class Angular2HtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `Angular2Lexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML + Angular2\"",
            "    aliases = [\"html+ng2\"]",
            "    filenames = ['*.ng2']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, Angular2Lexer, **options)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.templates",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for various template engines' markup.",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "import re",
            "",
            "from pygments.lexers.html import HtmlLexer, XmlLexer",
            "from pygments.lexers.javascript import JavascriptLexer, LassoLexer",
            "from pygments.lexers.css import CssLexer",
            "from pygments.lexers.php import PhpLexer",
            "from pygments.lexers.python import PythonLexer",
            "from pygments.lexers.perl import PerlLexer",
            "from pygments.lexers.jvm import JavaLexer, TeaLangLexer",
            "from pygments.lexers.data import YamlLexer",
            "from pygments.lexer import Lexer, DelegatingLexer, RegexLexer, bygroups, \\",
            "    include, using, this, default, combined",
            "from pygments.token import Error, Punctuation, Whitespace, \\",
            "    Text, Comment, Operator, Keyword, Name, String, Number, Other, Token",
            "from pygments.util import html_doctype_matches, looks_like_xml",
            "",
            "__all__ = ['HtmlPhpLexer', 'XmlPhpLexer', 'CssPhpLexer',",
            "           'JavascriptPhpLexer', 'ErbLexer', 'RhtmlLexer',",
            "           'XmlErbLexer', 'CssErbLexer', 'JavascriptErbLexer',",
            "           'SmartyLexer', 'HtmlSmartyLexer', 'XmlSmartyLexer',",
            "           'CssSmartyLexer', 'JavascriptSmartyLexer', 'DjangoLexer',",
            "           'HtmlDjangoLexer', 'CssDjangoLexer', 'XmlDjangoLexer',",
            "           'JavascriptDjangoLexer', 'GenshiLexer', 'HtmlGenshiLexer',",
            "           'GenshiTextLexer', 'CssGenshiLexer', 'JavascriptGenshiLexer',",
            "           'MyghtyLexer', 'MyghtyHtmlLexer', 'MyghtyXmlLexer',",
            "           'MyghtyCssLexer', 'MyghtyJavascriptLexer', 'MasonLexer', 'MakoLexer',",
            "           'MakoHtmlLexer', 'MakoXmlLexer', 'MakoJavascriptLexer',",
            "           'MakoCssLexer', 'JspLexer', 'CheetahLexer', 'CheetahHtmlLexer',",
            "           'CheetahXmlLexer', 'CheetahJavascriptLexer', 'EvoqueLexer',",
            "           'EvoqueHtmlLexer', 'EvoqueXmlLexer', 'ColdfusionLexer',",
            "           'ColdfusionHtmlLexer', 'ColdfusionCFCLexer', 'VelocityLexer',",
            "           'VelocityHtmlLexer', 'VelocityXmlLexer', 'SspLexer',",
            "           'TeaTemplateLexer', 'LassoHtmlLexer', 'LassoXmlLexer',",
            "           'LassoCssLexer', 'LassoJavascriptLexer', 'HandlebarsLexer',",
            "           'HandlebarsHtmlLexer', 'YamlJinjaLexer', 'LiquidLexer',",
            "           'TwigLexer', 'TwigHtmlLexer', 'Angular2Lexer', 'Angular2HtmlLexer']",
            "",
            "",
            "class ErbLexer(Lexer):",
            "    \"\"\"",
            "    Generic `ERB <http://ruby-doc.org/core/classes/ERB.html>`_ (Ruby Templating)",
            "    lexer.",
            "",
            "    Just highlights ruby code between the preprocessor directives, other data",
            "    is left untouched by the lexer.",
            "",
            "    All options are also forwarded to the `RubyLexer`.",
            "    \"\"\"",
            "",
            "    name = 'ERB'",
            "    aliases = ['erb']",
            "    mimetypes = ['application/x-ruby-templating']",
            "",
            "    _block_re = re.compile(r'(<%%|%%>|<%=|<%#|<%-|<%|-%>|%>|^%[^%].*?$)', re.M)",
            "",
            "    def __init__(self, **options):",
            "        from pygments.lexers.ruby import RubyLexer",
            "        self.ruby_lexer = RubyLexer(**options)",
            "        Lexer.__init__(self, **options)",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        \"\"\"",
            "        Since ERB doesn't allow \"<%\" and other tags inside of ruby",
            "        blocks we have to use a split approach here that fails for",
            "        that too.",
            "        \"\"\"",
            "        tokens = self._block_re.split(text)",
            "        tokens.reverse()",
            "        state = idx = 0",
            "        try:",
            "            while True:",
            "                # text",
            "                if state == 0:",
            "                    val = tokens.pop()",
            "                    yield idx, Other, val",
            "                    idx += len(val)",
            "                    state = 1",
            "                # block starts",
            "                elif state == 1:",
            "                    tag = tokens.pop()",
            "                    # literals",
            "                    if tag in ('<%%', '%%>'):",
            "                        yield idx, Other, tag",
            "                        idx += 3",
            "                        state = 0",
            "                    # comment",
            "                    elif tag == '<%#':",
            "                        yield idx, Comment.Preproc, tag",
            "                        val = tokens.pop()",
            "                        yield idx + 3, Comment, val",
            "                        idx += 3 + len(val)",
            "                        state = 2",
            "                    # blocks or output",
            "                    elif tag in ('<%', '<%=', '<%-'):",
            "                        yield idx, Comment.Preproc, tag",
            "                        idx += len(tag)",
            "                        data = tokens.pop()",
            "                        r_idx = 0",
            "                        for r_idx, r_token, r_value in \\",
            "                                self.ruby_lexer.get_tokens_unprocessed(data):",
            "                            yield r_idx + idx, r_token, r_value",
            "                        idx += len(data)",
            "                        state = 2",
            "                    elif tag in ('%>', '-%>'):",
            "                        yield idx, Error, tag",
            "                        idx += len(tag)",
            "                        state = 0",
            "                    # % raw ruby statements",
            "                    else:",
            "                        yield idx, Comment.Preproc, tag[0]",
            "                        r_idx = 0",
            "                        for r_idx, r_token, r_value in \\",
            "                                self.ruby_lexer.get_tokens_unprocessed(tag[1:]):",
            "                            yield idx + 1 + r_idx, r_token, r_value",
            "                        idx += len(tag)",
            "                        state = 0",
            "                # block ends",
            "                elif state == 2:",
            "                    tag = tokens.pop()",
            "                    if tag not in ('%>', '-%>'):",
            "                        yield idx, Other, tag",
            "                    else:",
            "                        yield idx, Comment.Preproc, tag",
            "                    idx += len(tag)",
            "                    state = 0",
            "        except IndexError:",
            "            return",
            "",
            "    def analyse_text(text):",
            "        if '<%' in text and '%>' in text:",
            "            return 0.4",
            "",
            "",
            "class SmartyLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `Smarty <http://smarty.php.net/>`_ template lexer.",
            "",
            "    Just highlights smarty code between the preprocessor directives, other",
            "    data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Smarty'",
            "    aliases = ['smarty']",
            "    filenames = ['*.tpl']",
            "    mimetypes = ['application/x-smarty']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'(\\{)(\\*.*?\\*)(\\})',",
            "             bygroups(Comment.Preproc, Comment, Comment.Preproc)),",
            "            (r'(\\{php\\})(.*?)(\\{/php\\})',",
            "             bygroups(Comment.Preproc, using(PhpLexer, startinline=True),",
            "                      Comment.Preproc)),",
            "            (r'(\\{)(/?[a-zA-Z_]\\w*)(\\s*)',",
            "             bygroups(Comment.Preproc, Name.Function, Text), 'smarty'),",
            "            (r'\\{', Comment.Preproc, 'smarty')",
            "        ],",
            "        'smarty': [",
            "            (r'\\s+', Text),",
            "            (r'\\{', Comment.Preproc, '#push'),",
            "            (r'\\}', Comment.Preproc, '#pop'),",
            "            (r'#[a-zA-Z_]\\w*#', Name.Variable),",
            "            (r'\\$[a-zA-Z_]\\w*(\\.\\w+)*', Name.Variable),",
            "            (r'[~!%^&*()+=|\\[\\]:;,.<>/?@-]', Operator),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'[a-zA-Z_]\\w*', Name.Attribute)",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\{if\\s+.*?\\}.*?\\{/if\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{include\\s+file=.*?\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{foreach\\s+.*?\\}.*?\\{/foreach\\}', text):",
            "            rv += 0.15",
            "        if re.search(r'\\{\\$.*?\\}', text):",
            "            rv += 0.01",
            "        return rv",
            "",
            "",
            "class VelocityLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `Velocity <http://velocity.apache.org/>`_ template lexer.",
            "",
            "    Just highlights velocity directives and variable references, other",
            "    data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Velocity'",
            "    aliases = ['velocity']",
            "    filenames = ['*.vm', '*.fhtml']",
            "",
            "    flags = re.MULTILINE | re.DOTALL",
            "",
            "    identifier = r'[a-zA-Z_]\\w*'",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{#$]+', Other),",
            "            (r'(#)(\\*.*?\\*)(#)',",
            "             bygroups(Comment.Preproc, Comment, Comment.Preproc)),",
            "            (r'(##)(.*?$)',",
            "             bygroups(Comment.Preproc, Comment)),",
            "            (r'(#\\{?)(' + identifier + r')(\\}?)(\\s?\\()',",
            "             bygroups(Comment.Preproc, Name.Function, Comment.Preproc, Punctuation),",
            "             'directiveparams'),",
            "            (r'(#\\{?)(' + identifier + r')(\\}|\\b)',",
            "             bygroups(Comment.Preproc, Name.Function, Comment.Preproc)),",
            "            (r'\\$!?\\{?', Punctuation, 'variable')",
            "        ],",
            "        'variable': [",
            "            (identifier, Name.Variable),",
            "            (r'\\(', Punctuation, 'funcparams'),",
            "            (r'(\\.)(' + identifier + r')',",
            "             bygroups(Punctuation, Name.Variable), '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "            default('#pop')",
            "        ],",
            "        'directiveparams': [",
            "            (r'(&&|\\|\\||==?|!=?|[-<>+*%&|^/])|\\b(eq|ne|gt|lt|ge|le|not|in)\\b',",
            "             Operator),",
            "            (r'\\[', Operator, 'rangeoperator'),",
            "            (r'\\b' + identifier + r'\\b', Name.Function),",
            "            include('funcparams')",
            "        ],",
            "        'rangeoperator': [",
            "            (r'\\.\\.', Operator),",
            "            include('funcparams'),",
            "            (r'\\]', Operator, '#pop')",
            "        ],",
            "        'funcparams': [",
            "            (r'\\$!?\\{?', Punctuation, 'variable'),",
            "            (r'\\s+', Text),",
            "            (r'[,:]', Punctuation),",
            "            (r'\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\"'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "            (r\"\\b[0-9]+\\b\", Number),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'\\(', Punctuation, '#push'),",
            "            (r'\\)', Punctuation, '#pop'),",
            "            (r'\\{', Punctuation, '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "            (r'\\[', Punctuation, '#push'),",
            "            (r'\\]', Punctuation, '#pop'),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'#\\{?macro\\}?\\(.*?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.25",
            "        if re.search(r'#\\{?if\\}?\\(.+?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.15",
            "        if re.search(r'#\\{?foreach\\}?\\(.+?\\).*?#\\{?end\\}?', text):",
            "            rv += 0.15",
            "        if re.search(r'\\$!?\\{?[a-zA-Z_]\\w*(\\([^)]*\\))?'",
            "                     r'(\\.\\w+(\\([^)]*\\))?)*\\}?', text):",
            "            rv += 0.01",
            "        return rv",
            "",
            "",
            "class VelocityHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `VelocityLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    \"\"\"",
            "",
            "    name = 'HTML+Velocity'",
            "    aliases = ['html+velocity']",
            "    alias_filenames = ['*.html', '*.fhtml']",
            "    mimetypes = ['text/html+velocity']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, VelocityLexer, **options)",
            "",
            "",
            "class VelocityXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `VelocityLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    \"\"\"",
            "",
            "    name = 'XML+Velocity'",
            "    aliases = ['xml+velocity']",
            "    alias_filenames = ['*.xml', '*.vm']",
            "    mimetypes = ['application/xml+velocity']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, VelocityLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = VelocityLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class DjangoLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `django <http://www.djangoproject.com/documentation/templates/>`_",
            "    and `jinja <https://jinja.pocoo.org/jinja/>`_ template lexer.",
            "",
            "    It just highlights django/jinja code between the preprocessor directives,",
            "    other data is left untouched by the lexer.",
            "    \"\"\"",
            "",
            "    name = 'Django/Jinja'",
            "    aliases = ['django', 'jinja']",
            "    mimetypes = ['application/x-django-templating', 'application/x-jinja']",
            "",
            "    flags = re.M | re.S",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'\\{\\{', Comment.Preproc, 'var'),",
            "            # jinja/django comments",
            "            (r'\\{#.*?#\\}', Comment),",
            "            # django comments",
            "            (r'(\\{%)(-?\\s*)(comment)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endcomment)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Comment, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # raw jinja blocks",
            "            (r'(\\{%)(-?\\s*)(raw)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endraw)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Text, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # filter blocks",
            "            (r'(\\{%)(-?\\s*)(filter)(\\s+)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Name.Function),",
            "             'block'),",
            "            (r'(\\{%)(-?\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword), 'block'),",
            "            (r'\\{', Other)",
            "        ],",
            "        'varnames': [",
            "            (r'(\\|)(\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Operator, Text, Name.Function)),",
            "            (r'(is)(\\s+)(not)?(\\s+)?([a-zA-Z_]\\w*)',",
            "             bygroups(Keyword, Text, Keyword, Text, Name.Function)),",
            "            (r'(_|true|false|none|True|False|None)\\b', Keyword.Pseudo),",
            "            (r'(in|as|reversed|recursive|not|and|or|is|if|else|import|'",
            "             r'with(?:(?:out)?\\s*context)?|scoped|ignore\\s+missing)\\b',",
            "             Keyword),",
            "            (r'(loop|block|super|forloop)\\b', Name.Builtin),",
            "            (r'[a-zA-Z_][\\w-]*', Name.Variable),",
            "            (r'\\.\\w+', Name.Variable),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'([{}()\\[\\]+\\-*/%,:~]|[><=]=?|!=)', Operator),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ],",
            "        'var': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(\\}\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames')",
            "        ],",
            "        'block': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(%\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames'),",
            "            (r'.', Punctuation)",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\{%\\s*(block|extends)', text) is not None:",
            "            rv += 0.4",
            "        if re.search(r'\\{%\\s*if\\s*.*?%\\}', text) is not None:",
            "            rv += 0.1",
            "        if re.search(r'\\{\\{.*?\\}\\}', text) is not None:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class MyghtyLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `myghty templates`_ lexer. Code that isn't Myghty",
            "    markup is yielded as `Token.Other`.",
            "",
            "    .. versionadded:: 0.6",
            "",
            "    .. _myghty templates: http://www.myghty.org/",
            "    \"\"\"",
            "",
            "    name = 'Myghty'",
            "    aliases = ['myghty']",
            "    filenames = ['*.myt', 'autodelegate']",
            "    mimetypes = ['application/x-myghty']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'(?s)(<%(?:def|method))(\\s*)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Text, Name.Function, Name.Tag,",
            "                      using(this), Name.Tag)),",
            "            (r'(?s)(<%\\w+)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Name.Function, Name.Tag,",
            "                      using(PythonLexer), Name.Tag)),",
            "            (r'(<&[^|])(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PythonLexer), Name.Tag)),",
            "            (r'(?s)(<&\\|)(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PythonLexer), Name.Tag)),",
            "            (r'</&>', Name.Tag),",
            "            (r'(?s)(<%!?)(.*?)(%>)',",
            "             bygroups(Name.Tag, using(PythonLexer), Name.Tag)),",
            "            (r'(?<=^)#[^\\n]*(\\n|\\Z)', Comment),",
            "            (r'(?<=^)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Name.Tag, using(PythonLexer), Other)),",
            "            (r\"\"\"(?sx)",
            "                 (.+?)               # anything, followed by:",
            "                 (?:",
            "                  (?<=\\n)(?=[%#]) |  # an eval or comment line",
            "                  (?=</?[%&]) |      # a substitution or block or",
            "                                     # call start or end",
            "                                     # - don't consume",
            "                  (\\\\\\n) |           # an escaped newline",
            "                  \\Z                 # end of string",
            "                 )\"\"\", bygroups(Other, Operator)),",
            "        ]",
            "    }",
            "",
            "",
            "class MyghtyHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'HTML+Myghty'",
            "    aliases = ['html+myghty']",
            "    mimetypes = ['text/html+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'XML+Myghty'",
            "    aliases = ['xml+myghty']",
            "    mimetypes = ['application/xml+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Myghty'",
            "    aliases = ['js+myghty', 'javascript+myghty']",
            "    mimetypes = ['application/x-javascript+myghty',",
            "                 'text/x-javascript+myghty',",
            "                 'text/javascript+mygthy']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MyghtyCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MyghtyLexer` that highlights unlexed data",
            "    with the `CssLexer`.",
            "",
            "    .. versionadded:: 0.6",
            "    \"\"\"",
            "",
            "    name = 'CSS+Myghty'",
            "    aliases = ['css+myghty']",
            "    mimetypes = ['text/css+myghty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, MyghtyLexer, **options)",
            "",
            "",
            "class MasonLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `mason templates`_ lexer. Stolen from Myghty lexer. Code that isn't",
            "    Mason markup is HTML.",
            "",
            "    .. _mason templates: http://www.masonhq.com/",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Mason'",
            "    aliases = ['mason']",
            "    filenames = ['*.m', '*.mhtml', '*.mc', '*.mi', 'autohandler', 'dhandler']",
            "    mimetypes = ['application/x-mason']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'\\s+', Text),",
            "            (r'(?s)(<%doc>)(.*?)(</%doc>)',",
            "             bygroups(Name.Tag, Comment.Multiline, Name.Tag)),",
            "            (r'(?s)(<%(?:def|method))(\\s*)(.*?)(>)(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, Text, Name.Function, Name.Tag,",
            "                      using(this), Name.Tag)),",
            "            (r'(?s)(<%(\\w+)(.*?)(>))(.*?)(</%\\2\\s*>)',",
            "             bygroups(Name.Tag, None, None, None, using(PerlLexer), Name.Tag)),",
            "            (r'(?s)(<&[^|])(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PerlLexer), Name.Tag)),",
            "            (r'(?s)(<&\\|)(.*?)(,.*?)?(&>)',",
            "             bygroups(Name.Tag, Name.Function, using(PerlLexer), Name.Tag)),",
            "            (r'</&>', Name.Tag),",
            "            (r'(?s)(<%!?)(.*?)(%>)',",
            "             bygroups(Name.Tag, using(PerlLexer), Name.Tag)),",
            "            (r'(?<=^)#[^\\n]*(\\n|\\Z)', Comment),",
            "            (r'(?<=^)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Name.Tag, using(PerlLexer), Other)),",
            "            (r\"\"\"(?sx)",
            "                 (.+?)               # anything, followed by:",
            "                 (?:",
            "                  (?<=\\n)(?=[%#]) |  # an eval or comment line",
            "                  (?=</?[%&]) |      # a substitution or block or",
            "                                     # call start or end",
            "                                     # - don't consume",
            "                  (\\\\\\n) |           # an escaped newline",
            "                  \\Z                 # end of string",
            "                 )\"\"\", bygroups(using(HtmlLexer), Operator)),",
            "        ]",
            "    }",
            "",
            "    def analyse_text(text):",
            "        result = 0.0",
            "        if re.search(r'</%(class|doc|init)>', text) is not None:",
            "            result = 1.0",
            "        elif re.search(r'<&.+&>', text, re.DOTALL) is not None:",
            "            result = 0.11",
            "        return result",
            "",
            "",
            "class MakoLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `mako templates`_ lexer. Code that isn't Mako",
            "    markup is yielded as `Token.Other`.",
            "",
            "    .. versionadded:: 0.7",
            "",
            "    .. _mako templates: http://www.makotemplates.org/",
            "    \"\"\"",
            "",
            "    name = 'Mako'",
            "    aliases = ['mako']",
            "    filenames = ['*.mao']",
            "    mimetypes = ['application/x-mako']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'(\\s*)(%)(\\s*end(?:\\w+))(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, Keyword, Other)),",
            "            (r'(\\s*)(%)([^\\n]*)(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, using(PythonLexer), Other)),",
            "            (r'(\\s*)(##[^\\n]*)(\\n|\\Z)',",
            "             bygroups(Text, Comment.Preproc, Other)),",
            "            (r'(?s)<%doc>.*?</%doc>', Comment.Preproc),",
            "            (r'(<%)([\\w.:]+)',",
            "             bygroups(Comment.Preproc, Name.Builtin), 'tag'),",
            "            (r'(</%)([\\w.:]+)(>)',",
            "             bygroups(Comment.Preproc, Name.Builtin, Comment.Preproc)),",
            "            (r'<%(?=([\\w.:]+))', Comment.Preproc, 'ondeftags'),",
            "            (r'(?s)(<%(?:!?))(.*?)(%>)',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(\\$\\{)(.*?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'''(?sx)",
            "                (.+?)                # anything, followed by:",
            "                (?:",
            "                 (?<=\\n)(?=%|\\#\\#) | # an eval or comment line",
            "                 (?=\\#\\*) |          # multiline comment",
            "                 (?=</?%) |          # a python block",
            "                                     # call start or end",
            "                 (?=\\$\\{) |          # a substitution",
            "                 (?<=\\n)(?=\\s*%) |",
            "                                     # - don't consume",
            "                 (\\\\\\n) |            # an escaped newline",
            "                 \\Z                  # end of string",
            "                )",
            "            ''', bygroups(Other, Operator)),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'ondeftags': [",
            "            (r'<%', Comment.Preproc),",
            "            (r'(?<=<%)(include|inherit|namespace|page)', Name.Builtin),",
            "            include('tag'),",
            "        ],",
            "        'tag': [",
            "            (r'((?:\\w+)\\s*=)(\\s*)(\".*?\")',",
            "             bygroups(Name.Attribute, Text, String)),",
            "            (r'/?\\s*>', Comment.Preproc, '#pop'),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'attr': [",
            "            ('\".*?\"', String, '#pop'),",
            "            (\"'.*?'\", String, '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class MakoHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'HTML+Mako'",
            "    aliases = ['html+mako']",
            "    mimetypes = ['text/html+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'XML+Mako'",
            "    aliases = ['xml+mako']",
            "    mimetypes = ['application/xml+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Mako'",
            "    aliases = ['js+mako', 'javascript+mako']",
            "    mimetypes = ['application/x-javascript+mako',",
            "                 'text/x-javascript+mako',",
            "                 'text/javascript+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, MakoLexer, **options)",
            "",
            "",
            "class MakoCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `MakoLexer` that highlights unlexed data",
            "    with the `CssLexer`.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    name = 'CSS+Mako'",
            "    aliases = ['css+mako']",
            "    mimetypes = ['text/css+mako']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, MakoLexer, **options)",
            "",
            "",
            "# Genshi and Cheetah lexers courtesy of Matt Good.",
            "",
            "class CheetahPythonLexer(Lexer):",
            "    \"\"\"",
            "    Lexer for handling Cheetah's special $ tokens in Python syntax.",
            "    \"\"\"",
            "",
            "    def get_tokens_unprocessed(self, text):",
            "        pylexer = PythonLexer(**self.options)",
            "        for pos, type_, value in pylexer.get_tokens_unprocessed(text):",
            "            if type_ == Token.Error and value == '$':",
            "                type_ = Comment.Preproc",
            "            yield pos, type_, value",
            "",
            "",
            "class CheetahLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `cheetah templates`_ lexer. Code that isn't Cheetah",
            "    markup is yielded as `Token.Other`.  This also works for",
            "    `spitfire templates`_ which use the same syntax.",
            "",
            "    .. _cheetah templates: http://www.cheetahtemplate.org/",
            "    .. _spitfire templates: http://code.google.com/p/spitfire/",
            "    \"\"\"",
            "",
            "    name = 'Cheetah'",
            "    aliases = ['cheetah', 'spitfire']",
            "    filenames = ['*.tmpl', '*.spt']",
            "    mimetypes = ['application/x-cheetah', 'application/x-spitfire']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'(##[^\\n]*)$',",
            "             (bygroups(Comment))),",
            "            (r'#[*](.|\\n)*?[*]#', Comment),",
            "            (r'#end[^#\\n]*(?:#|$)', Comment.Preproc),",
            "            (r'#slurp$', Comment.Preproc),",
            "            (r'(#[a-zA-Z]+)([^#\\n]*)(#|$)',",
            "             (bygroups(Comment.Preproc, using(CheetahPythonLexer),",
            "                       Comment.Preproc))),",
            "            # TODO support other Python syntax like $foo['bar']",
            "            (r'(\\$)([a-zA-Z_][\\w.]*\\w)',",
            "             bygroups(Comment.Preproc, using(CheetahPythonLexer))),",
            "            (r'(?s)(\\$\\{!?)(.*?)(\\})',",
            "             bygroups(Comment.Preproc, using(CheetahPythonLexer),",
            "                      Comment.Preproc)),",
            "            (r'''(?sx)",
            "                (.+?)               # anything, followed by:",
            "                (?:",
            "                 (?=\\#[#a-zA-Z]*) | # an eval comment",
            "                 (?=\\$[a-zA-Z_{]) | # a substitution",
            "                 \\Z                 # end of string",
            "                )",
            "            ''', Other),",
            "            (r'\\s+', Text),",
            "        ],",
            "    }",
            "",
            "",
            "class CheetahHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `HtmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Cheetah'",
            "    aliases = ['html+cheetah', 'html+spitfire', 'htmlcheetah']",
            "    mimetypes = ['text/html+cheetah', 'text/html+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, CheetahLexer, **options)",
            "",
            "",
            "class CheetahXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Cheetah'",
            "    aliases = ['xml+cheetah', 'xml+spitfire']",
            "    mimetypes = ['application/xml+cheetah', 'application/xml+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, CheetahLexer, **options)",
            "",
            "",
            "class CheetahJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `CheetahLexer` that highlights unlexed data",
            "    with the `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Cheetah'",
            "    aliases = ['js+cheetah', 'javascript+cheetah',",
            "               'js+spitfire', 'javascript+spitfire']",
            "    mimetypes = ['application/x-javascript+cheetah',",
            "                 'text/x-javascript+cheetah',",
            "                 'text/javascript+cheetah',",
            "                 'application/x-javascript+spitfire',",
            "                 'text/x-javascript+spitfire',",
            "                 'text/javascript+spitfire']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, CheetahLexer, **options)",
            "",
            "",
            "class GenshiTextLexer(RegexLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ text",
            "    templates.",
            "    \"\"\"",
            "",
            "    name = 'Genshi Text'",
            "    aliases = ['genshitext']",
            "    mimetypes = ['application/x-genshi-text', 'text/x-genshi']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^#$\\s]+', Other),",
            "            (r'^(\\s*)(##.*)$', bygroups(Text, Comment)),",
            "            (r'^(\\s*)(#)', bygroups(Text, Comment.Preproc), 'directive'),",
            "            include('variable'),",
            "            (r'[#$\\s]', Other),",
            "        ],",
            "        'directive': [",
            "            (r'\\n', Text, '#pop'),",
            "            (r'(?:def|for|if)\\s+.*', using(PythonLexer), '#pop'),",
            "            (r'(choose|when|with)([^\\S\\n]+)(.*)',",
            "             bygroups(Keyword, Text, using(PythonLexer)), '#pop'),",
            "            (r'(choose|otherwise)\\b', Keyword, '#pop'),",
            "            (r'(end\\w*)([^\\S\\n]*)(.*)', bygroups(Keyword, Text, Comment), '#pop'),",
            "        ],",
            "        'variable': [",
            "            (r'(?<!\\$)(\\$\\{)(.+?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(?<!\\$)(\\$)([a-zA-Z_][\\w.]*)',",
            "             Name.Variable),",
            "        ]",
            "    }",
            "",
            "",
            "class GenshiMarkupLexer(RegexLexer):",
            "    \"\"\"",
            "    Base lexer for Genshi markup, used by `HtmlGenshiLexer` and",
            "    `GenshiLexer`.",
            "    \"\"\"",
            "",
            "    flags = re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^<$]+', Other),",
            "            (r'(<\\?python)(.*?)(\\?>)',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            # yield style and script blocks as Other",
            "            (r'<\\s*(script|style)\\s*.*?>.*?<\\s*/\\1\\s*>', Other),",
            "            (r'<\\s*py:[a-zA-Z0-9]+', Name.Tag, 'pytag'),",
            "            (r'<\\s*[a-zA-Z0-9:.]+', Name.Tag, 'tag'),",
            "            include('variable'),",
            "            (r'[<$]', Other),",
            "        ],",
            "        'pytag': [",
            "            (r'\\s+', Text),",
            "            (r'[\\w:-]+\\s*=', Name.Attribute, 'pyattr'),",
            "            (r'/?\\s*>', Name.Tag, '#pop'),",
            "        ],",
            "        'pyattr': [",
            "            ('(\")(.*?)(\")', bygroups(String, using(PythonLexer), String), '#pop'),",
            "            (\"(')(.*?)(')\", bygroups(String, using(PythonLexer), String), '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            (r'py:[\\w-]+\\s*=', Name.Attribute, 'pyattr'),",
            "            (r'[\\w:-]+\\s*=', Name.Attribute, 'attr'),",
            "            (r'/?\\s*>', Name.Tag, '#pop'),",
            "        ],",
            "        'attr': [",
            "            ('\"', String, 'attr-dstring'),",
            "            (\"'\", String, 'attr-sstring'),",
            "            (r'[^\\s>]*', String, '#pop')",
            "        ],",
            "        'attr-dstring': [",
            "            ('\"', String, '#pop'),",
            "            include('strings'),",
            "            (\"'\", String)",
            "        ],",
            "        'attr-sstring': [",
            "            (\"'\", String, '#pop'),",
            "            include('strings'),",
            "            (\"'\", String)",
            "        ],",
            "        'strings': [",
            "            ('[^\"\\'$]+', String),",
            "            include('variable')",
            "        ],",
            "        'variable': [",
            "            (r'(?<!\\$)(\\$\\{)(.+?)(\\})',",
            "             bygroups(Comment.Preproc, using(PythonLexer), Comment.Preproc)),",
            "            (r'(?<!\\$)(\\$)([a-zA-Z_][\\w\\.]*)',",
            "             Name.Variable),",
            "        ]",
            "    }",
            "",
            "",
            "class HtmlGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ and",
            "    `kid <http://kid-templating.org/>`_ kid HTML templates.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Genshi'",
            "    aliases = ['html+genshi', 'html+kid']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, GenshiMarkupLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\$\\{.*?\\}', text) is not None:",
            "            rv += 0.2",
            "        if re.search(r'py:(.*?)=[\"\\']', text) is not None:",
            "            rv += 0.2",
            "        return rv + HtmlLexer.analyse_text(text) - 0.01",
            "",
            "",
            "class GenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights `genshi <http://genshi.edgewall.org/>`_ and",
            "    `kid <http://kid-templating.org/>`_ kid XML templates.",
            "    \"\"\"",
            "",
            "    name = 'Genshi'",
            "    aliases = ['genshi', 'kid', 'xml+genshi', 'xml+kid']",
            "    filenames = ['*.kid']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/x-genshi', 'application/x-kid']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, GenshiMarkupLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'\\$\\{.*?\\}', text) is not None:",
            "            rv += 0.2",
            "        if re.search(r'py:(.*?)=[\"\\']', text) is not None:",
            "            rv += 0.2",
            "        return rv + XmlLexer.analyse_text(text) - 0.01",
            "",
            "",
            "class JavascriptGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights javascript code in genshi text templates.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Genshi Text'",
            "    aliases = ['js+genshitext', 'js+genshi', 'javascript+genshitext',",
            "               'javascript+genshi']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+genshi',",
            "                 'text/x-javascript+genshi',",
            "                 'text/javascript+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, GenshiTextLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return GenshiLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class CssGenshiLexer(DelegatingLexer):",
            "    \"\"\"",
            "    A lexer that highlights CSS definitions in genshi text templates.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Genshi Text'",
            "    aliases = ['css+genshitext', 'css+genshi']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+genshi']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, GenshiTextLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return GenshiLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class RhtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the ERB lexer that highlights the unlexed data with the",
            "    html lexer.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'RHTML'",
            "    aliases = ['rhtml', 'html+erb', 'html+ruby']",
            "    filenames = ['*.rhtml']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = ErbLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            # one more than the XmlErbLexer returns",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights data outside preprocessor",
            "    directives with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Ruby'",
            "    aliases = ['xml+erb', 'xml+ruby']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/xml+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = ErbLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights unlexed data with the `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Ruby'",
            "    aliases = ['css+erb', 'css+ruby']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return ErbLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptErbLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `ErbLexer` which highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Ruby'",
            "    aliases = ['js+erb', 'javascript+erb', 'js+ruby', 'javascript+ruby']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+ruby',",
            "                 'text/x-javascript+ruby',",
            "                 'text/javascript+ruby']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, ErbLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return ErbLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class HtmlPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` that highlights unhandled data with the `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+PHP'",
            "    aliases = ['html+php']",
            "    filenames = ['*.phtml']",
            "    alias_filenames = ['*.php', '*.html', '*.htm', '*.xhtml',",
            "                       '*.php[345]']",
            "    mimetypes = ['application/x-php',",
            "                 'application/x-httpd-php', 'application/x-httpd-php3',",
            "                 'application/x-httpd-php4', 'application/x-httpd-php5']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = PhpLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` that highlights unhandled data with the `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+PHP'",
            "    aliases = ['xml+php']",
            "    alias_filenames = ['*.xml', '*.php', '*.php[345]']",
            "    mimetypes = ['application/xml+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = PhpLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` which highlights unmatched data with the `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+PHP'",
            "    aliases = ['css+php']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return PhpLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptPhpLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of `PhpLexer` which highlights unmatched data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+PHP'",
            "    aliases = ['js+php', 'javascript+php']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+php',",
            "                 'text/x-javascript+php',",
            "                 'text/javascript+php']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, PhpLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return PhpLexer.analyse_text(text)",
            "",
            "",
            "class HtmlSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Smarty'",
            "    aliases = ['html+smarty']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml', '*.tpl']",
            "    mimetypes = ['text/html+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = SmartyLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Smarty'",
            "    aliases = ['xml+smarty']",
            "    alias_filenames = ['*.xml', '*.tpl']",
            "    mimetypes = ['application/xml+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = SmartyLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Smarty'",
            "    aliases = ['css+smarty']",
            "    alias_filenames = ['*.css', '*.tpl']",
            "    mimetypes = ['text/css+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return SmartyLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptSmartyLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `SmartyLexer` that highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Smarty'",
            "    aliases = ['js+smarty', 'javascript+smarty']",
            "    alias_filenames = ['*.js', '*.tpl']",
            "    mimetypes = ['application/x-javascript+smarty',",
            "                 'text/x-javascript+smarty',",
            "                 'text/javascript+smarty']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, SmartyLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return SmartyLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class HtmlDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested Javascript and CSS is highlighted too.",
            "    \"\"\"",
            "",
            "    name = 'HTML+Django/Jinja'",
            "    aliases = ['html+django', 'html+jinja', 'htmldjango']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml']",
            "    mimetypes = ['text/html+django', 'text/html+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = DjangoLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class XmlDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "    \"\"\"",
            "",
            "    name = 'XML+Django/Jinja'",
            "    aliases = ['xml+django', 'xml+jinja']",
            "    alias_filenames = ['*.xml']",
            "    mimetypes = ['application/xml+django', 'application/xml+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = DjangoLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class CssDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `CssLexer`.",
            "    \"\"\"",
            "",
            "    name = 'CSS+Django/Jinja'",
            "    aliases = ['css+django', 'css+jinja']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+django', 'text/css+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(CssLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return DjangoLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JavascriptDjangoLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `JavascriptLexer`.",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Django/Jinja'",
            "    aliases = ['js+django', 'javascript+django',",
            "               'js+jinja', 'javascript+jinja']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+django',",
            "                 'application/x-javascript+jinja',",
            "                 'text/x-javascript+django',",
            "                 'text/x-javascript+jinja',",
            "                 'text/javascript+django',",
            "                 'text/javascript+jinja']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(JavascriptLexer, DjangoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return DjangoLexer.analyse_text(text) - 0.05",
            "",
            "",
            "class JspRootLexer(RegexLexer):",
            "    \"\"\"",
            "    Base for the `JspLexer`. Yields `Token.Other` for area outside of",
            "    JSP tags.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'<%\\S?', Keyword, 'sec'),",
            "            # FIXME: I want to make these keywords but still parse attributes.",
            "            (r'</?jsp:(forward|getProperty|include|plugin|setProperty|useBean).*?>',",
            "             Keyword),",
            "            (r'[^<]+', Other),",
            "            (r'<', Other),",
            "        ],",
            "        'sec': [",
            "            (r'%>', Keyword, '#pop'),",
            "            # note: '\\w\\W' != '.' without DOTALL.",
            "            (r'[\\w\\W]+?(?=%>|\\Z)', using(JavaLexer)),",
            "        ],",
            "    }",
            "",
            "",
            "class JspLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for Java Server Pages.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "    name = 'Java Server Page'",
            "    aliases = ['jsp']",
            "    filenames = ['*.jsp']",
            "    mimetypes = ['application/x-jsp']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, JspRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = JavaLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class EvoqueLexer(RegexLexer):",
            "    \"\"\"",
            "    For files using the Evoque templating system.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'Evoque'",
            "    aliases = ['evoque']",
            "    filenames = ['*.evoque']",
            "    mimetypes = ['application/x-evoque']",
            "",
            "    flags = re.DOTALL",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^#$]+', Other),",
            "            (r'#\\[', Comment.Multiline, 'comment'),",
            "            (r'\\$\\$', Other),",
            "            # svn keywords",
            "            (r'\\$\\w+:[^$\\n]*\\$', Comment.Multiline),",
            "            # directives: begin, end",
            "            (r'(\\$)(begin|end)(\\{(%)?)(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      String, Punctuation)),",
            "            # directives: evoque, overlay",
            "            # see doc for handling first name arg: /directives/evoque/",
            "            # + minor inconsistency: the \"name\" in e.g. $overlay{name=site_base}",
            "            # should be using(PythonLexer), not passed out as String",
            "            (r'(\\$)(evoque|overlay)(\\{(%)?)(\\s*[#\\w\\-\"\\'.]+)?'",
            "             r'(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      String, using(PythonLexer), Punctuation)),",
            "            # directives: if, for, prefer, test",
            "            (r'(\\$)(\\w+)(\\{(%)?)(.*?)((?(4)%)\\})',",
            "             bygroups(Punctuation, Name.Builtin, Punctuation, None,",
            "                      using(PythonLexer), Punctuation)),",
            "            # directive clauses (no {} expression)",
            "            (r'(\\$)(else|rof|fi)', bygroups(Punctuation, Name.Builtin)),",
            "            # expressions",
            "            (r'(\\$\\{(%)?)(.*?)((!)(.*?))?((?(2)%)\\})',",
            "             bygroups(Punctuation, None, using(PythonLexer),",
            "                      Name.Builtin, None, None, Punctuation)),",
            "            (r'#', Other),",
            "        ],",
            "        'comment': [",
            "            (r'[^\\]#]', Comment.Multiline),",
            "            (r'#\\[', Comment.Multiline, '#push'),",
            "            (r'\\]#', Comment.Multiline, '#pop'),",
            "            (r'[\\]#]', Comment.Multiline)",
            "        ],",
            "    }",
            "",
            "    def analyse_text(text):",
            "        \"\"\"Evoque templates use $evoque, which is unique.\"\"\"",
            "        if '$evoque' in text:",
            "            return 1",
            "",
            "class EvoqueHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `EvoqueLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'HTML+Evoque'",
            "    aliases = ['html+evoque']",
            "    filenames = ['*.html']",
            "    mimetypes = ['text/html+evoque']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, EvoqueLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return EvoqueLexer.analyse_text(text)",
            "",
            "",
            "class EvoqueXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `EvoqueLexer` that highlights unlexed data with the",
            "    `XmlLexer`.",
            "",
            "    .. versionadded:: 1.1",
            "    \"\"\"",
            "    name = 'XML+Evoque'",
            "    aliases = ['xml+evoque']",
            "    filenames = ['*.xml']",
            "    mimetypes = ['application/xml+evoque']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, EvoqueLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        return EvoqueLexer.analyse_text(text)",
            "",
            "",
            "class ColdfusionLexer(RegexLexer):",
            "    \"\"\"",
            "    Coldfusion statements",
            "    \"\"\"",
            "    name = 'cfstatement'",
            "    aliases = ['cfs']",
            "    filenames = []",
            "    mimetypes = []",
            "    flags = re.IGNORECASE",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'//.*?\\n', Comment.Single),",
            "            (r'/\\*(?:.|\\n)*?\\*/', Comment.Multiline),",
            "            (r'\\+\\+|--', Operator),",
            "            (r'[-+*/^&=!]', Operator),",
            "            (r'<=|>=|<|>|==', Operator),",
            "            (r'mod\\b', Operator),",
            "            (r'(eq|lt|gt|lte|gte|not|is|and|or)\\b', Operator),",
            "            (r'\\|\\||&&', Operator),",
            "            (r'\\?', Operator),",
            "            (r'\"', String.Double, 'string'),",
            "            # There is a special rule for allowing html in single quoted",
            "            # strings, evidently.",
            "            (r\"'.*?'\", String.Single),",
            "            (r'\\d+', Number),",
            "            (r'(if|else|len|var|xml|default|break|switch|component|property|function|do|'",
            "             r'try|catch|in|continue|for|return|while|required|any|array|binary|boolean|'",
            "             r'component|date|guid|numeric|query|string|struct|uuid|case)\\b', Keyword),",
            "            (r'(true|false|null)\\b', Keyword.Constant),",
            "            (r'(application|session|client|cookie|super|this|variables|arguments)\\b',",
            "             Name.Constant),",
            "            (r'([a-z_$][\\w.]*)(\\s*)(\\()',",
            "             bygroups(Name.Function, Text, Punctuation)),",
            "            (r'[a-z_$][\\w.]*', Name.Variable),",
            "            (r'[()\\[\\]{};:,.\\\\]', Punctuation),",
            "            (r'\\s+', Text),",
            "        ],",
            "        'string': [",
            "            (r'\"\"', String.Double),",
            "            (r'#.+?#', String.Interp),",
            "            (r'[^\"#]+', String.Double),",
            "            (r'#', String.Double),",
            "            (r'\"', String.Double, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class ColdfusionMarkupLexer(RegexLexer):",
            "    \"\"\"",
            "    Coldfusion markup only",
            "    \"\"\"",
            "    name = 'Coldfusion'",
            "    aliases = ['cf']",
            "    filenames = []",
            "    mimetypes = []",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^<]+', Other),",
            "            include('tags'),",
            "            (r'<[^<>]*', Other),",
            "        ],",
            "        'tags': [",
            "            (r'<!---', Comment.Multiline, 'cfcomment'),",
            "            (r'(?s)<!--.*?-->', Comment),",
            "            (r'<cfoutput.*?>', Name.Builtin, 'cfoutput'),",
            "            (r'(?s)(<cfscript.*?>)(.+?)(</cfscript.*?>)',",
            "             bygroups(Name.Builtin, using(ColdfusionLexer), Name.Builtin)),",
            "            # negative lookbehind is for strings with embedded >",
            "            (r'(?s)(</?cf(?:component|include|if|else|elseif|loop|return|'",
            "             r'dbinfo|dump|abort|location|invoke|throw|file|savecontent|'",
            "             r'mailpart|mail|header|content|zip|image|lock|argument|try|'",
            "             r'catch|break|directory|http|set|function|param)\\b)(.*?)((?<!\\\\)>)',",
            "             bygroups(Name.Builtin, using(ColdfusionLexer), Name.Builtin)),",
            "        ],",
            "        'cfoutput': [",
            "            (r'[^#<]+', Other),",
            "            (r'(#)(.*?)(#)', bygroups(Punctuation, using(ColdfusionLexer),",
            "                                      Punctuation)),",
            "            # (r'<cfoutput.*?>', Name.Builtin, '#push'),",
            "            (r'</cfoutput.*?>', Name.Builtin, '#pop'),",
            "            include('tags'),",
            "            (r'(?s)<[^<>]*', Other),",
            "            (r'#', Other),",
            "        ],",
            "        'cfcomment': [",
            "            (r'<!---', Comment.Multiline, '#push'),",
            "            (r'--->', Comment.Multiline, '#pop'),",
            "            (r'([^<-]|<(?!!---)|-(?!-->))+', Comment.Multiline),",
            "        ],",
            "    }",
            "",
            "",
            "class ColdfusionHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Coldfusion markup in html",
            "    \"\"\"",
            "    name = 'Coldfusion HTML'",
            "    aliases = ['cfm']",
            "    filenames = ['*.cfm', '*.cfml']",
            "    mimetypes = ['application/x-coldfusion']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, ColdfusionMarkupLexer, **options)",
            "",
            "",
            "class ColdfusionCFCLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Coldfusion markup/script components",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'Coldfusion CFC'",
            "    aliases = ['cfc']",
            "    filenames = ['*.cfc']",
            "    mimetypes = []",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(ColdfusionHtmlLexer, ColdfusionLexer, **options)",
            "",
            "",
            "class SspLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for Scalate Server Pages.",
            "",
            "    .. versionadded:: 1.4",
            "    \"\"\"",
            "    name = 'Scalate Server Page'",
            "    aliases = ['ssp']",
            "    filenames = ['*.ssp']",
            "    mimetypes = ['application/x-ssp']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, JspRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = 0.0",
            "        if re.search(r'val \\w+\\s*:', text):",
            "            rv += 0.6",
            "        if looks_like_xml(text):",
            "            rv += 0.2",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class TeaTemplateRootLexer(RegexLexer):",
            "    \"\"\"",
            "    Base for the `TeaTemplateLexer`. Yields `Token.Other` for area outside of",
            "    code blocks.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'<%\\S?', Keyword, 'sec'),",
            "            (r'[^<]+', Other),",
            "            (r'<', Other),",
            "        ],",
            "        'sec': [",
            "            (r'%>', Keyword, '#pop'),",
            "            # note: '\\w\\W' != '.' without DOTALL.",
            "            (r'[\\w\\W]+?(?=%>|\\Z)', using(TeaLangLexer)),",
            "        ],",
            "    }",
            "",
            "",
            "class TeaTemplateLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Lexer for `Tea Templates <http://teatrove.org/>`_.",
            "",
            "    .. versionadded:: 1.5",
            "    \"\"\"",
            "    name = 'Tea'",
            "    aliases = ['tea']",
            "    filenames = ['*.tea']",
            "    mimetypes = ['text/x-tea']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, TeaTemplateRootLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = TeaLangLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        if '<%' in text and '%>' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class LassoHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `HtmlLexer`.",
            "",
            "    Nested JavaScript and CSS is also highlighted.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'HTML+Lasso'",
            "    aliases = ['html+lasso']",
            "    alias_filenames = ['*.html', '*.htm', '*.xhtml', '*.lasso', '*.lasso[89]',",
            "                       '*.incl', '*.inc', '*.las']",
            "    mimetypes = ['text/html+lasso',",
            "                 'application/x-httpd-lasso',",
            "                 'application/x-httpd-lasso[89]']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.01",
            "        if html_doctype_matches(text):  # same as HTML lexer",
            "            rv += 0.5",
            "        return rv",
            "",
            "",
            "class LassoXmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `XmlLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'XML+Lasso'",
            "    aliases = ['xml+lasso']",
            "    alias_filenames = ['*.xml', '*.lasso', '*.lasso[89]',",
            "                       '*.incl', '*.inc', '*.las']",
            "    mimetypes = ['application/xml+lasso']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(XmlLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.01",
            "        if looks_like_xml(text):",
            "            rv += 0.4",
            "        return rv",
            "",
            "",
            "class LassoCssLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `CssLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'CSS+Lasso'",
            "    aliases = ['css+lasso']",
            "    alias_filenames = ['*.css']",
            "    mimetypes = ['text/css+lasso']",
            "",
            "    def __init__(self, **options):",
            "        options['requiredelimiters'] = True",
            "        super().__init__(CssLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.05",
            "        if re.search(r'\\w+:[^;]+;', text):",
            "            rv += 0.1",
            "        if 'padding:' in text:",
            "            rv += 0.1",
            "        return rv",
            "",
            "",
            "class LassoJavascriptLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `LassoLexer` which highlights unhandled data with the",
            "    `JavascriptLexer`.",
            "",
            "    .. versionadded:: 1.6",
            "    \"\"\"",
            "",
            "    name = 'JavaScript+Lasso'",
            "    aliases = ['js+lasso', 'javascript+lasso']",
            "    alias_filenames = ['*.js']",
            "    mimetypes = ['application/x-javascript+lasso',",
            "                 'text/x-javascript+lasso',",
            "                 'text/javascript+lasso']",
            "",
            "    def __init__(self, **options):",
            "        options['requiredelimiters'] = True",
            "        super().__init__(JavascriptLexer, LassoLexer, **options)",
            "",
            "    def analyse_text(text):",
            "        rv = LassoLexer.analyse_text(text) - 0.05",
            "        return rv",
            "",
            "",
            "class HandlebarsLexer(RegexLexer):",
            "    \"\"\"",
            "    Generic `handlebars <http://handlebarsjs.com/>` template lexer.",
            "",
            "    Highlights only the Handlebars template tags (stuff between `{{` and `}}`).",
            "    Everything else is left for a delegating lexer.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"Handlebars\"",
            "    aliases = ['handlebars']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "",
            "            # Comment start {{!  }} or {{!--",
            "            (r'\\{\\{!.*\\}\\}', Comment),",
            "",
            "            # HTML Escaping open {{{expression",
            "            (r'(\\{\\{\\{)(\\s*)', bygroups(Comment.Special, Text), 'tag'),",
            "",
            "            # {{blockOpen {{#blockOpen {{/blockClose with optional tilde ~",
            "            (r'(\\{\\{)([#~/]+)([^\\s}]*)',",
            "             bygroups(Comment.Preproc, Number.Attribute, Number.Attribute), 'tag'),",
            "            (r'(\\{\\{)(\\s*)', bygroups(Comment.Preproc, Text), 'tag'),",
            "        ],",
            "",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            # HTML Escaping close }}}",
            "            (r'\\}\\}\\}', Comment.Special, '#pop'),",
            "            # blockClose}}, includes optional tilde ~",
            "            (r'(~?)(\\}\\})', bygroups(Number, Comment.Preproc), '#pop'),",
            "",
            "            # {{opt=something}}",
            "            (r'([^\\s}]+)(=)', bygroups(Name.Attribute, Operator)),",
            "",
            "            # Partials {{> ...}}",
            "            (r'(>)(\\s*)(@partial-block)', bygroups(Keyword, Text, Keyword)),",
            "            (r'(#?>)(\\s*)([\\w-]+)', bygroups(Keyword, Text, Name.Variable)),",
            "            (r'(>)(\\s*)(\\()', bygroups(Keyword, Text, Punctuation),",
            "             'dynamic-partial'),",
            "",
            "            include('generic'),",
            "        ],",
            "        'dynamic-partial': [",
            "            (r'\\s+', Text),",
            "            (r'\\)', Punctuation, '#pop'),",
            "",
            "            (r'(lookup)(\\s+)(\\.|this)(\\s+)', bygroups(Keyword, Text,",
            "                                                      Name.Variable, Text)),",
            "            (r'(lookup)(\\s+)(\\S+)', bygroups(Keyword, Text,",
            "                                             using(this, state='variable'))),",
            "            (r'[\\w-]+', Name.Function),",
            "",
            "            include('generic'),",
            "        ],",
            "        'variable': [",
            "            (r'[()/@a-zA-Z][\\w-]*', Name.Variable),",
            "            (r'\\.[\\w-]+', Name.Variable),",
            "            (r'(this\\/|\\.\\/|(\\.\\.\\/)+)[\\w-]+', Name.Variable),",
            "        ],",
            "        'generic': [",
            "            include('variable'),",
            "",
            "            # borrowed from DjangoLexer",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ]",
            "    }",
            "",
            "",
            "class HandlebarsHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `HandlebarsLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML+Handlebars\"",
            "    aliases = [\"html+handlebars\"]",
            "    filenames = ['*.handlebars', '*.hbs']",
            "    mimetypes = ['text/html+handlebars', 'text/x-handlebars-template']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, HandlebarsLexer, **options)",
            "",
            "",
            "class YamlJinjaLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `DjangoLexer` that highlights unlexed data with the",
            "    `YamlLexer`.",
            "",
            "    Commonly used in Saltstack salt states.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'YAML+Jinja'",
            "    aliases = ['yaml+jinja', 'salt', 'sls']",
            "    filenames = ['*.sls']",
            "    mimetypes = ['text/x-yaml+jinja', 'text/x-sls']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(YamlLexer, DjangoLexer, **options)",
            "",
            "",
            "class LiquidLexer(RegexLexer):",
            "    \"\"\"",
            "    Lexer for `Liquid templates",
            "    <http://www.rubydoc.info/github/Shopify/liquid>`_.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "    name = 'liquid'",
            "    aliases = ['liquid']",
            "    filenames = ['*.liquid']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Text),",
            "            # tags and block tags",
            "            (r'(\\{%)(\\s*)', bygroups(Punctuation, Whitespace), 'tag-or-block'),",
            "            # output tags",
            "            (r'(\\{\\{)(\\s*)([^\\s}]+)',",
            "             bygroups(Punctuation, Whitespace, using(this, state = 'generic')),",
            "             'output'),",
            "            (r'\\{', Text)",
            "        ],",
            "",
            "        'tag-or-block': [",
            "            # builtin logic blocks",
            "            (r'(if|unless|elsif|case)(?=\\s+)', Keyword.Reserved, 'condition'),",
            "            (r'(when)(\\s+)', bygroups(Keyword.Reserved, Whitespace),",
            "             combined('end-of-block', 'whitespace', 'generic')),",
            "            (r'(else)(\\s*)(%\\})',",
            "             bygroups(Keyword.Reserved, Whitespace, Punctuation), '#pop'),",
            "",
            "            # other builtin blocks",
            "            (r'(capture)(\\s+)([^\\s%]+)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, using(this, state = 'variable'),",
            "                      Whitespace, Punctuation), '#pop'),",
            "            (r'(comment)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, Punctuation), 'comment'),",
            "            (r'(raw)(\\s*)(%\\})',",
            "             bygroups(Name.Tag, Whitespace, Punctuation), 'raw'),",
            "",
            "            # end of block",
            "            (r'(end(case|unless|if))(\\s*)(%\\})',",
            "             bygroups(Keyword.Reserved, None, Whitespace, Punctuation), '#pop'),",
            "            (r'(end([^\\s%]+))(\\s*)(%\\})',",
            "             bygroups(Name.Tag, None, Whitespace, Punctuation), '#pop'),",
            "",
            "            # builtin tags (assign and include are handled together with usual tags)",
            "            (r'(cycle)(\\s+)(?:([^\\s:]*)(:))?(\\s*)',",
            "             bygroups(Name.Tag, Whitespace,",
            "                      using(this, state='generic'), Punctuation, Whitespace),",
            "             'variable-tag-markup'),",
            "",
            "            # other tags or blocks",
            "            (r'([^\\s%]+)(\\s*)', bygroups(Name.Tag, Whitespace), 'tag-markup')",
            "        ],",
            "",
            "        'output': [",
            "            include('whitespace'),",
            "            (r'\\}\\}', Punctuation, '#pop'),  # end of output",
            "",
            "            (r'\\|', Punctuation, 'filters')",
            "        ],",
            "",
            "        'filters': [",
            "            include('whitespace'),",
            "            (r'\\}\\}', Punctuation, ('#pop', '#pop')),  # end of filters and output",
            "",
            "            (r'([^\\s|:]+)(:?)(\\s*)',",
            "             bygroups(Name.Function, Punctuation, Whitespace), 'filter-markup')",
            "        ],",
            "",
            "        'filter-markup': [",
            "            (r'\\|', Punctuation, '#pop'),",
            "            include('end-of-tag'),",
            "            include('default-param-markup')",
            "        ],",
            "",
            "        'condition': [",
            "            include('end-of-block'),",
            "            include('whitespace'),",
            "",
            "            (r'([^\\s=!><]+)(\\s*)([=!><]=?)(\\s*)(\\S+)(\\s*)(%\\})',",
            "             bygroups(using(this, state = 'generic'), Whitespace, Operator,",
            "                      Whitespace, using(this, state = 'generic'), Whitespace,",
            "                      Punctuation)),",
            "            (r'\\b!', Operator),",
            "            (r'\\bnot\\b', Operator.Word),",
            "            (r'([\\w.\\'\"]+)(\\s+)(contains)(\\s+)([\\w.\\'\"]+)',",
            "             bygroups(using(this, state = 'generic'), Whitespace, Operator.Word,",
            "                      Whitespace, using(this, state = 'generic'))),",
            "",
            "            include('generic'),",
            "            include('whitespace')",
            "        ],",
            "",
            "        'generic-value': [",
            "            include('generic'),",
            "            include('end-at-whitespace')",
            "        ],",
            "",
            "        'operator': [",
            "            (r'(\\s*)((=|!|>|<)=?)(\\s*)',",
            "             bygroups(Whitespace, Operator, None, Whitespace), '#pop'),",
            "            (r'(\\s*)(\\bcontains\\b)(\\s*)',",
            "             bygroups(Whitespace, Operator.Word, Whitespace), '#pop'),",
            "        ],",
            "",
            "        'end-of-tag': [",
            "            (r'\\}\\}', Punctuation, '#pop')",
            "        ],",
            "",
            "        'end-of-block': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop'))",
            "        ],",
            "",
            "        'end-at-whitespace': [",
            "            (r'\\s+', Whitespace, '#pop')",
            "        ],",
            "",
            "        # states for unknown markup",
            "        'param-markup': [",
            "            include('whitespace'),",
            "            # params with colons or equals",
            "            (r'([^\\s=:]+)(\\s*)(=|:)',",
            "             bygroups(Name.Attribute, Whitespace, Operator)),",
            "            # explicit variables",
            "            (r'(\\{\\{)(\\s*)([^\\s}])(\\s*)(\\}\\})',",
            "             bygroups(Punctuation, Whitespace, using(this, state = 'variable'),",
            "                      Whitespace, Punctuation)),",
            "",
            "            include('string'),",
            "            include('number'),",
            "            include('keyword'),",
            "            (r',', Punctuation)",
            "        ],",
            "",
            "        'default-param-markup': [",
            "            include('param-markup'),",
            "            (r'.', Text)  # fallback for switches / variables / un-quoted strings / ...",
            "        ],",
            "",
            "        'variable-param-markup': [",
            "            include('param-markup'),",
            "            include('variable'),",
            "            (r'.', Text)  # fallback",
            "        ],",
            "",
            "        'tag-markup': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop')),  # end of tag",
            "            include('default-param-markup')",
            "        ],",
            "",
            "        'variable-tag-markup': [",
            "            (r'%\\}', Punctuation, ('#pop', '#pop')),  # end of tag",
            "            include('variable-param-markup')",
            "        ],",
            "",
            "        # states for different values types",
            "        'keyword': [",
            "            (r'\\b(false|true)\\b', Keyword.Constant)",
            "        ],",
            "",
            "        'variable': [",
            "            (r'[a-zA-Z_]\\w*', Name.Variable),",
            "            (r'(?<=\\w)\\.(?=\\w)', Punctuation)",
            "        ],",
            "",
            "        'string': [",
            "            (r\"'[^']*'\", String.Single),",
            "            (r'\"[^\"]*\"', String.Double)",
            "        ],",
            "",
            "        'number': [",
            "            (r'\\d+\\.\\d+', Number.Float),",
            "            (r'\\d+', Number.Integer)",
            "        ],",
            "",
            "        'generic': [  # decides for variable, string, keyword or number",
            "            include('keyword'),",
            "            include('string'),",
            "            include('number'),",
            "            include('variable')",
            "        ],",
            "",
            "        'whitespace': [",
            "            (r'[ \\t]+', Whitespace)",
            "        ],",
            "",
            "        # states for builtin blocks",
            "        'comment': [",
            "            (r'(\\{%)(\\s*)(endcomment)(\\s*)(%\\})',",
            "             bygroups(Punctuation, Whitespace, Name.Tag, Whitespace,",
            "                      Punctuation), ('#pop', '#pop')),",
            "            (r'.', Comment)",
            "        ],",
            "",
            "        'raw': [",
            "            (r'[^{]+', Text),",
            "            (r'(\\{%)(\\s*)(endraw)(\\s*)(%\\})',",
            "             bygroups(Punctuation, Whitespace, Name.Tag, Whitespace,",
            "                      Punctuation), '#pop'),",
            "            (r'\\{', Text)",
            "        ],",
            "    }",
            "",
            "",
            "class TwigLexer(RegexLexer):",
            "    \"\"\"",
            "    `Twig <http://twig.sensiolabs.org/>`_ template lexer.",
            "",
            "    It just highlights Twig code between the preprocessor directives,",
            "    other data is left untouched by the lexer.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = 'Twig'",
            "    aliases = ['twig']",
            "    mimetypes = ['application/x-twig']",
            "",
            "    flags = re.M | re.S",
            "",
            "    # Note that a backslash is included in the following two patterns",
            "    # PHP uses a backslash as a namespace separator",
            "    _ident_char = r'[\\\\\\w-]|[^\\x00-\\x7f]'",
            "    _ident_begin = r'(?:[\\\\_a-z]|[^\\x00-\\x7f])'",
            "    _ident_end = r'(?:' + _ident_char + ')*'",
            "    _ident_inner = _ident_begin + _ident_end",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{]+', Other),",
            "            (r'\\{\\{', Comment.Preproc, 'var'),",
            "            # twig comments",
            "            (r'\\{\\#.*?\\#\\}', Comment),",
            "            # raw twig blocks",
            "            (r'(\\{%)(-?\\s*)(raw)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endraw)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Other, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            (r'(\\{%)(-?\\s*)(verbatim)(\\s*-?)(%\\})(.*?)'",
            "             r'(\\{%)(-?\\s*)(endverbatim)(\\s*-?)(%\\})',",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Comment.Preproc,",
            "                      Other, Comment.Preproc, Text, Keyword, Text,",
            "                      Comment.Preproc)),",
            "            # filter blocks",
            "            (r'(\\{%%)(-?\\s*)(filter)(\\s+)(%s)' % _ident_inner,",
            "             bygroups(Comment.Preproc, Text, Keyword, Text, Name.Function),",
            "             'tag'),",
            "            (r'(\\{%)(-?\\s*)([a-zA-Z_]\\w*)',",
            "             bygroups(Comment.Preproc, Text, Keyword), 'tag'),",
            "            (r'\\{', Other),",
            "        ],",
            "        'varnames': [",
            "            (r'(\\|)(\\s*)(%s)' % _ident_inner,",
            "             bygroups(Operator, Text, Name.Function)),",
            "            (r'(is)(\\s+)(not)?(\\s*)(%s)' % _ident_inner,",
            "             bygroups(Keyword, Text, Keyword, Text, Name.Function)),",
            "            (r'(?i)(true|false|none|null)\\b', Keyword.Pseudo),",
            "            (r'(in|not|and|b-and|or|b-or|b-xor|is'",
            "             r'if|elseif|else|import'",
            "             r'constant|defined|divisibleby|empty|even|iterable|odd|sameas'",
            "             r'matches|starts\\s+with|ends\\s+with)\\b',",
            "             Keyword),",
            "            (r'(loop|block|parent)\\b', Name.Builtin),",
            "            (_ident_inner, Name.Variable),",
            "            (r'\\.' + _ident_inner, Name.Variable),",
            "            (r'\\.[0-9]+', Number),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r'([{}()\\[\\]+\\-*/,:~%]|\\.\\.|\\?|:|\\*\\*|\\/\\/|!=|[><=]=?)', Operator),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "        ],",
            "        'var': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(\\}\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames')",
            "        ],",
            "        'tag': [",
            "            (r'\\s+', Text),",
            "            (r'(-?)(%\\})', bygroups(Text, Comment.Preproc), '#pop'),",
            "            include('varnames'),",
            "            (r'.', Punctuation),",
            "        ],",
            "    }",
            "",
            "",
            "class TwigHtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `TwigLexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML+Twig\"",
            "    aliases = [\"html+twig\"]",
            "    filenames = ['*.twig']",
            "    mimetypes = ['text/html+twig']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, TwigLexer, **options)",
            "",
            "",
            "class Angular2Lexer(RegexLexer):",
            "    \"\"\"",
            "    Generic",
            "    `angular2 <http://victorsavkin.com/post/119943127151/angular-2-template-syntax>`_",
            "    template lexer.",
            "",
            "    Highlights only the Angular template tags (stuff between `{{` and `}}` and",
            "    special attributes: '(event)=', '[property]=', '[(twoWayBinding)]=').",
            "    Everything else is left for a delegating lexer.",
            "",
            "    .. versionadded:: 2.1",
            "    \"\"\"",
            "",
            "    name = \"Angular2\"",
            "    aliases = ['ng2']",
            "",
            "    tokens = {",
            "        'root': [",
            "            (r'[^{([*#]+', Other),",
            "",
            "            # {{meal.name}}",
            "            (r'(\\{\\{)(\\s*)', bygroups(Comment.Preproc, Text), 'ngExpression'),",
            "",
            "            # (click)=\"deleteOrder()\"; [value]=\"test\"; [(twoWayTest)]=\"foo.bar\"",
            "            (r'([([]+)([\\w:.-]+)([\\])]+)(\\s*)(=)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Punctuation, Text, Operator, Text),",
            "             'attr'),",
            "            (r'([([]+)([\\w:.-]+)([\\])]+)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Punctuation, Text)),",
            "",
            "            # *ngIf=\"...\"; #f=\"ngForm\"",
            "            (r'([*#])([\\w:.-]+)(\\s*)(=)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Text, Operator, Text), 'attr'),",
            "            (r'([*#])([\\w:.-]+)(\\s*)',",
            "             bygroups(Punctuation, Name.Attribute, Text)),",
            "        ],",
            "",
            "        'ngExpression': [",
            "            (r'\\s+(\\|\\s+)?', Text),",
            "            (r'\\}\\}', Comment.Preproc, '#pop'),",
            "",
            "            # Literals",
            "            (r':?(true|false)', String.Boolean),",
            "            (r':?\"(\\\\\\\\|\\\\[^\\\\]|[^\"\\\\])*\"', String.Double),",
            "            (r\":?'(\\\\\\\\|\\\\[^\\\\]|[^'\\\\])*'\", String.Single),",
            "            (r\"[0-9](\\.[0-9]*)?(eE[+-][0-9])?[flFLdD]?|\"",
            "             r\"0[xX][0-9a-fA-F]+[Ll]?\", Number),",
            "",
            "            # Variabletext",
            "            (r'[a-zA-Z][\\w-]*(\\(.*\\))?', Name.Variable),",
            "            (r'\\.[\\w-]+(\\(.*\\))?', Name.Variable),",
            "",
            "            # inline If",
            "            (r'(\\?)(\\s*)([^}\\s]+)(\\s*)(:)(\\s*)([^}\\s]+)(\\s*)',",
            "             bygroups(Operator, Text, String, Text, Operator, Text, String, Text)),",
            "        ],",
            "        'attr': [",
            "            ('\".*?\"', String, '#pop'),",
            "            (\"'.*?'\", String, '#pop'),",
            "            (r'[^\\s>]+', String, '#pop'),",
            "        ],",
            "    }",
            "",
            "",
            "class Angular2HtmlLexer(DelegatingLexer):",
            "    \"\"\"",
            "    Subclass of the `Angular2Lexer` that highlights unlexed data with the",
            "    `HtmlLexer`.",
            "",
            "    .. versionadded:: 2.0",
            "    \"\"\"",
            "",
            "    name = \"HTML + Angular2\"",
            "    aliases = [\"html+ng2\"]",
            "    filenames = ['*.ng2']",
            "",
            "    def __init__(self, **options):",
            "        super().__init__(HtmlLexer, Angular2Lexer, **options)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1408": [
                "EvoqueLexer"
            ]
        },
        "addLocation": []
    },
    "pygments/lexers/varnish.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "              bygroups(Name.Attribute, Operator, Name.Variable.Global, Punctuation)),"
            },
            "1": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "             (r'(\\.probe)(\\s*=\\s*)(\\{)',"
            },
            "2": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "              bygroups(Name.Attribute, Operator, Punctuation), 'probe'),"
            },
            "3": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (r'(\\.\\w+\\b)(\\s*=\\s*)([^;]*)(\\s*;)',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+            (r'(\\.\\w+\\b)(\\s*=\\s*)([^;\\s]*)(\\s*;)',"
            },
            "5": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "              bygroups(Name.Attribute, Operator, using(this), Punctuation)),"
            },
            "6": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "             (r'\\{', Punctuation, '#push'),"
            },
            "7": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "             (r'\\}', Punctuation, '#pop'),"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.varnish",
            "    ~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Varnish configuration",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, this, \\",
            "    inherit, words",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation, Literal",
            "",
            "__all__ = ['VCLLexer', 'VCLSnippetLexer']",
            "",
            "",
            "class VCLLexer(RegexLexer):",
            "    \"\"\"",
            "    For Varnish Configuration Language (VCL).",
            "",
            "    .. versionadded:: 2.2",
            "    \"\"\"",
            "    name = 'VCL'",
            "    aliases = ['vcl']",
            "    filenames = ['*.vcl']",
            "    mimetypes = ['text/x-vclsrc']",
            "",
            "    def analyse_text(text):",
            "        # If the very first line is 'vcl 4.0;' it's pretty much guaranteed",
            "        # that this is VCL",
            "        if text.startswith('vcl 4.0;'):",
            "            return 1.0",
            "        # Skip over comments and blank lines",
            "        # This is accurate enough that returning 0.9 is reasonable.",
            "        # Almost no VCL files start without some comments.",
            "        elif '\\nvcl 4.0;' in text[:1000]:",
            "            return 0.9",
            "",
            "    tokens = {",
            "        'probe': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            (r'(\\.\\w+)(\\s*=\\s*)([^;]*)(;)',",
            "             bygroups(Name.Attribute, Operator, using(this), Punctuation)),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'acl': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            (r'[!/]+', Operator),",
            "            (r';', Punctuation),",
            "            (r'\\d+', Number),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'backend': [",
            "            include('whitespace'),",
            "            (r'(\\.probe)(\\s*=\\s*)(\\w+)(;)',",
            "             bygroups(Name.Attribute, Operator, Name.Variable.Global, Punctuation)),",
            "            (r'(\\.probe)(\\s*=\\s*)(\\{)',",
            "             bygroups(Name.Attribute, Operator, Punctuation), 'probe'),",
            "            (r'(\\.\\w+\\b)(\\s*=\\s*)([^;]*)(\\s*;)',",
            "             bygroups(Name.Attribute, Operator, using(this), Punctuation)),",
            "            (r'\\{', Punctuation, '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'statements': [",
            "            (r'(\\d\\.)?\\d+[sdwhmy]', Literal.Date),",
            "            (r'(\\d\\.)?\\d+ms', Literal.Date),",
            "            (r'(vcl_pass|vcl_hash|vcl_hit|vcl_init|vcl_backend_fetch|vcl_pipe|'",
            "             r'vcl_backend_response|vcl_synth|vcl_deliver|vcl_backend_error|'",
            "             r'vcl_fini|vcl_recv|vcl_purge|vcl_miss)\\b', Name.Function),",
            "            (r'(pipe|retry|hash|synth|deliver|purge|abandon|lookup|pass|fail|ok|'",
            "             r'miss|fetch|restart)\\b', Name.Constant),",
            "            (r'(beresp|obj|resp|req|req_top|bereq)\\.http\\.[a-zA-Z_-]+\\b', Name.Variable),",
            "            (words((",
            "                'obj.status', 'req.hash_always_miss', 'beresp.backend', 'req.esi_level',",
            "                'req.can_gzip', 'beresp.ttl', 'obj.uncacheable', 'req.ttl', 'obj.hits',",
            "                'client.identity', 'req.hash_ignore_busy', 'obj.reason', 'req.xid',",
            "                'req_top.proto', 'beresp.age', 'obj.proto', 'obj.age', 'local.ip',",
            "                'beresp.uncacheable', 'req.method', 'beresp.backend.ip', 'now',",
            "                'obj.grace', 'req.restarts', 'beresp.keep', 'req.proto', 'resp.proto',",
            "                'bereq.xid', 'bereq.between_bytes_timeout', 'req.esi',",
            "                'bereq.first_byte_timeout', 'bereq.method', 'bereq.connect_timeout',",
            "                'beresp.do_gzip',  'resp.status', 'beresp.do_gunzip',",
            "                'beresp.storage_hint', 'resp.is_streaming', 'beresp.do_stream',",
            "                'req_top.method', 'bereq.backend', 'beresp.backend.name', 'beresp.status',",
            "                'req.url', 'obj.keep', 'obj.ttl', 'beresp.reason', 'bereq.retries',",
            "                'resp.reason', 'bereq.url', 'beresp.do_esi', 'beresp.proto', 'client.ip',",
            "                'bereq.proto', 'server.hostname', 'remote.ip', 'req.backend_hint',",
            "                'server.identity', 'req_top.url', 'beresp.grace', 'beresp.was_304',",
            "                'server.ip', 'bereq.uncacheable'), suffix=r'\\b'),",
            "             Name.Variable),",
            "            (r'[!%&+*\\-,/<.}{>=|~]+', Operator),",
            "            (r'[();]', Punctuation),",
            "",
            "            (r'[,]+', Punctuation),",
            "            (words(('hash_data', 'regsub', 'regsuball', 'if', 'else',",
            "                    'elsif', 'elif', 'synth', 'synthetic', 'ban',",
            "                    'return', 'set', 'unset', 'import', 'include', 'new',",
            "                    'rollback', 'call'), suffix=r'\\b'),",
            "             Keyword),",
            "            (r'storage\\.\\w+\\.\\w+\\b', Name.Variable),",
            "            (words(('true', 'false')), Name.Builtin),",
            "            (r'\\d+\\b', Number),",
            "            (r'(backend)(\\s+\\w+)(\\s*\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'backend'),",
            "            (r'(probe\\s)(\\s*\\w+\\s)(\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'probe'),",
            "            (r'(acl\\s)(\\s*\\w+\\s)(\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'acl'),",
            "            (r'(vcl )(4.0)(;)$',",
            "             bygroups(Keyword.Reserved, Name.Constant, Punctuation)),",
            "            (r'(sub\\s+)([a-zA-Z]\\w*)(\\s*\\{)',",
            "                bygroups(Keyword, Name.Function, Punctuation)),",
            "            (r'([a-zA-Z_]\\w*)'",
            "             r'(\\.)'",
            "             r'([a-zA-Z_]\\w*)'",
            "             r'(\\s*\\(.*\\))',",
            "             bygroups(Name.Function, Punctuation, Name.Function, using(this))),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "        ],",
            "        'comment': [",
            "            (r'[^*/]+', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline),",
            "        ],",
            "        'comments': [",
            "            (r'#.*$', Comment),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "            (r'//.*$', Comment),",
            "        ],",
            "        'string': [",
            "            (r'\"', String, '#pop'),",
            "            (r'[^\"\\n]+', String),  # all other characters",
            "        ],",
            "        'multistring': [",
            "            (r'[^\"}]', String),",
            "            (r'\"\\}', String, '#pop'),",
            "            (r'[\"}]', String),",
            "        ],",
            "        'whitespace': [",
            "            (r'L?\"', String, 'string'),",
            "            (r'\\{\"', String, 'multistring'),",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'\\\\\\n', Text),  # line continuation",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            include('statements'),",
            "            (r'\\s+', Text),",
            "        ],",
            "    }",
            "",
            "",
            "class VCLSnippetLexer(VCLLexer):",
            "    \"\"\"",
            "    For Varnish Configuration Language snippets.",
            "",
            "    .. versionadded:: 2.2",
            "    \"\"\"",
            "    name = 'VCLSnippets'",
            "    aliases = ['vclsnippets', 'vclsnippet']",
            "    mimetypes = ['text/x-vclsnippet']",
            "    filenames = []",
            "",
            "    def analyse_text(text):",
            "        # override method inherited from VCLLexer",
            "        return 0",
            "",
            "    tokens = {",
            "        'snippetspre': [",
            "            (r'\\.\\.\\.+', Comment),",
            "            (r'(bereq|req|req_top|resp|beresp|obj|client|server|local|remote|'",
            "             r'storage)($|\\.\\*)', Name.Variable),",
            "        ],",
            "        'snippetspost': [",
            "            (r'(backend)\\b', Keyword.Reserved),",
            "        ],",
            "        'root': [",
            "            include('snippetspre'),",
            "            inherit,",
            "            include('snippetspost'),",
            "        ],",
            "    }"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    pygments.lexers.varnish",
            "    ~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "    Lexers for Varnish configuration",
            "",
            "    :copyright: Copyright 2006-2021 by the Pygments team, see AUTHORS.",
            "    :license: BSD, see LICENSE for details.",
            "\"\"\"",
            "",
            "from pygments.lexer import RegexLexer, include, bygroups, using, this, \\",
            "    inherit, words",
            "from pygments.token import Text, Comment, Operator, Keyword, Name, String, \\",
            "    Number, Punctuation, Literal",
            "",
            "__all__ = ['VCLLexer', 'VCLSnippetLexer']",
            "",
            "",
            "class VCLLexer(RegexLexer):",
            "    \"\"\"",
            "    For Varnish Configuration Language (VCL).",
            "",
            "    .. versionadded:: 2.2",
            "    \"\"\"",
            "    name = 'VCL'",
            "    aliases = ['vcl']",
            "    filenames = ['*.vcl']",
            "    mimetypes = ['text/x-vclsrc']",
            "",
            "    def analyse_text(text):",
            "        # If the very first line is 'vcl 4.0;' it's pretty much guaranteed",
            "        # that this is VCL",
            "        if text.startswith('vcl 4.0;'):",
            "            return 1.0",
            "        # Skip over comments and blank lines",
            "        # This is accurate enough that returning 0.9 is reasonable.",
            "        # Almost no VCL files start without some comments.",
            "        elif '\\nvcl 4.0;' in text[:1000]:",
            "            return 0.9",
            "",
            "    tokens = {",
            "        'probe': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            (r'(\\.\\w+)(\\s*=\\s*)([^;]*)(;)',",
            "             bygroups(Name.Attribute, Operator, using(this), Punctuation)),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'acl': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            (r'[!/]+', Operator),",
            "            (r';', Punctuation),",
            "            (r'\\d+', Number),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'backend': [",
            "            include('whitespace'),",
            "            (r'(\\.probe)(\\s*=\\s*)(\\w+)(;)',",
            "             bygroups(Name.Attribute, Operator, Name.Variable.Global, Punctuation)),",
            "            (r'(\\.probe)(\\s*=\\s*)(\\{)',",
            "             bygroups(Name.Attribute, Operator, Punctuation), 'probe'),",
            "            (r'(\\.\\w+\\b)(\\s*=\\s*)([^;\\s]*)(\\s*;)',",
            "             bygroups(Name.Attribute, Operator, using(this), Punctuation)),",
            "            (r'\\{', Punctuation, '#push'),",
            "            (r'\\}', Punctuation, '#pop'),",
            "        ],",
            "        'statements': [",
            "            (r'(\\d\\.)?\\d+[sdwhmy]', Literal.Date),",
            "            (r'(\\d\\.)?\\d+ms', Literal.Date),",
            "            (r'(vcl_pass|vcl_hash|vcl_hit|vcl_init|vcl_backend_fetch|vcl_pipe|'",
            "             r'vcl_backend_response|vcl_synth|vcl_deliver|vcl_backend_error|'",
            "             r'vcl_fini|vcl_recv|vcl_purge|vcl_miss)\\b', Name.Function),",
            "            (r'(pipe|retry|hash|synth|deliver|purge|abandon|lookup|pass|fail|ok|'",
            "             r'miss|fetch|restart)\\b', Name.Constant),",
            "            (r'(beresp|obj|resp|req|req_top|bereq)\\.http\\.[a-zA-Z_-]+\\b', Name.Variable),",
            "            (words((",
            "                'obj.status', 'req.hash_always_miss', 'beresp.backend', 'req.esi_level',",
            "                'req.can_gzip', 'beresp.ttl', 'obj.uncacheable', 'req.ttl', 'obj.hits',",
            "                'client.identity', 'req.hash_ignore_busy', 'obj.reason', 'req.xid',",
            "                'req_top.proto', 'beresp.age', 'obj.proto', 'obj.age', 'local.ip',",
            "                'beresp.uncacheable', 'req.method', 'beresp.backend.ip', 'now',",
            "                'obj.grace', 'req.restarts', 'beresp.keep', 'req.proto', 'resp.proto',",
            "                'bereq.xid', 'bereq.between_bytes_timeout', 'req.esi',",
            "                'bereq.first_byte_timeout', 'bereq.method', 'bereq.connect_timeout',",
            "                'beresp.do_gzip',  'resp.status', 'beresp.do_gunzip',",
            "                'beresp.storage_hint', 'resp.is_streaming', 'beresp.do_stream',",
            "                'req_top.method', 'bereq.backend', 'beresp.backend.name', 'beresp.status',",
            "                'req.url', 'obj.keep', 'obj.ttl', 'beresp.reason', 'bereq.retries',",
            "                'resp.reason', 'bereq.url', 'beresp.do_esi', 'beresp.proto', 'client.ip',",
            "                'bereq.proto', 'server.hostname', 'remote.ip', 'req.backend_hint',",
            "                'server.identity', 'req_top.url', 'beresp.grace', 'beresp.was_304',",
            "                'server.ip', 'bereq.uncacheable'), suffix=r'\\b'),",
            "             Name.Variable),",
            "            (r'[!%&+*\\-,/<.}{>=|~]+', Operator),",
            "            (r'[();]', Punctuation),",
            "",
            "            (r'[,]+', Punctuation),",
            "            (words(('hash_data', 'regsub', 'regsuball', 'if', 'else',",
            "                    'elsif', 'elif', 'synth', 'synthetic', 'ban',",
            "                    'return', 'set', 'unset', 'import', 'include', 'new',",
            "                    'rollback', 'call'), suffix=r'\\b'),",
            "             Keyword),",
            "            (r'storage\\.\\w+\\.\\w+\\b', Name.Variable),",
            "            (words(('true', 'false')), Name.Builtin),",
            "            (r'\\d+\\b', Number),",
            "            (r'(backend)(\\s+\\w+)(\\s*\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'backend'),",
            "            (r'(probe\\s)(\\s*\\w+\\s)(\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'probe'),",
            "            (r'(acl\\s)(\\s*\\w+\\s)(\\{)',",
            "             bygroups(Keyword, Name.Variable.Global, Punctuation), 'acl'),",
            "            (r'(vcl )(4.0)(;)$',",
            "             bygroups(Keyword.Reserved, Name.Constant, Punctuation)),",
            "            (r'(sub\\s+)([a-zA-Z]\\w*)(\\s*\\{)',",
            "                bygroups(Keyword, Name.Function, Punctuation)),",
            "            (r'([a-zA-Z_]\\w*)'",
            "             r'(\\.)'",
            "             r'([a-zA-Z_]\\w*)'",
            "             r'(\\s*\\(.*\\))',",
            "             bygroups(Name.Function, Punctuation, Name.Function, using(this))),",
            "            (r'[a-zA-Z_]\\w*', Name),",
            "        ],",
            "        'comment': [",
            "            (r'[^*/]+', Comment.Multiline),",
            "            (r'/\\*', Comment.Multiline, '#push'),",
            "            (r'\\*/', Comment.Multiline, '#pop'),",
            "            (r'[*/]', Comment.Multiline),",
            "        ],",
            "        'comments': [",
            "            (r'#.*$', Comment),",
            "            (r'/\\*', Comment.Multiline, 'comment'),",
            "            (r'//.*$', Comment),",
            "        ],",
            "        'string': [",
            "            (r'\"', String, '#pop'),",
            "            (r'[^\"\\n]+', String),  # all other characters",
            "        ],",
            "        'multistring': [",
            "            (r'[^\"}]', String),",
            "            (r'\"\\}', String, '#pop'),",
            "            (r'[\"}]', String),",
            "        ],",
            "        'whitespace': [",
            "            (r'L?\"', String, 'string'),",
            "            (r'\\{\"', String, 'multistring'),",
            "            (r'\\n', Text),",
            "            (r'\\s+', Text),",
            "            (r'\\\\\\n', Text),  # line continuation",
            "        ],",
            "        'root': [",
            "            include('whitespace'),",
            "            include('comments'),",
            "            include('statements'),",
            "            (r'\\s+', Text),",
            "        ],",
            "    }",
            "",
            "",
            "class VCLSnippetLexer(VCLLexer):",
            "    \"\"\"",
            "    For Varnish Configuration Language snippets.",
            "",
            "    .. versionadded:: 2.2",
            "    \"\"\"",
            "    name = 'VCLSnippets'",
            "    aliases = ['vclsnippets', 'vclsnippet']",
            "    mimetypes = ['text/x-vclsnippet']",
            "    filenames = []",
            "",
            "    def analyse_text(text):",
            "        # override method inherited from VCLLexer",
            "        return 0",
            "",
            "    tokens = {",
            "        'snippetspre': [",
            "            (r'\\.\\.\\.+', Comment),",
            "            (r'(bereq|req|req_top|resp|beresp|obj|client|server|local|remote|'",
            "             r'storage)($|\\.\\*)', Name.Variable),",
            "        ],",
            "        'snippetspost': [",
            "            (r'(backend)\\b', Keyword.Reserved),",
            "        ],",
            "        'root': [",
            "            include('snippetspre'),",
            "            inherit,",
            "            include('snippetspost'),",
            "        ],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "64": [
                "VCLLexer"
            ]
        },
        "addLocation": []
    }
}