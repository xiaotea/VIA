{
    "waitress/parser.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import re"
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from io import BytesIO"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from waitress.compat import ("
            },
            "4": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    tostr,"
            },
            "5": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    urlparse,"
            },
            "6": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    unquote_bytes_to_wsgi,"
            },
            "7": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-)"
            },
            "8": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "9": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from waitress.buffers import OverflowableBuffer"
            },
            "10": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "11": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from waitress.receiver import ("
            },
            "12": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    FixedStreamReceiver,"
            },
            "13": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ChunkedReceiver,"
            },
            "14": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-)"
            },
            "15": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from waitress.compat import tostr, unquote_bytes_to_wsgi, urlparse"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from waitress.receiver import ChunkedReceiver, FixedStreamReceiver"
            },
            "18": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from waitress.utilities import ("
            },
            "19": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    find_double_newline,"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+    BadRequest,"
            },
            "21": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 27,
                "PatchRowcode": "     RequestEntityTooLarge,"
            },
            "22": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "     RequestHeaderFieldsTooLarge,"
            },
            "23": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    BadRequest,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+    find_double_newline,"
            },
            "25": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " )"
            },
            "26": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "                 # Header finished."
            },
            "29": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "                 header_plus = s[:index]"
            },
            "30": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "                 consumed = len(data) - (len(s) - index)"
            },
            "31": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # Remove preceeding blank lines."
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+                # Remove preceeding blank lines. This is suggested by"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+                # https://tools.ietf.org/html/rfc7230#section-3.5 to support"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+                # clients sending an extra CR LF after another request when"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+                # using HTTP pipelining"
            },
            "37": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "                 header_plus = header_plus.lstrip()"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+"
            },
            "39": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "                 if not header_plus:"
            },
            "40": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "                     self.empty = True"
            },
            "41": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "                     self.completed = True"
            },
            "42": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "         Parses the header_plus block of text (the headers plus the"
            },
            "43": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         first line of the request)."
            },
            "44": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "         \"\"\""
            },
            "45": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        index = header_plus.find(b\"\\n\")"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+        index = header_plus.find(b\"\\r\\n\")"
            },
            "47": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "         if index >= 0:"
            },
            "48": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "             first_line = header_plus[:index].rstrip()"
            },
            "49": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            header = header_plus[index + 1 :]"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+            header = header_plus[index + 2 :]"
            },
            "51": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "         else:"
            },
            "52": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            first_line = header_plus.rstrip()"
            },
            "53": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            header = b\"\""
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+            raise ParsingError(\"HTTP message header invalid\")"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+        if b\"\\r\" in first_line or b\"\\n\" in first_line:"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+            raise ParsingError(\"Bare CR or LF found in HTTP message\")"
            },
            "58": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 176,
                "PatchRowcode": " "
            },
            "59": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "         self.first_line = first_line  # for testing"
            },
            "60": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 178,
                "PatchRowcode": " "
            },
            "61": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 296,
                "PatchRowcode": "     Splits the header into lines, putting multi-line headers together."
            },
            "62": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": 297,
                "PatchRowcode": "     \"\"\""
            },
            "63": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 298,
                "PatchRowcode": "     r = []"
            },
            "64": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    lines = header.split(b\"\\n\")"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 299,
                "PatchRowcode": "+    lines = header.split(b\"\\r\\n\")"
            },
            "66": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 300,
                "PatchRowcode": "     for line in lines:"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 301,
                "PatchRowcode": "+        if b\"\\r\" in line or b\"\\n\" in line:"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 302,
                "PatchRowcode": "+            raise ParsingError('Bare CR or LF found in header line \"%s\"' % tostr(line))"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+"
            },
            "70": {
                "beforePatchRowNumber": 304,
                "afterPatchRowNumber": 304,
                "PatchRowcode": "         if line.startswith((b\" \", b\"\\t\")):"
            },
            "71": {
                "beforePatchRowNumber": 305,
                "afterPatchRowNumber": 305,
                "PatchRowcode": "             if not r:"
            },
            "72": {
                "beforePatchRowNumber": 306,
                "afterPatchRowNumber": 306,
                "PatchRowcode": "                 # https://corte.si/posts/code/pathod/pythonservers/index.html"
            }
        },
        "frontPatchFile": [
            "##############################################################################",
            "#",
            "# Copyright (c) 2001, 2002 Zope Foundation and Contributors.",
            "# All Rights Reserved.",
            "#",
            "# This software is subject to the provisions of the Zope Public License,",
            "# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.",
            "# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED",
            "# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS",
            "# FOR A PARTICULAR PURPOSE.",
            "#",
            "##############################################################################",
            "\"\"\"HTTP Request Parser",
            "",
            "This server uses asyncore to accept connections and do initial",
            "processing but threads to do work.",
            "\"\"\"",
            "import re",
            "from io import BytesIO",
            "",
            "from waitress.compat import (",
            "    tostr,",
            "    urlparse,",
            "    unquote_bytes_to_wsgi,",
            ")",
            "",
            "from waitress.buffers import OverflowableBuffer",
            "",
            "from waitress.receiver import (",
            "    FixedStreamReceiver,",
            "    ChunkedReceiver,",
            ")",
            "",
            "from waitress.utilities import (",
            "    find_double_newline,",
            "    RequestEntityTooLarge,",
            "    RequestHeaderFieldsTooLarge,",
            "    BadRequest,",
            ")",
            "",
            "",
            "class ParsingError(Exception):",
            "    pass",
            "",
            "",
            "class HTTPRequestParser(object):",
            "    \"\"\"A structure that collects the HTTP request.",
            "",
            "    Once the stream is completed, the instance is passed to",
            "    a server task constructor.",
            "    \"\"\"",
            "",
            "    completed = False  # Set once request is completed.",
            "    empty = False  # Set if no request was made.",
            "    expect_continue = False  # client sent \"Expect: 100-continue\" header",
            "    headers_finished = False  # True when headers have been read",
            "    header_plus = b\"\"",
            "    chunked = False",
            "    content_length = 0",
            "    header_bytes_received = 0",
            "    body_bytes_received = 0",
            "    body_rcv = None",
            "    version = \"1.0\"",
            "    error = None",
            "    connection_close = False",
            "",
            "    # Other attributes: first_line, header, headers, command, uri, version,",
            "    # path, query, fragment",
            "",
            "    def __init__(self, adj):",
            "        \"\"\"",
            "        adj is an Adjustments object.",
            "        \"\"\"",
            "        # headers is a mapping containing keys translated to uppercase",
            "        # with dashes turned into underscores.",
            "        self.headers = {}",
            "        self.adj = adj",
            "",
            "    def received(self, data):",
            "        \"\"\"",
            "        Receives the HTTP stream for one request.  Returns the number of",
            "        bytes consumed.  Sets the completed flag once both the header and the",
            "        body have been received.",
            "        \"\"\"",
            "        if self.completed:",
            "            return 0  # Can't consume any more.",
            "        datalen = len(data)",
            "        br = self.body_rcv",
            "        if br is None:",
            "            # In header.",
            "            s = self.header_plus + data",
            "            index = find_double_newline(s)",
            "            if index >= 0:",
            "                # Header finished.",
            "                header_plus = s[:index]",
            "                consumed = len(data) - (len(s) - index)",
            "                # Remove preceeding blank lines.",
            "                header_plus = header_plus.lstrip()",
            "                if not header_plus:",
            "                    self.empty = True",
            "                    self.completed = True",
            "                else:",
            "                    try:",
            "                        self.parse_header(header_plus)",
            "                    except ParsingError as e:",
            "                        self.error = BadRequest(e.args[0])",
            "                        self.completed = True",
            "                    else:",
            "                        if self.body_rcv is None:",
            "                            # no content-length header and not a t-e: chunked",
            "                            # request",
            "                            self.completed = True",
            "                        if self.content_length > 0:",
            "                            max_body = self.adj.max_request_body_size",
            "                            # we won't accept this request if the content-length",
            "                            # is too large",
            "                            if self.content_length >= max_body:",
            "                                self.error = RequestEntityTooLarge(",
            "                                    \"exceeds max_body of %s\" % max_body",
            "                                )",
            "                                self.completed = True",
            "                self.headers_finished = True",
            "                return consumed",
            "            else:",
            "                # Header not finished yet.",
            "                self.header_bytes_received += datalen",
            "                max_header = self.adj.max_request_header_size",
            "                if self.header_bytes_received >= max_header:",
            "                    # malformed header, we need to construct some request",
            "                    # on our own. we disregard the incoming(?) requests HTTP",
            "                    # version and just use 1.0. IOW someone just sent garbage",
            "                    # over the wire",
            "                    self.parse_header(b\"GET / HTTP/1.0\\n\")",
            "                    self.error = RequestHeaderFieldsTooLarge(",
            "                        \"exceeds max_header of %s\" % max_header",
            "                    )",
            "                    self.completed = True",
            "                self.header_plus = s",
            "                return datalen",
            "        else:",
            "            # In body.",
            "            consumed = br.received(data)",
            "            self.body_bytes_received += consumed",
            "            max_body = self.adj.max_request_body_size",
            "            if self.body_bytes_received >= max_body:",
            "                # this will only be raised during t-e: chunked requests",
            "                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)",
            "                self.completed = True",
            "            elif br.error:",
            "                # garbage in chunked encoding input probably",
            "                self.error = br.error",
            "                self.completed = True",
            "            elif br.completed:",
            "                # The request (with the body) is ready to use.",
            "                self.completed = True",
            "                if self.chunked:",
            "                    # We've converted the chunked transfer encoding request",
            "                    # body into a normal request body, so we know its content",
            "                    # length; set the header here.  We already popped the",
            "                    # TRANSFER_ENCODING header in parse_header, so this will",
            "                    # appear to the client to be an entirely non-chunked HTTP",
            "                    # request with a valid content-length.",
            "                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())",
            "            return consumed",
            "",
            "    def parse_header(self, header_plus):",
            "        \"\"\"",
            "        Parses the header_plus block of text (the headers plus the",
            "        first line of the request).",
            "        \"\"\"",
            "        index = header_plus.find(b\"\\n\")",
            "        if index >= 0:",
            "            first_line = header_plus[:index].rstrip()",
            "            header = header_plus[index + 1 :]",
            "        else:",
            "            first_line = header_plus.rstrip()",
            "            header = b\"\"",
            "",
            "        self.first_line = first_line  # for testing",
            "",
            "        lines = get_header_lines(header)",
            "",
            "        headers = self.headers",
            "        for line in lines:",
            "            index = line.find(b\":\")",
            "            if index > 0:",
            "                key = line[:index]",
            "                if b\"_\" in key:",
            "                    continue",
            "                value = line[index + 1 :].strip()",
            "                key1 = tostr(key.upper().replace(b\"-\", b\"_\"))",
            "                # If a header already exists, we append subsequent values",
            "                # seperated by a comma. Applications already need to handle",
            "                # the comma seperated values, as HTTP front ends might do",
            "                # the concatenation for you (behavior specified in RFC2616).",
            "                try:",
            "                    headers[key1] += tostr(b\", \" + value)",
            "                except KeyError:",
            "                    headers[key1] = tostr(value)",
            "            # else there's garbage in the headers?",
            "",
            "        # command, uri, version will be bytes",
            "        command, uri, version = crack_first_line(first_line)",
            "        version = tostr(version)",
            "        command = tostr(command)",
            "        self.command = command",
            "        self.version = version",
            "        (",
            "            self.proxy_scheme,",
            "            self.proxy_netloc,",
            "            self.path,",
            "            self.query,",
            "            self.fragment,",
            "        ) = split_uri(uri)",
            "        self.url_scheme = self.adj.url_scheme",
            "        connection = headers.get(\"CONNECTION\", \"\")",
            "",
            "        if version == \"1.0\":",
            "            if connection.lower() != \"keep-alive\":",
            "                self.connection_close = True",
            "",
            "        if version == \"1.1\":",
            "            # since the server buffers data from chunked transfers and clients",
            "            # never need to deal with chunked requests, downstream clients",
            "            # should not see the HTTP_TRANSFER_ENCODING header; we pop it",
            "            # here",
            "            te = headers.pop(\"TRANSFER_ENCODING\", \"\")",
            "            if te.lower() == \"chunked\":",
            "                self.chunked = True",
            "                buf = OverflowableBuffer(self.adj.inbuf_overflow)",
            "                self.body_rcv = ChunkedReceiver(buf)",
            "            expect = headers.get(\"EXPECT\", \"\").lower()",
            "            self.expect_continue = expect == \"100-continue\"",
            "            if connection.lower() == \"close\":",
            "                self.connection_close = True",
            "",
            "        if not self.chunked:",
            "            try:",
            "                cl = int(headers.get(\"CONTENT_LENGTH\", 0))",
            "            except ValueError:",
            "                cl = 0",
            "            self.content_length = cl",
            "            if cl > 0:",
            "                buf = OverflowableBuffer(self.adj.inbuf_overflow)",
            "                self.body_rcv = FixedStreamReceiver(cl, buf)",
            "",
            "    def get_body_stream(self):",
            "        body_rcv = self.body_rcv",
            "        if body_rcv is not None:",
            "            return body_rcv.getfile()",
            "        else:",
            "            return BytesIO()",
            "",
            "    def close(self):",
            "        body_rcv = self.body_rcv",
            "        if body_rcv is not None:",
            "            body_rcv.getbuf().close()",
            "",
            "",
            "def split_uri(uri):",
            "    # urlsplit handles byte input by returning bytes on py3, so",
            "    # scheme, netloc, path, query, and fragment are bytes",
            "",
            "    scheme = netloc = path = query = fragment = b\"\"",
            "",
            "    # urlsplit below will treat this as a scheme-less netloc, thereby losing",
            "    # the original intent of the request. Here we shamelessly stole 4 lines of",
            "    # code from the CPython stdlib to parse out the fragment and query but",
            "    # leave the path alone. See",
            "    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468",
            "    # and https://github.com/Pylons/waitress/issues/260",
            "",
            "    if uri[:2] == b\"//\":",
            "        path = uri",
            "",
            "        if b\"#\" in path:",
            "            path, fragment = path.split(b\"#\", 1)",
            "",
            "        if b\"?\" in path:",
            "            path, query = path.split(b\"?\", 1)",
            "    else:",
            "        try:",
            "            scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)",
            "        except UnicodeError:",
            "            raise ParsingError(\"Bad URI\")",
            "",
            "    return (",
            "        tostr(scheme),",
            "        tostr(netloc),",
            "        unquote_bytes_to_wsgi(path),",
            "        tostr(query),",
            "        tostr(fragment),",
            "    )",
            "",
            "",
            "def get_header_lines(header):",
            "    \"\"\"",
            "    Splits the header into lines, putting multi-line headers together.",
            "    \"\"\"",
            "    r = []",
            "    lines = header.split(b\"\\n\")",
            "    for line in lines:",
            "        if line.startswith((b\" \", b\"\\t\")):",
            "            if not r:",
            "                # https://corte.si/posts/code/pathod/pythonservers/index.html",
            "                raise ParsingError('Malformed header line \"%s\"' % tostr(line))",
            "            r[-1] += line",
            "        else:",
            "            r.append(line)",
            "    return r",
            "",
            "",
            "first_line_re = re.compile(",
            "    b\"([^ ]+) \"",
            "    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"",
            "    b\"(( HTTP/([0-9.]+))$|$)\"",
            ")",
            "",
            "",
            "def crack_first_line(line):",
            "    m = first_line_re.match(line)",
            "    if m is not None and m.end() == len(line):",
            "        if m.group(3):",
            "            version = m.group(5)",
            "        else:",
            "            version = b\"\"",
            "        method = m.group(1)",
            "",
            "        # the request methods that are currently defined are all uppercase:",
            "        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and",
            "        # the request method is case sensitive according to",
            "        # https://tools.ietf.org/html/rfc7231#section-4.1",
            "",
            "        # By disallowing anything but uppercase methods we save poor",
            "        # unsuspecting souls from sending lowercase HTTP methods to waitress",
            "        # and having the request complete, while servers like nginx drop the",
            "        # request onto the floor.",
            "        if method != method.upper():",
            "            raise ParsingError('Malformed HTTP method \"%s\"' % tostr(method))",
            "        uri = m.group(2)",
            "        return method, uri, version",
            "    else:",
            "        return b\"\", b\"\", b\"\""
        ],
        "afterPatchFile": [
            "##############################################################################",
            "#",
            "# Copyright (c) 2001, 2002 Zope Foundation and Contributors.",
            "# All Rights Reserved.",
            "#",
            "# This software is subject to the provisions of the Zope Public License,",
            "# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.",
            "# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED",
            "# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS",
            "# FOR A PARTICULAR PURPOSE.",
            "#",
            "##############################################################################",
            "\"\"\"HTTP Request Parser",
            "",
            "This server uses asyncore to accept connections and do initial",
            "processing but threads to do work.",
            "\"\"\"",
            "import re",
            "from io import BytesIO",
            "",
            "from waitress.buffers import OverflowableBuffer",
            "from waitress.compat import tostr, unquote_bytes_to_wsgi, urlparse",
            "from waitress.receiver import ChunkedReceiver, FixedStreamReceiver",
            "from waitress.utilities import (",
            "    BadRequest,",
            "    RequestEntityTooLarge,",
            "    RequestHeaderFieldsTooLarge,",
            "    find_double_newline,",
            ")",
            "",
            "",
            "class ParsingError(Exception):",
            "    pass",
            "",
            "",
            "class HTTPRequestParser(object):",
            "    \"\"\"A structure that collects the HTTP request.",
            "",
            "    Once the stream is completed, the instance is passed to",
            "    a server task constructor.",
            "    \"\"\"",
            "",
            "    completed = False  # Set once request is completed.",
            "    empty = False  # Set if no request was made.",
            "    expect_continue = False  # client sent \"Expect: 100-continue\" header",
            "    headers_finished = False  # True when headers have been read",
            "    header_plus = b\"\"",
            "    chunked = False",
            "    content_length = 0",
            "    header_bytes_received = 0",
            "    body_bytes_received = 0",
            "    body_rcv = None",
            "    version = \"1.0\"",
            "    error = None",
            "    connection_close = False",
            "",
            "    # Other attributes: first_line, header, headers, command, uri, version,",
            "    # path, query, fragment",
            "",
            "    def __init__(self, adj):",
            "        \"\"\"",
            "        adj is an Adjustments object.",
            "        \"\"\"",
            "        # headers is a mapping containing keys translated to uppercase",
            "        # with dashes turned into underscores.",
            "        self.headers = {}",
            "        self.adj = adj",
            "",
            "    def received(self, data):",
            "        \"\"\"",
            "        Receives the HTTP stream for one request.  Returns the number of",
            "        bytes consumed.  Sets the completed flag once both the header and the",
            "        body have been received.",
            "        \"\"\"",
            "        if self.completed:",
            "            return 0  # Can't consume any more.",
            "        datalen = len(data)",
            "        br = self.body_rcv",
            "        if br is None:",
            "            # In header.",
            "            s = self.header_plus + data",
            "            index = find_double_newline(s)",
            "            if index >= 0:",
            "                # Header finished.",
            "                header_plus = s[:index]",
            "                consumed = len(data) - (len(s) - index)",
            "",
            "                # Remove preceeding blank lines. This is suggested by",
            "                # https://tools.ietf.org/html/rfc7230#section-3.5 to support",
            "                # clients sending an extra CR LF after another request when",
            "                # using HTTP pipelining",
            "                header_plus = header_plus.lstrip()",
            "",
            "                if not header_plus:",
            "                    self.empty = True",
            "                    self.completed = True",
            "                else:",
            "                    try:",
            "                        self.parse_header(header_plus)",
            "                    except ParsingError as e:",
            "                        self.error = BadRequest(e.args[0])",
            "                        self.completed = True",
            "                    else:",
            "                        if self.body_rcv is None:",
            "                            # no content-length header and not a t-e: chunked",
            "                            # request",
            "                            self.completed = True",
            "                        if self.content_length > 0:",
            "                            max_body = self.adj.max_request_body_size",
            "                            # we won't accept this request if the content-length",
            "                            # is too large",
            "                            if self.content_length >= max_body:",
            "                                self.error = RequestEntityTooLarge(",
            "                                    \"exceeds max_body of %s\" % max_body",
            "                                )",
            "                                self.completed = True",
            "                self.headers_finished = True",
            "                return consumed",
            "            else:",
            "                # Header not finished yet.",
            "                self.header_bytes_received += datalen",
            "                max_header = self.adj.max_request_header_size",
            "                if self.header_bytes_received >= max_header:",
            "                    # malformed header, we need to construct some request",
            "                    # on our own. we disregard the incoming(?) requests HTTP",
            "                    # version and just use 1.0. IOW someone just sent garbage",
            "                    # over the wire",
            "                    self.parse_header(b\"GET / HTTP/1.0\\n\")",
            "                    self.error = RequestHeaderFieldsTooLarge(",
            "                        \"exceeds max_header of %s\" % max_header",
            "                    )",
            "                    self.completed = True",
            "                self.header_plus = s",
            "                return datalen",
            "        else:",
            "            # In body.",
            "            consumed = br.received(data)",
            "            self.body_bytes_received += consumed",
            "            max_body = self.adj.max_request_body_size",
            "            if self.body_bytes_received >= max_body:",
            "                # this will only be raised during t-e: chunked requests",
            "                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)",
            "                self.completed = True",
            "            elif br.error:",
            "                # garbage in chunked encoding input probably",
            "                self.error = br.error",
            "                self.completed = True",
            "            elif br.completed:",
            "                # The request (with the body) is ready to use.",
            "                self.completed = True",
            "                if self.chunked:",
            "                    # We've converted the chunked transfer encoding request",
            "                    # body into a normal request body, so we know its content",
            "                    # length; set the header here.  We already popped the",
            "                    # TRANSFER_ENCODING header in parse_header, so this will",
            "                    # appear to the client to be an entirely non-chunked HTTP",
            "                    # request with a valid content-length.",
            "                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())",
            "            return consumed",
            "",
            "    def parse_header(self, header_plus):",
            "        \"\"\"",
            "        Parses the header_plus block of text (the headers plus the",
            "        first line of the request).",
            "        \"\"\"",
            "        index = header_plus.find(b\"\\r\\n\")",
            "        if index >= 0:",
            "            first_line = header_plus[:index].rstrip()",
            "            header = header_plus[index + 2 :]",
            "        else:",
            "            raise ParsingError(\"HTTP message header invalid\")",
            "",
            "        if b\"\\r\" in first_line or b\"\\n\" in first_line:",
            "            raise ParsingError(\"Bare CR or LF found in HTTP message\")",
            "",
            "        self.first_line = first_line  # for testing",
            "",
            "        lines = get_header_lines(header)",
            "",
            "        headers = self.headers",
            "        for line in lines:",
            "            index = line.find(b\":\")",
            "            if index > 0:",
            "                key = line[:index]",
            "                if b\"_\" in key:",
            "                    continue",
            "                value = line[index + 1 :].strip()",
            "                key1 = tostr(key.upper().replace(b\"-\", b\"_\"))",
            "                # If a header already exists, we append subsequent values",
            "                # seperated by a comma. Applications already need to handle",
            "                # the comma seperated values, as HTTP front ends might do",
            "                # the concatenation for you (behavior specified in RFC2616).",
            "                try:",
            "                    headers[key1] += tostr(b\", \" + value)",
            "                except KeyError:",
            "                    headers[key1] = tostr(value)",
            "            # else there's garbage in the headers?",
            "",
            "        # command, uri, version will be bytes",
            "        command, uri, version = crack_first_line(first_line)",
            "        version = tostr(version)",
            "        command = tostr(command)",
            "        self.command = command",
            "        self.version = version",
            "        (",
            "            self.proxy_scheme,",
            "            self.proxy_netloc,",
            "            self.path,",
            "            self.query,",
            "            self.fragment,",
            "        ) = split_uri(uri)",
            "        self.url_scheme = self.adj.url_scheme",
            "        connection = headers.get(\"CONNECTION\", \"\")",
            "",
            "        if version == \"1.0\":",
            "            if connection.lower() != \"keep-alive\":",
            "                self.connection_close = True",
            "",
            "        if version == \"1.1\":",
            "            # since the server buffers data from chunked transfers and clients",
            "            # never need to deal with chunked requests, downstream clients",
            "            # should not see the HTTP_TRANSFER_ENCODING header; we pop it",
            "            # here",
            "            te = headers.pop(\"TRANSFER_ENCODING\", \"\")",
            "            if te.lower() == \"chunked\":",
            "                self.chunked = True",
            "                buf = OverflowableBuffer(self.adj.inbuf_overflow)",
            "                self.body_rcv = ChunkedReceiver(buf)",
            "            expect = headers.get(\"EXPECT\", \"\").lower()",
            "            self.expect_continue = expect == \"100-continue\"",
            "            if connection.lower() == \"close\":",
            "                self.connection_close = True",
            "",
            "        if not self.chunked:",
            "            try:",
            "                cl = int(headers.get(\"CONTENT_LENGTH\", 0))",
            "            except ValueError:",
            "                cl = 0",
            "            self.content_length = cl",
            "            if cl > 0:",
            "                buf = OverflowableBuffer(self.adj.inbuf_overflow)",
            "                self.body_rcv = FixedStreamReceiver(cl, buf)",
            "",
            "    def get_body_stream(self):",
            "        body_rcv = self.body_rcv",
            "        if body_rcv is not None:",
            "            return body_rcv.getfile()",
            "        else:",
            "            return BytesIO()",
            "",
            "    def close(self):",
            "        body_rcv = self.body_rcv",
            "        if body_rcv is not None:",
            "            body_rcv.getbuf().close()",
            "",
            "",
            "def split_uri(uri):",
            "    # urlsplit handles byte input by returning bytes on py3, so",
            "    # scheme, netloc, path, query, and fragment are bytes",
            "",
            "    scheme = netloc = path = query = fragment = b\"\"",
            "",
            "    # urlsplit below will treat this as a scheme-less netloc, thereby losing",
            "    # the original intent of the request. Here we shamelessly stole 4 lines of",
            "    # code from the CPython stdlib to parse out the fragment and query but",
            "    # leave the path alone. See",
            "    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468",
            "    # and https://github.com/Pylons/waitress/issues/260",
            "",
            "    if uri[:2] == b\"//\":",
            "        path = uri",
            "",
            "        if b\"#\" in path:",
            "            path, fragment = path.split(b\"#\", 1)",
            "",
            "        if b\"?\" in path:",
            "            path, query = path.split(b\"?\", 1)",
            "    else:",
            "        try:",
            "            scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)",
            "        except UnicodeError:",
            "            raise ParsingError(\"Bad URI\")",
            "",
            "    return (",
            "        tostr(scheme),",
            "        tostr(netloc),",
            "        unquote_bytes_to_wsgi(path),",
            "        tostr(query),",
            "        tostr(fragment),",
            "    )",
            "",
            "",
            "def get_header_lines(header):",
            "    \"\"\"",
            "    Splits the header into lines, putting multi-line headers together.",
            "    \"\"\"",
            "    r = []",
            "    lines = header.split(b\"\\r\\n\")",
            "    for line in lines:",
            "        if b\"\\r\" in line or b\"\\n\" in line:",
            "            raise ParsingError('Bare CR or LF found in header line \"%s\"' % tostr(line))",
            "",
            "        if line.startswith((b\" \", b\"\\t\")):",
            "            if not r:",
            "                # https://corte.si/posts/code/pathod/pythonservers/index.html",
            "                raise ParsingError('Malformed header line \"%s\"' % tostr(line))",
            "            r[-1] += line",
            "        else:",
            "            r.append(line)",
            "    return r",
            "",
            "",
            "first_line_re = re.compile(",
            "    b\"([^ ]+) \"",
            "    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"",
            "    b\"(( HTTP/([0-9.]+))$|$)\"",
            ")",
            "",
            "",
            "def crack_first_line(line):",
            "    m = first_line_re.match(line)",
            "    if m is not None and m.end() == len(line):",
            "        if m.group(3):",
            "            version = m.group(5)",
            "        else:",
            "            version = b\"\"",
            "        method = m.group(1)",
            "",
            "        # the request methods that are currently defined are all uppercase:",
            "        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and",
            "        # the request method is case sensitive according to",
            "        # https://tools.ietf.org/html/rfc7231#section-4.1",
            "",
            "        # By disallowing anything but uppercase methods we save poor",
            "        # unsuspecting souls from sending lowercase HTTP methods to waitress",
            "        # and having the request complete, while servers like nginx drop the",
            "        # request onto the floor.",
            "        if method != method.upper():",
            "            raise ParsingError('Malformed HTTP method \"%s\"' % tostr(method))",
            "        uri = m.group(2)",
            "        return method, uri, version",
            "    else:",
            "        return b\"\", b\"\", b\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "22": [],
            "23": [],
            "24": [],
            "25": [],
            "26": [],
            "27": [],
            "29": [],
            "30": [],
            "31": [],
            "32": [],
            "33": [],
            "34": [],
            "36": [],
            "39": [],
            "98": [
                "HTTPRequestParser",
                "received"
            ],
            "172": [
                "HTTPRequestParser",
                "parse_header"
            ],
            "175": [
                "HTTPRequestParser",
                "parse_header"
            ],
            "177": [
                "HTTPRequestParser",
                "parse_header"
            ],
            "178": [
                "HTTPRequestParser",
                "parse_header"
            ],
            "302": [
                "get_header_lines"
            ]
        },
        "addLocation": []
    },
    "waitress/receiver.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " \"\"\"Data Chunk Receiver"
            },
            "1": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from waitress.utilities import find_double_newline"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from waitress.utilities import BadRequest"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+from waitress.utilities import BadRequest, find_double_newline"
            },
            "7": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " class FixedStreamReceiver(object):"
            },
            "10": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "     def received(self, data):"
            },
            "11": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "         \"See IStreamConsumer\""
            },
            "12": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "         rm = self.remain"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         if rm < 1:"
            },
            "15": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "             self.completed = True  # Avoid any chance of spinning"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "             return 0"
            },
            "18": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         datalen = len(data)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "         if rm <= datalen:"
            },
            "21": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "             self.buf.append(data[:rm])"
            },
            "22": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "             self.remain = 0"
            },
            "23": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "             self.completed = True"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "             return rm"
            },
            "26": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         else:"
            },
            "27": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "             self.buf.append(data)"
            },
            "28": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "             self.remain -= datalen"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "             return datalen"
            },
            "31": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " "
            },
            "32": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "     def getfile(self):"
            },
            "33": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 62,
                "PatchRowcode": " class ChunkedReceiver(object):"
            },
            "34": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " "
            },
            "35": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "     chunk_remainder = 0"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+    validate_chunk_end = False"
            },
            "37": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "     control_line = b\"\""
            },
            "38": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "     all_chunks_received = False"
            },
            "39": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     trailer = b\"\""
            },
            "40": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " "
            },
            "41": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "     def received(self, s):"
            },
            "42": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         # Returns the number of bytes consumed."
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+"
            },
            "44": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "         if self.completed:"
            },
            "45": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "             return 0"
            },
            "46": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "         orig_size = len(s)"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+"
            },
            "48": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         while s:"
            },
            "49": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "             rm = self.chunk_remainder"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+"
            },
            "51": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "             if rm > 0:"
            },
            "52": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "                 # Receive the remainder of a chunk."
            },
            "53": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "                 to_write = s[:rm]"
            },
            "54": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "                 self.buf.append(to_write)"
            },
            "55": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "                 written = len(to_write)"
            },
            "56": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "                 s = s[written:]"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+"
            },
            "58": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "                 self.chunk_remainder -= written"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+                if self.chunk_remainder == 0:"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+                    self.validate_chunk_end = True"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+            elif self.validate_chunk_end:"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+                pos = s.find(b\"\\r\\n\")"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+                if pos == 0:"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+                    # Chop off the terminating CR LF from the chunk"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+                    s = s[2:]"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+                else:"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+                    self.error = BadRequest(\"Chunk not properly terminated\")"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+                    self.all_chunks_received = True"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+                # Always exit this loop"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+                self.validate_chunk_end = False"
            },
            "74": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "             elif not self.all_chunks_received:"
            },
            "75": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "                 # Receive a control line."
            },
            "76": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "                 s = self.control_line + s"
            },
            "77": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                pos = s.find(b\"\\n\")"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+                pos = s.find(b\"\\r\\n\")"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+"
            },
            "80": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "                 if pos < 0:"
            },
            "81": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 120,
                "PatchRowcode": "                     # Control line not finished."
            },
            "82": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 121,
                "PatchRowcode": "                     self.control_line = s"
            },
            "83": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "                     s = \"\""
            },
            "84": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "                 else:"
            },
            "85": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "                     # Control line finished."
            },
            "86": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "                     line = s[:pos]"
            },
            "87": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    s = s[pos + 1 :]"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+                    s = s[pos + 2 :]"
            },
            "89": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "                     self.control_line = b\"\""
            },
            "90": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "                     line = line.strip()"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+"
            },
            "92": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "                     if line:"
            },
            "93": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "                         # Begin a new chunk."
            },
            "94": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "                         semi = line.find(b\";\")"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+"
            },
            "96": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "                         if semi >= 0:"
            },
            "97": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "                             # discard extension info."
            },
            "98": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "                             line = line[:semi]"
            },
            "99": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "                         except ValueError:  # garbage in input"
            },
            "100": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "                             self.error = BadRequest(\"garbage in chunked encoding input\")"
            },
            "101": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "                             sz = 0"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+"
            },
            "103": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "                         if sz > 0:"
            },
            "104": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "                             # Start a new chunk."
            },
            "105": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "                             self.chunk_remainder = sz"
            },
            "106": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "             else:"
            },
            "107": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "                 # Receive the trailer."
            },
            "108": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "                 trailer = self.trailer + s"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+"
            },
            "110": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "                 if trailer.startswith(b\"\\r\\n\"):"
            },
            "111": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "                     # No trailer."
            },
            "112": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "                     self.completed = True"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+"
            },
            "114": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "                     return orig_size - (len(trailer) - 2)"
            },
            "115": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                elif trailer.startswith(b\"\\n\"):"
            },
            "116": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # No trailer."
            },
            "117": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    self.completed = True"
            },
            "118": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return orig_size - (len(trailer) - 1)"
            },
            "119": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "                 pos = find_double_newline(trailer)"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+"
            },
            "121": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 161,
                "PatchRowcode": "                 if pos < 0:"
            },
            "122": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "                     # Trailer not finished."
            },
            "123": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "                     self.trailer = trailer"
            },
            "124": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "                     # Finished the trailer."
            },
            "125": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "                     self.completed = True"
            },
            "126": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "                     self.trailer = trailer[:pos]"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+"
            },
            "128": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "                     return orig_size - (len(trailer) - pos)"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+"
            },
            "130": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "         return orig_size"
            },
            "131": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 173,
                "PatchRowcode": " "
            },
            "132": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "     def getfile(self):"
            }
        },
        "frontPatchFile": [
            "##############################################################################",
            "#",
            "# Copyright (c) 2001, 2002 Zope Foundation and Contributors.",
            "# All Rights Reserved.",
            "#",
            "# This software is subject to the provisions of the Zope Public License,",
            "# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.",
            "# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED",
            "# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS",
            "# FOR A PARTICULAR PURPOSE.",
            "#",
            "##############################################################################",
            "\"\"\"Data Chunk Receiver",
            "\"\"\"",
            "",
            "from waitress.utilities import find_double_newline",
            "",
            "from waitress.utilities import BadRequest",
            "",
            "",
            "class FixedStreamReceiver(object):",
            "",
            "    # See IStreamConsumer",
            "    completed = False",
            "    error = None",
            "",
            "    def __init__(self, cl, buf):",
            "        self.remain = cl",
            "        self.buf = buf",
            "",
            "    def __len__(self):",
            "        return self.buf.__len__()",
            "",
            "    def received(self, data):",
            "        \"See IStreamConsumer\"",
            "        rm = self.remain",
            "        if rm < 1:",
            "            self.completed = True  # Avoid any chance of spinning",
            "            return 0",
            "        datalen = len(data)",
            "        if rm <= datalen:",
            "            self.buf.append(data[:rm])",
            "            self.remain = 0",
            "            self.completed = True",
            "            return rm",
            "        else:",
            "            self.buf.append(data)",
            "            self.remain -= datalen",
            "            return datalen",
            "",
            "    def getfile(self):",
            "        return self.buf.getfile()",
            "",
            "    def getbuf(self):",
            "        return self.buf",
            "",
            "",
            "class ChunkedReceiver(object):",
            "",
            "    chunk_remainder = 0",
            "    control_line = b\"\"",
            "    all_chunks_received = False",
            "    trailer = b\"\"",
            "    completed = False",
            "    error = None",
            "",
            "    # max_control_line = 1024",
            "    # max_trailer = 65536",
            "",
            "    def __init__(self, buf):",
            "        self.buf = buf",
            "",
            "    def __len__(self):",
            "        return self.buf.__len__()",
            "",
            "    def received(self, s):",
            "        # Returns the number of bytes consumed.",
            "        if self.completed:",
            "            return 0",
            "        orig_size = len(s)",
            "        while s:",
            "            rm = self.chunk_remainder",
            "            if rm > 0:",
            "                # Receive the remainder of a chunk.",
            "                to_write = s[:rm]",
            "                self.buf.append(to_write)",
            "                written = len(to_write)",
            "                s = s[written:]",
            "                self.chunk_remainder -= written",
            "            elif not self.all_chunks_received:",
            "                # Receive a control line.",
            "                s = self.control_line + s",
            "                pos = s.find(b\"\\n\")",
            "                if pos < 0:",
            "                    # Control line not finished.",
            "                    self.control_line = s",
            "                    s = \"\"",
            "                else:",
            "                    # Control line finished.",
            "                    line = s[:pos]",
            "                    s = s[pos + 1 :]",
            "                    self.control_line = b\"\"",
            "                    line = line.strip()",
            "                    if line:",
            "                        # Begin a new chunk.",
            "                        semi = line.find(b\";\")",
            "                        if semi >= 0:",
            "                            # discard extension info.",
            "                            line = line[:semi]",
            "                        try:",
            "                            sz = int(line.strip(), 16)  # hexadecimal",
            "                        except ValueError:  # garbage in input",
            "                            self.error = BadRequest(\"garbage in chunked encoding input\")",
            "                            sz = 0",
            "                        if sz > 0:",
            "                            # Start a new chunk.",
            "                            self.chunk_remainder = sz",
            "                        else:",
            "                            # Finished chunks.",
            "                            self.all_chunks_received = True",
            "                    # else expect a control line.",
            "            else:",
            "                # Receive the trailer.",
            "                trailer = self.trailer + s",
            "                if trailer.startswith(b\"\\r\\n\"):",
            "                    # No trailer.",
            "                    self.completed = True",
            "                    return orig_size - (len(trailer) - 2)",
            "                elif trailer.startswith(b\"\\n\"):",
            "                    # No trailer.",
            "                    self.completed = True",
            "                    return orig_size - (len(trailer) - 1)",
            "                pos = find_double_newline(trailer)",
            "                if pos < 0:",
            "                    # Trailer not finished.",
            "                    self.trailer = trailer",
            "                    s = b\"\"",
            "                else:",
            "                    # Finished the trailer.",
            "                    self.completed = True",
            "                    self.trailer = trailer[:pos]",
            "                    return orig_size - (len(trailer) - pos)",
            "        return orig_size",
            "",
            "    def getfile(self):",
            "        return self.buf.getfile()",
            "",
            "    def getbuf(self):",
            "        return self.buf"
        ],
        "afterPatchFile": [
            "##############################################################################",
            "#",
            "# Copyright (c) 2001, 2002 Zope Foundation and Contributors.",
            "# All Rights Reserved.",
            "#",
            "# This software is subject to the provisions of the Zope Public License,",
            "# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.",
            "# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED",
            "# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS",
            "# FOR A PARTICULAR PURPOSE.",
            "#",
            "##############################################################################",
            "\"\"\"Data Chunk Receiver",
            "\"\"\"",
            "",
            "from waitress.utilities import BadRequest, find_double_newline",
            "",
            "",
            "class FixedStreamReceiver(object):",
            "",
            "    # See IStreamConsumer",
            "    completed = False",
            "    error = None",
            "",
            "    def __init__(self, cl, buf):",
            "        self.remain = cl",
            "        self.buf = buf",
            "",
            "    def __len__(self):",
            "        return self.buf.__len__()",
            "",
            "    def received(self, data):",
            "        \"See IStreamConsumer\"",
            "        rm = self.remain",
            "",
            "        if rm < 1:",
            "            self.completed = True  # Avoid any chance of spinning",
            "",
            "            return 0",
            "        datalen = len(data)",
            "",
            "        if rm <= datalen:",
            "            self.buf.append(data[:rm])",
            "            self.remain = 0",
            "            self.completed = True",
            "",
            "            return rm",
            "        else:",
            "            self.buf.append(data)",
            "            self.remain -= datalen",
            "",
            "            return datalen",
            "",
            "    def getfile(self):",
            "        return self.buf.getfile()",
            "",
            "    def getbuf(self):",
            "        return self.buf",
            "",
            "",
            "class ChunkedReceiver(object):",
            "",
            "    chunk_remainder = 0",
            "    validate_chunk_end = False",
            "    control_line = b\"\"",
            "    all_chunks_received = False",
            "    trailer = b\"\"",
            "    completed = False",
            "    error = None",
            "",
            "    # max_control_line = 1024",
            "    # max_trailer = 65536",
            "",
            "    def __init__(self, buf):",
            "        self.buf = buf",
            "",
            "    def __len__(self):",
            "        return self.buf.__len__()",
            "",
            "    def received(self, s):",
            "        # Returns the number of bytes consumed.",
            "",
            "        if self.completed:",
            "            return 0",
            "        orig_size = len(s)",
            "",
            "        while s:",
            "            rm = self.chunk_remainder",
            "",
            "            if rm > 0:",
            "                # Receive the remainder of a chunk.",
            "                to_write = s[:rm]",
            "                self.buf.append(to_write)",
            "                written = len(to_write)",
            "                s = s[written:]",
            "",
            "                self.chunk_remainder -= written",
            "",
            "                if self.chunk_remainder == 0:",
            "                    self.validate_chunk_end = True",
            "            elif self.validate_chunk_end:",
            "                pos = s.find(b\"\\r\\n\")",
            "",
            "                if pos == 0:",
            "                    # Chop off the terminating CR LF from the chunk",
            "                    s = s[2:]",
            "                else:",
            "                    self.error = BadRequest(\"Chunk not properly terminated\")",
            "                    self.all_chunks_received = True",
            "",
            "                # Always exit this loop",
            "                self.validate_chunk_end = False",
            "            elif not self.all_chunks_received:",
            "                # Receive a control line.",
            "                s = self.control_line + s",
            "                pos = s.find(b\"\\r\\n\")",
            "",
            "                if pos < 0:",
            "                    # Control line not finished.",
            "                    self.control_line = s",
            "                    s = \"\"",
            "                else:",
            "                    # Control line finished.",
            "                    line = s[:pos]",
            "                    s = s[pos + 2 :]",
            "                    self.control_line = b\"\"",
            "                    line = line.strip()",
            "",
            "                    if line:",
            "                        # Begin a new chunk.",
            "                        semi = line.find(b\";\")",
            "",
            "                        if semi >= 0:",
            "                            # discard extension info.",
            "                            line = line[:semi]",
            "                        try:",
            "                            sz = int(line.strip(), 16)  # hexadecimal",
            "                        except ValueError:  # garbage in input",
            "                            self.error = BadRequest(\"garbage in chunked encoding input\")",
            "                            sz = 0",
            "",
            "                        if sz > 0:",
            "                            # Start a new chunk.",
            "                            self.chunk_remainder = sz",
            "                        else:",
            "                            # Finished chunks.",
            "                            self.all_chunks_received = True",
            "                    # else expect a control line.",
            "            else:",
            "                # Receive the trailer.",
            "                trailer = self.trailer + s",
            "",
            "                if trailer.startswith(b\"\\r\\n\"):",
            "                    # No trailer.",
            "                    self.completed = True",
            "",
            "                    return orig_size - (len(trailer) - 2)",
            "                pos = find_double_newline(trailer)",
            "",
            "                if pos < 0:",
            "                    # Trailer not finished.",
            "                    self.trailer = trailer",
            "                    s = b\"\"",
            "                else:",
            "                    # Finished the trailer.",
            "                    self.completed = True",
            "                    self.trailer = trailer[:pos]",
            "",
            "                    return orig_size - (len(trailer) - pos)",
            "",
            "        return orig_size",
            "",
            "    def getfile(self):",
            "        return self.buf.getfile()",
            "",
            "    def getbuf(self):",
            "        return self.buf"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "17": [],
            "18": [],
            "19": [],
            "94": [
                "ChunkedReceiver",
                "received"
            ],
            "102": [
                "ChunkedReceiver",
                "received"
            ],
            "130": [
                "ChunkedReceiver",
                "received"
            ],
            "131": [
                "ChunkedReceiver",
                "received"
            ],
            "132": [
                "ChunkedReceiver",
                "received"
            ],
            "133": [
                "ChunkedReceiver",
                "received"
            ]
        },
        "addLocation": []
    },
    "waitress/tests/test_channel.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 423,
                "afterPatchRowNumber": 423,
                "PatchRowcode": "     def test_received(self):"
            },
            "1": {
                "beforePatchRowNumber": 424,
                "afterPatchRowNumber": 424,
                "PatchRowcode": "         inst, sock, map = self._makeOneWithMap()"
            },
            "2": {
                "beforePatchRowNumber": 425,
                "afterPatchRowNumber": 425,
                "PatchRowcode": "         inst.server = DummyServer()"
            },
            "3": {
                "beforePatchRowNumber": 426,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 426,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "5": {
                "beforePatchRowNumber": 427,
                "afterPatchRowNumber": 427,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [inst])"
            },
            "6": {
                "beforePatchRowNumber": 428,
                "afterPatchRowNumber": 428,
                "PatchRowcode": "         self.assertTrue(inst.requests)"
            },
            "7": {
                "beforePatchRowNumber": 429,
                "afterPatchRowNumber": 429,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": 438,
                "PatchRowcode": "         inst.request = preq"
            },
            "9": {
                "beforePatchRowNumber": 439,
                "afterPatchRowNumber": 439,
                "PatchRowcode": "         preq.completed = False"
            },
            "10": {
                "beforePatchRowNumber": 440,
                "afterPatchRowNumber": 440,
                "PatchRowcode": "         preq.empty = True"
            },
            "11": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 441,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "13": {
                "beforePatchRowNumber": 442,
                "afterPatchRowNumber": 442,
                "PatchRowcode": "         self.assertEqual(inst.requests, ())"
            },
            "14": {
                "beforePatchRowNumber": 443,
                "afterPatchRowNumber": 443,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "15": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": 444,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 449,
                "PatchRowcode": "         inst.request = preq"
            },
            "17": {
                "beforePatchRowNumber": 450,
                "afterPatchRowNumber": 450,
                "PatchRowcode": "         preq.completed = True"
            },
            "18": {
                "beforePatchRowNumber": 451,
                "afterPatchRowNumber": 451,
                "PatchRowcode": "         preq.empty = True"
            },
            "19": {
                "beforePatchRowNumber": 452,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 452,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "21": {
                "beforePatchRowNumber": 453,
                "afterPatchRowNumber": 453,
                "PatchRowcode": "         self.assertEqual(inst.request, None)"
            },
            "22": {
                "beforePatchRowNumber": 454,
                "afterPatchRowNumber": 454,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "23": {
                "beforePatchRowNumber": 455,
                "afterPatchRowNumber": 455,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 460,
                "afterPatchRowNumber": 460,
                "PatchRowcode": "         inst.request = preq"
            },
            "25": {
                "beforePatchRowNumber": 461,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "         preq.completed = True"
            },
            "26": {
                "beforePatchRowNumber": 462,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "         preq.error = True"
            },
            "27": {
                "beforePatchRowNumber": 463,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 463,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "29": {
                "beforePatchRowNumber": 464,
                "afterPatchRowNumber": 464,
                "PatchRowcode": "         self.assertEqual(inst.request, None)"
            },
            "30": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": 465,
                "PatchRowcode": "         self.assertEqual(len(inst.server.tasks), 1)"
            },
            "31": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": 466,
                "PatchRowcode": "         self.assertTrue(inst.requests)"
            },
            "32": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": 473,
                "PatchRowcode": "         preq.completed = True"
            },
            "33": {
                "beforePatchRowNumber": 474,
                "afterPatchRowNumber": 474,
                "PatchRowcode": "         preq.empty = True"
            },
            "34": {
                "beforePatchRowNumber": 475,
                "afterPatchRowNumber": 475,
                "PatchRowcode": "         preq.connection_close = True"
            },
            "35": {
                "beforePatchRowNumber": 476,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\" + b\"a\" * 50000)"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 476,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\" + b\"a\" * 50000)"
            },
            "37": {
                "beforePatchRowNumber": 477,
                "afterPatchRowNumber": 477,
                "PatchRowcode": "         self.assertEqual(inst.request, None)"
            },
            "38": {
                "beforePatchRowNumber": 478,
                "afterPatchRowNumber": 478,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "39": {
                "beforePatchRowNumber": 479,
                "afterPatchRowNumber": 479,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 480,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_received_preq_completed_n_lt_data(self):"
            },
            "41": {
                "beforePatchRowNumber": 481,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst, sock, map = self._makeOneWithMap()"
            },
            "42": {
                "beforePatchRowNumber": 482,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.server = DummyServer()"
            },
            "43": {
                "beforePatchRowNumber": 483,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        preq = DummyParser()"
            },
            "44": {
                "beforePatchRowNumber": 484,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.request = preq"
            },
            "45": {
                "beforePatchRowNumber": 485,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        preq.completed = True"
            },
            "46": {
                "beforePatchRowNumber": 486,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        preq.empty = False"
            },
            "47": {
                "beforePatchRowNumber": 487,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        line = b\"GET / HTTP/1.1\\n\\n\""
            },
            "48": {
                "beforePatchRowNumber": 488,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        preq.retval = len(line)"
            },
            "49": {
                "beforePatchRowNumber": 489,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(line + line)"
            },
            "50": {
                "beforePatchRowNumber": 490,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.assertEqual(inst.request, None)"
            },
            "51": {
                "beforePatchRowNumber": 491,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.assertEqual(len(inst.requests), 2)"
            },
            "52": {
                "beforePatchRowNumber": 492,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.assertEqual(len(inst.server.tasks), 1)"
            },
            "53": {
                "beforePatchRowNumber": 493,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "54": {
                "beforePatchRowNumber": 494,
                "afterPatchRowNumber": 480,
                "PatchRowcode": "     def test_received_headers_finished_expect_continue_false(self):"
            },
            "55": {
                "beforePatchRowNumber": 495,
                "afterPatchRowNumber": 481,
                "PatchRowcode": "         inst, sock, map = self._makeOneWithMap()"
            },
            "56": {
                "beforePatchRowNumber": 496,
                "afterPatchRowNumber": 482,
                "PatchRowcode": "         inst.server = DummyServer()"
            },
            "57": {
                "beforePatchRowNumber": 501,
                "afterPatchRowNumber": 487,
                "PatchRowcode": "         preq.completed = False"
            },
            "58": {
                "beforePatchRowNumber": 502,
                "afterPatchRowNumber": 488,
                "PatchRowcode": "         preq.empty = False"
            },
            "59": {
                "beforePatchRowNumber": 503,
                "afterPatchRowNumber": 489,
                "PatchRowcode": "         preq.retval = 1"
            },
            "60": {
                "beforePatchRowNumber": 504,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 490,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "62": {
                "beforePatchRowNumber": 505,
                "afterPatchRowNumber": 491,
                "PatchRowcode": "         self.assertEqual(inst.request, preq)"
            },
            "63": {
                "beforePatchRowNumber": 506,
                "afterPatchRowNumber": 492,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "64": {
                "beforePatchRowNumber": 507,
                "afterPatchRowNumber": 493,
                "PatchRowcode": "         self.assertEqual(inst.outbufs[0].get(100), b\"\")"
            },
            "65": {
                "beforePatchRowNumber": 515,
                "afterPatchRowNumber": 501,
                "PatchRowcode": "         preq.headers_finished = True"
            },
            "66": {
                "beforePatchRowNumber": 516,
                "afterPatchRowNumber": 502,
                "PatchRowcode": "         preq.completed = False"
            },
            "67": {
                "beforePatchRowNumber": 517,
                "afterPatchRowNumber": 503,
                "PatchRowcode": "         preq.empty = False"
            },
            "68": {
                "beforePatchRowNumber": 518,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 504,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "70": {
                "beforePatchRowNumber": 519,
                "afterPatchRowNumber": 505,
                "PatchRowcode": "         self.assertEqual(inst.request, preq)"
            },
            "71": {
                "beforePatchRowNumber": 520,
                "afterPatchRowNumber": 506,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "72": {
                "beforePatchRowNumber": 521,
                "afterPatchRowNumber": 507,
                "PatchRowcode": "         self.assertEqual(sock.sent, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")"
            },
            "73": {
                "beforePatchRowNumber": 532,
                "afterPatchRowNumber": 518,
                "PatchRowcode": "         preq.completed = False"
            },
            "74": {
                "beforePatchRowNumber": 533,
                "afterPatchRowNumber": 519,
                "PatchRowcode": "         preq.empty = False"
            },
            "75": {
                "beforePatchRowNumber": 534,
                "afterPatchRowNumber": 520,
                "PatchRowcode": "         inst.sent_continue = True"
            },
            "76": {
                "beforePatchRowNumber": 535,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        inst.received(b\"GET / HTTP/1.1\\n\\n\")"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 521,
                "PatchRowcode": "+        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")"
            },
            "78": {
                "beforePatchRowNumber": 536,
                "afterPatchRowNumber": 522,
                "PatchRowcode": "         self.assertEqual(inst.request, preq)"
            },
            "79": {
                "beforePatchRowNumber": 537,
                "afterPatchRowNumber": 523,
                "PatchRowcode": "         self.assertEqual(inst.server.tasks, [])"
            },
            "80": {
                "beforePatchRowNumber": 538,
                "afterPatchRowNumber": 524,
                "PatchRowcode": "         self.assertEqual(sock.sent, b\"\")"
            }
        },
        "frontPatchFile": [
            "import unittest",
            "import io",
            "",
            "",
            "class TestHTTPChannel(unittest.TestCase):",
            "    def _makeOne(self, sock, addr, adj, map=None):",
            "        from waitress.channel import HTTPChannel",
            "",
            "        server = DummyServer()",
            "        return HTTPChannel(server, sock, addr, adj=adj, map=map)",
            "",
            "    def _makeOneWithMap(self, adj=None):",
            "        if adj is None:",
            "            adj = DummyAdjustments()",
            "        sock = DummySock()",
            "        map = {}",
            "        inst = self._makeOne(sock, \"127.0.0.1\", adj, map=map)",
            "        inst.outbuf_lock = DummyLock()",
            "        return inst, sock, map",
            "",
            "    def test_ctor(self):",
            "        inst, _, map = self._makeOneWithMap()",
            "        self.assertEqual(inst.addr, \"127.0.0.1\")",
            "        self.assertEqual(inst.sendbuf_len, 2048)",
            "        self.assertEqual(map[100], inst)",
            "",
            "    def test_total_outbufs_len_an_outbuf_size_gt_sys_maxint(self):",
            "        from waitress.compat import MAXINT",
            "",
            "        inst, _, map = self._makeOneWithMap()",
            "",
            "        class DummyBuffer(object):",
            "            chunks = []",
            "",
            "            def append(self, data):",
            "                self.chunks.append(data)",
            "",
            "        class DummyData(object):",
            "            def __len__(self):",
            "                return MAXINT",
            "",
            "        inst.total_outbufs_len = 1",
            "        inst.outbufs = [DummyBuffer()]",
            "        inst.write_soon(DummyData())",
            "        # we are testing that this method does not raise an OverflowError",
            "        # (see https://github.com/Pylons/waitress/issues/47)",
            "        self.assertEqual(inst.total_outbufs_len, MAXINT + 1)",
            "",
            "    def test_writable_something_in_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.total_outbufs_len = 3",
            "        self.assertTrue(inst.writable())",
            "",
            "    def test_writable_nothing_in_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        self.assertFalse(inst.writable())",
            "",
            "    def test_writable_nothing_in_outbuf_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = True",
            "        self.assertTrue(inst.writable())",
            "",
            "    def test_handle_write_not_connected(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.connected = False",
            "        self.assertFalse(inst.handle_write())",
            "",
            "    def test_handle_write_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "",
            "    def test_handle_write_no_request_with_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertNotEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_outbuf_raises_socketerror(self):",
            "        import socket",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"abc\", socket.error)",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_outbuf_raises_othererror(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"abc\", IOError)",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_no_requests_no_outbuf_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"\")",
            "        inst.outbufs = [outbuf]",
            "        inst.will_close = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_no_requests_outbuf_gt_send_bytes(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 2",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_close_when_flushed(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        outbuf = DummyBuffer(b\"abc\")",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.will_close = False",
            "        inst.close_when_flushed = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, True)",
            "        self.assertEqual(inst.close_when_flushed, False)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_readable_no_requests_not_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.will_close = False",
            "        self.assertEqual(inst.readable(), True)",
            "",
            "    def test_readable_no_requests_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.will_close = True",
            "        self.assertEqual(inst.readable(), False)",
            "",
            "    def test_readable_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = True",
            "        self.assertEqual(inst.readable(), False)",
            "",
            "    def test_handle_read_no_error(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = False",
            "        inst.recv = lambda *arg: b\"abc\"",
            "        inst.last_activity = 0",
            "        L = []",
            "        inst.received = lambda x: L.append(x)",
            "        result = inst.handle_read()",
            "        self.assertEqual(result, None)",
            "        self.assertNotEqual(inst.last_activity, 0)",
            "        self.assertEqual(L, [b\"abc\"])",
            "",
            "    def test_handle_read_error(self):",
            "        import socket",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = False",
            "",
            "        def recv(b):",
            "            raise socket.error",
            "",
            "        inst.recv = recv",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_read()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test_write_soon_empty_byte(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        wrote = inst.write_soon(b\"\")",
            "        self.assertEqual(wrote, 0)",
            "        self.assertEqual(len(inst.outbufs[0]), 0)",
            "",
            "    def test_write_soon_nonempty_byte(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        wrote = inst.write_soon(b\"a\")",
            "        self.assertEqual(wrote, 1)",
            "        self.assertEqual(len(inst.outbufs[0]), 1)",
            "",
            "    def test_write_soon_filewrapper(self):",
            "        from waitress.buffers import ReadOnlyFileBasedBuffer",
            "",
            "        f = io.BytesIO(b\"abc\")",
            "        wrapper = ReadOnlyFileBasedBuffer(f, 8192)",
            "        wrapper.prepare()",
            "        inst, sock, map = self._makeOneWithMap()",
            "        outbufs = inst.outbufs",
            "        orig_outbuf = outbufs[0]",
            "        wrote = inst.write_soon(wrapper)",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(outbufs), 3)",
            "        self.assertEqual(outbufs[0], orig_outbuf)",
            "        self.assertEqual(outbufs[1], wrapper)",
            "        self.assertEqual(outbufs[2].__class__.__name__, \"OverflowableBuffer\")",
            "",
            "    def test_write_soon_disconnected(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.connected = False",
            "        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))",
            "",
            "    def test_write_soon_disconnected_while_over_watermark(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        def dummy_flush():",
            "            inst.connected = False",
            "",
            "        inst._flush_outbufs_below_high_watermark = dummy_flush",
            "        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))",
            "",
            "    def test_write_soon_rotates_outbuf_on_overflow(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.outbuf_high_watermark = 3",
            "        inst.current_outbuf_count = 4",
            "        wrote = inst.write_soon(b\"xyz\")",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(inst.outbufs), 2)",
            "        self.assertEqual(inst.outbufs[0].get(), b\"\")",
            "        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")",
            "",
            "    def test_write_soon_waits_on_backpressure(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.outbuf_high_watermark = 3",
            "        inst.total_outbufs_len = 4",
            "        inst.current_outbuf_count = 4",
            "",
            "        class Lock(DummyLock):",
            "            def wait(self):",
            "                inst.total_outbufs_len = 0",
            "                super(Lock, self).wait()",
            "",
            "        inst.outbuf_lock = Lock()",
            "        wrote = inst.write_soon(b\"xyz\")",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(inst.outbufs), 2)",
            "        self.assertEqual(inst.outbufs[0].get(), b\"\")",
            "        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")",
            "        self.assertTrue(inst.outbuf_lock.waited)",
            "",
            "    def test_handle_write_notify_after_flush(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 1",
            "        inst.adj.outbuf_high_watermark = 5",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertTrue(inst.outbuf_lock.notified)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_no_notify_after_flush(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 1",
            "        inst.adj.outbuf_high_watermark = 2",
            "        sock.send = lambda x: False",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertFalse(inst.outbuf_lock.notified)",
            "        self.assertEqual(sock.sent, b\"\")",
            "",
            "    def test__flush_some_empty_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, False)",
            "",
            "    def test__flush_some_full_outbuf_socket_returns_nonzero(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.outbufs[0].append(b\"abc\")",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "",
            "    def test__flush_some_full_outbuf_socket_returns_zero(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: False",
            "        inst.outbufs[0].append(b\"abc\")",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, False)",
            "",
            "    def test_flush_some_multiple_buffers_first_empty(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: len(x)",
            "        buffer = DummyBuffer(b\"abc\")",
            "        inst.outbufs.append(buffer)",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "        self.assertEqual(buffer.skipped, 3)",
            "        self.assertEqual(inst.outbufs, [buffer])",
            "",
            "    def test_flush_some_multiple_buffers_close_raises(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: len(x)",
            "        buffer = DummyBuffer(b\"abc\")",
            "        inst.outbufs.append(buffer)",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        inst.logger = DummyLogger()",
            "",
            "        def doraise():",
            "            raise NotImplementedError",
            "",
            "        inst.outbufs[0].close = doraise",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "        self.assertEqual(buffer.skipped, 3)",
            "        self.assertEqual(inst.outbufs, [buffer])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test__flush_some_outbuf_len_gt_sys_maxint(self):",
            "        from waitress.compat import MAXINT",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        class DummyHugeOutbuffer(object):",
            "            def __init__(self):",
            "                self.length = MAXINT + 1",
            "",
            "            def __len__(self):",
            "                return self.length",
            "",
            "            def get(self, numbytes):",
            "                self.length = 0",
            "                return b\"123\"",
            "",
            "        buf = DummyHugeOutbuffer()",
            "        inst.outbufs = [buf]",
            "        inst.send = lambda *arg: 0",
            "        result = inst._flush_some()",
            "        # we are testing that _flush_some doesn't raise an OverflowError",
            "        # when one of its outbufs has a __len__ that returns gt sys.maxint",
            "        self.assertEqual(result, False)",
            "",
            "    def test_handle_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.handle_close()",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "",
            "    def test_handle_close_outbuf_raises_on_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        def doraise():",
            "            raise NotImplementedError",
            "",
            "        inst.outbufs[0].close = doraise",
            "        inst.logger = DummyLogger()",
            "        inst.handle_close()",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test_add_channel(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        fileno = inst._fileno",
            "        inst.add_channel(map)",
            "        self.assertEqual(map[fileno], inst)",
            "        self.assertEqual(inst.server.active_channels[fileno], inst)",
            "",
            "    def test_del_channel(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        fileno = inst._fileno",
            "        inst.server.active_channels[fileno] = True",
            "        inst.del_channel(map)",
            "        self.assertEqual(map.get(fileno), None)",
            "        self.assertEqual(inst.server.active_channels.get(fileno), None)",
            "",
            "    def test_received(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.server.tasks, [inst])",
            "        self.assertTrue(inst.requests)",
            "",
            "    def test_received_no_chunk(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        self.assertEqual(inst.received(b\"\"), False)",
            "",
            "    def test_received_preq_not_completed(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = False",
            "        preq.empty = True",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.requests, ())",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_preq_completed_empty(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.empty = True",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_preq_error(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.error = True",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(len(inst.server.tasks), 1)",
            "        self.assertTrue(inst.requests)",
            "",
            "    def test_received_preq_completed_connection_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.empty = True",
            "        preq.connection_close = True",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\" + b\"a\" * 50000)",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_preq_completed_n_lt_data(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.empty = False",
            "        line = b\"GET / HTTP/1.1\\n\\n\"",
            "        preq.retval = len(line)",
            "        inst.received(line + line)",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(len(inst.requests), 2)",
            "        self.assertEqual(len(inst.server.tasks), 1)",
            "",
            "    def test_received_headers_finished_expect_continue_false(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = False",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        preq.retval = 1",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(inst.outbufs[0].get(100), b\"\")",
            "",
            "    def test_received_headers_finished_expect_continue_true(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = True",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(sock.sent, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.sent_continue, True)",
            "        self.assertEqual(preq.completed, False)",
            "",
            "    def test_received_headers_finished_expect_continue_true_sent_true(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = True",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        inst.sent_continue = True",
            "        inst.received(b\"GET / HTTP/1.1\\n\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(inst.sent_continue, True)",
            "        self.assertEqual(preq.completed, False)",
            "",
            "    def test_service_no_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "",
            "    def test_service_with_one_request(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request = DummyRequest()",
            "        inst.task_class = DummyTaskClass()",
            "        inst.requests = [request]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_one_error_request(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request = DummyRequest()",
            "        request.error = DummyError()",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.requests = [request]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_multiple_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request1 = DummyRequest()",
            "        request2 = DummyRequest()",
            "        inst.task_class = DummyTaskClass()",
            "        inst.requests = [request1, request2]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request1.serviced)",
            "        self.assertTrue(request2.serviced)",
            "        self.assertTrue(request1.closed)",
            "        self.assertTrue(request2.closed)",
            "",
            "    def test_service_with_request_raises(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_already_wrote_header(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertTrue(inst.close_when_flushed)",
            "        self.assertEqual(inst.error_task_class.serviced, False)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_didnt_write_header_expose_tbs(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = True",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_didnt_write_header(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertTrue(inst.close_when_flushed)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_request_raises_disconnect(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ClientDisconnected)",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.infos), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.error_task_class.serviced, False)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_request_error_raises_disconnect(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        err_request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.parser_class = lambda x: err_request",
            "        inst.task_class = DummyTaskClass(RuntimeError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass(ClientDisconnected)",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(err_request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertEqual(len(inst.logger.infos), 0)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.task_class.serviced, True)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_cancel_no_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = ()",
            "        inst.cancel()",
            "        self.assertEqual(inst.requests, [])",
            "",
            "    def test_cancel_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [None]",
            "        inst.cancel()",
            "        self.assertEqual(inst.requests, [])",
            "",
            "",
            "class DummySock(object):",
            "    blocking = False",
            "    closed = False",
            "",
            "    def __init__(self):",
            "        self.sent = b\"\"",
            "",
            "    def setblocking(self, *arg):",
            "        self.blocking = True",
            "",
            "    def fileno(self):",
            "        return 100",
            "",
            "    def getpeername(self):",
            "        return \"127.0.0.1\"",
            "",
            "    def getsockopt(self, level, option):",
            "        return 2048",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "    def send(self, data):",
            "        self.sent += data",
            "        return len(data)",
            "",
            "",
            "class DummyLock(object):",
            "    notified = False",
            "",
            "    def __init__(self, acquirable=True):",
            "        self.acquirable = acquirable",
            "",
            "    def acquire(self, val):",
            "        self.val = val",
            "        self.acquired = True",
            "        return self.acquirable",
            "",
            "    def release(self):",
            "        self.released = True",
            "",
            "    def notify(self):",
            "        self.notified = True",
            "",
            "    def wait(self):",
            "        self.waited = True",
            "",
            "    def __exit__(self, type, val, traceback):",
            "        self.acquire(True)",
            "",
            "    def __enter__(self):",
            "        pass",
            "",
            "",
            "class DummyBuffer(object):",
            "    closed = False",
            "",
            "    def __init__(self, data, toraise=None):",
            "        self.data = data",
            "        self.toraise = toraise",
            "",
            "    def get(self, *arg):",
            "        if self.toraise:",
            "            raise self.toraise",
            "        data = self.data",
            "        self.data = b\"\"",
            "        return data",
            "",
            "    def skip(self, num, x):",
            "        self.skipped = num",
            "",
            "    def __len__(self):",
            "        return len(self.data)",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "",
            "class DummyAdjustments(object):",
            "    outbuf_overflow = 1048576",
            "    outbuf_high_watermark = 1048576",
            "    inbuf_overflow = 512000",
            "    cleanup_interval = 900",
            "    url_scheme = \"http\"",
            "    channel_timeout = 300",
            "    log_socket_errors = True",
            "    recv_bytes = 8192",
            "    send_bytes = 1",
            "    expose_tracebacks = True",
            "    ident = \"waitress\"",
            "    max_request_header_size = 10000",
            "",
            "",
            "class DummyServer(object):",
            "    trigger_pulled = False",
            "    adj = DummyAdjustments()",
            "",
            "    def __init__(self):",
            "        self.tasks = []",
            "        self.active_channels = {}",
            "",
            "    def add_task(self, task):",
            "        self.tasks.append(task)",
            "",
            "    def pull_trigger(self):",
            "        self.trigger_pulled = True",
            "",
            "",
            "class DummyParser(object):",
            "    version = 1",
            "    data = None",
            "    completed = True",
            "    empty = False",
            "    headers_finished = False",
            "    expect_continue = False",
            "    retval = None",
            "    error = None",
            "    connection_close = False",
            "",
            "    def received(self, data):",
            "        self.data = data",
            "        if self.retval is not None:",
            "            return self.retval",
            "        return len(data)",
            "",
            "",
            "class DummyRequest(object):",
            "    error = None",
            "    path = \"/\"",
            "    version = \"1.0\"",
            "    closed = False",
            "",
            "    def __init__(self):",
            "        self.headers = {}",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "",
            "class DummyLogger(object):",
            "    def __init__(self):",
            "        self.exceptions = []",
            "        self.infos = []",
            "        self.warnings = []",
            "",
            "    def info(self, msg):",
            "        self.infos.append(msg)",
            "",
            "    def exception(self, msg):",
            "        self.exceptions.append(msg)",
            "",
            "",
            "class DummyError(object):",
            "    code = \"431\"",
            "    reason = \"Bleh\"",
            "    body = \"My body\"",
            "",
            "",
            "class DummyTaskClass(object):",
            "    wrote_header = True",
            "    close_on_finish = False",
            "    serviced = False",
            "",
            "    def __init__(self, toraise=None):",
            "        self.toraise = toraise",
            "",
            "    def __call__(self, channel, request):",
            "        self.request = request",
            "        return self",
            "",
            "    def service(self):",
            "        self.serviced = True",
            "        self.request.serviced = True",
            "        if self.toraise:",
            "            raise self.toraise"
        ],
        "afterPatchFile": [
            "import unittest",
            "import io",
            "",
            "",
            "class TestHTTPChannel(unittest.TestCase):",
            "    def _makeOne(self, sock, addr, adj, map=None):",
            "        from waitress.channel import HTTPChannel",
            "",
            "        server = DummyServer()",
            "        return HTTPChannel(server, sock, addr, adj=adj, map=map)",
            "",
            "    def _makeOneWithMap(self, adj=None):",
            "        if adj is None:",
            "            adj = DummyAdjustments()",
            "        sock = DummySock()",
            "        map = {}",
            "        inst = self._makeOne(sock, \"127.0.0.1\", adj, map=map)",
            "        inst.outbuf_lock = DummyLock()",
            "        return inst, sock, map",
            "",
            "    def test_ctor(self):",
            "        inst, _, map = self._makeOneWithMap()",
            "        self.assertEqual(inst.addr, \"127.0.0.1\")",
            "        self.assertEqual(inst.sendbuf_len, 2048)",
            "        self.assertEqual(map[100], inst)",
            "",
            "    def test_total_outbufs_len_an_outbuf_size_gt_sys_maxint(self):",
            "        from waitress.compat import MAXINT",
            "",
            "        inst, _, map = self._makeOneWithMap()",
            "",
            "        class DummyBuffer(object):",
            "            chunks = []",
            "",
            "            def append(self, data):",
            "                self.chunks.append(data)",
            "",
            "        class DummyData(object):",
            "            def __len__(self):",
            "                return MAXINT",
            "",
            "        inst.total_outbufs_len = 1",
            "        inst.outbufs = [DummyBuffer()]",
            "        inst.write_soon(DummyData())",
            "        # we are testing that this method does not raise an OverflowError",
            "        # (see https://github.com/Pylons/waitress/issues/47)",
            "        self.assertEqual(inst.total_outbufs_len, MAXINT + 1)",
            "",
            "    def test_writable_something_in_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.total_outbufs_len = 3",
            "        self.assertTrue(inst.writable())",
            "",
            "    def test_writable_nothing_in_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        self.assertFalse(inst.writable())",
            "",
            "    def test_writable_nothing_in_outbuf_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = True",
            "        self.assertTrue(inst.writable())",
            "",
            "    def test_handle_write_not_connected(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.connected = False",
            "        self.assertFalse(inst.handle_write())",
            "",
            "    def test_handle_write_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "",
            "    def test_handle_write_no_request_with_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertNotEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_outbuf_raises_socketerror(self):",
            "        import socket",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"abc\", socket.error)",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_outbuf_raises_othererror(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"abc\", IOError)",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_no_requests_no_outbuf_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        outbuf = DummyBuffer(b\"\")",
            "        inst.outbufs = [outbuf]",
            "        inst.will_close = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_handle_write_no_requests_outbuf_gt_send_bytes(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 2",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_close_when_flushed(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        outbuf = DummyBuffer(b\"abc\")",
            "        inst.outbufs = [outbuf]",
            "        inst.total_outbufs_len = len(outbuf)",
            "        inst.will_close = False",
            "        inst.close_when_flushed = True",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, True)",
            "        self.assertEqual(inst.close_when_flushed, False)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "        self.assertTrue(outbuf.closed)",
            "",
            "    def test_readable_no_requests_not_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.will_close = False",
            "        self.assertEqual(inst.readable(), True)",
            "",
            "    def test_readable_no_requests_will_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.will_close = True",
            "        self.assertEqual(inst.readable(), False)",
            "",
            "    def test_readable_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = True",
            "        self.assertEqual(inst.readable(), False)",
            "",
            "    def test_handle_read_no_error(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = False",
            "        inst.recv = lambda *arg: b\"abc\"",
            "        inst.last_activity = 0",
            "        L = []",
            "        inst.received = lambda x: L.append(x)",
            "        result = inst.handle_read()",
            "        self.assertEqual(result, None)",
            "        self.assertNotEqual(inst.last_activity, 0)",
            "        self.assertEqual(L, [b\"abc\"])",
            "",
            "    def test_handle_read_error(self):",
            "        import socket",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.will_close = False",
            "",
            "        def recv(b):",
            "            raise socket.error",
            "",
            "        inst.recv = recv",
            "        inst.last_activity = 0",
            "        inst.logger = DummyLogger()",
            "        result = inst.handle_read()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.last_activity, 0)",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test_write_soon_empty_byte(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        wrote = inst.write_soon(b\"\")",
            "        self.assertEqual(wrote, 0)",
            "        self.assertEqual(len(inst.outbufs[0]), 0)",
            "",
            "    def test_write_soon_nonempty_byte(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        wrote = inst.write_soon(b\"a\")",
            "        self.assertEqual(wrote, 1)",
            "        self.assertEqual(len(inst.outbufs[0]), 1)",
            "",
            "    def test_write_soon_filewrapper(self):",
            "        from waitress.buffers import ReadOnlyFileBasedBuffer",
            "",
            "        f = io.BytesIO(b\"abc\")",
            "        wrapper = ReadOnlyFileBasedBuffer(f, 8192)",
            "        wrapper.prepare()",
            "        inst, sock, map = self._makeOneWithMap()",
            "        outbufs = inst.outbufs",
            "        orig_outbuf = outbufs[0]",
            "        wrote = inst.write_soon(wrapper)",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(outbufs), 3)",
            "        self.assertEqual(outbufs[0], orig_outbuf)",
            "        self.assertEqual(outbufs[1], wrapper)",
            "        self.assertEqual(outbufs[2].__class__.__name__, \"OverflowableBuffer\")",
            "",
            "    def test_write_soon_disconnected(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.connected = False",
            "        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))",
            "",
            "    def test_write_soon_disconnected_while_over_watermark(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        def dummy_flush():",
            "            inst.connected = False",
            "",
            "        inst._flush_outbufs_below_high_watermark = dummy_flush",
            "        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))",
            "",
            "    def test_write_soon_rotates_outbuf_on_overflow(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.outbuf_high_watermark = 3",
            "        inst.current_outbuf_count = 4",
            "        wrote = inst.write_soon(b\"xyz\")",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(inst.outbufs), 2)",
            "        self.assertEqual(inst.outbufs[0].get(), b\"\")",
            "        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")",
            "",
            "    def test_write_soon_waits_on_backpressure(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.outbuf_high_watermark = 3",
            "        inst.total_outbufs_len = 4",
            "        inst.current_outbuf_count = 4",
            "",
            "        class Lock(DummyLock):",
            "            def wait(self):",
            "                inst.total_outbufs_len = 0",
            "                super(Lock, self).wait()",
            "",
            "        inst.outbuf_lock = Lock()",
            "        wrote = inst.write_soon(b\"xyz\")",
            "        self.assertEqual(wrote, 3)",
            "        self.assertEqual(len(inst.outbufs), 2)",
            "        self.assertEqual(inst.outbufs[0].get(), b\"\")",
            "        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")",
            "        self.assertTrue(inst.outbuf_lock.waited)",
            "",
            "    def test_handle_write_notify_after_flush(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 1",
            "        inst.adj.outbuf_high_watermark = 5",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertTrue(inst.outbuf_lock.notified)",
            "        self.assertEqual(sock.sent, b\"abc\")",
            "",
            "    def test_handle_write_no_notify_after_flush(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [True]",
            "        inst.outbufs = [DummyBuffer(b\"abc\")]",
            "        inst.total_outbufs_len = len(inst.outbufs[0])",
            "        inst.adj.send_bytes = 1",
            "        inst.adj.outbuf_high_watermark = 2",
            "        sock.send = lambda x: False",
            "        inst.will_close = False",
            "        inst.last_activity = 0",
            "        result = inst.handle_write()",
            "        self.assertEqual(result, None)",
            "        self.assertEqual(inst.will_close, False)",
            "        self.assertTrue(inst.outbuf_lock.acquired)",
            "        self.assertFalse(inst.outbuf_lock.notified)",
            "        self.assertEqual(sock.sent, b\"\")",
            "",
            "    def test__flush_some_empty_outbuf(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, False)",
            "",
            "    def test__flush_some_full_outbuf_socket_returns_nonzero(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.outbufs[0].append(b\"abc\")",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "",
            "    def test__flush_some_full_outbuf_socket_returns_zero(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: False",
            "        inst.outbufs[0].append(b\"abc\")",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, False)",
            "",
            "    def test_flush_some_multiple_buffers_first_empty(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: len(x)",
            "        buffer = DummyBuffer(b\"abc\")",
            "        inst.outbufs.append(buffer)",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "        self.assertEqual(buffer.skipped, 3)",
            "        self.assertEqual(inst.outbufs, [buffer])",
            "",
            "    def test_flush_some_multiple_buffers_close_raises(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        sock.send = lambda x: len(x)",
            "        buffer = DummyBuffer(b\"abc\")",
            "        inst.outbufs.append(buffer)",
            "        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)",
            "        inst.logger = DummyLogger()",
            "",
            "        def doraise():",
            "            raise NotImplementedError",
            "",
            "        inst.outbufs[0].close = doraise",
            "        result = inst._flush_some()",
            "        self.assertEqual(result, True)",
            "        self.assertEqual(buffer.skipped, 3)",
            "        self.assertEqual(inst.outbufs, [buffer])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test__flush_some_outbuf_len_gt_sys_maxint(self):",
            "        from waitress.compat import MAXINT",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        class DummyHugeOutbuffer(object):",
            "            def __init__(self):",
            "                self.length = MAXINT + 1",
            "",
            "            def __len__(self):",
            "                return self.length",
            "",
            "            def get(self, numbytes):",
            "                self.length = 0",
            "                return b\"123\"",
            "",
            "        buf = DummyHugeOutbuffer()",
            "        inst.outbufs = [buf]",
            "        inst.send = lambda *arg: 0",
            "        result = inst._flush_some()",
            "        # we are testing that _flush_some doesn't raise an OverflowError",
            "        # when one of its outbufs has a __len__ that returns gt sys.maxint",
            "        self.assertEqual(result, False)",
            "",
            "    def test_handle_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.handle_close()",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "",
            "    def test_handle_close_outbuf_raises_on_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "",
            "        def doraise():",
            "            raise NotImplementedError",
            "",
            "        inst.outbufs[0].close = doraise",
            "        inst.logger = DummyLogger()",
            "        inst.handle_close()",
            "        self.assertEqual(inst.connected, False)",
            "        self.assertEqual(sock.closed, True)",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "",
            "    def test_add_channel(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        fileno = inst._fileno",
            "        inst.add_channel(map)",
            "        self.assertEqual(map[fileno], inst)",
            "        self.assertEqual(inst.server.active_channels[fileno], inst)",
            "",
            "    def test_del_channel(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        fileno = inst._fileno",
            "        inst.server.active_channels[fileno] = True",
            "        inst.del_channel(map)",
            "        self.assertEqual(map.get(fileno), None)",
            "        self.assertEqual(inst.server.active_channels.get(fileno), None)",
            "",
            "    def test_received(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.server.tasks, [inst])",
            "        self.assertTrue(inst.requests)",
            "",
            "    def test_received_no_chunk(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        self.assertEqual(inst.received(b\"\"), False)",
            "",
            "    def test_received_preq_not_completed(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = False",
            "        preq.empty = True",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.requests, ())",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_preq_completed_empty(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.empty = True",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_preq_error(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.error = True",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(len(inst.server.tasks), 1)",
            "        self.assertTrue(inst.requests)",
            "",
            "    def test_received_preq_completed_connection_close(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.completed = True",
            "        preq.empty = True",
            "        preq.connection_close = True",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\" + b\"a\" * 50000)",
            "        self.assertEqual(inst.request, None)",
            "        self.assertEqual(inst.server.tasks, [])",
            "",
            "    def test_received_headers_finished_expect_continue_false(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = False",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        preq.retval = 1",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(inst.outbufs[0].get(100), b\"\")",
            "",
            "    def test_received_headers_finished_expect_continue_true(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = True",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(sock.sent, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.sent_continue, True)",
            "        self.assertEqual(preq.completed, False)",
            "",
            "    def test_received_headers_finished_expect_continue_true_sent_true(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.server = DummyServer()",
            "        preq = DummyParser()",
            "        inst.request = preq",
            "        preq.expect_continue = True",
            "        preq.headers_finished = True",
            "        preq.completed = False",
            "        preq.empty = False",
            "        inst.sent_continue = True",
            "        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")",
            "        self.assertEqual(inst.request, preq)",
            "        self.assertEqual(inst.server.tasks, [])",
            "        self.assertEqual(sock.sent, b\"\")",
            "        self.assertEqual(inst.sent_continue, True)",
            "        self.assertEqual(preq.completed, False)",
            "",
            "    def test_service_no_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = []",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "",
            "    def test_service_with_one_request(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request = DummyRequest()",
            "        inst.task_class = DummyTaskClass()",
            "        inst.requests = [request]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_one_error_request(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request = DummyRequest()",
            "        request.error = DummyError()",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.requests = [request]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_multiple_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        request1 = DummyRequest()",
            "        request2 = DummyRequest()",
            "        inst.task_class = DummyTaskClass()",
            "        inst.requests = [request1, request2]",
            "        inst.service()",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertTrue(request1.serviced)",
            "        self.assertTrue(request2.serviced)",
            "        self.assertTrue(request1.closed)",
            "        self.assertTrue(request2.closed)",
            "",
            "    def test_service_with_request_raises(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_already_wrote_header(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertTrue(inst.close_when_flushed)",
            "        self.assertEqual(inst.error_task_class.serviced, False)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_didnt_write_header_expose_tbs(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = True",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_requests_raises_didnt_write_header(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ValueError)",
            "        inst.task_class.wrote_header = False",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertTrue(inst.close_when_flushed)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_request_raises_disconnect(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.task_class = DummyTaskClass(ClientDisconnected)",
            "        inst.error_task_class = DummyTaskClass()",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.infos), 1)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.error_task_class.serviced, False)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_service_with_request_error_raises_disconnect(self):",
            "        from waitress.channel import ClientDisconnected",
            "",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.adj.expose_tracebacks = False",
            "        inst.server = DummyServer()",
            "        request = DummyRequest()",
            "        err_request = DummyRequest()",
            "        inst.requests = [request]",
            "        inst.parser_class = lambda x: err_request",
            "        inst.task_class = DummyTaskClass(RuntimeError)",
            "        inst.task_class.wrote_header = False",
            "        inst.error_task_class = DummyTaskClass(ClientDisconnected)",
            "        inst.logger = DummyLogger()",
            "        inst.service()",
            "        self.assertTrue(request.serviced)",
            "        self.assertTrue(err_request.serviced)",
            "        self.assertEqual(inst.requests, [])",
            "        self.assertEqual(len(inst.logger.exceptions), 1)",
            "        self.assertEqual(len(inst.logger.infos), 0)",
            "        self.assertTrue(inst.server.trigger_pulled)",
            "        self.assertTrue(inst.last_activity)",
            "        self.assertFalse(inst.will_close)",
            "        self.assertEqual(inst.task_class.serviced, True)",
            "        self.assertEqual(inst.error_task_class.serviced, True)",
            "        self.assertTrue(request.closed)",
            "",
            "    def test_cancel_no_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = ()",
            "        inst.cancel()",
            "        self.assertEqual(inst.requests, [])",
            "",
            "    def test_cancel_with_requests(self):",
            "        inst, sock, map = self._makeOneWithMap()",
            "        inst.requests = [None]",
            "        inst.cancel()",
            "        self.assertEqual(inst.requests, [])",
            "",
            "",
            "class DummySock(object):",
            "    blocking = False",
            "    closed = False",
            "",
            "    def __init__(self):",
            "        self.sent = b\"\"",
            "",
            "    def setblocking(self, *arg):",
            "        self.blocking = True",
            "",
            "    def fileno(self):",
            "        return 100",
            "",
            "    def getpeername(self):",
            "        return \"127.0.0.1\"",
            "",
            "    def getsockopt(self, level, option):",
            "        return 2048",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "    def send(self, data):",
            "        self.sent += data",
            "        return len(data)",
            "",
            "",
            "class DummyLock(object):",
            "    notified = False",
            "",
            "    def __init__(self, acquirable=True):",
            "        self.acquirable = acquirable",
            "",
            "    def acquire(self, val):",
            "        self.val = val",
            "        self.acquired = True",
            "        return self.acquirable",
            "",
            "    def release(self):",
            "        self.released = True",
            "",
            "    def notify(self):",
            "        self.notified = True",
            "",
            "    def wait(self):",
            "        self.waited = True",
            "",
            "    def __exit__(self, type, val, traceback):",
            "        self.acquire(True)",
            "",
            "    def __enter__(self):",
            "        pass",
            "",
            "",
            "class DummyBuffer(object):",
            "    closed = False",
            "",
            "    def __init__(self, data, toraise=None):",
            "        self.data = data",
            "        self.toraise = toraise",
            "",
            "    def get(self, *arg):",
            "        if self.toraise:",
            "            raise self.toraise",
            "        data = self.data",
            "        self.data = b\"\"",
            "        return data",
            "",
            "    def skip(self, num, x):",
            "        self.skipped = num",
            "",
            "    def __len__(self):",
            "        return len(self.data)",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "",
            "class DummyAdjustments(object):",
            "    outbuf_overflow = 1048576",
            "    outbuf_high_watermark = 1048576",
            "    inbuf_overflow = 512000",
            "    cleanup_interval = 900",
            "    url_scheme = \"http\"",
            "    channel_timeout = 300",
            "    log_socket_errors = True",
            "    recv_bytes = 8192",
            "    send_bytes = 1",
            "    expose_tracebacks = True",
            "    ident = \"waitress\"",
            "    max_request_header_size = 10000",
            "",
            "",
            "class DummyServer(object):",
            "    trigger_pulled = False",
            "    adj = DummyAdjustments()",
            "",
            "    def __init__(self):",
            "        self.tasks = []",
            "        self.active_channels = {}",
            "",
            "    def add_task(self, task):",
            "        self.tasks.append(task)",
            "",
            "    def pull_trigger(self):",
            "        self.trigger_pulled = True",
            "",
            "",
            "class DummyParser(object):",
            "    version = 1",
            "    data = None",
            "    completed = True",
            "    empty = False",
            "    headers_finished = False",
            "    expect_continue = False",
            "    retval = None",
            "    error = None",
            "    connection_close = False",
            "",
            "    def received(self, data):",
            "        self.data = data",
            "        if self.retval is not None:",
            "            return self.retval",
            "        return len(data)",
            "",
            "",
            "class DummyRequest(object):",
            "    error = None",
            "    path = \"/\"",
            "    version = \"1.0\"",
            "    closed = False",
            "",
            "    def __init__(self):",
            "        self.headers = {}",
            "",
            "    def close(self):",
            "        self.closed = True",
            "",
            "",
            "class DummyLogger(object):",
            "    def __init__(self):",
            "        self.exceptions = []",
            "        self.infos = []",
            "        self.warnings = []",
            "",
            "    def info(self, msg):",
            "        self.infos.append(msg)",
            "",
            "    def exception(self, msg):",
            "        self.exceptions.append(msg)",
            "",
            "",
            "class DummyError(object):",
            "    code = \"431\"",
            "    reason = \"Bleh\"",
            "    body = \"My body\"",
            "",
            "",
            "class DummyTaskClass(object):",
            "    wrote_header = True",
            "    close_on_finish = False",
            "    serviced = False",
            "",
            "    def __init__(self, toraise=None):",
            "        self.toraise = toraise",
            "",
            "    def __call__(self, channel, request):",
            "        self.request = request",
            "        return self",
            "",
            "    def service(self):",
            "        self.serviced = True",
            "        self.request.serviced = True",
            "        if self.toraise:",
            "            raise self.toraise"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "426": [
                "TestHTTPChannel",
                "test_received"
            ],
            "441": [
                "TestHTTPChannel",
                "test_received_preq_not_completed"
            ],
            "452": [
                "TestHTTPChannel",
                "test_received_preq_completed_empty"
            ],
            "463": [
                "TestHTTPChannel",
                "test_received_preq_error"
            ],
            "476": [
                "TestHTTPChannel",
                "test_received_preq_completed_connection_close"
            ],
            "480": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "481": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "482": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "483": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "484": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "485": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "486": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "487": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "488": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "489": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "490": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "491": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "492": [
                "TestHTTPChannel",
                "test_received_preq_completed_n_lt_data"
            ],
            "493": [
                "TestHTTPChannel"
            ],
            "504": [
                "TestHTTPChannel",
                "test_received_headers_finished_expect_continue_false"
            ],
            "518": [
                "TestHTTPChannel",
                "test_received_headers_finished_expect_continue_true"
            ],
            "535": [
                "TestHTTPChannel",
                "test_received_headers_finished_expect_continue_true_sent_true"
            ]
        },
        "addLocation": []
    }
}