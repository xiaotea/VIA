{
    "lib/ansible/module_utils/identity/keycloak/keycloak.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "         auth_keycloak_url=dict(type='str', aliases=['url'], required=True),"
            },
            "1": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         auth_client_id=dict(type='str', default='admin-cli'),"
            },
            "2": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         auth_realm=dict(type='str', required=True),"
            },
            "3": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        auth_client_secret=dict(type='str', default=None),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+        auth_client_secret=dict(type='str', default=None, no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "         auth_username=dict(type='str', aliases=['username'], required=True),"
            },
            "6": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),"
            },
            "7": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "         validate_certs=dict(type='bool', default=True)"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2017, Eike Frost <ei@kefro.st>",
            "#",
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlencode",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError",
            "",
            "URL_TOKEN = \"{url}/realms/{realm}/protocol/openid-connect/token\"",
            "URL_CLIENT = \"{url}/admin/realms/{realm}/clients/{id}\"",
            "URL_CLIENTS = \"{url}/admin/realms/{realm}/clients\"",
            "URL_CLIENT_ROLES = \"{url}/admin/realms/{realm}/clients/{id}/roles\"",
            "URL_REALM_ROLES = \"{url}/admin/realms/{realm}/roles\"",
            "",
            "URL_CLIENTTEMPLATE = \"{url}/admin/realms/{realm}/client-templates/{id}\"",
            "URL_CLIENTTEMPLATES = \"{url}/admin/realms/{realm}/client-templates\"",
            "URL_GROUPS = \"{url}/admin/realms/{realm}/groups\"",
            "URL_GROUP = \"{url}/admin/realms/{realm}/groups/{groupid}\"",
            "",
            "",
            "def keycloak_argument_spec():",
            "    \"\"\"",
            "    Returns argument_spec of options common to keycloak_*-modules",
            "",
            "    :return: argument_spec dict",
            "    \"\"\"",
            "    return dict(",
            "        auth_keycloak_url=dict(type='str', aliases=['url'], required=True),",
            "        auth_client_id=dict(type='str', default='admin-cli'),",
            "        auth_realm=dict(type='str', required=True),",
            "        auth_client_secret=dict(type='str', default=None),",
            "        auth_username=dict(type='str', aliases=['username'], required=True),",
            "        auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),",
            "        validate_certs=dict(type='bool', default=True)",
            "    )",
            "",
            "",
            "def camel(words):",
            "    return words.split('_')[0] + ''.join(x.capitalize() or '_' for x in words.split('_')[1:])",
            "",
            "",
            "class KeycloakError(Exception):",
            "    pass",
            "",
            "",
            "def get_token(base_url, validate_certs, auth_realm, client_id,",
            "              auth_username, auth_password, client_secret):",
            "    auth_url = URL_TOKEN.format(url=base_url, realm=auth_realm)",
            "    temp_payload = {",
            "        'grant_type': 'password',",
            "        'client_id': client_id,",
            "        'client_secret': client_secret,",
            "        'username': auth_username,",
            "        'password': auth_password,",
            "    }",
            "    # Remove empty items, for instance missing client_secret",
            "    payload = dict(",
            "        (k, v) for k, v in temp_payload.items() if v is not None)",
            "    try:",
            "        r = json.load(open_url(auth_url, method='POST',",
            "                               validate_certs=validate_certs,",
            "                               data=urlencode(payload)))",
            "    except ValueError as e:",
            "        raise KeycloakError(",
            "            'API returned invalid JSON when trying to obtain access token from %s: %s'",
            "            % (auth_url, str(e)))",
            "    except Exception as e:",
            "        raise KeycloakError('Could not obtain access token from %s: %s'",
            "                            % (auth_url, str(e)))",
            "",
            "    try:",
            "        return {",
            "            'Authorization': 'Bearer ' + r['access_token'],",
            "            'Content-Type': 'application/json'",
            "        }",
            "    except KeyError:",
            "        raise KeycloakError(",
            "            'Could not obtain access token from %s' % auth_url)",
            "",
            "",
            "class KeycloakAPI(object):",
            "    \"\"\" Keycloak API access; Keycloak uses OAuth 2.0 to protect its API, an access token for which",
            "        is obtained through OpenID connect",
            "    \"\"\"",
            "    def __init__(self, module, connection_header):",
            "        self.module = module",
            "        self.baseurl = self.module.params.get('auth_keycloak_url')",
            "        self.validate_certs = self.module.params.get('validate_certs')",
            "        self.restheaders = connection_header",
            "",
            "    def get_clients(self, realm='master', filter=None):",
            "        \"\"\" Obtains client representations for clients in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :param filter: if defined, only the client with clientId specified in the filter is returned",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        clientlist_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "        if filter is not None:",
            "            clientlist_url += '?clientId=%s' % filter",
            "",
            "        try:",
            "            return json.load(open_url(clientlist_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_by_clientid(self, client_id, realm='master'):",
            "        \"\"\" Get client representation by clientId",
            "        :param client_id: The clientId to be queried",
            "        :param realm: realm from which to obtain the client representation",
            "        :return: dict with a client representation or None if none matching exist",
            "        \"\"\"",
            "        r = self.get_clients(realm=realm, filter=client_id)",
            "        if len(r) > 0:",
            "            return r[0]",
            "        else:",
            "            return None",
            "",
            "    def get_client_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client representation by id",
            "",
            "        :param id: id (not clientId) of client to be queried",
            "        :param realm: client from this realm",
            "        :return: dict of client representation or None if none matching exist",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return json.load(open_url(client_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                          % (id, realm, str(e)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_id(self, client_id, realm='master'):",
            "        \"\"\" Obtain id of client by client_id",
            "",
            "        :param client_id: client_id of client to be queried",
            "        :param realm: client template from this realm",
            "        :return: id of client (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_by_clientid(client_id, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client(self, id, clientrep, realm=\"master\"):",
            "        \"\"\" Update an existing client",
            "        :param id: id (not clientId) of client to be updated in Keycloak",
            "        :param clientrep: corresponding (partial/full) client representation with updates",
            "        :param realm: realm the client is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client(self, clientrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clientrep: Client representation of client to be created. Must at least contain field clientId",
            "        :param realm: realm for client to be created",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(client_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client %s in realm %s: %s'",
            "                                      % (clientrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client from Keycloak",
            "",
            "        :param id: id (not clientId) of client to be deleted",
            "        :param realm: realm of client to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_templates(self, realm='master'):",
            "        \"\"\" Obtains client template representations for client templates in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_template_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client template representation by id",
            "",
            "        :param id: id (not name) of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, id=id, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client templates %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client template %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_template_by_name(self, name, realm='master'):",
            "        \"\"\" Obtain client template representation by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        result = self.get_client_templates(realm)",
            "        if isinstance(result, list):",
            "            result = [x for x in result if x['name'] == name]",
            "            if len(result) > 0:",
            "                return result[0]",
            "        return None",
            "",
            "    def get_client_template_id(self, name, realm='master'):",
            "        \"\"\" Obtain client template id by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: client template id (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_template_by_name(name, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client_template(self, id, clienttrep, realm=\"master\"):",
            "        \"\"\" Update an existing client template",
            "        :param id: id (not name) of client template to be updated in Keycloak",
            "        :param clienttrep: corresponding (partial/full) client template representation with updates",
            "        :param realm: realm the client template is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client_template(self, clienttrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clienttrep: Client template representation of client template to be created. Must at least contain field name",
            "        :param realm: realm for client template to be created in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client template %s in realm %s: %s'",
            "                                      % (clienttrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client_template(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client template from Keycloak",
            "",
            "        :param id: id (not name) of client to be deleted",
            "        :param realm: realm of client template to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_groups(self, realm=\"master\"):",
            "        \"\"\" Fetch the name and ID of all groups on the Keycloak server.",
            "",
            "        To fetch the full data of the group, make a subsequent call to",
            "        get_group_by_groupid, passing in the ID of the group you wish to return.",
            "",
            "        :param realm: Return the groups of this realm (default \"master\").",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch list of groups in realm %s: %s\"",
            "                                      % (realm, str(e)))",
            "",
            "    def get_group_by_groupid(self, gid, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group from the provided realm using the group's unique ID.",
            "",
            "        If the group does not exist, None is returned.",
            "",
            "        gid is a UUID provided by the Keycloak API",
            "        :param gid: UUID of the group to be returned",
            "        :param realm: Realm in which the group resides; default 'master'.",
            "        \"\"\"",
            "        groups_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=gid)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                          % (gid, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (gid, realm, str(e)))",
            "",
            "    def get_group_by_name(self, name, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group within a realm based on its name.",
            "",
            "        The Keycloak API does not allow filtering of the Groups resource by name.",
            "        As a result, this method first retrieves the entire list of groups - name and ID -",
            "        then performs a second query to fetch the group.",
            "",
            "        If the group does not exist, None is returned.",
            "        :param name: Name of the group to fetch.",
            "        :param realm: Realm in which the group resides; default 'master'",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            all_groups = self.get_groups(realm=realm)",
            "",
            "            for group in all_groups:",
            "                if group['name'] == name:",
            "                    return self.get_group_by_groupid(group['id'], realm=realm)",
            "",
            "            return None",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (name, realm, str(e)))",
            "",
            "    def create_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Create a Keycloak group.",
            "",
            "        :param grouprep: a GroupRepresentation of the group to be created. Must contain at minimum the field name.",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return open_url(groups_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not create group %s in realm %s: %s\"",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def update_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Update an existing group.",
            "",
            "        :param grouprep: A GroupRepresentation of the updated group.",
            "        :return HTTPResponse object on success",
            "        \"\"\"",
            "        group_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=grouprep['id'])",
            "",
            "        try:",
            "            return open_url(group_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update group %s in realm %s: %s'",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def delete_group(self, name=None, groupid=None, realm=\"master\"):",
            "        \"\"\" Delete a group. One of name or groupid must be provided.",
            "",
            "        Providing the group ID is preferred as it avoids a second lookup to",
            "        convert a group name to an ID.",
            "",
            "        :param name: The name of the group. A lookup will be performed to retrieve the group ID.",
            "        :param groupid: The ID of the group (preferred to name).",
            "        :param realm: The realm in which this group resides, default \"master\".",
            "        \"\"\"",
            "",
            "        if groupid is None and name is None:",
            "            # prefer an exception since this is almost certainly a programming error in the module itself.",
            "            raise Exception(\"Unable to delete group - one of group ID or name must be provided.\")",
            "",
            "        # only lookup the name if groupid isn't provided.",
            "        # in the case that both are provided, prefer the ID, since it's one",
            "        # less lookup.",
            "        if groupid is None and name is not None:",
            "            for group in self.get_groups(realm=realm):",
            "                if group['name'] == name:",
            "                    groupid = group['id']",
            "                    break",
            "",
            "        # if the group doesn't exist - no problem, nothing to delete.",
            "        if groupid is None:",
            "            return None",
            "",
            "        # should have a good groupid by here.",
            "        group_url = URL_GROUP.format(realm=realm, groupid=groupid, url=self.baseurl)",
            "        try:",
            "            return open_url(group_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Unable to delete group %s: %s\" % (groupid, str(e)))"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2017, Eike Frost <ei@kefro.st>",
            "#",
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlencode",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError",
            "",
            "URL_TOKEN = \"{url}/realms/{realm}/protocol/openid-connect/token\"",
            "URL_CLIENT = \"{url}/admin/realms/{realm}/clients/{id}\"",
            "URL_CLIENTS = \"{url}/admin/realms/{realm}/clients\"",
            "URL_CLIENT_ROLES = \"{url}/admin/realms/{realm}/clients/{id}/roles\"",
            "URL_REALM_ROLES = \"{url}/admin/realms/{realm}/roles\"",
            "",
            "URL_CLIENTTEMPLATE = \"{url}/admin/realms/{realm}/client-templates/{id}\"",
            "URL_CLIENTTEMPLATES = \"{url}/admin/realms/{realm}/client-templates\"",
            "URL_GROUPS = \"{url}/admin/realms/{realm}/groups\"",
            "URL_GROUP = \"{url}/admin/realms/{realm}/groups/{groupid}\"",
            "",
            "",
            "def keycloak_argument_spec():",
            "    \"\"\"",
            "    Returns argument_spec of options common to keycloak_*-modules",
            "",
            "    :return: argument_spec dict",
            "    \"\"\"",
            "    return dict(",
            "        auth_keycloak_url=dict(type='str', aliases=['url'], required=True),",
            "        auth_client_id=dict(type='str', default='admin-cli'),",
            "        auth_realm=dict(type='str', required=True),",
            "        auth_client_secret=dict(type='str', default=None, no_log=True),",
            "        auth_username=dict(type='str', aliases=['username'], required=True),",
            "        auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),",
            "        validate_certs=dict(type='bool', default=True)",
            "    )",
            "",
            "",
            "def camel(words):",
            "    return words.split('_')[0] + ''.join(x.capitalize() or '_' for x in words.split('_')[1:])",
            "",
            "",
            "class KeycloakError(Exception):",
            "    pass",
            "",
            "",
            "def get_token(base_url, validate_certs, auth_realm, client_id,",
            "              auth_username, auth_password, client_secret):",
            "    auth_url = URL_TOKEN.format(url=base_url, realm=auth_realm)",
            "    temp_payload = {",
            "        'grant_type': 'password',",
            "        'client_id': client_id,",
            "        'client_secret': client_secret,",
            "        'username': auth_username,",
            "        'password': auth_password,",
            "    }",
            "    # Remove empty items, for instance missing client_secret",
            "    payload = dict(",
            "        (k, v) for k, v in temp_payload.items() if v is not None)",
            "    try:",
            "        r = json.load(open_url(auth_url, method='POST',",
            "                               validate_certs=validate_certs,",
            "                               data=urlencode(payload)))",
            "    except ValueError as e:",
            "        raise KeycloakError(",
            "            'API returned invalid JSON when trying to obtain access token from %s: %s'",
            "            % (auth_url, str(e)))",
            "    except Exception as e:",
            "        raise KeycloakError('Could not obtain access token from %s: %s'",
            "                            % (auth_url, str(e)))",
            "",
            "    try:",
            "        return {",
            "            'Authorization': 'Bearer ' + r['access_token'],",
            "            'Content-Type': 'application/json'",
            "        }",
            "    except KeyError:",
            "        raise KeycloakError(",
            "            'Could not obtain access token from %s' % auth_url)",
            "",
            "",
            "class KeycloakAPI(object):",
            "    \"\"\" Keycloak API access; Keycloak uses OAuth 2.0 to protect its API, an access token for which",
            "        is obtained through OpenID connect",
            "    \"\"\"",
            "    def __init__(self, module, connection_header):",
            "        self.module = module",
            "        self.baseurl = self.module.params.get('auth_keycloak_url')",
            "        self.validate_certs = self.module.params.get('validate_certs')",
            "        self.restheaders = connection_header",
            "",
            "    def get_clients(self, realm='master', filter=None):",
            "        \"\"\" Obtains client representations for clients in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :param filter: if defined, only the client with clientId specified in the filter is returned",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        clientlist_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "        if filter is not None:",
            "            clientlist_url += '?clientId=%s' % filter",
            "",
            "        try:",
            "            return json.load(open_url(clientlist_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_by_clientid(self, client_id, realm='master'):",
            "        \"\"\" Get client representation by clientId",
            "        :param client_id: The clientId to be queried",
            "        :param realm: realm from which to obtain the client representation",
            "        :return: dict with a client representation or None if none matching exist",
            "        \"\"\"",
            "        r = self.get_clients(realm=realm, filter=client_id)",
            "        if len(r) > 0:",
            "            return r[0]",
            "        else:",
            "            return None",
            "",
            "    def get_client_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client representation by id",
            "",
            "        :param id: id (not clientId) of client to be queried",
            "        :param realm: client from this realm",
            "        :return: dict of client representation or None if none matching exist",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return json.load(open_url(client_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                          % (id, realm, str(e)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_id(self, client_id, realm='master'):",
            "        \"\"\" Obtain id of client by client_id",
            "",
            "        :param client_id: client_id of client to be queried",
            "        :param realm: client template from this realm",
            "        :return: id of client (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_by_clientid(client_id, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client(self, id, clientrep, realm=\"master\"):",
            "        \"\"\" Update an existing client",
            "        :param id: id (not clientId) of client to be updated in Keycloak",
            "        :param clientrep: corresponding (partial/full) client representation with updates",
            "        :param realm: realm the client is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client(self, clientrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clientrep: Client representation of client to be created. Must at least contain field clientId",
            "        :param realm: realm for client to be created",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(client_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client %s in realm %s: %s'",
            "                                      % (clientrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client from Keycloak",
            "",
            "        :param id: id (not clientId) of client to be deleted",
            "        :param realm: realm of client to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_templates(self, realm='master'):",
            "        \"\"\" Obtains client template representations for client templates in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_template_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client template representation by id",
            "",
            "        :param id: id (not name) of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, id=id, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client templates %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client template %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_template_by_name(self, name, realm='master'):",
            "        \"\"\" Obtain client template representation by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        result = self.get_client_templates(realm)",
            "        if isinstance(result, list):",
            "            result = [x for x in result if x['name'] == name]",
            "            if len(result) > 0:",
            "                return result[0]",
            "        return None",
            "",
            "    def get_client_template_id(self, name, realm='master'):",
            "        \"\"\" Obtain client template id by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: client template id (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_template_by_name(name, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client_template(self, id, clienttrep, realm=\"master\"):",
            "        \"\"\" Update an existing client template",
            "        :param id: id (not name) of client template to be updated in Keycloak",
            "        :param clienttrep: corresponding (partial/full) client template representation with updates",
            "        :param realm: realm the client template is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client_template(self, clienttrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clienttrep: Client template representation of client template to be created. Must at least contain field name",
            "        :param realm: realm for client template to be created in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client template %s in realm %s: %s'",
            "                                      % (clienttrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client_template(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client template from Keycloak",
            "",
            "        :param id: id (not name) of client to be deleted",
            "        :param realm: realm of client template to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_groups(self, realm=\"master\"):",
            "        \"\"\" Fetch the name and ID of all groups on the Keycloak server.",
            "",
            "        To fetch the full data of the group, make a subsequent call to",
            "        get_group_by_groupid, passing in the ID of the group you wish to return.",
            "",
            "        :param realm: Return the groups of this realm (default \"master\").",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch list of groups in realm %s: %s\"",
            "                                      % (realm, str(e)))",
            "",
            "    def get_group_by_groupid(self, gid, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group from the provided realm using the group's unique ID.",
            "",
            "        If the group does not exist, None is returned.",
            "",
            "        gid is a UUID provided by the Keycloak API",
            "        :param gid: UUID of the group to be returned",
            "        :param realm: Realm in which the group resides; default 'master'.",
            "        \"\"\"",
            "        groups_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=gid)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                          % (gid, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (gid, realm, str(e)))",
            "",
            "    def get_group_by_name(self, name, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group within a realm based on its name.",
            "",
            "        The Keycloak API does not allow filtering of the Groups resource by name.",
            "        As a result, this method first retrieves the entire list of groups - name and ID -",
            "        then performs a second query to fetch the group.",
            "",
            "        If the group does not exist, None is returned.",
            "        :param name: Name of the group to fetch.",
            "        :param realm: Realm in which the group resides; default 'master'",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            all_groups = self.get_groups(realm=realm)",
            "",
            "            for group in all_groups:",
            "                if group['name'] == name:",
            "                    return self.get_group_by_groupid(group['id'], realm=realm)",
            "",
            "            return None",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (name, realm, str(e)))",
            "",
            "    def create_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Create a Keycloak group.",
            "",
            "        :param grouprep: a GroupRepresentation of the group to be created. Must contain at minimum the field name.",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return open_url(groups_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not create group %s in realm %s: %s\"",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def update_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Update an existing group.",
            "",
            "        :param grouprep: A GroupRepresentation of the updated group.",
            "        :return HTTPResponse object on success",
            "        \"\"\"",
            "        group_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=grouprep['id'])",
            "",
            "        try:",
            "            return open_url(group_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update group %s in realm %s: %s'",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def delete_group(self, name=None, groupid=None, realm=\"master\"):",
            "        \"\"\" Delete a group. One of name or groupid must be provided.",
            "",
            "        Providing the group ID is preferred as it avoids a second lookup to",
            "        convert a group name to an ID.",
            "",
            "        :param name: The name of the group. A lookup will be performed to retrieve the group ID.",
            "        :param groupid: The ID of the group (preferred to name).",
            "        :param realm: The realm in which this group resides, default \"master\".",
            "        \"\"\"",
            "",
            "        if groupid is None and name is None:",
            "            # prefer an exception since this is almost certainly a programming error in the module itself.",
            "            raise Exception(\"Unable to delete group - one of group ID or name must be provided.\")",
            "",
            "        # only lookup the name if groupid isn't provided.",
            "        # in the case that both are provided, prefer the ID, since it's one",
            "        # less lookup.",
            "        if groupid is None and name is not None:",
            "            for group in self.get_groups(realm=realm):",
            "                if group['name'] == name:",
            "                    groupid = group['id']",
            "                    break",
            "",
            "        # if the group doesn't exist - no problem, nothing to delete.",
            "        if groupid is None:",
            "            return None",
            "",
            "        # should have a good groupid by here.",
            "        group_url = URL_GROUP.format(realm=realm, groupid=groupid, url=self.baseurl)",
            "        try:",
            "            return open_url(group_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Unable to delete group %s: %s\" % (groupid, str(e)))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "60": [
                "keycloak_argument_spec"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/module_utils/netapp.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "     return dict("
            },
            "1": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         api_url=dict(required=True, type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         validate_certs=dict(required=False, type='bool', default=True),"
            },
            "3": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        api_key=dict(required=True, type='str'),"
            },
            "4": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        secret_key=dict(required=True, type='str')"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+        api_key=dict(required=True, type='str', no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+        secret_key=dict(required=True, type='str', no_log=True)"
            },
            "7": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "     )"
            },
            "8": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 145,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 146,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Copyright (c) 2017, Sumit Kumar <sumit4@netapp.com>",
            "# Copyright (c) 2017, Michael Price <michael.price@netapp.com>",
            "# All rights reserved.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "import json",
            "import os",
            "import random",
            "import mimetypes",
            "",
            "from pprint import pformat",
            "from ansible.module_utils import six",
            "from ansible.module_utils.basic import AnsibleModule, missing_required_lib",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError, URLError",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.api import basic_auth_argument_spec",
            "from ansible.module_utils._text import to_native",
            "",
            "try:",
            "    from ansible.module_utils.ansible_release import __version__ as ansible_version",
            "except ImportError:",
            "    ansible_version = 'unknown'",
            "",
            "try:",
            "    from netapp_lib.api.zapi import zapi",
            "    HAS_NETAPP_LIB = True",
            "except ImportError:",
            "    HAS_NETAPP_LIB = False",
            "",
            "try:",
            "    import requests",
            "    HAS_REQUESTS = True",
            "except ImportError:",
            "    HAS_REQUESTS = False",
            "",
            "import ssl",
            "try:",
            "    from urlparse import urlparse, urlunparse",
            "except ImportError:",
            "    from urllib.parse import urlparse, urlunparse",
            "",
            "",
            "HAS_SF_SDK = False",
            "SF_BYTE_MAP = dict(",
            "    # Management GUI displays 1024 ** 3 as 1.1 GB, thus use 1000.",
            "    bytes=1,",
            "    b=1,",
            "    kb=1000,",
            "    mb=1000 ** 2,",
            "    gb=1000 ** 3,",
            "    tb=1000 ** 4,",
            "    pb=1000 ** 5,",
            "    eb=1000 ** 6,",
            "    zb=1000 ** 7,",
            "    yb=1000 ** 8",
            ")",
            "",
            "POW2_BYTE_MAP = dict(",
            "    # Here, 1 kb = 1024",
            "    bytes=1,",
            "    b=1,",
            "    kb=1024,",
            "    mb=1024 ** 2,",
            "    gb=1024 ** 3,",
            "    tb=1024 ** 4,",
            "    pb=1024 ** 5,",
            "    eb=1024 ** 6,",
            "    zb=1024 ** 7,",
            "    yb=1024 ** 8",
            ")",
            "",
            "try:",
            "    from solidfire.factory import ElementFactory",
            "    from solidfire.custom.models import TimeIntervalFrequency",
            "    from solidfire.models import Schedule, ScheduleInfo",
            "",
            "    HAS_SF_SDK = True",
            "except Exception:",
            "    HAS_SF_SDK = False",
            "",
            "",
            "def has_netapp_lib():",
            "    return HAS_NETAPP_LIB",
            "",
            "",
            "def has_sf_sdk():",
            "    return HAS_SF_SDK",
            "",
            "",
            "def na_ontap_host_argument_spec():",
            "",
            "    return dict(",
            "        hostname=dict(required=True, type='str'),",
            "        username=dict(required=True, type='str', aliases=['user']),",
            "        password=dict(required=True, type='str', aliases=['pass'], no_log=True),",
            "        https=dict(required=False, type='bool', default=False),",
            "        validate_certs=dict(required=False, type='bool', default=True),",
            "        http_port=dict(required=False, type='int'),",
            "        ontapi=dict(required=False, type='int'),",
            "        use_rest=dict(required=False, type='str', default='Auto', choices=['Never', 'Always', 'Auto'])",
            "    )",
            "",
            "",
            "def ontap_sf_host_argument_spec():",
            "",
            "    return dict(",
            "        hostname=dict(required=True, type='str'),",
            "        username=dict(required=True, type='str', aliases=['user']),",
            "        password=dict(required=True, type='str', aliases=['pass'], no_log=True)",
            "    )",
            "",
            "",
            "def aws_cvs_host_argument_spec():",
            "",
            "    return dict(",
            "        api_url=dict(required=True, type='str'),",
            "        validate_certs=dict(required=False, type='bool', default=True),",
            "        api_key=dict(required=True, type='str'),",
            "        secret_key=dict(required=True, type='str')",
            "    )",
            "",
            "",
            "def create_sf_connection(module, port=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "",
            "    if HAS_SF_SDK and hostname and username and password:",
            "        try:",
            "            return_val = ElementFactory.create(hostname, username, password, port=port)",
            "            return return_val",
            "        except Exception:",
            "            raise Exception(\"Unable to create SF connection\")",
            "    else:",
            "        module.fail_json(msg=\"the python SolidFire SDK module is required\")",
            "",
            "",
            "def setup_na_ontap_zapi(module, vserver=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "    https = module.params['https']",
            "    validate_certs = module.params['validate_certs']",
            "    port = module.params['http_port']",
            "    version = module.params['ontapi']",
            "",
            "    if HAS_NETAPP_LIB:",
            "        # set up zapi",
            "        server = zapi.NaServer(hostname)",
            "        server.set_username(username)",
            "        server.set_password(password)",
            "        if vserver:",
            "            server.set_vserver(vserver)",
            "        if version:",
            "            minor = version",
            "        else:",
            "            minor = 110",
            "        server.set_api_version(major=1, minor=minor)",
            "        # default is HTTP",
            "        if https:",
            "            if port is None:",
            "                port = 443",
            "            transport_type = 'HTTPS'",
            "            # HACK to bypass certificate verification",
            "            if validate_certs is False:",
            "                if not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):",
            "                    ssl._create_default_https_context = ssl._create_unverified_context",
            "        else:",
            "            if port is None:",
            "                port = 80",
            "            transport_type = 'HTTP'",
            "        server.set_transport_type(transport_type)",
            "        server.set_port(port)",
            "        server.set_server_type('FILER')",
            "        return server",
            "    else:",
            "        module.fail_json(msg=\"the python NetApp-Lib module is required\")",
            "",
            "",
            "def setup_ontap_zapi(module, vserver=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "",
            "    if HAS_NETAPP_LIB:",
            "        # set up zapi",
            "        server = zapi.NaServer(hostname)",
            "        server.set_username(username)",
            "        server.set_password(password)",
            "        if vserver:",
            "            server.set_vserver(vserver)",
            "        # Todo : Replace hard-coded values with configurable parameters.",
            "        server.set_api_version(major=1, minor=110)",
            "        server.set_port(80)",
            "        server.set_server_type('FILER')",
            "        server.set_transport_type('HTTP')",
            "        return server",
            "    else:",
            "        module.fail_json(msg=\"the python NetApp-Lib module is required\")",
            "",
            "",
            "def eseries_host_argument_spec():",
            "    \"\"\"Retrieve a base argument specification common to all NetApp E-Series modules\"\"\"",
            "    argument_spec = basic_auth_argument_spec()",
            "    argument_spec.update(dict(",
            "        api_username=dict(type='str', required=True),",
            "        api_password=dict(type='str', required=True, no_log=True),",
            "        api_url=dict(type='str', required=True),",
            "        ssid=dict(type='str', required=False, default='1'),",
            "        validate_certs=dict(type='bool', required=False, default=True)",
            "    ))",
            "    return argument_spec",
            "",
            "",
            "class NetAppESeriesModule(object):",
            "    \"\"\"Base class for all NetApp E-Series modules.",
            "",
            "    Provides a set of common methods for NetApp E-Series modules, including version checking, mode (proxy, embedded)",
            "    verification, http requests, secure http redirection for embedded web services, and logging setup.",
            "",
            "    Be sure to add the following lines in the module's documentation section:",
            "    extends_documentation_fragment:",
            "        - netapp.eseries",
            "",
            "    :param dict(dict) ansible_options: dictionary of ansible option definitions",
            "    :param str web_services_version: minimally required web services rest api version (default value: \"02.00.0000.0000\")",
            "    :param bool supports_check_mode: whether the module will support the check_mode capabilities (default=False)",
            "    :param list(list) mutually_exclusive: list containing list(s) of mutually exclusive options (optional)",
            "    :param list(list) required_if: list containing list(s) containing the option, the option value, and then",
            "    a list of required options. (optional)",
            "    :param list(list) required_one_of: list containing list(s) of options for which at least one is required. (optional)",
            "    :param list(list) required_together: list containing list(s) of options that are required together. (optional)",
            "    :param bool log_requests: controls whether to log each request (default: True)",
            "    \"\"\"",
            "    DEFAULT_TIMEOUT = 60",
            "    DEFAULT_SECURE_PORT = \"8443\"",
            "    DEFAULT_REST_API_PATH = \"devmgr/v2/\"",
            "    DEFAULT_REST_API_ABOUT_PATH = \"devmgr/utils/about\"",
            "    DEFAULT_HEADERS = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\",",
            "                       \"netapp-client-type\": \"Ansible-%s\" % ansible_version}",
            "    HTTP_AGENT = \"Ansible / %s\" % ansible_version",
            "    SIZE_UNIT_MAP = dict(bytes=1, b=1, kb=1024, mb=1024**2, gb=1024**3, tb=1024**4,",
            "                         pb=1024**5, eb=1024**6, zb=1024**7, yb=1024**8)",
            "",
            "    def __init__(self, ansible_options, web_services_version=None, supports_check_mode=False,",
            "                 mutually_exclusive=None, required_if=None, required_one_of=None, required_together=None,",
            "                 log_requests=True):",
            "        argument_spec = eseries_host_argument_spec()",
            "        argument_spec.update(ansible_options)",
            "",
            "        self.module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=supports_check_mode,",
            "                                    mutually_exclusive=mutually_exclusive, required_if=required_if,",
            "                                    required_one_of=required_one_of, required_together=required_together)",
            "",
            "        args = self.module.params",
            "        self.web_services_version = web_services_version if web_services_version else \"02.00.0000.0000\"",
            "        self.ssid = args[\"ssid\"]",
            "        self.url = args[\"api_url\"]",
            "        self.log_requests = log_requests",
            "        self.creds = dict(url_username=args[\"api_username\"],",
            "                          url_password=args[\"api_password\"],",
            "                          validate_certs=args[\"validate_certs\"])",
            "",
            "        if not self.url.endswith(\"/\"):",
            "            self.url += \"/\"",
            "",
            "        self.is_embedded_mode = None",
            "        self.is_web_services_valid_cache = None",
            "",
            "    def _check_web_services_version(self):",
            "        \"\"\"Verify proxy or embedded web services meets minimum version required for module.",
            "",
            "        The minimum required web services version is evaluated against version supplied through the web services rest",
            "        api. AnsibleFailJson exception will be raised when the minimum is not met or exceeded.",
            "",
            "        This helper function will update the supplied api url if secure http is not used for embedded web services",
            "",
            "        :raise AnsibleFailJson: raised when the contacted api service does not meet the minimum required version.",
            "        \"\"\"",
            "        if not self.is_web_services_valid_cache:",
            "",
            "            url_parts = urlparse(self.url)",
            "            if not url_parts.scheme or not url_parts.netloc:",
            "                self.module.fail_json(msg=\"Failed to provide valid API URL. Example: https://192.168.1.100:8443/devmgr/v2. URL [%s].\" % self.url)",
            "",
            "            if url_parts.scheme not in [\"http\", \"https\"]:",
            "                self.module.fail_json(msg=\"Protocol must be http or https. URL [%s].\" % self.url)",
            "",
            "            self.url = \"%s://%s/\" % (url_parts.scheme, url_parts.netloc)",
            "            about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "            rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, ignore_errors=True, **self.creds)",
            "",
            "            if rc != 200:",
            "                self.module.warn(\"Failed to retrieve web services about information! Retrying with secure ports. Array Id [%s].\" % self.ssid)",
            "                self.url = \"https://%s:8443/\" % url_parts.netloc.split(\":\")[0]",
            "                about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "                try:",
            "                    rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, **self.creds)",
            "                except Exception as error:",
            "                    self.module.fail_json(msg=\"Failed to retrieve the webservices about information! Array Id [%s]. Error [%s].\"",
            "                                              % (self.ssid, to_native(error)))",
            "",
            "            major, minor, other, revision = data[\"version\"].split(\".\")",
            "            minimum_major, minimum_minor, other, minimum_revision = self.web_services_version.split(\".\")",
            "",
            "            if not (major > minimum_major or",
            "                    (major == minimum_major and minor > minimum_minor) or",
            "                    (major == minimum_major and minor == minimum_minor and revision >= minimum_revision)):",
            "                self.module.fail_json(msg=\"Web services version does not meet minimum version required. Current version: [%s].\"",
            "                                          \" Version required: [%s].\" % (data[\"version\"], self.web_services_version))",
            "",
            "            self.module.log(\"Web services rest api version met the minimum required version.\")",
            "            self.is_web_services_valid_cache = True",
            "",
            "    def is_embedded(self):",
            "        \"\"\"Determine whether web services server is the embedded web services.",
            "",
            "        If web services about endpoint fails based on an URLError then the request will be attempted again using",
            "        secure http.",
            "",
            "        :raise AnsibleFailJson: raised when web services about endpoint failed to be contacted.",
            "        :return bool: whether contacted web services is running from storage array (embedded) or from a proxy.",
            "        \"\"\"",
            "        self._check_web_services_version()",
            "",
            "        if self.is_embedded_mode is None:",
            "            about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "            try:",
            "                rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, **self.creds)",
            "                self.is_embedded_mode = not data[\"runningAsProxy\"]",
            "            except Exception as error:",
            "                self.module.fail_json(msg=\"Failed to retrieve the webservices about information! Array Id [%s]. Error [%s].\"",
            "                                          % (self.ssid, to_native(error)))",
            "",
            "        return self.is_embedded_mode",
            "",
            "    def request(self, path, data=None, method='GET', headers=None, ignore_errors=False):",
            "        \"\"\"Issue an HTTP request to a url, retrieving an optional JSON response.",
            "",
            "        :param str path: web services rest api endpoint path (Example: storage-systems/1/graph). Note that when the",
            "        full url path is specified then that will be used without supplying the protocol, hostname, port and rest path.",
            "        :param data: data required for the request (data may be json or any python structured data)",
            "        :param str method: request method such as GET, POST, DELETE.",
            "        :param dict headers: dictionary containing request headers.",
            "        :param bool ignore_errors: forces the request to ignore any raised exceptions.",
            "        \"\"\"",
            "        self._check_web_services_version()",
            "",
            "        if headers is None:",
            "            headers = self.DEFAULT_HEADERS",
            "",
            "        if not isinstance(data, str) and headers[\"Content-Type\"] == \"application/json\":",
            "            data = json.dumps(data)",
            "",
            "        if path.startswith(\"/\"):",
            "            path = path[1:]",
            "        request_url = self.url + self.DEFAULT_REST_API_PATH + path",
            "",
            "        if self.log_requests or True:",
            "            self.module.log(pformat(dict(url=request_url, data=data, method=method)))",
            "",
            "        return request(url=request_url, data=data, method=method, headers=headers, use_proxy=True, force=False, last_mod_time=None,",
            "                       timeout=self.DEFAULT_TIMEOUT, http_agent=self.HTTP_AGENT, force_basic_auth=True, ignore_errors=ignore_errors, **self.creds)",
            "",
            "",
            "def create_multipart_formdata(files, fields=None, send_8kb=False):",
            "    \"\"\"Create the data for a multipart/form request.",
            "",
            "    :param list(list) files: list of lists each containing (name, filename, path).",
            "    :param list(list) fields: list of lists each containing (key, value).",
            "    :param bool send_8kb: only sends the first 8kb of the files (default: False).",
            "    \"\"\"",
            "    boundary = \"---------------------------\" + \"\".join([str(random.randint(0, 9)) for x in range(27)])",
            "    data_parts = list()",
            "    data = None",
            "",
            "    if six.PY2:  # Generate payload for Python 2",
            "        newline = \"\\r\\n\"",
            "        if fields is not None:",
            "            for key, value in fields:",
            "                data_parts.extend([\"--%s\" % boundary,",
            "                                   'Content-Disposition: form-data; name=\"%s\"' % key,",
            "                                   \"\",",
            "                                   value])",
            "",
            "        for name, filename, path in files:",
            "            with open(path, \"rb\") as fh:",
            "                value = fh.read(8192) if send_8kb else fh.read()",
            "",
            "                data_parts.extend([\"--%s\" % boundary,",
            "                                   'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (name, filename),",
            "                                   \"Content-Type: %s\" % (mimetypes.guess_type(path)[0] or \"application/octet-stream\"),",
            "                                   \"\",",
            "                                   value])",
            "        data_parts.extend([\"--%s--\" % boundary, \"\"])",
            "        data = newline.join(data_parts)",
            "",
            "    else:",
            "        newline = six.b(\"\\r\\n\")",
            "        if fields is not None:",
            "            for key, value in fields:",
            "                data_parts.extend([six.b(\"--%s\" % boundary),",
            "                                   six.b('Content-Disposition: form-data; name=\"%s\"' % key),",
            "                                   six.b(\"\"),",
            "                                   six.b(value)])",
            "",
            "        for name, filename, path in files:",
            "            with open(path, \"rb\") as fh:",
            "                value = fh.read(8192) if send_8kb else fh.read()",
            "",
            "                data_parts.extend([six.b(\"--%s\" % boundary),",
            "                                   six.b('Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (name, filename)),",
            "                                   six.b(\"Content-Type: %s\" % (mimetypes.guess_type(path)[0] or \"application/octet-stream\")),",
            "                                   six.b(\"\"),",
            "                                   value])",
            "        data_parts.extend([six.b(\"--%s--\" % boundary), b\"\"])",
            "        data = newline.join(data_parts)",
            "",
            "    headers = {",
            "        \"Content-Type\": \"multipart/form-data; boundary=%s\" % boundary,",
            "        \"Content-Length\": str(len(data))}",
            "",
            "    return headers, data",
            "",
            "",
            "def request(url, data=None, headers=None, method='GET', use_proxy=True,",
            "            force=False, last_mod_time=None, timeout=10, validate_certs=True,",
            "            url_username=None, url_password=None, http_agent=None, force_basic_auth=True, ignore_errors=False):",
            "    \"\"\"Issue an HTTP request to a url, retrieving an optional JSON response.\"\"\"",
            "",
            "    if headers is None:",
            "        headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}",
            "    headers.update({\"netapp-client-type\": \"Ansible-%s\" % ansible_version})",
            "",
            "    if not http_agent:",
            "        http_agent = \"Ansible / %s\" % ansible_version",
            "",
            "    try:",
            "        r = open_url(url=url, data=data, headers=headers, method=method, use_proxy=use_proxy,",
            "                     force=force, last_mod_time=last_mod_time, timeout=timeout, validate_certs=validate_certs,",
            "                     url_username=url_username, url_password=url_password, http_agent=http_agent,",
            "                     force_basic_auth=force_basic_auth)",
            "    except HTTPError as err:",
            "        r = err.fp",
            "",
            "    try:",
            "        raw_data = r.read()",
            "        if raw_data:",
            "            data = json.loads(raw_data)",
            "        else:",
            "            raw_data = None",
            "    except Exception:",
            "        if ignore_errors:",
            "            pass",
            "        else:",
            "            raise Exception(raw_data)",
            "",
            "    resp_code = r.getcode()",
            "",
            "    if resp_code >= 400 and not ignore_errors:",
            "        raise Exception(resp_code, data)",
            "    else:",
            "        return resp_code, data",
            "",
            "",
            "def ems_log_event(source, server, name=\"Ansible\", id=\"12345\", version=ansible_version,",
            "                  category=\"Information\", event=\"setup\", autosupport=\"false\"):",
            "    ems_log = zapi.NaElement('ems-autosupport-log')",
            "    # Host name invoking the API.",
            "    ems_log.add_new_child(\"computer-name\", name)",
            "    # ID of event. A user defined event-id, range [0..2^32-2].",
            "    ems_log.add_new_child(\"event-id\", id)",
            "    # Name of the application invoking the API.",
            "    ems_log.add_new_child(\"event-source\", source)",
            "    # Version of application invoking the API.",
            "    ems_log.add_new_child(\"app-version\", version)",
            "    # Application defined category of the event.",
            "    ems_log.add_new_child(\"category\", category)",
            "    # Description of event to log. An application defined message to log.",
            "    ems_log.add_new_child(\"event-description\", event)",
            "    ems_log.add_new_child(\"log-level\", \"6\")",
            "    ems_log.add_new_child(\"auto-support\", autosupport)",
            "    server.invoke_successfully(ems_log, True)",
            "",
            "",
            "def get_cserver_zapi(server):",
            "    vserver_info = zapi.NaElement('vserver-get-iter')",
            "    query_details = zapi.NaElement.create_node_with_children('vserver-info', **{'vserver-type': 'admin'})",
            "    query = zapi.NaElement('query')",
            "    query.add_child_elem(query_details)",
            "    vserver_info.add_child_elem(query)",
            "    result = server.invoke_successfully(vserver_info,",
            "                                        enable_tunneling=False)",
            "    attribute_list = result.get_child_by_name('attributes-list')",
            "    vserver_list = attribute_list.get_child_by_name('vserver-info')",
            "    return vserver_list.get_child_content('vserver-name')",
            "",
            "",
            "def get_cserver(connection, is_rest=False):",
            "    if not is_rest:",
            "        return get_cserver_zapi(connection)",
            "",
            "    params = {'fields': 'type'}",
            "    api = \"private/cli/vserver\"",
            "    json, error = connection.get(api, params)",
            "    if json is None or error is not None:",
            "        # exit if there is an error or no data",
            "        return None",
            "    vservers = json.get('records')",
            "    if vservers is not None:",
            "        for vserver in vservers:",
            "            if vserver['type'] == 'admin':     # cluster admin",
            "                return vserver['vserver']",
            "        if len(vservers) == 1:                  # assume vserver admin",
            "            return vservers[0]['vserver']",
            "",
            "    return None",
            "",
            "",
            "class OntapRestAPI(object):",
            "    def __init__(self, module, timeout=60):",
            "        self.module = module",
            "        self.username = self.module.params['username']",
            "        self.password = self.module.params['password']",
            "        self.hostname = self.module.params['hostname']",
            "        self.use_rest = self.module.params['use_rest']",
            "        self.verify = self.module.params['validate_certs']",
            "        self.timeout = timeout",
            "        self.url = 'https://' + self.hostname + '/api/'",
            "        self.errors = list()",
            "        self.debug_logs = list()",
            "        self.check_required_library()",
            "",
            "    def check_required_library(self):",
            "        if not HAS_REQUESTS:",
            "            self.module.fail_json(msg=missing_required_lib('requests'))",
            "",
            "    def send_request(self, method, api, params, json=None, return_status_code=False):",
            "        ''' send http request and process reponse, including error conditions '''",
            "        url = self.url + api",
            "        status_code = None",
            "        content = None",
            "        json_dict = None",
            "        json_error = None",
            "        error_details = None",
            "",
            "        def get_json(response):",
            "            ''' extract json, and error message if present '''",
            "            try:",
            "                json = response.json()",
            "            except ValueError:",
            "                return None, None",
            "            error = json.get('error')",
            "            return json, error",
            "",
            "        try:",
            "            response = requests.request(method, url, verify=self.verify, auth=(self.username, self.password), params=params, timeout=self.timeout, json=json)",
            "            content = response.content  # for debug purposes",
            "            status_code = response.status_code",
            "            # If the response was successful, no Exception will be raised",
            "            response.raise_for_status()",
            "            json_dict, json_error = get_json(response)",
            "        except requests.exceptions.HTTPError as err:",
            "            __, json_error = get_json(response)",
            "            if json_error is None:",
            "                self.log_error(status_code, 'HTTP error: %s' % err)",
            "                error_details = str(err)",
            "            # If an error was reported in the json payload, it is handled below",
            "        except requests.exceptions.ConnectionError as err:",
            "            self.log_error(status_code, 'Connection error: %s' % err)",
            "            error_details = str(err)",
            "        except Exception as err:",
            "            self.log_error(status_code, 'Other error: %s' % err)",
            "            error_details = str(err)",
            "        if json_error is not None:",
            "            self.log_error(status_code, 'Endpoint error: %d: %s' % (status_code, json_error))",
            "            error_details = json_error",
            "        self.log_debug(status_code, content)",
            "        if return_status_code:",
            "            return status_code, error_details",
            "        return json_dict, error_details",
            "",
            "    def get(self, api, params):",
            "        method = 'GET'",
            "        return self.send_request(method, api, params)",
            "",
            "    def post(self, api, data, params=None):",
            "        method = 'POST'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def patch(self, api, data, params=None):",
            "        method = 'PATCH'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def delete(self, api, data, params=None):",
            "        method = 'DELETE'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def _is_rest(self, used_unsupported_rest_properties=None):",
            "        if self.use_rest == \"Always\":",
            "            if used_unsupported_rest_properties:",
            "                error = \"REST API currently does not support '%s'\" % \\",
            "                        ', '.join(used_unsupported_rest_properties)",
            "                return True, error",
            "            else:",
            "                return True, None",
            "        if self.use_rest == 'Never' or used_unsupported_rest_properties:",
            "            # force ZAPI if requested or if some parameter requires it",
            "            return False, None",
            "        method = 'HEAD'",
            "        api = 'cluster/software'",
            "        status_code, __ = self.send_request(method, api, params=None, return_status_code=True)",
            "        if status_code == 200:",
            "            return True, None",
            "        return False, None",
            "",
            "    def is_rest(self, used_unsupported_rest_properties=None):",
            "        ''' only return error if there is a reason to '''",
            "        use_rest, error = self._is_rest(used_unsupported_rest_properties)",
            "        if used_unsupported_rest_properties is None:",
            "            return use_rest",
            "        return use_rest, error",
            "",
            "    def log_error(self, status_code, message):",
            "        self.errors.append(message)",
            "        self.debug_logs.append((status_code, message))",
            "",
            "    def log_debug(self, status_code, content):",
            "        self.debug_logs.append((status_code, content))",
            "",
            "",
            "class AwsCvsRestAPI(object):",
            "    def __init__(self, module, timeout=60):",
            "        self.module = module",
            "        self.api_key = self.module.params['api_key']",
            "        self.secret_key = self.module.params['secret_key']",
            "        self.api_url = self.module.params['api_url']",
            "        self.verify = self.module.params['validate_certs']",
            "        self.timeout = timeout",
            "        self.url = 'https://' + self.api_url + '/v1/'",
            "        self.check_required_library()",
            "",
            "    def check_required_library(self):",
            "        if not HAS_REQUESTS:",
            "            self.module.fail_json(msg=missing_required_lib('requests'))",
            "",
            "    def send_request(self, method, api, params, json=None):",
            "        ''' send http request and process reponse, including error conditions '''",
            "        url = self.url + api",
            "        status_code = None",
            "        content = None",
            "        json_dict = None",
            "        json_error = None",
            "        error_details = None",
            "        headers = {",
            "            'Content-type': \"application/json\",",
            "            'api-key': self.api_key,",
            "            'secret-key': self.secret_key,",
            "            'Cache-Control': \"no-cache\",",
            "        }",
            "",
            "        def get_json(response):",
            "            ''' extract json, and error message if present '''",
            "            try:",
            "                json = response.json()",
            "",
            "            except ValueError:",
            "                return None, None",
            "            success_code = [200, 201, 202]",
            "            if response.status_code not in success_code:",
            "                error = json.get('message')",
            "            else:",
            "                error = None",
            "            return json, error",
            "        try:",
            "            response = requests.request(method, url, headers=headers, timeout=self.timeout, json=json)",
            "            status_code = response.status_code",
            "            # If the response was successful, no Exception will be raised",
            "            json_dict, json_error = get_json(response)",
            "        except requests.exceptions.HTTPError as err:",
            "            __, json_error = get_json(response)",
            "            if json_error is None:",
            "                error_details = str(err)",
            "        except requests.exceptions.ConnectionError as err:",
            "            error_details = str(err)",
            "        except Exception as err:",
            "            error_details = str(err)",
            "        if json_error is not None:",
            "            error_details = json_error",
            "",
            "        return json_dict, error_details",
            "",
            "    # If an error was reported in the json payload, it is handled below",
            "    def get(self, api, params=None):",
            "        method = 'GET'",
            "        return self.send_request(method, api, params)",
            "",
            "    def post(self, api, data, params=None):",
            "        method = 'POST'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def patch(self, api, data, params=None):",
            "        method = 'PATCH'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def put(self, api, data, params=None):",
            "        method = 'PUT'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def delete(self, api, data, params=None):",
            "        method = 'DELETE'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def get_state(self, jobId):",
            "        \"\"\" Method to get the state of the job \"\"\"",
            "        method = 'GET'",
            "        response, status_code = self.get('Jobs/%s' % jobId)",
            "        while str(response['state']) not in 'done':",
            "            response, status_code = self.get('Jobs/%s' % jobId)",
            "        return 'done'"
        ],
        "afterPatchFile": [
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Copyright (c) 2017, Sumit Kumar <sumit4@netapp.com>",
            "# Copyright (c) 2017, Michael Price <michael.price@netapp.com>",
            "# All rights reserved.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "import json",
            "import os",
            "import random",
            "import mimetypes",
            "",
            "from pprint import pformat",
            "from ansible.module_utils import six",
            "from ansible.module_utils.basic import AnsibleModule, missing_required_lib",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError, URLError",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.api import basic_auth_argument_spec",
            "from ansible.module_utils._text import to_native",
            "",
            "try:",
            "    from ansible.module_utils.ansible_release import __version__ as ansible_version",
            "except ImportError:",
            "    ansible_version = 'unknown'",
            "",
            "try:",
            "    from netapp_lib.api.zapi import zapi",
            "    HAS_NETAPP_LIB = True",
            "except ImportError:",
            "    HAS_NETAPP_LIB = False",
            "",
            "try:",
            "    import requests",
            "    HAS_REQUESTS = True",
            "except ImportError:",
            "    HAS_REQUESTS = False",
            "",
            "import ssl",
            "try:",
            "    from urlparse import urlparse, urlunparse",
            "except ImportError:",
            "    from urllib.parse import urlparse, urlunparse",
            "",
            "",
            "HAS_SF_SDK = False",
            "SF_BYTE_MAP = dict(",
            "    # Management GUI displays 1024 ** 3 as 1.1 GB, thus use 1000.",
            "    bytes=1,",
            "    b=1,",
            "    kb=1000,",
            "    mb=1000 ** 2,",
            "    gb=1000 ** 3,",
            "    tb=1000 ** 4,",
            "    pb=1000 ** 5,",
            "    eb=1000 ** 6,",
            "    zb=1000 ** 7,",
            "    yb=1000 ** 8",
            ")",
            "",
            "POW2_BYTE_MAP = dict(",
            "    # Here, 1 kb = 1024",
            "    bytes=1,",
            "    b=1,",
            "    kb=1024,",
            "    mb=1024 ** 2,",
            "    gb=1024 ** 3,",
            "    tb=1024 ** 4,",
            "    pb=1024 ** 5,",
            "    eb=1024 ** 6,",
            "    zb=1024 ** 7,",
            "    yb=1024 ** 8",
            ")",
            "",
            "try:",
            "    from solidfire.factory import ElementFactory",
            "    from solidfire.custom.models import TimeIntervalFrequency",
            "    from solidfire.models import Schedule, ScheduleInfo",
            "",
            "    HAS_SF_SDK = True",
            "except Exception:",
            "    HAS_SF_SDK = False",
            "",
            "",
            "def has_netapp_lib():",
            "    return HAS_NETAPP_LIB",
            "",
            "",
            "def has_sf_sdk():",
            "    return HAS_SF_SDK",
            "",
            "",
            "def na_ontap_host_argument_spec():",
            "",
            "    return dict(",
            "        hostname=dict(required=True, type='str'),",
            "        username=dict(required=True, type='str', aliases=['user']),",
            "        password=dict(required=True, type='str', aliases=['pass'], no_log=True),",
            "        https=dict(required=False, type='bool', default=False),",
            "        validate_certs=dict(required=False, type='bool', default=True),",
            "        http_port=dict(required=False, type='int'),",
            "        ontapi=dict(required=False, type='int'),",
            "        use_rest=dict(required=False, type='str', default='Auto', choices=['Never', 'Always', 'Auto'])",
            "    )",
            "",
            "",
            "def ontap_sf_host_argument_spec():",
            "",
            "    return dict(",
            "        hostname=dict(required=True, type='str'),",
            "        username=dict(required=True, type='str', aliases=['user']),",
            "        password=dict(required=True, type='str', aliases=['pass'], no_log=True)",
            "    )",
            "",
            "",
            "def aws_cvs_host_argument_spec():",
            "",
            "    return dict(",
            "        api_url=dict(required=True, type='str'),",
            "        validate_certs=dict(required=False, type='bool', default=True),",
            "        api_key=dict(required=True, type='str', no_log=True),",
            "        secret_key=dict(required=True, type='str', no_log=True)",
            "    )",
            "",
            "",
            "def create_sf_connection(module, port=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "",
            "    if HAS_SF_SDK and hostname and username and password:",
            "        try:",
            "            return_val = ElementFactory.create(hostname, username, password, port=port)",
            "            return return_val",
            "        except Exception:",
            "            raise Exception(\"Unable to create SF connection\")",
            "    else:",
            "        module.fail_json(msg=\"the python SolidFire SDK module is required\")",
            "",
            "",
            "def setup_na_ontap_zapi(module, vserver=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "    https = module.params['https']",
            "    validate_certs = module.params['validate_certs']",
            "    port = module.params['http_port']",
            "    version = module.params['ontapi']",
            "",
            "    if HAS_NETAPP_LIB:",
            "        # set up zapi",
            "        server = zapi.NaServer(hostname)",
            "        server.set_username(username)",
            "        server.set_password(password)",
            "        if vserver:",
            "            server.set_vserver(vserver)",
            "        if version:",
            "            minor = version",
            "        else:",
            "            minor = 110",
            "        server.set_api_version(major=1, minor=minor)",
            "        # default is HTTP",
            "        if https:",
            "            if port is None:",
            "                port = 443",
            "            transport_type = 'HTTPS'",
            "            # HACK to bypass certificate verification",
            "            if validate_certs is False:",
            "                if not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):",
            "                    ssl._create_default_https_context = ssl._create_unverified_context",
            "        else:",
            "            if port is None:",
            "                port = 80",
            "            transport_type = 'HTTP'",
            "        server.set_transport_type(transport_type)",
            "        server.set_port(port)",
            "        server.set_server_type('FILER')",
            "        return server",
            "    else:",
            "        module.fail_json(msg=\"the python NetApp-Lib module is required\")",
            "",
            "",
            "def setup_ontap_zapi(module, vserver=None):",
            "    hostname = module.params['hostname']",
            "    username = module.params['username']",
            "    password = module.params['password']",
            "",
            "    if HAS_NETAPP_LIB:",
            "        # set up zapi",
            "        server = zapi.NaServer(hostname)",
            "        server.set_username(username)",
            "        server.set_password(password)",
            "        if vserver:",
            "            server.set_vserver(vserver)",
            "        # Todo : Replace hard-coded values with configurable parameters.",
            "        server.set_api_version(major=1, minor=110)",
            "        server.set_port(80)",
            "        server.set_server_type('FILER')",
            "        server.set_transport_type('HTTP')",
            "        return server",
            "    else:",
            "        module.fail_json(msg=\"the python NetApp-Lib module is required\")",
            "",
            "",
            "def eseries_host_argument_spec():",
            "    \"\"\"Retrieve a base argument specification common to all NetApp E-Series modules\"\"\"",
            "    argument_spec = basic_auth_argument_spec()",
            "    argument_spec.update(dict(",
            "        api_username=dict(type='str', required=True),",
            "        api_password=dict(type='str', required=True, no_log=True),",
            "        api_url=dict(type='str', required=True),",
            "        ssid=dict(type='str', required=False, default='1'),",
            "        validate_certs=dict(type='bool', required=False, default=True)",
            "    ))",
            "    return argument_spec",
            "",
            "",
            "class NetAppESeriesModule(object):",
            "    \"\"\"Base class for all NetApp E-Series modules.",
            "",
            "    Provides a set of common methods for NetApp E-Series modules, including version checking, mode (proxy, embedded)",
            "    verification, http requests, secure http redirection for embedded web services, and logging setup.",
            "",
            "    Be sure to add the following lines in the module's documentation section:",
            "    extends_documentation_fragment:",
            "        - netapp.eseries",
            "",
            "    :param dict(dict) ansible_options: dictionary of ansible option definitions",
            "    :param str web_services_version: minimally required web services rest api version (default value: \"02.00.0000.0000\")",
            "    :param bool supports_check_mode: whether the module will support the check_mode capabilities (default=False)",
            "    :param list(list) mutually_exclusive: list containing list(s) of mutually exclusive options (optional)",
            "    :param list(list) required_if: list containing list(s) containing the option, the option value, and then",
            "    a list of required options. (optional)",
            "    :param list(list) required_one_of: list containing list(s) of options for which at least one is required. (optional)",
            "    :param list(list) required_together: list containing list(s) of options that are required together. (optional)",
            "    :param bool log_requests: controls whether to log each request (default: True)",
            "    \"\"\"",
            "    DEFAULT_TIMEOUT = 60",
            "    DEFAULT_SECURE_PORT = \"8443\"",
            "    DEFAULT_REST_API_PATH = \"devmgr/v2/\"",
            "    DEFAULT_REST_API_ABOUT_PATH = \"devmgr/utils/about\"",
            "    DEFAULT_HEADERS = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\",",
            "                       \"netapp-client-type\": \"Ansible-%s\" % ansible_version}",
            "    HTTP_AGENT = \"Ansible / %s\" % ansible_version",
            "    SIZE_UNIT_MAP = dict(bytes=1, b=1, kb=1024, mb=1024**2, gb=1024**3, tb=1024**4,",
            "                         pb=1024**5, eb=1024**6, zb=1024**7, yb=1024**8)",
            "",
            "    def __init__(self, ansible_options, web_services_version=None, supports_check_mode=False,",
            "                 mutually_exclusive=None, required_if=None, required_one_of=None, required_together=None,",
            "                 log_requests=True):",
            "        argument_spec = eseries_host_argument_spec()",
            "        argument_spec.update(ansible_options)",
            "",
            "        self.module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=supports_check_mode,",
            "                                    mutually_exclusive=mutually_exclusive, required_if=required_if,",
            "                                    required_one_of=required_one_of, required_together=required_together)",
            "",
            "        args = self.module.params",
            "        self.web_services_version = web_services_version if web_services_version else \"02.00.0000.0000\"",
            "        self.ssid = args[\"ssid\"]",
            "        self.url = args[\"api_url\"]",
            "        self.log_requests = log_requests",
            "        self.creds = dict(url_username=args[\"api_username\"],",
            "                          url_password=args[\"api_password\"],",
            "                          validate_certs=args[\"validate_certs\"])",
            "",
            "        if not self.url.endswith(\"/\"):",
            "            self.url += \"/\"",
            "",
            "        self.is_embedded_mode = None",
            "        self.is_web_services_valid_cache = None",
            "",
            "    def _check_web_services_version(self):",
            "        \"\"\"Verify proxy or embedded web services meets minimum version required for module.",
            "",
            "        The minimum required web services version is evaluated against version supplied through the web services rest",
            "        api. AnsibleFailJson exception will be raised when the minimum is not met or exceeded.",
            "",
            "        This helper function will update the supplied api url if secure http is not used for embedded web services",
            "",
            "        :raise AnsibleFailJson: raised when the contacted api service does not meet the minimum required version.",
            "        \"\"\"",
            "        if not self.is_web_services_valid_cache:",
            "",
            "            url_parts = urlparse(self.url)",
            "            if not url_parts.scheme or not url_parts.netloc:",
            "                self.module.fail_json(msg=\"Failed to provide valid API URL. Example: https://192.168.1.100:8443/devmgr/v2. URL [%s].\" % self.url)",
            "",
            "            if url_parts.scheme not in [\"http\", \"https\"]:",
            "                self.module.fail_json(msg=\"Protocol must be http or https. URL [%s].\" % self.url)",
            "",
            "            self.url = \"%s://%s/\" % (url_parts.scheme, url_parts.netloc)",
            "            about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "            rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, ignore_errors=True, **self.creds)",
            "",
            "            if rc != 200:",
            "                self.module.warn(\"Failed to retrieve web services about information! Retrying with secure ports. Array Id [%s].\" % self.ssid)",
            "                self.url = \"https://%s:8443/\" % url_parts.netloc.split(\":\")[0]",
            "                about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "                try:",
            "                    rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, **self.creds)",
            "                except Exception as error:",
            "                    self.module.fail_json(msg=\"Failed to retrieve the webservices about information! Array Id [%s]. Error [%s].\"",
            "                                              % (self.ssid, to_native(error)))",
            "",
            "            major, minor, other, revision = data[\"version\"].split(\".\")",
            "            minimum_major, minimum_minor, other, minimum_revision = self.web_services_version.split(\".\")",
            "",
            "            if not (major > minimum_major or",
            "                    (major == minimum_major and minor > minimum_minor) or",
            "                    (major == minimum_major and minor == minimum_minor and revision >= minimum_revision)):",
            "                self.module.fail_json(msg=\"Web services version does not meet minimum version required. Current version: [%s].\"",
            "                                          \" Version required: [%s].\" % (data[\"version\"], self.web_services_version))",
            "",
            "            self.module.log(\"Web services rest api version met the minimum required version.\")",
            "            self.is_web_services_valid_cache = True",
            "",
            "    def is_embedded(self):",
            "        \"\"\"Determine whether web services server is the embedded web services.",
            "",
            "        If web services about endpoint fails based on an URLError then the request will be attempted again using",
            "        secure http.",
            "",
            "        :raise AnsibleFailJson: raised when web services about endpoint failed to be contacted.",
            "        :return bool: whether contacted web services is running from storage array (embedded) or from a proxy.",
            "        \"\"\"",
            "        self._check_web_services_version()",
            "",
            "        if self.is_embedded_mode is None:",
            "            about_url = self.url + self.DEFAULT_REST_API_ABOUT_PATH",
            "            try:",
            "                rc, data = request(about_url, timeout=self.DEFAULT_TIMEOUT, headers=self.DEFAULT_HEADERS, **self.creds)",
            "                self.is_embedded_mode = not data[\"runningAsProxy\"]",
            "            except Exception as error:",
            "                self.module.fail_json(msg=\"Failed to retrieve the webservices about information! Array Id [%s]. Error [%s].\"",
            "                                          % (self.ssid, to_native(error)))",
            "",
            "        return self.is_embedded_mode",
            "",
            "    def request(self, path, data=None, method='GET', headers=None, ignore_errors=False):",
            "        \"\"\"Issue an HTTP request to a url, retrieving an optional JSON response.",
            "",
            "        :param str path: web services rest api endpoint path (Example: storage-systems/1/graph). Note that when the",
            "        full url path is specified then that will be used without supplying the protocol, hostname, port and rest path.",
            "        :param data: data required for the request (data may be json or any python structured data)",
            "        :param str method: request method such as GET, POST, DELETE.",
            "        :param dict headers: dictionary containing request headers.",
            "        :param bool ignore_errors: forces the request to ignore any raised exceptions.",
            "        \"\"\"",
            "        self._check_web_services_version()",
            "",
            "        if headers is None:",
            "            headers = self.DEFAULT_HEADERS",
            "",
            "        if not isinstance(data, str) and headers[\"Content-Type\"] == \"application/json\":",
            "            data = json.dumps(data)",
            "",
            "        if path.startswith(\"/\"):",
            "            path = path[1:]",
            "        request_url = self.url + self.DEFAULT_REST_API_PATH + path",
            "",
            "        if self.log_requests or True:",
            "            self.module.log(pformat(dict(url=request_url, data=data, method=method)))",
            "",
            "        return request(url=request_url, data=data, method=method, headers=headers, use_proxy=True, force=False, last_mod_time=None,",
            "                       timeout=self.DEFAULT_TIMEOUT, http_agent=self.HTTP_AGENT, force_basic_auth=True, ignore_errors=ignore_errors, **self.creds)",
            "",
            "",
            "def create_multipart_formdata(files, fields=None, send_8kb=False):",
            "    \"\"\"Create the data for a multipart/form request.",
            "",
            "    :param list(list) files: list of lists each containing (name, filename, path).",
            "    :param list(list) fields: list of lists each containing (key, value).",
            "    :param bool send_8kb: only sends the first 8kb of the files (default: False).",
            "    \"\"\"",
            "    boundary = \"---------------------------\" + \"\".join([str(random.randint(0, 9)) for x in range(27)])",
            "    data_parts = list()",
            "    data = None",
            "",
            "    if six.PY2:  # Generate payload for Python 2",
            "        newline = \"\\r\\n\"",
            "        if fields is not None:",
            "            for key, value in fields:",
            "                data_parts.extend([\"--%s\" % boundary,",
            "                                   'Content-Disposition: form-data; name=\"%s\"' % key,",
            "                                   \"\",",
            "                                   value])",
            "",
            "        for name, filename, path in files:",
            "            with open(path, \"rb\") as fh:",
            "                value = fh.read(8192) if send_8kb else fh.read()",
            "",
            "                data_parts.extend([\"--%s\" % boundary,",
            "                                   'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (name, filename),",
            "                                   \"Content-Type: %s\" % (mimetypes.guess_type(path)[0] or \"application/octet-stream\"),",
            "                                   \"\",",
            "                                   value])",
            "        data_parts.extend([\"--%s--\" % boundary, \"\"])",
            "        data = newline.join(data_parts)",
            "",
            "    else:",
            "        newline = six.b(\"\\r\\n\")",
            "        if fields is not None:",
            "            for key, value in fields:",
            "                data_parts.extend([six.b(\"--%s\" % boundary),",
            "                                   six.b('Content-Disposition: form-data; name=\"%s\"' % key),",
            "                                   six.b(\"\"),",
            "                                   six.b(value)])",
            "",
            "        for name, filename, path in files:",
            "            with open(path, \"rb\") as fh:",
            "                value = fh.read(8192) if send_8kb else fh.read()",
            "",
            "                data_parts.extend([six.b(\"--%s\" % boundary),",
            "                                   six.b('Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (name, filename)),",
            "                                   six.b(\"Content-Type: %s\" % (mimetypes.guess_type(path)[0] or \"application/octet-stream\")),",
            "                                   six.b(\"\"),",
            "                                   value])",
            "        data_parts.extend([six.b(\"--%s--\" % boundary), b\"\"])",
            "        data = newline.join(data_parts)",
            "",
            "    headers = {",
            "        \"Content-Type\": \"multipart/form-data; boundary=%s\" % boundary,",
            "        \"Content-Length\": str(len(data))}",
            "",
            "    return headers, data",
            "",
            "",
            "def request(url, data=None, headers=None, method='GET', use_proxy=True,",
            "            force=False, last_mod_time=None, timeout=10, validate_certs=True,",
            "            url_username=None, url_password=None, http_agent=None, force_basic_auth=True, ignore_errors=False):",
            "    \"\"\"Issue an HTTP request to a url, retrieving an optional JSON response.\"\"\"",
            "",
            "    if headers is None:",
            "        headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}",
            "    headers.update({\"netapp-client-type\": \"Ansible-%s\" % ansible_version})",
            "",
            "    if not http_agent:",
            "        http_agent = \"Ansible / %s\" % ansible_version",
            "",
            "    try:",
            "        r = open_url(url=url, data=data, headers=headers, method=method, use_proxy=use_proxy,",
            "                     force=force, last_mod_time=last_mod_time, timeout=timeout, validate_certs=validate_certs,",
            "                     url_username=url_username, url_password=url_password, http_agent=http_agent,",
            "                     force_basic_auth=force_basic_auth)",
            "    except HTTPError as err:",
            "        r = err.fp",
            "",
            "    try:",
            "        raw_data = r.read()",
            "        if raw_data:",
            "            data = json.loads(raw_data)",
            "        else:",
            "            raw_data = None",
            "    except Exception:",
            "        if ignore_errors:",
            "            pass",
            "        else:",
            "            raise Exception(raw_data)",
            "",
            "    resp_code = r.getcode()",
            "",
            "    if resp_code >= 400 and not ignore_errors:",
            "        raise Exception(resp_code, data)",
            "    else:",
            "        return resp_code, data",
            "",
            "",
            "def ems_log_event(source, server, name=\"Ansible\", id=\"12345\", version=ansible_version,",
            "                  category=\"Information\", event=\"setup\", autosupport=\"false\"):",
            "    ems_log = zapi.NaElement('ems-autosupport-log')",
            "    # Host name invoking the API.",
            "    ems_log.add_new_child(\"computer-name\", name)",
            "    # ID of event. A user defined event-id, range [0..2^32-2].",
            "    ems_log.add_new_child(\"event-id\", id)",
            "    # Name of the application invoking the API.",
            "    ems_log.add_new_child(\"event-source\", source)",
            "    # Version of application invoking the API.",
            "    ems_log.add_new_child(\"app-version\", version)",
            "    # Application defined category of the event.",
            "    ems_log.add_new_child(\"category\", category)",
            "    # Description of event to log. An application defined message to log.",
            "    ems_log.add_new_child(\"event-description\", event)",
            "    ems_log.add_new_child(\"log-level\", \"6\")",
            "    ems_log.add_new_child(\"auto-support\", autosupport)",
            "    server.invoke_successfully(ems_log, True)",
            "",
            "",
            "def get_cserver_zapi(server):",
            "    vserver_info = zapi.NaElement('vserver-get-iter')",
            "    query_details = zapi.NaElement.create_node_with_children('vserver-info', **{'vserver-type': 'admin'})",
            "    query = zapi.NaElement('query')",
            "    query.add_child_elem(query_details)",
            "    vserver_info.add_child_elem(query)",
            "    result = server.invoke_successfully(vserver_info,",
            "                                        enable_tunneling=False)",
            "    attribute_list = result.get_child_by_name('attributes-list')",
            "    vserver_list = attribute_list.get_child_by_name('vserver-info')",
            "    return vserver_list.get_child_content('vserver-name')",
            "",
            "",
            "def get_cserver(connection, is_rest=False):",
            "    if not is_rest:",
            "        return get_cserver_zapi(connection)",
            "",
            "    params = {'fields': 'type'}",
            "    api = \"private/cli/vserver\"",
            "    json, error = connection.get(api, params)",
            "    if json is None or error is not None:",
            "        # exit if there is an error or no data",
            "        return None",
            "    vservers = json.get('records')",
            "    if vservers is not None:",
            "        for vserver in vservers:",
            "            if vserver['type'] == 'admin':     # cluster admin",
            "                return vserver['vserver']",
            "        if len(vservers) == 1:                  # assume vserver admin",
            "            return vservers[0]['vserver']",
            "",
            "    return None",
            "",
            "",
            "class OntapRestAPI(object):",
            "    def __init__(self, module, timeout=60):",
            "        self.module = module",
            "        self.username = self.module.params['username']",
            "        self.password = self.module.params['password']",
            "        self.hostname = self.module.params['hostname']",
            "        self.use_rest = self.module.params['use_rest']",
            "        self.verify = self.module.params['validate_certs']",
            "        self.timeout = timeout",
            "        self.url = 'https://' + self.hostname + '/api/'",
            "        self.errors = list()",
            "        self.debug_logs = list()",
            "        self.check_required_library()",
            "",
            "    def check_required_library(self):",
            "        if not HAS_REQUESTS:",
            "            self.module.fail_json(msg=missing_required_lib('requests'))",
            "",
            "    def send_request(self, method, api, params, json=None, return_status_code=False):",
            "        ''' send http request and process reponse, including error conditions '''",
            "        url = self.url + api",
            "        status_code = None",
            "        content = None",
            "        json_dict = None",
            "        json_error = None",
            "        error_details = None",
            "",
            "        def get_json(response):",
            "            ''' extract json, and error message if present '''",
            "            try:",
            "                json = response.json()",
            "            except ValueError:",
            "                return None, None",
            "            error = json.get('error')",
            "            return json, error",
            "",
            "        try:",
            "            response = requests.request(method, url, verify=self.verify, auth=(self.username, self.password), params=params, timeout=self.timeout, json=json)",
            "            content = response.content  # for debug purposes",
            "            status_code = response.status_code",
            "            # If the response was successful, no Exception will be raised",
            "            response.raise_for_status()",
            "            json_dict, json_error = get_json(response)",
            "        except requests.exceptions.HTTPError as err:",
            "            __, json_error = get_json(response)",
            "            if json_error is None:",
            "                self.log_error(status_code, 'HTTP error: %s' % err)",
            "                error_details = str(err)",
            "            # If an error was reported in the json payload, it is handled below",
            "        except requests.exceptions.ConnectionError as err:",
            "            self.log_error(status_code, 'Connection error: %s' % err)",
            "            error_details = str(err)",
            "        except Exception as err:",
            "            self.log_error(status_code, 'Other error: %s' % err)",
            "            error_details = str(err)",
            "        if json_error is not None:",
            "            self.log_error(status_code, 'Endpoint error: %d: %s' % (status_code, json_error))",
            "            error_details = json_error",
            "        self.log_debug(status_code, content)",
            "        if return_status_code:",
            "            return status_code, error_details",
            "        return json_dict, error_details",
            "",
            "    def get(self, api, params):",
            "        method = 'GET'",
            "        return self.send_request(method, api, params)",
            "",
            "    def post(self, api, data, params=None):",
            "        method = 'POST'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def patch(self, api, data, params=None):",
            "        method = 'PATCH'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def delete(self, api, data, params=None):",
            "        method = 'DELETE'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def _is_rest(self, used_unsupported_rest_properties=None):",
            "        if self.use_rest == \"Always\":",
            "            if used_unsupported_rest_properties:",
            "                error = \"REST API currently does not support '%s'\" % \\",
            "                        ', '.join(used_unsupported_rest_properties)",
            "                return True, error",
            "            else:",
            "                return True, None",
            "        if self.use_rest == 'Never' or used_unsupported_rest_properties:",
            "            # force ZAPI if requested or if some parameter requires it",
            "            return False, None",
            "        method = 'HEAD'",
            "        api = 'cluster/software'",
            "        status_code, __ = self.send_request(method, api, params=None, return_status_code=True)",
            "        if status_code == 200:",
            "            return True, None",
            "        return False, None",
            "",
            "    def is_rest(self, used_unsupported_rest_properties=None):",
            "        ''' only return error if there is a reason to '''",
            "        use_rest, error = self._is_rest(used_unsupported_rest_properties)",
            "        if used_unsupported_rest_properties is None:",
            "            return use_rest",
            "        return use_rest, error",
            "",
            "    def log_error(self, status_code, message):",
            "        self.errors.append(message)",
            "        self.debug_logs.append((status_code, message))",
            "",
            "    def log_debug(self, status_code, content):",
            "        self.debug_logs.append((status_code, content))",
            "",
            "",
            "class AwsCvsRestAPI(object):",
            "    def __init__(self, module, timeout=60):",
            "        self.module = module",
            "        self.api_key = self.module.params['api_key']",
            "        self.secret_key = self.module.params['secret_key']",
            "        self.api_url = self.module.params['api_url']",
            "        self.verify = self.module.params['validate_certs']",
            "        self.timeout = timeout",
            "        self.url = 'https://' + self.api_url + '/v1/'",
            "        self.check_required_library()",
            "",
            "    def check_required_library(self):",
            "        if not HAS_REQUESTS:",
            "            self.module.fail_json(msg=missing_required_lib('requests'))",
            "",
            "    def send_request(self, method, api, params, json=None):",
            "        ''' send http request and process reponse, including error conditions '''",
            "        url = self.url + api",
            "        status_code = None",
            "        content = None",
            "        json_dict = None",
            "        json_error = None",
            "        error_details = None",
            "        headers = {",
            "            'Content-type': \"application/json\",",
            "            'api-key': self.api_key,",
            "            'secret-key': self.secret_key,",
            "            'Cache-Control': \"no-cache\",",
            "        }",
            "",
            "        def get_json(response):",
            "            ''' extract json, and error message if present '''",
            "            try:",
            "                json = response.json()",
            "",
            "            except ValueError:",
            "                return None, None",
            "            success_code = [200, 201, 202]",
            "            if response.status_code not in success_code:",
            "                error = json.get('message')",
            "            else:",
            "                error = None",
            "            return json, error",
            "        try:",
            "            response = requests.request(method, url, headers=headers, timeout=self.timeout, json=json)",
            "            status_code = response.status_code",
            "            # If the response was successful, no Exception will be raised",
            "            json_dict, json_error = get_json(response)",
            "        except requests.exceptions.HTTPError as err:",
            "            __, json_error = get_json(response)",
            "            if json_error is None:",
            "                error_details = str(err)",
            "        except requests.exceptions.ConnectionError as err:",
            "            error_details = str(err)",
            "        except Exception as err:",
            "            error_details = str(err)",
            "        if json_error is not None:",
            "            error_details = json_error",
            "",
            "        return json_dict, error_details",
            "",
            "    # If an error was reported in the json payload, it is handled below",
            "    def get(self, api, params=None):",
            "        method = 'GET'",
            "        return self.send_request(method, api, params)",
            "",
            "    def post(self, api, data, params=None):",
            "        method = 'POST'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def patch(self, api, data, params=None):",
            "        method = 'PATCH'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def put(self, api, data, params=None):",
            "        method = 'PUT'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def delete(self, api, data, params=None):",
            "        method = 'DELETE'",
            "        return self.send_request(method, api, params, json=data)",
            "",
            "    def get_state(self, jobId):",
            "        \"\"\" Method to get the state of the job \"\"\"",
            "        method = 'GET'",
            "        response, status_code = self.get('Jobs/%s' % jobId)",
            "        while str(response['state']) not in 'done':",
            "            response, status_code = self.get('Jobs/%s' % jobId)",
            "        return 'done'"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "142": [
                "aws_cvs_host_argument_spec"
            ],
            "143": [
                "aws_cvs_host_argument_spec"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/docker/docker_swarm.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 622,
                "afterPatchRowNumber": 622,
                "PatchRowcode": "         name=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 623,
                "afterPatchRowNumber": 623,
                "PatchRowcode": "         labels=dict(type='dict'),"
            },
            "2": {
                "beforePatchRowNumber": 624,
                "afterPatchRowNumber": 624,
                "PatchRowcode": "         signing_ca_cert=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 625,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        signing_ca_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 625,
                "PatchRowcode": "+        signing_ca_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 626,
                "afterPatchRowNumber": 626,
                "PatchRowcode": "         ca_force_rotate=dict(type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 627,
                "afterPatchRowNumber": 627,
                "PatchRowcode": "         autolock_managers=dict(type='bool'),"
            },
            "7": {
                "beforePatchRowNumber": 628,
                "afterPatchRowNumber": 628,
                "PatchRowcode": "         node_id=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2016 Red Hat | Ansible",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: docker_swarm",
            "short_description: Manage Swarm cluster",
            "version_added: \"2.7\"",
            "description:",
            "  - Create a new Swarm cluster.",
            "  - Add/Remove nodes or managers to an existing cluster.",
            "options:",
            "  advertise_addr:",
            "    description:",
            "      - Externally reachable address advertised to other nodes.",
            "      - This can either be an address/port combination",
            "          in the form C(192.168.1.1:4567), or an interface followed by a",
            "          port number, like C(eth0:4567).",
            "      - If the port number is omitted,",
            "          the port number from the listen address is used.",
            "      - If I(advertise_addr) is not specified, it will be automatically",
            "          detected when possible.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "  default_addr_pool:",
            "    description:",
            "      - Default address pool in CIDR format.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: list",
            "    elements: str",
            "    version_added: \"2.8\"",
            "  subnet_size:",
            "    description:",
            "      - Default address pool subnet mask length.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: int",
            "    version_added: \"2.8\"",
            "  listen_addr:",
            "    description:",
            "      - Listen address used for inter-manager communication.",
            "      - This can either be an address/port combination in the form",
            "          C(192.168.1.1:4567), or an interface followed by a port number,",
            "          like C(eth0:4567).",
            "      - If the port number is omitted, the default swarm listening port",
            "          is used.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "    default: 0.0.0.0:2377",
            "  force:",
            "    description:",
            "      - Use with state C(present) to force creating a new Swarm, even if already part of one.",
            "      - Use with state C(absent) to Leave the swarm even if this node is a manager.",
            "    type: bool",
            "    default: no",
            "  state:",
            "    description:",
            "      - Set to C(present), to create/update a new cluster.",
            "      - Set to C(join), to join an existing cluster.",
            "      - Set to C(absent), to leave an existing cluster.",
            "      - Set to C(remove), to remove an absent node from the cluster.",
            "        Note that removing requires Docker SDK for Python >= 2.4.0.",
            "      - Set to C(inspect) to display swarm informations.",
            "    type: str",
            "    default: present",
            "    choices:",
            "      - present",
            "      - join",
            "      - absent",
            "      - remove",
            "      - inspect",
            "  node_id:",
            "    description:",
            "      - Swarm id of the node to remove.",
            "      - Used with I(state=remove).",
            "    type: str",
            "  join_token:",
            "    description:",
            "      - Swarm token used to join a swarm cluster.",
            "      - Used with I(state=join).",
            "    type: str",
            "  remote_addrs:",
            "    description:",
            "      - Remote address of one or more manager nodes of an existing Swarm to connect to.",
            "      - Used with I(state=join).",
            "    type: list",
            "    elements: str",
            "  task_history_retention_limit:",
            "    description:",
            "      - Maximum number of tasks history stored.",
            "      - Docker default value is C(5).",
            "    type: int",
            "  snapshot_interval:",
            "    description:",
            "      - Number of logs entries between snapshot.",
            "      - Docker default value is C(10000).",
            "    type: int",
            "  keep_old_snapshots:",
            "    description:",
            "      - Number of snapshots to keep beyond the current snapshot.",
            "      - Docker default value is C(0).",
            "    type: int",
            "  log_entries_for_slow_followers:",
            "    description:",
            "      - Number of log entries to keep around to sync up slow followers after a snapshot is created.",
            "    type: int",
            "  heartbeat_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) between each heartbeat.",
            "      - Docker default value is C(1s).",
            "    type: int",
            "  election_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) needed without a leader to trigger a new election.",
            "      - Docker default value is C(10s).",
            "    type: int",
            "  dispatcher_heartbeat_period:",
            "    description:",
            "      - The delay for an agent to send a heartbeat to the dispatcher.",
            "      - Docker default value is C(5s).",
            "    type: int",
            "  node_cert_expiry:",
            "    description:",
            "      - Automatic expiry for nodes certificates.",
            "      - Docker default value is C(3months).",
            "    type: int",
            "  name:",
            "    description:",
            "      - The name of the swarm.",
            "    type: str",
            "  labels:",
            "    description:",
            "      - User-defined key/value metadata.",
            "      - Label operations in this module apply to the docker swarm cluster.",
            "        Use M(docker_node) module to add/modify/remove swarm node labels.",
            "      - Requires API version >= 1.32.",
            "    type: dict",
            "  signing_ca_cert:",
            "    description:",
            "      - The desired signing CA certificate for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a certificate, but the contents of the certificate.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  signing_ca_key:",
            "    description:",
            "      - The desired signing CA key for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a key, but the contents of the key.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  ca_force_rotate:",
            "    description:",
            "      - An integer whose purpose is to force swarm to generate a new signing CA certificate and key,",
            "          if none have been specified.",
            "      - Docker default value is C(0).",
            "      - Requires API version >= 1.30.",
            "    type: int",
            "  autolock_managers:",
            "    description:",
            "      - If set, generate a key and use it to lock data stored on the managers.",
            "      - Docker default value is C(no).",
            "      - M(docker_swarm_info) can be used to retrieve the unlock key.",
            "    type: bool",
            "  rotate_worker_token:",
            "    description: Rotate the worker join token.",
            "    type: bool",
            "    default: no",
            "  rotate_manager_token:",
            "    description: Rotate the manager join token.",
            "    type: bool",
            "    default: no",
            "extends_documentation_fragment:",
            "  - docker",
            "  - docker.docker_py_1_documentation",
            "requirements:",
            "  - \"L(Docker SDK for Python,https://docker-py.readthedocs.io/en/stable/) >= 1.10.0 (use L(docker-py,https://pypi.org/project/docker-py/) for Python 2.6)\"",
            "  - Docker API >= 1.25",
            "author:",
            "  - Thierry Bouvet (@tbouvet)",
            "  - Piotr Wojciechowski (@WojciechowskiPiotr)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "- name: Init a new swarm with default parameters",
            "  docker_swarm:",
            "    state: present",
            "",
            "- name: Update swarm configuration",
            "  docker_swarm:",
            "    state: present",
            "    election_tick: 5",
            "",
            "- name: Add nodes",
            "  docker_swarm:",
            "    state: join",
            "    advertise_addr: 192.168.1.2",
            "    join_token: SWMTKN-1--xxxxx",
            "    remote_addrs: [ '192.168.1.1:2377' ]",
            "",
            "- name: Leave swarm for a node",
            "  docker_swarm:",
            "    state: absent",
            "",
            "- name: Remove a swarm manager",
            "  docker_swarm:",
            "    state: absent",
            "    force: true",
            "",
            "- name: Remove node from swarm",
            "  docker_swarm:",
            "    state: remove",
            "    node_id: mynode",
            "",
            "- name: Inspect swarm",
            "  docker_swarm:",
            "    state: inspect",
            "  register: swarm_info",
            "'''",
            "",
            "RETURN = '''",
            "swarm_facts:",
            "  description: Informations about swarm.",
            "  returned: success",
            "  type: dict",
            "  contains:",
            "      JoinTokens:",
            "          description: Tokens to connect to the Swarm.",
            "          returned: success",
            "          type: dict",
            "          contains:",
            "              Worker:",
            "                  description: Token to create a new *worker* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "              Manager:",
            "                  description: Token to create a new *manager* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "      UnlockKey:",
            "          description: The swarm unlock-key if I(autolock_managers) is C(true).",
            "          returned: on success if I(autolock_managers) is C(true)",
            "            and swarm is initialised, or if I(autolock_managers) has changed.",
            "          type: str",
            "          example: SWMKEY-1-xxx",
            "",
            "actions:",
            "  description: Provides the actions done on the swarm.",
            "  returned: when action failed.",
            "  type: list",
            "  elements: str",
            "  example: \"['This cluster is already a swarm cluster']\"",
            "",
            "'''",
            "",
            "import json",
            "import traceback",
            "",
            "try:",
            "    from docker.errors import DockerException, APIError",
            "except ImportError:",
            "    # missing Docker SDK for Python handled in ansible.module_utils.docker.common",
            "    pass",
            "",
            "from ansible.module_utils.docker.common import (",
            "    DockerBaseClass,",
            "    DifferenceTracker,",
            "    RequestException,",
            ")",
            "",
            "from ansible.module_utils.docker.swarm import AnsibleDockerSwarmClient",
            "",
            "from ansible.module_utils._text import to_native",
            "",
            "",
            "class TaskParameters(DockerBaseClass):",
            "    def __init__(self):",
            "        super(TaskParameters, self).__init__()",
            "",
            "        self.advertise_addr = None",
            "        self.listen_addr = None",
            "        self.remote_addrs = None",
            "        self.join_token = None",
            "",
            "        # Spec",
            "        self.snapshot_interval = None",
            "        self.task_history_retention_limit = None",
            "        self.keep_old_snapshots = None",
            "        self.log_entries_for_slow_followers = None",
            "        self.heartbeat_tick = None",
            "        self.election_tick = None",
            "        self.dispatcher_heartbeat_period = None",
            "        self.node_cert_expiry = None",
            "        self.name = None",
            "        self.labels = None",
            "        self.log_driver = None",
            "        self.signing_ca_cert = None",
            "        self.signing_ca_key = None",
            "        self.ca_force_rotate = None",
            "        self.autolock_managers = None",
            "        self.rotate_worker_token = None",
            "        self.rotate_manager_token = None",
            "        self.default_addr_pool = None",
            "        self.subnet_size = None",
            "",
            "    @staticmethod",
            "    def from_ansible_params(client):",
            "        result = TaskParameters()",
            "        for key, value in client.module.params.items():",
            "            if key in result.__dict__:",
            "                setattr(result, key, value)",
            "",
            "        result.update_parameters(client)",
            "        return result",
            "",
            "    def update_from_swarm_info(self, swarm_info):",
            "        spec = swarm_info['Spec']",
            "",
            "        ca_config = spec.get('CAConfig') or dict()",
            "        if self.node_cert_expiry is None:",
            "            self.node_cert_expiry = ca_config.get('NodeCertExpiry')",
            "        if self.ca_force_rotate is None:",
            "            self.ca_force_rotate = ca_config.get('ForceRotate')",
            "",
            "        dispatcher = spec.get('Dispatcher') or dict()",
            "        if self.dispatcher_heartbeat_period is None:",
            "            self.dispatcher_heartbeat_period = dispatcher.get('HeartbeatPeriod')",
            "",
            "        raft = spec.get('Raft') or dict()",
            "        if self.snapshot_interval is None:",
            "            self.snapshot_interval = raft.get('SnapshotInterval')",
            "        if self.keep_old_snapshots is None:",
            "            self.keep_old_snapshots = raft.get('KeepOldSnapshots')",
            "        if self.heartbeat_tick is None:",
            "            self.heartbeat_tick = raft.get('HeartbeatTick')",
            "        if self.log_entries_for_slow_followers is None:",
            "            self.log_entries_for_slow_followers = raft.get('LogEntriesForSlowFollowers')",
            "        if self.election_tick is None:",
            "            self.election_tick = raft.get('ElectionTick')",
            "",
            "        orchestration = spec.get('Orchestration') or dict()",
            "        if self.task_history_retention_limit is None:",
            "            self.task_history_retention_limit = orchestration.get('TaskHistoryRetentionLimit')",
            "",
            "        encryption_config = spec.get('EncryptionConfig') or dict()",
            "        if self.autolock_managers is None:",
            "            self.autolock_managers = encryption_config.get('AutoLockManagers')",
            "",
            "        if self.name is None:",
            "            self.name = spec['Name']",
            "",
            "        if self.labels is None:",
            "            self.labels = spec.get('Labels') or {}",
            "",
            "        if 'LogDriver' in spec['TaskDefaults']:",
            "            self.log_driver = spec['TaskDefaults']['LogDriver']",
            "",
            "    def update_parameters(self, client):",
            "        assign = dict(",
            "            snapshot_interval='snapshot_interval',",
            "            task_history_retention_limit='task_history_retention_limit',",
            "            keep_old_snapshots='keep_old_snapshots',",
            "            log_entries_for_slow_followers='log_entries_for_slow_followers',",
            "            heartbeat_tick='heartbeat_tick',",
            "            election_tick='election_tick',",
            "            dispatcher_heartbeat_period='dispatcher_heartbeat_period',",
            "            node_cert_expiry='node_cert_expiry',",
            "            name='name',",
            "            labels='labels',",
            "            signing_ca_cert='signing_ca_cert',",
            "            signing_ca_key='signing_ca_key',",
            "            ca_force_rotate='ca_force_rotate',",
            "            autolock_managers='autolock_managers',",
            "            log_driver='log_driver',",
            "        )",
            "        params = dict()",
            "        for dest, source in assign.items():",
            "            if not client.option_minimal_versions[source]['supported']:",
            "                continue",
            "            value = getattr(self, source)",
            "            if value is not None:",
            "                params[dest] = value",
            "        self.spec = client.create_swarm_spec(**params)",
            "",
            "    def compare_to_active(self, other, client, differences):",
            "        for k in self.__dict__:",
            "            if k in ('advertise_addr', 'listen_addr', 'remote_addrs', 'join_token',",
            "                     'rotate_worker_token', 'rotate_manager_token', 'spec',",
            "                     'default_addr_pool', 'subnet_size'):",
            "                continue",
            "            if not client.option_minimal_versions[k]['supported']:",
            "                continue",
            "            value = getattr(self, k)",
            "            if value is None:",
            "                continue",
            "            other_value = getattr(other, k)",
            "            if value != other_value:",
            "                differences.add(k, parameter=value, active=other_value)",
            "        if self.rotate_worker_token:",
            "            differences.add('rotate_worker_token', parameter=True, active=False)",
            "        if self.rotate_manager_token:",
            "            differences.add('rotate_manager_token', parameter=True, active=False)",
            "        return differences",
            "",
            "",
            "class SwarmManager(DockerBaseClass):",
            "",
            "    def __init__(self, client, results):",
            "",
            "        super(SwarmManager, self).__init__()",
            "",
            "        self.client = client",
            "        self.results = results",
            "        self.check_mode = self.client.check_mode",
            "        self.swarm_info = {}",
            "",
            "        self.state = client.module.params['state']",
            "        self.force = client.module.params['force']",
            "        self.node_id = client.module.params['node_id']",
            "",
            "        self.differences = DifferenceTracker()",
            "        self.parameters = TaskParameters.from_ansible_params(client)",
            "",
            "        self.created = False",
            "",
            "    def __call__(self):",
            "        choice_map = {",
            "            \"present\": self.init_swarm,",
            "            \"join\": self.join,",
            "            \"absent\": self.leave,",
            "            \"remove\": self.remove,",
            "            \"inspect\": self.inspect_swarm",
            "        }",
            "",
            "        if self.state == 'inspect':",
            "            self.client.module.deprecate(",
            "                \"The 'inspect' state is deprecated, please use 'docker_swarm_info' to inspect swarm cluster\",",
            "                version='2.12')",
            "",
            "        choice_map.get(self.state)()",
            "",
            "        if self.client.module._diff or self.parameters.debug:",
            "            diff = dict()",
            "            diff['before'], diff['after'] = self.differences.get_before_after()",
            "            self.results['diff'] = diff",
            "",
            "    def inspect_swarm(self):",
            "        try:",
            "            data = self.client.inspect_swarm()",
            "            json_str = json.dumps(data, ensure_ascii=False)",
            "            self.swarm_info = json.loads(json_str)",
            "",
            "            self.results['changed'] = False",
            "            self.results['swarm_facts'] = self.swarm_info",
            "",
            "            unlock_key = self.get_unlock_key()",
            "            self.swarm_info.update(unlock_key)",
            "        except APIError:",
            "            return",
            "",
            "    def get_unlock_key(self):",
            "        default = {'UnlockKey': None}",
            "        if not self.has_swarm_lock_changed():",
            "            return default",
            "        try:",
            "            return self.client.get_unlock_key() or default",
            "        except APIError:",
            "            return default",
            "",
            "    def has_swarm_lock_changed(self):",
            "        return self.parameters.autolock_managers and (",
            "            self.created or self.differences.has_difference_for('autolock_managers')",
            "        )",
            "",
            "    def init_swarm(self):",
            "        if not self.force and self.client.check_if_swarm_manager():",
            "            self.__update_swarm()",
            "            return",
            "",
            "        if not self.check_mode:",
            "            init_arguments = {",
            "                'advertise_addr': self.parameters.advertise_addr,",
            "                'listen_addr': self.parameters.listen_addr,",
            "                'force_new_cluster': self.force,",
            "                'swarm_spec': self.parameters.spec,",
            "            }",
            "            if self.parameters.default_addr_pool is not None:",
            "                init_arguments['default_addr_pool'] = self.parameters.default_addr_pool",
            "            if self.parameters.subnet_size is not None:",
            "                init_arguments['subnet_size'] = self.parameters.subnet_size",
            "            try:",
            "                self.client.init_swarm(**init_arguments)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not create a new Swarm Cluster: %s\" % to_native(exc))",
            "",
            "        if not self.client.check_if_swarm_manager():",
            "            if not self.check_mode:",
            "                self.client.fail(\"Swarm not created or other error!\")",
            "",
            "        self.created = True",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"New Swarm cluster created: %s\" % (self.swarm_info.get('ID')))",
            "        self.differences.add('state', parameter='present', active='absent')",
            "        self.results['changed'] = True",
            "        self.results['swarm_facts'] = {",
            "            'JoinTokens': self.swarm_info.get('JoinTokens'),",
            "            'UnlockKey': self.swarm_info.get('UnlockKey')",
            "        }",
            "",
            "    def __update_swarm(self):",
            "        try:",
            "            self.inspect_swarm()",
            "            version = self.swarm_info['Version']['Index']",
            "            self.parameters.update_from_swarm_info(self.swarm_info)",
            "            old_parameters = TaskParameters()",
            "            old_parameters.update_from_swarm_info(self.swarm_info)",
            "            self.parameters.compare_to_active(old_parameters, self.client, self.differences)",
            "            if self.differences.empty:",
            "                self.results['actions'].append(\"No modification\")",
            "                self.results['changed'] = False",
            "                return",
            "            update_parameters = TaskParameters.from_ansible_params(self.client)",
            "            update_parameters.update_parameters(self.client)",
            "            if not self.check_mode:",
            "                self.client.update_swarm(",
            "                    version=version, swarm_spec=update_parameters.spec,",
            "                    rotate_worker_token=self.parameters.rotate_worker_token,",
            "                    rotate_manager_token=self.parameters.rotate_manager_token)",
            "        except APIError as exc:",
            "            self.client.fail(\"Can not update a Swarm Cluster: %s\" % to_native(exc))",
            "            return",
            "",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"Swarm cluster updated\")",
            "        self.results['changed'] = True",
            "",
            "    def join(self):",
            "        if self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is already part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.join_swarm(",
            "                    remote_addrs=self.parameters.remote_addrs, join_token=self.parameters.join_token,",
            "                    listen_addr=self.parameters.listen_addr, advertise_addr=self.parameters.advertise_addr)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not join the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"New node is added to swarm cluster\")",
            "        self.differences.add('joined', parameter=True, active=False)",
            "        self.results['changed'] = True",
            "",
            "    def leave(self):",
            "        if not self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is not part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.leave_swarm(force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"This node can not leave the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node has left the swarm cluster\")",
            "        self.differences.add('joined', parameter='absent', active='present')",
            "        self.results['changed'] = True",
            "",
            "    def remove(self):",
            "        if not self.client.check_if_swarm_manager():",
            "            self.client.fail(\"This node is not a manager.\")",
            "",
            "        try:",
            "            status_down = self.client.check_if_swarm_node_is_down(node_id=self.node_id, repeat_check=5)",
            "        except APIError:",
            "            return",
            "",
            "        if not status_down:",
            "            self.client.fail(\"Can not remove the node. The status node is ready and not down.\")",
            "",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.remove_node(node_id=self.node_id, force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not remove the node from the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node is removed from swarm cluster.\")",
            "        self.differences.add('joined', parameter=False, active=True)",
            "        self.results['changed'] = True",
            "",
            "",
            "def _detect_remove_operation(client):",
            "    return client.module.params['state'] == 'remove'",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        advertise_addr=dict(type='str'),",
            "        state=dict(type='str', default='present', choices=['present', 'join', 'absent', 'remove', 'inspect']),",
            "        force=dict(type='bool', default=False),",
            "        listen_addr=dict(type='str', default='0.0.0.0:2377'),",
            "        remote_addrs=dict(type='list', elements='str'),",
            "        join_token=dict(type='str'),",
            "        snapshot_interval=dict(type='int'),",
            "        task_history_retention_limit=dict(type='int'),",
            "        keep_old_snapshots=dict(type='int'),",
            "        log_entries_for_slow_followers=dict(type='int'),",
            "        heartbeat_tick=dict(type='int'),",
            "        election_tick=dict(type='int'),",
            "        dispatcher_heartbeat_period=dict(type='int'),",
            "        node_cert_expiry=dict(type='int'),",
            "        name=dict(type='str'),",
            "        labels=dict(type='dict'),",
            "        signing_ca_cert=dict(type='str'),",
            "        signing_ca_key=dict(type='str'),",
            "        ca_force_rotate=dict(type='int'),",
            "        autolock_managers=dict(type='bool'),",
            "        node_id=dict(type='str'),",
            "        rotate_worker_token=dict(type='bool', default=False),",
            "        rotate_manager_token=dict(type='bool', default=False),",
            "        default_addr_pool=dict(type='list', elements='str'),",
            "        subnet_size=dict(type='int'),",
            "    )",
            "",
            "    required_if = [",
            "        ('state', 'join', ['advertise_addr', 'remote_addrs', 'join_token']),",
            "        ('state', 'remove', ['node_id'])",
            "    ]",
            "",
            "    option_minimal_versions = dict(",
            "        labels=dict(docker_py_version='2.6.0', docker_api_version='1.32'),",
            "        signing_ca_cert=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        signing_ca_key=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        ca_force_rotate=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        autolock_managers=dict(docker_py_version='2.6.0'),",
            "        log_driver=dict(docker_py_version='2.6.0'),",
            "        remove_operation=dict(",
            "            docker_py_version='2.4.0',",
            "            detect_usage=_detect_remove_operation,",
            "            usage_msg='remove swarm nodes'",
            "        ),",
            "        default_addr_pool=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "        subnet_size=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "    )",
            "",
            "    client = AnsibleDockerSwarmClient(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "        required_if=required_if,",
            "        min_docker_version='1.10.0',",
            "        min_docker_api_version='1.25',",
            "        option_minimal_versions=option_minimal_versions,",
            "    )",
            "",
            "    try:",
            "        results = dict(",
            "            changed=False,",
            "            result='',",
            "            actions=[]",
            "        )",
            "",
            "        SwarmManager(client, results)()",
            "        client.module.exit_json(**results)",
            "    except DockerException as e:",
            "        client.fail('An unexpected docker error occurred: {0}'.format(e), exception=traceback.format_exc())",
            "    except RequestException as e:",
            "        client.fail('An unexpected requests error occurred when docker-py tried to talk to the docker daemon: {0}'.format(e), exception=traceback.format_exc())",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2016 Red Hat | Ansible",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: docker_swarm",
            "short_description: Manage Swarm cluster",
            "version_added: \"2.7\"",
            "description:",
            "  - Create a new Swarm cluster.",
            "  - Add/Remove nodes or managers to an existing cluster.",
            "options:",
            "  advertise_addr:",
            "    description:",
            "      - Externally reachable address advertised to other nodes.",
            "      - This can either be an address/port combination",
            "          in the form C(192.168.1.1:4567), or an interface followed by a",
            "          port number, like C(eth0:4567).",
            "      - If the port number is omitted,",
            "          the port number from the listen address is used.",
            "      - If I(advertise_addr) is not specified, it will be automatically",
            "          detected when possible.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "  default_addr_pool:",
            "    description:",
            "      - Default address pool in CIDR format.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: list",
            "    elements: str",
            "    version_added: \"2.8\"",
            "  subnet_size:",
            "    description:",
            "      - Default address pool subnet mask length.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: int",
            "    version_added: \"2.8\"",
            "  listen_addr:",
            "    description:",
            "      - Listen address used for inter-manager communication.",
            "      - This can either be an address/port combination in the form",
            "          C(192.168.1.1:4567), or an interface followed by a port number,",
            "          like C(eth0:4567).",
            "      - If the port number is omitted, the default swarm listening port",
            "          is used.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "    default: 0.0.0.0:2377",
            "  force:",
            "    description:",
            "      - Use with state C(present) to force creating a new Swarm, even if already part of one.",
            "      - Use with state C(absent) to Leave the swarm even if this node is a manager.",
            "    type: bool",
            "    default: no",
            "  state:",
            "    description:",
            "      - Set to C(present), to create/update a new cluster.",
            "      - Set to C(join), to join an existing cluster.",
            "      - Set to C(absent), to leave an existing cluster.",
            "      - Set to C(remove), to remove an absent node from the cluster.",
            "        Note that removing requires Docker SDK for Python >= 2.4.0.",
            "      - Set to C(inspect) to display swarm informations.",
            "    type: str",
            "    default: present",
            "    choices:",
            "      - present",
            "      - join",
            "      - absent",
            "      - remove",
            "      - inspect",
            "  node_id:",
            "    description:",
            "      - Swarm id of the node to remove.",
            "      - Used with I(state=remove).",
            "    type: str",
            "  join_token:",
            "    description:",
            "      - Swarm token used to join a swarm cluster.",
            "      - Used with I(state=join).",
            "    type: str",
            "  remote_addrs:",
            "    description:",
            "      - Remote address of one or more manager nodes of an existing Swarm to connect to.",
            "      - Used with I(state=join).",
            "    type: list",
            "    elements: str",
            "  task_history_retention_limit:",
            "    description:",
            "      - Maximum number of tasks history stored.",
            "      - Docker default value is C(5).",
            "    type: int",
            "  snapshot_interval:",
            "    description:",
            "      - Number of logs entries between snapshot.",
            "      - Docker default value is C(10000).",
            "    type: int",
            "  keep_old_snapshots:",
            "    description:",
            "      - Number of snapshots to keep beyond the current snapshot.",
            "      - Docker default value is C(0).",
            "    type: int",
            "  log_entries_for_slow_followers:",
            "    description:",
            "      - Number of log entries to keep around to sync up slow followers after a snapshot is created.",
            "    type: int",
            "  heartbeat_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) between each heartbeat.",
            "      - Docker default value is C(1s).",
            "    type: int",
            "  election_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) needed without a leader to trigger a new election.",
            "      - Docker default value is C(10s).",
            "    type: int",
            "  dispatcher_heartbeat_period:",
            "    description:",
            "      - The delay for an agent to send a heartbeat to the dispatcher.",
            "      - Docker default value is C(5s).",
            "    type: int",
            "  node_cert_expiry:",
            "    description:",
            "      - Automatic expiry for nodes certificates.",
            "      - Docker default value is C(3months).",
            "    type: int",
            "  name:",
            "    description:",
            "      - The name of the swarm.",
            "    type: str",
            "  labels:",
            "    description:",
            "      - User-defined key/value metadata.",
            "      - Label operations in this module apply to the docker swarm cluster.",
            "        Use M(docker_node) module to add/modify/remove swarm node labels.",
            "      - Requires API version >= 1.32.",
            "    type: dict",
            "  signing_ca_cert:",
            "    description:",
            "      - The desired signing CA certificate for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a certificate, but the contents of the certificate.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  signing_ca_key:",
            "    description:",
            "      - The desired signing CA key for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a key, but the contents of the key.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  ca_force_rotate:",
            "    description:",
            "      - An integer whose purpose is to force swarm to generate a new signing CA certificate and key,",
            "          if none have been specified.",
            "      - Docker default value is C(0).",
            "      - Requires API version >= 1.30.",
            "    type: int",
            "  autolock_managers:",
            "    description:",
            "      - If set, generate a key and use it to lock data stored on the managers.",
            "      - Docker default value is C(no).",
            "      - M(docker_swarm_info) can be used to retrieve the unlock key.",
            "    type: bool",
            "  rotate_worker_token:",
            "    description: Rotate the worker join token.",
            "    type: bool",
            "    default: no",
            "  rotate_manager_token:",
            "    description: Rotate the manager join token.",
            "    type: bool",
            "    default: no",
            "extends_documentation_fragment:",
            "  - docker",
            "  - docker.docker_py_1_documentation",
            "requirements:",
            "  - \"L(Docker SDK for Python,https://docker-py.readthedocs.io/en/stable/) >= 1.10.0 (use L(docker-py,https://pypi.org/project/docker-py/) for Python 2.6)\"",
            "  - Docker API >= 1.25",
            "author:",
            "  - Thierry Bouvet (@tbouvet)",
            "  - Piotr Wojciechowski (@WojciechowskiPiotr)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "- name: Init a new swarm with default parameters",
            "  docker_swarm:",
            "    state: present",
            "",
            "- name: Update swarm configuration",
            "  docker_swarm:",
            "    state: present",
            "    election_tick: 5",
            "",
            "- name: Add nodes",
            "  docker_swarm:",
            "    state: join",
            "    advertise_addr: 192.168.1.2",
            "    join_token: SWMTKN-1--xxxxx",
            "    remote_addrs: [ '192.168.1.1:2377' ]",
            "",
            "- name: Leave swarm for a node",
            "  docker_swarm:",
            "    state: absent",
            "",
            "- name: Remove a swarm manager",
            "  docker_swarm:",
            "    state: absent",
            "    force: true",
            "",
            "- name: Remove node from swarm",
            "  docker_swarm:",
            "    state: remove",
            "    node_id: mynode",
            "",
            "- name: Inspect swarm",
            "  docker_swarm:",
            "    state: inspect",
            "  register: swarm_info",
            "'''",
            "",
            "RETURN = '''",
            "swarm_facts:",
            "  description: Informations about swarm.",
            "  returned: success",
            "  type: dict",
            "  contains:",
            "      JoinTokens:",
            "          description: Tokens to connect to the Swarm.",
            "          returned: success",
            "          type: dict",
            "          contains:",
            "              Worker:",
            "                  description: Token to create a new *worker* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "              Manager:",
            "                  description: Token to create a new *manager* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "      UnlockKey:",
            "          description: The swarm unlock-key if I(autolock_managers) is C(true).",
            "          returned: on success if I(autolock_managers) is C(true)",
            "            and swarm is initialised, or if I(autolock_managers) has changed.",
            "          type: str",
            "          example: SWMKEY-1-xxx",
            "",
            "actions:",
            "  description: Provides the actions done on the swarm.",
            "  returned: when action failed.",
            "  type: list",
            "  elements: str",
            "  example: \"['This cluster is already a swarm cluster']\"",
            "",
            "'''",
            "",
            "import json",
            "import traceback",
            "",
            "try:",
            "    from docker.errors import DockerException, APIError",
            "except ImportError:",
            "    # missing Docker SDK for Python handled in ansible.module_utils.docker.common",
            "    pass",
            "",
            "from ansible.module_utils.docker.common import (",
            "    DockerBaseClass,",
            "    DifferenceTracker,",
            "    RequestException,",
            ")",
            "",
            "from ansible.module_utils.docker.swarm import AnsibleDockerSwarmClient",
            "",
            "from ansible.module_utils._text import to_native",
            "",
            "",
            "class TaskParameters(DockerBaseClass):",
            "    def __init__(self):",
            "        super(TaskParameters, self).__init__()",
            "",
            "        self.advertise_addr = None",
            "        self.listen_addr = None",
            "        self.remote_addrs = None",
            "        self.join_token = None",
            "",
            "        # Spec",
            "        self.snapshot_interval = None",
            "        self.task_history_retention_limit = None",
            "        self.keep_old_snapshots = None",
            "        self.log_entries_for_slow_followers = None",
            "        self.heartbeat_tick = None",
            "        self.election_tick = None",
            "        self.dispatcher_heartbeat_period = None",
            "        self.node_cert_expiry = None",
            "        self.name = None",
            "        self.labels = None",
            "        self.log_driver = None",
            "        self.signing_ca_cert = None",
            "        self.signing_ca_key = None",
            "        self.ca_force_rotate = None",
            "        self.autolock_managers = None",
            "        self.rotate_worker_token = None",
            "        self.rotate_manager_token = None",
            "        self.default_addr_pool = None",
            "        self.subnet_size = None",
            "",
            "    @staticmethod",
            "    def from_ansible_params(client):",
            "        result = TaskParameters()",
            "        for key, value in client.module.params.items():",
            "            if key in result.__dict__:",
            "                setattr(result, key, value)",
            "",
            "        result.update_parameters(client)",
            "        return result",
            "",
            "    def update_from_swarm_info(self, swarm_info):",
            "        spec = swarm_info['Spec']",
            "",
            "        ca_config = spec.get('CAConfig') or dict()",
            "        if self.node_cert_expiry is None:",
            "            self.node_cert_expiry = ca_config.get('NodeCertExpiry')",
            "        if self.ca_force_rotate is None:",
            "            self.ca_force_rotate = ca_config.get('ForceRotate')",
            "",
            "        dispatcher = spec.get('Dispatcher') or dict()",
            "        if self.dispatcher_heartbeat_period is None:",
            "            self.dispatcher_heartbeat_period = dispatcher.get('HeartbeatPeriod')",
            "",
            "        raft = spec.get('Raft') or dict()",
            "        if self.snapshot_interval is None:",
            "            self.snapshot_interval = raft.get('SnapshotInterval')",
            "        if self.keep_old_snapshots is None:",
            "            self.keep_old_snapshots = raft.get('KeepOldSnapshots')",
            "        if self.heartbeat_tick is None:",
            "            self.heartbeat_tick = raft.get('HeartbeatTick')",
            "        if self.log_entries_for_slow_followers is None:",
            "            self.log_entries_for_slow_followers = raft.get('LogEntriesForSlowFollowers')",
            "        if self.election_tick is None:",
            "            self.election_tick = raft.get('ElectionTick')",
            "",
            "        orchestration = spec.get('Orchestration') or dict()",
            "        if self.task_history_retention_limit is None:",
            "            self.task_history_retention_limit = orchestration.get('TaskHistoryRetentionLimit')",
            "",
            "        encryption_config = spec.get('EncryptionConfig') or dict()",
            "        if self.autolock_managers is None:",
            "            self.autolock_managers = encryption_config.get('AutoLockManagers')",
            "",
            "        if self.name is None:",
            "            self.name = spec['Name']",
            "",
            "        if self.labels is None:",
            "            self.labels = spec.get('Labels') or {}",
            "",
            "        if 'LogDriver' in spec['TaskDefaults']:",
            "            self.log_driver = spec['TaskDefaults']['LogDriver']",
            "",
            "    def update_parameters(self, client):",
            "        assign = dict(",
            "            snapshot_interval='snapshot_interval',",
            "            task_history_retention_limit='task_history_retention_limit',",
            "            keep_old_snapshots='keep_old_snapshots',",
            "            log_entries_for_slow_followers='log_entries_for_slow_followers',",
            "            heartbeat_tick='heartbeat_tick',",
            "            election_tick='election_tick',",
            "            dispatcher_heartbeat_period='dispatcher_heartbeat_period',",
            "            node_cert_expiry='node_cert_expiry',",
            "            name='name',",
            "            labels='labels',",
            "            signing_ca_cert='signing_ca_cert',",
            "            signing_ca_key='signing_ca_key',",
            "            ca_force_rotate='ca_force_rotate',",
            "            autolock_managers='autolock_managers',",
            "            log_driver='log_driver',",
            "        )",
            "        params = dict()",
            "        for dest, source in assign.items():",
            "            if not client.option_minimal_versions[source]['supported']:",
            "                continue",
            "            value = getattr(self, source)",
            "            if value is not None:",
            "                params[dest] = value",
            "        self.spec = client.create_swarm_spec(**params)",
            "",
            "    def compare_to_active(self, other, client, differences):",
            "        for k in self.__dict__:",
            "            if k in ('advertise_addr', 'listen_addr', 'remote_addrs', 'join_token',",
            "                     'rotate_worker_token', 'rotate_manager_token', 'spec',",
            "                     'default_addr_pool', 'subnet_size'):",
            "                continue",
            "            if not client.option_minimal_versions[k]['supported']:",
            "                continue",
            "            value = getattr(self, k)",
            "            if value is None:",
            "                continue",
            "            other_value = getattr(other, k)",
            "            if value != other_value:",
            "                differences.add(k, parameter=value, active=other_value)",
            "        if self.rotate_worker_token:",
            "            differences.add('rotate_worker_token', parameter=True, active=False)",
            "        if self.rotate_manager_token:",
            "            differences.add('rotate_manager_token', parameter=True, active=False)",
            "        return differences",
            "",
            "",
            "class SwarmManager(DockerBaseClass):",
            "",
            "    def __init__(self, client, results):",
            "",
            "        super(SwarmManager, self).__init__()",
            "",
            "        self.client = client",
            "        self.results = results",
            "        self.check_mode = self.client.check_mode",
            "        self.swarm_info = {}",
            "",
            "        self.state = client.module.params['state']",
            "        self.force = client.module.params['force']",
            "        self.node_id = client.module.params['node_id']",
            "",
            "        self.differences = DifferenceTracker()",
            "        self.parameters = TaskParameters.from_ansible_params(client)",
            "",
            "        self.created = False",
            "",
            "    def __call__(self):",
            "        choice_map = {",
            "            \"present\": self.init_swarm,",
            "            \"join\": self.join,",
            "            \"absent\": self.leave,",
            "            \"remove\": self.remove,",
            "            \"inspect\": self.inspect_swarm",
            "        }",
            "",
            "        if self.state == 'inspect':",
            "            self.client.module.deprecate(",
            "                \"The 'inspect' state is deprecated, please use 'docker_swarm_info' to inspect swarm cluster\",",
            "                version='2.12')",
            "",
            "        choice_map.get(self.state)()",
            "",
            "        if self.client.module._diff or self.parameters.debug:",
            "            diff = dict()",
            "            diff['before'], diff['after'] = self.differences.get_before_after()",
            "            self.results['diff'] = diff",
            "",
            "    def inspect_swarm(self):",
            "        try:",
            "            data = self.client.inspect_swarm()",
            "            json_str = json.dumps(data, ensure_ascii=False)",
            "            self.swarm_info = json.loads(json_str)",
            "",
            "            self.results['changed'] = False",
            "            self.results['swarm_facts'] = self.swarm_info",
            "",
            "            unlock_key = self.get_unlock_key()",
            "            self.swarm_info.update(unlock_key)",
            "        except APIError:",
            "            return",
            "",
            "    def get_unlock_key(self):",
            "        default = {'UnlockKey': None}",
            "        if not self.has_swarm_lock_changed():",
            "            return default",
            "        try:",
            "            return self.client.get_unlock_key() or default",
            "        except APIError:",
            "            return default",
            "",
            "    def has_swarm_lock_changed(self):",
            "        return self.parameters.autolock_managers and (",
            "            self.created or self.differences.has_difference_for('autolock_managers')",
            "        )",
            "",
            "    def init_swarm(self):",
            "        if not self.force and self.client.check_if_swarm_manager():",
            "            self.__update_swarm()",
            "            return",
            "",
            "        if not self.check_mode:",
            "            init_arguments = {",
            "                'advertise_addr': self.parameters.advertise_addr,",
            "                'listen_addr': self.parameters.listen_addr,",
            "                'force_new_cluster': self.force,",
            "                'swarm_spec': self.parameters.spec,",
            "            }",
            "            if self.parameters.default_addr_pool is not None:",
            "                init_arguments['default_addr_pool'] = self.parameters.default_addr_pool",
            "            if self.parameters.subnet_size is not None:",
            "                init_arguments['subnet_size'] = self.parameters.subnet_size",
            "            try:",
            "                self.client.init_swarm(**init_arguments)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not create a new Swarm Cluster: %s\" % to_native(exc))",
            "",
            "        if not self.client.check_if_swarm_manager():",
            "            if not self.check_mode:",
            "                self.client.fail(\"Swarm not created or other error!\")",
            "",
            "        self.created = True",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"New Swarm cluster created: %s\" % (self.swarm_info.get('ID')))",
            "        self.differences.add('state', parameter='present', active='absent')",
            "        self.results['changed'] = True",
            "        self.results['swarm_facts'] = {",
            "            'JoinTokens': self.swarm_info.get('JoinTokens'),",
            "            'UnlockKey': self.swarm_info.get('UnlockKey')",
            "        }",
            "",
            "    def __update_swarm(self):",
            "        try:",
            "            self.inspect_swarm()",
            "            version = self.swarm_info['Version']['Index']",
            "            self.parameters.update_from_swarm_info(self.swarm_info)",
            "            old_parameters = TaskParameters()",
            "            old_parameters.update_from_swarm_info(self.swarm_info)",
            "            self.parameters.compare_to_active(old_parameters, self.client, self.differences)",
            "            if self.differences.empty:",
            "                self.results['actions'].append(\"No modification\")",
            "                self.results['changed'] = False",
            "                return",
            "            update_parameters = TaskParameters.from_ansible_params(self.client)",
            "            update_parameters.update_parameters(self.client)",
            "            if not self.check_mode:",
            "                self.client.update_swarm(",
            "                    version=version, swarm_spec=update_parameters.spec,",
            "                    rotate_worker_token=self.parameters.rotate_worker_token,",
            "                    rotate_manager_token=self.parameters.rotate_manager_token)",
            "        except APIError as exc:",
            "            self.client.fail(\"Can not update a Swarm Cluster: %s\" % to_native(exc))",
            "            return",
            "",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"Swarm cluster updated\")",
            "        self.results['changed'] = True",
            "",
            "    def join(self):",
            "        if self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is already part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.join_swarm(",
            "                    remote_addrs=self.parameters.remote_addrs, join_token=self.parameters.join_token,",
            "                    listen_addr=self.parameters.listen_addr, advertise_addr=self.parameters.advertise_addr)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not join the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"New node is added to swarm cluster\")",
            "        self.differences.add('joined', parameter=True, active=False)",
            "        self.results['changed'] = True",
            "",
            "    def leave(self):",
            "        if not self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is not part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.leave_swarm(force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"This node can not leave the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node has left the swarm cluster\")",
            "        self.differences.add('joined', parameter='absent', active='present')",
            "        self.results['changed'] = True",
            "",
            "    def remove(self):",
            "        if not self.client.check_if_swarm_manager():",
            "            self.client.fail(\"This node is not a manager.\")",
            "",
            "        try:",
            "            status_down = self.client.check_if_swarm_node_is_down(node_id=self.node_id, repeat_check=5)",
            "        except APIError:",
            "            return",
            "",
            "        if not status_down:",
            "            self.client.fail(\"Can not remove the node. The status node is ready and not down.\")",
            "",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.remove_node(node_id=self.node_id, force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not remove the node from the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node is removed from swarm cluster.\")",
            "        self.differences.add('joined', parameter=False, active=True)",
            "        self.results['changed'] = True",
            "",
            "",
            "def _detect_remove_operation(client):",
            "    return client.module.params['state'] == 'remove'",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        advertise_addr=dict(type='str'),",
            "        state=dict(type='str', default='present', choices=['present', 'join', 'absent', 'remove', 'inspect']),",
            "        force=dict(type='bool', default=False),",
            "        listen_addr=dict(type='str', default='0.0.0.0:2377'),",
            "        remote_addrs=dict(type='list', elements='str'),",
            "        join_token=dict(type='str'),",
            "        snapshot_interval=dict(type='int'),",
            "        task_history_retention_limit=dict(type='int'),",
            "        keep_old_snapshots=dict(type='int'),",
            "        log_entries_for_slow_followers=dict(type='int'),",
            "        heartbeat_tick=dict(type='int'),",
            "        election_tick=dict(type='int'),",
            "        dispatcher_heartbeat_period=dict(type='int'),",
            "        node_cert_expiry=dict(type='int'),",
            "        name=dict(type='str'),",
            "        labels=dict(type='dict'),",
            "        signing_ca_cert=dict(type='str'),",
            "        signing_ca_key=dict(type='str', no_log=True),",
            "        ca_force_rotate=dict(type='int'),",
            "        autolock_managers=dict(type='bool'),",
            "        node_id=dict(type='str'),",
            "        rotate_worker_token=dict(type='bool', default=False),",
            "        rotate_manager_token=dict(type='bool', default=False),",
            "        default_addr_pool=dict(type='list', elements='str'),",
            "        subnet_size=dict(type='int'),",
            "    )",
            "",
            "    required_if = [",
            "        ('state', 'join', ['advertise_addr', 'remote_addrs', 'join_token']),",
            "        ('state', 'remove', ['node_id'])",
            "    ]",
            "",
            "    option_minimal_versions = dict(",
            "        labels=dict(docker_py_version='2.6.0', docker_api_version='1.32'),",
            "        signing_ca_cert=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        signing_ca_key=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        ca_force_rotate=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        autolock_managers=dict(docker_py_version='2.6.0'),",
            "        log_driver=dict(docker_py_version='2.6.0'),",
            "        remove_operation=dict(",
            "            docker_py_version='2.4.0',",
            "            detect_usage=_detect_remove_operation,",
            "            usage_msg='remove swarm nodes'",
            "        ),",
            "        default_addr_pool=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "        subnet_size=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "    )",
            "",
            "    client = AnsibleDockerSwarmClient(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "        required_if=required_if,",
            "        min_docker_version='1.10.0',",
            "        min_docker_api_version='1.25',",
            "        option_minimal_versions=option_minimal_versions,",
            "    )",
            "",
            "    try:",
            "        results = dict(",
            "            changed=False,",
            "            result='',",
            "            actions=[]",
            "        )",
            "",
            "        SwarmManager(client, results)()",
            "        client.module.exit_json(**results)",
            "    except DockerException as e:",
            "        client.fail('An unexpected docker error occurred: {0}'.format(e), exception=traceback.format_exc())",
            "    except RequestException as e:",
            "        client.fail('An unexpected requests error occurred when docker-py tried to talk to the docker daemon: {0}'.format(e), exception=traceback.format_exc())",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "625": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_backend_service.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 732,
                "afterPatchRowNumber": 732,
                "PatchRowcode": "             health_checks=dict(required=True, type='list', elements='str'),"
            },
            "1": {
                "beforePatchRowNumber": 733,
                "afterPatchRowNumber": 733,
                "PatchRowcode": "             iap=dict("
            },
            "2": {
                "beforePatchRowNumber": 734,
                "afterPatchRowNumber": 734,
                "PatchRowcode": "                 type='dict',"
            },
            "3": {
                "beforePatchRowNumber": 735,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                options=dict(enabled=dict(type='bool'), oauth2_client_id=dict(required=True, type='str'), oauth2_client_secret=dict(required=True, type='str')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 735,
                "PatchRowcode": "+                options=dict("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 736,
                "PatchRowcode": "+                    enabled=dict(type='bool'),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 737,
                "PatchRowcode": "+                    oauth2_client_id=dict(required=True, type='str'),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 738,
                "PatchRowcode": "+                    oauth2_client_secret=dict(required=True, type='str', no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 739,
                "PatchRowcode": "+                ),"
            },
            "9": {
                "beforePatchRowNumber": 736,
                "afterPatchRowNumber": 740,
                "PatchRowcode": "             ),"
            },
            "10": {
                "beforePatchRowNumber": 737,
                "afterPatchRowNumber": 741,
                "PatchRowcode": "             load_balancing_scheme=dict(default='EXTERNAL', type='str'),"
            },
            "11": {
                "beforePatchRowNumber": 738,
                "afterPatchRowNumber": 742,
                "PatchRowcode": "             name=dict(required=True, type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_backend_service",
            "description:",
            "- A Backend Service defines a group of virtual machines that will serve traffic for",
            "  load balancing. This resource is a global backend service, appropriate for external",
            "  load balancing or self-managed internal load balancing.",
            "- For managed internal load balancing, use a regional backend service instead.",
            "- Currently self-managed internal load balancing is only available in beta.",
            "short_description: Creates a GCP BackendService",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  affinity_cookie_ttl_sec:",
            "    description:",
            "    - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "      to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "      session (or equivalent). The maximum allowed value for TTL is one day.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "    type: int",
            "  backends:",
            "    description:",
            "    - The set of backends that serve this BackendService.",
            "    required: false",
            "    type: list",
            "    suboptions:",
            "      balancing_mode:",
            "        description:",
            "        - Specifies the balancing mode for this backend.",
            "        - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "          Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "        - 'Some valid choices include: \"UTILIZATION\", \"RATE\", \"CONNECTION\"'",
            "        required: false",
            "        default: UTILIZATION",
            "        type: str",
            "      capacity_scaler:",
            "        description:",
            "        - A multiplier applied to the group's maximum servicing capacity (based on",
            "          UTILIZATION, RATE or CONNECTION).",
            "        - Default value is 1, which means the group will serve up to 100% of its configured",
            "          capacity (depending on balancingMode). A setting of 0 means the group is",
            "          completely drained, offering 0% of its available Capacity. Valid range is",
            "          [0.0,1.0].",
            "        required: false",
            "        default: '1.0'",
            "        type: str",
            "      description:",
            "        description:",
            "        - An optional description of this resource.",
            "        - Provide this property when you create the resource.",
            "        required: false",
            "        type: str",
            "      group:",
            "        description:",
            "        - The fully-qualified URL of an Instance Group or Network Endpoint Group resource.",
            "          In case of instance group this defines the list of instances that serve",
            "          traffic. Member virtual machine instances from each instance group must",
            "          live in the same zone as the instance group itself. No two backends in a",
            "          backend service are allowed to use same Instance Group resource.",
            "        - For Network Endpoint Groups this defines list of endpoints. All endpoints",
            "          of Network Endpoint Group must be hosted on instances located in the same",
            "          zone as the Network Endpoint Group.",
            "        - Backend service can not contain mix of Instance Group and Network Endpoint",
            "          Group backends.",
            "        - Note that you must specify an Instance Group or Network Endpoint Group resource",
            "          using the fully-qualified URL, rather than a partial URL.",
            "        required: false",
            "        type: str",
            "      max_connections:",
            "        description:",
            "        - The max number of simultaneous connections for the group. Can be used with",
            "          either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or one of maxConnectionsPerInstance",
            "          or maxConnectionsPerEndpoint, as appropriate for group type, must be set.",
            "        required: false",
            "        type: int",
            "      max_connections_per_instance:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend instance",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        required: false",
            "        type: int",
            "      max_connections_per_endpoint:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend network",
            "          endpoint can handle. This is used to calculate the capacity of the group.",
            "          Can be used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerEndpoint",
            "          must be set.",
            "        required: false",
            "        type: int",
            "        version_added: 2.9",
            "      max_rate:",
            "        description:",
            "        - The max requests per second (RPS) of the group.",
            "        - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "          if RATE mode. For RATE mode, either maxRate or one of maxRatePerInstance",
            "          or maxRatePerEndpoint, as appropriate for group type, must be set.",
            "        required: false",
            "        type: int",
            "      max_rate_per_instance:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend instance can handle.",
            "          This is used to calculate the capacity of the group. Can be used in either",
            "          balancing mode. For RATE mode, either maxRate or maxRatePerInstance must",
            "          be set.",
            "        required: false",
            "        type: str",
            "      max_rate_per_endpoint:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend network endpoint",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either balancing mode. For RATE mode, either maxRate or maxRatePerEndpoint",
            "          must be set.",
            "        required: false",
            "        type: str",
            "        version_added: 2.9",
            "      max_utilization:",
            "        description:",
            "        - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "          target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "        required: false",
            "        default: '0.8'",
            "        type: str",
            "  cdn_policy:",
            "    description:",
            "    - Cloud CDN configuration for this BackendService.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      cache_key_policy:",
            "        description:",
            "        - The CacheKeyPolicy for this CdnPolicy.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          include_host:",
            "            description:",
            "            - If true requests to different hosts will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_protocol:",
            "            description:",
            "            - If true, http and https requests will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_query_string:",
            "            description:",
            "            - If true, include query string parameters in the cache key according",
            "              to query_string_whitelist and query_string_blacklist. If neither is",
            "              set, the entire query string will be included.",
            "            - If false, the query string will be excluded from the cache key entirely.",
            "            required: false",
            "            type: bool",
            "          query_string_blacklist:",
            "            description:",
            "            - Names of query string parameters to exclude in cache keys.",
            "            - All other parameters will be included. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "            type: list",
            "          query_string_whitelist:",
            "            description:",
            "            - Names of query string parameters to include in cache keys.",
            "            - All other parameters will be excluded. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "            type: list",
            "      signed_url_cache_max_age_sec:",
            "        description:",
            "        - Maximum number of seconds the response to a signed URL request will be considered",
            "          fresh, defaults to 1hr (3600s). After this time period, the response will",
            "          be revalidated before being served.",
            "        - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "          behave as though all responses from this backend had a \"Cache-Control: public,",
            "          max-age=[TTL]\" header, regardless of any existing Cache-Control header.",
            "          The actual headers served in responses will not be altered.'",
            "        required: false",
            "        default: '3600'",
            "        type: int",
            "        version_added: 2.8",
            "  connection_draining:",
            "    description:",
            "    - Settings for connection draining .",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      draining_timeout_sec:",
            "        description:",
            "        - Time for which instance will be drained (not accept new connections, but",
            "          still work to finish started).",
            "        required: false",
            "        default: '300'",
            "        type: int",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  enable_cdn:",
            "    description:",
            "    - If true, enable Cloud CDN for this BackendService.",
            "    required: false",
            "    type: bool",
            "  health_checks:",
            "    description:",
            "    - The set of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "      checking this BackendService. Currently at most one health check can be specified,",
            "      and a health check is required.",
            "    - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "      instead.",
            "    required: true",
            "    type: list",
            "  iap:",
            "    description:",
            "    - Settings for enabling Cloud Identity Aware Proxy.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.7",
            "    suboptions:",
            "      enabled:",
            "        description:",
            "        - Enables IAP.",
            "        required: false",
            "        type: bool",
            "      oauth2_client_id:",
            "        description:",
            "        - OAuth2 Client ID for IAP .",
            "        required: true",
            "        type: str",
            "      oauth2_client_secret:",
            "        description:",
            "        - OAuth2 Client Secret for IAP .",
            "        required: true",
            "        type: str",
            "  load_balancing_scheme:",
            "    description:",
            "    - Indicates whether the backend service will be used with internal or external",
            "      load balancing. A backend service created for one type of load balancing cannot",
            "      be used with the other. Must be `EXTERNAL` or `INTERNAL_SELF_MANAGED` for a",
            "      global backend service. Defaults to `EXTERNAL`.",
            "    - 'Some valid choices include: \"EXTERNAL\", \"INTERNAL_SELF_MANAGED\"'",
            "    required: false",
            "    default: EXTERNAL",
            "    type: str",
            "    version_added: 2.7",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  port_name:",
            "    description:",
            "    - Name of backend port. The same name should appear in the instance groups referenced",
            "      by this service. Required when the load balancing scheme is EXTERNAL.",
            "    required: false",
            "    type: str",
            "  protocol:",
            "    description:",
            "    - The protocol this BackendService uses to communicate with backends.",
            "    - 'Possible values are HTTP, HTTPS, HTTP2, TCP, and SSL. The default is HTTP.",
            "      **NOTE**: HTTP2 is only valid for beta HTTP/2 load balancer types and may result",
            "      in errors if used with the GA API.'",
            "    - 'Some valid choices include: \"HTTP\", \"HTTPS\", \"HTTP2\", \"TCP\", \"SSL\"'",
            "    required: false",
            "    type: str",
            "  security_policy:",
            "    description:",
            "    - The security policy associated with this backend service.",
            "    required: false",
            "    type: str",
            "    version_added: 2.8",
            "  session_affinity:",
            "    description:",
            "    - Type of session affinity to use. The default is NONE.",
            "    - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "    - When the protocol is UDP, this field is not used.",
            "    - 'Some valid choices include: \"NONE\", \"CLIENT_IP\", \"GENERATED_COOKIE\"'",
            "    required: false",
            "    type: str",
            "  timeout_sec:",
            "    description:",
            "    - How many seconds to wait for the backend before considering it a failed request.",
            "      Default is 30 seconds. Valid range is [1, 86400].",
            "    required: false",
            "    type: int",
            "    aliases:",
            "    - timeout_seconds",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/backendServices)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/load-balancing/http/backend-service)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance group",
            "  gcp_compute_instance_group:",
            "    name: instancegroup-backendservice",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: instancegroup",
            "",
            "- name: create a HTTP health check",
            "  gcp_compute_http_health_check:",
            "    name: httphealthcheck-backendservice",
            "    healthy_threshold: 10",
            "    port: 8080",
            "    timeout_sec: 2",
            "    unhealthy_threshold: 5",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: healthcheck",
            "",
            "- name: create a backend service",
            "  gcp_compute_backend_service:",
            "    name: test_object",
            "    backends:",
            "    - group: \"{{ instancegroup.selfLink }}\"",
            "    health_checks:",
            "    - \"{{ healthcheck.selfLink }}\"",
            "    enable_cdn: 'true'",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "affinityCookieTtlSec:",
            "  description:",
            "  - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "    to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "    session (or equivalent). The maximum allowed value for TTL is one day.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: int",
            "backends:",
            "  description:",
            "  - The set of backends that serve this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    balancingMode:",
            "      description:",
            "      - Specifies the balancing mode for this backend.",
            "      - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "        Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "      returned: success",
            "      type: str",
            "    capacityScaler:",
            "      description:",
            "      - A multiplier applied to the group's maximum servicing capacity (based on UTILIZATION,",
            "        RATE or CONNECTION).",
            "      - Default value is 1, which means the group will serve up to 100% of its configured",
            "        capacity (depending on balancingMode). A setting of 0 means the group is completely",
            "        drained, offering 0% of its available Capacity. Valid range is [0.0,1.0].",
            "      returned: success",
            "      type: str",
            "    description:",
            "      description:",
            "      - An optional description of this resource.",
            "      - Provide this property when you create the resource.",
            "      returned: success",
            "      type: str",
            "    group:",
            "      description:",
            "      - The fully-qualified URL of an Instance Group or Network Endpoint Group resource.",
            "        In case of instance group this defines the list of instances that serve traffic.",
            "        Member virtual machine instances from each instance group must live in the",
            "        same zone as the instance group itself. No two backends in a backend service",
            "        are allowed to use same Instance Group resource.",
            "      - For Network Endpoint Groups this defines list of endpoints. All endpoints",
            "        of Network Endpoint Group must be hosted on instances located in the same",
            "        zone as the Network Endpoint Group.",
            "      - Backend service can not contain mix of Instance Group and Network Endpoint",
            "        Group backends.",
            "      - Note that you must specify an Instance Group or Network Endpoint Group resource",
            "        using the fully-qualified URL, rather than a partial URL.",
            "      returned: success",
            "      type: str",
            "    maxConnections:",
            "      description:",
            "      - The max number of simultaneous connections for the group. Can be used with",
            "        either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or one of maxConnectionsPerInstance",
            "        or maxConnectionsPerEndpoint, as appropriate for group type, must be set.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerInstance:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend instance",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerEndpoint:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend network endpoint",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerEndpoint must",
            "        be set.",
            "      returned: success",
            "      type: int",
            "    maxRate:",
            "      description:",
            "      - The max requests per second (RPS) of the group.",
            "      - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "        if RATE mode. For RATE mode, either maxRate or one of maxRatePerInstance or",
            "        maxRatePerEndpoint, as appropriate for group type, must be set.",
            "      returned: success",
            "      type: int",
            "    maxRatePerInstance:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend instance can handle.",
            "        This is used to calculate the capacity of the group. Can be used in either",
            "        balancing mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      returned: success",
            "      type: str",
            "    maxRatePerEndpoint:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend network endpoint can",
            "        handle. This is used to calculate the capacity of the group. Can be used in",
            "        either balancing mode. For RATE mode, either maxRate or maxRatePerEndpoint",
            "        must be set.",
            "      returned: success",
            "      type: str",
            "    maxUtilization:",
            "      description:",
            "      - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "        target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "      returned: success",
            "      type: str",
            "cdnPolicy:",
            "  description:",
            "  - Cloud CDN configuration for this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    cacheKeyPolicy:",
            "      description:",
            "      - The CacheKeyPolicy for this CdnPolicy.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        includeHost:",
            "          description:",
            "          - If true requests to different hosts will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeProtocol:",
            "          description:",
            "          - If true, http and https requests will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeQueryString:",
            "          description:",
            "          - If true, include query string parameters in the cache key according to",
            "            query_string_whitelist and query_string_blacklist. If neither is set,",
            "            the entire query string will be included.",
            "          - If false, the query string will be excluded from the cache key entirely.",
            "          returned: success",
            "          type: bool",
            "        queryStringBlacklist:",
            "          description:",
            "          - Names of query string parameters to exclude in cache keys.",
            "          - All other parameters will be included. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "        queryStringWhitelist:",
            "          description:",
            "          - Names of query string parameters to include in cache keys.",
            "          - All other parameters will be excluded. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "    signedUrlCacheMaxAgeSec:",
            "      description:",
            "      - Maximum number of seconds the response to a signed URL request will be considered",
            "        fresh, defaults to 1hr (3600s). After this time period, the response will",
            "        be revalidated before being served.",
            "      - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "        behave as though all responses from this backend had a \"Cache-Control: public,",
            "        max-age=[TTL]\" header, regardless of any existing Cache-Control header. The",
            "        actual headers served in responses will not be altered.'",
            "      returned: success",
            "      type: int",
            "connectionDraining:",
            "  description:",
            "  - Settings for connection draining .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    drainingTimeoutSec:",
            "      description:",
            "      - Time for which instance will be drained (not accept new connections, but still",
            "        work to finish started).",
            "      returned: success",
            "      type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "fingerprint:",
            "  description:",
            "  - Fingerprint of this resource. A hash of the contents stored in this object. This",
            "    field is used in optimistic locking.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "enableCDN:",
            "  description:",
            "  - If true, enable Cloud CDN for this BackendService.",
            "  returned: success",
            "  type: bool",
            "healthChecks:",
            "  description:",
            "  - The set of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "    checking this BackendService. Currently at most one health check can be specified,",
            "    and a health check is required.",
            "  - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "    instead.",
            "  returned: success",
            "  type: list",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "iap:",
            "  description:",
            "  - Settings for enabling Cloud Identity Aware Proxy.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    enabled:",
            "      description:",
            "      - Enables IAP.",
            "      returned: success",
            "      type: bool",
            "    oauth2ClientId:",
            "      description:",
            "      - OAuth2 Client ID for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecret:",
            "      description:",
            "      - OAuth2 Client Secret for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecretSha256:",
            "      description:",
            "      - OAuth2 Client Secret SHA-256 for IAP .",
            "      returned: success",
            "      type: str",
            "loadBalancingScheme:",
            "  description:",
            "  - Indicates whether the backend service will be used with internal or external load",
            "    balancing. A backend service created for one type of load balancing cannot be",
            "    used with the other. Must be `EXTERNAL` or `INTERNAL_SELF_MANAGED` for a global",
            "    backend service. Defaults to `EXTERNAL`.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "portName:",
            "  description:",
            "  - Name of backend port. The same name should appear in the instance groups referenced",
            "    by this service. Required when the load balancing scheme is EXTERNAL.",
            "  returned: success",
            "  type: str",
            "protocol:",
            "  description:",
            "  - The protocol this BackendService uses to communicate with backends.",
            "  - 'Possible values are HTTP, HTTPS, HTTP2, TCP, and SSL. The default is HTTP. **NOTE**:",
            "    HTTP2 is only valid for beta HTTP/2 load balancer types and may result in errors",
            "    if used with the GA API.'",
            "  returned: success",
            "  type: str",
            "securityPolicy:",
            "  description:",
            "  - The security policy associated with this backend service.",
            "  returned: success",
            "  type: str",
            "sessionAffinity:",
            "  description:",
            "  - Type of session affinity to use. The default is NONE.",
            "  - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "  - When the protocol is UDP, this field is not used.",
            "  returned: success",
            "  type: str",
            "timeoutSec:",
            "  description:",
            "  - How many seconds to wait for the backend before considering it a failed request.",
            "    Default is 30 seconds. Valid range is [1, 86400].",
            "  returned: success",
            "  type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            affinity_cookie_ttl_sec=dict(type='int'),",
            "            backends=dict(",
            "                type='list',",
            "                elements='dict',",
            "                options=dict(",
            "                    balancing_mode=dict(default='UTILIZATION', type='str'),",
            "                    capacity_scaler=dict(default=1.0, type='str'),",
            "                    description=dict(type='str'),",
            "                    group=dict(type='str'),",
            "                    max_connections=dict(type='int'),",
            "                    max_connections_per_instance=dict(type='int'),",
            "                    max_connections_per_endpoint=dict(type='int'),",
            "                    max_rate=dict(type='int'),",
            "                    max_rate_per_instance=dict(type='str'),",
            "                    max_rate_per_endpoint=dict(type='str'),",
            "                    max_utilization=dict(default=0.8, type='str'),",
            "                ),",
            "            ),",
            "            cdn_policy=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    cache_key_policy=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            include_host=dict(type='bool'),",
            "                            include_protocol=dict(type='bool'),",
            "                            include_query_string=dict(type='bool'),",
            "                            query_string_blacklist=dict(type='list', elements='str'),",
            "                            query_string_whitelist=dict(type='list', elements='str'),",
            "                        ),",
            "                    ),",
            "                    signed_url_cache_max_age_sec=dict(default=3600, type='int'),",
            "                ),",
            "            ),",
            "            connection_draining=dict(type='dict', options=dict(draining_timeout_sec=dict(default=300, type='int'))),",
            "            description=dict(type='str'),",
            "            enable_cdn=dict(type='bool'),",
            "            health_checks=dict(required=True, type='list', elements='str'),",
            "            iap=dict(",
            "                type='dict',",
            "                options=dict(enabled=dict(type='bool'), oauth2_client_id=dict(required=True, type='str'), oauth2_client_secret=dict(required=True, type='str')),",
            "            ),",
            "            load_balancing_scheme=dict(default='EXTERNAL', type='str'),",
            "            name=dict(required=True, type='str'),",
            "            port_name=dict(type='str'),",
            "            protocol=dict(type='str'),",
            "            security_policy=dict(type='str'),",
            "            session_affinity=dict(type='str'),",
            "            timeout_sec=dict(type='int', aliases=['timeout_seconds']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#backendService'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('securityPolicy') != request.get('securityPolicy'):",
            "        security_policy_update(module, request, response)",
            "",
            "",
            "def security_policy_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/backendServices/{name}/setSecurityPolicy\"]).format(**module.params),",
            "        {u'securityPolicy': module.params.get('security_policy')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#backendService',",
            "        u'affinityCookieTtlSec': module.params.get('affinity_cookie_ttl_sec'),",
            "        u'backends': BackendServiceBackendsArray(module.params.get('backends', []), module).to_request(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(module.params.get('cdn_policy', {}), module).to_request(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(module.params.get('connection_draining', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'enableCDN': module.params.get('enable_cdn'),",
            "        u'healthChecks': module.params.get('health_checks'),",
            "        u'iap': BackendServiceIap(module.params.get('iap', {}), module).to_request(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': module.params.get('port_name'),",
            "        u'protocol': module.params.get('protocol'),",
            "        u'securityPolicy': module.params.get('security_policy'),",
            "        u'sessionAffinity': module.params.get('session_affinity'),",
            "        u'timeoutSec': module.params.get('timeout_sec'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'affinityCookieTtlSec': response.get(u'affinityCookieTtlSec'),",
            "        u'backends': BackendServiceBackendsArray(response.get(u'backends', []), module).from_response(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(response.get(u'cdnPolicy', {}), module).from_response(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(response.get(u'connectionDraining', {}), module).from_response(),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'fingerprint': response.get(u'fingerprint'),",
            "        u'description': response.get(u'description'),",
            "        u'enableCDN': response.get(u'enableCDN'),",
            "        u'healthChecks': response.get(u'healthChecks'),",
            "        u'id': response.get(u'id'),",
            "        u'iap': BackendServiceIap(response.get(u'iap', {}), module).from_response(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': response.get(u'portName'),",
            "        u'protocol': response.get(u'protocol'),",
            "        u'securityPolicy': response.get(u'securityPolicy'),",
            "        u'sessionAffinity': response.get(u'sessionAffinity'),",
            "        u'timeoutSec': response.get(u'timeoutSec'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#backendService')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class BackendServiceBackendsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get('balancing_mode'),",
            "                u'capacityScaler': item.get('capacity_scaler'),",
            "                u'description': item.get('description'),",
            "                u'group': item.get('group'),",
            "                u'maxConnections': item.get('max_connections'),",
            "                u'maxConnectionsPerInstance': item.get('max_connections_per_instance'),",
            "                u'maxConnectionsPerEndpoint': item.get('max_connections_per_endpoint'),",
            "                u'maxRate': item.get('max_rate'),",
            "                u'maxRatePerInstance': item.get('max_rate_per_instance'),",
            "                u'maxRatePerEndpoint': item.get('max_rate_per_endpoint'),",
            "                u'maxUtilization': item.get('max_utilization'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get(u'balancingMode'),",
            "                u'capacityScaler': item.get(u'capacityScaler'),",
            "                u'description': item.get(u'description'),",
            "                u'group': item.get(u'group'),",
            "                u'maxConnections': item.get(u'maxConnections'),",
            "                u'maxConnectionsPerInstance': item.get(u'maxConnectionsPerInstance'),",
            "                u'maxConnectionsPerEndpoint': item.get(u'maxConnectionsPerEndpoint'),",
            "                u'maxRate': item.get(u'maxRate'),",
            "                u'maxRatePerInstance': item.get(u'maxRatePerInstance'),",
            "                u'maxRatePerEndpoint': item.get(u'maxRatePerEndpoint'),",
            "                u'maxUtilization': item.get(u'maxUtilization'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCdnpolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get('cache_key_policy', {}), self.module).to_request(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get('signed_url_cache_max_age_sec'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get(u'cacheKeyPolicy', {}), self.module).from_response(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get(u'signedUrlCacheMaxAgeSec'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCachekeypolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get('include_host'),",
            "                u'includeProtocol': self.request.get('include_protocol'),",
            "                u'includeQueryString': self.request.get('include_query_string'),",
            "                u'queryStringBlacklist': self.request.get('query_string_blacklist'),",
            "                u'queryStringWhitelist': self.request.get('query_string_whitelist'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get(u'includeHost'),",
            "                u'includeProtocol': self.request.get(u'includeProtocol'),",
            "                u'includeQueryString': self.request.get(u'includeQueryString'),",
            "                u'queryStringBlacklist': self.request.get(u'queryStringBlacklist'),",
            "                u'queryStringWhitelist': self.request.get(u'queryStringWhitelist'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceConnectiondraining(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get('draining_timeout_sec')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get(u'drainingTimeoutSec')})",
            "",
            "",
            "class BackendServiceIap(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get('enabled'),",
            "                u'oauth2ClientId': self.request.get('oauth2_client_id'),",
            "                u'oauth2ClientSecret': self.request.get('oauth2_client_secret'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get(u'enabled'),",
            "                u'oauth2ClientId': self.request.get(u'oauth2ClientId'),",
            "                u'oauth2ClientSecret': self.request.get(u'oauth2ClientSecret'),",
            "            }",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_backend_service",
            "description:",
            "- A Backend Service defines a group of virtual machines that will serve traffic for",
            "  load balancing. This resource is a global backend service, appropriate for external",
            "  load balancing or self-managed internal load balancing.",
            "- For managed internal load balancing, use a regional backend service instead.",
            "- Currently self-managed internal load balancing is only available in beta.",
            "short_description: Creates a GCP BackendService",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  affinity_cookie_ttl_sec:",
            "    description:",
            "    - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "      to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "      session (or equivalent). The maximum allowed value for TTL is one day.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "    type: int",
            "  backends:",
            "    description:",
            "    - The set of backends that serve this BackendService.",
            "    required: false",
            "    type: list",
            "    suboptions:",
            "      balancing_mode:",
            "        description:",
            "        - Specifies the balancing mode for this backend.",
            "        - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "          Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "        - 'Some valid choices include: \"UTILIZATION\", \"RATE\", \"CONNECTION\"'",
            "        required: false",
            "        default: UTILIZATION",
            "        type: str",
            "      capacity_scaler:",
            "        description:",
            "        - A multiplier applied to the group's maximum servicing capacity (based on",
            "          UTILIZATION, RATE or CONNECTION).",
            "        - Default value is 1, which means the group will serve up to 100% of its configured",
            "          capacity (depending on balancingMode). A setting of 0 means the group is",
            "          completely drained, offering 0% of its available Capacity. Valid range is",
            "          [0.0,1.0].",
            "        required: false",
            "        default: '1.0'",
            "        type: str",
            "      description:",
            "        description:",
            "        - An optional description of this resource.",
            "        - Provide this property when you create the resource.",
            "        required: false",
            "        type: str",
            "      group:",
            "        description:",
            "        - The fully-qualified URL of an Instance Group or Network Endpoint Group resource.",
            "          In case of instance group this defines the list of instances that serve",
            "          traffic. Member virtual machine instances from each instance group must",
            "          live in the same zone as the instance group itself. No two backends in a",
            "          backend service are allowed to use same Instance Group resource.",
            "        - For Network Endpoint Groups this defines list of endpoints. All endpoints",
            "          of Network Endpoint Group must be hosted on instances located in the same",
            "          zone as the Network Endpoint Group.",
            "        - Backend service can not contain mix of Instance Group and Network Endpoint",
            "          Group backends.",
            "        - Note that you must specify an Instance Group or Network Endpoint Group resource",
            "          using the fully-qualified URL, rather than a partial URL.",
            "        required: false",
            "        type: str",
            "      max_connections:",
            "        description:",
            "        - The max number of simultaneous connections for the group. Can be used with",
            "          either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or one of maxConnectionsPerInstance",
            "          or maxConnectionsPerEndpoint, as appropriate for group type, must be set.",
            "        required: false",
            "        type: int",
            "      max_connections_per_instance:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend instance",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        required: false",
            "        type: int",
            "      max_connections_per_endpoint:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend network",
            "          endpoint can handle. This is used to calculate the capacity of the group.",
            "          Can be used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerEndpoint",
            "          must be set.",
            "        required: false",
            "        type: int",
            "        version_added: 2.9",
            "      max_rate:",
            "        description:",
            "        - The max requests per second (RPS) of the group.",
            "        - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "          if RATE mode. For RATE mode, either maxRate or one of maxRatePerInstance",
            "          or maxRatePerEndpoint, as appropriate for group type, must be set.",
            "        required: false",
            "        type: int",
            "      max_rate_per_instance:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend instance can handle.",
            "          This is used to calculate the capacity of the group. Can be used in either",
            "          balancing mode. For RATE mode, either maxRate or maxRatePerInstance must",
            "          be set.",
            "        required: false",
            "        type: str",
            "      max_rate_per_endpoint:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend network endpoint",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either balancing mode. For RATE mode, either maxRate or maxRatePerEndpoint",
            "          must be set.",
            "        required: false",
            "        type: str",
            "        version_added: 2.9",
            "      max_utilization:",
            "        description:",
            "        - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "          target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "        required: false",
            "        default: '0.8'",
            "        type: str",
            "  cdn_policy:",
            "    description:",
            "    - Cloud CDN configuration for this BackendService.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      cache_key_policy:",
            "        description:",
            "        - The CacheKeyPolicy for this CdnPolicy.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          include_host:",
            "            description:",
            "            - If true requests to different hosts will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_protocol:",
            "            description:",
            "            - If true, http and https requests will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_query_string:",
            "            description:",
            "            - If true, include query string parameters in the cache key according",
            "              to query_string_whitelist and query_string_blacklist. If neither is",
            "              set, the entire query string will be included.",
            "            - If false, the query string will be excluded from the cache key entirely.",
            "            required: false",
            "            type: bool",
            "          query_string_blacklist:",
            "            description:",
            "            - Names of query string parameters to exclude in cache keys.",
            "            - All other parameters will be included. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "            type: list",
            "          query_string_whitelist:",
            "            description:",
            "            - Names of query string parameters to include in cache keys.",
            "            - All other parameters will be excluded. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "            type: list",
            "      signed_url_cache_max_age_sec:",
            "        description:",
            "        - Maximum number of seconds the response to a signed URL request will be considered",
            "          fresh, defaults to 1hr (3600s). After this time period, the response will",
            "          be revalidated before being served.",
            "        - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "          behave as though all responses from this backend had a \"Cache-Control: public,",
            "          max-age=[TTL]\" header, regardless of any existing Cache-Control header.",
            "          The actual headers served in responses will not be altered.'",
            "        required: false",
            "        default: '3600'",
            "        type: int",
            "        version_added: 2.8",
            "  connection_draining:",
            "    description:",
            "    - Settings for connection draining .",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      draining_timeout_sec:",
            "        description:",
            "        - Time for which instance will be drained (not accept new connections, but",
            "          still work to finish started).",
            "        required: false",
            "        default: '300'",
            "        type: int",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  enable_cdn:",
            "    description:",
            "    - If true, enable Cloud CDN for this BackendService.",
            "    required: false",
            "    type: bool",
            "  health_checks:",
            "    description:",
            "    - The set of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "      checking this BackendService. Currently at most one health check can be specified,",
            "      and a health check is required.",
            "    - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "      instead.",
            "    required: true",
            "    type: list",
            "  iap:",
            "    description:",
            "    - Settings for enabling Cloud Identity Aware Proxy.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.7",
            "    suboptions:",
            "      enabled:",
            "        description:",
            "        - Enables IAP.",
            "        required: false",
            "        type: bool",
            "      oauth2_client_id:",
            "        description:",
            "        - OAuth2 Client ID for IAP .",
            "        required: true",
            "        type: str",
            "      oauth2_client_secret:",
            "        description:",
            "        - OAuth2 Client Secret for IAP .",
            "        required: true",
            "        type: str",
            "  load_balancing_scheme:",
            "    description:",
            "    - Indicates whether the backend service will be used with internal or external",
            "      load balancing. A backend service created for one type of load balancing cannot",
            "      be used with the other. Must be `EXTERNAL` or `INTERNAL_SELF_MANAGED` for a",
            "      global backend service. Defaults to `EXTERNAL`.",
            "    - 'Some valid choices include: \"EXTERNAL\", \"INTERNAL_SELF_MANAGED\"'",
            "    required: false",
            "    default: EXTERNAL",
            "    type: str",
            "    version_added: 2.7",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  port_name:",
            "    description:",
            "    - Name of backend port. The same name should appear in the instance groups referenced",
            "      by this service. Required when the load balancing scheme is EXTERNAL.",
            "    required: false",
            "    type: str",
            "  protocol:",
            "    description:",
            "    - The protocol this BackendService uses to communicate with backends.",
            "    - 'Possible values are HTTP, HTTPS, HTTP2, TCP, and SSL. The default is HTTP.",
            "      **NOTE**: HTTP2 is only valid for beta HTTP/2 load balancer types and may result",
            "      in errors if used with the GA API.'",
            "    - 'Some valid choices include: \"HTTP\", \"HTTPS\", \"HTTP2\", \"TCP\", \"SSL\"'",
            "    required: false",
            "    type: str",
            "  security_policy:",
            "    description:",
            "    - The security policy associated with this backend service.",
            "    required: false",
            "    type: str",
            "    version_added: 2.8",
            "  session_affinity:",
            "    description:",
            "    - Type of session affinity to use. The default is NONE.",
            "    - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "    - When the protocol is UDP, this field is not used.",
            "    - 'Some valid choices include: \"NONE\", \"CLIENT_IP\", \"GENERATED_COOKIE\"'",
            "    required: false",
            "    type: str",
            "  timeout_sec:",
            "    description:",
            "    - How many seconds to wait for the backend before considering it a failed request.",
            "      Default is 30 seconds. Valid range is [1, 86400].",
            "    required: false",
            "    type: int",
            "    aliases:",
            "    - timeout_seconds",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/backendServices)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/load-balancing/http/backend-service)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance group",
            "  gcp_compute_instance_group:",
            "    name: instancegroup-backendservice",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: instancegroup",
            "",
            "- name: create a HTTP health check",
            "  gcp_compute_http_health_check:",
            "    name: httphealthcheck-backendservice",
            "    healthy_threshold: 10",
            "    port: 8080",
            "    timeout_sec: 2",
            "    unhealthy_threshold: 5",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: healthcheck",
            "",
            "- name: create a backend service",
            "  gcp_compute_backend_service:",
            "    name: test_object",
            "    backends:",
            "    - group: \"{{ instancegroup.selfLink }}\"",
            "    health_checks:",
            "    - \"{{ healthcheck.selfLink }}\"",
            "    enable_cdn: 'true'",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "affinityCookieTtlSec:",
            "  description:",
            "  - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "    to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "    session (or equivalent). The maximum allowed value for TTL is one day.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: int",
            "backends:",
            "  description:",
            "  - The set of backends that serve this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    balancingMode:",
            "      description:",
            "      - Specifies the balancing mode for this backend.",
            "      - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "        Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "      returned: success",
            "      type: str",
            "    capacityScaler:",
            "      description:",
            "      - A multiplier applied to the group's maximum servicing capacity (based on UTILIZATION,",
            "        RATE or CONNECTION).",
            "      - Default value is 1, which means the group will serve up to 100% of its configured",
            "        capacity (depending on balancingMode). A setting of 0 means the group is completely",
            "        drained, offering 0% of its available Capacity. Valid range is [0.0,1.0].",
            "      returned: success",
            "      type: str",
            "    description:",
            "      description:",
            "      - An optional description of this resource.",
            "      - Provide this property when you create the resource.",
            "      returned: success",
            "      type: str",
            "    group:",
            "      description:",
            "      - The fully-qualified URL of an Instance Group or Network Endpoint Group resource.",
            "        In case of instance group this defines the list of instances that serve traffic.",
            "        Member virtual machine instances from each instance group must live in the",
            "        same zone as the instance group itself. No two backends in a backend service",
            "        are allowed to use same Instance Group resource.",
            "      - For Network Endpoint Groups this defines list of endpoints. All endpoints",
            "        of Network Endpoint Group must be hosted on instances located in the same",
            "        zone as the Network Endpoint Group.",
            "      - Backend service can not contain mix of Instance Group and Network Endpoint",
            "        Group backends.",
            "      - Note that you must specify an Instance Group or Network Endpoint Group resource",
            "        using the fully-qualified URL, rather than a partial URL.",
            "      returned: success",
            "      type: str",
            "    maxConnections:",
            "      description:",
            "      - The max number of simultaneous connections for the group. Can be used with",
            "        either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or one of maxConnectionsPerInstance",
            "        or maxConnectionsPerEndpoint, as appropriate for group type, must be set.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerInstance:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend instance",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerEndpoint:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend network endpoint",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerEndpoint must",
            "        be set.",
            "      returned: success",
            "      type: int",
            "    maxRate:",
            "      description:",
            "      - The max requests per second (RPS) of the group.",
            "      - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "        if RATE mode. For RATE mode, either maxRate or one of maxRatePerInstance or",
            "        maxRatePerEndpoint, as appropriate for group type, must be set.",
            "      returned: success",
            "      type: int",
            "    maxRatePerInstance:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend instance can handle.",
            "        This is used to calculate the capacity of the group. Can be used in either",
            "        balancing mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      returned: success",
            "      type: str",
            "    maxRatePerEndpoint:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend network endpoint can",
            "        handle. This is used to calculate the capacity of the group. Can be used in",
            "        either balancing mode. For RATE mode, either maxRate or maxRatePerEndpoint",
            "        must be set.",
            "      returned: success",
            "      type: str",
            "    maxUtilization:",
            "      description:",
            "      - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "        target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "      returned: success",
            "      type: str",
            "cdnPolicy:",
            "  description:",
            "  - Cloud CDN configuration for this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    cacheKeyPolicy:",
            "      description:",
            "      - The CacheKeyPolicy for this CdnPolicy.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        includeHost:",
            "          description:",
            "          - If true requests to different hosts will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeProtocol:",
            "          description:",
            "          - If true, http and https requests will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeQueryString:",
            "          description:",
            "          - If true, include query string parameters in the cache key according to",
            "            query_string_whitelist and query_string_blacklist. If neither is set,",
            "            the entire query string will be included.",
            "          - If false, the query string will be excluded from the cache key entirely.",
            "          returned: success",
            "          type: bool",
            "        queryStringBlacklist:",
            "          description:",
            "          - Names of query string parameters to exclude in cache keys.",
            "          - All other parameters will be included. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "        queryStringWhitelist:",
            "          description:",
            "          - Names of query string parameters to include in cache keys.",
            "          - All other parameters will be excluded. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "    signedUrlCacheMaxAgeSec:",
            "      description:",
            "      - Maximum number of seconds the response to a signed URL request will be considered",
            "        fresh, defaults to 1hr (3600s). After this time period, the response will",
            "        be revalidated before being served.",
            "      - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "        behave as though all responses from this backend had a \"Cache-Control: public,",
            "        max-age=[TTL]\" header, regardless of any existing Cache-Control header. The",
            "        actual headers served in responses will not be altered.'",
            "      returned: success",
            "      type: int",
            "connectionDraining:",
            "  description:",
            "  - Settings for connection draining .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    drainingTimeoutSec:",
            "      description:",
            "      - Time for which instance will be drained (not accept new connections, but still",
            "        work to finish started).",
            "      returned: success",
            "      type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "fingerprint:",
            "  description:",
            "  - Fingerprint of this resource. A hash of the contents stored in this object. This",
            "    field is used in optimistic locking.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "enableCDN:",
            "  description:",
            "  - If true, enable Cloud CDN for this BackendService.",
            "  returned: success",
            "  type: bool",
            "healthChecks:",
            "  description:",
            "  - The set of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "    checking this BackendService. Currently at most one health check can be specified,",
            "    and a health check is required.",
            "  - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "    instead.",
            "  returned: success",
            "  type: list",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "iap:",
            "  description:",
            "  - Settings for enabling Cloud Identity Aware Proxy.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    enabled:",
            "      description:",
            "      - Enables IAP.",
            "      returned: success",
            "      type: bool",
            "    oauth2ClientId:",
            "      description:",
            "      - OAuth2 Client ID for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecret:",
            "      description:",
            "      - OAuth2 Client Secret for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecretSha256:",
            "      description:",
            "      - OAuth2 Client Secret SHA-256 for IAP .",
            "      returned: success",
            "      type: str",
            "loadBalancingScheme:",
            "  description:",
            "  - Indicates whether the backend service will be used with internal or external load",
            "    balancing. A backend service created for one type of load balancing cannot be",
            "    used with the other. Must be `EXTERNAL` or `INTERNAL_SELF_MANAGED` for a global",
            "    backend service. Defaults to `EXTERNAL`.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "portName:",
            "  description:",
            "  - Name of backend port. The same name should appear in the instance groups referenced",
            "    by this service. Required when the load balancing scheme is EXTERNAL.",
            "  returned: success",
            "  type: str",
            "protocol:",
            "  description:",
            "  - The protocol this BackendService uses to communicate with backends.",
            "  - 'Possible values are HTTP, HTTPS, HTTP2, TCP, and SSL. The default is HTTP. **NOTE**:",
            "    HTTP2 is only valid for beta HTTP/2 load balancer types and may result in errors",
            "    if used with the GA API.'",
            "  returned: success",
            "  type: str",
            "securityPolicy:",
            "  description:",
            "  - The security policy associated with this backend service.",
            "  returned: success",
            "  type: str",
            "sessionAffinity:",
            "  description:",
            "  - Type of session affinity to use. The default is NONE.",
            "  - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "  - When the protocol is UDP, this field is not used.",
            "  returned: success",
            "  type: str",
            "timeoutSec:",
            "  description:",
            "  - How many seconds to wait for the backend before considering it a failed request.",
            "    Default is 30 seconds. Valid range is [1, 86400].",
            "  returned: success",
            "  type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            affinity_cookie_ttl_sec=dict(type='int'),",
            "            backends=dict(",
            "                type='list',",
            "                elements='dict',",
            "                options=dict(",
            "                    balancing_mode=dict(default='UTILIZATION', type='str'),",
            "                    capacity_scaler=dict(default=1.0, type='str'),",
            "                    description=dict(type='str'),",
            "                    group=dict(type='str'),",
            "                    max_connections=dict(type='int'),",
            "                    max_connections_per_instance=dict(type='int'),",
            "                    max_connections_per_endpoint=dict(type='int'),",
            "                    max_rate=dict(type='int'),",
            "                    max_rate_per_instance=dict(type='str'),",
            "                    max_rate_per_endpoint=dict(type='str'),",
            "                    max_utilization=dict(default=0.8, type='str'),",
            "                ),",
            "            ),",
            "            cdn_policy=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    cache_key_policy=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            include_host=dict(type='bool'),",
            "                            include_protocol=dict(type='bool'),",
            "                            include_query_string=dict(type='bool'),",
            "                            query_string_blacklist=dict(type='list', elements='str'),",
            "                            query_string_whitelist=dict(type='list', elements='str'),",
            "                        ),",
            "                    ),",
            "                    signed_url_cache_max_age_sec=dict(default=3600, type='int'),",
            "                ),",
            "            ),",
            "            connection_draining=dict(type='dict', options=dict(draining_timeout_sec=dict(default=300, type='int'))),",
            "            description=dict(type='str'),",
            "            enable_cdn=dict(type='bool'),",
            "            health_checks=dict(required=True, type='list', elements='str'),",
            "            iap=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    enabled=dict(type='bool'),",
            "                    oauth2_client_id=dict(required=True, type='str'),",
            "                    oauth2_client_secret=dict(required=True, type='str', no_log=True),",
            "                ),",
            "            ),",
            "            load_balancing_scheme=dict(default='EXTERNAL', type='str'),",
            "            name=dict(required=True, type='str'),",
            "            port_name=dict(type='str'),",
            "            protocol=dict(type='str'),",
            "            security_policy=dict(type='str'),",
            "            session_affinity=dict(type='str'),",
            "            timeout_sec=dict(type='int', aliases=['timeout_seconds']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#backendService'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('securityPolicy') != request.get('securityPolicy'):",
            "        security_policy_update(module, request, response)",
            "",
            "",
            "def security_policy_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/backendServices/{name}/setSecurityPolicy\"]).format(**module.params),",
            "        {u'securityPolicy': module.params.get('security_policy')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#backendService',",
            "        u'affinityCookieTtlSec': module.params.get('affinity_cookie_ttl_sec'),",
            "        u'backends': BackendServiceBackendsArray(module.params.get('backends', []), module).to_request(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(module.params.get('cdn_policy', {}), module).to_request(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(module.params.get('connection_draining', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'enableCDN': module.params.get('enable_cdn'),",
            "        u'healthChecks': module.params.get('health_checks'),",
            "        u'iap': BackendServiceIap(module.params.get('iap', {}), module).to_request(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': module.params.get('port_name'),",
            "        u'protocol': module.params.get('protocol'),",
            "        u'securityPolicy': module.params.get('security_policy'),",
            "        u'sessionAffinity': module.params.get('session_affinity'),",
            "        u'timeoutSec': module.params.get('timeout_sec'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'affinityCookieTtlSec': response.get(u'affinityCookieTtlSec'),",
            "        u'backends': BackendServiceBackendsArray(response.get(u'backends', []), module).from_response(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(response.get(u'cdnPolicy', {}), module).from_response(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(response.get(u'connectionDraining', {}), module).from_response(),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'fingerprint': response.get(u'fingerprint'),",
            "        u'description': response.get(u'description'),",
            "        u'enableCDN': response.get(u'enableCDN'),",
            "        u'healthChecks': response.get(u'healthChecks'),",
            "        u'id': response.get(u'id'),",
            "        u'iap': BackendServiceIap(response.get(u'iap', {}), module).from_response(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': response.get(u'portName'),",
            "        u'protocol': response.get(u'protocol'),",
            "        u'securityPolicy': response.get(u'securityPolicy'),",
            "        u'sessionAffinity': response.get(u'sessionAffinity'),",
            "        u'timeoutSec': response.get(u'timeoutSec'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#backendService')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class BackendServiceBackendsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get('balancing_mode'),",
            "                u'capacityScaler': item.get('capacity_scaler'),",
            "                u'description': item.get('description'),",
            "                u'group': item.get('group'),",
            "                u'maxConnections': item.get('max_connections'),",
            "                u'maxConnectionsPerInstance': item.get('max_connections_per_instance'),",
            "                u'maxConnectionsPerEndpoint': item.get('max_connections_per_endpoint'),",
            "                u'maxRate': item.get('max_rate'),",
            "                u'maxRatePerInstance': item.get('max_rate_per_instance'),",
            "                u'maxRatePerEndpoint': item.get('max_rate_per_endpoint'),",
            "                u'maxUtilization': item.get('max_utilization'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get(u'balancingMode'),",
            "                u'capacityScaler': item.get(u'capacityScaler'),",
            "                u'description': item.get(u'description'),",
            "                u'group': item.get(u'group'),",
            "                u'maxConnections': item.get(u'maxConnections'),",
            "                u'maxConnectionsPerInstance': item.get(u'maxConnectionsPerInstance'),",
            "                u'maxConnectionsPerEndpoint': item.get(u'maxConnectionsPerEndpoint'),",
            "                u'maxRate': item.get(u'maxRate'),",
            "                u'maxRatePerInstance': item.get(u'maxRatePerInstance'),",
            "                u'maxRatePerEndpoint': item.get(u'maxRatePerEndpoint'),",
            "                u'maxUtilization': item.get(u'maxUtilization'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCdnpolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get('cache_key_policy', {}), self.module).to_request(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get('signed_url_cache_max_age_sec'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get(u'cacheKeyPolicy', {}), self.module).from_response(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get(u'signedUrlCacheMaxAgeSec'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCachekeypolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get('include_host'),",
            "                u'includeProtocol': self.request.get('include_protocol'),",
            "                u'includeQueryString': self.request.get('include_query_string'),",
            "                u'queryStringBlacklist': self.request.get('query_string_blacklist'),",
            "                u'queryStringWhitelist': self.request.get('query_string_whitelist'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get(u'includeHost'),",
            "                u'includeProtocol': self.request.get(u'includeProtocol'),",
            "                u'includeQueryString': self.request.get(u'includeQueryString'),",
            "                u'queryStringBlacklist': self.request.get(u'queryStringBlacklist'),",
            "                u'queryStringWhitelist': self.request.get(u'queryStringWhitelist'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceConnectiondraining(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get('draining_timeout_sec')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get(u'drainingTimeoutSec')})",
            "",
            "",
            "class BackendServiceIap(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get('enabled'),",
            "                u'oauth2ClientId': self.request.get('oauth2_client_id'),",
            "                u'oauth2ClientSecret': self.request.get('oauth2_client_secret'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get(u'enabled'),",
            "                u'oauth2ClientId': self.request.get(u'oauth2ClientId'),",
            "                u'oauth2ClientSecret': self.request.get(u'oauth2ClientSecret'),",
            "            }",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "735": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_disk.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 460,
                "afterPatchRowNumber": 460,
                "PatchRowcode": "             type=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 461,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "             source_image=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 462,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "             zone=dict(required=True, type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 463,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": 464,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 463,
                "PatchRowcode": "+            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 464,
                "PatchRowcode": "+            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "7": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": 465,
                "PatchRowcode": "             source_snapshot=dict(type='dict'),"
            },
            "8": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 466,
                "PatchRowcode": "+            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "10": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": 467,
                "PatchRowcode": "         )"
            },
            "11": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": 468,
                "PatchRowcode": "     )"
            },
            "12": {
                "beforePatchRowNumber": 469,
                "afterPatchRowNumber": 469,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP Disk",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.7",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "    type: int",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    type: int",
            "    version_added: 2.8",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    type: str",
            "    version_added: 2.7",
            "  source_image:",
            "    description:",
            "    - The source image used to create this disk. If the source image is deleted, this",
            "      field will not be set.",
            "    - 'To create a disk with one of the public operating system images, specify the",
            "      image by its family name. For example, specify family/debian-8 to use the latest",
            "      Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "      use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "      To create a disk with a private image that you created, specify the image name",
            "      in the following format: global/images/my-private-image You can also specify",
            "      a private image by its image family, which returns the latest version of the",
            "      image in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "      .'",
            "    required: false",
            "    type: str",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk resides.",
            "    required: true",
            "    type: str",
            "  source_image_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source image. Required if the source",
            "      image is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/disks)'",
            "- 'Adding a persistent disk: U(https://cloud.google.com/compute/docs/disks/add-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    zone: us-central1-a",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last detach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "sourceImage:",
            "  description:",
            "  - The source image used to create this disk. If the source image is deleted, this",
            "    field will not be set.",
            "  - 'To create a disk with one of the public operating system images, specify the",
            "    image by its family name. For example, specify family/debian-8 to use the latest",
            "    Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "    use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "    To create a disk with a private image that you created, specify the image name",
            "    in the following format: global/images/my-private-image You can also specify a",
            "    private image by its image family, which returns the latest version of the image",
            "    in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "    .'",
            "  returned: success",
            "  type: str",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk resides.",
            "  returned: success",
            "  type: str",
            "sourceImageEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source image. Required if the source",
            "    image is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceImageId:",
            "  description:",
            "  - The ID value of the image used to create this disk. This value identifies the",
            "    exact image that was used to create this persistent disk. For example, if you",
            "    created the persistent disk from an image that was later deleted and recreated",
            "    under the same name, the source image ID would identify the exact version of the",
            "    image that was used.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            type=dict(type='str'),",
            "            source_image=dict(type='str'),",
            "            zone=dict(required=True, type='str'),",
            "            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'sourceImageEncryptionKey': DiskSourceimageencryptionkey(module.params.get('source_image_encryption_key', {}), module).to_request(),",
            "        u'diskEncryptionKey': DiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': DiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'type': disk_type_selflink(module.params.get('type'), module.params),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'type': response.get(u'type'),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class DiskSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP Disk",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.7",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "    type: int",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    type: int",
            "    version_added: 2.8",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    type: str",
            "    version_added: 2.7",
            "  source_image:",
            "    description:",
            "    - The source image used to create this disk. If the source image is deleted, this",
            "      field will not be set.",
            "    - 'To create a disk with one of the public operating system images, specify the",
            "      image by its family name. For example, specify family/debian-8 to use the latest",
            "      Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "      use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "      To create a disk with a private image that you created, specify the image name",
            "      in the following format: global/images/my-private-image You can also specify",
            "      a private image by its image family, which returns the latest version of the",
            "      image in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "      .'",
            "    required: false",
            "    type: str",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk resides.",
            "    required: true",
            "    type: str",
            "  source_image_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source image. Required if the source",
            "      image is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/disks)'",
            "- 'Adding a persistent disk: U(https://cloud.google.com/compute/docs/disks/add-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    zone: us-central1-a",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last detach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "sourceImage:",
            "  description:",
            "  - The source image used to create this disk. If the source image is deleted, this",
            "    field will not be set.",
            "  - 'To create a disk with one of the public operating system images, specify the",
            "    image by its family name. For example, specify family/debian-8 to use the latest",
            "    Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "    use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "    To create a disk with a private image that you created, specify the image name",
            "    in the following format: global/images/my-private-image You can also specify a",
            "    private image by its image family, which returns the latest version of the image",
            "    in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "    .'",
            "  returned: success",
            "  type: str",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk resides.",
            "  returned: success",
            "  type: str",
            "sourceImageEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source image. Required if the source",
            "    image is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceImageId:",
            "  description:",
            "  - The ID value of the image used to create this disk. This value identifies the",
            "    exact image that was used to create this persistent disk. For example, if you",
            "    created the persistent disk from an image that was later deleted and recreated",
            "    under the same name, the source image ID would identify the exact version of the",
            "    image that was used.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            type=dict(type='str'),",
            "            source_image=dict(type='str'),",
            "            zone=dict(required=True, type='str'),",
            "            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'sourceImageEncryptionKey': DiskSourceimageencryptionkey(module.params.get('source_image_encryption_key', {}), module).to_request(),",
            "        u'diskEncryptionKey': DiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': DiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'type': disk_type_selflink(module.params.get('type'), module.params),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'type': response.get(u'type'),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class DiskSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "463": [
                "main"
            ],
            "464": [
                "main"
            ],
            "466": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_image.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 461,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "             disk_size_gb=dict(type='int'),"
            },
            "1": {
                "beforePatchRowNumber": 462,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "             family=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 463,
                "afterPatchRowNumber": 463,
                "PatchRowcode": "             guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str'))),"
            },
            "3": {
                "beforePatchRowNumber": 464,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 464,
                "PatchRowcode": "+            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "5": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": 465,
                "PatchRowcode": "             labels=dict(type='dict'),"
            },
            "6": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": 466,
                "PatchRowcode": "             licenses=dict(type='list', elements='str'),"
            },
            "7": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": 467,
                "PatchRowcode": "             name=dict(required=True, type='str'),"
            },
            "8": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": 468,
                "PatchRowcode": "             raw_disk=dict(type='dict', options=dict(container_type=dict(type='str'), sha1_checksum=dict(type='str'), source=dict(required=True, type='str'))),"
            },
            "9": {
                "beforePatchRowNumber": 469,
                "afterPatchRowNumber": 469,
                "PatchRowcode": "             source_disk=dict(type='dict'),"
            },
            "10": {
                "beforePatchRowNumber": 470,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 470,
                "PatchRowcode": "+            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "12": {
                "beforePatchRowNumber": 471,
                "afterPatchRowNumber": 471,
                "PatchRowcode": "             source_disk_id=dict(type='str'),"
            },
            "13": {
                "beforePatchRowNumber": 472,
                "afterPatchRowNumber": 472,
                "PatchRowcode": "             source_type=dict(type='str'),"
            },
            "14": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": 473,
                "PatchRowcode": "         )"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_image",
            "description:",
            "- Represents an Image resource.",
            "- Google Compute Engine uses operating system images to create the root persistent",
            "  disks for your instances. You specify an image when you create an instance. Images",
            "  contain a boot loader, an operating system, and a root file system. Linux operating",
            "  system images are also capable of running containers on Compute Engine.",
            "- Images can be either public or custom.",
            "- Public images are provided and maintained by Google, open-source communities, and",
            "  third-party vendors. By default, all projects have access to these images and can",
            "  use them to create instances. Custom images are available only to your project.",
            "  You can create a custom image from root persistent disks and other images. Then,",
            "  use the custom image to create an instance.",
            "short_description: Creates a GCP Image",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  disk_size_gb:",
            "    description:",
            "    - Size of the image when restored onto a persistent disk (in GB).",
            "    required: false",
            "    type: int",
            "  family:",
            "    description:",
            "    - The name of the image family to which this image belongs. You can create disks",
            "      by specifying an image family instead of a specific image name. The image family",
            "      always returns its latest image that is not deprecated. The name of the image",
            "      family must comply with RFC1035.",
            "    required: false",
            "    type: str",
            "  guest_os_features:",
            "    description:",
            "    - A list of features to enable on the guest OS. Applicable for bootable images",
            "      only. Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which",
            "      allows each virtual CPU to have its own queue. For Windows images, you can only",
            "      enable VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher.",
            "      Linux images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "    - For new Windows images, the server might also populate this field with the value",
            "      WINDOWS, to indicate that this is a Windows image.",
            "    - This value is purely informational and does not enable or disable any features.",
            "    required: false",
            "    type: list",
            "    suboptions:",
            "      type:",
            "        description:",
            "        - The type of supported feature. Currently only VIRTIO_SCSI_MULTIQUEUE is",
            "          supported. For newer Windows images, the server might also populate this",
            "          property with the value WINDOWS to indicate that this is a Windows image.",
            "          This value is purely informational and does not enable or disable any features.",
            "        - 'Some valid choices include: \"VIRTIO_SCSI_MULTIQUEUE\"'",
            "        required: false",
            "        type: str",
            "  image_encryption_key:",
            "    description:",
            "    - Encrypts the image using a customer-supplied encryption key.",
            "    - After you encrypt an image with a customer-supplied key, you must provide the",
            "      same key if you use the image later (e.g. to create a disk from the image) .",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Image.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.8",
            "  licenses:",
            "    description:",
            "    - Any applicable license URI.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  raw_disk:",
            "    description:",
            "    - The parameters of the raw disk image.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      container_type:",
            "        description:",
            "        - The format used to encode and transmit the block device, which should be",
            "          TAR. This is just a container and transmission format and not a runtime",
            "          format. Provided by the client when the disk image is created.",
            "        - 'Some valid choices include: \"TAR\"'",
            "        required: false",
            "        type: str",
            "      sha1_checksum:",
            "        description:",
            "        - An optional SHA1 checksum of the disk image before unpackaging.",
            "        - This is provided by the client when the disk image is created.",
            "        required: false",
            "        type: str",
            "      source:",
            "        description:",
            "        - The full Google Cloud Storage URL where disk storage is stored You must",
            "          provide either this property or the sourceDisk property but not both.",
            "        required: true",
            "        type: str",
            "  source_disk:",
            "    description:",
            "    - The source disk to create this image based on.",
            "    - You must provide either this property or the rawDisk.source property but not",
            "      both to create an image.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "    type: dict",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source disk. Required if the source",
            "      disk is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  source_disk_id:",
            "    description:",
            "    - The ID value of the disk used to create this image. This value may be used to",
            "      determine whether the image was taken from the current or a previous instance",
            "      of a given disk name.",
            "    required: false",
            "    type: str",
            "  source_type:",
            "    description:",
            "    - The type of the image used to create this disk. The default and only value is",
            "      RAW .",
            "    - 'Some valid choices include: \"RAW\"'",
            "    required: false",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/images)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/images)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-image",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a image",
            "  gcp_compute_image:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "archiveSizeBytes:",
            "  description:",
            "  - Size of the image tar.gz archive stored in Google Cloud Storage (in bytes).",
            "  returned: success",
            "  type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "deprecated:",
            "  description:",
            "  - The deprecation status associated with this image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    deleted:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DELETED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    deprecated:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DEPRECATED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    obsolete:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to OBSOLETE. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    replacement:",
            "      description:",
            "      - The URL of the suggested replacement for a deprecated resource.",
            "      - The suggested replacement resource must be the same kind of resource as the",
            "        deprecated resource.",
            "      returned: success",
            "      type: str",
            "    state:",
            "      description:",
            "      - The deprecation state of this resource. This can be DEPRECATED, OBSOLETE,",
            "        or DELETED. Operations which create a new resource using a DEPRECATED resource",
            "        will return successfully, but with a warning indicating the deprecated resource",
            "        and recommending its replacement. Operations which use OBSOLETE or DELETED",
            "        resources will be rejected and result in an error.",
            "      returned: success",
            "      type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "diskSizeGb:",
            "  description:",
            "  - Size of the image when restored onto a persistent disk (in GB).",
            "  returned: success",
            "  type: int",
            "family:",
            "  description:",
            "  - The name of the image family to which this image belongs. You can create disks",
            "    by specifying an image family instead of a specific image name. The image family",
            "    always returns its latest image that is not deprecated. The name of the image",
            "    family must comply with RFC1035.",
            "  returned: success",
            "  type: str",
            "guestOsFeatures:",
            "  description:",
            "  - A list of features to enable on the guest OS. Applicable for bootable images only.",
            "    Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which allows",
            "    each virtual CPU to have its own queue. For Windows images, you can only enable",
            "    VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher. Linux",
            "    images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "  - For new Windows images, the server might also populate this field with the value",
            "    WINDOWS, to indicate that this is a Windows image.",
            "  - This value is purely informational and does not enable or disable any features.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    type:",
            "      description:",
            "      - The type of supported feature. Currently only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "        For newer Windows images, the server might also populate this property with",
            "        the value WINDOWS to indicate that this is a Windows image. This value is",
            "        purely informational and does not enable or disable any features.",
            "      returned: success",
            "      type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "imageEncryptionKey:",
            "  description:",
            "  - Encrypts the image using a customer-supplied encryption key.",
            "  - After you encrypt an image with a customer-supplied key, you must provide the",
            "    same key if you use the image later (e.g. to create a disk from the image) .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this Image.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "licenses:",
            "  description:",
            "  - Any applicable license URI.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "rawDisk:",
            "  description:",
            "  - The parameters of the raw disk image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    containerType:",
            "      description:",
            "      - The format used to encode and transmit the block device, which should be TAR.",
            "        This is just a container and transmission format and not a runtime format.",
            "        Provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    sha1Checksum:",
            "      description:",
            "      - An optional SHA1 checksum of the disk image before unpackaging.",
            "      - This is provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    source:",
            "      description:",
            "      - The full Google Cloud Storage URL where disk storage is stored You must provide",
            "        either this property or the sourceDisk property but not both.",
            "      returned: success",
            "      type: str",
            "sourceDisk:",
            "  description:",
            "  - The source disk to create this image based on.",
            "  - You must provide either this property or the rawDisk.source property but not both",
            "    to create an image.",
            "  returned: success",
            "  type: dict",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source disk. Required if the source",
            "    disk is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceDiskId:",
            "  description:",
            "  - The ID value of the disk used to create this image. This value may be used to",
            "    determine whether the image was taken from the current or a previous instance",
            "    of a given disk name.",
            "  returned: success",
            "  type: str",
            "sourceType:",
            "  description:",
            "  - The type of the image used to create this disk. The default and only value is",
            "    RAW .",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            disk_size_gb=dict(type='int'),",
            "            family=dict(type='str'),",
            "            guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str'))),",
            "            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            raw_disk=dict(type='dict', options=dict(container_type=dict(type='str'), sha1_checksum=dict(type='str'), source=dict(required=True, type='str'))),",
            "            source_disk=dict(type='dict'),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            source_disk_id=dict(type='str'),",
            "            source_type=dict(type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#image'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/images/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#image',",
            "        u'description': module.params.get('description'),",
            "        u'diskSizeGb': module.params.get('disk_size_gb'),",
            "        u'family': module.params.get('family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(module.params.get('guest_os_features', []), module).to_request(),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(module.params.get('image_encryption_key', {}), module).to_request(),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'rawDisk': ImageRawdisk(module.params.get('raw_disk', {}), module).to_request(),",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'selfLink'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(module.params.get('source_disk_encryption_key', {}), module).to_request(),",
            "        u'sourceDiskId': module.params.get('source_disk_id'),",
            "        u'sourceType': module.params.get('source_type'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'archiveSizeBytes': response.get(u'archiveSizeBytes'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'deprecated': ImageDeprecated(response.get(u'deprecated', {}), module).from_response(),",
            "        u'description': response.get(u'description'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'family': response.get(u'family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(response.get(u'guestOsFeatures', []), module).from_response(),",
            "        u'id': response.get(u'id'),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(response.get(u'imageEncryptionKey', {}), module).from_response(),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': response.get(u'name'),",
            "        u'rawDisk': ImageRawdisk(response.get(u'rawDisk', {}), module).from_response(),",
            "        u'sourceDisk': response.get(u'sourceDisk'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(response.get(u'sourceDiskEncryptionKey', {}), module).from_response(),",
            "        u'sourceDiskId': response.get(u'sourceDiskId'),",
            "        u'sourceType': response.get(u'sourceType'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#image')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class ImageDeprecated(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get('deleted'),",
            "                u'deprecated': self.request.get('deprecated'),",
            "                u'obsolete': self.request.get('obsolete'),",
            "                u'replacement': self.request.get('replacement'),",
            "                u'state': self.request.get('state'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get(u'deleted'),",
            "                u'deprecated': self.request.get(u'deprecated'),",
            "                u'obsolete': self.request.get(u'obsolete'),",
            "                u'replacement': self.request.get(u'replacement'),",
            "                u'state': self.request.get(u'state'),",
            "            }",
            "        )",
            "",
            "",
            "class ImageGuestosfeaturesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get(u'type')})",
            "",
            "",
            "class ImageImageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class ImageRawdisk(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get('container_type'), u'sha1Checksum': self.request.get('sha1_checksum'), u'source': self.request.get('source')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get(u'containerType'), u'sha1Checksum': self.request.get(u'sha1Checksum'), u'source': self.request.get(u'source')}",
            "        )",
            "",
            "",
            "class ImageSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_image",
            "description:",
            "- Represents an Image resource.",
            "- Google Compute Engine uses operating system images to create the root persistent",
            "  disks for your instances. You specify an image when you create an instance. Images",
            "  contain a boot loader, an operating system, and a root file system. Linux operating",
            "  system images are also capable of running containers on Compute Engine.",
            "- Images can be either public or custom.",
            "- Public images are provided and maintained by Google, open-source communities, and",
            "  third-party vendors. By default, all projects have access to these images and can",
            "  use them to create instances. Custom images are available only to your project.",
            "  You can create a custom image from root persistent disks and other images. Then,",
            "  use the custom image to create an instance.",
            "short_description: Creates a GCP Image",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  disk_size_gb:",
            "    description:",
            "    - Size of the image when restored onto a persistent disk (in GB).",
            "    required: false",
            "    type: int",
            "  family:",
            "    description:",
            "    - The name of the image family to which this image belongs. You can create disks",
            "      by specifying an image family instead of a specific image name. The image family",
            "      always returns its latest image that is not deprecated. The name of the image",
            "      family must comply with RFC1035.",
            "    required: false",
            "    type: str",
            "  guest_os_features:",
            "    description:",
            "    - A list of features to enable on the guest OS. Applicable for bootable images",
            "      only. Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which",
            "      allows each virtual CPU to have its own queue. For Windows images, you can only",
            "      enable VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher.",
            "      Linux images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "    - For new Windows images, the server might also populate this field with the value",
            "      WINDOWS, to indicate that this is a Windows image.",
            "    - This value is purely informational and does not enable or disable any features.",
            "    required: false",
            "    type: list",
            "    suboptions:",
            "      type:",
            "        description:",
            "        - The type of supported feature. Currently only VIRTIO_SCSI_MULTIQUEUE is",
            "          supported. For newer Windows images, the server might also populate this",
            "          property with the value WINDOWS to indicate that this is a Windows image.",
            "          This value is purely informational and does not enable or disable any features.",
            "        - 'Some valid choices include: \"VIRTIO_SCSI_MULTIQUEUE\"'",
            "        required: false",
            "        type: str",
            "  image_encryption_key:",
            "    description:",
            "    - Encrypts the image using a customer-supplied encryption key.",
            "    - After you encrypt an image with a customer-supplied key, you must provide the",
            "      same key if you use the image later (e.g. to create a disk from the image) .",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Image.",
            "    required: false",
            "    type: dict",
            "    version_added: 2.8",
            "  licenses:",
            "    description:",
            "    - Any applicable license URI.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  raw_disk:",
            "    description:",
            "    - The parameters of the raw disk image.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      container_type:",
            "        description:",
            "        - The format used to encode and transmit the block device, which should be",
            "          TAR. This is just a container and transmission format and not a runtime",
            "          format. Provided by the client when the disk image is created.",
            "        - 'Some valid choices include: \"TAR\"'",
            "        required: false",
            "        type: str",
            "      sha1_checksum:",
            "        description:",
            "        - An optional SHA1 checksum of the disk image before unpackaging.",
            "        - This is provided by the client when the disk image is created.",
            "        required: false",
            "        type: str",
            "      source:",
            "        description:",
            "        - The full Google Cloud Storage URL where disk storage is stored You must",
            "          provide either this property or the sourceDisk property but not both.",
            "        required: true",
            "        type: str",
            "  source_disk:",
            "    description:",
            "    - The source disk to create this image based on.",
            "    - You must provide either this property or the rawDisk.source property but not",
            "      both to create an image.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "    type: dict",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source disk. Required if the source",
            "      disk is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  source_disk_id:",
            "    description:",
            "    - The ID value of the disk used to create this image. This value may be used to",
            "      determine whether the image was taken from the current or a previous instance",
            "      of a given disk name.",
            "    required: false",
            "    type: str",
            "  source_type:",
            "    description:",
            "    - The type of the image used to create this disk. The default and only value is",
            "      RAW .",
            "    - 'Some valid choices include: \"RAW\"'",
            "    required: false",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/images)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/images)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-image",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a image",
            "  gcp_compute_image:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "archiveSizeBytes:",
            "  description:",
            "  - Size of the image tar.gz archive stored in Google Cloud Storage (in bytes).",
            "  returned: success",
            "  type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "deprecated:",
            "  description:",
            "  - The deprecation status associated with this image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    deleted:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DELETED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    deprecated:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DEPRECATED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    obsolete:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to OBSOLETE. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    replacement:",
            "      description:",
            "      - The URL of the suggested replacement for a deprecated resource.",
            "      - The suggested replacement resource must be the same kind of resource as the",
            "        deprecated resource.",
            "      returned: success",
            "      type: str",
            "    state:",
            "      description:",
            "      - The deprecation state of this resource. This can be DEPRECATED, OBSOLETE,",
            "        or DELETED. Operations which create a new resource using a DEPRECATED resource",
            "        will return successfully, but with a warning indicating the deprecated resource",
            "        and recommending its replacement. Operations which use OBSOLETE or DELETED",
            "        resources will be rejected and result in an error.",
            "      returned: success",
            "      type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "diskSizeGb:",
            "  description:",
            "  - Size of the image when restored onto a persistent disk (in GB).",
            "  returned: success",
            "  type: int",
            "family:",
            "  description:",
            "  - The name of the image family to which this image belongs. You can create disks",
            "    by specifying an image family instead of a specific image name. The image family",
            "    always returns its latest image that is not deprecated. The name of the image",
            "    family must comply with RFC1035.",
            "  returned: success",
            "  type: str",
            "guestOsFeatures:",
            "  description:",
            "  - A list of features to enable on the guest OS. Applicable for bootable images only.",
            "    Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which allows",
            "    each virtual CPU to have its own queue. For Windows images, you can only enable",
            "    VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher. Linux",
            "    images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "  - For new Windows images, the server might also populate this field with the value",
            "    WINDOWS, to indicate that this is a Windows image.",
            "  - This value is purely informational and does not enable or disable any features.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    type:",
            "      description:",
            "      - The type of supported feature. Currently only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "        For newer Windows images, the server might also populate this property with",
            "        the value WINDOWS to indicate that this is a Windows image. This value is",
            "        purely informational and does not enable or disable any features.",
            "      returned: success",
            "      type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "imageEncryptionKey:",
            "  description:",
            "  - Encrypts the image using a customer-supplied encryption key.",
            "  - After you encrypt an image with a customer-supplied key, you must provide the",
            "    same key if you use the image later (e.g. to create a disk from the image) .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this Image.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "licenses:",
            "  description:",
            "  - Any applicable license URI.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "rawDisk:",
            "  description:",
            "  - The parameters of the raw disk image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    containerType:",
            "      description:",
            "      - The format used to encode and transmit the block device, which should be TAR.",
            "        This is just a container and transmission format and not a runtime format.",
            "        Provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    sha1Checksum:",
            "      description:",
            "      - An optional SHA1 checksum of the disk image before unpackaging.",
            "      - This is provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    source:",
            "      description:",
            "      - The full Google Cloud Storage URL where disk storage is stored You must provide",
            "        either this property or the sourceDisk property but not both.",
            "      returned: success",
            "      type: str",
            "sourceDisk:",
            "  description:",
            "  - The source disk to create this image based on.",
            "  - You must provide either this property or the rawDisk.source property but not both",
            "    to create an image.",
            "  returned: success",
            "  type: dict",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source disk. Required if the source",
            "    disk is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceDiskId:",
            "  description:",
            "  - The ID value of the disk used to create this image. This value may be used to",
            "    determine whether the image was taken from the current or a previous instance",
            "    of a given disk name.",
            "  returned: success",
            "  type: str",
            "sourceType:",
            "  description:",
            "  - The type of the image used to create this disk. The default and only value is",
            "    RAW .",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            disk_size_gb=dict(type='int'),",
            "            family=dict(type='str'),",
            "            guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str'))),",
            "            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            raw_disk=dict(type='dict', options=dict(container_type=dict(type='str'), sha1_checksum=dict(type='str'), source=dict(required=True, type='str'))),",
            "            source_disk=dict(type='dict'),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            source_disk_id=dict(type='str'),",
            "            source_type=dict(type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#image'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/images/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#image',",
            "        u'description': module.params.get('description'),",
            "        u'diskSizeGb': module.params.get('disk_size_gb'),",
            "        u'family': module.params.get('family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(module.params.get('guest_os_features', []), module).to_request(),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(module.params.get('image_encryption_key', {}), module).to_request(),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'rawDisk': ImageRawdisk(module.params.get('raw_disk', {}), module).to_request(),",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'selfLink'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(module.params.get('source_disk_encryption_key', {}), module).to_request(),",
            "        u'sourceDiskId': module.params.get('source_disk_id'),",
            "        u'sourceType': module.params.get('source_type'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'archiveSizeBytes': response.get(u'archiveSizeBytes'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'deprecated': ImageDeprecated(response.get(u'deprecated', {}), module).from_response(),",
            "        u'description': response.get(u'description'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'family': response.get(u'family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(response.get(u'guestOsFeatures', []), module).from_response(),",
            "        u'id': response.get(u'id'),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(response.get(u'imageEncryptionKey', {}), module).from_response(),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': response.get(u'name'),",
            "        u'rawDisk': ImageRawdisk(response.get(u'rawDisk', {}), module).from_response(),",
            "        u'sourceDisk': response.get(u'sourceDisk'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(response.get(u'sourceDiskEncryptionKey', {}), module).from_response(),",
            "        u'sourceDiskId': response.get(u'sourceDiskId'),",
            "        u'sourceType': response.get(u'sourceType'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#image')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class ImageDeprecated(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get('deleted'),",
            "                u'deprecated': self.request.get('deprecated'),",
            "                u'obsolete': self.request.get('obsolete'),",
            "                u'replacement': self.request.get('replacement'),",
            "                u'state': self.request.get('state'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get(u'deleted'),",
            "                u'deprecated': self.request.get(u'deprecated'),",
            "                u'obsolete': self.request.get(u'obsolete'),",
            "                u'replacement': self.request.get(u'replacement'),",
            "                u'state': self.request.get(u'state'),",
            "            }",
            "        )",
            "",
            "",
            "class ImageGuestosfeaturesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get(u'type')})",
            "",
            "",
            "class ImageImageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class ImageRawdisk(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get('container_type'), u'sha1Checksum': self.request.get('sha1_checksum'), u'source': self.request.get('source')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get(u'containerType'), u'sha1Checksum': self.request.get(u'sha1Checksum'), u'source': self.request.get(u'source')}",
            "        )",
            "",
            "",
            "class ImageSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "464": [
                "main"
            ],
            "470": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_instance_template.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 914,
                "afterPatchRowNumber": 914,
                "PatchRowcode": "                             auto_delete=dict(type='bool'),"
            },
            "1": {
                "beforePatchRowNumber": 915,
                "afterPatchRowNumber": 915,
                "PatchRowcode": "                             boot=dict(type='bool'),"
            },
            "2": {
                "beforePatchRowNumber": 916,
                "afterPatchRowNumber": 916,
                "PatchRowcode": "                             device_name=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 917,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), rsa_encrypted_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 917,
                "PatchRowcode": "+                            disk_encryption_key=dict("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 918,
                "PatchRowcode": "+                                type='dict',"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 919,
                "PatchRowcode": "+                                options=dict("
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 920,
                "PatchRowcode": "+                                    raw_key=dict(type='str', no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 921,
                "PatchRowcode": "+                                    rsa_encrypted_key=dict(type='str', no_log=True),"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 922,
                "PatchRowcode": "+                                ),"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 923,
                "PatchRowcode": "+                            ),"
            },
            "11": {
                "beforePatchRowNumber": 918,
                "afterPatchRowNumber": 924,
                "PatchRowcode": "                             index=dict(type='int'),"
            },
            "12": {
                "beforePatchRowNumber": 919,
                "afterPatchRowNumber": 925,
                "PatchRowcode": "                             initialize_params=dict("
            },
            "13": {
                "beforePatchRowNumber": 920,
                "afterPatchRowNumber": 926,
                "PatchRowcode": "                                 type='dict',"
            },
            "14": {
                "beforePatchRowNumber": 923,
                "afterPatchRowNumber": 929,
                "PatchRowcode": "                                     disk_size_gb=dict(type='int'),"
            },
            "15": {
                "beforePatchRowNumber": 924,
                "afterPatchRowNumber": 930,
                "PatchRowcode": "                                     disk_type=dict(type='str'),"
            },
            "16": {
                "beforePatchRowNumber": 925,
                "afterPatchRowNumber": 931,
                "PatchRowcode": "                                     source_image=dict(type='str'),"
            },
            "17": {
                "beforePatchRowNumber": 926,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 932,
                "PatchRowcode": "+                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "19": {
                "beforePatchRowNumber": 927,
                "afterPatchRowNumber": 933,
                "PatchRowcode": "                                 ),"
            },
            "20": {
                "beforePatchRowNumber": 928,
                "afterPatchRowNumber": 934,
                "PatchRowcode": "                             ),"
            },
            "21": {
                "beforePatchRowNumber": 929,
                "afterPatchRowNumber": 935,
                "PatchRowcode": "                             interface=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_instance_template",
            "description:",
            "- Defines an Instance Template resource that provides configuration settings for your",
            "  virtual machine instances. Instance templates are not tied to the lifetime of an",
            "  instance and can be used and reused as to deploy virtual machines. You can also",
            "  use different templates to create different virtual machine configurations. Instance",
            "  templates are required when you create a managed instance group.",
            "- 'Tip: Disks should be set to autoDelete=true so that leftover disks are not left",
            "  behind on machine deletion.'",
            "short_description: Creates a GCP InstanceTemplate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "    required: true",
            "    type: str",
            "  properties:",
            "    description:",
            "    - The instance properties for this instance template.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      can_ip_forward:",
            "        description:",
            "        - Enables instances created based on this template to send packets with source",
            "          IP addresses other than their own and receive packets with destination IP",
            "          addresses other than their own. If these instances will be used as an IP",
            "          gateway or it will be set as the next-hop in a Route resource, specify true.",
            "          If unsure, leave this set to false.",
            "        required: false",
            "        type: bool",
            "      description:",
            "        description:",
            "        - An optional text description for the instances that are created from this",
            "          instance template.",
            "        required: false",
            "        type: str",
            "      disks:",
            "        description:",
            "        - An array of disks that are associated with the instances that are created",
            "          from this template.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          auto_delete:",
            "            description:",
            "            - Specifies whether the disk will be auto-deleted when the instance is",
            "              deleted (but not when the disk is detached from the instance).",
            "            - 'Tip: Disks should be set to autoDelete=true so that leftover disks",
            "              are not left behind on machine deletion.'",
            "            required: false",
            "            type: bool",
            "          boot:",
            "            description:",
            "            - Indicates that this is a boot disk. The virtual machine will use the",
            "              first partition of the disk for its root filesystem.",
            "            required: false",
            "            type: bool",
            "          device_name:",
            "            description:",
            "            - Specifies a unique device name of your choice that is reflected into",
            "              the /dev/disk/by-id/google-* tree of a Linux operating system running",
            "              within the instance. This name can be used to reference the device for",
            "              mounting, resizing, and so on, from within the instance.",
            "            required: false",
            "            type: str",
            "          disk_encryption_key:",
            "            description:",
            "            - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "            required: false",
            "            type: dict",
            "            suboptions:",
            "              raw_key:",
            "                description:",
            "                - Specifies a 256-bit customer-supplied encryption key, encoded in",
            "                  RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                required: false",
            "                type: str",
            "              rsa_encrypted_key:",
            "                description:",
            "                - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                  encryption key to either encrypt or decrypt this resource.",
            "                required: false",
            "                type: str",
            "          index:",
            "            description:",
            "            - Assigns a zero-based index to this disk, where 0 is reserved for the",
            "              boot disk. For example, if you have many disks attached to an instance,",
            "              each disk would have a unique index number. If not specified, the server",
            "              will choose an appropriate value.",
            "            required: false",
            "            type: int",
            "          initialize_params:",
            "            description:",
            "            - Specifies the parameters for a new disk that will be created alongside",
            "              the new instance. Use initialization parameters to create boot disks",
            "              or local SSDs attached to the new instance.",
            "            required: false",
            "            type: dict",
            "            suboptions:",
            "              disk_name:",
            "                description:",
            "                - Specifies the disk name. If not specified, the default is to use",
            "                  the name of the instance.",
            "                required: false",
            "                type: str",
            "              disk_size_gb:",
            "                description:",
            "                - Specifies the size of the disk in base-2 GB.",
            "                required: false",
            "                type: int",
            "              disk_type:",
            "                description:",
            "                - Reference to a disk type.",
            "                - Specifies the disk type to use to create the instance.",
            "                - If not specified, the default is pd-standard.",
            "                required: false",
            "                type: str",
            "              source_image:",
            "                description:",
            "                - The source image to create this disk. When creating a new instance,",
            "                  one of initializeParams.sourceImage or disks.source is required.",
            "                  To create a disk with one of the public operating system images,",
            "                  specify the image by its family name.",
            "                required: false",
            "                type: str",
            "              source_image_encryption_key:",
            "                description:",
            "                - The customer-supplied encryption key of the source image. Required",
            "                  if the source image is protected by a customer-supplied encryption",
            "                  key.",
            "                - Instance templates do not store customer-supplied encryption keys,",
            "                  so you cannot create disks for instances in a managed instance group",
            "                  if the source images are encrypted with your own keys.",
            "                required: false",
            "                type: dict",
            "                suboptions:",
            "                  raw_key:",
            "                    description:",
            "                    - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                      in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                    required: false",
            "                    type: str",
            "          interface:",
            "            description:",
            "            - Specifies the disk interface to use for attaching this disk, which is",
            "              either SCSI or NVME. The default is SCSI.",
            "            - Persistent disks must always use SCSI and the request will fail if you",
            "              attempt to attach a persistent disk in any other format than SCSI.",
            "            - 'Some valid choices include: \"SCSI\", \"NVME\"'",
            "            required: false",
            "            type: str",
            "          mode:",
            "            description:",
            "            - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "              If not specified, the default is to attach the disk in READ_WRITE mode.",
            "            - 'Some valid choices include: \"READ_WRITE\", \"READ_ONLY\"'",
            "            required: false",
            "            type: str",
            "          source:",
            "            description:",
            "            - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "              or disks.source is required.",
            "            - If desired, you can also attach existing non-root persistent disks using",
            "              this property. This field is only applicable for persistent disks.",
            "            - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "              the disk.",
            "            - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "              in two ways. First, you can place a dictionary with key ''name'' and",
            "              value of your resource''s name Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_disk task and then set this source",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "          type:",
            "            description:",
            "            - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not",
            "              specified, the default is PERSISTENT.",
            "            - 'Some valid choices include: \"SCRATCH\", \"PERSISTENT\"'",
            "            required: false",
            "            type: str",
            "      labels:",
            "        description:",
            "        - Labels to apply to this address. A list of key->value pairs.",
            "        required: false",
            "        type: dict",
            "        version_added: 2.9",
            "      machine_type:",
            "        description:",
            "        - The machine type to use in the VM instance template.",
            "        required: true",
            "        type: str",
            "      min_cpu_platform:",
            "        description:",
            "        - Specifies a minimum CPU platform for the VM instance. Applicable values",
            "          are the friendly names of CPU platforms .",
            "        required: false",
            "        type: str",
            "      metadata:",
            "        description:",
            "        - The metadata key/value pairs to assign to instances that are created from",
            "          this template. These pairs can consist of custom metadata or predefined",
            "          keys.",
            "        required: false",
            "        type: dict",
            "      guest_accelerators:",
            "        description:",
            "        - List of the type and count of accelerator cards attached to the instance",
            "          .",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          accelerator_count:",
            "            description:",
            "            - The number of the guest accelerator cards exposed to this instance.",
            "            required: false",
            "            type: int",
            "          accelerator_type:",
            "            description:",
            "            - Full or partial URL of the accelerator type resource to expose to this",
            "              instance.",
            "            required: false",
            "            type: str",
            "      network_interfaces:",
            "        description:",
            "        - An array of configurations for this interface. This specifies how this interface",
            "          is configured to interact with other network services, such as connecting",
            "          to the internet. Only one network interface is supported per instance.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          access_configs:",
            "            description:",
            "            - An array of configurations for this interface. Currently, only one access",
            "              config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs",
            "              specified, then this instance will have no external internet access.",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              name:",
            "                description:",
            "                - The name of this access configuration. The default and recommended",
            "                  name is External NAT but you can use any arbitrary string you would",
            "                  like. For example, My external IP or Network Access.",
            "                required: true",
            "                type: str",
            "              nat_ip:",
            "                description:",
            "                - Reference to an address.",
            "                - An external IP address associated with this instance.",
            "                - Specify an unused static external IP address available to the project",
            "                  or leave this field undefined to use an IP from a shared ephemeral",
            "                  IP address pool. If you specify a static external IP address, it",
            "                  must live in the same region as the zone of the instance.",
            "                - 'This field represents a link to a Address resource in GCP. It can",
            "                  be specified in two ways. First, you can place a dictionary with",
            "                  key ''address'' and value of your resource''s address Alternatively,",
            "                  you can add `register: name-of-resource` to a gcp_compute_address",
            "                  task and then set this nat_ip field to \"{{ name-of-resource }}\"'",
            "                required: false",
            "                type: dict",
            "              type:",
            "                description:",
            "                - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "                - 'Some valid choices include: \"ONE_TO_ONE_NAT\"'",
            "                required: true",
            "                type: str",
            "          alias_ip_ranges:",
            "            description:",
            "            - An array of alias IP ranges for this network interface. Can only be",
            "              specified for network interfaces on subnet-mode networks.",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              ip_cidr_range:",
            "                description:",
            "                - The IP CIDR range represented by this alias IP range.",
            "                - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                  contain IP addresses reserved by system or used by other network",
            "                  interfaces. This range may be a single IP address (e.g. 10.2.3.4),",
            "                  a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "                required: false",
            "                type: str",
            "              subnetwork_range_name:",
            "                description:",
            "                - Optional subnetwork secondary range name specifying the secondary",
            "                  range from which to allocate the IP CIDR range for this alias IP",
            "                  range. If left unspecified, the primary range of the subnetwork",
            "                  will be used.",
            "                required: false",
            "                type: str",
            "          network:",
            "            description:",
            "            - Specifies the title of an existing network. When creating an instance,",
            "              if neither the network nor the subnetwork is specified, the default",
            "              network global/networks/default is used; if the network is not specified",
            "              but the subnetwork is specified, the network is inferred.",
            "            - 'This field represents a link to a Network resource in GCP. It can be",
            "              specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "              and value of your resource''s selfLink Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_network task and then set this network",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "          network_ip:",
            "            description:",
            "            - An IPv4 internal network address to assign to the instance for this",
            "              network interface. If not specified by the user, an unused internal",
            "              IP is assigned by the system.",
            "            required: false",
            "            type: str",
            "          subnetwork:",
            "            description:",
            "            - Reference to a VPC network.",
            "            - If the network resource is in legacy mode, do not provide this property.",
            "              If the network is in auto subnet mode, providing the subnetwork is optional.",
            "              If the network is in custom subnet mode, then this field should be specified.",
            "            - 'This field represents a link to a Subnetwork resource in GCP. It can",
            "              be specified in two ways. First, you can place a dictionary with key",
            "              ''selfLink'' and value of your resource''s selfLink Alternatively, you",
            "              can add `register: name-of-resource` to a gcp_compute_subnetwork task",
            "              and then set this subnetwork field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "      scheduling:",
            "        description:",
            "        - Sets the scheduling options for this instance.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          automatic_restart:",
            "            description:",
            "            - Specifies whether the instance should be automatically restarted if",
            "              it is terminated by Compute Engine (not terminated by a user).",
            "            - You can only set the automatic restart option for standard instances.",
            "              Preemptible instances cannot be automatically restarted.",
            "            required: false",
            "            type: bool",
            "          on_host_maintenance:",
            "            description:",
            "            - Defines the maintenance behavior for this instance. For standard instances,",
            "              the default behavior is MIGRATE. For preemptible instances, the default",
            "              and only possible behavior is TERMINATE.",
            "            - For more information, see Setting Instance Scheduling Options.",
            "            required: false",
            "            type: str",
            "          preemptible:",
            "            description:",
            "            - Defines whether the instance is preemptible. This can only be set during",
            "              instance creation, it cannot be set or changed after the instance has",
            "              been created.",
            "            required: false",
            "            type: bool",
            "      service_accounts:",
            "        description:",
            "        - A list of service accounts, with their specified scopes, authorized for",
            "          this instance. Only one service account per VM instance is supported.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          email:",
            "            description:",
            "            - Email address of the service account.",
            "            required: false",
            "            type: str",
            "          scopes:",
            "            description:",
            "            - The list of scopes to be made available for this service account.",
            "            required: false",
            "            type: list",
            "      tags:",
            "        description:",
            "        - A list of tags to apply to this instance. Tags are used to identify valid",
            "          sources or targets for network firewalls and are specified by the client",
            "          during instance creation. The tags can be later modified by the setTags",
            "          method. Each tag within the list must comply with RFC1035.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          fingerprint:",
            "            description:",
            "            - Specifies a fingerprint for this request, which is essentially a hash",
            "              of the metadata's contents and used for optimistic locking.",
            "            - The fingerprint is initially generated by Compute Engine and changes",
            "              after every request to modify or update metadata. You must always provide",
            "              an up-to-date fingerprint hash in order to update or change metadata.",
            "            required: false",
            "            type: str",
            "          items:",
            "            description:",
            "            - An array of tags. Each tag must be 1-63 characters long, and comply",
            "              with RFC1035.",
            "            required: false",
            "            type: list",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-instancetemplate",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a address",
            "  gcp_compute_address:",
            "    name: address-instancetemplate",
            "    region: us-west1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: address",
            "",
            "- name: create a instance template",
            "  gcp_compute_instance_template:",
            "    name: test_object",
            "    properties:",
            "      disks:",
            "      - auto_delete: 'true'",
            "        boot: 'true'",
            "        initialize_params:",
            "          source_image: projects/ubuntu-os-cloud/global/images/family/ubuntu-1604-lts",
            "      machine_type: n1-standard-1",
            "      network_interfaces:",
            "      - network: \"{{ network }}\"",
            "        access_configs:",
            "        - name: test-config",
            "          type: ONE_TO_ONE_NAT",
            "          nat_ip: \"{{ address }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "  returned: success",
            "  type: str",
            "properties:",
            "  description:",
            "  - The instance properties for this instance template.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    canIpForward:",
            "      description:",
            "      - Enables instances created based on this template to send packets with source",
            "        IP addresses other than their own and receive packets with destination IP",
            "        addresses other than their own. If these instances will be used as an IP gateway",
            "        or it will be set as the next-hop in a Route resource, specify true. If unsure,",
            "        leave this set to false.",
            "      returned: success",
            "      type: bool",
            "    description:",
            "      description:",
            "      - An optional text description for the instances that are created from this",
            "        instance template.",
            "      returned: success",
            "      type: str",
            "    disks:",
            "      description:",
            "      - An array of disks that are associated with the instances that are created",
            "        from this template.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        autoDelete:",
            "          description:",
            "          - Specifies whether the disk will be auto-deleted when the instance is deleted",
            "            (but not when the disk is detached from the instance).",
            "          - 'Tip: Disks should be set to autoDelete=true so that leftover disks are",
            "            not left behind on machine deletion.'",
            "          returned: success",
            "          type: bool",
            "        boot:",
            "          description:",
            "          - Indicates that this is a boot disk. The virtual machine will use the first",
            "            partition of the disk for its root filesystem.",
            "          returned: success",
            "          type: bool",
            "        deviceName:",
            "          description:",
            "          - Specifies a unique device name of your choice that is reflected into the",
            "            /dev/disk/by-id/google-* tree of a Linux operating system running within",
            "            the instance. This name can be used to reference the device for mounting,",
            "            resizing, and so on, from within the instance.",
            "          returned: success",
            "          type: str",
            "        diskEncryptionKey:",
            "          description:",
            "          - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            rawKey:",
            "              description:",
            "              - Specifies a 256-bit customer-supplied encryption key, encoded in RFC",
            "                4648 base64 to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            rsaEncryptedKey:",
            "              description:",
            "              - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                encryption key to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            sha256:",
            "              description:",
            "              - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                encryption key that protects this resource.",
            "              returned: success",
            "              type: str",
            "        index:",
            "          description:",
            "          - Assigns a zero-based index to this disk, where 0 is reserved for the boot",
            "            disk. For example, if you have many disks attached to an instance, each",
            "            disk would have a unique index number. If not specified, the server will",
            "            choose an appropriate value.",
            "          returned: success",
            "          type: int",
            "        initializeParams:",
            "          description:",
            "          - Specifies the parameters for a new disk that will be created alongside",
            "            the new instance. Use initialization parameters to create boot disks or",
            "            local SSDs attached to the new instance.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            diskName:",
            "              description:",
            "              - Specifies the disk name. If not specified, the default is to use the",
            "                name of the instance.",
            "              returned: success",
            "              type: str",
            "            diskSizeGb:",
            "              description:",
            "              - Specifies the size of the disk in base-2 GB.",
            "              returned: success",
            "              type: int",
            "            diskType:",
            "              description:",
            "              - Reference to a disk type.",
            "              - Specifies the disk type to use to create the instance.",
            "              - If not specified, the default is pd-standard.",
            "              returned: success",
            "              type: str",
            "            sourceImage:",
            "              description:",
            "              - The source image to create this disk. When creating a new instance,",
            "                one of initializeParams.sourceImage or disks.source is required. To",
            "                create a disk with one of the public operating system images, specify",
            "                the image by its family name.",
            "              returned: success",
            "              type: str",
            "            sourceImageEncryptionKey:",
            "              description:",
            "              - The customer-supplied encryption key of the source image. Required",
            "                if the source image is protected by a customer-supplied encryption",
            "                key.",
            "              - Instance templates do not store customer-supplied encryption keys,",
            "                so you cannot create disks for instances in a managed instance group",
            "                if the source images are encrypted with your own keys.",
            "              returned: success",
            "              type: complex",
            "              contains:",
            "                rawKey:",
            "                  description:",
            "                  - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                    in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                  returned: success",
            "                  type: str",
            "                sha256:",
            "                  description:",
            "                  - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                    encryption key that protects this resource.",
            "                  returned: success",
            "                  type: str",
            "        interface:",
            "          description:",
            "          - Specifies the disk interface to use for attaching this disk, which is",
            "            either SCSI or NVME. The default is SCSI.",
            "          - Persistent disks must always use SCSI and the request will fail if you",
            "            attempt to attach a persistent disk in any other format than SCSI.",
            "          returned: success",
            "          type: str",
            "        mode:",
            "          description:",
            "          - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "            If not specified, the default is to attach the disk in READ_WRITE mode.",
            "          returned: success",
            "          type: str",
            "        source:",
            "          description:",
            "          - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "            or disks.source is required.",
            "          - If desired, you can also attach existing non-root persistent disks using",
            "            this property. This field is only applicable for persistent disks.",
            "          - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "            the disk.",
            "          returned: success",
            "          type: dict",
            "        type:",
            "          description:",
            "          - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not specified,",
            "            the default is PERSISTENT.",
            "          returned: success",
            "          type: str",
            "    labels:",
            "      description:",
            "      - Labels to apply to this address. A list of key->value pairs.",
            "      returned: success",
            "      type: dict",
            "    machineType:",
            "      description:",
            "      - The machine type to use in the VM instance template.",
            "      returned: success",
            "      type: str",
            "    minCpuPlatform:",
            "      description:",
            "      - Specifies a minimum CPU platform for the VM instance. Applicable values are",
            "        the friendly names of CPU platforms .",
            "      returned: success",
            "      type: str",
            "    metadata:",
            "      description:",
            "      - The metadata key/value pairs to assign to instances that are created from",
            "        this template. These pairs can consist of custom metadata or predefined keys.",
            "      returned: success",
            "      type: dict",
            "    guestAccelerators:",
            "      description:",
            "      - List of the type and count of accelerator cards attached to the instance .",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        acceleratorCount:",
            "          description:",
            "          - The number of the guest accelerator cards exposed to this instance.",
            "          returned: success",
            "          type: int",
            "        acceleratorType:",
            "          description:",
            "          - Full or partial URL of the accelerator type resource to expose to this",
            "            instance.",
            "          returned: success",
            "          type: str",
            "    networkInterfaces:",
            "      description:",
            "      - An array of configurations for this interface. This specifies how this interface",
            "        is configured to interact with other network services, such as connecting",
            "        to the internet. Only one network interface is supported per instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        accessConfigs:",
            "          description:",
            "          - An array of configurations for this interface. Currently, only one access",
            "            config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs specified,",
            "            then this instance will have no external internet access.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            name:",
            "              description:",
            "              - The name of this access configuration. The default and recommended",
            "                name is External NAT but you can use any arbitrary string you would",
            "                like. For example, My external IP or Network Access.",
            "              returned: success",
            "              type: str",
            "            natIP:",
            "              description:",
            "              - Reference to an address.",
            "              - An external IP address associated with this instance.",
            "              - Specify an unused static external IP address available to the project",
            "                or leave this field undefined to use an IP from a shared ephemeral",
            "                IP address pool. If you specify a static external IP address, it must",
            "                live in the same region as the zone of the instance.",
            "              returned: success",
            "              type: dict",
            "            type:",
            "              description:",
            "              - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "              returned: success",
            "              type: str",
            "        aliasIpRanges:",
            "          description:",
            "          - An array of alias IP ranges for this network interface. Can only be specified",
            "            for network interfaces on subnet-mode networks.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            ipCidrRange:",
            "              description:",
            "              - The IP CIDR range represented by this alias IP range.",
            "              - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                contain IP addresses reserved by system or used by other network interfaces.",
            "                This range may be a single IP address (e.g. 10.2.3.4), a netmask (e.g.",
            "                /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "              returned: success",
            "              type: str",
            "            subnetworkRangeName:",
            "              description:",
            "              - Optional subnetwork secondary range name specifying the secondary",
            "                range from which to allocate the IP CIDR range for this alias IP range.",
            "                If left unspecified, the primary range of the subnetwork will be used.",
            "              returned: success",
            "              type: str",
            "        name:",
            "          description:",
            "          - The name of the network interface, generated by the server. For network",
            "            devices, these are eth0, eth1, etc .",
            "          returned: success",
            "          type: str",
            "        network:",
            "          description:",
            "          - Specifies the title of an existing network. When creating an instance,",
            "            if neither the network nor the subnetwork is specified, the default network",
            "            global/networks/default is used; if the network is not specified but the",
            "            subnetwork is specified, the network is inferred.",
            "          returned: success",
            "          type: dict",
            "        networkIP:",
            "          description:",
            "          - An IPv4 internal network address to assign to the instance for this network",
            "            interface. If not specified by the user, an unused internal IP is assigned",
            "            by the system.",
            "          returned: success",
            "          type: str",
            "        subnetwork:",
            "          description:",
            "          - Reference to a VPC network.",
            "          - If the network resource is in legacy mode, do not provide this property.",
            "            If the network is in auto subnet mode, providing the subnetwork is optional.",
            "            If the network is in custom subnet mode, then this field should be specified.",
            "          returned: success",
            "          type: dict",
            "    scheduling:",
            "      description:",
            "      - Sets the scheduling options for this instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        automaticRestart:",
            "          description:",
            "          - Specifies whether the instance should be automatically restarted if it",
            "            is terminated by Compute Engine (not terminated by a user).",
            "          - You can only set the automatic restart option for standard instances.",
            "            Preemptible instances cannot be automatically restarted.",
            "          returned: success",
            "          type: bool",
            "        onHostMaintenance:",
            "          description:",
            "          - Defines the maintenance behavior for this instance. For standard instances,",
            "            the default behavior is MIGRATE. For preemptible instances, the default",
            "            and only possible behavior is TERMINATE.",
            "          - For more information, see Setting Instance Scheduling Options.",
            "          returned: success",
            "          type: str",
            "        preemptible:",
            "          description:",
            "          - Defines whether the instance is preemptible. This can only be set during",
            "            instance creation, it cannot be set or changed after the instance has",
            "            been created.",
            "          returned: success",
            "          type: bool",
            "    serviceAccounts:",
            "      description:",
            "      - A list of service accounts, with their specified scopes, authorized for this",
            "        instance. Only one service account per VM instance is supported.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        email:",
            "          description:",
            "          - Email address of the service account.",
            "          returned: success",
            "          type: str",
            "        scopes:",
            "          description:",
            "          - The list of scopes to be made available for this service account.",
            "          returned: success",
            "          type: list",
            "    tags:",
            "      description:",
            "      - A list of tags to apply to this instance. Tags are used to identify valid",
            "        sources or targets for network firewalls and are specified by the client during",
            "        instance creation. The tags can be later modified by the setTags method. Each",
            "        tag within the list must comply with RFC1035.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        fingerprint:",
            "          description:",
            "          - Specifies a fingerprint for this request, which is essentially a hash",
            "            of the metadata's contents and used for optimistic locking.",
            "          - The fingerprint is initially generated by Compute Engine and changes after",
            "            every request to modify or update metadata. You must always provide an",
            "            up-to-date fingerprint hash in order to update or change metadata.",
            "          returned: success",
            "          type: str",
            "        items:",
            "          description:",
            "          - An array of tags. Each tag must be 1-63 characters long, and comply with",
            "            RFC1035.",
            "          returned: success",
            "          type: list",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(required=True, type='str'),",
            "            properties=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    can_ip_forward=dict(type='bool'),",
            "                    description=dict(type='str'),",
            "                    disks=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            auto_delete=dict(type='bool'),",
            "                            boot=dict(type='bool'),",
            "                            device_name=dict(type='str'),",
            "                            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), rsa_encrypted_key=dict(type='str'))),",
            "                            index=dict(type='int'),",
            "                            initialize_params=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    disk_name=dict(type='str'),",
            "                                    disk_size_gb=dict(type='int'),",
            "                                    disk_type=dict(type='str'),",
            "                                    source_image=dict(type='str'),",
            "                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "                                ),",
            "                            ),",
            "                            interface=dict(type='str'),",
            "                            mode=dict(type='str'),",
            "                            source=dict(type='dict'),",
            "                            type=dict(type='str'),",
            "                        ),",
            "                    ),",
            "                    labels=dict(type='dict'),",
            "                    machine_type=dict(required=True, type='str'),",
            "                    min_cpu_platform=dict(type='str'),",
            "                    metadata=dict(type='dict'),",
            "                    guest_accelerators=dict(type='list', elements='dict', options=dict(accelerator_count=dict(type='int'), accelerator_type=dict(type='str'))),",
            "                    network_interfaces=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            access_configs=dict(",
            "                                type='list',",
            "                                elements='dict',",
            "                                options=dict(name=dict(required=True, type='str'), nat_ip=dict(type='dict'), type=dict(required=True, type='str')),",
            "                            ),",
            "                            alias_ip_ranges=dict(",
            "                                type='list', elements='dict', options=dict(ip_cidr_range=dict(type='str'), subnetwork_range_name=dict(type='str'))",
            "                            ),",
            "                            network=dict(type='dict'),",
            "                            network_ip=dict(type='str'),",
            "                            subnetwork=dict(type='dict'),",
            "                        ),",
            "                    ),",
            "                    scheduling=dict(",
            "                        type='dict', options=dict(automatic_restart=dict(type='bool'), on_host_maintenance=dict(type='str'), preemptible=dict(type='bool'))",
            "                    ),",
            "                    service_accounts=dict(type='list', elements='dict', options=dict(email=dict(type='str'), scopes=dict(type='list', elements='str'))),",
            "                    tags=dict(type='dict', options=dict(fingerprint=dict(type='str'), items=dict(type='list', elements='str'))),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#instanceTemplate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#instanceTemplate',",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'properties': InstanceTemplateProperties(module.params.get('properties', {}), module).to_request(),",
            "    }",
            "    request = encode_request(request, module)",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    result = decode_response(result, module)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "    request = decode_response(request, module)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'properties': InstanceTemplateProperties(response.get(u'properties', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    response = fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#instanceTemplate')",
            "    if response:",
            "        return decode_response(response, module)",
            "    else:",
            "        return {}",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "def encode_request(request, module):",
            "    if 'properties' in request and request['properties'] is not None and 'metadata' in request['properties'] and request['properties']['metadata'] is not None:",
            "        request['properties']['metadata'] = metadata_encoder(request['properties']['metadata'])",
            "    return request",
            "",
            "",
            "def decode_response(response, module):",
            "    if (",
            "        'properties' in response",
            "        and response['properties'] is not None",
            "        and 'metadata' in response['properties']",
            "        and response['properties']['metadata'] is not None",
            "    ):",
            "        response['properties']['metadata'] = metadata_decoder(response['properties']['metadata'])",
            "    return response",
            "",
            "",
            "# TODO(alexstephen): Implement updating metadata on existing resources.",
            "",
            "# Expose instance 'metadata' as a simple name/value pair hash. However the API",
            "# defines metadata as a NestedObject with the following layout:",
            "#",
            "# metadata {",
            "#   fingerprint: 'hash-of-last-metadata'",
            "#   items: [",
            "#     {",
            "#       key: 'metadata1-key'",
            "#       value: 'metadata1-value'",
            "#     },",
            "#     ...",
            "#   ]",
            "# }",
            "#",
            "def metadata_encoder(metadata):",
            "    metadata_new = []",
            "    for key in metadata:",
            "        value = metadata[key]",
            "        metadata_new.append({\"key\": key, \"value\": value})",
            "    return {'items': metadata_new}",
            "",
            "",
            "# Map metadata.items[]{key:,value:} => metadata[key]=value",
            "def metadata_decoder(metadata):",
            "    items = {}",
            "    if 'items' in metadata:",
            "        metadata_items = metadata['items']",
            "        for item in metadata_items:",
            "            items[item['key']] = item['value']",
            "    return items",
            "",
            "",
            "class InstanceTemplateProperties(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get('can_ip_forward'),",
            "                u'description': self.request.get('description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get('disks', []), self.module).to_request(),",
            "                u'labels': self.request.get('labels'),",
            "                u'machineType': self.request.get('machine_type'),",
            "                u'minCpuPlatform': self.request.get('min_cpu_platform'),",
            "                u'metadata': self.request.get('metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get('guest_accelerators', []), self.module).to_request(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get('network_interfaces', []), self.module).to_request(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get('scheduling', {}), self.module).to_request(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get('service_accounts', []), self.module).to_request(),",
            "                u'tags': InstanceTemplateTags(self.request.get('tags', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get(u'canIpForward'),",
            "                u'description': self.request.get(u'description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get(u'disks', []), self.module).from_response(),",
            "                u'labels': self.request.get(u'labels'),",
            "                u'machineType': self.request.get(u'machineType'),",
            "                u'minCpuPlatform': self.request.get(u'minCpuPlatform'),",
            "                u'metadata': self.request.get(u'metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get(u'guestAccelerators', []), self.module).from_response(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get(u'networkInterfaces', []), self.module).from_response(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get(u'scheduling', {}), self.module).from_response(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get(u'serviceAccounts', []), self.module).from_response(),",
            "                u'tags': InstanceTemplateTags(self.request.get(u'tags', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDisksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get('auto_delete'),",
            "                u'boot': item.get('boot'),",
            "                u'deviceName': item.get('device_name'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get('disk_encryption_key', {}), self.module).to_request(),",
            "                u'index': item.get('index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(item.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get('interface'),",
            "                u'mode': item.get('mode'),",
            "                u'source': replace_resource_dict(item.get(u'source', {}), 'name'),",
            "                u'type': item.get('type'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get(u'autoDelete'),",
            "                u'boot': item.get(u'boot'),",
            "                u'deviceName': item.get(u'deviceName'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get(u'diskEncryptionKey', {}), self.module).from_response(),",
            "                u'index': item.get(u'index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(self.module.params.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get(u'interface'),",
            "                u'mode': item.get(u'mode'),",
            "                u'source': item.get(u'source'),",
            "                u'type': item.get(u'type'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'rsaEncryptedKey': self.request.get('rsa_encrypted_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'rsaEncryptedKey': self.request.get(u'rsaEncryptedKey')})",
            "",
            "",
            "class InstanceTemplateInitializeparams(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get('disk_name'),",
            "                u'diskSizeGb': self.request.get('disk_size_gb'),",
            "                u'diskType': disk_type_selflink(self.request.get('disk_type'), self.module.params),",
            "                u'sourceImage': self.request.get('source_image'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get('source_image_encryption_key', {}), self.module",
            "                ).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get(u'diskName'),",
            "                u'diskSizeGb': self.request.get(u'diskSizeGb'),",
            "                u'diskType': self.request.get(u'diskType'),",
            "                u'sourceImage': self.request.get(u'sourceImage'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get(u'sourceImageEncryptionKey', {}), self.module",
            "                ).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class InstanceTemplateGuestacceleratorsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get('accelerator_count'), u'acceleratorType': item.get('accelerator_type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get(u'acceleratorCount'), u'acceleratorType': item.get(u'acceleratorType')})",
            "",
            "",
            "class InstanceTemplateNetworkinterfacesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get('access_configs', []), self.module).to_request(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get('alias_ip_ranges', []), self.module).to_request(),",
            "                u'network': replace_resource_dict(item.get(u'network', {}), 'selfLink'),",
            "                u'networkIP': item.get('network_ip'),",
            "                u'subnetwork': replace_resource_dict(item.get(u'subnetwork', {}), 'selfLink'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get(u'accessConfigs', []), self.module).from_response(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get(u'aliasIpRanges', []), self.module).from_response(),",
            "                u'network': item.get(u'network'),",
            "                u'networkIP': item.get(u'networkIP'),",
            "                u'subnetwork': item.get(u'subnetwork'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateAccessconfigsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {u'name': item.get('name'), u'natIP': replace_resource_dict(item.get(u'nat_ip', {}), 'address'), u'type': item.get('type')}",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'natIP': item.get(u'natIP'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceTemplateAliasiprangesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get('ip_cidr_range'), u'subnetworkRangeName': item.get('subnetwork_range_name')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get(u'ipCidrRange'), u'subnetworkRangeName': item.get(u'subnetworkRangeName')})",
            "",
            "",
            "class InstanceTemplateScheduling(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get('automatic_restart'),",
            "                u'onHostMaintenance': self.request.get('on_host_maintenance'),",
            "                u'preemptible': self.request.get('preemptible'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get(u'automaticRestart'),",
            "                u'onHostMaintenance': self.request.get(u'onHostMaintenance'),",
            "                u'preemptible': self.request.get(u'preemptible'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateServiceaccountsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get('email'), u'scopes': item.get('scopes')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get(u'email'), u'scopes': item.get(u'scopes')})",
            "",
            "",
            "class InstanceTemplateTags(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get('fingerprint'), u'items': self.request.get('items')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get(u'fingerprint'), u'items': self.request.get(u'items')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_instance_template",
            "description:",
            "- Defines an Instance Template resource that provides configuration settings for your",
            "  virtual machine instances. Instance templates are not tied to the lifetime of an",
            "  instance and can be used and reused as to deploy virtual machines. You can also",
            "  use different templates to create different virtual machine configurations. Instance",
            "  templates are required when you create a managed instance group.",
            "- 'Tip: Disks should be set to autoDelete=true so that leftover disks are not left",
            "  behind on machine deletion.'",
            "short_description: Creates a GCP InstanceTemplate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "    required: true",
            "    type: str",
            "  properties:",
            "    description:",
            "    - The instance properties for this instance template.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      can_ip_forward:",
            "        description:",
            "        - Enables instances created based on this template to send packets with source",
            "          IP addresses other than their own and receive packets with destination IP",
            "          addresses other than their own. If these instances will be used as an IP",
            "          gateway or it will be set as the next-hop in a Route resource, specify true.",
            "          If unsure, leave this set to false.",
            "        required: false",
            "        type: bool",
            "      description:",
            "        description:",
            "        - An optional text description for the instances that are created from this",
            "          instance template.",
            "        required: false",
            "        type: str",
            "      disks:",
            "        description:",
            "        - An array of disks that are associated with the instances that are created",
            "          from this template.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          auto_delete:",
            "            description:",
            "            - Specifies whether the disk will be auto-deleted when the instance is",
            "              deleted (but not when the disk is detached from the instance).",
            "            - 'Tip: Disks should be set to autoDelete=true so that leftover disks",
            "              are not left behind on machine deletion.'",
            "            required: false",
            "            type: bool",
            "          boot:",
            "            description:",
            "            - Indicates that this is a boot disk. The virtual machine will use the",
            "              first partition of the disk for its root filesystem.",
            "            required: false",
            "            type: bool",
            "          device_name:",
            "            description:",
            "            - Specifies a unique device name of your choice that is reflected into",
            "              the /dev/disk/by-id/google-* tree of a Linux operating system running",
            "              within the instance. This name can be used to reference the device for",
            "              mounting, resizing, and so on, from within the instance.",
            "            required: false",
            "            type: str",
            "          disk_encryption_key:",
            "            description:",
            "            - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "            required: false",
            "            type: dict",
            "            suboptions:",
            "              raw_key:",
            "                description:",
            "                - Specifies a 256-bit customer-supplied encryption key, encoded in",
            "                  RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                required: false",
            "                type: str",
            "              rsa_encrypted_key:",
            "                description:",
            "                - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                  encryption key to either encrypt or decrypt this resource.",
            "                required: false",
            "                type: str",
            "          index:",
            "            description:",
            "            - Assigns a zero-based index to this disk, where 0 is reserved for the",
            "              boot disk. For example, if you have many disks attached to an instance,",
            "              each disk would have a unique index number. If not specified, the server",
            "              will choose an appropriate value.",
            "            required: false",
            "            type: int",
            "          initialize_params:",
            "            description:",
            "            - Specifies the parameters for a new disk that will be created alongside",
            "              the new instance. Use initialization parameters to create boot disks",
            "              or local SSDs attached to the new instance.",
            "            required: false",
            "            type: dict",
            "            suboptions:",
            "              disk_name:",
            "                description:",
            "                - Specifies the disk name. If not specified, the default is to use",
            "                  the name of the instance.",
            "                required: false",
            "                type: str",
            "              disk_size_gb:",
            "                description:",
            "                - Specifies the size of the disk in base-2 GB.",
            "                required: false",
            "                type: int",
            "              disk_type:",
            "                description:",
            "                - Reference to a disk type.",
            "                - Specifies the disk type to use to create the instance.",
            "                - If not specified, the default is pd-standard.",
            "                required: false",
            "                type: str",
            "              source_image:",
            "                description:",
            "                - The source image to create this disk. When creating a new instance,",
            "                  one of initializeParams.sourceImage or disks.source is required.",
            "                  To create a disk with one of the public operating system images,",
            "                  specify the image by its family name.",
            "                required: false",
            "                type: str",
            "              source_image_encryption_key:",
            "                description:",
            "                - The customer-supplied encryption key of the source image. Required",
            "                  if the source image is protected by a customer-supplied encryption",
            "                  key.",
            "                - Instance templates do not store customer-supplied encryption keys,",
            "                  so you cannot create disks for instances in a managed instance group",
            "                  if the source images are encrypted with your own keys.",
            "                required: false",
            "                type: dict",
            "                suboptions:",
            "                  raw_key:",
            "                    description:",
            "                    - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                      in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                    required: false",
            "                    type: str",
            "          interface:",
            "            description:",
            "            - Specifies the disk interface to use for attaching this disk, which is",
            "              either SCSI or NVME. The default is SCSI.",
            "            - Persistent disks must always use SCSI and the request will fail if you",
            "              attempt to attach a persistent disk in any other format than SCSI.",
            "            - 'Some valid choices include: \"SCSI\", \"NVME\"'",
            "            required: false",
            "            type: str",
            "          mode:",
            "            description:",
            "            - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "              If not specified, the default is to attach the disk in READ_WRITE mode.",
            "            - 'Some valid choices include: \"READ_WRITE\", \"READ_ONLY\"'",
            "            required: false",
            "            type: str",
            "          source:",
            "            description:",
            "            - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "              or disks.source is required.",
            "            - If desired, you can also attach existing non-root persistent disks using",
            "              this property. This field is only applicable for persistent disks.",
            "            - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "              the disk.",
            "            - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "              in two ways. First, you can place a dictionary with key ''name'' and",
            "              value of your resource''s name Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_disk task and then set this source",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "          type:",
            "            description:",
            "            - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not",
            "              specified, the default is PERSISTENT.",
            "            - 'Some valid choices include: \"SCRATCH\", \"PERSISTENT\"'",
            "            required: false",
            "            type: str",
            "      labels:",
            "        description:",
            "        - Labels to apply to this address. A list of key->value pairs.",
            "        required: false",
            "        type: dict",
            "        version_added: 2.9",
            "      machine_type:",
            "        description:",
            "        - The machine type to use in the VM instance template.",
            "        required: true",
            "        type: str",
            "      min_cpu_platform:",
            "        description:",
            "        - Specifies a minimum CPU platform for the VM instance. Applicable values",
            "          are the friendly names of CPU platforms .",
            "        required: false",
            "        type: str",
            "      metadata:",
            "        description:",
            "        - The metadata key/value pairs to assign to instances that are created from",
            "          this template. These pairs can consist of custom metadata or predefined",
            "          keys.",
            "        required: false",
            "        type: dict",
            "      guest_accelerators:",
            "        description:",
            "        - List of the type and count of accelerator cards attached to the instance",
            "          .",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          accelerator_count:",
            "            description:",
            "            - The number of the guest accelerator cards exposed to this instance.",
            "            required: false",
            "            type: int",
            "          accelerator_type:",
            "            description:",
            "            - Full or partial URL of the accelerator type resource to expose to this",
            "              instance.",
            "            required: false",
            "            type: str",
            "      network_interfaces:",
            "        description:",
            "        - An array of configurations for this interface. This specifies how this interface",
            "          is configured to interact with other network services, such as connecting",
            "          to the internet. Only one network interface is supported per instance.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          access_configs:",
            "            description:",
            "            - An array of configurations for this interface. Currently, only one access",
            "              config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs",
            "              specified, then this instance will have no external internet access.",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              name:",
            "                description:",
            "                - The name of this access configuration. The default and recommended",
            "                  name is External NAT but you can use any arbitrary string you would",
            "                  like. For example, My external IP or Network Access.",
            "                required: true",
            "                type: str",
            "              nat_ip:",
            "                description:",
            "                - Reference to an address.",
            "                - An external IP address associated with this instance.",
            "                - Specify an unused static external IP address available to the project",
            "                  or leave this field undefined to use an IP from a shared ephemeral",
            "                  IP address pool. If you specify a static external IP address, it",
            "                  must live in the same region as the zone of the instance.",
            "                - 'This field represents a link to a Address resource in GCP. It can",
            "                  be specified in two ways. First, you can place a dictionary with",
            "                  key ''address'' and value of your resource''s address Alternatively,",
            "                  you can add `register: name-of-resource` to a gcp_compute_address",
            "                  task and then set this nat_ip field to \"{{ name-of-resource }}\"'",
            "                required: false",
            "                type: dict",
            "              type:",
            "                description:",
            "                - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "                - 'Some valid choices include: \"ONE_TO_ONE_NAT\"'",
            "                required: true",
            "                type: str",
            "          alias_ip_ranges:",
            "            description:",
            "            - An array of alias IP ranges for this network interface. Can only be",
            "              specified for network interfaces on subnet-mode networks.",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              ip_cidr_range:",
            "                description:",
            "                - The IP CIDR range represented by this alias IP range.",
            "                - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                  contain IP addresses reserved by system or used by other network",
            "                  interfaces. This range may be a single IP address (e.g. 10.2.3.4),",
            "                  a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "                required: false",
            "                type: str",
            "              subnetwork_range_name:",
            "                description:",
            "                - Optional subnetwork secondary range name specifying the secondary",
            "                  range from which to allocate the IP CIDR range for this alias IP",
            "                  range. If left unspecified, the primary range of the subnetwork",
            "                  will be used.",
            "                required: false",
            "                type: str",
            "          network:",
            "            description:",
            "            - Specifies the title of an existing network. When creating an instance,",
            "              if neither the network nor the subnetwork is specified, the default",
            "              network global/networks/default is used; if the network is not specified",
            "              but the subnetwork is specified, the network is inferred.",
            "            - 'This field represents a link to a Network resource in GCP. It can be",
            "              specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "              and value of your resource''s selfLink Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_network task and then set this network",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "          network_ip:",
            "            description:",
            "            - An IPv4 internal network address to assign to the instance for this",
            "              network interface. If not specified by the user, an unused internal",
            "              IP is assigned by the system.",
            "            required: false",
            "            type: str",
            "          subnetwork:",
            "            description:",
            "            - Reference to a VPC network.",
            "            - If the network resource is in legacy mode, do not provide this property.",
            "              If the network is in auto subnet mode, providing the subnetwork is optional.",
            "              If the network is in custom subnet mode, then this field should be specified.",
            "            - 'This field represents a link to a Subnetwork resource in GCP. It can",
            "              be specified in two ways. First, you can place a dictionary with key",
            "              ''selfLink'' and value of your resource''s selfLink Alternatively, you",
            "              can add `register: name-of-resource` to a gcp_compute_subnetwork task",
            "              and then set this subnetwork field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "            type: dict",
            "      scheduling:",
            "        description:",
            "        - Sets the scheduling options for this instance.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          automatic_restart:",
            "            description:",
            "            - Specifies whether the instance should be automatically restarted if",
            "              it is terminated by Compute Engine (not terminated by a user).",
            "            - You can only set the automatic restart option for standard instances.",
            "              Preemptible instances cannot be automatically restarted.",
            "            required: false",
            "            type: bool",
            "          on_host_maintenance:",
            "            description:",
            "            - Defines the maintenance behavior for this instance. For standard instances,",
            "              the default behavior is MIGRATE. For preemptible instances, the default",
            "              and only possible behavior is TERMINATE.",
            "            - For more information, see Setting Instance Scheduling Options.",
            "            required: false",
            "            type: str",
            "          preemptible:",
            "            description:",
            "            - Defines whether the instance is preemptible. This can only be set during",
            "              instance creation, it cannot be set or changed after the instance has",
            "              been created.",
            "            required: false",
            "            type: bool",
            "      service_accounts:",
            "        description:",
            "        - A list of service accounts, with their specified scopes, authorized for",
            "          this instance. Only one service account per VM instance is supported.",
            "        required: false",
            "        type: list",
            "        suboptions:",
            "          email:",
            "            description:",
            "            - Email address of the service account.",
            "            required: false",
            "            type: str",
            "          scopes:",
            "            description:",
            "            - The list of scopes to be made available for this service account.",
            "            required: false",
            "            type: list",
            "      tags:",
            "        description:",
            "        - A list of tags to apply to this instance. Tags are used to identify valid",
            "          sources or targets for network firewalls and are specified by the client",
            "          during instance creation. The tags can be later modified by the setTags",
            "          method. Each tag within the list must comply with RFC1035.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          fingerprint:",
            "            description:",
            "            - Specifies a fingerprint for this request, which is essentially a hash",
            "              of the metadata's contents and used for optimistic locking.",
            "            - The fingerprint is initially generated by Compute Engine and changes",
            "              after every request to modify or update metadata. You must always provide",
            "              an up-to-date fingerprint hash in order to update or change metadata.",
            "            required: false",
            "            type: str",
            "          items:",
            "            description:",
            "            - An array of tags. Each tag must be 1-63 characters long, and comply",
            "              with RFC1035.",
            "            required: false",
            "            type: list",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-instancetemplate",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a address",
            "  gcp_compute_address:",
            "    name: address-instancetemplate",
            "    region: us-west1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: address",
            "",
            "- name: create a instance template",
            "  gcp_compute_instance_template:",
            "    name: test_object",
            "    properties:",
            "      disks:",
            "      - auto_delete: 'true'",
            "        boot: 'true'",
            "        initialize_params:",
            "          source_image: projects/ubuntu-os-cloud/global/images/family/ubuntu-1604-lts",
            "      machine_type: n1-standard-1",
            "      network_interfaces:",
            "      - network: \"{{ network }}\"",
            "        access_configs:",
            "        - name: test-config",
            "          type: ONE_TO_ONE_NAT",
            "          nat_ip: \"{{ address }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "  returned: success",
            "  type: str",
            "properties:",
            "  description:",
            "  - The instance properties for this instance template.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    canIpForward:",
            "      description:",
            "      - Enables instances created based on this template to send packets with source",
            "        IP addresses other than their own and receive packets with destination IP",
            "        addresses other than their own. If these instances will be used as an IP gateway",
            "        or it will be set as the next-hop in a Route resource, specify true. If unsure,",
            "        leave this set to false.",
            "      returned: success",
            "      type: bool",
            "    description:",
            "      description:",
            "      - An optional text description for the instances that are created from this",
            "        instance template.",
            "      returned: success",
            "      type: str",
            "    disks:",
            "      description:",
            "      - An array of disks that are associated with the instances that are created",
            "        from this template.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        autoDelete:",
            "          description:",
            "          - Specifies whether the disk will be auto-deleted when the instance is deleted",
            "            (but not when the disk is detached from the instance).",
            "          - 'Tip: Disks should be set to autoDelete=true so that leftover disks are",
            "            not left behind on machine deletion.'",
            "          returned: success",
            "          type: bool",
            "        boot:",
            "          description:",
            "          - Indicates that this is a boot disk. The virtual machine will use the first",
            "            partition of the disk for its root filesystem.",
            "          returned: success",
            "          type: bool",
            "        deviceName:",
            "          description:",
            "          - Specifies a unique device name of your choice that is reflected into the",
            "            /dev/disk/by-id/google-* tree of a Linux operating system running within",
            "            the instance. This name can be used to reference the device for mounting,",
            "            resizing, and so on, from within the instance.",
            "          returned: success",
            "          type: str",
            "        diskEncryptionKey:",
            "          description:",
            "          - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            rawKey:",
            "              description:",
            "              - Specifies a 256-bit customer-supplied encryption key, encoded in RFC",
            "                4648 base64 to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            rsaEncryptedKey:",
            "              description:",
            "              - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                encryption key to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            sha256:",
            "              description:",
            "              - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                encryption key that protects this resource.",
            "              returned: success",
            "              type: str",
            "        index:",
            "          description:",
            "          - Assigns a zero-based index to this disk, where 0 is reserved for the boot",
            "            disk. For example, if you have many disks attached to an instance, each",
            "            disk would have a unique index number. If not specified, the server will",
            "            choose an appropriate value.",
            "          returned: success",
            "          type: int",
            "        initializeParams:",
            "          description:",
            "          - Specifies the parameters for a new disk that will be created alongside",
            "            the new instance. Use initialization parameters to create boot disks or",
            "            local SSDs attached to the new instance.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            diskName:",
            "              description:",
            "              - Specifies the disk name. If not specified, the default is to use the",
            "                name of the instance.",
            "              returned: success",
            "              type: str",
            "            diskSizeGb:",
            "              description:",
            "              - Specifies the size of the disk in base-2 GB.",
            "              returned: success",
            "              type: int",
            "            diskType:",
            "              description:",
            "              - Reference to a disk type.",
            "              - Specifies the disk type to use to create the instance.",
            "              - If not specified, the default is pd-standard.",
            "              returned: success",
            "              type: str",
            "            sourceImage:",
            "              description:",
            "              - The source image to create this disk. When creating a new instance,",
            "                one of initializeParams.sourceImage or disks.source is required. To",
            "                create a disk with one of the public operating system images, specify",
            "                the image by its family name.",
            "              returned: success",
            "              type: str",
            "            sourceImageEncryptionKey:",
            "              description:",
            "              - The customer-supplied encryption key of the source image. Required",
            "                if the source image is protected by a customer-supplied encryption",
            "                key.",
            "              - Instance templates do not store customer-supplied encryption keys,",
            "                so you cannot create disks for instances in a managed instance group",
            "                if the source images are encrypted with your own keys.",
            "              returned: success",
            "              type: complex",
            "              contains:",
            "                rawKey:",
            "                  description:",
            "                  - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                    in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                  returned: success",
            "                  type: str",
            "                sha256:",
            "                  description:",
            "                  - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                    encryption key that protects this resource.",
            "                  returned: success",
            "                  type: str",
            "        interface:",
            "          description:",
            "          - Specifies the disk interface to use for attaching this disk, which is",
            "            either SCSI or NVME. The default is SCSI.",
            "          - Persistent disks must always use SCSI and the request will fail if you",
            "            attempt to attach a persistent disk in any other format than SCSI.",
            "          returned: success",
            "          type: str",
            "        mode:",
            "          description:",
            "          - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "            If not specified, the default is to attach the disk in READ_WRITE mode.",
            "          returned: success",
            "          type: str",
            "        source:",
            "          description:",
            "          - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "            or disks.source is required.",
            "          - If desired, you can also attach existing non-root persistent disks using",
            "            this property. This field is only applicable for persistent disks.",
            "          - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "            the disk.",
            "          returned: success",
            "          type: dict",
            "        type:",
            "          description:",
            "          - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not specified,",
            "            the default is PERSISTENT.",
            "          returned: success",
            "          type: str",
            "    labels:",
            "      description:",
            "      - Labels to apply to this address. A list of key->value pairs.",
            "      returned: success",
            "      type: dict",
            "    machineType:",
            "      description:",
            "      - The machine type to use in the VM instance template.",
            "      returned: success",
            "      type: str",
            "    minCpuPlatform:",
            "      description:",
            "      - Specifies a minimum CPU platform for the VM instance. Applicable values are",
            "        the friendly names of CPU platforms .",
            "      returned: success",
            "      type: str",
            "    metadata:",
            "      description:",
            "      - The metadata key/value pairs to assign to instances that are created from",
            "        this template. These pairs can consist of custom metadata or predefined keys.",
            "      returned: success",
            "      type: dict",
            "    guestAccelerators:",
            "      description:",
            "      - List of the type and count of accelerator cards attached to the instance .",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        acceleratorCount:",
            "          description:",
            "          - The number of the guest accelerator cards exposed to this instance.",
            "          returned: success",
            "          type: int",
            "        acceleratorType:",
            "          description:",
            "          - Full or partial URL of the accelerator type resource to expose to this",
            "            instance.",
            "          returned: success",
            "          type: str",
            "    networkInterfaces:",
            "      description:",
            "      - An array of configurations for this interface. This specifies how this interface",
            "        is configured to interact with other network services, such as connecting",
            "        to the internet. Only one network interface is supported per instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        accessConfigs:",
            "          description:",
            "          - An array of configurations for this interface. Currently, only one access",
            "            config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs specified,",
            "            then this instance will have no external internet access.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            name:",
            "              description:",
            "              - The name of this access configuration. The default and recommended",
            "                name is External NAT but you can use any arbitrary string you would",
            "                like. For example, My external IP or Network Access.",
            "              returned: success",
            "              type: str",
            "            natIP:",
            "              description:",
            "              - Reference to an address.",
            "              - An external IP address associated with this instance.",
            "              - Specify an unused static external IP address available to the project",
            "                or leave this field undefined to use an IP from a shared ephemeral",
            "                IP address pool. If you specify a static external IP address, it must",
            "                live in the same region as the zone of the instance.",
            "              returned: success",
            "              type: dict",
            "            type:",
            "              description:",
            "              - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "              returned: success",
            "              type: str",
            "        aliasIpRanges:",
            "          description:",
            "          - An array of alias IP ranges for this network interface. Can only be specified",
            "            for network interfaces on subnet-mode networks.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            ipCidrRange:",
            "              description:",
            "              - The IP CIDR range represented by this alias IP range.",
            "              - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                contain IP addresses reserved by system or used by other network interfaces.",
            "                This range may be a single IP address (e.g. 10.2.3.4), a netmask (e.g.",
            "                /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "              returned: success",
            "              type: str",
            "            subnetworkRangeName:",
            "              description:",
            "              - Optional subnetwork secondary range name specifying the secondary",
            "                range from which to allocate the IP CIDR range for this alias IP range.",
            "                If left unspecified, the primary range of the subnetwork will be used.",
            "              returned: success",
            "              type: str",
            "        name:",
            "          description:",
            "          - The name of the network interface, generated by the server. For network",
            "            devices, these are eth0, eth1, etc .",
            "          returned: success",
            "          type: str",
            "        network:",
            "          description:",
            "          - Specifies the title of an existing network. When creating an instance,",
            "            if neither the network nor the subnetwork is specified, the default network",
            "            global/networks/default is used; if the network is not specified but the",
            "            subnetwork is specified, the network is inferred.",
            "          returned: success",
            "          type: dict",
            "        networkIP:",
            "          description:",
            "          - An IPv4 internal network address to assign to the instance for this network",
            "            interface. If not specified by the user, an unused internal IP is assigned",
            "            by the system.",
            "          returned: success",
            "          type: str",
            "        subnetwork:",
            "          description:",
            "          - Reference to a VPC network.",
            "          - If the network resource is in legacy mode, do not provide this property.",
            "            If the network is in auto subnet mode, providing the subnetwork is optional.",
            "            If the network is in custom subnet mode, then this field should be specified.",
            "          returned: success",
            "          type: dict",
            "    scheduling:",
            "      description:",
            "      - Sets the scheduling options for this instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        automaticRestart:",
            "          description:",
            "          - Specifies whether the instance should be automatically restarted if it",
            "            is terminated by Compute Engine (not terminated by a user).",
            "          - You can only set the automatic restart option for standard instances.",
            "            Preemptible instances cannot be automatically restarted.",
            "          returned: success",
            "          type: bool",
            "        onHostMaintenance:",
            "          description:",
            "          - Defines the maintenance behavior for this instance. For standard instances,",
            "            the default behavior is MIGRATE. For preemptible instances, the default",
            "            and only possible behavior is TERMINATE.",
            "          - For more information, see Setting Instance Scheduling Options.",
            "          returned: success",
            "          type: str",
            "        preemptible:",
            "          description:",
            "          - Defines whether the instance is preemptible. This can only be set during",
            "            instance creation, it cannot be set or changed after the instance has",
            "            been created.",
            "          returned: success",
            "          type: bool",
            "    serviceAccounts:",
            "      description:",
            "      - A list of service accounts, with their specified scopes, authorized for this",
            "        instance. Only one service account per VM instance is supported.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        email:",
            "          description:",
            "          - Email address of the service account.",
            "          returned: success",
            "          type: str",
            "        scopes:",
            "          description:",
            "          - The list of scopes to be made available for this service account.",
            "          returned: success",
            "          type: list",
            "    tags:",
            "      description:",
            "      - A list of tags to apply to this instance. Tags are used to identify valid",
            "        sources or targets for network firewalls and are specified by the client during",
            "        instance creation. The tags can be later modified by the setTags method. Each",
            "        tag within the list must comply with RFC1035.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        fingerprint:",
            "          description:",
            "          - Specifies a fingerprint for this request, which is essentially a hash",
            "            of the metadata's contents and used for optimistic locking.",
            "          - The fingerprint is initially generated by Compute Engine and changes after",
            "            every request to modify or update metadata. You must always provide an",
            "            up-to-date fingerprint hash in order to update or change metadata.",
            "          returned: success",
            "          type: str",
            "        items:",
            "          description:",
            "          - An array of tags. Each tag must be 1-63 characters long, and comply with",
            "            RFC1035.",
            "          returned: success",
            "          type: list",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(required=True, type='str'),",
            "            properties=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    can_ip_forward=dict(type='bool'),",
            "                    description=dict(type='str'),",
            "                    disks=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            auto_delete=dict(type='bool'),",
            "                            boot=dict(type='bool'),",
            "                            device_name=dict(type='str'),",
            "                            disk_encryption_key=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    raw_key=dict(type='str', no_log=True),",
            "                                    rsa_encrypted_key=dict(type='str', no_log=True),",
            "                                ),",
            "                            ),",
            "                            index=dict(type='int'),",
            "                            initialize_params=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    disk_name=dict(type='str'),",
            "                                    disk_size_gb=dict(type='int'),",
            "                                    disk_type=dict(type='str'),",
            "                                    source_image=dict(type='str'),",
            "                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "                                ),",
            "                            ),",
            "                            interface=dict(type='str'),",
            "                            mode=dict(type='str'),",
            "                            source=dict(type='dict'),",
            "                            type=dict(type='str'),",
            "                        ),",
            "                    ),",
            "                    labels=dict(type='dict'),",
            "                    machine_type=dict(required=True, type='str'),",
            "                    min_cpu_platform=dict(type='str'),",
            "                    metadata=dict(type='dict'),",
            "                    guest_accelerators=dict(type='list', elements='dict', options=dict(accelerator_count=dict(type='int'), accelerator_type=dict(type='str'))),",
            "                    network_interfaces=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            access_configs=dict(",
            "                                type='list',",
            "                                elements='dict',",
            "                                options=dict(name=dict(required=True, type='str'), nat_ip=dict(type='dict'), type=dict(required=True, type='str')),",
            "                            ),",
            "                            alias_ip_ranges=dict(",
            "                                type='list', elements='dict', options=dict(ip_cidr_range=dict(type='str'), subnetwork_range_name=dict(type='str'))",
            "                            ),",
            "                            network=dict(type='dict'),",
            "                            network_ip=dict(type='str'),",
            "                            subnetwork=dict(type='dict'),",
            "                        ),",
            "                    ),",
            "                    scheduling=dict(",
            "                        type='dict', options=dict(automatic_restart=dict(type='bool'), on_host_maintenance=dict(type='str'), preemptible=dict(type='bool'))",
            "                    ),",
            "                    service_accounts=dict(type='list', elements='dict', options=dict(email=dict(type='str'), scopes=dict(type='list', elements='str'))),",
            "                    tags=dict(type='dict', options=dict(fingerprint=dict(type='str'), items=dict(type='list', elements='str'))),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#instanceTemplate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#instanceTemplate',",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'properties': InstanceTemplateProperties(module.params.get('properties', {}), module).to_request(),",
            "    }",
            "    request = encode_request(request, module)",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    result = decode_response(result, module)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "    request = decode_response(request, module)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'properties': InstanceTemplateProperties(response.get(u'properties', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    response = fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#instanceTemplate')",
            "    if response:",
            "        return decode_response(response, module)",
            "    else:",
            "        return {}",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "def encode_request(request, module):",
            "    if 'properties' in request and request['properties'] is not None and 'metadata' in request['properties'] and request['properties']['metadata'] is not None:",
            "        request['properties']['metadata'] = metadata_encoder(request['properties']['metadata'])",
            "    return request",
            "",
            "",
            "def decode_response(response, module):",
            "    if (",
            "        'properties' in response",
            "        and response['properties'] is not None",
            "        and 'metadata' in response['properties']",
            "        and response['properties']['metadata'] is not None",
            "    ):",
            "        response['properties']['metadata'] = metadata_decoder(response['properties']['metadata'])",
            "    return response",
            "",
            "",
            "# TODO(alexstephen): Implement updating metadata on existing resources.",
            "",
            "# Expose instance 'metadata' as a simple name/value pair hash. However the API",
            "# defines metadata as a NestedObject with the following layout:",
            "#",
            "# metadata {",
            "#   fingerprint: 'hash-of-last-metadata'",
            "#   items: [",
            "#     {",
            "#       key: 'metadata1-key'",
            "#       value: 'metadata1-value'",
            "#     },",
            "#     ...",
            "#   ]",
            "# }",
            "#",
            "def metadata_encoder(metadata):",
            "    metadata_new = []",
            "    for key in metadata:",
            "        value = metadata[key]",
            "        metadata_new.append({\"key\": key, \"value\": value})",
            "    return {'items': metadata_new}",
            "",
            "",
            "# Map metadata.items[]{key:,value:} => metadata[key]=value",
            "def metadata_decoder(metadata):",
            "    items = {}",
            "    if 'items' in metadata:",
            "        metadata_items = metadata['items']",
            "        for item in metadata_items:",
            "            items[item['key']] = item['value']",
            "    return items",
            "",
            "",
            "class InstanceTemplateProperties(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get('can_ip_forward'),",
            "                u'description': self.request.get('description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get('disks', []), self.module).to_request(),",
            "                u'labels': self.request.get('labels'),",
            "                u'machineType': self.request.get('machine_type'),",
            "                u'minCpuPlatform': self.request.get('min_cpu_platform'),",
            "                u'metadata': self.request.get('metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get('guest_accelerators', []), self.module).to_request(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get('network_interfaces', []), self.module).to_request(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get('scheduling', {}), self.module).to_request(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get('service_accounts', []), self.module).to_request(),",
            "                u'tags': InstanceTemplateTags(self.request.get('tags', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get(u'canIpForward'),",
            "                u'description': self.request.get(u'description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get(u'disks', []), self.module).from_response(),",
            "                u'labels': self.request.get(u'labels'),",
            "                u'machineType': self.request.get(u'machineType'),",
            "                u'minCpuPlatform': self.request.get(u'minCpuPlatform'),",
            "                u'metadata': self.request.get(u'metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get(u'guestAccelerators', []), self.module).from_response(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get(u'networkInterfaces', []), self.module).from_response(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get(u'scheduling', {}), self.module).from_response(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get(u'serviceAccounts', []), self.module).from_response(),",
            "                u'tags': InstanceTemplateTags(self.request.get(u'tags', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDisksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get('auto_delete'),",
            "                u'boot': item.get('boot'),",
            "                u'deviceName': item.get('device_name'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get('disk_encryption_key', {}), self.module).to_request(),",
            "                u'index': item.get('index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(item.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get('interface'),",
            "                u'mode': item.get('mode'),",
            "                u'source': replace_resource_dict(item.get(u'source', {}), 'name'),",
            "                u'type': item.get('type'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get(u'autoDelete'),",
            "                u'boot': item.get(u'boot'),",
            "                u'deviceName': item.get(u'deviceName'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get(u'diskEncryptionKey', {}), self.module).from_response(),",
            "                u'index': item.get(u'index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(self.module.params.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get(u'interface'),",
            "                u'mode': item.get(u'mode'),",
            "                u'source': item.get(u'source'),",
            "                u'type': item.get(u'type'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'rsaEncryptedKey': self.request.get('rsa_encrypted_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'rsaEncryptedKey': self.request.get(u'rsaEncryptedKey')})",
            "",
            "",
            "class InstanceTemplateInitializeparams(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get('disk_name'),",
            "                u'diskSizeGb': self.request.get('disk_size_gb'),",
            "                u'diskType': disk_type_selflink(self.request.get('disk_type'), self.module.params),",
            "                u'sourceImage': self.request.get('source_image'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get('source_image_encryption_key', {}), self.module",
            "                ).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get(u'diskName'),",
            "                u'diskSizeGb': self.request.get(u'diskSizeGb'),",
            "                u'diskType': self.request.get(u'diskType'),",
            "                u'sourceImage': self.request.get(u'sourceImage'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get(u'sourceImageEncryptionKey', {}), self.module",
            "                ).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class InstanceTemplateGuestacceleratorsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get('accelerator_count'), u'acceleratorType': item.get('accelerator_type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get(u'acceleratorCount'), u'acceleratorType': item.get(u'acceleratorType')})",
            "",
            "",
            "class InstanceTemplateNetworkinterfacesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get('access_configs', []), self.module).to_request(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get('alias_ip_ranges', []), self.module).to_request(),",
            "                u'network': replace_resource_dict(item.get(u'network', {}), 'selfLink'),",
            "                u'networkIP': item.get('network_ip'),",
            "                u'subnetwork': replace_resource_dict(item.get(u'subnetwork', {}), 'selfLink'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get(u'accessConfigs', []), self.module).from_response(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get(u'aliasIpRanges', []), self.module).from_response(),",
            "                u'network': item.get(u'network'),",
            "                u'networkIP': item.get(u'networkIP'),",
            "                u'subnetwork': item.get(u'subnetwork'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateAccessconfigsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {u'name': item.get('name'), u'natIP': replace_resource_dict(item.get(u'nat_ip', {}), 'address'), u'type': item.get('type')}",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'natIP': item.get(u'natIP'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceTemplateAliasiprangesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get('ip_cidr_range'), u'subnetworkRangeName': item.get('subnetwork_range_name')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get(u'ipCidrRange'), u'subnetworkRangeName': item.get(u'subnetworkRangeName')})",
            "",
            "",
            "class InstanceTemplateScheduling(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get('automatic_restart'),",
            "                u'onHostMaintenance': self.request.get('on_host_maintenance'),",
            "                u'preemptible': self.request.get('preemptible'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get(u'automaticRestart'),",
            "                u'onHostMaintenance': self.request.get(u'onHostMaintenance'),",
            "                u'preemptible': self.request.get(u'preemptible'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateServiceaccountsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get('email'), u'scopes': item.get('scopes')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get(u'email'), u'scopes': item.get(u'scopes')})",
            "",
            "",
            "class InstanceTemplateTags(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get('fingerprint'), u'items': self.request.get('items')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get(u'fingerprint'), u'items': self.request.get(u'items')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "917": [
                "main"
            ],
            "926": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_region_disk.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": 369,
                "PatchRowcode": "             replica_zones=dict(required=True, type='list', elements='str'),"
            },
            "1": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 370,
                "PatchRowcode": "             type=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 371,
                "PatchRowcode": "             region=dict(required=True, type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "5": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 373,
                "PatchRowcode": "             source_snapshot=dict(type='dict'),"
            },
            "6": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 374,
                "PatchRowcode": "+            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "8": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "         )"
            },
            "9": {
                "beforePatchRowNumber": 376,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "     )"
            },
            "10": {
                "beforePatchRowNumber": 377,
                "afterPatchRowNumber": 377,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_region_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP RegionDisk",
            "version_added: 2.8",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    type: dict",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "    type: int",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    type: int",
            "  replica_zones:",
            "    description:",
            "    - URLs of the zones where the disk should be replicated to.",
            "    required: true",
            "    type: list",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    type: str",
            "  region:",
            "    description:",
            "    - A reference to the region where the disk resides.",
            "    required: true",
            "    type: str",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/beta/regionDisks)'",
            "- 'Adding or Resizing Regional Persistent Disks: U(https://cloud.google.com/compute/docs/disks/regional-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a region disk",
            "  gcp_compute_region_disk:",
            "    name: test_object",
            "    size_gb: 500",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    region: us-central1",
            "    replica_zones:",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-a",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-b",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last detach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "replicaZones:",
            "  description:",
            "  - URLs of the zones where the disk should be replicated to.",
            "  returned: success",
            "  type: list",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - A reference to the region where the disk resides.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            replica_zones=dict(required=True, type='list', elements='str'),",
            "            type=dict(type='str'),",
            "            region=dict(required=True, type='str'),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'diskEncryptionKey': RegionDiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': RegionDiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'replicaZones': module.params.get('replica_zones'),",
            "        u'type': region_disk_type_selflink(module.params.get('type'), module.params),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'replicaZones': response.get(u'replicaZones'),",
            "        u'type': response.get(u'type'),",
            "    }",
            "",
            "",
            "def zone_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def region_disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/regions/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class RegionDiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class RegionDiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_region_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP RegionDisk",
            "version_added: 2.8",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    type: dict",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "    type: list",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "    type: int",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    type: int",
            "  replica_zones:",
            "    description:",
            "    - URLs of the zones where the disk should be replicated to.",
            "    required: true",
            "    type: list",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    type: str",
            "  region:",
            "    description:",
            "    - A reference to the region where the disk resides.",
            "    required: true",
            "    type: str",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/beta/regionDisks)'",
            "- 'Adding or Resizing Regional Persistent Disks: U(https://cloud.google.com/compute/docs/disks/regional-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a region disk",
            "  gcp_compute_region_disk:",
            "    name: test_object",
            "    size_gb: 500",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    region: us-central1",
            "    replica_zones:",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-a",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-b",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last detach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "replicaZones:",
            "  description:",
            "  - URLs of the zones where the disk should be replicated to.",
            "  returned: success",
            "  type: list",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - A reference to the region where the disk resides.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            replica_zones=dict(required=True, type='list', elements='str'),",
            "            type=dict(type='str'),",
            "            region=dict(required=True, type='str'),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'diskEncryptionKey': RegionDiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': RegionDiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'replicaZones': module.params.get('replica_zones'),",
            "        u'type': region_disk_type_selflink(module.params.get('type'), module.params),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'replicaZones': response.get(u'replicaZones'),",
            "        u'type': response.get(u'type'),",
            "    }",
            "",
            "",
            "def zone_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def region_disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/regions/.*/diskTypes/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class RegionDiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class RegionDiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "372": [
                "main"
            ],
            "374": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_snapshot.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "             labels=dict(type='dict'),"
            },
            "1": {
                "beforePatchRowNumber": 292,
                "afterPatchRowNumber": 292,
                "PatchRowcode": "             source_disk=dict(required=True, type='dict'),"
            },
            "2": {
                "beforePatchRowNumber": 293,
                "afterPatchRowNumber": 293,
                "PatchRowcode": "             zone=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 294,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": 295,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+            snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 295,
                "PatchRowcode": "+            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "7": {
                "beforePatchRowNumber": 296,
                "afterPatchRowNumber": 296,
                "PatchRowcode": "         )"
            },
            "8": {
                "beforePatchRowNumber": 297,
                "afterPatchRowNumber": 297,
                "PatchRowcode": "     )"
            },
            "9": {
                "beforePatchRowNumber": 298,
                "afterPatchRowNumber": 298,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_snapshot",
            "description:",
            "- Represents a Persistent Disk Snapshot resource.",
            "- Use snapshots to back up data from your persistent disks. Snapshots are different",
            "  from public images and custom images, which are used primarily to create instances",
            "  or configure instance templates. Snapshots are useful for periodic backup of the",
            "  data on your persistent disks. You can create snapshots from persistent disks even",
            "  while they are attached to running instances.",
            "- Snapshots are incremental, so you can create regular snapshots on a persistent disk",
            "  faster and at a much lower cost than if you regularly created a full image of the",
            "  disk.",
            "short_description: Creates a GCP Snapshot",
            "version_added: 2.9",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Snapshot.",
            "    required: false",
            "    type: dict",
            "  source_disk:",
            "    description:",
            "    - A reference to the disk used to create this snapshot.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''name'' and value of",
            "      your resource''s name Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: true",
            "    type: dict",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk is hosted.",
            "    required: false",
            "    type: str",
            "  snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the snapshot. Required if the source",
            "      snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/snapshots)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/disks/create-snapshots)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-snapshot",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a snapshot",
            "  gcp_compute_snapshot:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    zone: us-central1-a",
            "    labels:",
            "      my_label: value",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "diskSizeGb:",
            "  description:",
            "  - Size of the snapshot, specified in GB.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "storageBytes:",
            "  description:",
            "  - A size of the the storage used by the snapshot. As snapshots share storage, this",
            "    number is expected to change with snapshot creation/deletion.",
            "  returned: success",
            "  type: int",
            "licenses:",
            "  description:",
            "  - A list of public visible licenses that apply to this snapshot. This can be because",
            "    the original image had licenses attached (such as a Windows image). snapshotEncryptionKey",
            "    nested object Encrypts the snapshot using a customer-supplied encryption key.",
            "  returned: success",
            "  type: list",
            "labels:",
            "  description:",
            "  - Labels to apply to this Snapshot.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "sourceDisk:",
            "  description:",
            "  - A reference to the disk used to create this snapshot.",
            "  returned: success",
            "  type: dict",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk is hosted.",
            "  returned: success",
            "  type: str",
            "snapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the snapshot. Required if the source snapshot",
            "    is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            source_disk=dict(required=True, type='dict'),",
            "            zone=dict(type='str'),",
            "            snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#snapshot'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, create_link(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/snapshots/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#snapshot',",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'name'),",
            "        u'zone': module.params.get('zone'),",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/snapshots/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/snapshots\".format(**module.params)",
            "",
            "",
            "def create_link(module):",
            "    res = {'project': module.params['project'], 'zone': module.params['zone'], 'source_disk': replace_resource_dict(module.params['source_disk'], 'name')}",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{source_disk}/createSnapshot\".format(**res)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'id': response.get(u'id'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'storageBytes': response.get(u'storageBytes'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#snapshot')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = navigate_hash(op_result, ['selfLink'])",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class SnapshotSnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class SnapshotSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_snapshot",
            "description:",
            "- Represents a Persistent Disk Snapshot resource.",
            "- Use snapshots to back up data from your persistent disks. Snapshots are different",
            "  from public images and custom images, which are used primarily to create instances",
            "  or configure instance templates. Snapshots are useful for periodic backup of the",
            "  data on your persistent disks. You can create snapshots from persistent disks even",
            "  while they are attached to running instances.",
            "- Snapshots are incremental, so you can create regular snapshots on a persistent disk",
            "  faster and at a much lower cost than if you regularly created a full image of the",
            "  disk.",
            "short_description: Creates a GCP Snapshot",
            "version_added: 2.9",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Snapshot.",
            "    required: false",
            "    type: dict",
            "  source_disk:",
            "    description:",
            "    - A reference to the disk used to create this snapshot.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''name'' and value of",
            "      your resource''s name Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: true",
            "    type: dict",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk is hosted.",
            "    required: false",
            "    type: str",
            "  snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the snapshot. Required if the source",
            "      snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "        type: str",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "        type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/snapshots)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/disks/create-snapshots)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-snapshot",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a snapshot",
            "  gcp_compute_snapshot:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    zone: us-central1-a",
            "    labels:",
            "      my_label: value",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "diskSizeGb:",
            "  description:",
            "  - Size of the snapshot, specified in GB.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "storageBytes:",
            "  description:",
            "  - A size of the the storage used by the snapshot. As snapshots share storage, this",
            "    number is expected to change with snapshot creation/deletion.",
            "  returned: success",
            "  type: int",
            "licenses:",
            "  description:",
            "  - A list of public visible licenses that apply to this snapshot. This can be because",
            "    the original image had licenses attached (such as a Windows image). snapshotEncryptionKey",
            "    nested object Encrypts the snapshot using a customer-supplied encryption key.",
            "  returned: success",
            "  type: list",
            "labels:",
            "  description:",
            "  - Labels to apply to this Snapshot.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "sourceDisk:",
            "  description:",
            "  - A reference to the disk used to create this snapshot.",
            "  returned: success",
            "  type: dict",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk is hosted.",
            "  returned: success",
            "  type: str",
            "snapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the snapshot. Required if the source snapshot",
            "    is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            source_disk=dict(required=True, type='dict'),",
            "            zone=dict(type='str'),",
            "            snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#snapshot'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, create_link(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/snapshots/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#snapshot',",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'name'),",
            "        u'zone': module.params.get('zone'),",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/snapshots/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/snapshots\".format(**module.params)",
            "",
            "",
            "def create_link(module):",
            "    res = {'project': module.params['project'], 'zone': module.params['zone'], 'source_disk': replace_resource_dict(module.params['source_disk'], 'name')}",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{source_disk}/createSnapshot\".format(**res)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'id': response.get(u'id'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'storageBytes': response.get(u'storageBytes'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/.*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#snapshot')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = navigate_hash(op_result, ['selfLink'])",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class SnapshotSnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class SnapshotSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "294": [
                "main"
            ],
            "295": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_ssl_certificate.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "             certificate=dict(required=True, type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "             description=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "             name=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            private_key=dict(required=True, type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+            private_key=dict(required=True, type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         )"
            },
            "6": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "     )"
            },
            "7": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 186,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_ssl_certificate",
            "description:",
            "- An SslCertificate resource, used for HTTPS load balancing. This resource provides",
            "  a mechanism to upload an SSL key and certificate to the load balancer to serve secure",
            "  connections from the user.",
            "short_description: Creates a GCP SslCertificate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  certificate:",
            "    description:",
            "    - The certificate in PEM format.",
            "    - The certificate chain must be no greater than 5 certs long.",
            "    - The chain must include at least one intermediate cert.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: false",
            "    type: str",
            "  private_key:",
            "    description:",
            "    - The write-only private key in PEM format.",
            "    required: true",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/sslCertificates)'",
            "- 'Official Documentation: U(https://cloud.google.com/load-balancing/docs/ssl-certificates)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a SSL certificate",
            "  gcp_compute_ssl_certificate:",
            "    name: test_object",
            "    description: A certificate for testing. Do not use this certificate in production",
            "    certificate: |-",
            "      -----BEGIN CERTIFICATE-----",
            "      MIICqjCCAk+gAwIBAgIJAIuJ+0352Kq4MAoGCCqGSM49BAMCMIGwMQswCQYDVQQG",
            "      EwJVUzETMBEGA1UECAwKV2FzaGluZ3RvbjERMA8GA1UEBwwIS2lya2xhbmQxFTAT",
            "      BgNVBAoMDEdvb2dsZSwgSW5jLjEeMBwGA1UECwwVR29vZ2xlIENsb3VkIFBsYXRm",
            "      b3JtMR8wHQYDVQQDDBZ3d3cubXktc2VjdXJlLXNpdGUuY29tMSEwHwYJKoZIhvcN",
            "      AQkBFhJuZWxzb25hQGdvb2dsZS5jb20wHhcNMTcwNjI4MDQ1NjI2WhcNMjcwNjI2",
            "      MDQ1NjI2WjCBsDELMAkGA1UEBhMCVVMxEzARBgNVBAgMCldhc2hpbmd0b24xETAP",
            "      BgNVBAcMCEtpcmtsYW5kMRUwEwYDVQQKDAxHb29nbGUsIEluYy4xHjAcBgNVBAsM",
            "      FUdvb2dsZSBDbG91ZCBQbGF0Zm9ybTEfMB0GA1UEAwwWd3d3Lm15LXNlY3VyZS1z",
            "      aXRlLmNvbTEhMB8GCSqGSIb3DQEJARYSbmVsc29uYUBnb29nbGUuY29tMFkwEwYH",
            "      KoZIzj0CAQYIKoZIzj0DAQcDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ",
            "      4mzkzTv0dXyB750fOGN02HtkpBOZzzvUARTR10JQoSe2/5PIwaNQME4wHQYDVR0O",
            "      BBYEFKIQC3A2SDpxcdfn0YLKineDNq/BMB8GA1UdIwQYMBaAFKIQC3A2SDpxcdfn",
            "      0YLKineDNq/BMAwGA1UdEwQFMAMBAf8wCgYIKoZIzj0EAwIDSQAwRgIhALs4vy+O",
            "      M3jcqgA4fSW/oKw6UJxp+M6a+nGMX+UJR3YgAiEAvvl39QRVAiv84hdoCuyON0lJ",
            "      zqGNhIPGq2ULqXKK8BY=",
            "      -----END CERTIFICATE-----",
            "    private_key: |-",
            "      -----BEGIN EC PRIVATE KEY-----",
            "      MHcCAQEEIObtRo8tkUqoMjeHhsOh2ouPpXCgBcP+EDxZCB/tws15oAoGCCqGSM49",
            "      AwEHoUQDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ4mzkzTv0dXyB750f",
            "      OGN02HtkpBOZzzvUARTR10JQoSe2/5PIwQ==",
            "      -----END EC PRIVATE KEY-----",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "certificate:",
            "  description:",
            "  - The certificate in PEM format.",
            "  - The certificate chain must be no greater than 5 certs long.",
            "  - The chain must include at least one intermediate cert.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "privateKey:",
            "  description:",
            "  - The write-only private key in PEM format.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            certificate=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(type='str'),",
            "            private_key=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#sslCertificate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#sslCertificate',",
            "        u'certificate': module.params.get('certificate'),",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'certificate': response.get(u'certificate'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#sslCertificate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_ssl_certificate",
            "description:",
            "- An SslCertificate resource, used for HTTPS load balancing. This resource provides",
            "  a mechanism to upload an SSL key and certificate to the load balancer to serve secure",
            "  connections from the user.",
            "short_description: Creates a GCP SslCertificate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  certificate:",
            "    description:",
            "    - The certificate in PEM format.",
            "    - The certificate chain must be no greater than 5 certs long.",
            "    - The chain must include at least one intermediate cert.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: false",
            "    type: str",
            "  private_key:",
            "    description:",
            "    - The write-only private key in PEM format.",
            "    required: true",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/sslCertificates)'",
            "- 'Official Documentation: U(https://cloud.google.com/load-balancing/docs/ssl-certificates)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a SSL certificate",
            "  gcp_compute_ssl_certificate:",
            "    name: test_object",
            "    description: A certificate for testing. Do not use this certificate in production",
            "    certificate: |-",
            "      -----BEGIN CERTIFICATE-----",
            "      MIICqjCCAk+gAwIBAgIJAIuJ+0352Kq4MAoGCCqGSM49BAMCMIGwMQswCQYDVQQG",
            "      EwJVUzETMBEGA1UECAwKV2FzaGluZ3RvbjERMA8GA1UEBwwIS2lya2xhbmQxFTAT",
            "      BgNVBAoMDEdvb2dsZSwgSW5jLjEeMBwGA1UECwwVR29vZ2xlIENsb3VkIFBsYXRm",
            "      b3JtMR8wHQYDVQQDDBZ3d3cubXktc2VjdXJlLXNpdGUuY29tMSEwHwYJKoZIhvcN",
            "      AQkBFhJuZWxzb25hQGdvb2dsZS5jb20wHhcNMTcwNjI4MDQ1NjI2WhcNMjcwNjI2",
            "      MDQ1NjI2WjCBsDELMAkGA1UEBhMCVVMxEzARBgNVBAgMCldhc2hpbmd0b24xETAP",
            "      BgNVBAcMCEtpcmtsYW5kMRUwEwYDVQQKDAxHb29nbGUsIEluYy4xHjAcBgNVBAsM",
            "      FUdvb2dsZSBDbG91ZCBQbGF0Zm9ybTEfMB0GA1UEAwwWd3d3Lm15LXNlY3VyZS1z",
            "      aXRlLmNvbTEhMB8GCSqGSIb3DQEJARYSbmVsc29uYUBnb29nbGUuY29tMFkwEwYH",
            "      KoZIzj0CAQYIKoZIzj0DAQcDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ",
            "      4mzkzTv0dXyB750fOGN02HtkpBOZzzvUARTR10JQoSe2/5PIwaNQME4wHQYDVR0O",
            "      BBYEFKIQC3A2SDpxcdfn0YLKineDNq/BMB8GA1UdIwQYMBaAFKIQC3A2SDpxcdfn",
            "      0YLKineDNq/BMAwGA1UdEwQFMAMBAf8wCgYIKoZIzj0EAwIDSQAwRgIhALs4vy+O",
            "      M3jcqgA4fSW/oKw6UJxp+M6a+nGMX+UJR3YgAiEAvvl39QRVAiv84hdoCuyON0lJ",
            "      zqGNhIPGq2ULqXKK8BY=",
            "      -----END CERTIFICATE-----",
            "    private_key: |-",
            "      -----BEGIN EC PRIVATE KEY-----",
            "      MHcCAQEEIObtRo8tkUqoMjeHhsOh2ouPpXCgBcP+EDxZCB/tws15oAoGCCqGSM49",
            "      AwEHoUQDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ4mzkzTv0dXyB750f",
            "      OGN02HtkpBOZzzvUARTR10JQoSe2/5PIwQ==",
            "      -----END EC PRIVATE KEY-----",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "certificate:",
            "  description:",
            "  - The certificate in PEM format.",
            "  - The certificate chain must be no greater than 5 certs long.",
            "  - The chain must include at least one intermediate cert.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "privateKey:",
            "  description:",
            "  - The write-only private key in PEM format.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            certificate=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(type='str'),",
            "            private_key=dict(required=True, type='str', no_log=True),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#sslCertificate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#sslCertificate',",
            "        u'certificate': module.params.get('certificate'),",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'certificate': response.get(u'certificate'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#sslCertificate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "183": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_vpn_tunnel.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": 280,
                "PatchRowcode": "             target_vpn_gateway=dict(type='dict'),"
            },
            "1": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 281,
                "PatchRowcode": "             router=dict(type='dict'),"
            },
            "2": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 282,
                "PatchRowcode": "             peer_ip=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            shared_secret=dict(required=True, type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+            shared_secret=dict(required=True, type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": 284,
                "PatchRowcode": "             ike_version=dict(default=2, type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 285,
                "afterPatchRowNumber": 285,
                "PatchRowcode": "             local_traffic_selector=dict(type='list', elements='str'),"
            },
            "7": {
                "beforePatchRowNumber": 286,
                "afterPatchRowNumber": 286,
                "PatchRowcode": "             remote_traffic_selector=dict(type='list', elements='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_vpn_tunnel",
            "description:",
            "- VPN tunnel resource.",
            "short_description: Creates a GCP VpnTunnel",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. The name must be 1-63 characters long, and comply with",
            "      RFC1035. Specifically, the name must be 1-63 characters long and match the regular",
            "      expression `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must",
            "      be a lowercase letter, and all following characters must be a dash, lowercase",
            "      letter, or digit, except the last character, which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  target_vpn_gateway:",
            "    description:",
            "    - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "    - 'This field represents a link to a TargetVpnGateway resource in GCP. It can",
            "      be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "      and value of your resource''s selfLink Alternatively, you can add `register:",
            "      name-of-resource` to a gcp_compute_target_vpn_gateway task and then set this",
            "      target_vpn_gateway field to \"{{ name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  router:",
            "    description:",
            "    - URL of router resource to be used for dynamic routing.",
            "    - 'This field represents a link to a Router resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_router task and then set this router field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "    type: dict",
            "  peer_ip:",
            "    description:",
            "    - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "    required: false",
            "    type: str",
            "  shared_secret:",
            "    description:",
            "    - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "      the peer VPN gateway.",
            "    required: true",
            "    type: str",
            "  ike_version:",
            "    description:",
            "    - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "    - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "    required: false",
            "    default: '2'",
            "    type: int",
            "  local_traffic_selector:",
            "    description:",
            "    - Local traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "    type: list",
            "  remote_traffic_selector:",
            "    description:",
            "    - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "    type: list",
            "  region:",
            "    description:",
            "    - The region where the tunnel is located.",
            "    required: true",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/vpnTunnels)'",
            "- 'Cloud VPN Overview: U(https://cloud.google.com/vpn/docs/concepts/overview)'",
            "- 'Networks and Tunnel Routing: U(https://cloud.google.com/vpn/docs/concepts/choosing-networks-routing)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-vpn-tunnel",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a router",
            "  gcp_compute_router:",
            "    name: router-vpn-tunnel",
            "    network: \"{{ network }}\"",
            "    bgp:",
            "      asn: 64514",
            "      advertise_mode: CUSTOM",
            "      advertised_groups:",
            "      - ALL_SUBNETS",
            "      advertised_ip_ranges:",
            "      - range: 1.2.3.4",
            "      - range: 6.7.0.0/16",
            "    region: us-central1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: router",
            "",
            "- name: create a target vpn gateway",
            "  gcp_compute_target_vpn_gateway:",
            "    name: gateway-vpn-tunnel",
            "    region: us-west1",
            "    network: \"{{ network }}\"",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: gateway",
            "",
            "- name: create a vpn tunnel",
            "  gcp_compute_vpn_tunnel:",
            "    name: test_object",
            "    region: us-west1",
            "    target_vpn_gateway: \"{{ gateway }}\"",
            "    router: \"{{ router }}\"",
            "    shared_secret: super secret",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. The name must be 1-63 characters long, and comply with RFC1035.",
            "    Specifically, the name must be 1-63 characters long and match the regular expression",
            "    `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must be a lowercase",
            "    letter, and all following characters must be a dash, lowercase letter, or digit,",
            "    except the last character, which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "targetVpnGateway:",
            "  description:",
            "  - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "  returned: success",
            "  type: dict",
            "router:",
            "  description:",
            "  - URL of router resource to be used for dynamic routing.",
            "  returned: success",
            "  type: dict",
            "peerIp:",
            "  description:",
            "  - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "  returned: success",
            "  type: str",
            "sharedSecret:",
            "  description:",
            "  - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "    the peer VPN gateway.",
            "  returned: success",
            "  type: str",
            "sharedSecretHash:",
            "  description:",
            "  - Hash of the shared secret.",
            "  returned: success",
            "  type: str",
            "ikeVersion:",
            "  description:",
            "  - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "  - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "  returned: success",
            "  type: int",
            "localTrafficSelector:",
            "  description:",
            "  - Local traffic selector to use when establishing the VPN tunnel with peer VPN gateway.",
            "    The value should be a CIDR formatted string, for example `192.168.0.0/16`. The",
            "    ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "remoteTrafficSelector:",
            "  description:",
            "  - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "    gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "    The ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "region:",
            "  description:",
            "  - The region where the tunnel is located.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            target_vpn_gateway=dict(type='dict'),",
            "            router=dict(type='dict'),",
            "            peer_ip=dict(type='str'),",
            "            shared_secret=dict(required=True, type='str'),",
            "            ike_version=dict(default=2, type='int'),",
            "            local_traffic_selector=dict(type='list', elements='str'),",
            "            remote_traffic_selector=dict(type='list', elements='str'),",
            "            region=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#vpnTunnel'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#vpnTunnel',",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': module.params.get('peer_ip'),",
            "        u'sharedSecret': module.params.get('shared_secret'),",
            "        u'ikeVersion': module.params.get('ike_version'),",
            "        u'localTrafficSelector': module.params.get('local_traffic_selector'),",
            "        u'remoteTrafficSelector': module.params.get('remote_traffic_selector'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'name': response.get(u'name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': response.get(u'peerIp'),",
            "        u'sharedSecret': response.get(u'sharedSecret'),",
            "        u'sharedSecretHash': response.get(u'sharedSecretHash'),",
            "        u'ikeVersion': response.get(u'ikeVersion'),",
            "        u'localTrafficSelector': response.get(u'localTrafficSelector'),",
            "        u'remoteTrafficSelector': response.get(u'remoteTrafficSelector'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#vpnTunnel')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_vpn_tunnel",
            "description:",
            "- VPN tunnel resource.",
            "short_description: Creates a GCP VpnTunnel",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  name:",
            "    description:",
            "    - Name of the resource. The name must be 1-63 characters long, and comply with",
            "      RFC1035. Specifically, the name must be 1-63 characters long and match the regular",
            "      expression `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must",
            "      be a lowercase letter, and all following characters must be a dash, lowercase",
            "      letter, or digit, except the last character, which cannot be a dash.",
            "    required: true",
            "    type: str",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "    type: str",
            "  target_vpn_gateway:",
            "    description:",
            "    - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "    - 'This field represents a link to a TargetVpnGateway resource in GCP. It can",
            "      be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "      and value of your resource''s selfLink Alternatively, you can add `register:",
            "      name-of-resource` to a gcp_compute_target_vpn_gateway task and then set this",
            "      target_vpn_gateway field to \"{{ name-of-resource }}\"'",
            "    required: false",
            "    type: dict",
            "  router:",
            "    description:",
            "    - URL of router resource to be used for dynamic routing.",
            "    - 'This field represents a link to a Router resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_router task and then set this router field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "    type: dict",
            "  peer_ip:",
            "    description:",
            "    - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "    required: false",
            "    type: str",
            "  shared_secret:",
            "    description:",
            "    - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "      the peer VPN gateway.",
            "    required: true",
            "    type: str",
            "  ike_version:",
            "    description:",
            "    - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "    - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "    required: false",
            "    default: '2'",
            "    type: int",
            "  local_traffic_selector:",
            "    description:",
            "    - Local traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "    type: list",
            "  remote_traffic_selector:",
            "    description:",
            "    - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "    type: list",
            "  region:",
            "    description:",
            "    - The region where the tunnel is located.",
            "    required: true",
            "    type: str",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/vpnTunnels)'",
            "- 'Cloud VPN Overview: U(https://cloud.google.com/vpn/docs/concepts/overview)'",
            "- 'Networks and Tunnel Routing: U(https://cloud.google.com/vpn/docs/concepts/choosing-networks-routing)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-vpn-tunnel",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a router",
            "  gcp_compute_router:",
            "    name: router-vpn-tunnel",
            "    network: \"{{ network }}\"",
            "    bgp:",
            "      asn: 64514",
            "      advertise_mode: CUSTOM",
            "      advertised_groups:",
            "      - ALL_SUBNETS",
            "      advertised_ip_ranges:",
            "      - range: 1.2.3.4",
            "      - range: 6.7.0.0/16",
            "    region: us-central1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: router",
            "",
            "- name: create a target vpn gateway",
            "  gcp_compute_target_vpn_gateway:",
            "    name: gateway-vpn-tunnel",
            "    region: us-west1",
            "    network: \"{{ network }}\"",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: gateway",
            "",
            "- name: create a vpn tunnel",
            "  gcp_compute_vpn_tunnel:",
            "    name: test_object",
            "    region: us-west1",
            "    target_vpn_gateway: \"{{ gateway }}\"",
            "    router: \"{{ router }}\"",
            "    shared_secret: super secret",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. The name must be 1-63 characters long, and comply with RFC1035.",
            "    Specifically, the name must be 1-63 characters long and match the regular expression",
            "    `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must be a lowercase",
            "    letter, and all following characters must be a dash, lowercase letter, or digit,",
            "    except the last character, which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "targetVpnGateway:",
            "  description:",
            "  - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "  returned: success",
            "  type: dict",
            "router:",
            "  description:",
            "  - URL of router resource to be used for dynamic routing.",
            "  returned: success",
            "  type: dict",
            "peerIp:",
            "  description:",
            "  - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "  returned: success",
            "  type: str",
            "sharedSecret:",
            "  description:",
            "  - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "    the peer VPN gateway.",
            "  returned: success",
            "  type: str",
            "sharedSecretHash:",
            "  description:",
            "  - Hash of the shared secret.",
            "  returned: success",
            "  type: str",
            "ikeVersion:",
            "  description:",
            "  - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "  - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "  returned: success",
            "  type: int",
            "localTrafficSelector:",
            "  description:",
            "  - Local traffic selector to use when establishing the VPN tunnel with peer VPN gateway.",
            "    The value should be a CIDR formatted string, for example `192.168.0.0/16`. The",
            "    ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "remoteTrafficSelector:",
            "  description:",
            "  - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "    gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "    The ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "region:",
            "  description:",
            "  - The region where the tunnel is located.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            target_vpn_gateway=dict(type='dict'),",
            "            router=dict(type='dict'),",
            "            peer_ip=dict(type='str'),",
            "            shared_secret=dict(required=True, type='str', no_log=True),",
            "            ike_version=dict(default=2, type='int'),",
            "            local_traffic_selector=dict(type='list', elements='str'),",
            "            remote_traffic_selector=dict(type='list', elements='str'),",
            "            region=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#vpnTunnel'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    delete(module, self_link(module), kind)",
            "    create(module, collection(module), kind)",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#vpnTunnel',",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': module.params.get('peer_ip'),",
            "        u'sharedSecret': module.params.get('shared_secret'),",
            "        u'ikeVersion': module.params.get('ike_version'),",
            "        u'localTrafficSelector': module.params.get('local_traffic_selector'),",
            "        u'remoteTrafficSelector': module.params.get('remote_traffic_selector'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'name': response.get(u'name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': response.get(u'peerIp'),",
            "        u'sharedSecret': response.get(u'sharedSecret'),",
            "        u'sharedSecretHash': response.get(u'sharedSecretHash'),",
            "        u'ikeVersion': response.get(u'ikeVersion'),",
            "        u'localTrafficSelector': response.get(u'localTrafficSelector'),",
            "        u'remoteTrafficSelector': response.get(u'remoteTrafficSelector'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#vpnTunnel')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "283": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_sql_instance.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 688,
                "afterPatchRowNumber": 688,
                "PatchRowcode": "                         options=dict("
            },
            "1": {
                "beforePatchRowNumber": 689,
                "afterPatchRowNumber": 689,
                "PatchRowcode": "                             ca_certificate=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 690,
                "afterPatchRowNumber": 690,
                "PatchRowcode": "                             client_certificate=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 691,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            client_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 691,
                "PatchRowcode": "+                            client_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 692,
                "afterPatchRowNumber": 692,
                "PatchRowcode": "                             connect_retry_interval=dict(type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 693,
                "afterPatchRowNumber": 693,
                "PatchRowcode": "                             dump_file_path=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 694,
                "afterPatchRowNumber": 694,
                "PatchRowcode": "                             master_heartbeat_period=dict(type='int'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_sql_instance",
            "description:",
            "- Represents a Cloud SQL instance. Cloud SQL instances are SQL databases hosted in",
            "  Google's cloud. The Instances resource provides methods for common configuration",
            "  and management tasks.",
            "short_description: Creates a GCP Instance",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  backend_type:",
            "    description:",
            "    - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "    - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "    - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "    - 'Some valid choices include: \"FIRST_GEN\", \"SECOND_GEN\", \"EXTERNAL\"'",
            "    required: false",
            "    type: str",
            "  connection_name:",
            "    description:",
            "    - Connection name of the Cloud SQL instance used in connection strings.",
            "    required: false",
            "    type: str",
            "  database_version:",
            "    description:",
            "    - The database engine type and version. For First Generation instances, can be",
            "      MYSQL_5_5, or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or",
            "      MYSQL_5_7. Defaults to MYSQL_5_6.",
            "    - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be",
            "      changed after instance creation.'",
            "    - 'Some valid choices include: \"MYSQL_5_5\", \"MYSQL_5_6\", \"MYSQL_5_7\", \"POSTGRES_9_6\"'",
            "    required: false",
            "    type: str",
            "  failover_replica:",
            "    description:",
            "    - The name and status of the failover replica. This property is applicable only",
            "      to Second Generation instances.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      name:",
            "        description:",
            "        - The name of the failover replica. If specified at instance creation, a failover",
            "          replica is created for the instance. The name doesn't include the project",
            "          ID. This property is applicable only to Second Generation instances.",
            "        required: false",
            "        type: str",
            "  instance_type:",
            "    description:",
            "    - The instance type. This can be one of the following.",
            "    - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "    - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "    - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "    - 'Some valid choices include: \"CLOUD_SQL_INSTANCE\", \"ON_PREMISES_INSTANCE\", \"READ_REPLICA_INSTANCE\"'",
            "    required: false",
            "    type: str",
            "  ipv6_address:",
            "    description:",
            "    - The IPv6 address assigned to the instance. This property is applicable only",
            "      to First Generation instances.",
            "    required: false",
            "    type: str",
            "  master_instance_name:",
            "    description:",
            "    - The name of the instance which will act as master in the replication setup.",
            "    required: false",
            "    type: str",
            "  max_disk_size:",
            "    description:",
            "    - The maximum disk size of the instance in bytes.",
            "    required: false",
            "    type: int",
            "  name:",
            "    description:",
            "    - Name of the Cloud SQL instance. This does not include the project ID.",
            "    required: true",
            "    type: str",
            "  region:",
            "    description:",
            "    - The geographical region. Defaults to us-central or us-central1 depending on",
            "      the instance type (First Generation or Second Generation/PostgreSQL).",
            "    required: false",
            "    type: str",
            "  replica_configuration:",
            "    description:",
            "    - Configuration specific to failover replicas and read replicas.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      failover_target:",
            "        description:",
            "        - Specifies if the replica is the failover target. If the field is set to",
            "          true the replica will be designated as a failover replica.",
            "        - In case the master instance fails, the replica instance will be promoted",
            "          as the new master instance.",
            "        - Only one replica can be specified as failover target, and the replica has",
            "          to be in different zone with the master instance.",
            "        required: false",
            "        type: bool",
            "      mysql_replica_configuration:",
            "        description:",
            "        - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "          Replication configuration information such as the username, password, certificates,",
            "          and keys are not stored in the instance metadata. The configuration information",
            "          is used only to set up the replication connection and is stored by MySQL",
            "          in a file named master.info in the data directory.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          ca_certificate:",
            "            description:",
            "            - PEM representation of the trusted CA's x509 certificate.",
            "            required: false",
            "            type: str",
            "          client_certificate:",
            "            description:",
            "            - PEM representation of the slave's x509 certificate .",
            "            required: false",
            "            type: str",
            "          client_key:",
            "            description:",
            "            - PEM representation of the slave's private key. The corresponding public",
            "              key is encoded in the client's certificate.",
            "            required: false",
            "            type: str",
            "          connect_retry_interval:",
            "            description:",
            "            - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "            required: false",
            "            type: int",
            "          dump_file_path:",
            "            description:",
            "            - Path to a SQL dump file in Google Cloud Storage from which the slave",
            "              instance is to be created. The URI is in the form gs://bucketName/fileName.",
            "              Compressed gzip files (.gz) are also supported. Dumps should have the",
            "              binlog coordinates from which replication should begin. This can be",
            "              accomplished by setting --master-data to 1 when using mysqldump.",
            "            required: false",
            "            type: str",
            "          master_heartbeat_period:",
            "            description:",
            "            - Interval in milliseconds between replication heartbeats.",
            "            required: false",
            "            type: int",
            "          password:",
            "            description:",
            "            - The password for the replication connection.",
            "            required: false",
            "            type: str",
            "          ssl_cipher:",
            "            description:",
            "            - A list of permissible ciphers to use for SSL encryption.",
            "            required: false",
            "            type: str",
            "          username:",
            "            description:",
            "            - The username for the replication connection.",
            "            required: false",
            "            type: str",
            "          verify_server_certificate:",
            "            description:",
            "            - Whether or not to check the master's Common Name value in the certificate",
            "              that it sends during the SSL handshake.",
            "            required: false",
            "            type: bool",
            "      replica_names:",
            "        description:",
            "        - The replicas of the instance.",
            "        required: false",
            "        type: list",
            "      service_account_email_address:",
            "        description:",
            "        - The service account email address assigned to the instance. This property",
            "          is applicable only to Second Generation instances.",
            "        required: false",
            "        type: str",
            "  settings:",
            "    description:",
            "    - The user settings.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      database_flags:",
            "        description:",
            "        - The database flags passed to the instance at startup.",
            "        required: false",
            "        type: list",
            "        version_added: 2.9",
            "        suboptions:",
            "          name:",
            "            description:",
            "            - The name of the flag. These flags are passed at instance startup, so",
            "              include both server options and system variables for MySQL. Flags should",
            "              be specified with underscores, not hyphens.",
            "            required: false",
            "            type: str",
            "          value:",
            "            description:",
            "            - The value of the flag. Booleans should be set to on for true and off",
            "              for false. This field must be omitted if the flag doesn't take a value.",
            "            required: false",
            "            type: str",
            "      ip_configuration:",
            "        description:",
            "        - The settings for IP Management. This allows to enable or disable the instance",
            "          IP and manage which external networks can connect to the instance. The IPv4",
            "          address cannot be disabled for Second Generation instances.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          ipv4_enabled:",
            "            description:",
            "            - Whether the instance should be assigned an IP address or not.",
            "            required: false",
            "            type: bool",
            "          authorized_networks:",
            "            description:",
            "            - The list of external networks that are allowed to connect to the instance",
            "              using the IP. In CIDR notation, also known as 'slash' notation (e.g.",
            "              192.168.100.0/24).",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              expiration_time:",
            "                description:",
            "                - The time when this access control entry expires in RFC 3339 format,",
            "                  for example 2012-11-15T16:19:00.094Z.",
            "                required: false",
            "                type: str",
            "              name:",
            "                description:",
            "                - An optional label to identify this entry.",
            "                required: false",
            "                type: str",
            "              value:",
            "                description:",
            "                - The whitelisted value for the access control list. For example,",
            "                  to grant access to a client from an external IP (IPv4 or IPv6) address",
            "                  or subnet, use that address or subnet here.",
            "                required: false",
            "                type: str",
            "          require_ssl:",
            "            description:",
            "            - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "              over IP.",
            "            required: false",
            "            type: bool",
            "      tier:",
            "        description:",
            "        - The tier or machine type for this instance, for example db-n1-standard-1.",
            "          For MySQL instances, this field determines whether the instance is Second",
            "          Generation (recommended) or First Generation.",
            "        required: false",
            "        type: str",
            "      availability_type:",
            "        description:",
            "        - The availabilityType define if your postgres instance is run zonal or regional.",
            "        - 'Some valid choices include: \"ZONAL\", \"REGIONAL\"'",
            "        required: false",
            "        type: str",
            "      backup_configuration:",
            "        description:",
            "        - The daily backup configuration for the instance.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          enabled:",
            "            description:",
            "            - Enable Autobackup for your instance.",
            "            required: false",
            "            type: bool",
            "          binary_log_enabled:",
            "            description:",
            "            - Whether binary log is enabled. If backup configuration is disabled,",
            "              binary log must be disabled as well. MySQL only.",
            "            required: false",
            "            type: bool",
            "          start_time:",
            "            description:",
            "            - Define the backup start time in UTC (HH:MM) .",
            "            required: false",
            "            type: str",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance",
            "  gcp_sql_instance:",
            "    name: \"{{resource_name}}-2\"",
            "    settings:",
            "      ip_configuration:",
            "        authorized_networks:",
            "        - name: google dns server",
            "          value: 8.8.8.8/32",
            "      tier: db-n1-standard-1",
            "    region: us-central1",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "backendType:",
            "  description:",
            "  - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "  - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "  - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "  returned: success",
            "  type: str",
            "connectionName:",
            "  description:",
            "  - Connection name of the Cloud SQL instance used in connection strings.",
            "  returned: success",
            "  type: str",
            "databaseVersion:",
            "  description:",
            "  - The database engine type and version. For First Generation instances, can be MYSQL_5_5,",
            "    or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or MYSQL_5_7.",
            "    Defaults to MYSQL_5_6.",
            "  - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be changed",
            "    after instance creation.'",
            "  returned: success",
            "  type: str",
            "failoverReplica:",
            "  description:",
            "  - The name and status of the failover replica. This property is applicable only",
            "    to Second Generation instances.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    available:",
            "      description:",
            "      - The availability status of the failover replica. A false status indicates",
            "        that the failover replica is out of sync. The master can only failover to",
            "        the failover replica when the status is true.",
            "      returned: success",
            "      type: bool",
            "    name:",
            "      description:",
            "      - The name of the failover replica. If specified at instance creation, a failover",
            "        replica is created for the instance. The name doesn't include the project",
            "        ID. This property is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "instanceType:",
            "  description:",
            "  - The instance type. This can be one of the following.",
            "  - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "  - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "  - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "  returned: success",
            "  type: str",
            "ipAddresses:",
            "  description:",
            "  - The assigned IP addresses for the instance.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipAddress:",
            "      description:",
            "      - The IP address assigned.",
            "      returned: success",
            "      type: str",
            "    timeToRetire:",
            "      description:",
            "      - The due time for this IP to be retired in RFC 3339 format, for example 2012-11-15T16:19:00.094Z.",
            "        This field is only available when the IP is scheduled to be retired.",
            "      returned: success",
            "      type: str",
            "    type:",
            "      description:",
            "      - The type of this IP address. A PRIMARY address is an address that can accept",
            "        incoming connections. An OUTGOING address is the source address of connections",
            "        originating from the instance, if supported.",
            "      returned: success",
            "      type: str",
            "ipv6Address:",
            "  description:",
            "  - The IPv6 address assigned to the instance. This property is applicable only to",
            "    First Generation instances.",
            "  returned: success",
            "  type: str",
            "masterInstanceName:",
            "  description:",
            "  - The name of the instance which will act as master in the replication setup.",
            "  returned: success",
            "  type: str",
            "maxDiskSize:",
            "  description:",
            "  - The maximum disk size of the instance in bytes.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the Cloud SQL instance. This does not include the project ID.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - The geographical region. Defaults to us-central or us-central1 depending on the",
            "    instance type (First Generation or Second Generation/PostgreSQL).",
            "  returned: success",
            "  type: str",
            "replicaConfiguration:",
            "  description:",
            "  - Configuration specific to failover replicas and read replicas.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    failoverTarget:",
            "      description:",
            "      - Specifies if the replica is the failover target. If the field is set to true",
            "        the replica will be designated as a failover replica.",
            "      - In case the master instance fails, the replica instance will be promoted as",
            "        the new master instance.",
            "      - Only one replica can be specified as failover target, and the replica has",
            "        to be in different zone with the master instance.",
            "      returned: success",
            "      type: bool",
            "    mysqlReplicaConfiguration:",
            "      description:",
            "      - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "        Replication configuration information such as the username, password, certificates,",
            "        and keys are not stored in the instance metadata. The configuration information",
            "        is used only to set up the replication connection and is stored by MySQL in",
            "        a file named master.info in the data directory.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        caCertificate:",
            "          description:",
            "          - PEM representation of the trusted CA's x509 certificate.",
            "          returned: success",
            "          type: str",
            "        clientCertificate:",
            "          description:",
            "          - PEM representation of the slave's x509 certificate .",
            "          returned: success",
            "          type: str",
            "        clientKey:",
            "          description:",
            "          - PEM representation of the slave's private key. The corresponding public",
            "            key is encoded in the client's certificate.",
            "          returned: success",
            "          type: str",
            "        connectRetryInterval:",
            "          description:",
            "          - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "          returned: success",
            "          type: int",
            "        dumpFilePath:",
            "          description:",
            "          - Path to a SQL dump file in Google Cloud Storage from which the slave instance",
            "            is to be created. The URI is in the form gs://bucketName/fileName. Compressed",
            "            gzip files (.gz) are also supported. Dumps should have the binlog coordinates",
            "            from which replication should begin. This can be accomplished by setting",
            "            --master-data to 1 when using mysqldump.",
            "          returned: success",
            "          type: str",
            "        masterHeartbeatPeriod:",
            "          description:",
            "          - Interval in milliseconds between replication heartbeats.",
            "          returned: success",
            "          type: int",
            "        password:",
            "          description:",
            "          - The password for the replication connection.",
            "          returned: success",
            "          type: str",
            "        sslCipher:",
            "          description:",
            "          - A list of permissible ciphers to use for SSL encryption.",
            "          returned: success",
            "          type: str",
            "        username:",
            "          description:",
            "          - The username for the replication connection.",
            "          returned: success",
            "          type: str",
            "        verifyServerCertificate:",
            "          description:",
            "          - Whether or not to check the master's Common Name value in the certificate",
            "            that it sends during the SSL handshake.",
            "          returned: success",
            "          type: bool",
            "    replicaNames:",
            "      description:",
            "      - The replicas of the instance.",
            "      returned: success",
            "      type: list",
            "    serviceAccountEmailAddress:",
            "      description:",
            "      - The service account email address assigned to the instance. This property",
            "        is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "settings:",
            "  description:",
            "  - The user settings.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    databaseFlags:",
            "      description:",
            "      - The database flags passed to the instance at startup.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        name:",
            "          description:",
            "          - The name of the flag. These flags are passed at instance startup, so include",
            "            both server options and system variables for MySQL. Flags should be specified",
            "            with underscores, not hyphens.",
            "          returned: success",
            "          type: str",
            "        value:",
            "          description:",
            "          - The value of the flag. Booleans should be set to on for true and off for",
            "            false. This field must be omitted if the flag doesn't take a value.",
            "          returned: success",
            "          type: str",
            "    ipConfiguration:",
            "      description:",
            "      - The settings for IP Management. This allows to enable or disable the instance",
            "        IP and manage which external networks can connect to the instance. The IPv4",
            "        address cannot be disabled for Second Generation instances.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        ipv4Enabled:",
            "          description:",
            "          - Whether the instance should be assigned an IP address or not.",
            "          returned: success",
            "          type: bool",
            "        authorizedNetworks:",
            "          description:",
            "          - The list of external networks that are allowed to connect to the instance",
            "            using the IP. In CIDR notation, also known as 'slash' notation (e.g. 192.168.100.0/24).",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            expirationTime:",
            "              description:",
            "              - The time when this access control entry expires in RFC 3339 format,",
            "                for example 2012-11-15T16:19:00.094Z.",
            "              returned: success",
            "              type: str",
            "            name:",
            "              description:",
            "              - An optional label to identify this entry.",
            "              returned: success",
            "              type: str",
            "            value:",
            "              description:",
            "              - The whitelisted value for the access control list. For example, to",
            "                grant access to a client from an external IP (IPv4 or IPv6) address",
            "                or subnet, use that address or subnet here.",
            "              returned: success",
            "              type: str",
            "        requireSsl:",
            "          description:",
            "          - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "            over IP.",
            "          returned: success",
            "          type: bool",
            "    tier:",
            "      description:",
            "      - The tier or machine type for this instance, for example db-n1-standard-1.",
            "        For MySQL instances, this field determines whether the instance is Second",
            "        Generation (recommended) or First Generation.",
            "      returned: success",
            "      type: str",
            "    availabilityType:",
            "      description:",
            "      - The availabilityType define if your postgres instance is run zonal or regional.",
            "      returned: success",
            "      type: str",
            "    backupConfiguration:",
            "      description:",
            "      - The daily backup configuration for the instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        enabled:",
            "          description:",
            "          - Enable Autobackup for your instance.",
            "          returned: success",
            "          type: bool",
            "        binaryLogEnabled:",
            "          description:",
            "          - Whether binary log is enabled. If backup configuration is disabled, binary",
            "            log must be disabled as well. MySQL only.",
            "          returned: success",
            "          type: bool",
            "        startTime:",
            "          description:",
            "          - Define the backup start time in UTC (HH:MM) .",
            "          returned: success",
            "          type: str",
            "    settingsVersion:",
            "      description:",
            "      - The version of instance settings. This is a required field for update method",
            "        to make sure concurrent updates are handled properly. During update, use the",
            "        most recent settingsVersion value for this instance and do not try to update",
            "        this value.",
            "      returned: success",
            "      type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            backend_type=dict(type='str'),",
            "            connection_name=dict(type='str'),",
            "            database_version=dict(type='str'),",
            "            failover_replica=dict(type='dict', options=dict(name=dict(type='str'))),",
            "            instance_type=dict(type='str'),",
            "            ipv6_address=dict(type='str'),",
            "            master_instance_name=dict(type='str'),",
            "            max_disk_size=dict(type='int'),",
            "            name=dict(required=True, type='str'),",
            "            region=dict(type='str'),",
            "            replica_configuration=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    failover_target=dict(type='bool'),",
            "                    mysql_replica_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ca_certificate=dict(type='str'),",
            "                            client_certificate=dict(type='str'),",
            "                            client_key=dict(type='str'),",
            "                            connect_retry_interval=dict(type='int'),",
            "                            dump_file_path=dict(type='str'),",
            "                            master_heartbeat_period=dict(type='int'),",
            "                            password=dict(type='str'),",
            "                            ssl_cipher=dict(type='str'),",
            "                            username=dict(type='str'),",
            "                            verify_server_certificate=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    replica_names=dict(type='list', elements='str'),",
            "                    service_account_email_address=dict(type='str'),",
            "                ),",
            "            ),",
            "            settings=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    database_flags=dict(type='list', elements='dict', options=dict(name=dict(type='str'), value=dict(type='str'))),",
            "                    ip_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ipv4_enabled=dict(type='bool'),",
            "                            authorized_networks=dict(",
            "                                type='list', elements='dict', options=dict(expiration_time=dict(type='str'), name=dict(type='str'), value=dict(type='str'))",
            "                            ),",
            "                            require_ssl=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    tier=dict(type='str'),",
            "                    availability_type=dict(type='str'),",
            "                    backup_configuration=dict(",
            "                        type='dict', options=dict(enabled=dict(type='bool'), binary_log_enabled=dict(type='bool'), start_time=dict(type='str'))",
            "                    ),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/sqlservice.admin']",
            "",
            "    state = module.params['state']",
            "    kind = 'sql#instance'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind, fetch)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    module.fail_json(msg=\"SQL objects can't be updated to ensure data safety\")",
            "",
            "",
            "def delete(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'sql#instance',",
            "        u'backendType': module.params.get('backend_type'),",
            "        u'connectionName': module.params.get('connection_name'),",
            "        u'databaseVersion': module.params.get('database_version'),",
            "        u'failoverReplica': InstanceFailoverreplica(module.params.get('failover_replica', {}), module).to_request(),",
            "        u'instanceType': module.params.get('instance_type'),",
            "        u'ipv6Address': module.params.get('ipv6_address'),",
            "        u'masterInstanceName': module.params.get('master_instance_name'),",
            "        u'maxDiskSize': module.params.get('max_disk_size'),",
            "        u'name': module.params.get('name'),",
            "        u'region': module.params.get('region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(module.params.get('replica_configuration', {}), module).to_request(),",
            "        u'settings': InstanceSettings(module.params.get('settings', {}), module).to_request(),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'sql')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    # SQL only: return on 403 if not exist",
            "    if allow_not_found and response.status_code == 403:",
            "        return None",
            "",
            "    try:",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError) as inst:",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % inst)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'backendType': response.get(u'backendType'),",
            "        u'connectionName': response.get(u'connectionName'),",
            "        u'databaseVersion': response.get(u'databaseVersion'),",
            "        u'failoverReplica': InstanceFailoverreplica(response.get(u'failoverReplica', {}), module).from_response(),",
            "        u'instanceType': response.get(u'instanceType'),",
            "        u'ipAddresses': InstanceIpaddressesArray(response.get(u'ipAddresses', []), module).from_response(),",
            "        u'ipv6Address': response.get(u'ipv6Address'),",
            "        u'masterInstanceName': response.get(u'masterInstanceName'),",
            "        u'maxDiskSize': response.get(u'maxDiskSize'),",
            "        u'name': response.get(u'name'),",
            "        u'region': response.get(u'region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(response.get(u'replicaConfiguration', {}), module).from_response(),",
            "        u'settings': InstanceSettings(response.get(u'settings', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/sql/v1beta4/projects/{project}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'sql#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'sql#instance')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'sql#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class InstanceFailoverreplica(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'name': self.request.get('name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'name': self.request.get(u'name')})",
            "",
            "",
            "class InstanceIpaddressesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get('ip_address'), u'timeToRetire': item.get('time_to_retire'), u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get(u'ipAddress'), u'timeToRetire': item.get(u'timeToRetire'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceReplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get('failover_target'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(self.request.get('mysql_replica_configuration', {}), self.module).to_request(),",
            "                u'replicaNames': self.request.get('replica_names'),",
            "                u'serviceAccountEmailAddress': self.request.get('service_account_email_address'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get(u'failoverTarget'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(",
            "                    self.request.get(u'mysqlReplicaConfiguration', {}), self.module",
            "                ).from_response(),",
            "                u'replicaNames': self.request.get(u'replicaNames'),",
            "                u'serviceAccountEmailAddress': self.request.get(u'serviceAccountEmailAddress'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceMysqlreplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get('ca_certificate'),",
            "                u'clientCertificate': self.request.get('client_certificate'),",
            "                u'clientKey': self.request.get('client_key'),",
            "                u'connectRetryInterval': self.request.get('connect_retry_interval'),",
            "                u'dumpFilePath': self.request.get('dump_file_path'),",
            "                u'masterHeartbeatPeriod': self.request.get('master_heartbeat_period'),",
            "                u'password': self.request.get('password'),",
            "                u'sslCipher': self.request.get('ssl_cipher'),",
            "                u'username': self.request.get('username'),",
            "                u'verifyServerCertificate': self.request.get('verify_server_certificate'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get(u'caCertificate'),",
            "                u'clientCertificate': self.request.get(u'clientCertificate'),",
            "                u'clientKey': self.request.get(u'clientKey'),",
            "                u'connectRetryInterval': self.request.get(u'connectRetryInterval'),",
            "                u'dumpFilePath': self.request.get(u'dumpFilePath'),",
            "                u'masterHeartbeatPeriod': self.request.get(u'masterHeartbeatPeriod'),",
            "                u'password': self.request.get(u'password'),",
            "                u'sslCipher': self.request.get(u'sslCipher'),",
            "                u'username': self.request.get(u'username'),",
            "                u'verifyServerCertificate': self.request.get(u'verifyServerCertificate'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceSettings(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'databaseFlags': InstanceDatabaseflagsArray(self.request.get('database_flags', []), self.module).to_request(),",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get('ip_configuration', {}), self.module).to_request(),",
            "                u'tier': self.request.get('tier'),",
            "                u'availabilityType': self.request.get('availability_type'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get('backup_configuration', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'databaseFlags': InstanceDatabaseflagsArray(self.request.get(u'databaseFlags', []), self.module).from_response(),",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get(u'ipConfiguration', {}), self.module).from_response(),",
            "                u'tier': self.request.get(u'tier'),",
            "                u'availabilityType': self.request.get(u'availabilityType'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get(u'backupConfiguration', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceDatabaseflagsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceIpconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get('ipv4_enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get('authorized_networks', []), self.module).to_request(),",
            "                u'requireSsl': self.request.get('require_ssl'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get(u'ipv4Enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get(u'authorizedNetworks', []), self.module).from_response(),",
            "                u'requireSsl': self.request.get(u'requireSsl'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceAuthorizednetworksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get('expiration_time'), u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get(u'expirationTime'), u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceBackupconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get('enabled'), u'binaryLogEnabled': self.request.get('binary_log_enabled'), u'startTime': self.request.get('start_time')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get(u'enabled'), u'binaryLogEnabled': self.request.get(u'binaryLogEnabled'), u'startTime': self.request.get(u'startTime')}",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_sql_instance",
            "description:",
            "- Represents a Cloud SQL instance. Cloud SQL instances are SQL databases hosted in",
            "  Google's cloud. The Instances resource provides methods for common configuration",
            "  and management tasks.",
            "short_description: Creates a GCP Instance",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "    type: str",
            "  backend_type:",
            "    description:",
            "    - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "    - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "    - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "    - 'Some valid choices include: \"FIRST_GEN\", \"SECOND_GEN\", \"EXTERNAL\"'",
            "    required: false",
            "    type: str",
            "  connection_name:",
            "    description:",
            "    - Connection name of the Cloud SQL instance used in connection strings.",
            "    required: false",
            "    type: str",
            "  database_version:",
            "    description:",
            "    - The database engine type and version. For First Generation instances, can be",
            "      MYSQL_5_5, or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or",
            "      MYSQL_5_7. Defaults to MYSQL_5_6.",
            "    - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be",
            "      changed after instance creation.'",
            "    - 'Some valid choices include: \"MYSQL_5_5\", \"MYSQL_5_6\", \"MYSQL_5_7\", \"POSTGRES_9_6\"'",
            "    required: false",
            "    type: str",
            "  failover_replica:",
            "    description:",
            "    - The name and status of the failover replica. This property is applicable only",
            "      to Second Generation instances.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      name:",
            "        description:",
            "        - The name of the failover replica. If specified at instance creation, a failover",
            "          replica is created for the instance. The name doesn't include the project",
            "          ID. This property is applicable only to Second Generation instances.",
            "        required: false",
            "        type: str",
            "  instance_type:",
            "    description:",
            "    - The instance type. This can be one of the following.",
            "    - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "    - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "    - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "    - 'Some valid choices include: \"CLOUD_SQL_INSTANCE\", \"ON_PREMISES_INSTANCE\", \"READ_REPLICA_INSTANCE\"'",
            "    required: false",
            "    type: str",
            "  ipv6_address:",
            "    description:",
            "    - The IPv6 address assigned to the instance. This property is applicable only",
            "      to First Generation instances.",
            "    required: false",
            "    type: str",
            "  master_instance_name:",
            "    description:",
            "    - The name of the instance which will act as master in the replication setup.",
            "    required: false",
            "    type: str",
            "  max_disk_size:",
            "    description:",
            "    - The maximum disk size of the instance in bytes.",
            "    required: false",
            "    type: int",
            "  name:",
            "    description:",
            "    - Name of the Cloud SQL instance. This does not include the project ID.",
            "    required: true",
            "    type: str",
            "  region:",
            "    description:",
            "    - The geographical region. Defaults to us-central or us-central1 depending on",
            "      the instance type (First Generation or Second Generation/PostgreSQL).",
            "    required: false",
            "    type: str",
            "  replica_configuration:",
            "    description:",
            "    - Configuration specific to failover replicas and read replicas.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      failover_target:",
            "        description:",
            "        - Specifies if the replica is the failover target. If the field is set to",
            "          true the replica will be designated as a failover replica.",
            "        - In case the master instance fails, the replica instance will be promoted",
            "          as the new master instance.",
            "        - Only one replica can be specified as failover target, and the replica has",
            "          to be in different zone with the master instance.",
            "        required: false",
            "        type: bool",
            "      mysql_replica_configuration:",
            "        description:",
            "        - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "          Replication configuration information such as the username, password, certificates,",
            "          and keys are not stored in the instance metadata. The configuration information",
            "          is used only to set up the replication connection and is stored by MySQL",
            "          in a file named master.info in the data directory.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          ca_certificate:",
            "            description:",
            "            - PEM representation of the trusted CA's x509 certificate.",
            "            required: false",
            "            type: str",
            "          client_certificate:",
            "            description:",
            "            - PEM representation of the slave's x509 certificate .",
            "            required: false",
            "            type: str",
            "          client_key:",
            "            description:",
            "            - PEM representation of the slave's private key. The corresponding public",
            "              key is encoded in the client's certificate.",
            "            required: false",
            "            type: str",
            "          connect_retry_interval:",
            "            description:",
            "            - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "            required: false",
            "            type: int",
            "          dump_file_path:",
            "            description:",
            "            - Path to a SQL dump file in Google Cloud Storage from which the slave",
            "              instance is to be created. The URI is in the form gs://bucketName/fileName.",
            "              Compressed gzip files (.gz) are also supported. Dumps should have the",
            "              binlog coordinates from which replication should begin. This can be",
            "              accomplished by setting --master-data to 1 when using mysqldump.",
            "            required: false",
            "            type: str",
            "          master_heartbeat_period:",
            "            description:",
            "            - Interval in milliseconds between replication heartbeats.",
            "            required: false",
            "            type: int",
            "          password:",
            "            description:",
            "            - The password for the replication connection.",
            "            required: false",
            "            type: str",
            "          ssl_cipher:",
            "            description:",
            "            - A list of permissible ciphers to use for SSL encryption.",
            "            required: false",
            "            type: str",
            "          username:",
            "            description:",
            "            - The username for the replication connection.",
            "            required: false",
            "            type: str",
            "          verify_server_certificate:",
            "            description:",
            "            - Whether or not to check the master's Common Name value in the certificate",
            "              that it sends during the SSL handshake.",
            "            required: false",
            "            type: bool",
            "      replica_names:",
            "        description:",
            "        - The replicas of the instance.",
            "        required: false",
            "        type: list",
            "      service_account_email_address:",
            "        description:",
            "        - The service account email address assigned to the instance. This property",
            "          is applicable only to Second Generation instances.",
            "        required: false",
            "        type: str",
            "  settings:",
            "    description:",
            "    - The user settings.",
            "    required: false",
            "    type: dict",
            "    suboptions:",
            "      database_flags:",
            "        description:",
            "        - The database flags passed to the instance at startup.",
            "        required: false",
            "        type: list",
            "        version_added: 2.9",
            "        suboptions:",
            "          name:",
            "            description:",
            "            - The name of the flag. These flags are passed at instance startup, so",
            "              include both server options and system variables for MySQL. Flags should",
            "              be specified with underscores, not hyphens.",
            "            required: false",
            "            type: str",
            "          value:",
            "            description:",
            "            - The value of the flag. Booleans should be set to on for true and off",
            "              for false. This field must be omitted if the flag doesn't take a value.",
            "            required: false",
            "            type: str",
            "      ip_configuration:",
            "        description:",
            "        - The settings for IP Management. This allows to enable or disable the instance",
            "          IP and manage which external networks can connect to the instance. The IPv4",
            "          address cannot be disabled for Second Generation instances.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          ipv4_enabled:",
            "            description:",
            "            - Whether the instance should be assigned an IP address or not.",
            "            required: false",
            "            type: bool",
            "          authorized_networks:",
            "            description:",
            "            - The list of external networks that are allowed to connect to the instance",
            "              using the IP. In CIDR notation, also known as 'slash' notation (e.g.",
            "              192.168.100.0/24).",
            "            required: false",
            "            type: list",
            "            suboptions:",
            "              expiration_time:",
            "                description:",
            "                - The time when this access control entry expires in RFC 3339 format,",
            "                  for example 2012-11-15T16:19:00.094Z.",
            "                required: false",
            "                type: str",
            "              name:",
            "                description:",
            "                - An optional label to identify this entry.",
            "                required: false",
            "                type: str",
            "              value:",
            "                description:",
            "                - The whitelisted value for the access control list. For example,",
            "                  to grant access to a client from an external IP (IPv4 or IPv6) address",
            "                  or subnet, use that address or subnet here.",
            "                required: false",
            "                type: str",
            "          require_ssl:",
            "            description:",
            "            - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "              over IP.",
            "            required: false",
            "            type: bool",
            "      tier:",
            "        description:",
            "        - The tier or machine type for this instance, for example db-n1-standard-1.",
            "          For MySQL instances, this field determines whether the instance is Second",
            "          Generation (recommended) or First Generation.",
            "        required: false",
            "        type: str",
            "      availability_type:",
            "        description:",
            "        - The availabilityType define if your postgres instance is run zonal or regional.",
            "        - 'Some valid choices include: \"ZONAL\", \"REGIONAL\"'",
            "        required: false",
            "        type: str",
            "      backup_configuration:",
            "        description:",
            "        - The daily backup configuration for the instance.",
            "        required: false",
            "        type: dict",
            "        suboptions:",
            "          enabled:",
            "            description:",
            "            - Enable Autobackup for your instance.",
            "            required: false",
            "            type: bool",
            "          binary_log_enabled:",
            "            description:",
            "            - Whether binary log is enabled. If backup configuration is disabled,",
            "              binary log must be disabled as well. MySQL only.",
            "            required: false",
            "            type: bool",
            "          start_time:",
            "            description:",
            "            - Define the backup start time in UTC (HH:MM) .",
            "            required: false",
            "            type: str",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance",
            "  gcp_sql_instance:",
            "    name: \"{{resource_name}}-2\"",
            "    settings:",
            "      ip_configuration:",
            "        authorized_networks:",
            "        - name: google dns server",
            "          value: 8.8.8.8/32",
            "      tier: db-n1-standard-1",
            "    region: us-central1",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "backendType:",
            "  description:",
            "  - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "  - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "  - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "  returned: success",
            "  type: str",
            "connectionName:",
            "  description:",
            "  - Connection name of the Cloud SQL instance used in connection strings.",
            "  returned: success",
            "  type: str",
            "databaseVersion:",
            "  description:",
            "  - The database engine type and version. For First Generation instances, can be MYSQL_5_5,",
            "    or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or MYSQL_5_7.",
            "    Defaults to MYSQL_5_6.",
            "  - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be changed",
            "    after instance creation.'",
            "  returned: success",
            "  type: str",
            "failoverReplica:",
            "  description:",
            "  - The name and status of the failover replica. This property is applicable only",
            "    to Second Generation instances.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    available:",
            "      description:",
            "      - The availability status of the failover replica. A false status indicates",
            "        that the failover replica is out of sync. The master can only failover to",
            "        the failover replica when the status is true.",
            "      returned: success",
            "      type: bool",
            "    name:",
            "      description:",
            "      - The name of the failover replica. If specified at instance creation, a failover",
            "        replica is created for the instance. The name doesn't include the project",
            "        ID. This property is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "instanceType:",
            "  description:",
            "  - The instance type. This can be one of the following.",
            "  - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "  - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "  - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "  returned: success",
            "  type: str",
            "ipAddresses:",
            "  description:",
            "  - The assigned IP addresses for the instance.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipAddress:",
            "      description:",
            "      - The IP address assigned.",
            "      returned: success",
            "      type: str",
            "    timeToRetire:",
            "      description:",
            "      - The due time for this IP to be retired in RFC 3339 format, for example 2012-11-15T16:19:00.094Z.",
            "        This field is only available when the IP is scheduled to be retired.",
            "      returned: success",
            "      type: str",
            "    type:",
            "      description:",
            "      - The type of this IP address. A PRIMARY address is an address that can accept",
            "        incoming connections. An OUTGOING address is the source address of connections",
            "        originating from the instance, if supported.",
            "      returned: success",
            "      type: str",
            "ipv6Address:",
            "  description:",
            "  - The IPv6 address assigned to the instance. This property is applicable only to",
            "    First Generation instances.",
            "  returned: success",
            "  type: str",
            "masterInstanceName:",
            "  description:",
            "  - The name of the instance which will act as master in the replication setup.",
            "  returned: success",
            "  type: str",
            "maxDiskSize:",
            "  description:",
            "  - The maximum disk size of the instance in bytes.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the Cloud SQL instance. This does not include the project ID.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - The geographical region. Defaults to us-central or us-central1 depending on the",
            "    instance type (First Generation or Second Generation/PostgreSQL).",
            "  returned: success",
            "  type: str",
            "replicaConfiguration:",
            "  description:",
            "  - Configuration specific to failover replicas and read replicas.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    failoverTarget:",
            "      description:",
            "      - Specifies if the replica is the failover target. If the field is set to true",
            "        the replica will be designated as a failover replica.",
            "      - In case the master instance fails, the replica instance will be promoted as",
            "        the new master instance.",
            "      - Only one replica can be specified as failover target, and the replica has",
            "        to be in different zone with the master instance.",
            "      returned: success",
            "      type: bool",
            "    mysqlReplicaConfiguration:",
            "      description:",
            "      - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "        Replication configuration information such as the username, password, certificates,",
            "        and keys are not stored in the instance metadata. The configuration information",
            "        is used only to set up the replication connection and is stored by MySQL in",
            "        a file named master.info in the data directory.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        caCertificate:",
            "          description:",
            "          - PEM representation of the trusted CA's x509 certificate.",
            "          returned: success",
            "          type: str",
            "        clientCertificate:",
            "          description:",
            "          - PEM representation of the slave's x509 certificate .",
            "          returned: success",
            "          type: str",
            "        clientKey:",
            "          description:",
            "          - PEM representation of the slave's private key. The corresponding public",
            "            key is encoded in the client's certificate.",
            "          returned: success",
            "          type: str",
            "        connectRetryInterval:",
            "          description:",
            "          - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "          returned: success",
            "          type: int",
            "        dumpFilePath:",
            "          description:",
            "          - Path to a SQL dump file in Google Cloud Storage from which the slave instance",
            "            is to be created. The URI is in the form gs://bucketName/fileName. Compressed",
            "            gzip files (.gz) are also supported. Dumps should have the binlog coordinates",
            "            from which replication should begin. This can be accomplished by setting",
            "            --master-data to 1 when using mysqldump.",
            "          returned: success",
            "          type: str",
            "        masterHeartbeatPeriod:",
            "          description:",
            "          - Interval in milliseconds between replication heartbeats.",
            "          returned: success",
            "          type: int",
            "        password:",
            "          description:",
            "          - The password for the replication connection.",
            "          returned: success",
            "          type: str",
            "        sslCipher:",
            "          description:",
            "          - A list of permissible ciphers to use for SSL encryption.",
            "          returned: success",
            "          type: str",
            "        username:",
            "          description:",
            "          - The username for the replication connection.",
            "          returned: success",
            "          type: str",
            "        verifyServerCertificate:",
            "          description:",
            "          - Whether or not to check the master's Common Name value in the certificate",
            "            that it sends during the SSL handshake.",
            "          returned: success",
            "          type: bool",
            "    replicaNames:",
            "      description:",
            "      - The replicas of the instance.",
            "      returned: success",
            "      type: list",
            "    serviceAccountEmailAddress:",
            "      description:",
            "      - The service account email address assigned to the instance. This property",
            "        is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "settings:",
            "  description:",
            "  - The user settings.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    databaseFlags:",
            "      description:",
            "      - The database flags passed to the instance at startup.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        name:",
            "          description:",
            "          - The name of the flag. These flags are passed at instance startup, so include",
            "            both server options and system variables for MySQL. Flags should be specified",
            "            with underscores, not hyphens.",
            "          returned: success",
            "          type: str",
            "        value:",
            "          description:",
            "          - The value of the flag. Booleans should be set to on for true and off for",
            "            false. This field must be omitted if the flag doesn't take a value.",
            "          returned: success",
            "          type: str",
            "    ipConfiguration:",
            "      description:",
            "      - The settings for IP Management. This allows to enable or disable the instance",
            "        IP and manage which external networks can connect to the instance. The IPv4",
            "        address cannot be disabled for Second Generation instances.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        ipv4Enabled:",
            "          description:",
            "          - Whether the instance should be assigned an IP address or not.",
            "          returned: success",
            "          type: bool",
            "        authorizedNetworks:",
            "          description:",
            "          - The list of external networks that are allowed to connect to the instance",
            "            using the IP. In CIDR notation, also known as 'slash' notation (e.g. 192.168.100.0/24).",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            expirationTime:",
            "              description:",
            "              - The time when this access control entry expires in RFC 3339 format,",
            "                for example 2012-11-15T16:19:00.094Z.",
            "              returned: success",
            "              type: str",
            "            name:",
            "              description:",
            "              - An optional label to identify this entry.",
            "              returned: success",
            "              type: str",
            "            value:",
            "              description:",
            "              - The whitelisted value for the access control list. For example, to",
            "                grant access to a client from an external IP (IPv4 or IPv6) address",
            "                or subnet, use that address or subnet here.",
            "              returned: success",
            "              type: str",
            "        requireSsl:",
            "          description:",
            "          - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "            over IP.",
            "          returned: success",
            "          type: bool",
            "    tier:",
            "      description:",
            "      - The tier or machine type for this instance, for example db-n1-standard-1.",
            "        For MySQL instances, this field determines whether the instance is Second",
            "        Generation (recommended) or First Generation.",
            "      returned: success",
            "      type: str",
            "    availabilityType:",
            "      description:",
            "      - The availabilityType define if your postgres instance is run zonal or regional.",
            "      returned: success",
            "      type: str",
            "    backupConfiguration:",
            "      description:",
            "      - The daily backup configuration for the instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        enabled:",
            "          description:",
            "          - Enable Autobackup for your instance.",
            "          returned: success",
            "          type: bool",
            "        binaryLogEnabled:",
            "          description:",
            "          - Whether binary log is enabled. If backup configuration is disabled, binary",
            "            log must be disabled as well. MySQL only.",
            "          returned: success",
            "          type: bool",
            "        startTime:",
            "          description:",
            "          - Define the backup start time in UTC (HH:MM) .",
            "          returned: success",
            "          type: str",
            "    settingsVersion:",
            "      description:",
            "      - The version of instance settings. This is a required field for update method",
            "        to make sure concurrent updates are handled properly. During update, use the",
            "        most recent settingsVersion value for this instance and do not try to update",
            "        this value.",
            "      returned: success",
            "      type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            backend_type=dict(type='str'),",
            "            connection_name=dict(type='str'),",
            "            database_version=dict(type='str'),",
            "            failover_replica=dict(type='dict', options=dict(name=dict(type='str'))),",
            "            instance_type=dict(type='str'),",
            "            ipv6_address=dict(type='str'),",
            "            master_instance_name=dict(type='str'),",
            "            max_disk_size=dict(type='int'),",
            "            name=dict(required=True, type='str'),",
            "            region=dict(type='str'),",
            "            replica_configuration=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    failover_target=dict(type='bool'),",
            "                    mysql_replica_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ca_certificate=dict(type='str'),",
            "                            client_certificate=dict(type='str'),",
            "                            client_key=dict(type='str', no_log=True),",
            "                            connect_retry_interval=dict(type='int'),",
            "                            dump_file_path=dict(type='str'),",
            "                            master_heartbeat_period=dict(type='int'),",
            "                            password=dict(type='str'),",
            "                            ssl_cipher=dict(type='str'),",
            "                            username=dict(type='str'),",
            "                            verify_server_certificate=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    replica_names=dict(type='list', elements='str'),",
            "                    service_account_email_address=dict(type='str'),",
            "                ),",
            "            ),",
            "            settings=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    database_flags=dict(type='list', elements='dict', options=dict(name=dict(type='str'), value=dict(type='str'))),",
            "                    ip_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ipv4_enabled=dict(type='bool'),",
            "                            authorized_networks=dict(",
            "                                type='list', elements='dict', options=dict(expiration_time=dict(type='str'), name=dict(type='str'), value=dict(type='str'))",
            "                            ),",
            "                            require_ssl=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    tier=dict(type='str'),",
            "                    availability_type=dict(type='str'),",
            "                    backup_configuration=dict(",
            "                        type='dict', options=dict(enabled=dict(type='bool'), binary_log_enabled=dict(type='bool'), start_time=dict(type='str'))",
            "                    ),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/sqlservice.admin']",
            "",
            "    state = module.params['state']",
            "    kind = 'sql#instance'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind, fetch)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    module.fail_json(msg=\"SQL objects can't be updated to ensure data safety\")",
            "",
            "",
            "def delete(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'sql#instance',",
            "        u'backendType': module.params.get('backend_type'),",
            "        u'connectionName': module.params.get('connection_name'),",
            "        u'databaseVersion': module.params.get('database_version'),",
            "        u'failoverReplica': InstanceFailoverreplica(module.params.get('failover_replica', {}), module).to_request(),",
            "        u'instanceType': module.params.get('instance_type'),",
            "        u'ipv6Address': module.params.get('ipv6_address'),",
            "        u'masterInstanceName': module.params.get('master_instance_name'),",
            "        u'maxDiskSize': module.params.get('max_disk_size'),",
            "        u'name': module.params.get('name'),",
            "        u'region': module.params.get('region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(module.params.get('replica_configuration', {}), module).to_request(),",
            "        u'settings': InstanceSettings(module.params.get('settings', {}), module).to_request(),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'sql')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    # SQL only: return on 403 if not exist",
            "    if allow_not_found and response.status_code == 403:",
            "        return None",
            "",
            "    try:",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError) as inst:",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % inst)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'backendType': response.get(u'backendType'),",
            "        u'connectionName': response.get(u'connectionName'),",
            "        u'databaseVersion': response.get(u'databaseVersion'),",
            "        u'failoverReplica': InstanceFailoverreplica(response.get(u'failoverReplica', {}), module).from_response(),",
            "        u'instanceType': response.get(u'instanceType'),",
            "        u'ipAddresses': InstanceIpaddressesArray(response.get(u'ipAddresses', []), module).from_response(),",
            "        u'ipv6Address': response.get(u'ipv6Address'),",
            "        u'masterInstanceName': response.get(u'masterInstanceName'),",
            "        u'maxDiskSize': response.get(u'maxDiskSize'),",
            "        u'name': response.get(u'name'),",
            "        u'region': response.get(u'region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(response.get(u'replicaConfiguration', {}), module).from_response(),",
            "        u'settings': InstanceSettings(response.get(u'settings', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/sql/v1beta4/projects/{project}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'sql#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'sql#instance')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'sql#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class InstanceFailoverreplica(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'name': self.request.get('name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'name': self.request.get(u'name')})",
            "",
            "",
            "class InstanceIpaddressesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get('ip_address'), u'timeToRetire': item.get('time_to_retire'), u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get(u'ipAddress'), u'timeToRetire': item.get(u'timeToRetire'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceReplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get('failover_target'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(self.request.get('mysql_replica_configuration', {}), self.module).to_request(),",
            "                u'replicaNames': self.request.get('replica_names'),",
            "                u'serviceAccountEmailAddress': self.request.get('service_account_email_address'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get(u'failoverTarget'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(",
            "                    self.request.get(u'mysqlReplicaConfiguration', {}), self.module",
            "                ).from_response(),",
            "                u'replicaNames': self.request.get(u'replicaNames'),",
            "                u'serviceAccountEmailAddress': self.request.get(u'serviceAccountEmailAddress'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceMysqlreplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get('ca_certificate'),",
            "                u'clientCertificate': self.request.get('client_certificate'),",
            "                u'clientKey': self.request.get('client_key'),",
            "                u'connectRetryInterval': self.request.get('connect_retry_interval'),",
            "                u'dumpFilePath': self.request.get('dump_file_path'),",
            "                u'masterHeartbeatPeriod': self.request.get('master_heartbeat_period'),",
            "                u'password': self.request.get('password'),",
            "                u'sslCipher': self.request.get('ssl_cipher'),",
            "                u'username': self.request.get('username'),",
            "                u'verifyServerCertificate': self.request.get('verify_server_certificate'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get(u'caCertificate'),",
            "                u'clientCertificate': self.request.get(u'clientCertificate'),",
            "                u'clientKey': self.request.get(u'clientKey'),",
            "                u'connectRetryInterval': self.request.get(u'connectRetryInterval'),",
            "                u'dumpFilePath': self.request.get(u'dumpFilePath'),",
            "                u'masterHeartbeatPeriod': self.request.get(u'masterHeartbeatPeriod'),",
            "                u'password': self.request.get(u'password'),",
            "                u'sslCipher': self.request.get(u'sslCipher'),",
            "                u'username': self.request.get(u'username'),",
            "                u'verifyServerCertificate': self.request.get(u'verifyServerCertificate'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceSettings(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'databaseFlags': InstanceDatabaseflagsArray(self.request.get('database_flags', []), self.module).to_request(),",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get('ip_configuration', {}), self.module).to_request(),",
            "                u'tier': self.request.get('tier'),",
            "                u'availabilityType': self.request.get('availability_type'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get('backup_configuration', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'databaseFlags': InstanceDatabaseflagsArray(self.request.get(u'databaseFlags', []), self.module).from_response(),",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get(u'ipConfiguration', {}), self.module).from_response(),",
            "                u'tier': self.request.get(u'tier'),",
            "                u'availabilityType': self.request.get(u'availabilityType'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get(u'backupConfiguration', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceDatabaseflagsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceIpconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get('ipv4_enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get('authorized_networks', []), self.module).to_request(),",
            "                u'requireSsl': self.request.get('require_ssl'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get(u'ipv4Enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get(u'authorizedNetworks', []), self.module).from_response(),",
            "                u'requireSsl': self.request.get(u'requireSsl'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceAuthorizednetworksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get('expiration_time'), u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get(u'expirationTime'), u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceBackupconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get('enabled'), u'binaryLogEnabled': self.request.get('binary_log_enabled'), u'startTime': self.request.get('start_time')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get(u'enabled'), u'binaryLogEnabled': self.request.get(u'binaryLogEnabled'), u'startTime': self.request.get(u'startTime')}",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "691": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/misc/ovirt.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 380,
                "PatchRowcode": "             instance_gateway=dict(type='str', aliases=['gateway']),"
            },
            "1": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             instance_domain=dict(type='str', aliases=['domain']),"
            },
            "2": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "             instance_dns=dict(type='str', aliases=['dns']),"
            },
            "3": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            instance_rootpw=dict(type='str', aliases=['rootpw']),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+            instance_rootpw=dict(type='str', aliases=['rootpw'], no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "             instance_key=dict(type='str', aliases=['key']),"
            },
            "6": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             sdomain=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "             region=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2013, Vincent Van der Kussen <vincent at vanderkussen.org>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ovirt",
            "author:",
            "- Vincent Van der Kussen (@vincentvdk)",
            "short_description: oVirt/RHEV platform management",
            "description:",
            "    - This module only supports oVirt/RHEV version 3. A newer module M(ovirt_vm) supports oVirt/RHV version 4.",
            "    - Allows you to create new instances, either from scratch or an image, in addition to deleting or stopping instances on the oVirt/RHEV platform.",
            "version_added: \"1.4\"",
            "options:",
            "  user:",
            "    description:",
            "     - The user to authenticate with.",
            "    required: true",
            "  url:",
            "    description:",
            "     - The url of the oVirt instance.",
            "    required: true",
            "  instance_name:",
            "    description:",
            "     - The name of the instance to use.",
            "    required: true",
            "    aliases: [ vmname ]",
            "  password:",
            "    description:",
            "     - Password of the user to authenticate with.",
            "    required: true",
            "  image:",
            "    description:",
            "     - The template to use for the instance.",
            "  resource_type:",
            "    description:",
            "     - Whether you want to deploy an image or create an instance from scratch.",
            "    choices: [ new, template ]",
            "  zone:",
            "    description:",
            "     - Deploy the image to this oVirt cluster.",
            "  instance_disksize:",
            "    description:",
            "     - Size of the instance's disk in GB.",
            "    aliases: [ vm_disksize]",
            "  instance_cpus:",
            "    description:",
            "     - The instance's number of CPUs.",
            "    default: 1",
            "    aliases: [ vmcpus ]",
            "  instance_nic:",
            "    description:",
            "     - The name of the network interface in oVirt/RHEV.",
            "    aliases: [ vmnic  ]",
            "  instance_network:",
            "    description:",
            "     - The logical network the machine should belong to.",
            "    default: rhevm",
            "    aliases: [ vmnetwork ]",
            "  instance_mem:",
            "    description:",
            "     - The instance's amount of memory in MB.",
            "    aliases: [ vmmem ]",
            "  instance_type:",
            "    description:",
            "     - Define whether the instance is a server, desktop or high_performance.",
            "     - I(high_performance) is supported since Ansible 2.5 and oVirt/RHV 4.2.",
            "    choices: [ desktop, server, high_performance ]",
            "    default: server",
            "    aliases: [ vmtype ]",
            "  disk_alloc:",
            "    description:",
            "     - Define whether disk is thin or preallocated.",
            "    choices: [ preallocated, thin ]",
            "    default: thin",
            "  disk_int:",
            "    description:",
            "     - Interface type of the disk.",
            "    choices: [ ide, virtio ]",
            "    default: virtio",
            "  instance_os:",
            "    description:",
            "     - Type of Operating System.",
            "    aliases: [ vmos ]",
            "  instance_cores:",
            "    description:",
            "     - Define the instance's number of cores.",
            "    default: 1",
            "    aliases: [ vmcores ]",
            "  sdomain:",
            "    description:",
            "     - The Storage Domain where you want to create the instance's disk on.",
            "  region:",
            "    description:",
            "     - The oVirt/RHEV datacenter where you want to deploy to.",
            "  instance_dns:",
            "    description:",
            "     - Define the instance's Primary DNS server.",
            "    aliases: [ dns ]",
            "    version_added: \"2.1\"",
            "  instance_domain:",
            "    description:",
            "     - Define the instance's Domain.",
            "    aliases: [ domain ]",
            "    version_added: \"2.1\"",
            "  instance_hostname:",
            "    description:",
            "     - Define the instance's Hostname.",
            "    aliases: [ hostname ]",
            "    version_added: \"2.1\"",
            "  instance_ip:",
            "    description:",
            "     - Define the instance's IP.",
            "    aliases: [ ip ]",
            "    version_added: \"2.1\"",
            "  instance_netmask:",
            "    description:",
            "     - Define the instance's Netmask.",
            "    aliases: [ netmask ]",
            "    version_added: \"2.1\"",
            "  instance_rootpw:",
            "    description:",
            "     - Define the instance's Root password.",
            "    aliases: [ rootpw ]",
            "    version_added: \"2.1\"",
            "  instance_key:",
            "    description:",
            "     - Define the instance's Authorized key.",
            "    aliases: [ key ]",
            "    version_added: \"2.1\"",
            "  state:",
            "    description:",
            "     - Create, terminate or remove instances.",
            "    choices: [ absent, present, restarted, shutdown, started ]",
            "    default: present",
            "requirements:",
            "  - ovirt-engine-sdk-python",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Basic example to provision from image",
            "  ovirt:",
            "    user: admin@internal",
            "    url: https://ovirt.example.com",
            "    instance_name: ansiblevm04",
            "    password: secret",
            "    image: centos_64",
            "    zone: cluster01",
            "    resource_type: template",
            "",
            "- name: Full example to create new instance from scratch",
            "  ovirt:",
            "    instance_name: testansible",
            "    resource_type: new",
            "    instance_type: server",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    instance_disksize: 10",
            "    zone: cluster01",
            "    region: datacenter1",
            "    instance_cpus: 1",
            "    instance_nic: nic1",
            "    instance_network: rhevm",
            "    instance_mem: 1000",
            "    disk_alloc: thin",
            "    sdomain: FIBER01",
            "    instance_cores: 1",
            "    instance_os: rhel_6x64",
            "    disk_int: virtio",
            "",
            "- name: Stopping an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: stopped",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an instance with cloud init information",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    hostname: testansible",
            "    domain: ansible.local",
            "    ip: 192.0.2.100",
            "    netmask: 255.255.255.0",
            "    gateway: 192.0.2.1",
            "    rootpw: bigsecret",
            "'''",
            "",
            "import time",
            "",
            "try:",
            "    from ovirtsdk.api import API",
            "    from ovirtsdk.xml import params",
            "    HAS_OVIRTSDK = True",
            "except ImportError:",
            "    HAS_OVIRTSDK = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# create connection with API",
            "#",
            "def conn(url, user, password):",
            "    api = API(url=url, username=user, password=password, insecure=True)",
            "    try:",
            "        value = api.test()",
            "    except Exception:",
            "        raise Exception(\"error connecting to the oVirt API\")",
            "    return api",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# Create VM from scratch",
            "def create_vm(conn, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int):",
            "    if vmdisk_alloc == 'thin':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=True, interface=vmdisk_int, type_=\"System\",",
            "                             format='cow',",
            "                             storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name='nic1', network=network_net, interface='virtio')",
            "    elif vmdisk_alloc == 'preallocated':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=False, interface=vmdisk_int, type_=\"System\",",
            "                             format='raw', storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name=vmnic, network=network_net, interface='virtio')",
            "",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception(\"Error creating VM with specified parameters\")",
            "    vm = conn.vms.get(name=vmname)",
            "    try:",
            "        vm.disks.add(vmdisk)",
            "    except Exception:",
            "        raise Exception(\"Error attaching disk\")",
            "    try:",
            "        vm.nics.add(nic_net1)",
            "    except Exception:",
            "        raise Exception(\"Error adding nic\")",
            "",
            "",
            "# create an instance from a template",
            "def create_vm_template(conn, vmname, image, zone):",
            "    vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), template=conn.templates.get(name=image), disks=params.Disks(clone=True))",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception('error adding template %s' % image)",
            "",
            "",
            "# start instance",
            "def vm_start(conn, vmname, hostname=None, ip=None, netmask=None, gateway=None,",
            "             domain=None, dns=None, rootpw=None, key=None):",
            "    vm = conn.vms.get(name=vmname)",
            "    use_cloud_init = False",
            "    nics = None",
            "    nic = None",
            "    if hostname or ip or netmask or gateway or domain or dns or rootpw or key:",
            "        use_cloud_init = True",
            "    if ip and netmask and gateway:",
            "        ipinfo = params.IP(address=ip, netmask=netmask, gateway=gateway)",
            "        nic = params.GuestNicConfiguration(name='eth0', boot_protocol='STATIC', ip=ipinfo, on_boot=True)",
            "        nics = params.Nics()",
            "    nics = params.GuestNicsConfiguration(nic_configuration=[nic])",
            "    initialization = params.Initialization(regenerate_ssh_keys=True, host_name=hostname, domain=domain, user_name='root',",
            "                                           root_password=rootpw, nic_configurations=nics, dns_servers=dns,",
            "                                           authorized_ssh_keys=key)",
            "    action = params.Action(use_cloud_init=use_cloud_init, vm=params.VM(initialization=initialization))",
            "    vm.start(action=action)",
            "",
            "",
            "# Stop instance",
            "def vm_stop(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "",
            "",
            "# restart instance",
            "def vm_restart(conn, vmname):",
            "    state = vm_status(conn, vmname)",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "    while conn.vms.get(vmname).get_status().get_state() != 'down':",
            "        time.sleep(5)",
            "    vm.start()",
            "",
            "",
            "# remove an instance",
            "def vm_remove(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.delete()",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# VM statuses",
            "#",
            "# Get the VMs status",
            "def vm_status(conn, vmname):",
            "    status = conn.vms.get(name=vmname).status.state",
            "    return status",
            "",
            "",
            "# Get VM object and return it's name if object exists",
            "def get_vm(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    if vm is None:",
            "        name = \"empty\"",
            "    else:",
            "        name = vm.get_name()",
            "    return name",
            "",
            "# ------------------------------------------------------------------- #",
            "# Hypervisor operations",
            "#",
            "# not available yet",
            "# ------------------------------------------------------------------- #",
            "# Main",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            state=dict(type='str', default='present', choices=['absent', 'present', 'restart', 'shutdown', 'started']),",
            "            user=dict(type='str', required=True),",
            "            url=dict(type='str', required=True),",
            "            instance_name=dict(type='str', required=True, aliases=['vmname']),",
            "            password=dict(type='str', required=True, no_log=True),",
            "            image=dict(type='str'),",
            "            resource_type=dict(type='str', choices=['new', 'template']),",
            "            zone=dict(type='str'),",
            "            instance_disksize=dict(type='str', aliases=['vm_disksize']),",
            "            instance_cpus=dict(type='str', default=1, aliases=['vmcpus']),",
            "            instance_nic=dict(type='str', aliases=['vmnic']),",
            "            instance_network=dict(type='str', default='rhevm', aliases=['vmnetwork']),",
            "            instance_mem=dict(type='str', aliases=['vmmem']),",
            "            instance_type=dict(type='str', default='server', aliases=['vmtype'], choices=['desktop', 'server', 'high_performance']),",
            "            disk_alloc=dict(type='str', default='thin', choices=['preallocated', 'thin']),",
            "            disk_int=dict(type='str', default='virtio', choices=['ide', 'virtio']),",
            "            instance_os=dict(type='str', aliases=['vmos']),",
            "            instance_cores=dict(type='str', default=1, aliases=['vmcores']),",
            "            instance_hostname=dict(type='str', aliases=['hostname']),",
            "            instance_ip=dict(type='str', aliases=['ip']),",
            "            instance_netmask=dict(type='str', aliases=['netmask']),",
            "            instance_gateway=dict(type='str', aliases=['gateway']),",
            "            instance_domain=dict(type='str', aliases=['domain']),",
            "            instance_dns=dict(type='str', aliases=['dns']),",
            "            instance_rootpw=dict(type='str', aliases=['rootpw']),",
            "            instance_key=dict(type='str', aliases=['key']),",
            "            sdomain=dict(type='str'),",
            "            region=dict(type='str'),",
            "        ),",
            "    )",
            "",
            "    if not HAS_OVIRTSDK:",
            "        module.fail_json(msg='ovirtsdk required for this module')",
            "",
            "    state = module.params['state']",
            "    user = module.params['user']",
            "    url = module.params['url']",
            "    vmname = module.params['instance_name']",
            "    password = module.params['password']",
            "    image = module.params['image']  # name of the image to deploy",
            "    resource_type = module.params['resource_type']  # template or from scratch",
            "    zone = module.params['zone']  # oVirt cluster",
            "    vmdisk_size = module.params['instance_disksize']  # disksize",
            "    vmcpus = module.params['instance_cpus']  # number of cpu",
            "    vmnic = module.params['instance_nic']  # network interface",
            "    vmnetwork = module.params['instance_network']  # logical network",
            "    vmmem = module.params['instance_mem']  # mem size",
            "    vmdisk_alloc = module.params['disk_alloc']  # thin, preallocated",
            "    vmdisk_int = module.params['disk_int']  # disk interface virtio or ide",
            "    vmos = module.params['instance_os']  # Operating System",
            "    vmtype = module.params['instance_type']  # server, desktop or high_performance",
            "    vmcores = module.params['instance_cores']  # number of cores",
            "    sdomain = module.params['sdomain']  # storage domain to store disk on",
            "    region = module.params['region']  # oVirt Datacenter",
            "    hostname = module.params['instance_hostname']",
            "    ip = module.params['instance_ip']",
            "    netmask = module.params['instance_netmask']",
            "    gateway = module.params['instance_gateway']",
            "    domain = module.params['instance_domain']",
            "    dns = module.params['instance_dns']",
            "    rootpw = module.params['instance_rootpw']",
            "    key = module.params['instance_key']",
            "    # initialize connection",
            "    try:",
            "        c = conn(url + \"/api\", user, password)",
            "    except Exception as e:",
            "        module.fail_json(msg='%s' % e)",
            "",
            "    if state == 'present':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            if resource_type == 'template':",
            "                try:",
            "                    create_vm_template(c, vmname, image, zone)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from template %s\" % (vmname, image))",
            "            elif resource_type == 'new':",
            "                # FIXME: refactor, use keyword args.",
            "                try:",
            "                    create_vm(c, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from scratch\" % vmname)",
            "            else:",
            "                module.exit_json(changed=False, msg=\"You did not specify a resource type\")",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s already exists\" % vmname)",
            "",
            "    if state == 'started':",
            "        if vm_status(c, vmname) == 'up':",
            "            module.exit_json(changed=False, msg=\"VM %s is already running\" % vmname)",
            "        else:",
            "            # vm_start(c, vmname)",
            "            vm_start(c, vmname, hostname, ip, netmask, gateway, domain, dns, rootpw, key)",
            "            module.exit_json(changed=True, msg=\"VM %s started\" % vmname)",
            "",
            "    if state == 'shutdown':",
            "        if vm_status(c, vmname) == 'down':",
            "            module.exit_json(changed=False, msg=\"VM %s is already shutdown\" % vmname)",
            "        else:",
            "            vm_stop(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is shutting down\" % vmname)",
            "",
            "    if state == 'restart':",
            "        if vm_status(c, vmname) == 'up':",
            "            vm_restart(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is restarted\" % vmname)",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s is not running\" % vmname)",
            "",
            "    if state == 'absent':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            module.exit_json(changed=False, msg=\"VM %s does not exist\" % vmname)",
            "        else:",
            "            vm_remove(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s removed\" % vmname)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2013, Vincent Van der Kussen <vincent at vanderkussen.org>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ovirt",
            "author:",
            "- Vincent Van der Kussen (@vincentvdk)",
            "short_description: oVirt/RHEV platform management",
            "description:",
            "    - This module only supports oVirt/RHEV version 3. A newer module M(ovirt_vm) supports oVirt/RHV version 4.",
            "    - Allows you to create new instances, either from scratch or an image, in addition to deleting or stopping instances on the oVirt/RHEV platform.",
            "version_added: \"1.4\"",
            "options:",
            "  user:",
            "    description:",
            "     - The user to authenticate with.",
            "    required: true",
            "  url:",
            "    description:",
            "     - The url of the oVirt instance.",
            "    required: true",
            "  instance_name:",
            "    description:",
            "     - The name of the instance to use.",
            "    required: true",
            "    aliases: [ vmname ]",
            "  password:",
            "    description:",
            "     - Password of the user to authenticate with.",
            "    required: true",
            "  image:",
            "    description:",
            "     - The template to use for the instance.",
            "  resource_type:",
            "    description:",
            "     - Whether you want to deploy an image or create an instance from scratch.",
            "    choices: [ new, template ]",
            "  zone:",
            "    description:",
            "     - Deploy the image to this oVirt cluster.",
            "  instance_disksize:",
            "    description:",
            "     - Size of the instance's disk in GB.",
            "    aliases: [ vm_disksize]",
            "  instance_cpus:",
            "    description:",
            "     - The instance's number of CPUs.",
            "    default: 1",
            "    aliases: [ vmcpus ]",
            "  instance_nic:",
            "    description:",
            "     - The name of the network interface in oVirt/RHEV.",
            "    aliases: [ vmnic  ]",
            "  instance_network:",
            "    description:",
            "     - The logical network the machine should belong to.",
            "    default: rhevm",
            "    aliases: [ vmnetwork ]",
            "  instance_mem:",
            "    description:",
            "     - The instance's amount of memory in MB.",
            "    aliases: [ vmmem ]",
            "  instance_type:",
            "    description:",
            "     - Define whether the instance is a server, desktop or high_performance.",
            "     - I(high_performance) is supported since Ansible 2.5 and oVirt/RHV 4.2.",
            "    choices: [ desktop, server, high_performance ]",
            "    default: server",
            "    aliases: [ vmtype ]",
            "  disk_alloc:",
            "    description:",
            "     - Define whether disk is thin or preallocated.",
            "    choices: [ preallocated, thin ]",
            "    default: thin",
            "  disk_int:",
            "    description:",
            "     - Interface type of the disk.",
            "    choices: [ ide, virtio ]",
            "    default: virtio",
            "  instance_os:",
            "    description:",
            "     - Type of Operating System.",
            "    aliases: [ vmos ]",
            "  instance_cores:",
            "    description:",
            "     - Define the instance's number of cores.",
            "    default: 1",
            "    aliases: [ vmcores ]",
            "  sdomain:",
            "    description:",
            "     - The Storage Domain where you want to create the instance's disk on.",
            "  region:",
            "    description:",
            "     - The oVirt/RHEV datacenter where you want to deploy to.",
            "  instance_dns:",
            "    description:",
            "     - Define the instance's Primary DNS server.",
            "    aliases: [ dns ]",
            "    version_added: \"2.1\"",
            "  instance_domain:",
            "    description:",
            "     - Define the instance's Domain.",
            "    aliases: [ domain ]",
            "    version_added: \"2.1\"",
            "  instance_hostname:",
            "    description:",
            "     - Define the instance's Hostname.",
            "    aliases: [ hostname ]",
            "    version_added: \"2.1\"",
            "  instance_ip:",
            "    description:",
            "     - Define the instance's IP.",
            "    aliases: [ ip ]",
            "    version_added: \"2.1\"",
            "  instance_netmask:",
            "    description:",
            "     - Define the instance's Netmask.",
            "    aliases: [ netmask ]",
            "    version_added: \"2.1\"",
            "  instance_rootpw:",
            "    description:",
            "     - Define the instance's Root password.",
            "    aliases: [ rootpw ]",
            "    version_added: \"2.1\"",
            "  instance_key:",
            "    description:",
            "     - Define the instance's Authorized key.",
            "    aliases: [ key ]",
            "    version_added: \"2.1\"",
            "  state:",
            "    description:",
            "     - Create, terminate or remove instances.",
            "    choices: [ absent, present, restarted, shutdown, started ]",
            "    default: present",
            "requirements:",
            "  - ovirt-engine-sdk-python",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Basic example to provision from image",
            "  ovirt:",
            "    user: admin@internal",
            "    url: https://ovirt.example.com",
            "    instance_name: ansiblevm04",
            "    password: secret",
            "    image: centos_64",
            "    zone: cluster01",
            "    resource_type: template",
            "",
            "- name: Full example to create new instance from scratch",
            "  ovirt:",
            "    instance_name: testansible",
            "    resource_type: new",
            "    instance_type: server",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    instance_disksize: 10",
            "    zone: cluster01",
            "    region: datacenter1",
            "    instance_cpus: 1",
            "    instance_nic: nic1",
            "    instance_network: rhevm",
            "    instance_mem: 1000",
            "    disk_alloc: thin",
            "    sdomain: FIBER01",
            "    instance_cores: 1",
            "    instance_os: rhel_6x64",
            "    disk_int: virtio",
            "",
            "- name: Stopping an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: stopped",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an instance with cloud init information",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    hostname: testansible",
            "    domain: ansible.local",
            "    ip: 192.0.2.100",
            "    netmask: 255.255.255.0",
            "    gateway: 192.0.2.1",
            "    rootpw: bigsecret",
            "'''",
            "",
            "import time",
            "",
            "try:",
            "    from ovirtsdk.api import API",
            "    from ovirtsdk.xml import params",
            "    HAS_OVIRTSDK = True",
            "except ImportError:",
            "    HAS_OVIRTSDK = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# create connection with API",
            "#",
            "def conn(url, user, password):",
            "    api = API(url=url, username=user, password=password, insecure=True)",
            "    try:",
            "        value = api.test()",
            "    except Exception:",
            "        raise Exception(\"error connecting to the oVirt API\")",
            "    return api",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# Create VM from scratch",
            "def create_vm(conn, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int):",
            "    if vmdisk_alloc == 'thin':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=True, interface=vmdisk_int, type_=\"System\",",
            "                             format='cow',",
            "                             storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name='nic1', network=network_net, interface='virtio')",
            "    elif vmdisk_alloc == 'preallocated':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=False, interface=vmdisk_int, type_=\"System\",",
            "                             format='raw', storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name=vmnic, network=network_net, interface='virtio')",
            "",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception(\"Error creating VM with specified parameters\")",
            "    vm = conn.vms.get(name=vmname)",
            "    try:",
            "        vm.disks.add(vmdisk)",
            "    except Exception:",
            "        raise Exception(\"Error attaching disk\")",
            "    try:",
            "        vm.nics.add(nic_net1)",
            "    except Exception:",
            "        raise Exception(\"Error adding nic\")",
            "",
            "",
            "# create an instance from a template",
            "def create_vm_template(conn, vmname, image, zone):",
            "    vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), template=conn.templates.get(name=image), disks=params.Disks(clone=True))",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception('error adding template %s' % image)",
            "",
            "",
            "# start instance",
            "def vm_start(conn, vmname, hostname=None, ip=None, netmask=None, gateway=None,",
            "             domain=None, dns=None, rootpw=None, key=None):",
            "    vm = conn.vms.get(name=vmname)",
            "    use_cloud_init = False",
            "    nics = None",
            "    nic = None",
            "    if hostname or ip or netmask or gateway or domain or dns or rootpw or key:",
            "        use_cloud_init = True",
            "    if ip and netmask and gateway:",
            "        ipinfo = params.IP(address=ip, netmask=netmask, gateway=gateway)",
            "        nic = params.GuestNicConfiguration(name='eth0', boot_protocol='STATIC', ip=ipinfo, on_boot=True)",
            "        nics = params.Nics()",
            "    nics = params.GuestNicsConfiguration(nic_configuration=[nic])",
            "    initialization = params.Initialization(regenerate_ssh_keys=True, host_name=hostname, domain=domain, user_name='root',",
            "                                           root_password=rootpw, nic_configurations=nics, dns_servers=dns,",
            "                                           authorized_ssh_keys=key)",
            "    action = params.Action(use_cloud_init=use_cloud_init, vm=params.VM(initialization=initialization))",
            "    vm.start(action=action)",
            "",
            "",
            "# Stop instance",
            "def vm_stop(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "",
            "",
            "# restart instance",
            "def vm_restart(conn, vmname):",
            "    state = vm_status(conn, vmname)",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "    while conn.vms.get(vmname).get_status().get_state() != 'down':",
            "        time.sleep(5)",
            "    vm.start()",
            "",
            "",
            "# remove an instance",
            "def vm_remove(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.delete()",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# VM statuses",
            "#",
            "# Get the VMs status",
            "def vm_status(conn, vmname):",
            "    status = conn.vms.get(name=vmname).status.state",
            "    return status",
            "",
            "",
            "# Get VM object and return it's name if object exists",
            "def get_vm(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    if vm is None:",
            "        name = \"empty\"",
            "    else:",
            "        name = vm.get_name()",
            "    return name",
            "",
            "# ------------------------------------------------------------------- #",
            "# Hypervisor operations",
            "#",
            "# not available yet",
            "# ------------------------------------------------------------------- #",
            "# Main",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            state=dict(type='str', default='present', choices=['absent', 'present', 'restart', 'shutdown', 'started']),",
            "            user=dict(type='str', required=True),",
            "            url=dict(type='str', required=True),",
            "            instance_name=dict(type='str', required=True, aliases=['vmname']),",
            "            password=dict(type='str', required=True, no_log=True),",
            "            image=dict(type='str'),",
            "            resource_type=dict(type='str', choices=['new', 'template']),",
            "            zone=dict(type='str'),",
            "            instance_disksize=dict(type='str', aliases=['vm_disksize']),",
            "            instance_cpus=dict(type='str', default=1, aliases=['vmcpus']),",
            "            instance_nic=dict(type='str', aliases=['vmnic']),",
            "            instance_network=dict(type='str', default='rhevm', aliases=['vmnetwork']),",
            "            instance_mem=dict(type='str', aliases=['vmmem']),",
            "            instance_type=dict(type='str', default='server', aliases=['vmtype'], choices=['desktop', 'server', 'high_performance']),",
            "            disk_alloc=dict(type='str', default='thin', choices=['preallocated', 'thin']),",
            "            disk_int=dict(type='str', default='virtio', choices=['ide', 'virtio']),",
            "            instance_os=dict(type='str', aliases=['vmos']),",
            "            instance_cores=dict(type='str', default=1, aliases=['vmcores']),",
            "            instance_hostname=dict(type='str', aliases=['hostname']),",
            "            instance_ip=dict(type='str', aliases=['ip']),",
            "            instance_netmask=dict(type='str', aliases=['netmask']),",
            "            instance_gateway=dict(type='str', aliases=['gateway']),",
            "            instance_domain=dict(type='str', aliases=['domain']),",
            "            instance_dns=dict(type='str', aliases=['dns']),",
            "            instance_rootpw=dict(type='str', aliases=['rootpw'], no_log=True),",
            "            instance_key=dict(type='str', aliases=['key']),",
            "            sdomain=dict(type='str'),",
            "            region=dict(type='str'),",
            "        ),",
            "    )",
            "",
            "    if not HAS_OVIRTSDK:",
            "        module.fail_json(msg='ovirtsdk required for this module')",
            "",
            "    state = module.params['state']",
            "    user = module.params['user']",
            "    url = module.params['url']",
            "    vmname = module.params['instance_name']",
            "    password = module.params['password']",
            "    image = module.params['image']  # name of the image to deploy",
            "    resource_type = module.params['resource_type']  # template or from scratch",
            "    zone = module.params['zone']  # oVirt cluster",
            "    vmdisk_size = module.params['instance_disksize']  # disksize",
            "    vmcpus = module.params['instance_cpus']  # number of cpu",
            "    vmnic = module.params['instance_nic']  # network interface",
            "    vmnetwork = module.params['instance_network']  # logical network",
            "    vmmem = module.params['instance_mem']  # mem size",
            "    vmdisk_alloc = module.params['disk_alloc']  # thin, preallocated",
            "    vmdisk_int = module.params['disk_int']  # disk interface virtio or ide",
            "    vmos = module.params['instance_os']  # Operating System",
            "    vmtype = module.params['instance_type']  # server, desktop or high_performance",
            "    vmcores = module.params['instance_cores']  # number of cores",
            "    sdomain = module.params['sdomain']  # storage domain to store disk on",
            "    region = module.params['region']  # oVirt Datacenter",
            "    hostname = module.params['instance_hostname']",
            "    ip = module.params['instance_ip']",
            "    netmask = module.params['instance_netmask']",
            "    gateway = module.params['instance_gateway']",
            "    domain = module.params['instance_domain']",
            "    dns = module.params['instance_dns']",
            "    rootpw = module.params['instance_rootpw']",
            "    key = module.params['instance_key']",
            "    # initialize connection",
            "    try:",
            "        c = conn(url + \"/api\", user, password)",
            "    except Exception as e:",
            "        module.fail_json(msg='%s' % e)",
            "",
            "    if state == 'present':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            if resource_type == 'template':",
            "                try:",
            "                    create_vm_template(c, vmname, image, zone)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from template %s\" % (vmname, image))",
            "            elif resource_type == 'new':",
            "                # FIXME: refactor, use keyword args.",
            "                try:",
            "                    create_vm(c, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from scratch\" % vmname)",
            "            else:",
            "                module.exit_json(changed=False, msg=\"You did not specify a resource type\")",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s already exists\" % vmname)",
            "",
            "    if state == 'started':",
            "        if vm_status(c, vmname) == 'up':",
            "            module.exit_json(changed=False, msg=\"VM %s is already running\" % vmname)",
            "        else:",
            "            # vm_start(c, vmname)",
            "            vm_start(c, vmname, hostname, ip, netmask, gateway, domain, dns, rootpw, key)",
            "            module.exit_json(changed=True, msg=\"VM %s started\" % vmname)",
            "",
            "    if state == 'shutdown':",
            "        if vm_status(c, vmname) == 'down':",
            "            module.exit_json(changed=False, msg=\"VM %s is already shutdown\" % vmname)",
            "        else:",
            "            vm_stop(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is shutting down\" % vmname)",
            "",
            "    if state == 'restart':",
            "        if vm_status(c, vmname) == 'up':",
            "            vm_restart(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is restarted\" % vmname)",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s is not running\" % vmname)",
            "",
            "    if state == 'absent':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            module.exit_json(changed=False, msg=\"VM %s does not exist\" % vmname)",
            "        else:",
            "            vm_remove(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s removed\" % vmname)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "383": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_firewall_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 504,
                "afterPatchRowNumber": 504,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 505,
                "afterPatchRowNumber": 505,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 506,
                "afterPatchRowNumber": 506,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 507,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 507,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 508,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 508,
                "afterPatchRowNumber": 509,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 509,
                "afterPatchRowNumber": 510,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 510,
                "afterPatchRowNumber": 511,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_firewall_policy",
            "short_description: Configure 1&1 firewall policy.",
            "description:",
            "     - Create, remove, reconfigure, update firewall policies.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a firewall policy state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environment variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Firewall policy name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  firewall_policy:",
            "    description:",
            "      - The identifier (id or name) of the firewall policy used with update state.",
            "    required: true",
            "  rules:",
            "    description:",
            "      - A list of rules that will be set for the firewall policy.",
            "        Each rule must contain protocol parameter, in addition to three optional parameters",
            "        (port_from, port_to, and source)",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a firewall policy.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a firewall policy. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing firewall policy.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing firewall policy. Used in combination with update state.",
            "    required: false",
            "  description:",
            "    description:",
            "      - Firewall policy description. maxLength=256",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible-firewall-policy",
            "    description: Testing creation of firewall policies with ansible",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 80",
            "       port_to: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible-firewall-policy",
            "",
            "# Update a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    firewall_policy: ansible-firewall-policy",
            "    name: ansible-firewall-policy-updated",
            "    description: Testing creation of firewall policies with ansible - updated",
            "",
            "# Add server to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    add_server_ips:",
            "     - server_identifier (id or name)",
            "     - server_identifier #2 (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's IP id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    description: Adding rules to an existing firewall policy",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 70",
            "       port_to: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_from: 60",
            "       port_to: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "'''",
            "",
            "RETURN = '''",
            "firewall_policy:",
            "    description: Information about the firewall policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_firewall_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, firewall_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in server_ids:",
            "            server = get_server(oneandone_conn, _server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.attach_server_firewall_policy(",
            "            firewall_id=firewall_id,",
            "            server_ips=attach_servers)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_server(module, oneandone_conn, firewall_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            firewall_server = oneandone_conn.get_firewall_server(",
            "                firewall_id=firewall_id,",
            "                server_ip_id=server_ip_id)",
            "            if firewall_server:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_server(",
            "            firewall_id=firewall_id,",
            "            server_ip_id=server_ip_id)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _add_firewall_rules(module, oneandone_conn, firewall_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        if module.check_mode:",
            "            firewall_policy_id = get_firewall_policy(oneandone_conn, firewall_id)",
            "            if (firewall_rules and firewall_policy_id):",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.add_firewall_policy_rule(",
            "            firewall_id=firewall_id,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_rule(module, oneandone_conn, firewall_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_firewall_policy_rule(",
            "                firewall_id=firewall_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_rule(",
            "            firewall_id=firewall_id,",
            "            rule_id=rule_id",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a firewall policy based on input arguments.",
            "    Firewall rules and server ips can be added/removed to/from",
            "    firewall policy. Firewall policy name and description can be",
            "    updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        firewall_policy_id = module.params.get('firewall_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        add_server_ips = module.params.get('add_server_ips')",
            "        remove_server_ips = module.params.get('remove_server_ips')",
            "        add_rules = module.params.get('add_rules')",
            "        remove_rules = module.params.get('remove_rules')",
            "",
            "        changed = False",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy_id, True)",
            "        if firewall_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        if name or description:",
            "            _check_mode(module, True)",
            "            firewall_policy = oneandone_conn.modify_firewall(",
            "                firewall_id=firewall_policy['id'],",
            "                name=name,",
            "                description=description)",
            "            changed = True",
            "",
            "        if add_server_ips:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_server_ips(module,",
            "                                                    oneandone_conn,",
            "                                                    firewall_policy['id'],",
            "                                                    add_server_ips))",
            "",
            "            firewall_policy = _add_server_ips(module, oneandone_conn, firewall_policy['id'], add_server_ips)",
            "            changed = True",
            "",
            "        if remove_server_ips:",
            "            chk_changed = False",
            "            for server_ip_id in remove_server_ips:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_server(module,",
            "                                                           oneandone_conn,",
            "                                                           firewall_policy['id'],",
            "                                                           server_ip_id)",
            "",
            "                _remove_firewall_server(module,",
            "                                        oneandone_conn,",
            "                                        firewall_policy['id'],",
            "                                        server_ip_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_rules:",
            "            firewall_policy = _add_firewall_rules(module,",
            "                                                  oneandone_conn,",
            "                                                  firewall_policy['id'],",
            "                                                  add_rules)",
            "            _check_mode(module, firewall_policy)",
            "            changed = True",
            "",
            "        if remove_rules:",
            "            chk_changed = False",
            "            for rule_id in remove_rules:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_rule(module,",
            "                                                         oneandone_conn,",
            "                                                         firewall_policy['id'],",
            "                                                         rule_id)",
            "",
            "                _remove_firewall_rule(module,",
            "                                      oneandone_conn,",
            "                                      firewall_policy['id'],",
            "                                      rule_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def create_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        firewall_policy_obj = oneandone.client.FirewallPolicy(",
            "            name=name,",
            "            description=description",
            "        )",
            "",
            "        _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.create_firewall_policy(",
            "            firewall_policy=firewall_policy_obj,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.firewall_policy,",
            "                firewall_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)  # refresh",
            "        changed = True if firewall_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def remove_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        fp_id = module.params.get('name')",
            "        firewall_policy_id = get_firewall_policy(oneandone_conn, fp_id)",
            "        if module.check_mode:",
            "            if firewall_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.delete_firewall(firewall_policy_id)",
            "",
            "        changed = True if firewall_policy else False",
            "",
            "        return (changed, {",
            "            'id': firewall_policy['id'],",
            "            'name': firewall_policy['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            firewall_policy=dict(type='str'),",
            "            description=dict(type='str'),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='The \"auth_token\" parameter or ' +",
            "            'ONEANDONE_AUTH_TOKEN environment variable is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = remove_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'update':",
            "        if not module.params.get('firewall_policy'):",
            "            module.fail_json(",
            "                msg=\"'firewall_policy' parameter is required to update a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = update_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new firewall policies.\" % param)",
            "        try:",
            "            (changed, firewall_policy) = create_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, firewall_policy=firewall_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_firewall_policy",
            "short_description: Configure 1&1 firewall policy.",
            "description:",
            "     - Create, remove, reconfigure, update firewall policies.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a firewall policy state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environment variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Firewall policy name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  firewall_policy:",
            "    description:",
            "      - The identifier (id or name) of the firewall policy used with update state.",
            "    required: true",
            "  rules:",
            "    description:",
            "      - A list of rules that will be set for the firewall policy.",
            "        Each rule must contain protocol parameter, in addition to three optional parameters",
            "        (port_from, port_to, and source)",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a firewall policy.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a firewall policy. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing firewall policy.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing firewall policy. Used in combination with update state.",
            "    required: false",
            "  description:",
            "    description:",
            "      - Firewall policy description. maxLength=256",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible-firewall-policy",
            "    description: Testing creation of firewall policies with ansible",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 80",
            "       port_to: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible-firewall-policy",
            "",
            "# Update a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    firewall_policy: ansible-firewall-policy",
            "    name: ansible-firewall-policy-updated",
            "    description: Testing creation of firewall policies with ansible - updated",
            "",
            "# Add server to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    add_server_ips:",
            "     - server_identifier (id or name)",
            "     - server_identifier #2 (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's IP id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    description: Adding rules to an existing firewall policy",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 70",
            "       port_to: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_from: 60",
            "       port_to: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "'''",
            "",
            "RETURN = '''",
            "firewall_policy:",
            "    description: Information about the firewall policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_firewall_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, firewall_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in server_ids:",
            "            server = get_server(oneandone_conn, _server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.attach_server_firewall_policy(",
            "            firewall_id=firewall_id,",
            "            server_ips=attach_servers)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_server(module, oneandone_conn, firewall_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            firewall_server = oneandone_conn.get_firewall_server(",
            "                firewall_id=firewall_id,",
            "                server_ip_id=server_ip_id)",
            "            if firewall_server:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_server(",
            "            firewall_id=firewall_id,",
            "            server_ip_id=server_ip_id)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _add_firewall_rules(module, oneandone_conn, firewall_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        if module.check_mode:",
            "            firewall_policy_id = get_firewall_policy(oneandone_conn, firewall_id)",
            "            if (firewall_rules and firewall_policy_id):",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.add_firewall_policy_rule(",
            "            firewall_id=firewall_id,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_rule(module, oneandone_conn, firewall_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_firewall_policy_rule(",
            "                firewall_id=firewall_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_rule(",
            "            firewall_id=firewall_id,",
            "            rule_id=rule_id",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a firewall policy based on input arguments.",
            "    Firewall rules and server ips can be added/removed to/from",
            "    firewall policy. Firewall policy name and description can be",
            "    updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        firewall_policy_id = module.params.get('firewall_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        add_server_ips = module.params.get('add_server_ips')",
            "        remove_server_ips = module.params.get('remove_server_ips')",
            "        add_rules = module.params.get('add_rules')",
            "        remove_rules = module.params.get('remove_rules')",
            "",
            "        changed = False",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy_id, True)",
            "        if firewall_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        if name or description:",
            "            _check_mode(module, True)",
            "            firewall_policy = oneandone_conn.modify_firewall(",
            "                firewall_id=firewall_policy['id'],",
            "                name=name,",
            "                description=description)",
            "            changed = True",
            "",
            "        if add_server_ips:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_server_ips(module,",
            "                                                    oneandone_conn,",
            "                                                    firewall_policy['id'],",
            "                                                    add_server_ips))",
            "",
            "            firewall_policy = _add_server_ips(module, oneandone_conn, firewall_policy['id'], add_server_ips)",
            "            changed = True",
            "",
            "        if remove_server_ips:",
            "            chk_changed = False",
            "            for server_ip_id in remove_server_ips:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_server(module,",
            "                                                           oneandone_conn,",
            "                                                           firewall_policy['id'],",
            "                                                           server_ip_id)",
            "",
            "                _remove_firewall_server(module,",
            "                                        oneandone_conn,",
            "                                        firewall_policy['id'],",
            "                                        server_ip_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_rules:",
            "            firewall_policy = _add_firewall_rules(module,",
            "                                                  oneandone_conn,",
            "                                                  firewall_policy['id'],",
            "                                                  add_rules)",
            "            _check_mode(module, firewall_policy)",
            "            changed = True",
            "",
            "        if remove_rules:",
            "            chk_changed = False",
            "            for rule_id in remove_rules:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_rule(module,",
            "                                                         oneandone_conn,",
            "                                                         firewall_policy['id'],",
            "                                                         rule_id)",
            "",
            "                _remove_firewall_rule(module,",
            "                                      oneandone_conn,",
            "                                      firewall_policy['id'],",
            "                                      rule_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def create_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        firewall_policy_obj = oneandone.client.FirewallPolicy(",
            "            name=name,",
            "            description=description",
            "        )",
            "",
            "        _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.create_firewall_policy(",
            "            firewall_policy=firewall_policy_obj,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.firewall_policy,",
            "                firewall_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)  # refresh",
            "        changed = True if firewall_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def remove_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        fp_id = module.params.get('name')",
            "        firewall_policy_id = get_firewall_policy(oneandone_conn, fp_id)",
            "        if module.check_mode:",
            "            if firewall_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.delete_firewall(firewall_policy_id)",
            "",
            "        changed = True if firewall_policy else False",
            "",
            "        return (changed, {",
            "            'id': firewall_policy['id'],",
            "            'name': firewall_policy['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            firewall_policy=dict(type='str'),",
            "            description=dict(type='str'),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='The \"auth_token\" parameter or ' +",
            "            'ONEANDONE_AUTH_TOKEN environment variable is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = remove_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'update':",
            "        if not module.params.get('firewall_policy'):",
            "            module.fail_json(",
            "                msg=\"'firewall_policy' parameter is required to update a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = update_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new firewall policies.\" % param)",
            "        try:",
            "            (changed, firewall_policy) = create_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, firewall_policy=firewall_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "507": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_load_balancer.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 595,
                "afterPatchRowNumber": 595,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 596,
                "afterPatchRowNumber": 596,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 597,
                "afterPatchRowNumber": 597,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 598,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 598,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 599,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 599,
                "afterPatchRowNumber": 600,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 600,
                "afterPatchRowNumber": 601,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 601,
                "afterPatchRowNumber": 602,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_load_balancer",
            "short_description: Configure 1&1 load balancer.",
            "description:",
            "     - Create, remove, update load balancers.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a load balancer state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  load_balancer:",
            "    description:",
            "      - The identifier (id or name) of the load balancer used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Load balancer name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  health_check_test:",
            "    description:",
            "      - Type of the health check. At the moment, HTTP is not allowed.",
            "    choices: [ \"NONE\", \"TCP\", \"HTTP\", \"ICMP\" ]",
            "    required: true",
            "  health_check_interval:",
            "    description:",
            "      - Health check period in seconds. minimum=5, maximum=300, multipleOf=1",
            "    required: true",
            "  health_check_path:",
            "    description:",
            "      - Url to call for checking. Required for HTTP health check. maxLength=1000",
            "    required: false",
            "  health_check_parse:",
            "    description:",
            "      - Regular expression to check. Required for HTTP health check. maxLength=64",
            "    required: false",
            "  persistence:",
            "    description:",
            "      - Persistence.",
            "    required: true",
            "    type: bool",
            "  persistence_time:",
            "    description:",
            "      - Persistence time in seconds. Required if persistence is enabled. minimum=30, maximum=1200, multipleOf=1",
            "    required: true",
            "  method:",
            "    description:",
            "      - Balancing procedure.",
            "    choices: [ \"ROUND_ROBIN\", \"LEAST_CONNECTIONS\" ]",
            "    required: true",
            "  datacenter:",
            "    description:",
            "      - ID or country code of the datacenter where the load balancer will be created.",
            "    default: US",
            "    choices: [ \"US\", \"ES\", \"DE\", \"GB\" ]",
            "    required: false",
            "  rules:",
            "    description:",
            "      - A list of rule objects that will be set for the load balancer. Each rule must contain protocol,",
            "        port_balancer, and port_server parameters, in addition to source parameter, which is optional.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Description of the load balancer. maxLength=256",
            "    required: false",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a load balancer.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a load balancer. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing load balancer.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing load balancer. Used in combination with update state.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    description: Testing creation of load balancer with ansible",
            "    health_check_test: TCP",
            "    health_check_interval: 40",
            "    persistence: true",
            "    persistence_time: 1200",
            "    method: ROUND_ROBIN",
            "    datacenter: US",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 80",
            "       port_server: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: absent",
            "",
            "# Update a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer",
            "    name: ansible load balancer updated",
            "    description: Testing the update of a load balancer with ansible",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add server to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding server to a load balancer with ansible",
            "    add_server_ips:",
            "     - server identifier (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Removing server from a load balancer with ansible",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's ip id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 70",
            "       port_server: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 60",
            "       port_server: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "load_balancer:",
            "    description: Information about the load balancer that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Balancer\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_load_balancer,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "HEALTH_CHECK_TESTS = ['NONE', 'TCP', 'HTTP', 'ICMP']",
            "METHODS = ['ROUND_ROBIN', 'LEAST_CONNECTIONS']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, load_balancer_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a load balancer.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for server_id in server_ids:",
            "            server = get_server(oneandone_conn, server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.attach_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ips=attach_servers)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_server(module, oneandone_conn, load_balancer_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a load balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            lb_server = oneandone_conn.get_load_balancer_server(",
            "                load_balancer_id=load_balancer_id,",
            "                server_ip_id=server_ip_id)",
            "            if lb_server:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ip_id=server_ip_id)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_load_balancer_rules(module, oneandone_conn, load_balancer_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        load_balancer_rules = []",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        if module.check_mode:",
            "            lb_id = get_load_balancer(oneandone_conn, load_balancer_id)",
            "            if (load_balancer_rules and lb_id):",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.add_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_rule(module, oneandone_conn, load_balancer_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_load_balancer_rule(",
            "                load_balancer_id=load_balancer_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            rule_id=rule_id",
            "        )",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a load_balancer based on input arguments.",
            "    Load balancer rules and server ips can be added/removed to/from",
            "    load balancer. Load balancer name, description, health_check_test,",
            "    health_check_interval, persistence, persistence_time, and method",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    load_balancer_id = module.params.get('load_balancer')",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    health_check_test = module.params.get('health_check_test')",
            "    health_check_interval = module.params.get('health_check_interval')",
            "    health_check_path = module.params.get('health_check_path')",
            "    health_check_parse = module.params.get('health_check_parse')",
            "    persistence = module.params.get('persistence')",
            "    persistence_time = module.params.get('persistence_time')",
            "    method = module.params.get('method')",
            "    add_server_ips = module.params.get('add_server_ips')",
            "    remove_server_ips = module.params.get('remove_server_ips')",
            "    add_rules = module.params.get('add_rules')",
            "    remove_rules = module.params.get('remove_rules')",
            "",
            "    changed = False",
            "",
            "    load_balancer = get_load_balancer(oneandone_conn, load_balancer_id, True)",
            "    if load_balancer is None:",
            "        _check_mode(module, False)",
            "",
            "    if (name or description or health_check_test or health_check_interval or health_check_path or",
            "            health_check_parse or persistence or persistence_time or method):",
            "        _check_mode(module, True)",
            "        load_balancer = oneandone_conn.modify_load_balancer(",
            "            load_balancer_id=load_balancer['id'],",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method)",
            "        changed = True",
            "",
            "    if add_server_ips:",
            "        if module.check_mode:",
            "            _check_mode(module, _add_server_ips(module,",
            "                                                oneandone_conn,",
            "                                                load_balancer['id'],",
            "                                                add_server_ips))",
            "",
            "        load_balancer = _add_server_ips(module, oneandone_conn, load_balancer['id'], add_server_ips)",
            "        changed = True",
            "",
            "    if remove_server_ips:",
            "        chk_changed = False",
            "        for server_ip_id in remove_server_ips:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_server(module,",
            "                                                            oneandone_conn,",
            "                                                            load_balancer['id'],",
            "                                                            server_ip_id)",
            "",
            "            _remove_load_balancer_server(module,",
            "                                         oneandone_conn,",
            "                                         load_balancer['id'],",
            "                                         server_ip_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    if add_rules:",
            "        load_balancer = _add_load_balancer_rules(module,",
            "                                                 oneandone_conn,",
            "                                                 load_balancer['id'],",
            "                                                 add_rules)",
            "        _check_mode(module, load_balancer)",
            "        changed = True",
            "",
            "    if remove_rules:",
            "        chk_changed = False",
            "        for rule_id in remove_rules:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_rule(module,",
            "                                                          oneandone_conn,",
            "                                                          load_balancer['id'],",
            "                                                          rule_id)",
            "",
            "            _remove_load_balancer_rule(module,",
            "                                       oneandone_conn,",
            "                                       load_balancer['id'],",
            "                                       rule_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    try:",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        health_check_test = module.params.get('health_check_test')",
            "        health_check_interval = module.params.get('health_check_interval')",
            "        health_check_path = module.params.get('health_check_path')",
            "        health_check_parse = module.params.get('health_check_parse')",
            "        persistence = module.params.get('persistence')",
            "        persistence_time = module.params.get('persistence_time')",
            "        method = module.params.get('method')",
            "        datacenter = module.params.get('datacenter')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        load_balancer_rules = []",
            "",
            "        datacenter_id = None",
            "        if datacenter is not None:",
            "            datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "            if datacenter_id is None:",
            "                module.fail_json(",
            "                    msg='datacenter %s not found.' % datacenter)",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        _check_mode(module, True)",
            "        load_balancer_obj = oneandone.client.LoadBalancer(",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method,",
            "            datacenter_id=datacenter_id",
            "        )",
            "",
            "        load_balancer = oneandone_conn.create_load_balancer(",
            "            load_balancer=load_balancer_obj,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.load_balancer,",
            "                                                  load_balancer['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)  # refresh",
            "        changed = True if load_balancer else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        lb_id = module.params.get('name')",
            "        load_balancer_id = get_load_balancer(oneandone_conn, lb_id)",
            "        if module.check_mode:",
            "            if load_balancer_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        load_balancer = oneandone_conn.delete_load_balancer(load_balancer_id)",
            "",
            "        changed = True if load_balancer else False",
            "",
            "        return (changed, {",
            "            'id': load_balancer['id'],",
            "            'name': load_balancer['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            load_balancer=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            health_check_test=dict(",
            "                choices=HEALTH_CHECK_TESTS),",
            "            health_check_interval=dict(type='str'),",
            "            health_check_path=dict(type='str'),",
            "            health_check_parse=dict(type='str'),",
            "            persistence=dict(type='bool'),",
            "            persistence_time=dict(type='str'),",
            "            method=dict(",
            "                choices=METHODS),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = remove_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('load_balancer'):",
            "            module.fail_json(",
            "                msg=\"'load_balancer' parameter is required for updating a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = update_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'health_check_test', 'health_check_interval', 'persistence',",
            "                      'persistence_time', 'method', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new load balancers.\" % param)",
            "        try:",
            "            (changed, load_balancer) = create_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, load_balancer=load_balancer)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_load_balancer",
            "short_description: Configure 1&1 load balancer.",
            "description:",
            "     - Create, remove, update load balancers.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a load balancer state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  load_balancer:",
            "    description:",
            "      - The identifier (id or name) of the load balancer used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Load balancer name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  health_check_test:",
            "    description:",
            "      - Type of the health check. At the moment, HTTP is not allowed.",
            "    choices: [ \"NONE\", \"TCP\", \"HTTP\", \"ICMP\" ]",
            "    required: true",
            "  health_check_interval:",
            "    description:",
            "      - Health check period in seconds. minimum=5, maximum=300, multipleOf=1",
            "    required: true",
            "  health_check_path:",
            "    description:",
            "      - Url to call for checking. Required for HTTP health check. maxLength=1000",
            "    required: false",
            "  health_check_parse:",
            "    description:",
            "      - Regular expression to check. Required for HTTP health check. maxLength=64",
            "    required: false",
            "  persistence:",
            "    description:",
            "      - Persistence.",
            "    required: true",
            "    type: bool",
            "  persistence_time:",
            "    description:",
            "      - Persistence time in seconds. Required if persistence is enabled. minimum=30, maximum=1200, multipleOf=1",
            "    required: true",
            "  method:",
            "    description:",
            "      - Balancing procedure.",
            "    choices: [ \"ROUND_ROBIN\", \"LEAST_CONNECTIONS\" ]",
            "    required: true",
            "  datacenter:",
            "    description:",
            "      - ID or country code of the datacenter where the load balancer will be created.",
            "    default: US",
            "    choices: [ \"US\", \"ES\", \"DE\", \"GB\" ]",
            "    required: false",
            "  rules:",
            "    description:",
            "      - A list of rule objects that will be set for the load balancer. Each rule must contain protocol,",
            "        port_balancer, and port_server parameters, in addition to source parameter, which is optional.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Description of the load balancer. maxLength=256",
            "    required: false",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a load balancer.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a load balancer. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing load balancer.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing load balancer. Used in combination with update state.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    description: Testing creation of load balancer with ansible",
            "    health_check_test: TCP",
            "    health_check_interval: 40",
            "    persistence: true",
            "    persistence_time: 1200",
            "    method: ROUND_ROBIN",
            "    datacenter: US",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 80",
            "       port_server: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: absent",
            "",
            "# Update a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer",
            "    name: ansible load balancer updated",
            "    description: Testing the update of a load balancer with ansible",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add server to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding server to a load balancer with ansible",
            "    add_server_ips:",
            "     - server identifier (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Removing server from a load balancer with ansible",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's ip id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 70",
            "       port_server: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 60",
            "       port_server: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "load_balancer:",
            "    description: Information about the load balancer that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Balancer\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_load_balancer,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "HEALTH_CHECK_TESTS = ['NONE', 'TCP', 'HTTP', 'ICMP']",
            "METHODS = ['ROUND_ROBIN', 'LEAST_CONNECTIONS']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, load_balancer_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a load balancer.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for server_id in server_ids:",
            "            server = get_server(oneandone_conn, server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.attach_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ips=attach_servers)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_server(module, oneandone_conn, load_balancer_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a load balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            lb_server = oneandone_conn.get_load_balancer_server(",
            "                load_balancer_id=load_balancer_id,",
            "                server_ip_id=server_ip_id)",
            "            if lb_server:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ip_id=server_ip_id)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_load_balancer_rules(module, oneandone_conn, load_balancer_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        load_balancer_rules = []",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        if module.check_mode:",
            "            lb_id = get_load_balancer(oneandone_conn, load_balancer_id)",
            "            if (load_balancer_rules and lb_id):",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.add_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_rule(module, oneandone_conn, load_balancer_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_load_balancer_rule(",
            "                load_balancer_id=load_balancer_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            rule_id=rule_id",
            "        )",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a load_balancer based on input arguments.",
            "    Load balancer rules and server ips can be added/removed to/from",
            "    load balancer. Load balancer name, description, health_check_test,",
            "    health_check_interval, persistence, persistence_time, and method",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    load_balancer_id = module.params.get('load_balancer')",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    health_check_test = module.params.get('health_check_test')",
            "    health_check_interval = module.params.get('health_check_interval')",
            "    health_check_path = module.params.get('health_check_path')",
            "    health_check_parse = module.params.get('health_check_parse')",
            "    persistence = module.params.get('persistence')",
            "    persistence_time = module.params.get('persistence_time')",
            "    method = module.params.get('method')",
            "    add_server_ips = module.params.get('add_server_ips')",
            "    remove_server_ips = module.params.get('remove_server_ips')",
            "    add_rules = module.params.get('add_rules')",
            "    remove_rules = module.params.get('remove_rules')",
            "",
            "    changed = False",
            "",
            "    load_balancer = get_load_balancer(oneandone_conn, load_balancer_id, True)",
            "    if load_balancer is None:",
            "        _check_mode(module, False)",
            "",
            "    if (name or description or health_check_test or health_check_interval or health_check_path or",
            "            health_check_parse or persistence or persistence_time or method):",
            "        _check_mode(module, True)",
            "        load_balancer = oneandone_conn.modify_load_balancer(",
            "            load_balancer_id=load_balancer['id'],",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method)",
            "        changed = True",
            "",
            "    if add_server_ips:",
            "        if module.check_mode:",
            "            _check_mode(module, _add_server_ips(module,",
            "                                                oneandone_conn,",
            "                                                load_balancer['id'],",
            "                                                add_server_ips))",
            "",
            "        load_balancer = _add_server_ips(module, oneandone_conn, load_balancer['id'], add_server_ips)",
            "        changed = True",
            "",
            "    if remove_server_ips:",
            "        chk_changed = False",
            "        for server_ip_id in remove_server_ips:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_server(module,",
            "                                                            oneandone_conn,",
            "                                                            load_balancer['id'],",
            "                                                            server_ip_id)",
            "",
            "            _remove_load_balancer_server(module,",
            "                                         oneandone_conn,",
            "                                         load_balancer['id'],",
            "                                         server_ip_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    if add_rules:",
            "        load_balancer = _add_load_balancer_rules(module,",
            "                                                 oneandone_conn,",
            "                                                 load_balancer['id'],",
            "                                                 add_rules)",
            "        _check_mode(module, load_balancer)",
            "        changed = True",
            "",
            "    if remove_rules:",
            "        chk_changed = False",
            "        for rule_id in remove_rules:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_rule(module,",
            "                                                          oneandone_conn,",
            "                                                          load_balancer['id'],",
            "                                                          rule_id)",
            "",
            "            _remove_load_balancer_rule(module,",
            "                                       oneandone_conn,",
            "                                       load_balancer['id'],",
            "                                       rule_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    try:",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        health_check_test = module.params.get('health_check_test')",
            "        health_check_interval = module.params.get('health_check_interval')",
            "        health_check_path = module.params.get('health_check_path')",
            "        health_check_parse = module.params.get('health_check_parse')",
            "        persistence = module.params.get('persistence')",
            "        persistence_time = module.params.get('persistence_time')",
            "        method = module.params.get('method')",
            "        datacenter = module.params.get('datacenter')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        load_balancer_rules = []",
            "",
            "        datacenter_id = None",
            "        if datacenter is not None:",
            "            datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "            if datacenter_id is None:",
            "                module.fail_json(",
            "                    msg='datacenter %s not found.' % datacenter)",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        _check_mode(module, True)",
            "        load_balancer_obj = oneandone.client.LoadBalancer(",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method,",
            "            datacenter_id=datacenter_id",
            "        )",
            "",
            "        load_balancer = oneandone_conn.create_load_balancer(",
            "            load_balancer=load_balancer_obj,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.load_balancer,",
            "                                                  load_balancer['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)  # refresh",
            "        changed = True if load_balancer else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        lb_id = module.params.get('name')",
            "        load_balancer_id = get_load_balancer(oneandone_conn, lb_id)",
            "        if module.check_mode:",
            "            if load_balancer_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        load_balancer = oneandone_conn.delete_load_balancer(load_balancer_id)",
            "",
            "        changed = True if load_balancer else False",
            "",
            "        return (changed, {",
            "            'id': load_balancer['id'],",
            "            'name': load_balancer['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            load_balancer=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            health_check_test=dict(",
            "                choices=HEALTH_CHECK_TESTS),",
            "            health_check_interval=dict(type='str'),",
            "            health_check_path=dict(type='str'),",
            "            health_check_parse=dict(type='str'),",
            "            persistence=dict(type='bool'),",
            "            persistence_time=dict(type='str'),",
            "            method=dict(",
            "                choices=METHODS),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = remove_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('load_balancer'):",
            "            module.fail_json(",
            "                msg=\"'load_balancer' parameter is required for updating a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = update_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'health_check_test', 'health_check_interval', 'persistence',",
            "                      'persistence_time', 'method', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new load balancers.\" % param)",
            "        try:",
            "            (changed, load_balancer) = create_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, load_balancer=load_balancer)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "598": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_monitoring_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 950,
                "afterPatchRowNumber": 950,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 951,
                "afterPatchRowNumber": 951,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 952,
                "afterPatchRowNumber": 952,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 953,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 953,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 954,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 954,
                "afterPatchRowNumber": 955,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 955,
                "afterPatchRowNumber": 956,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 956,
                "afterPatchRowNumber": 957,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_monitoring_policy",
            "short_description: Configure 1&1 monitoring policy.",
            "description:",
            "     - Create, remove, update monitoring policies",
            "       (and add/remove ports, processes, and servers).",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a monitoring policy's state to create, remove, update.",
            "    required: false",
            "    default: present",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Monitoring policy name used with present state. Used as identifier (id or name) when used with absent state. maxLength=128",
            "    required: true",
            "  monitoring_policy:",
            "    description:",
            "      - The identifier (id or name) of the monitoring policy used with update state.",
            "    required: true",
            "  agent:",
            "    description:",
            "      - Set true for using agent.",
            "    required: true",
            "  email:",
            "    description:",
            "      - User's email. maxLength=128",
            "    required: true",
            "  description:",
            "    description:",
            "      - Monitoring policy description. maxLength=256",
            "    required: false",
            "  thresholds:",
            "    description:",
            "      - Monitoring policy thresholds. Each of the suboptions have warning and critical,",
            "        which both have alert and value suboptions. Warning is used to set limits for",
            "        warning alerts, critical is used to set critical alerts. alert enables alert,",
            "        and value is used to advise when the value is exceeded.",
            "    required: true",
            "    suboptions:",
            "      cpu:",
            "        description:",
            "          - Consumption limits of CPU.",
            "        required: true",
            "      ram:",
            "        description:",
            "          - Consumption limits of RAM.",
            "        required: true",
            "      disk:",
            "        description:",
            "          - Consumption limits of hard disk.",
            "        required: true",
            "      internal_ping:",
            "        description:",
            "          - Response limits of internal ping.",
            "        required: true",
            "      transfer:",
            "        description:",
            "          - Consumption limits for transfer.",
            "        required: true",
            "  ports:",
            "    description:",
            "      - Array of ports that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      protocol:",
            "        description:",
            "          - Internet protocol.",
            "        choices: [ \"TCP\", \"UDP\" ]",
            "        required: true",
            "      port:",
            "        description:",
            "          - Port number. minimum=1, maximum=65535",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RESPONDING\", \"NOT_RESPONDING\" ]",
            "        required: true",
            "      email_notification:",
            "        description:",
            "          - Set true for sending e-mail notifications.",
            "        required: true",
            "  processes:",
            "    description:",
            "      - Array of processes that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      process:",
            "        description:",
            "          - Name of the process. maxLength=50",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RUNNING\", \"NOT_RUNNING\" ]",
            "        required: true",
            "  add_ports:",
            "    description:",
            "      - Ports to add to the monitoring policy.",
            "    required: false",
            "  add_processes:",
            "    description:",
            "      - Processes to add to the monitoring policy.",
            "    required: false",
            "  add_servers:",
            "    description:",
            "      - Servers to add to the monitoring policy.",
            "    required: false",
            "  remove_ports:",
            "    description:",
            "      - Ports to remove from the monitoring policy.",
            "    required: false",
            "  remove_processes:",
            "    description:",
            "      - Processes to remove from the monitoring policy.",
            "    required: false",
            "  remove_servers:",
            "    description:",
            "      - Servers to remove from the monitoring policy.",
            "    required: false",
            "  update_ports:",
            "    description:",
            "      - Ports to be updated on the monitoring policy.",
            "    required: false",
            "  update_processes:",
            "    description:",
            "      - Processes to be updated on the monitoring policy.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible monitoring policy",
            "    description: Testing creation of a monitoring policy with ansible",
            "    email: your@emailaddress.com",
            "    agent: true",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 92",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 50",
            "           alert: false",
            "         critical:",
            "           value: 100",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 1000",
            "           alert: false",
            "         critical:",
            "           value: 2000",
            "           alert: false",
            "    ports:",
            "     -",
            "       protocol: TCP",
            "       port: 22",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    processes:",
            "     -",
            "       process: test",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible monitoring policy",
            "",
            "# Update a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy",
            "    name: ansible monitoring policy updated",
            "    description: Testing creation of a monitoring policy with ansible updated",
            "    email: another@emailaddress.com",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 60",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 900",
            "           alert: false",
            "         critical:",
            "           value: 1900",
            "           alert: false",
            "    wait: true",
            "    state: update",
            "",
            "# Add a port to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_ports:",
            "     -",
            "       protocol: TCP",
            "       port: 33",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing ports of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_ports:",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 34",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 23",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a port from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_ports:",
            "     - port_id",
            "    state: update",
            "",
            "# Add a process to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_processes:",
            "     -",
            "       process: test_2",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing processes of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_processes:",
            "     -",
            "       id: process_id",
            "       process: test_1",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "     -",
            "       id: process_id",
            "       process: test_3",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a process from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_processes:",
            "     - process_id",
            "    wait: true",
            "    state: update",
            "",
            "# Add server to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_servers:",
            "     - server id or name",
            "    wait: true",
            "    state: update",
            "",
            "# Remove server from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_servers:",
            "     - server01",
            "    wait: true",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "monitoring_policy:",
            "    description: Information about the monitoring policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_monitoring_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_ports(module, oneandone_conn, monitoring_policy_id, ports):",
            "    \"\"\"",
            "    Adds new ports to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_ports = []",
            "",
            "        for _port in ports:",
            "            monitoring_policy_port = oneandone.client.Port(",
            "                protocol=_port['protocol'],",
            "                port=_port['port'],",
            "                alert_if=_port['alert_if'],",
            "                email_notification=_port['email_notification']",
            "            )",
            "            monitoring_policy_ports.append(monitoring_policy_port)",
            "",
            "        if module.check_mode:",
            "            if monitoring_policy_ports:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            ports=monitoring_policy_ports)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_port(module, oneandone_conn, monitoring_policy_id, port_id):",
            "    \"\"\"",
            "    Removes a port from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if monitoring_policy:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_port(module, oneandone_conn, monitoring_policy_id, port_id, port):",
            "    \"\"\"",
            "    Modifies a monitoring policy port.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_port = oneandone_conn.get_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if cm_port:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_port = oneandone.client.Port(",
            "            protocol=port['protocol'],",
            "            port=port['port'],",
            "            alert_if=port['alert_if'],",
            "            email_notification=port['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id,",
            "            port=monitoring_policy_port)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_processes(module, oneandone_conn, monitoring_policy_id, processes):",
            "    \"\"\"",
            "    Adds new processes to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_processes = []",
            "",
            "        for _process in processes:",
            "            monitoring_policy_process = oneandone.client.Process(",
            "                process=_process['process'],",
            "                alert_if=_process['alert_if'],",
            "                email_notification=_process['email_notification']",
            "            )",
            "            monitoring_policy_processes.append(monitoring_policy_process)",
            "",
            "        if module.check_mode:",
            "            mp_id = get_monitoring_policy(oneandone_conn, monitoring_policy_id)",
            "            if (monitoring_policy_processes and mp_id):",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            processes=monitoring_policy_processes)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_process(module, oneandone_conn, monitoring_policy_id, process_id):",
            "    \"\"\"",
            "    Removes a process from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id",
            "            )",
            "            if process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_process(module, oneandone_conn, monitoring_policy_id, process_id, process):",
            "    \"\"\"",
            "    Modifies a monitoring policy process.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id)",
            "            if cm_process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_process = oneandone.client.Process(",
            "            process=process['process'],",
            "            alert_if=process['alert_if'],",
            "            email_notification=process['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id,",
            "            process=monitoring_policy_process)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _attach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, servers):",
            "    \"\"\"",
            "    Attaches servers to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in servers:",
            "            server_id = get_server(oneandone_conn, _server_id)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server_id",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.attach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            servers=attach_servers)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _detach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, server_id):",
            "    \"\"\"",
            "    Detaches a server from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            mp_server = oneandone_conn.get_monitoring_policy_server(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                server_id=server_id)",
            "            if mp_server:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.detach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            server_id=server_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a monitoring_policy based on input arguments.",
            "    Monitoring policy ports, processes and servers can be added/removed to/from",
            "    a monitoring policy. Monitoring policy name, description, email,",
            "    thresholds for cpu, ram, disk, transfer and internal_ping",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_id = module.params.get('monitoring_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        thresholds = module.params.get('thresholds')",
            "        add_ports = module.params.get('add_ports')",
            "        update_ports = module.params.get('update_ports')",
            "        remove_ports = module.params.get('remove_ports')",
            "        add_processes = module.params.get('add_processes')",
            "        update_processes = module.params.get('update_processes')",
            "        remove_processes = module.params.get('remove_processes')",
            "        add_servers = module.params.get('add_servers')",
            "        remove_servers = module.params.get('remove_servers')",
            "",
            "        changed = False",
            "",
            "        monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy_id, True)",
            "        if monitoring_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(",
            "            name=name,",
            "            description=description,",
            "            email=email",
            "        )",
            "",
            "        _thresholds = None",
            "",
            "        if thresholds:",
            "            threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "            _thresholds = []",
            "            for treshold in thresholds:",
            "                key = treshold.keys()[0]",
            "                if key in threshold_entities:",
            "                    _threshold = oneandone.client.Threshold(",
            "                        entity=key,",
            "                        warning_value=treshold[key]['warning']['value'],",
            "                        warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                        critical_value=treshold[key]['critical']['value'],",
            "                        critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                    _thresholds.append(_threshold)",
            "",
            "        if name or description or email or thresholds:",
            "            _check_mode(module, True)",
            "            monitoring_policy = oneandone_conn.modify_monitoring_policy(",
            "                monitoring_policy_id=monitoring_policy['id'],",
            "                monitoring_policy=_monitoring_policy,",
            "                thresholds=_thresholds)",
            "            changed = True",
            "",
            "        if add_ports:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_ports(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_ports))",
            "",
            "            monitoring_policy = _add_ports(module, oneandone_conn, monitoring_policy['id'], add_ports)",
            "            changed = True",
            "",
            "        if update_ports:",
            "            chk_changed = False",
            "            for update_port in update_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_port(module,",
            "                                                oneandone_conn,",
            "                                                monitoring_policy['id'],",
            "                                                update_port['id'],",
            "                                                update_port)",
            "",
            "                _modify_port(module,",
            "                             oneandone_conn,",
            "                             monitoring_policy['id'],",
            "                             update_port['id'],",
            "                             update_port)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_ports:",
            "            chk_changed = False",
            "            for port_id in remove_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_port(module,",
            "                                                                  oneandone_conn,",
            "                                                                  monitoring_policy['id'],",
            "                                                                  port_id)",
            "",
            "                _delete_monitoring_policy_port(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               port_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_processes:",
            "            monitoring_policy = _add_processes(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_processes)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if update_processes:",
            "            chk_changed = False",
            "            for update_process in update_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_process(module,",
            "                                                   oneandone_conn,",
            "                                                   monitoring_policy['id'],",
            "                                                   update_process['id'],",
            "                                                   update_process)",
            "",
            "                _modify_process(module,",
            "                                oneandone_conn,",
            "                                monitoring_policy['id'],",
            "                                update_process['id'],",
            "                                update_process)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_processes:",
            "            chk_changed = False",
            "            for process_id in remove_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_process(module,",
            "                                                                     oneandone_conn,",
            "                                                                     monitoring_policy['id'],",
            "                                                                     process_id)",
            "",
            "                _delete_monitoring_policy_process(module,",
            "                                                  oneandone_conn,",
            "                                                  monitoring_policy['id'],",
            "                                                  process_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_servers:",
            "            monitoring_policy = _attach_monitoring_policy_server(module,",
            "                                                                 oneandone_conn,",
            "                                                                 monitoring_policy['id'],",
            "                                                                 add_servers)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if remove_servers:",
            "            chk_changed = False",
            "            for _server_id in remove_servers:",
            "                server_id = get_server(oneandone_conn, _server_id)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _detach_monitoring_policy_server(module,",
            "                                                                    oneandone_conn,",
            "                                                                    monitoring_policy['id'],",
            "                                                                    server_id)",
            "",
            "                _detach_monitoring_policy_server(module,",
            "                                                 oneandone_conn,",
            "                                                 monitoring_policy['id'],",
            "                                                 server_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Creates a new monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        agent = module.params.get('agent')",
            "        thresholds = module.params.get('thresholds')",
            "        ports = module.params.get('ports')",
            "        processes = module.params.get('processes')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(name,",
            "                                                               description,",
            "                                                               email,",
            "                                                               agent, )",
            "",
            "        _monitoring_policy.specs['agent'] = str(_monitoring_policy.specs['agent']).lower()",
            "",
            "        threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "        _thresholds = []",
            "        for treshold in thresholds:",
            "            key = treshold.keys()[0]",
            "            if key in threshold_entities:",
            "                _threshold = oneandone.client.Threshold(",
            "                    entity=key,",
            "                    warning_value=treshold[key]['warning']['value'],",
            "                    warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                    critical_value=treshold[key]['critical']['value'],",
            "                    critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                _thresholds.append(_threshold)",
            "",
            "        _ports = []",
            "        for port in ports:",
            "            _port = oneandone.client.Port(",
            "                protocol=port['protocol'],",
            "                port=port['port'],",
            "                alert_if=port['alert_if'],",
            "                email_notification=str(port['email_notification']).lower())",
            "            _ports.append(_port)",
            "",
            "        _processes = []",
            "        for process in processes:",
            "            _process = oneandone.client.Process(",
            "                process=process['process'],",
            "                alert_if=process['alert_if'],",
            "                email_notification=str(process['email_notification']).lower())",
            "            _processes.append(_process)",
            "",
            "        _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.create_monitoring_policy(",
            "            monitoring_policy=_monitoring_policy,",
            "            thresholds=_thresholds,",
            "            ports=_ports,",
            "            processes=_processes",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.monitoring_policy,",
            "                monitoring_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        mp_id = module.params.get('name')",
            "        monitoring_policy_id = get_monitoring_policy(oneandone_conn, mp_id)",
            "        if module.check_mode:",
            "            if monitoring_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy(monitoring_policy_id)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        return (changed, {",
            "            'id': monitoring_policy['id'],",
            "            'name': monitoring_policy['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            monitoring_policy=dict(type='str'),",
            "            agent=dict(type='str'),",
            "            email=dict(type='str'),",
            "            description=dict(type='str'),",
            "            thresholds=dict(type='list', default=[]),",
            "            ports=dict(type='list', default=[]),",
            "            processes=dict(type='list', default=[]),",
            "            add_ports=dict(type='list', default=[]),",
            "            update_ports=dict(type='list', default=[]),",
            "            remove_ports=dict(type='list', default=[]),",
            "            add_processes=dict(type='list', default=[]),",
            "            update_processes=dict(type='list', default=[]),",
            "            remove_processes=dict(type='list', default=[]),",
            "            add_servers=dict(type='list', default=[]),",
            "            remove_servers=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = remove_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('monitoring_policy'):",
            "            module.fail_json(",
            "                msg=\"'monitoring_policy' parameter is required to update a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = update_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'agent', 'email', 'thresholds', 'ports', 'processes'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for a new monitoring policy.\" % param)",
            "        try:",
            "            (changed, monitoring_policy) = create_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, monitoring_policy=monitoring_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_monitoring_policy",
            "short_description: Configure 1&1 monitoring policy.",
            "description:",
            "     - Create, remove, update monitoring policies",
            "       (and add/remove ports, processes, and servers).",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a monitoring policy's state to create, remove, update.",
            "    required: false",
            "    default: present",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Monitoring policy name used with present state. Used as identifier (id or name) when used with absent state. maxLength=128",
            "    required: true",
            "  monitoring_policy:",
            "    description:",
            "      - The identifier (id or name) of the monitoring policy used with update state.",
            "    required: true",
            "  agent:",
            "    description:",
            "      - Set true for using agent.",
            "    required: true",
            "  email:",
            "    description:",
            "      - User's email. maxLength=128",
            "    required: true",
            "  description:",
            "    description:",
            "      - Monitoring policy description. maxLength=256",
            "    required: false",
            "  thresholds:",
            "    description:",
            "      - Monitoring policy thresholds. Each of the suboptions have warning and critical,",
            "        which both have alert and value suboptions. Warning is used to set limits for",
            "        warning alerts, critical is used to set critical alerts. alert enables alert,",
            "        and value is used to advise when the value is exceeded.",
            "    required: true",
            "    suboptions:",
            "      cpu:",
            "        description:",
            "          - Consumption limits of CPU.",
            "        required: true",
            "      ram:",
            "        description:",
            "          - Consumption limits of RAM.",
            "        required: true",
            "      disk:",
            "        description:",
            "          - Consumption limits of hard disk.",
            "        required: true",
            "      internal_ping:",
            "        description:",
            "          - Response limits of internal ping.",
            "        required: true",
            "      transfer:",
            "        description:",
            "          - Consumption limits for transfer.",
            "        required: true",
            "  ports:",
            "    description:",
            "      - Array of ports that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      protocol:",
            "        description:",
            "          - Internet protocol.",
            "        choices: [ \"TCP\", \"UDP\" ]",
            "        required: true",
            "      port:",
            "        description:",
            "          - Port number. minimum=1, maximum=65535",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RESPONDING\", \"NOT_RESPONDING\" ]",
            "        required: true",
            "      email_notification:",
            "        description:",
            "          - Set true for sending e-mail notifications.",
            "        required: true",
            "  processes:",
            "    description:",
            "      - Array of processes that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      process:",
            "        description:",
            "          - Name of the process. maxLength=50",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RUNNING\", \"NOT_RUNNING\" ]",
            "        required: true",
            "  add_ports:",
            "    description:",
            "      - Ports to add to the monitoring policy.",
            "    required: false",
            "  add_processes:",
            "    description:",
            "      - Processes to add to the monitoring policy.",
            "    required: false",
            "  add_servers:",
            "    description:",
            "      - Servers to add to the monitoring policy.",
            "    required: false",
            "  remove_ports:",
            "    description:",
            "      - Ports to remove from the monitoring policy.",
            "    required: false",
            "  remove_processes:",
            "    description:",
            "      - Processes to remove from the monitoring policy.",
            "    required: false",
            "  remove_servers:",
            "    description:",
            "      - Servers to remove from the monitoring policy.",
            "    required: false",
            "  update_ports:",
            "    description:",
            "      - Ports to be updated on the monitoring policy.",
            "    required: false",
            "  update_processes:",
            "    description:",
            "      - Processes to be updated on the monitoring policy.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible monitoring policy",
            "    description: Testing creation of a monitoring policy with ansible",
            "    email: your@emailaddress.com",
            "    agent: true",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 92",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 50",
            "           alert: false",
            "         critical:",
            "           value: 100",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 1000",
            "           alert: false",
            "         critical:",
            "           value: 2000",
            "           alert: false",
            "    ports:",
            "     -",
            "       protocol: TCP",
            "       port: 22",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    processes:",
            "     -",
            "       process: test",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible monitoring policy",
            "",
            "# Update a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy",
            "    name: ansible monitoring policy updated",
            "    description: Testing creation of a monitoring policy with ansible updated",
            "    email: another@emailaddress.com",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 60",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 900",
            "           alert: false",
            "         critical:",
            "           value: 1900",
            "           alert: false",
            "    wait: true",
            "    state: update",
            "",
            "# Add a port to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_ports:",
            "     -",
            "       protocol: TCP",
            "       port: 33",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing ports of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_ports:",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 34",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 23",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a port from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_ports:",
            "     - port_id",
            "    state: update",
            "",
            "# Add a process to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_processes:",
            "     -",
            "       process: test_2",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing processes of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_processes:",
            "     -",
            "       id: process_id",
            "       process: test_1",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "     -",
            "       id: process_id",
            "       process: test_3",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a process from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_processes:",
            "     - process_id",
            "    wait: true",
            "    state: update",
            "",
            "# Add server to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_servers:",
            "     - server id or name",
            "    wait: true",
            "    state: update",
            "",
            "# Remove server from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_servers:",
            "     - server01",
            "    wait: true",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "monitoring_policy:",
            "    description: Information about the monitoring policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_monitoring_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_ports(module, oneandone_conn, monitoring_policy_id, ports):",
            "    \"\"\"",
            "    Adds new ports to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_ports = []",
            "",
            "        for _port in ports:",
            "            monitoring_policy_port = oneandone.client.Port(",
            "                protocol=_port['protocol'],",
            "                port=_port['port'],",
            "                alert_if=_port['alert_if'],",
            "                email_notification=_port['email_notification']",
            "            )",
            "            monitoring_policy_ports.append(monitoring_policy_port)",
            "",
            "        if module.check_mode:",
            "            if monitoring_policy_ports:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            ports=monitoring_policy_ports)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_port(module, oneandone_conn, monitoring_policy_id, port_id):",
            "    \"\"\"",
            "    Removes a port from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if monitoring_policy:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_port(module, oneandone_conn, monitoring_policy_id, port_id, port):",
            "    \"\"\"",
            "    Modifies a monitoring policy port.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_port = oneandone_conn.get_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if cm_port:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_port = oneandone.client.Port(",
            "            protocol=port['protocol'],",
            "            port=port['port'],",
            "            alert_if=port['alert_if'],",
            "            email_notification=port['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id,",
            "            port=monitoring_policy_port)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_processes(module, oneandone_conn, monitoring_policy_id, processes):",
            "    \"\"\"",
            "    Adds new processes to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_processes = []",
            "",
            "        for _process in processes:",
            "            monitoring_policy_process = oneandone.client.Process(",
            "                process=_process['process'],",
            "                alert_if=_process['alert_if'],",
            "                email_notification=_process['email_notification']",
            "            )",
            "            monitoring_policy_processes.append(monitoring_policy_process)",
            "",
            "        if module.check_mode:",
            "            mp_id = get_monitoring_policy(oneandone_conn, monitoring_policy_id)",
            "            if (monitoring_policy_processes and mp_id):",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            processes=monitoring_policy_processes)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_process(module, oneandone_conn, monitoring_policy_id, process_id):",
            "    \"\"\"",
            "    Removes a process from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id",
            "            )",
            "            if process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_process(module, oneandone_conn, monitoring_policy_id, process_id, process):",
            "    \"\"\"",
            "    Modifies a monitoring policy process.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id)",
            "            if cm_process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_process = oneandone.client.Process(",
            "            process=process['process'],",
            "            alert_if=process['alert_if'],",
            "            email_notification=process['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id,",
            "            process=monitoring_policy_process)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _attach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, servers):",
            "    \"\"\"",
            "    Attaches servers to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in servers:",
            "            server_id = get_server(oneandone_conn, _server_id)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server_id",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.attach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            servers=attach_servers)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _detach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, server_id):",
            "    \"\"\"",
            "    Detaches a server from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            mp_server = oneandone_conn.get_monitoring_policy_server(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                server_id=server_id)",
            "            if mp_server:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.detach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            server_id=server_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a monitoring_policy based on input arguments.",
            "    Monitoring policy ports, processes and servers can be added/removed to/from",
            "    a monitoring policy. Monitoring policy name, description, email,",
            "    thresholds for cpu, ram, disk, transfer and internal_ping",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_id = module.params.get('monitoring_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        thresholds = module.params.get('thresholds')",
            "        add_ports = module.params.get('add_ports')",
            "        update_ports = module.params.get('update_ports')",
            "        remove_ports = module.params.get('remove_ports')",
            "        add_processes = module.params.get('add_processes')",
            "        update_processes = module.params.get('update_processes')",
            "        remove_processes = module.params.get('remove_processes')",
            "        add_servers = module.params.get('add_servers')",
            "        remove_servers = module.params.get('remove_servers')",
            "",
            "        changed = False",
            "",
            "        monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy_id, True)",
            "        if monitoring_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(",
            "            name=name,",
            "            description=description,",
            "            email=email",
            "        )",
            "",
            "        _thresholds = None",
            "",
            "        if thresholds:",
            "            threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "            _thresholds = []",
            "            for treshold in thresholds:",
            "                key = treshold.keys()[0]",
            "                if key in threshold_entities:",
            "                    _threshold = oneandone.client.Threshold(",
            "                        entity=key,",
            "                        warning_value=treshold[key]['warning']['value'],",
            "                        warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                        critical_value=treshold[key]['critical']['value'],",
            "                        critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                    _thresholds.append(_threshold)",
            "",
            "        if name or description or email or thresholds:",
            "            _check_mode(module, True)",
            "            monitoring_policy = oneandone_conn.modify_monitoring_policy(",
            "                monitoring_policy_id=monitoring_policy['id'],",
            "                monitoring_policy=_monitoring_policy,",
            "                thresholds=_thresholds)",
            "            changed = True",
            "",
            "        if add_ports:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_ports(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_ports))",
            "",
            "            monitoring_policy = _add_ports(module, oneandone_conn, monitoring_policy['id'], add_ports)",
            "            changed = True",
            "",
            "        if update_ports:",
            "            chk_changed = False",
            "            for update_port in update_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_port(module,",
            "                                                oneandone_conn,",
            "                                                monitoring_policy['id'],",
            "                                                update_port['id'],",
            "                                                update_port)",
            "",
            "                _modify_port(module,",
            "                             oneandone_conn,",
            "                             monitoring_policy['id'],",
            "                             update_port['id'],",
            "                             update_port)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_ports:",
            "            chk_changed = False",
            "            for port_id in remove_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_port(module,",
            "                                                                  oneandone_conn,",
            "                                                                  monitoring_policy['id'],",
            "                                                                  port_id)",
            "",
            "                _delete_monitoring_policy_port(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               port_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_processes:",
            "            monitoring_policy = _add_processes(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_processes)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if update_processes:",
            "            chk_changed = False",
            "            for update_process in update_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_process(module,",
            "                                                   oneandone_conn,",
            "                                                   monitoring_policy['id'],",
            "                                                   update_process['id'],",
            "                                                   update_process)",
            "",
            "                _modify_process(module,",
            "                                oneandone_conn,",
            "                                monitoring_policy['id'],",
            "                                update_process['id'],",
            "                                update_process)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_processes:",
            "            chk_changed = False",
            "            for process_id in remove_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_process(module,",
            "                                                                     oneandone_conn,",
            "                                                                     monitoring_policy['id'],",
            "                                                                     process_id)",
            "",
            "                _delete_monitoring_policy_process(module,",
            "                                                  oneandone_conn,",
            "                                                  monitoring_policy['id'],",
            "                                                  process_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_servers:",
            "            monitoring_policy = _attach_monitoring_policy_server(module,",
            "                                                                 oneandone_conn,",
            "                                                                 monitoring_policy['id'],",
            "                                                                 add_servers)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if remove_servers:",
            "            chk_changed = False",
            "            for _server_id in remove_servers:",
            "                server_id = get_server(oneandone_conn, _server_id)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _detach_monitoring_policy_server(module,",
            "                                                                    oneandone_conn,",
            "                                                                    monitoring_policy['id'],",
            "                                                                    server_id)",
            "",
            "                _detach_monitoring_policy_server(module,",
            "                                                 oneandone_conn,",
            "                                                 monitoring_policy['id'],",
            "                                                 server_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Creates a new monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        agent = module.params.get('agent')",
            "        thresholds = module.params.get('thresholds')",
            "        ports = module.params.get('ports')",
            "        processes = module.params.get('processes')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(name,",
            "                                                               description,",
            "                                                               email,",
            "                                                               agent, )",
            "",
            "        _monitoring_policy.specs['agent'] = str(_monitoring_policy.specs['agent']).lower()",
            "",
            "        threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "        _thresholds = []",
            "        for treshold in thresholds:",
            "            key = treshold.keys()[0]",
            "            if key in threshold_entities:",
            "                _threshold = oneandone.client.Threshold(",
            "                    entity=key,",
            "                    warning_value=treshold[key]['warning']['value'],",
            "                    warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                    critical_value=treshold[key]['critical']['value'],",
            "                    critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                _thresholds.append(_threshold)",
            "",
            "        _ports = []",
            "        for port in ports:",
            "            _port = oneandone.client.Port(",
            "                protocol=port['protocol'],",
            "                port=port['port'],",
            "                alert_if=port['alert_if'],",
            "                email_notification=str(port['email_notification']).lower())",
            "            _ports.append(_port)",
            "",
            "        _processes = []",
            "        for process in processes:",
            "            _process = oneandone.client.Process(",
            "                process=process['process'],",
            "                alert_if=process['alert_if'],",
            "                email_notification=str(process['email_notification']).lower())",
            "            _processes.append(_process)",
            "",
            "        _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.create_monitoring_policy(",
            "            monitoring_policy=_monitoring_policy,",
            "            thresholds=_thresholds,",
            "            ports=_ports,",
            "            processes=_processes",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.monitoring_policy,",
            "                monitoring_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        mp_id = module.params.get('name')",
            "        monitoring_policy_id = get_monitoring_policy(oneandone_conn, mp_id)",
            "        if module.check_mode:",
            "            if monitoring_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy(monitoring_policy_id)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        return (changed, {",
            "            'id': monitoring_policy['id'],",
            "            'name': monitoring_policy['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            monitoring_policy=dict(type='str'),",
            "            agent=dict(type='str'),",
            "            email=dict(type='str'),",
            "            description=dict(type='str'),",
            "            thresholds=dict(type='list', default=[]),",
            "            ports=dict(type='list', default=[]),",
            "            processes=dict(type='list', default=[]),",
            "            add_ports=dict(type='list', default=[]),",
            "            update_ports=dict(type='list', default=[]),",
            "            remove_ports=dict(type='list', default=[]),",
            "            add_processes=dict(type='list', default=[]),",
            "            update_processes=dict(type='list', default=[]),",
            "            remove_processes=dict(type='list', default=[]),",
            "            add_servers=dict(type='list', default=[]),",
            "            remove_servers=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = remove_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('monitoring_policy'):",
            "            module.fail_json(",
            "                msg=\"'monitoring_policy' parameter is required to update a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = update_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'agent', 'email', 'thresholds', 'ports', 'processes'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for a new monitoring policy.\" % param)",
            "        try:",
            "            (changed, monitoring_policy) = create_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, monitoring_policy=monitoring_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "953": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_private_network.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 389,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 391,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_private_network",
            "short_description: Configure 1&1 private networking.",
            "description:",
            "     - Create, remove, reconfigure, update a private network.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a network's state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  private_network:",
            "    description:",
            "      - The identifier (id or name) of the network used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Private network name used with present state. Used as identifier (id or name) when used with absent state.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Set a description for the network.",
            "  datacenter:",
            "    description:",
            "      - The identifier of the datacenter where the private network will be created",
            "  network_address:",
            "    description:",
            "      - Set a private network space, i.e. 192.168.1.0",
            "  subnet_mask:",
            "    description:",
            "      - Set the netmask for the private network, i.e. 255.255.255.0",
            "  add_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be added to the private network.",
            "  remove_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be removed from the private network.",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy private networks.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    name: backup_network",
            "    description: Testing creation of a private network with ansible",
            "    network_address: 70.35.193.100",
            "    subnet_mask: 255.0.0.0",
            "    datacenter: US",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: backup_network",
            "",
            "# Modify the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    network_address: 192.168.2.0",
            "    subnet_mask: 255.255.255.0",
            "",
            "# Add members to the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    add_members:",
            "     - server identifier (id or name)",
            "",
            "# Remove members from the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    remove_members:",
            "     - server identifier (id or name)",
            "",
            "'''",
            "",
            "RETURN = '''",
            "private_network:",
            "    description: Information about the private network.",
            "    type: dict",
            "    sample: '{\"name\": \"backup_network\", \"id\": \"55726DEDA20C99CF6F2AF8F18CAC9963\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_private_network,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion,",
            "    wait_for_resource_deletion_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_servers(module, oneandone_conn, name, members):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id and members:",
            "                return True",
            "            return False",
            "",
            "        network = oneandone_conn.attach_private_network_servers(",
            "            private_network_id=private_network_id,",
            "            server_ids=members)",
            "",
            "        return network",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_member(module, oneandone_conn, name, member_id):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id:",
            "                network_member = oneandone_conn.get_private_network_server(",
            "                    private_network_id=private_network_id,",
            "                    server_id=member_id)",
            "                if network_member:",
            "                    return True",
            "            return False",
            "",
            "        network = oneandone_conn.remove_private_network_server(",
            "            private_network_id=name,",
            "            server_id=member_id)",
            "",
            "        return network",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new private network",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any network was added.",
            "    \"\"\"",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    network_address = module.params.get('network_address')",
            "    subnet_mask = module.params.get('subnet_mask')",
            "    datacenter = module.params.get('datacenter')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        network = oneandone_conn.create_private_network(",
            "            private_network=oneandone.client.PrivateNetwork(",
            "                name=name,",
            "                description=description,",
            "                network_address=network_address,",
            "                subnet_mask=subnet_mask,",
            "                datacenter_id=datacenter_id",
            "            ))",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.private_network,",
            "                network['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "            network = get_private_network(oneandone_conn,",
            "                                          network['id'],",
            "                                          True)",
            "",
            "        changed = True if network else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, network)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Modifies a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        _private_network_id = module.params.get('private_network')",
            "        _name = module.params.get('name')",
            "        _description = module.params.get('description')",
            "        _network_address = module.params.get('network_address')",
            "        _subnet_mask = module.params.get('subnet_mask')",
            "        _add_members = module.params.get('add_members')",
            "        _remove_members = module.params.get('remove_members')",
            "",
            "        changed = False",
            "",
            "        private_network = get_private_network(oneandone_conn,",
            "                                              _private_network_id,",
            "                                              True)",
            "        if private_network is None:",
            "            _check_mode(module, False)",
            "",
            "        if _name or _description or _network_address or _subnet_mask:",
            "            _check_mode(module, True)",
            "            private_network = oneandone_conn.modify_private_network(",
            "                private_network_id=private_network['id'],",
            "                name=_name,",
            "                description=_description,",
            "                network_address=_network_address,",
            "                subnet_mask=_subnet_mask)",
            "            changed = True",
            "",
            "        if _add_members:",
            "            instances = []",
            "",
            "            for member in _add_members:",
            "                instance_id = get_server(oneandone_conn, member)",
            "                instance_obj = oneandone.client.AttachServer(server_id=instance_id)",
            "",
            "                instances.extend([instance_obj])",
            "            private_network = _add_servers(module, oneandone_conn, private_network['id'], instances)",
            "            _check_mode(module, private_network)",
            "            changed = True",
            "",
            "        if _remove_members:",
            "            chk_changed = False",
            "            for member in _remove_members:",
            "                instance = get_server(oneandone_conn, member, True)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_member(module,",
            "                                                  oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  instance['id'])",
            "                _check_mode(module, instance and chk_changed)",
            "",
            "                _remove_member(module,",
            "                               oneandone_conn,",
            "                               private_network['id'],",
            "                               instance['id'])",
            "            private_network = get_private_network(oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  True)",
            "            changed = True",
            "",
            "        return (changed, private_network)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object.",
            "    \"\"\"",
            "    try:",
            "        pn_id = module.params.get('name')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        private_network_id = get_private_network(oneandone_conn, pn_id)",
            "        if module.check_mode:",
            "            if private_network_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        private_network = oneandone_conn.delete_private_network(private_network_id)",
            "        wait_for_resource_deletion_completion(oneandone_conn,",
            "                                              OneAndOneResources.private_network,",
            "                                              private_network['id'],",
            "                                              wait_timeout,",
            "                                              wait_interval)",
            "",
            "        changed = True if private_network else False",
            "",
            "        return (changed, {",
            "            'id': private_network['id'],",
            "            'name': private_network['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            private_network=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            network_address=dict(type='str'),",
            "            subnet_mask=dict(type='str'),",
            "            add_members=dict(type='list', default=[]),",
            "            remove_members=dict(type='list', default=[]),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a network.\")",
            "        try:",
            "            (changed, private_network) = remove_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('private_network'):",
            "            module.fail_json(",
            "                msg=\"'private_network' parameter is required for updating a network.\")",
            "        try:",
            "            (changed, private_network) = update_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'present':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for new networks.\")",
            "        try:",
            "            (changed, private_network) = create_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, private_network=private_network)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_private_network",
            "short_description: Configure 1&1 private networking.",
            "description:",
            "     - Create, remove, reconfigure, update a private network.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a network's state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  private_network:",
            "    description:",
            "      - The identifier (id or name) of the network used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Private network name used with present state. Used as identifier (id or name) when used with absent state.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Set a description for the network.",
            "  datacenter:",
            "    description:",
            "      - The identifier of the datacenter where the private network will be created",
            "  network_address:",
            "    description:",
            "      - Set a private network space, i.e. 192.168.1.0",
            "  subnet_mask:",
            "    description:",
            "      - Set the netmask for the private network, i.e. 255.255.255.0",
            "  add_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be added to the private network.",
            "  remove_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be removed from the private network.",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy private networks.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    name: backup_network",
            "    description: Testing creation of a private network with ansible",
            "    network_address: 70.35.193.100",
            "    subnet_mask: 255.0.0.0",
            "    datacenter: US",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: backup_network",
            "",
            "# Modify the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    network_address: 192.168.2.0",
            "    subnet_mask: 255.255.255.0",
            "",
            "# Add members to the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    add_members:",
            "     - server identifier (id or name)",
            "",
            "# Remove members from the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    remove_members:",
            "     - server identifier (id or name)",
            "",
            "'''",
            "",
            "RETURN = '''",
            "private_network:",
            "    description: Information about the private network.",
            "    type: dict",
            "    sample: '{\"name\": \"backup_network\", \"id\": \"55726DEDA20C99CF6F2AF8F18CAC9963\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_private_network,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion,",
            "    wait_for_resource_deletion_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_servers(module, oneandone_conn, name, members):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id and members:",
            "                return True",
            "            return False",
            "",
            "        network = oneandone_conn.attach_private_network_servers(",
            "            private_network_id=private_network_id,",
            "            server_ids=members)",
            "",
            "        return network",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_member(module, oneandone_conn, name, member_id):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id:",
            "                network_member = oneandone_conn.get_private_network_server(",
            "                    private_network_id=private_network_id,",
            "                    server_id=member_id)",
            "                if network_member:",
            "                    return True",
            "            return False",
            "",
            "        network = oneandone_conn.remove_private_network_server(",
            "            private_network_id=name,",
            "            server_id=member_id)",
            "",
            "        return network",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new private network",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any network was added.",
            "    \"\"\"",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    network_address = module.params.get('network_address')",
            "    subnet_mask = module.params.get('subnet_mask')",
            "    datacenter = module.params.get('datacenter')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        network = oneandone_conn.create_private_network(",
            "            private_network=oneandone.client.PrivateNetwork(",
            "                name=name,",
            "                description=description,",
            "                network_address=network_address,",
            "                subnet_mask=subnet_mask,",
            "                datacenter_id=datacenter_id",
            "            ))",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.private_network,",
            "                network['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "            network = get_private_network(oneandone_conn,",
            "                                          network['id'],",
            "                                          True)",
            "",
            "        changed = True if network else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, network)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Modifies a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        _private_network_id = module.params.get('private_network')",
            "        _name = module.params.get('name')",
            "        _description = module.params.get('description')",
            "        _network_address = module.params.get('network_address')",
            "        _subnet_mask = module.params.get('subnet_mask')",
            "        _add_members = module.params.get('add_members')",
            "        _remove_members = module.params.get('remove_members')",
            "",
            "        changed = False",
            "",
            "        private_network = get_private_network(oneandone_conn,",
            "                                              _private_network_id,",
            "                                              True)",
            "        if private_network is None:",
            "            _check_mode(module, False)",
            "",
            "        if _name or _description or _network_address or _subnet_mask:",
            "            _check_mode(module, True)",
            "            private_network = oneandone_conn.modify_private_network(",
            "                private_network_id=private_network['id'],",
            "                name=_name,",
            "                description=_description,",
            "                network_address=_network_address,",
            "                subnet_mask=_subnet_mask)",
            "            changed = True",
            "",
            "        if _add_members:",
            "            instances = []",
            "",
            "            for member in _add_members:",
            "                instance_id = get_server(oneandone_conn, member)",
            "                instance_obj = oneandone.client.AttachServer(server_id=instance_id)",
            "",
            "                instances.extend([instance_obj])",
            "            private_network = _add_servers(module, oneandone_conn, private_network['id'], instances)",
            "            _check_mode(module, private_network)",
            "            changed = True",
            "",
            "        if _remove_members:",
            "            chk_changed = False",
            "            for member in _remove_members:",
            "                instance = get_server(oneandone_conn, member, True)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_member(module,",
            "                                                  oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  instance['id'])",
            "                _check_mode(module, instance and chk_changed)",
            "",
            "                _remove_member(module,",
            "                               oneandone_conn,",
            "                               private_network['id'],",
            "                               instance['id'])",
            "            private_network = get_private_network(oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  True)",
            "            changed = True",
            "",
            "        return (changed, private_network)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object.",
            "    \"\"\"",
            "    try:",
            "        pn_id = module.params.get('name')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        private_network_id = get_private_network(oneandone_conn, pn_id)",
            "        if module.check_mode:",
            "            if private_network_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        private_network = oneandone_conn.delete_private_network(private_network_id)",
            "        wait_for_resource_deletion_completion(oneandone_conn,",
            "                                              OneAndOneResources.private_network,",
            "                                              private_network['id'],",
            "                                              wait_timeout,",
            "                                              wait_interval)",
            "",
            "        changed = True if private_network else False",
            "",
            "        return (changed, {",
            "            'id': private_network['id'],",
            "            'name': private_network['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            private_network=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            network_address=dict(type='str'),",
            "            subnet_mask=dict(type='str'),",
            "            add_members=dict(type='list', default=[]),",
            "            remove_members=dict(type='list', default=[]),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a network.\")",
            "        try:",
            "            (changed, private_network) = remove_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('private_network'):",
            "            module.fail_json(",
            "                msg=\"'private_network' parameter is required for updating a network.\")",
            "        try:",
            "            (changed, private_network) = update_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'present':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for new networks.\")",
            "        try:",
            "            (changed, private_network) = create_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, private_network=private_network)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "387": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_public_ip.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 277,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": 278,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": 279,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 282,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 283,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 284,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_public_ip",
            "short_description: Configure 1&1 public IPs.",
            "description:",
            "     - Create, update, and remove public IPs.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a public ip state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  reverse_dns:",
            "    description:",
            "      - Reverse DNS name. maxLength=256",
            "    required: false",
            "  datacenter:",
            "    description:",
            "      - ID of the datacenter where the IP will be created (only for unassigned IPs).",
            "    required: false",
            "  type:",
            "    description:",
            "      - Type of IP. Currently, only IPV4 is available.",
            "    choices: [\"IPV4\", \"IPV6\"]",
            "    default: 'IPV4'",
            "    required: false",
            "  public_ip_id:",
            "    description:",
            "      - The ID of the public IP used with update and delete states.",
            "    required: true",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Create a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    reverse_dns: example.com",
            "    datacenter: US",
            "    type: IPV4",
            "",
            "# Update a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    reverse_dns: secondexample.com",
            "    state: update",
            "",
            "",
            "# Delete a public IP",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    state: absent",
            "",
            "'''",
            "",
            "RETURN = '''",
            "public_ip:",
            "    description: Information about the public ip that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"F77CC589EBC120905B4F4719217BFF6D\", \"ip\": \"10.5.132.106\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_datacenter,",
            "    get_public_ip,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "TYPES = ['IPV4', 'IPV6']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def create_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was added.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    datacenter = module.params.get('datacenter')",
            "    ip_type = module.params.get('type')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            _check_mode(module, False)",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.create_public_ip(",
            "            reverse_dns=reverse_dns,",
            "            ip_type=ip_type,",
            "            datacenter_id=datacenter_id)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Update a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was changed.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    public_ip_id = module.params.get('public_ip_id')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.modify_public_ip(",
            "            ip_id=public_ip['id'],",
            "            reverse_dns=reverse_dns)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def delete_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Delete a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was deleted.",
            "    \"\"\"",
            "    public_ip_id = module.params.get('public_ip_id')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        deleted_public_ip = oneandone_conn.delete_public_ip(",
            "            ip_id=public_ip['id'])",
            "",
            "        changed = True if deleted_public_ip else False",
            "",
            "        return (changed, {",
            "            'id': public_ip['id']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            public_ip_id=dict(type='str'),",
            "            reverse_dns=dict(type='str'),",
            "            datacenter=dict(",
            "                choices=DATACENTERS,",
            "                default='US'),",
            "            type=dict(",
            "                choices=TYPES,",
            "                default='IPV4'),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to delete a public ip.\")",
            "        try:",
            "            (changed, public_ip) = delete_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to update a public ip.\")",
            "        try:",
            "            (changed, public_ip) = update_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        try:",
            "            (changed, public_ip) = create_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, public_ip=public_ip)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_public_ip",
            "short_description: Configure 1&1 public IPs.",
            "description:",
            "     - Create, update, and remove public IPs.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a public ip state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  reverse_dns:",
            "    description:",
            "      - Reverse DNS name. maxLength=256",
            "    required: false",
            "  datacenter:",
            "    description:",
            "      - ID of the datacenter where the IP will be created (only for unassigned IPs).",
            "    required: false",
            "  type:",
            "    description:",
            "      - Type of IP. Currently, only IPV4 is available.",
            "    choices: [\"IPV4\", \"IPV6\"]",
            "    default: 'IPV4'",
            "    required: false",
            "  public_ip_id:",
            "    description:",
            "      - The ID of the public IP used with update and delete states.",
            "    required: true",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Create a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    reverse_dns: example.com",
            "    datacenter: US",
            "    type: IPV4",
            "",
            "# Update a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    reverse_dns: secondexample.com",
            "    state: update",
            "",
            "",
            "# Delete a public IP",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    state: absent",
            "",
            "'''",
            "",
            "RETURN = '''",
            "public_ip:",
            "    description: Information about the public ip that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"F77CC589EBC120905B4F4719217BFF6D\", \"ip\": \"10.5.132.106\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_datacenter,",
            "    get_public_ip,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "TYPES = ['IPV4', 'IPV6']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def create_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was added.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    datacenter = module.params.get('datacenter')",
            "    ip_type = module.params.get('type')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            _check_mode(module, False)",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.create_public_ip(",
            "            reverse_dns=reverse_dns,",
            "            ip_type=ip_type,",
            "            datacenter_id=datacenter_id)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Update a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was changed.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    public_ip_id = module.params.get('public_ip_id')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.modify_public_ip(",
            "            ip_id=public_ip['id'],",
            "            reverse_dns=reverse_dns)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def delete_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Delete a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was deleted.",
            "    \"\"\"",
            "    public_ip_id = module.params.get('public_ip_id')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        deleted_public_ip = oneandone_conn.delete_public_ip(",
            "            ip_id=public_ip['id'])",
            "",
            "        changed = True if deleted_public_ip else False",
            "",
            "        return (changed, {",
            "            'id': public_ip['id']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            public_ip_id=dict(type='str'),",
            "            reverse_dns=dict(type='str'),",
            "            datacenter=dict(",
            "                choices=DATACENTERS,",
            "                default='US'),",
            "            type=dict(",
            "                choices=TYPES,",
            "                default='IPV4'),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to delete a public ip.\")",
            "        try:",
            "            (changed, public_ip) = delete_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to update a public ip.\")",
            "        try:",
            "            (changed, public_ip) = update_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        try:",
            "            (changed, public_ip) = create_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, public_ip=public_ip)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "280": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/rackspace/rax_clb_ssl.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         loadbalancer=dict(required=True),"
            },
            "1": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "         state=dict(default='present', choices=['present', 'absent']),"
            },
            "2": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         enabled=dict(type='bool', default=True),"
            },
            "3": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        private_key=dict(),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+        private_key=dict(no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         certificate=dict(),"
            },
            "6": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 241,
                "PatchRowcode": "         intermediate_certificate=dict(),"
            },
            "7": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "         secure_port=dict(type='int', default=443),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: rax_clb_ssl",
            "short_description: Manage SSL termination for a Rackspace Cloud Load Balancer.",
            "description:",
            "- Set up, reconfigure, or remove SSL termination for an existing load balancer.",
            "version_added: \"2.0\"",
            "options:",
            "  loadbalancer:",
            "    description:",
            "    - Name or ID of the load balancer on which to manage SSL termination.",
            "    required: true",
            "  state:",
            "    description:",
            "    - If set to \"present\", SSL termination will be added to this load balancer.",
            "    - If \"absent\", SSL termination will be removed instead.",
            "    choices:",
            "      - present",
            "      - absent",
            "    default: present",
            "  enabled:",
            "    description:",
            "    - If set to \"false\", temporarily disable SSL termination without discarding",
            "    - existing credentials.",
            "    default: true",
            "    type: bool",
            "  private_key:",
            "    description:",
            "    - The private SSL key as a string in PEM format.",
            "  certificate:",
            "    description:",
            "    - The public SSL certificates as a string in PEM format.",
            "  intermediate_certificate:",
            "    description:",
            "    - One or more intermediate certificate authorities as a string in PEM",
            "    - format, concatenated into a single string.",
            "  secure_port:",
            "    description:",
            "    - The port to listen for secure traffic.",
            "    default: 443",
            "  secure_traffic_only:",
            "    description:",
            "    - If \"true\", the load balancer will *only* accept secure traffic.",
            "    default: false",
            "    type: bool",
            "  https_redirect:",
            "    description:",
            "    - If \"true\", the load balancer will redirect HTTP traffic to HTTPS.",
            "    - Requires \"secure_traffic_only\" to be true. Incurs an implicit wait if SSL",
            "    - termination is also applied or removed.",
            "    type: bool",
            "  wait:",
            "    description:",
            "    - Wait for the balancer to be in state \"running\" before turning.",
            "    default: false",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "    - How long before \"wait\" gives up, in seconds.",
            "    default: 300",
            "author: Ash Wilson (@smashwilson)",
            "extends_documentation_fragment:",
            "  - rackspace",
            "  - rackspace.openstack",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Enable SSL termination on a load balancer",
            "  rax_clb_ssl:",
            "    loadbalancer: the_loadbalancer",
            "    state: present",
            "    private_key: \"{{ lookup('file', 'credentials/server.key' ) }}\"",
            "    certificate: \"{{ lookup('file', 'credentials/server.crt' ) }}\"",
            "    intermediate_certificate: \"{{ lookup('file', 'credentials/trust-chain.crt') }}\"",
            "    secure_traffic_only: true",
            "    wait: true",
            "",
            "- name: Disable SSL termination",
            "  rax_clb_ssl:",
            "    loadbalancer: \"{{ registered_lb.balancer.id }}\"",
            "    state: absent",
            "    wait: true",
            "'''",
            "",
            "try:",
            "    import pyrax",
            "    HAS_PYRAX = True",
            "except ImportError:",
            "    HAS_PYRAX = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.rax import (rax_argument_spec,",
            "                                      rax_find_loadbalancer,",
            "                                      rax_required_together,",
            "                                      rax_to_dict,",
            "                                      setup_rax_module,",
            "                                      )",
            "",
            "",
            "def cloud_load_balancer_ssl(module, loadbalancer, state, enabled, private_key,",
            "                            certificate, intermediate_certificate, secure_port,",
            "                            secure_traffic_only, https_redirect,",
            "                            wait, wait_timeout):",
            "    # Validate arguments.",
            "",
            "    if state == 'present':",
            "        if not private_key:",
            "            module.fail_json(msg=\"private_key must be provided.\")",
            "        else:",
            "            private_key = private_key.strip()",
            "",
            "        if not certificate:",
            "            module.fail_json(msg=\"certificate must be provided.\")",
            "        else:",
            "            certificate = certificate.strip()",
            "",
            "    attempts = wait_timeout // 5",
            "",
            "    # Locate the load balancer.",
            "",
            "    balancer = rax_find_loadbalancer(module, pyrax, loadbalancer)",
            "    existing_ssl = balancer.get_ssl_termination()",
            "",
            "    changed = False",
            "",
            "    if state == 'present':",
            "        # Apply or reconfigure SSL termination on the load balancer.",
            "        ssl_attrs = dict(",
            "            securePort=secure_port,",
            "            privatekey=private_key,",
            "            certificate=certificate,",
            "            intermediateCertificate=intermediate_certificate,",
            "            enabled=enabled,",
            "            secureTrafficOnly=secure_traffic_only",
            "        )",
            "",
            "        needs_change = False",
            "",
            "        if existing_ssl:",
            "            for ssl_attr, value in ssl_attrs.items():",
            "                if ssl_attr == 'privatekey':",
            "                    # The private key is not included in get_ssl_termination's",
            "                    # output (as it shouldn't be). Also, if you're changing the",
            "                    # private key, you'll also be changing the certificate,",
            "                    # so we don't lose anything by not checking it.",
            "                    continue",
            "",
            "                if value is not None and existing_ssl.get(ssl_attr) != value:",
            "                    # module.fail_json(msg='Unnecessary change', attr=ssl_attr, value=value, existing=existing_ssl.get(ssl_attr))",
            "                    needs_change = True",
            "        else:",
            "            needs_change = True",
            "",
            "        if needs_change:",
            "            try:",
            "                balancer.add_ssl_termination(**ssl_attrs)",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "    elif state == 'absent':",
            "        # Remove SSL termination if it's already configured.",
            "        if existing_ssl:",
            "            try:",
            "                balancer.delete_ssl_termination()",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "",
            "    if https_redirect is not None and balancer.httpsRedirect != https_redirect:",
            "        if changed:",
            "            # This wait is unavoidable because load balancers are immutable",
            "            # while the SSL termination changes above are being applied.",
            "            pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "        try:",
            "            balancer.update(httpsRedirect=https_redirect)",
            "        except pyrax.exceptions.PyraxException as e:",
            "            module.fail_json(msg='%s' % e.message)",
            "        changed = True",
            "",
            "    if changed and wait:",
            "        pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "    balancer.get()",
            "    new_ssl_termination = balancer.get_ssl_termination()",
            "",
            "    # Intentionally omit the private key from the module output, so you don't",
            "    # accidentally echo it with `ansible-playbook -v` or `debug`, and the",
            "    # certificate, which is just long. Convert other attributes to snake_case",
            "    # and include https_redirect at the top-level.",
            "    if new_ssl_termination:",
            "        new_ssl = dict(",
            "            enabled=new_ssl_termination['enabled'],",
            "            secure_port=new_ssl_termination['securePort'],",
            "            secure_traffic_only=new_ssl_termination['secureTrafficOnly']",
            "        )",
            "    else:",
            "        new_ssl = None",
            "",
            "    result = dict(",
            "        changed=changed,",
            "        https_redirect=balancer.httpsRedirect,",
            "        ssl_termination=new_ssl,",
            "        balancer=rax_to_dict(balancer, 'clb')",
            "    )",
            "    success = True",
            "",
            "    if balancer.status == 'ERROR':",
            "        result['msg'] = '%s failed to build' % balancer.id",
            "        success = False",
            "    elif wait and balancer.status not in ('ACTIVE', 'ERROR'):",
            "        result['msg'] = 'Timeout waiting on %s' % balancer.id",
            "        success = False",
            "",
            "    if success:",
            "        module.exit_json(**result)",
            "    else:",
            "        module.fail_json(**result)",
            "",
            "",
            "def main():",
            "    argument_spec = rax_argument_spec()",
            "    argument_spec.update(dict(",
            "        loadbalancer=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        enabled=dict(type='bool', default=True),",
            "        private_key=dict(),",
            "        certificate=dict(),",
            "        intermediate_certificate=dict(),",
            "        secure_port=dict(type='int', default=443),",
            "        secure_traffic_only=dict(type='bool', default=False),",
            "        https_redirect=dict(type='bool'),",
            "        wait=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int', default=300)",
            "    ))",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        required_together=rax_required_together(),",
            "    )",
            "",
            "    if not HAS_PYRAX:",
            "        module.fail_json(msg='pyrax is required for this module.')",
            "",
            "    loadbalancer = module.params.get('loadbalancer')",
            "    state = module.params.get('state')",
            "    enabled = module.boolean(module.params.get('enabled'))",
            "    private_key = module.params.get('private_key')",
            "    certificate = module.params.get('certificate')",
            "    intermediate_certificate = module.params.get('intermediate_certificate')",
            "    secure_port = module.params.get('secure_port')",
            "    secure_traffic_only = module.boolean(module.params.get('secure_traffic_only'))",
            "    https_redirect = module.boolean(module.params.get('https_redirect'))",
            "    wait = module.boolean(module.params.get('wait'))",
            "    wait_timeout = module.params.get('wait_timeout')",
            "",
            "    setup_rax_module(module, pyrax)",
            "",
            "    cloud_load_balancer_ssl(",
            "        module, loadbalancer, state, enabled, private_key, certificate,",
            "        intermediate_certificate, secure_port, secure_traffic_only,",
            "        https_redirect, wait, wait_timeout",
            "    )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: rax_clb_ssl",
            "short_description: Manage SSL termination for a Rackspace Cloud Load Balancer.",
            "description:",
            "- Set up, reconfigure, or remove SSL termination for an existing load balancer.",
            "version_added: \"2.0\"",
            "options:",
            "  loadbalancer:",
            "    description:",
            "    - Name or ID of the load balancer on which to manage SSL termination.",
            "    required: true",
            "  state:",
            "    description:",
            "    - If set to \"present\", SSL termination will be added to this load balancer.",
            "    - If \"absent\", SSL termination will be removed instead.",
            "    choices:",
            "      - present",
            "      - absent",
            "    default: present",
            "  enabled:",
            "    description:",
            "    - If set to \"false\", temporarily disable SSL termination without discarding",
            "    - existing credentials.",
            "    default: true",
            "    type: bool",
            "  private_key:",
            "    description:",
            "    - The private SSL key as a string in PEM format.",
            "  certificate:",
            "    description:",
            "    - The public SSL certificates as a string in PEM format.",
            "  intermediate_certificate:",
            "    description:",
            "    - One or more intermediate certificate authorities as a string in PEM",
            "    - format, concatenated into a single string.",
            "  secure_port:",
            "    description:",
            "    - The port to listen for secure traffic.",
            "    default: 443",
            "  secure_traffic_only:",
            "    description:",
            "    - If \"true\", the load balancer will *only* accept secure traffic.",
            "    default: false",
            "    type: bool",
            "  https_redirect:",
            "    description:",
            "    - If \"true\", the load balancer will redirect HTTP traffic to HTTPS.",
            "    - Requires \"secure_traffic_only\" to be true. Incurs an implicit wait if SSL",
            "    - termination is also applied or removed.",
            "    type: bool",
            "  wait:",
            "    description:",
            "    - Wait for the balancer to be in state \"running\" before turning.",
            "    default: false",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "    - How long before \"wait\" gives up, in seconds.",
            "    default: 300",
            "author: Ash Wilson (@smashwilson)",
            "extends_documentation_fragment:",
            "  - rackspace",
            "  - rackspace.openstack",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Enable SSL termination on a load balancer",
            "  rax_clb_ssl:",
            "    loadbalancer: the_loadbalancer",
            "    state: present",
            "    private_key: \"{{ lookup('file', 'credentials/server.key' ) }}\"",
            "    certificate: \"{{ lookup('file', 'credentials/server.crt' ) }}\"",
            "    intermediate_certificate: \"{{ lookup('file', 'credentials/trust-chain.crt') }}\"",
            "    secure_traffic_only: true",
            "    wait: true",
            "",
            "- name: Disable SSL termination",
            "  rax_clb_ssl:",
            "    loadbalancer: \"{{ registered_lb.balancer.id }}\"",
            "    state: absent",
            "    wait: true",
            "'''",
            "",
            "try:",
            "    import pyrax",
            "    HAS_PYRAX = True",
            "except ImportError:",
            "    HAS_PYRAX = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.rax import (rax_argument_spec,",
            "                                      rax_find_loadbalancer,",
            "                                      rax_required_together,",
            "                                      rax_to_dict,",
            "                                      setup_rax_module,",
            "                                      )",
            "",
            "",
            "def cloud_load_balancer_ssl(module, loadbalancer, state, enabled, private_key,",
            "                            certificate, intermediate_certificate, secure_port,",
            "                            secure_traffic_only, https_redirect,",
            "                            wait, wait_timeout):",
            "    # Validate arguments.",
            "",
            "    if state == 'present':",
            "        if not private_key:",
            "            module.fail_json(msg=\"private_key must be provided.\")",
            "        else:",
            "            private_key = private_key.strip()",
            "",
            "        if not certificate:",
            "            module.fail_json(msg=\"certificate must be provided.\")",
            "        else:",
            "            certificate = certificate.strip()",
            "",
            "    attempts = wait_timeout // 5",
            "",
            "    # Locate the load balancer.",
            "",
            "    balancer = rax_find_loadbalancer(module, pyrax, loadbalancer)",
            "    existing_ssl = balancer.get_ssl_termination()",
            "",
            "    changed = False",
            "",
            "    if state == 'present':",
            "        # Apply or reconfigure SSL termination on the load balancer.",
            "        ssl_attrs = dict(",
            "            securePort=secure_port,",
            "            privatekey=private_key,",
            "            certificate=certificate,",
            "            intermediateCertificate=intermediate_certificate,",
            "            enabled=enabled,",
            "            secureTrafficOnly=secure_traffic_only",
            "        )",
            "",
            "        needs_change = False",
            "",
            "        if existing_ssl:",
            "            for ssl_attr, value in ssl_attrs.items():",
            "                if ssl_attr == 'privatekey':",
            "                    # The private key is not included in get_ssl_termination's",
            "                    # output (as it shouldn't be). Also, if you're changing the",
            "                    # private key, you'll also be changing the certificate,",
            "                    # so we don't lose anything by not checking it.",
            "                    continue",
            "",
            "                if value is not None and existing_ssl.get(ssl_attr) != value:",
            "                    # module.fail_json(msg='Unnecessary change', attr=ssl_attr, value=value, existing=existing_ssl.get(ssl_attr))",
            "                    needs_change = True",
            "        else:",
            "            needs_change = True",
            "",
            "        if needs_change:",
            "            try:",
            "                balancer.add_ssl_termination(**ssl_attrs)",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "    elif state == 'absent':",
            "        # Remove SSL termination if it's already configured.",
            "        if existing_ssl:",
            "            try:",
            "                balancer.delete_ssl_termination()",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "",
            "    if https_redirect is not None and balancer.httpsRedirect != https_redirect:",
            "        if changed:",
            "            # This wait is unavoidable because load balancers are immutable",
            "            # while the SSL termination changes above are being applied.",
            "            pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "        try:",
            "            balancer.update(httpsRedirect=https_redirect)",
            "        except pyrax.exceptions.PyraxException as e:",
            "            module.fail_json(msg='%s' % e.message)",
            "        changed = True",
            "",
            "    if changed and wait:",
            "        pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "    balancer.get()",
            "    new_ssl_termination = balancer.get_ssl_termination()",
            "",
            "    # Intentionally omit the private key from the module output, so you don't",
            "    # accidentally echo it with `ansible-playbook -v` or `debug`, and the",
            "    # certificate, which is just long. Convert other attributes to snake_case",
            "    # and include https_redirect at the top-level.",
            "    if new_ssl_termination:",
            "        new_ssl = dict(",
            "            enabled=new_ssl_termination['enabled'],",
            "            secure_port=new_ssl_termination['securePort'],",
            "            secure_traffic_only=new_ssl_termination['secureTrafficOnly']",
            "        )",
            "    else:",
            "        new_ssl = None",
            "",
            "    result = dict(",
            "        changed=changed,",
            "        https_redirect=balancer.httpsRedirect,",
            "        ssl_termination=new_ssl,",
            "        balancer=rax_to_dict(balancer, 'clb')",
            "    )",
            "    success = True",
            "",
            "    if balancer.status == 'ERROR':",
            "        result['msg'] = '%s failed to build' % balancer.id",
            "        success = False",
            "    elif wait and balancer.status not in ('ACTIVE', 'ERROR'):",
            "        result['msg'] = 'Timeout waiting on %s' % balancer.id",
            "        success = False",
            "",
            "    if success:",
            "        module.exit_json(**result)",
            "    else:",
            "        module.fail_json(**result)",
            "",
            "",
            "def main():",
            "    argument_spec = rax_argument_spec()",
            "    argument_spec.update(dict(",
            "        loadbalancer=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        enabled=dict(type='bool', default=True),",
            "        private_key=dict(no_log=True),",
            "        certificate=dict(),",
            "        intermediate_certificate=dict(),",
            "        secure_port=dict(type='int', default=443),",
            "        secure_traffic_only=dict(type='bool', default=False),",
            "        https_redirect=dict(type='bool'),",
            "        wait=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int', default=300)",
            "    ))",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        required_together=rax_required_together(),",
            "    )",
            "",
            "    if not HAS_PYRAX:",
            "        module.fail_json(msg='pyrax is required for this module.')",
            "",
            "    loadbalancer = module.params.get('loadbalancer')",
            "    state = module.params.get('state')",
            "    enabled = module.boolean(module.params.get('enabled'))",
            "    private_key = module.params.get('private_key')",
            "    certificate = module.params.get('certificate')",
            "    intermediate_certificate = module.params.get('intermediate_certificate')",
            "    secure_port = module.params.get('secure_port')",
            "    secure_traffic_only = module.boolean(module.params.get('secure_traffic_only'))",
            "    https_redirect = module.boolean(module.params.get('https_redirect'))",
            "    wait = module.boolean(module.params.get('wait'))",
            "    wait_timeout = module.params.get('wait_timeout')",
            "",
            "    setup_rax_module(module, pyrax)",
            "",
            "    cloud_load_balancer_ssl(",
            "        module, loadbalancer, state, enabled, private_key, certificate,",
            "        intermediate_certificate, secure_port, secure_traffic_only,",
            "        https_redirect, wait, wait_timeout",
            "    )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "239": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/spotinst/spotinst_aws_elastigroup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1438,
                "afterPatchRowNumber": 1438,
                "PatchRowcode": "         min_size=dict(type='int', required=True),"
            },
            "1": {
                "beforePatchRowNumber": 1439,
                "afterPatchRowNumber": 1439,
                "PatchRowcode": "         monitoring=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 1440,
                "afterPatchRowNumber": 1440,
                "PatchRowcode": "         multai_load_balancers=dict(type='list'),"
            },
            "3": {
                "beforePatchRowNumber": 1441,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        multai_token=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1441,
                "PatchRowcode": "+        multai_token=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 1442,
                "afterPatchRowNumber": 1442,
                "PatchRowcode": "         name=dict(type='str', required=True),"
            },
            "6": {
                "beforePatchRowNumber": 1443,
                "afterPatchRowNumber": 1443,
                "PatchRowcode": "         network_interfaces=dict(type='list'),"
            },
            "7": {
                "beforePatchRowNumber": 1444,
                "afterPatchRowNumber": 1444,
                "PatchRowcode": "         on_demand_count=dict(type='int'),"
            },
            "8": {
                "beforePatchRowNumber": 1462,
                "afterPatchRowNumber": 1462,
                "PatchRowcode": "         target_group_arns=dict(type='list'),"
            },
            "9": {
                "beforePatchRowNumber": 1463,
                "afterPatchRowNumber": 1463,
                "PatchRowcode": "         tenancy=dict(type='str'),"
            },
            "10": {
                "beforePatchRowNumber": 1464,
                "afterPatchRowNumber": 1464,
                "PatchRowcode": "         terminate_at_end_of_billing_hour=dict(type='bool'),"
            },
            "11": {
                "beforePatchRowNumber": 1465,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        token=dict(type='str'),"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1465,
                "PatchRowcode": "+        token=dict(type='str', no_log=True),"
            },
            "13": {
                "beforePatchRowNumber": 1466,
                "afterPatchRowNumber": 1466,
                "PatchRowcode": "         unit=dict(type='str'),"
            },
            "14": {
                "beforePatchRowNumber": 1467,
                "afterPatchRowNumber": 1467,
                "PatchRowcode": "         user_data=dict(type='str'),"
            },
            "15": {
                "beforePatchRowNumber": 1468,
                "afterPatchRowNumber": 1468,
                "PatchRowcode": "         utilize_reserved_instances=dict(type='bool'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# Copyright (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "DOCUMENTATION = \"\"\"",
            "---",
            "module: spotinst_aws_elastigroup",
            "version_added: 2.5",
            "short_description: Create, update or delete Spotinst AWS Elastigroups",
            "author: Spotinst (@talzur)",
            "description:",
            "  - Can create, update, or delete Spotinst AWS Elastigroups",
            "    Launch configuration is part of the elastigroup configuration,",
            "    so no additional modules are necessary for handling the launch configuration.",
            "    You will have to have a credentials file in this location - <home>/.spotinst/credentials",
            "    The credentials file must contain a row that looks like this",
            "    token = <YOUR TOKEN>",
            "    Full documentation available at https://help.spotinst.com/hc/en-us/articles/115003530285-Ansible-",
            "requirements:",
            "  - python >= 2.7",
            "  - spotinst_sdk >= 1.0.38",
            "options:",
            "",
            "  credentials_path:",
            "    description:",
            "      - (String) Optional parameter that allows to set a non-default credentials path.",
            "       Default is ~/.spotinst/credentials",
            "",
            "  account_id:",
            "    description:",
            "      - (String) Optional parameter that allows to set an account-id inside the module configuration",
            "       By default this is retrieved from the credentials path",
            "",
            "  availability_vs_cost:",
            "    choices:",
            "      - availabilityOriented",
            "      - costOriented",
            "      - balanced",
            "    description:",
            "      - (String) The strategy orientation.",
            "    required: true",
            "",
            "  availability_zones:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Availability Zones that are configured in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        name (String),",
            "        subnet_id (String),",
            "        placement_group_name (String),",
            "    required: true",
            "",
            "  block_device_mappings:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Block Device Mappings for elastigroup instances;",
            "        You can specify virtual devices and EBS volumes.;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        device_name (List of Strings),",
            "        virtual_name (String),",
            "        no_device (String),",
            "        ebs (Object, expects the following keys-",
            "        delete_on_termination(Boolean),",
            "        encrypted(Boolean),",
            "        iops (Integer),",
            "        snapshot_id(Integer),",
            "        volume_type(String),",
            "        volume_size(Integer))",
            "",
            "  chef:",
            "    description:",
            "      - (Object) The Chef integration configuration.;",
            "        Expects the following keys - chef_server (String),",
            "        organization (String),",
            "        user (String),",
            "        pem_key (String),",
            "        chef_version (String)",
            "",
            "  draining_timeout:",
            "    description:",
            "      - (Integer) Time for instance to be drained from incoming requests and deregistered from ELB before termination.",
            "",
            "  ebs_optimized:",
            "    description:",
            "      - (Boolean) Enable EBS optimization for supported instances which are not enabled by default.;",
            "        Note - additional charges will be applied.",
            "    type: bool",
            "",
            "  ebs_volume_pool:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of EBS devices to reattach to the elastigroup when available;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        volume_ids (List of Strings),",
            "        device_name (String)",
            "",
            "  ecs:",
            "    description:",
            "      - (Object) The ECS integration configuration.;",
            "        Expects the following key -",
            "        cluster_name (String)",
            "",
            "",
            "  elastic_ips:",
            "    description:",
            "      - (List of Strings) List of ElasticIps Allocation Ids (Example C(eipalloc-9d4e16f8)) to associate to the group instances",
            "",
            "  fallback_to_od:",
            "    description:",
            "      - (Boolean) In case of no spots available, Elastigroup will launch an On-demand instance instead",
            "    type: bool",
            "  health_check_grace_period:",
            "    description:",
            "      - (Integer) The amount of time, in seconds, after the instance has launched to start and check its health.",
            "    default: 300",
            "",
            "  health_check_unhealthy_duration_before_replacement:",
            "    description:",
            "      - (Integer) Minimal mount of time instance should be unhealthy for us to consider it unhealthy.",
            "",
            "  health_check_type:",
            "    choices:",
            "      - ELB",
            "      - HCS",
            "      - TARGET_GROUP",
            "      - MLB",
            "      - EC2",
            "    description:",
            "      - (String) The service to use for the health check.",
            "",
            "  iam_role_name:",
            "    description:",
            "      - (String) The instance profile iamRole name",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  iam_role_arn:",
            "    description:",
            "      - (String) The instance profile iamRole arn",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  id:",
            "    description:",
            "      - (String) The group id if it already exists and you want to update, or delete it.",
            "        This will not work unless the uniqueness_by field is set to id.",
            "        When this is set, and the uniqueness_by field is set, the group will either be updated or deleted, but not created.",
            "",
            "  ignore_changes:",
            "    choices:",
            "      - image_id",
            "      - target",
            "    description:",
            "      - (List of Strings) list of fields on which changes should be ignored when updating",
            "",
            "  image_id:",
            "    description:",
            "      - (String) The image Id used to launch the instance.;",
            "        In case of conflict between Instance type and image type, an error will be returned",
            "    required: true",
            "",
            "  key_pair:",
            "    description:",
            "      - (String) Specify a Key Pair to attach to the instances",
            "    required: true",
            "",
            "  kubernetes:",
            "    description:",
            "      - (Object) The Kubernetes integration configuration.",
            "        Expects the following keys -",
            "        api_server (String),",
            "        token (String)",
            "",
            "  lifetime_period:",
            "    description:",
            "      - (String) lifetime period",
            "",
            "  load_balancers:",
            "    description:",
            "      - (List of Strings) List of classic ELB names",
            "",
            "  max_size:",
            "    description:",
            "      - (Integer) The upper limit number of instances that you can scale up to",
            "    required: true",
            "",
            "  mesosphere:",
            "    description:",
            "      - (Object) The Mesosphere integration configuration.",
            "        Expects the following key -",
            "        api_server (String)",
            "",
            "  min_size:",
            "    description:",
            "      - (Integer) The lower limit number of instances that you can scale down to",
            "    required: true",
            "",
            "  monitoring:",
            "    description:",
            "      - (Boolean) Describes whether instance Enhanced Monitoring is enabled",
            "    required: true",
            "",
            "  name:",
            "    description:",
            "      - (String) Unique name for elastigroup to be created, updated or deleted",
            "    required: true",
            "",
            "  network_interfaces:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of network interfaces to add to the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        description (String),",
            "        device_index (Integer),",
            "        secondary_private_ip_address_count (Integer),",
            "        associate_public_ip_address (Boolean),",
            "        delete_on_termination (Boolean),",
            "        groups (List of Strings),",
            "        network_interface_id (String),",
            "        private_ip_address (String),",
            "        subnet_id (String),",
            "        associate_ipv6_address (Boolean),",
            "        private_ip_addresses (List of Objects, Keys are privateIpAddress (String, required) and primary (Boolean))",
            "",
            "  on_demand_count:",
            "    description:",
            "      - (Integer) Required if risk is not set",
            "      - Number of on demand instances to launch. All other instances will be spot instances.;",
            "        Either set this parameter or the risk parameter",
            "",
            "  on_demand_instance_type:",
            "    description:",
            "      - (String) On-demand instance type that will be provisioned",
            "    required: true",
            "",
            "  opsworks:",
            "    description:",
            "      - (Object) The elastigroup OpsWorks integration configration.;",
            "        Expects the following key -",
            "        layer_id (String)",
            "",
            "  persistence:",
            "    description:",
            "      - (Object) The Stateful elastigroup configration.;",
            "        Accepts the following keys -",
            "        should_persist_root_device (Boolean),",
            "        should_persist_block_devices (Boolean),",
            "        should_persist_private_ip (Boolean)",
            "",
            "  product:",
            "    choices:",
            "      - Linux/UNIX",
            "      - SUSE Linux",
            "      - Windows",
            "      - Linux/UNIX (Amazon VPC)",
            "      - SUSE Linux (Amazon VPC)",
            "      - Windows",
            "    description:",
            "      - (String) Operation system type._",
            "    required: true",
            "",
            "  rancher:",
            "    description:",
            "      - (Object) The Rancher integration configuration.;",
            "        Expects the following keys -",
            "        version (String),",
            "        access_key (String),",
            "        secret_key (String),",
            "        master_host (String)",
            "",
            "  right_scale:",
            "    description:",
            "      - (Object) The Rightscale integration configuration.;",
            "        Expects the following keys -",
            "        account_id (String),",
            "        refresh_token (String)",
            "",
            "  risk:",
            "    description:",
            "      - (Integer) required if on demand is not set. The percentage of Spot instances to launch (0 - 100).",
            "",
            "  roll_config:",
            "    description:",
            "      - (Object) Roll configuration.;",
            "        If you would like the group to roll after updating, please use this feature.",
            "        Accepts the following keys -",
            "        batch_size_percentage(Integer, Required),",
            "        grace_period - (Integer, Required),",
            "        health_check_type(String, Optional)",
            "",
            "  scheduled_tasks:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scheduled tasks to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        adjustment (Integer),",
            "        scale_target_capacity (Integer),",
            "        scale_min_capacity (Integer),",
            "        scale_max_capacity (Integer),",
            "        adjustment_percentage (Integer),",
            "        batch_size_percentage (Integer),",
            "        cron_expression (String),",
            "        frequency (String),",
            "        grace_period (Integer),",
            "        task_type (String, required),",
            "        is_enabled (Boolean)",
            "",
            "  security_group_ids:",
            "    description:",
            "      - (List of Strings) One or more security group IDs. ;",
            "        In case of update it will override the existing Security Group with the new given array",
            "    required: true",
            "",
            "  shutdown_script:",
            "    description:",
            "      - (String) The Base64-encoded shutdown script that executes prior to instance termination.",
            "        Encode before setting.",
            "",
            "  signals:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of signals to configure in the elastigroup;",
            "        keys allowed are -",
            "        name (String, required),",
            "        timeout (Integer)",
            "",
            "  spin_up_time:",
            "    description:",
            "      - (Integer) spin up time, in seconds, for the instance",
            "",
            "  spot_instance_types:",
            "    description:",
            "      - (List of Strings) Spot instance type that will be provisioned.",
            "    required: true",
            "",
            "  state:",
            "    choices:",
            "      - present",
            "      - absent",
            "    description:",
            "      - (String) create or delete the elastigroup",
            "",
            "  tags:",
            "    description:",
            "      - (List of tagKey:tagValue paris) a list of tags to configure in the elastigroup. Please specify list of keys and values (key colon value);",
            "",
            "  target:",
            "    description:",
            "      - (Integer) The number of instances to launch",
            "    required: true",
            "",
            "  target_group_arns:",
            "    description:",
            "      - (List of Strings) List of target group arns instances should be registered to",
            "",
            "  tenancy:",
            "    choices:",
            "      - default",
            "      - dedicated",
            "    description:",
            "      - (String) dedicated vs shared tenancy",
            "",
            "  terminate_at_end_of_billing_hour:",
            "    description:",
            "      - (Boolean) terminate at the end of billing hour",
            "    type: bool",
            "  unit:",
            "    choices:",
            "      - instance",
            "      - weight",
            "    description:",
            "      - (String) The capacity unit to launch instances by.",
            "    required: true",
            "",
            "  up_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions (List of Objects, Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required)",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        min_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "",
            "  down_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions ((List of Objects), Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required),",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        max_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "  target_tracking_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of target tracking policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        source (String, required),",
            "        metric_name (String, required),",
            "        statistic (String, required),",
            "        unit (String, required),",
            "        cooldown (String, required),",
            "        target (String, required)",
            "",
            "  uniqueness_by:",
            "    choices:",
            "      - id",
            "      - name",
            "    description:",
            "      - (String) If your group names are not unique, you may use this feature to update or delete a specific group.",
            "        Whenever this property is set, you must set a group_id in order to update or delete a group, otherwise a group will be created.",
            "",
            "",
            "  user_data:",
            "    description:",
            "      - (String) Base64-encoded MIME user data. Encode before setting the value.",
            "",
            "",
            "  utilize_reserved_instances:",
            "    description:",
            "      - (Boolean) In case of any available Reserved Instances,",
            "         Elastigroup will utilize your reservations before purchasing Spot instances.",
            "    type: bool",
            "",
            "  wait_for_instances:",
            "    description:",
            "      - (Boolean) Whether or not the elastigroup creation / update actions should wait for the instances to spin",
            "    type: bool",
            "",
            "  wait_timeout:",
            "    description:",
            "      - (Integer) How long the module should wait for instances before failing the action.;",
            "        Only works if wait_for_instances is True.",
            "",
            "\"\"\"",
            "EXAMPLES = '''",
            "# Basic configuration YAML example",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup and wait 600 seconds to retrieve the instances, and use their private ips",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/sda1'",
            "              ebs:",
            "                volume_size: 100",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup with multiple block device mappings, tags, and also an account id",
            "# In organizations with more than one account, it is required to specify an account_id",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              ebs:",
            "                volume_size: 60",
            "                volume_type: gp2",
            "            - device_name: '/dev/xvdb'",
            "              ebs:",
            "                volume_size: 120",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example we have set up block device mapping with ephemeral devices",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              virtual_name: ephemeral0",
            "            - device_name: '/dev/xvdb/'",
            "              virtual_name: ephemeral1",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example we create a basic group configuration with a network interface defined.",
            "# Each network interface must have a device index",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          network_interfaces:",
            "            - associate_public_ip_address: true",
            "              device_index: 0",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "",
            "# In this example we create a basic group configuration with a target tracking scaling policy defined",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          account_id: act-92d45673",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-79da021e",
            "          image_id: ami-f173cc91",
            "          fallback_to_od: true",
            "          tags:",
            "            - Creator: ValueOfCreatorTag",
            "            - Environment: ValueOfEnvironmentTag",
            "          key_pair: spotinst-labs-oregon",
            "          max_size: 10",
            "          min_size: 0",
            "          target: 2",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-1",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-46cdc13d",
            "          spot_instance_types:",
            "            - c3.large",
            "          target_tracking_policies:",
            "            - policy_name: target-tracking-1",
            "              namespace: AWS/EC2",
            "              metric_name: CPUUtilization",
            "              statistic: average",
            "              unit: percent",
            "              target: 50",
            "              cooldown: 120",
            "          do_not_update:",
            "            - image_id",
            "      register: result",
            "    - debug: var=result",
            "",
            "'''",
            "RETURN = '''",
            "---",
            "instances:",
            "    description: List of active elastigroup instances and their details.",
            "    returned: success",
            "    type: dict",
            "    sample: [",
            "         {",
            "            \"spotInstanceRequestId\": \"sir-regs25zp\",",
            "            \"instanceId\": \"i-09640ad8678234c\",",
            "            \"instanceType\": \"m4.large\",",
            "            \"product\": \"Linux/UNIX\",",
            "            \"availabilityZone\": \"us-west-2b\",",
            "            \"privateIp\": \"180.0.2.244\",",
            "            \"createdAt\": \"2017-07-17T12:46:18.000Z\",",
            "            \"status\": \"fulfilled\"",
            "        }",
            "    ]",
            "group_id:",
            "    description: Created / Updated group's ID.",
            "    returned: success",
            "    type: str",
            "    sample: \"sig-12345\"",
            "",
            "'''",
            "",
            "HAS_SPOTINST_SDK = False",
            "__metaclass__ = type",
            "",
            "import os",
            "import time",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "try:",
            "    import spotinst_sdk as spotinst",
            "    from spotinst_sdk import SpotinstClientException",
            "",
            "    HAS_SPOTINST_SDK = True",
            "",
            "except ImportError:",
            "    pass",
            "",
            "eni_fields = ('description',",
            "              'device_index',",
            "              'secondary_private_ip_address_count',",
            "              'associate_public_ip_address',",
            "              'delete_on_termination',",
            "              'groups',",
            "              'network_interface_id',",
            "              'private_ip_address',",
            "              'subnet_id',",
            "              'associate_ipv6_address')",
            "",
            "private_ip_fields = ('private_ip_address',",
            "                     'primary')",
            "",
            "capacity_fields = (dict(ansible_field_name='min_size',",
            "                        spotinst_field_name='minimum'),",
            "                   dict(ansible_field_name='max_size',",
            "                        spotinst_field_name='maximum'),",
            "                   'target',",
            "                   'unit')",
            "",
            "lspec_fields = ('user_data',",
            "                'key_pair',",
            "                'tenancy',",
            "                'shutdown_script',",
            "                'monitoring',",
            "                'ebs_optimized',",
            "                'image_id',",
            "                'health_check_type',",
            "                'health_check_grace_period',",
            "                'health_check_unhealthy_duration_before_replacement',",
            "                'security_group_ids')",
            "",
            "iam_fields = (dict(ansible_field_name='iam_role_name',",
            "                   spotinst_field_name='name'),",
            "              dict(ansible_field_name='iam_role_arn',",
            "                   spotinst_field_name='arn'))",
            "",
            "scheduled_task_fields = ('adjustment',",
            "                         'adjustment_percentage',",
            "                         'batch_size_percentage',",
            "                         'cron_expression',",
            "                         'frequency',",
            "                         'grace_period',",
            "                         'task_type',",
            "                         'is_enabled',",
            "                         'scale_target_capacity',",
            "                         'scale_min_capacity',",
            "                         'scale_max_capacity')",
            "",
            "scaling_policy_fields = ('policy_name',",
            "                         'namespace',",
            "                         'metric_name',",
            "                         'dimensions',",
            "                         'statistic',",
            "                         'evaluation_periods',",
            "                         'period',",
            "                         'threshold',",
            "                         'cooldown',",
            "                         'unit',",
            "                         'operator')",
            "",
            "tracking_policy_fields = ('policy_name',",
            "                          'namespace',",
            "                          'source',",
            "                          'metric_name',",
            "                          'statistic',",
            "                          'unit',",
            "                          'cooldown',",
            "                          'target',",
            "                          'threshold')",
            "",
            "action_fields = (dict(ansible_field_name='action_type',",
            "                      spotinst_field_name='type'),",
            "                 'adjustment',",
            "                 'min_target_capacity',",
            "                 'max_target_capacity',",
            "                 'target',",
            "                 'minimum',",
            "                 'maximum')",
            "",
            "signal_fields = ('name',",
            "                 'timeout')",
            "",
            "multai_lb_fields = ('balancer_id',",
            "                    'project_id',",
            "                    'target_set_id',",
            "                    'az_awareness',",
            "                    'auto_weight')",
            "",
            "persistence_fields = ('should_persist_root_device',",
            "                      'should_persist_block_devices',",
            "                      'should_persist_private_ip')",
            "",
            "strategy_fields = ('risk',",
            "                   'utilize_reserved_instances',",
            "                   'fallback_to_od',",
            "                   'on_demand_count',",
            "                   'availability_vs_cost',",
            "                   'draining_timeout',",
            "                   'spin_up_time',",
            "                   'lifetime_period')",
            "",
            "ebs_fields = ('delete_on_termination',",
            "              'encrypted',",
            "              'iops',",
            "              'snapshot_id',",
            "              'volume_type',",
            "              'volume_size')",
            "",
            "bdm_fields = ('device_name',",
            "              'virtual_name',",
            "              'no_device')",
            "",
            "kubernetes_fields = ('api_server',",
            "                     'token')",
            "",
            "right_scale_fields = ('account_id',",
            "                      'refresh_token')",
            "",
            "rancher_fields = ('access_key',",
            "                  'secret_key',",
            "                  'master_host',",
            "                  'version')",
            "",
            "chef_fields = ('chef_server',",
            "               'organization',",
            "               'user',",
            "               'pem_key',",
            "               'chef_version')",
            "",
            "az_fields = ('name',",
            "             'subnet_id',",
            "             'placement_group_name')",
            "",
            "opsworks_fields = ('layer_id',)",
            "",
            "scaling_strategy_fields = ('terminate_at_end_of_billing_hour',)",
            "",
            "mesosphere_fields = ('api_server',)",
            "",
            "ecs_fields = ('cluster_name',)",
            "",
            "multai_fields = ('multai_token',)",
            "",
            "",
            "def handle_elastigroup(client, module):",
            "    has_changed = False",
            "    should_create = False",
            "    group_id = None",
            "    message = 'None'",
            "",
            "    name = module.params.get('name')",
            "    state = module.params.get('state')",
            "    uniqueness_by = module.params.get('uniqueness_by')",
            "    external_group_id = module.params.get('id')",
            "",
            "    if uniqueness_by == 'id':",
            "        if external_group_id is None:",
            "            should_create = True",
            "        else:",
            "            should_create = False",
            "            group_id = external_group_id",
            "    else:",
            "        groups = client.get_elastigroups()",
            "        should_create, group_id = find_group_with_same_name(groups, name)",
            "",
            "    if should_create is True:",
            "        if state == 'present':",
            "            eg = expand_elastigroup(module, is_update=False)",
            "            module.debug(str(\" [INFO] \" + message + \"\\n\"))",
            "            group = client.create_elastigroup(group=eg)",
            "            group_id = group['id']",
            "            message = 'Created group Successfully.'",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            message = 'Cannot delete non-existent group.'",
            "            has_changed = False",
            "    else:",
            "        eg = expand_elastigroup(module, is_update=True)",
            "",
            "        if state == 'present':",
            "            group = client.update_elastigroup(group_update=eg, group_id=group_id)",
            "            message = 'Updated group successfully.'",
            "",
            "            try:",
            "                roll_config = module.params.get('roll_config')",
            "                if roll_config:",
            "                    eg_roll = spotinst.aws_elastigroup.Roll(",
            "                        batch_size_percentage=roll_config.get('batch_size_percentage'),",
            "                        grace_period=roll_config.get('grace_period'),",
            "                        health_check_type=roll_config.get('health_check_type')",
            "                    )",
            "                    roll_response = client.roll_group(group_roll=eg_roll, group_id=group_id)",
            "                    message = 'Updated and started rolling the group successfully.'",
            "",
            "            except SpotinstClientException as exc:",
            "                message = 'Updated group successfully, but failed to perform roll. Error:' + str(exc)",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            try:",
            "                client.delete_elastigroup(group_id=group_id)",
            "            except SpotinstClientException as exc:",
            "                if \"GROUP_DOESNT_EXIST\" in exc.message:",
            "                    pass",
            "                else:",
            "                    module.fail_json(msg=\"Error while attempting to delete group : \" + exc.message)",
            "",
            "            message = 'Deleted group successfully.'",
            "            has_changed = True",
            "",
            "    return group_id, message, has_changed",
            "",
            "",
            "def retrieve_group_instances(client, module, group_id):",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_for_instances = module.params.get('wait_for_instances')",
            "",
            "    health_check_type = module.params.get('health_check_type')",
            "",
            "    if wait_timeout is None:",
            "        wait_timeout = 300",
            "",
            "    wait_timeout = time.time() + wait_timeout",
            "    target = module.params.get('target')",
            "    state = module.params.get('state')",
            "    instances = list()",
            "",
            "    if state == 'present' and group_id is not None and wait_for_instances is True:",
            "",
            "        is_amount_fulfilled = False",
            "        while is_amount_fulfilled is False and wait_timeout > time.time():",
            "            instances = list()",
            "            amount_of_fulfilled_instances = 0",
            "",
            "            if health_check_type is not None:",
            "                healthy_instances = client.get_instance_healthiness(group_id=group_id)",
            "",
            "                for healthy_instance in healthy_instances:",
            "                    if(healthy_instance.get('healthStatus') == 'HEALTHY'):",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(healthy_instance)",
            "",
            "            else:",
            "                active_instances = client.get_elastigroup_active_instances(group_id=group_id)",
            "",
            "                for active_instance in active_instances:",
            "                    if active_instance.get('private_ip') is not None:",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(active_instance)",
            "",
            "            if amount_of_fulfilled_instances >= target:",
            "                is_amount_fulfilled = True",
            "",
            "            time.sleep(10)",
            "",
            "    return instances",
            "",
            "",
            "def find_group_with_same_name(groups, name):",
            "    for group in groups:",
            "        if group['name'] == name:",
            "            return False, group.get('id')",
            "",
            "    return True, None",
            "",
            "",
            "def expand_elastigroup(module, is_update):",
            "    do_not_update = module.params['do_not_update']",
            "    name = module.params.get('name')",
            "",
            "    eg = spotinst.aws_elastigroup.Elastigroup()",
            "    description = module.params.get('description')",
            "",
            "    if name is not None:",
            "        eg.name = name",
            "    if description is not None:",
            "        eg.description = description",
            "",
            "    # Capacity",
            "    expand_capacity(eg, module, is_update, do_not_update)",
            "    # Strategy",
            "    expand_strategy(eg, module)",
            "    # Scaling",
            "    expand_scaling(eg, module)",
            "    # Third party integrations",
            "    expand_integrations(eg, module)",
            "    # Compute",
            "    expand_compute(eg, module, is_update, do_not_update)",
            "    # Multai",
            "    expand_multai(eg, module)",
            "    # Scheduling",
            "    expand_scheduled_tasks(eg, module)",
            "",
            "    return eg",
            "",
            "",
            "def expand_compute(eg, module, is_update, do_not_update):",
            "    elastic_ips = module.params['elastic_ips']",
            "    on_demand_instance_type = module.params.get('on_demand_instance_type')",
            "    spot_instance_types = module.params['spot_instance_types']",
            "    ebs_volume_pool = module.params['ebs_volume_pool']",
            "    availability_zones_list = module.params['availability_zones']",
            "    product = module.params.get('product')",
            "",
            "    eg_compute = spotinst.aws_elastigroup.Compute()",
            "",
            "    if product is not None:",
            "        # Only put product on group creation",
            "        if is_update is not True:",
            "            eg_compute.product = product",
            "",
            "    if elastic_ips is not None:",
            "        eg_compute.elastic_ips = elastic_ips",
            "",
            "    if on_demand_instance_type or spot_instance_types is not None:",
            "        eg_instance_types = spotinst.aws_elastigroup.InstanceTypes()",
            "",
            "        if on_demand_instance_type is not None:",
            "            eg_instance_types.spot = spot_instance_types",
            "        if spot_instance_types is not None:",
            "            eg_instance_types.ondemand = on_demand_instance_type",
            "",
            "        if eg_instance_types.spot is not None or eg_instance_types.ondemand is not None:",
            "            eg_compute.instance_types = eg_instance_types",
            "",
            "    expand_ebs_volume_pool(eg_compute, ebs_volume_pool)",
            "",
            "    eg_compute.availability_zones = expand_list(availability_zones_list, az_fields, 'AvailabilityZone')",
            "",
            "    expand_launch_spec(eg_compute, module, is_update, do_not_update)",
            "",
            "    eg.compute = eg_compute",
            "",
            "",
            "def expand_ebs_volume_pool(eg_compute, ebs_volumes_list):",
            "    if ebs_volumes_list is not None:",
            "        eg_volumes = []",
            "",
            "        for volume in ebs_volumes_list:",
            "            eg_volume = spotinst.aws_elastigroup.EbsVolume()",
            "",
            "            if volume.get('device_name') is not None:",
            "                eg_volume.device_name = volume.get('device_name')",
            "            if volume.get('volume_ids') is not None:",
            "                eg_volume.volume_ids = volume.get('volume_ids')",
            "",
            "            if eg_volume.device_name is not None:",
            "                eg_volumes.append(eg_volume)",
            "",
            "        if len(eg_volumes) > 0:",
            "            eg_compute.ebs_volume_pool = eg_volumes",
            "",
            "",
            "def expand_launch_spec(eg_compute, module, is_update, do_not_update):",
            "    eg_launch_spec = expand_fields(lspec_fields, module.params, 'LaunchSpecification')",
            "",
            "    if module.params['iam_role_arn'] is not None or module.params['iam_role_name'] is not None:",
            "        eg_launch_spec.iam_role = expand_fields(iam_fields, module.params, 'IamRole')",
            "",
            "    tags = module.params['tags']",
            "    load_balancers = module.params['load_balancers']",
            "    target_group_arns = module.params['target_group_arns']",
            "    block_device_mappings = module.params['block_device_mappings']",
            "    network_interfaces = module.params['network_interfaces']",
            "",
            "    if is_update is True:",
            "        if 'image_id' in do_not_update:",
            "            delattr(eg_launch_spec, 'image_id')",
            "",
            "    expand_tags(eg_launch_spec, tags)",
            "",
            "    expand_load_balancers(eg_launch_spec, load_balancers, target_group_arns)",
            "",
            "    expand_block_device_mappings(eg_launch_spec, block_device_mappings)",
            "",
            "    expand_network_interfaces(eg_launch_spec, network_interfaces)",
            "",
            "    eg_compute.launch_specification = eg_launch_spec",
            "",
            "",
            "def expand_integrations(eg, module):",
            "    rancher = module.params.get('rancher')",
            "    mesosphere = module.params.get('mesosphere')",
            "    ecs = module.params.get('ecs')",
            "    kubernetes = module.params.get('kubernetes')",
            "    right_scale = module.params.get('right_scale')",
            "    opsworks = module.params.get('opsworks')",
            "    chef = module.params.get('chef')",
            "",
            "    integration_exists = False",
            "",
            "    eg_integrations = spotinst.aws_elastigroup.ThirdPartyIntegrations()",
            "",
            "    if mesosphere is not None:",
            "        eg_integrations.mesosphere = expand_fields(mesosphere_fields, mesosphere, 'Mesosphere')",
            "        integration_exists = True",
            "",
            "    if ecs is not None:",
            "        eg_integrations.ecs = expand_fields(ecs_fields, ecs, 'EcsConfiguration')",
            "        integration_exists = True",
            "",
            "    if kubernetes is not None:",
            "        eg_integrations.kubernetes = expand_fields(kubernetes_fields, kubernetes, 'KubernetesConfiguration')",
            "        integration_exists = True",
            "",
            "    if right_scale is not None:",
            "        eg_integrations.right_scale = expand_fields(right_scale_fields, right_scale, 'RightScaleConfiguration')",
            "        integration_exists = True",
            "",
            "    if opsworks is not None:",
            "        eg_integrations.opsworks = expand_fields(opsworks_fields, opsworks, 'OpsWorksConfiguration')",
            "        integration_exists = True",
            "",
            "    if rancher is not None:",
            "        eg_integrations.rancher = expand_fields(rancher_fields, rancher, 'Rancher')",
            "        integration_exists = True",
            "",
            "    if chef is not None:",
            "        eg_integrations.chef = expand_fields(chef_fields, chef, 'ChefConfiguration')",
            "        integration_exists = True",
            "",
            "    if integration_exists:",
            "        eg.third_parties_integration = eg_integrations",
            "",
            "",
            "def expand_capacity(eg, module, is_update, do_not_update):",
            "    eg_capacity = expand_fields(capacity_fields, module.params, 'Capacity')",
            "",
            "    if is_update is True:",
            "        delattr(eg_capacity, 'unit')",
            "",
            "        if 'target' in do_not_update:",
            "            delattr(eg_capacity, 'target')",
            "",
            "    eg.capacity = eg_capacity",
            "",
            "",
            "def expand_strategy(eg, module):",
            "    persistence = module.params.get('persistence')",
            "    signals = module.params.get('signals')",
            "",
            "    eg_strategy = expand_fields(strategy_fields, module.params, 'Strategy')",
            "",
            "    terminate_at_end_of_billing_hour = module.params.get('terminate_at_end_of_billing_hour')",
            "",
            "    if terminate_at_end_of_billing_hour is not None:",
            "        eg_strategy.eg_scaling_strategy = expand_fields(scaling_strategy_fields,",
            "                                                        module.params, 'ScalingStrategy')",
            "",
            "    if persistence is not None:",
            "        eg_strategy.persistence = expand_fields(persistence_fields, persistence, 'Persistence')",
            "",
            "    if signals is not None:",
            "        eg_signals = expand_list(signals, signal_fields, 'Signal')",
            "",
            "        if len(eg_signals) > 0:",
            "            eg_strategy.signals = eg_signals",
            "",
            "    eg.strategy = eg_strategy",
            "",
            "",
            "def expand_multai(eg, module):",
            "    multai_load_balancers = module.params.get('multai_load_balancers')",
            "",
            "    eg_multai = expand_fields(multai_fields, module.params, 'Multai')",
            "",
            "    if multai_load_balancers is not None:",
            "        eg_multai_load_balancers = expand_list(multai_load_balancers, multai_lb_fields, 'MultaiLoadBalancer')",
            "",
            "        if len(eg_multai_load_balancers) > 0:",
            "            eg_multai.balancers = eg_multai_load_balancers",
            "            eg.multai = eg_multai",
            "",
            "",
            "def expand_scheduled_tasks(eg, module):",
            "    scheduled_tasks = module.params.get('scheduled_tasks')",
            "",
            "    if scheduled_tasks is not None:",
            "        eg_scheduling = spotinst.aws_elastigroup.Scheduling()",
            "",
            "        eg_tasks = expand_list(scheduled_tasks, scheduled_task_fields, 'ScheduledTask')",
            "",
            "        if len(eg_tasks) > 0:",
            "            eg_scheduling.tasks = eg_tasks",
            "            eg.scheduling = eg_scheduling",
            "",
            "",
            "def expand_load_balancers(eg_launchspec, load_balancers, target_group_arns):",
            "    if load_balancers is not None or target_group_arns is not None:",
            "        eg_load_balancers_config = spotinst.aws_elastigroup.LoadBalancersConfig()",
            "        eg_total_lbs = []",
            "",
            "        if load_balancers is not None:",
            "            for elb_name in load_balancers:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if elb_name is not None:",
            "                    eg_elb.name = elb_name",
            "                    eg_elb.type = 'CLASSIC'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if target_group_arns is not None:",
            "            for target_arn in target_group_arns:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if target_arn is not None:",
            "                    eg_elb.arn = target_arn",
            "                    eg_elb.type = 'TARGET_GROUP'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if len(eg_total_lbs) > 0:",
            "            eg_load_balancers_config.load_balancers = eg_total_lbs",
            "            eg_launchspec.load_balancers_config = eg_load_balancers_config",
            "",
            "",
            "def expand_tags(eg_launchspec, tags):",
            "    if tags is not None:",
            "        eg_tags = []",
            "",
            "        for tag in tags:",
            "            eg_tag = spotinst.aws_elastigroup.Tag()",
            "            if tag.keys():",
            "                eg_tag.tag_key = tag.keys()[0]",
            "            if tag.values():",
            "                eg_tag.tag_value = tag.values()[0]",
            "",
            "            eg_tags.append(eg_tag)",
            "",
            "        if len(eg_tags) > 0:",
            "            eg_launchspec.tags = eg_tags",
            "",
            "",
            "def expand_block_device_mappings(eg_launchspec, bdms):",
            "    if bdms is not None:",
            "        eg_bdms = []",
            "",
            "        for bdm in bdms:",
            "            eg_bdm = expand_fields(bdm_fields, bdm, 'BlockDeviceMapping')",
            "",
            "            if bdm.get('ebs') is not None:",
            "                eg_bdm.ebs = expand_fields(ebs_fields, bdm.get('ebs'), 'EBS')",
            "",
            "            eg_bdms.append(eg_bdm)",
            "",
            "        if len(eg_bdms) > 0:",
            "            eg_launchspec.block_device_mappings = eg_bdms",
            "",
            "",
            "def expand_network_interfaces(eg_launchspec, enis):",
            "    if enis is not None:",
            "        eg_enis = []",
            "",
            "        for eni in enis:",
            "            eg_eni = expand_fields(eni_fields, eni, 'NetworkInterface')",
            "",
            "            eg_pias = expand_list(eni.get('private_ip_addresses'), private_ip_fields, 'PrivateIpAddress')",
            "",
            "            if eg_pias is not None:",
            "                eg_eni.private_ip_addresses = eg_pias",
            "",
            "            eg_enis.append(eg_eni)",
            "",
            "        if len(eg_enis) > 0:",
            "            eg_launchspec.network_interfaces = eg_enis",
            "",
            "",
            "def expand_scaling(eg, module):",
            "    up_scaling_policies = module.params['up_scaling_policies']",
            "    down_scaling_policies = module.params['down_scaling_policies']",
            "    target_tracking_policies = module.params['target_tracking_policies']",
            "",
            "    eg_scaling = spotinst.aws_elastigroup.Scaling()",
            "",
            "    if up_scaling_policies is not None:",
            "        eg_up_scaling_policies = expand_scaling_policies(up_scaling_policies)",
            "        if len(eg_up_scaling_policies) > 0:",
            "            eg_scaling.up = eg_up_scaling_policies",
            "",
            "    if down_scaling_policies is not None:",
            "        eg_down_scaling_policies = expand_scaling_policies(down_scaling_policies)",
            "        if len(eg_down_scaling_policies) > 0:",
            "            eg_scaling.down = eg_down_scaling_policies",
            "",
            "    if target_tracking_policies is not None:",
            "        eg_target_tracking_policies = expand_target_tracking_policies(target_tracking_policies)",
            "        if len(eg_target_tracking_policies) > 0:",
            "            eg_scaling.target = eg_target_tracking_policies",
            "",
            "    if eg_scaling.down is not None or eg_scaling.up is not None or eg_scaling.target is not None:",
            "        eg.scaling = eg_scaling",
            "",
            "",
            "def expand_list(items, fields, class_name):",
            "    if items is not None:",
            "        new_objects_list = []",
            "        for item in items:",
            "            new_obj = expand_fields(fields, item, class_name)",
            "            new_objects_list.append(new_obj)",
            "",
            "        return new_objects_list",
            "",
            "",
            "def expand_fields(fields, item, class_name):",
            "    class_ = getattr(spotinst.aws_elastigroup, class_name)",
            "    new_obj = class_()",
            "",
            "    # Handle primitive fields",
            "    if item is not None:",
            "        for field in fields:",
            "            if isinstance(field, dict):",
            "                ansible_field_name = field['ansible_field_name']",
            "                spotinst_field_name = field['spotinst_field_name']",
            "            else:",
            "                ansible_field_name = field",
            "                spotinst_field_name = field",
            "            if item.get(ansible_field_name) is not None:",
            "                setattr(new_obj, spotinst_field_name, item.get(ansible_field_name))",
            "",
            "    return new_obj",
            "",
            "",
            "def expand_scaling_policies(scaling_policies):",
            "    eg_scaling_policies = []",
            "",
            "    for policy in scaling_policies:",
            "        eg_policy = expand_fields(scaling_policy_fields, policy, 'ScalingPolicy')",
            "        eg_policy.action = expand_fields(action_fields, policy, 'ScalingPolicyAction')",
            "        eg_scaling_policies.append(eg_policy)",
            "",
            "    return eg_scaling_policies",
            "",
            "",
            "def expand_target_tracking_policies(tracking_policies):",
            "    eg_tracking_policies = []",
            "",
            "    for policy in tracking_policies:",
            "        eg_policy = expand_fields(tracking_policy_fields, policy, 'TargetTrackingPolicy')",
            "        eg_tracking_policies.append(eg_policy)",
            "",
            "    return eg_tracking_policies",
            "",
            "",
            "def main():",
            "    fields = dict(",
            "        account_id=dict(type='str'),",
            "        availability_vs_cost=dict(type='str', required=True),",
            "        availability_zones=dict(type='list', required=True),",
            "        block_device_mappings=dict(type='list'),",
            "        chef=dict(type='dict'),",
            "        credentials_path=dict(type='path', default=\"~/.spotinst/credentials\"),",
            "        do_not_update=dict(default=[], type='list'),",
            "        down_scaling_policies=dict(type='list'),",
            "        draining_timeout=dict(type='int'),",
            "        ebs_optimized=dict(type='bool'),",
            "        ebs_volume_pool=dict(type='list'),",
            "        ecs=dict(type='dict'),",
            "        elastic_beanstalk=dict(type='dict'),",
            "        elastic_ips=dict(type='list'),",
            "        fallback_to_od=dict(type='bool'),",
            "        id=dict(type='str'),",
            "        health_check_grace_period=dict(type='int'),",
            "        health_check_type=dict(type='str'),",
            "        health_check_unhealthy_duration_before_replacement=dict(type='int'),",
            "        iam_role_arn=dict(type='str'),",
            "        iam_role_name=dict(type='str'),",
            "        image_id=dict(type='str', required=True),",
            "        key_pair=dict(type='str'),",
            "        kubernetes=dict(type='dict'),",
            "        lifetime_period=dict(type='int'),",
            "        load_balancers=dict(type='list'),",
            "        max_size=dict(type='int', required=True),",
            "        mesosphere=dict(type='dict'),",
            "        min_size=dict(type='int', required=True),",
            "        monitoring=dict(type='str'),",
            "        multai_load_balancers=dict(type='list'),",
            "        multai_token=dict(type='str'),",
            "        name=dict(type='str', required=True),",
            "        network_interfaces=dict(type='list'),",
            "        on_demand_count=dict(type='int'),",
            "        on_demand_instance_type=dict(type='str'),",
            "        opsworks=dict(type='dict'),",
            "        persistence=dict(type='dict'),",
            "        product=dict(type='str', required=True),",
            "        rancher=dict(type='dict'),",
            "        right_scale=dict(type='dict'),",
            "        risk=dict(type='int'),",
            "        roll_config=dict(type='dict'),",
            "        scheduled_tasks=dict(type='list'),",
            "        security_group_ids=dict(type='list', required=True),",
            "        shutdown_script=dict(type='str'),",
            "        signals=dict(type='list'),",
            "        spin_up_time=dict(type='int'),",
            "        spot_instance_types=dict(type='list', required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        tags=dict(type='list'),",
            "        target=dict(type='int', required=True),",
            "        target_group_arns=dict(type='list'),",
            "        tenancy=dict(type='str'),",
            "        terminate_at_end_of_billing_hour=dict(type='bool'),",
            "        token=dict(type='str'),",
            "        unit=dict(type='str'),",
            "        user_data=dict(type='str'),",
            "        utilize_reserved_instances=dict(type='bool'),",
            "        uniqueness_by=dict(default='name', choices=['name', 'id']),",
            "        up_scaling_policies=dict(type='list'),",
            "        target_tracking_policies=dict(type='list'),",
            "        wait_for_instances=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int')",
            "    )",
            "",
            "    module = AnsibleModule(argument_spec=fields)",
            "",
            "    if not HAS_SPOTINST_SDK:",
            "        module.fail_json(msg=\"the Spotinst SDK library is required. (pip install spotinst_sdk)\")",
            "",
            "    # Retrieve creds file variables",
            "    creds_file_loaded_vars = dict()",
            "",
            "    credentials_path = module.params.get('credentials_path')",
            "",
            "    try:",
            "        with open(credentials_path, \"r\") as creds:",
            "            for line in creds:",
            "                eq_index = line.find('=')",
            "                var_name = line[:eq_index].strip()",
            "                string_value = line[eq_index + 1:].strip()",
            "                creds_file_loaded_vars[var_name] = string_value",
            "    except IOError:",
            "        pass",
            "    # End of creds file retrieval",
            "",
            "    token = module.params.get('token')",
            "    if not token:",
            "        token = os.environ.get('SPOTINST_TOKEN')",
            "    if not token:",
            "        token = creds_file_loaded_vars.get(\"token\")",
            "",
            "    account = module.params.get('account_id')",
            "    if not account:",
            "        account = os.environ.get('SPOTINST_ACCOUNT_ID') or os.environ.get('ACCOUNT')",
            "    if not account:",
            "        account = creds_file_loaded_vars.get(\"account\")",
            "",
            "    client = spotinst.SpotinstClient(auth_token=token, print_output=False)",
            "",
            "    if account is not None:",
            "        client = spotinst.SpotinstClient(auth_token=token, print_output=False, account_id=account)",
            "",
            "    group_id, message, has_changed = handle_elastigroup(client=client, module=module)",
            "",
            "    instances = retrieve_group_instances(client=client, module=module, group_id=group_id)",
            "",
            "    module.exit_json(changed=has_changed, group_id=group_id, message=message, instances=instances)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# Copyright (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "DOCUMENTATION = \"\"\"",
            "---",
            "module: spotinst_aws_elastigroup",
            "version_added: 2.5",
            "short_description: Create, update or delete Spotinst AWS Elastigroups",
            "author: Spotinst (@talzur)",
            "description:",
            "  - Can create, update, or delete Spotinst AWS Elastigroups",
            "    Launch configuration is part of the elastigroup configuration,",
            "    so no additional modules are necessary for handling the launch configuration.",
            "    You will have to have a credentials file in this location - <home>/.spotinst/credentials",
            "    The credentials file must contain a row that looks like this",
            "    token = <YOUR TOKEN>",
            "    Full documentation available at https://help.spotinst.com/hc/en-us/articles/115003530285-Ansible-",
            "requirements:",
            "  - python >= 2.7",
            "  - spotinst_sdk >= 1.0.38",
            "options:",
            "",
            "  credentials_path:",
            "    description:",
            "      - (String) Optional parameter that allows to set a non-default credentials path.",
            "       Default is ~/.spotinst/credentials",
            "",
            "  account_id:",
            "    description:",
            "      - (String) Optional parameter that allows to set an account-id inside the module configuration",
            "       By default this is retrieved from the credentials path",
            "",
            "  availability_vs_cost:",
            "    choices:",
            "      - availabilityOriented",
            "      - costOriented",
            "      - balanced",
            "    description:",
            "      - (String) The strategy orientation.",
            "    required: true",
            "",
            "  availability_zones:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Availability Zones that are configured in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        name (String),",
            "        subnet_id (String),",
            "        placement_group_name (String),",
            "    required: true",
            "",
            "  block_device_mappings:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Block Device Mappings for elastigroup instances;",
            "        You can specify virtual devices and EBS volumes.;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        device_name (List of Strings),",
            "        virtual_name (String),",
            "        no_device (String),",
            "        ebs (Object, expects the following keys-",
            "        delete_on_termination(Boolean),",
            "        encrypted(Boolean),",
            "        iops (Integer),",
            "        snapshot_id(Integer),",
            "        volume_type(String),",
            "        volume_size(Integer))",
            "",
            "  chef:",
            "    description:",
            "      - (Object) The Chef integration configuration.;",
            "        Expects the following keys - chef_server (String),",
            "        organization (String),",
            "        user (String),",
            "        pem_key (String),",
            "        chef_version (String)",
            "",
            "  draining_timeout:",
            "    description:",
            "      - (Integer) Time for instance to be drained from incoming requests and deregistered from ELB before termination.",
            "",
            "  ebs_optimized:",
            "    description:",
            "      - (Boolean) Enable EBS optimization for supported instances which are not enabled by default.;",
            "        Note - additional charges will be applied.",
            "    type: bool",
            "",
            "  ebs_volume_pool:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of EBS devices to reattach to the elastigroup when available;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        volume_ids (List of Strings),",
            "        device_name (String)",
            "",
            "  ecs:",
            "    description:",
            "      - (Object) The ECS integration configuration.;",
            "        Expects the following key -",
            "        cluster_name (String)",
            "",
            "",
            "  elastic_ips:",
            "    description:",
            "      - (List of Strings) List of ElasticIps Allocation Ids (Example C(eipalloc-9d4e16f8)) to associate to the group instances",
            "",
            "  fallback_to_od:",
            "    description:",
            "      - (Boolean) In case of no spots available, Elastigroup will launch an On-demand instance instead",
            "    type: bool",
            "  health_check_grace_period:",
            "    description:",
            "      - (Integer) The amount of time, in seconds, after the instance has launched to start and check its health.",
            "    default: 300",
            "",
            "  health_check_unhealthy_duration_before_replacement:",
            "    description:",
            "      - (Integer) Minimal mount of time instance should be unhealthy for us to consider it unhealthy.",
            "",
            "  health_check_type:",
            "    choices:",
            "      - ELB",
            "      - HCS",
            "      - TARGET_GROUP",
            "      - MLB",
            "      - EC2",
            "    description:",
            "      - (String) The service to use for the health check.",
            "",
            "  iam_role_name:",
            "    description:",
            "      - (String) The instance profile iamRole name",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  iam_role_arn:",
            "    description:",
            "      - (String) The instance profile iamRole arn",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  id:",
            "    description:",
            "      - (String) The group id if it already exists and you want to update, or delete it.",
            "        This will not work unless the uniqueness_by field is set to id.",
            "        When this is set, and the uniqueness_by field is set, the group will either be updated or deleted, but not created.",
            "",
            "  ignore_changes:",
            "    choices:",
            "      - image_id",
            "      - target",
            "    description:",
            "      - (List of Strings) list of fields on which changes should be ignored when updating",
            "",
            "  image_id:",
            "    description:",
            "      - (String) The image Id used to launch the instance.;",
            "        In case of conflict between Instance type and image type, an error will be returned",
            "    required: true",
            "",
            "  key_pair:",
            "    description:",
            "      - (String) Specify a Key Pair to attach to the instances",
            "    required: true",
            "",
            "  kubernetes:",
            "    description:",
            "      - (Object) The Kubernetes integration configuration.",
            "        Expects the following keys -",
            "        api_server (String),",
            "        token (String)",
            "",
            "  lifetime_period:",
            "    description:",
            "      - (String) lifetime period",
            "",
            "  load_balancers:",
            "    description:",
            "      - (List of Strings) List of classic ELB names",
            "",
            "  max_size:",
            "    description:",
            "      - (Integer) The upper limit number of instances that you can scale up to",
            "    required: true",
            "",
            "  mesosphere:",
            "    description:",
            "      - (Object) The Mesosphere integration configuration.",
            "        Expects the following key -",
            "        api_server (String)",
            "",
            "  min_size:",
            "    description:",
            "      - (Integer) The lower limit number of instances that you can scale down to",
            "    required: true",
            "",
            "  monitoring:",
            "    description:",
            "      - (Boolean) Describes whether instance Enhanced Monitoring is enabled",
            "    required: true",
            "",
            "  name:",
            "    description:",
            "      - (String) Unique name for elastigroup to be created, updated or deleted",
            "    required: true",
            "",
            "  network_interfaces:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of network interfaces to add to the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        description (String),",
            "        device_index (Integer),",
            "        secondary_private_ip_address_count (Integer),",
            "        associate_public_ip_address (Boolean),",
            "        delete_on_termination (Boolean),",
            "        groups (List of Strings),",
            "        network_interface_id (String),",
            "        private_ip_address (String),",
            "        subnet_id (String),",
            "        associate_ipv6_address (Boolean),",
            "        private_ip_addresses (List of Objects, Keys are privateIpAddress (String, required) and primary (Boolean))",
            "",
            "  on_demand_count:",
            "    description:",
            "      - (Integer) Required if risk is not set",
            "      - Number of on demand instances to launch. All other instances will be spot instances.;",
            "        Either set this parameter or the risk parameter",
            "",
            "  on_demand_instance_type:",
            "    description:",
            "      - (String) On-demand instance type that will be provisioned",
            "    required: true",
            "",
            "  opsworks:",
            "    description:",
            "      - (Object) The elastigroup OpsWorks integration configration.;",
            "        Expects the following key -",
            "        layer_id (String)",
            "",
            "  persistence:",
            "    description:",
            "      - (Object) The Stateful elastigroup configration.;",
            "        Accepts the following keys -",
            "        should_persist_root_device (Boolean),",
            "        should_persist_block_devices (Boolean),",
            "        should_persist_private_ip (Boolean)",
            "",
            "  product:",
            "    choices:",
            "      - Linux/UNIX",
            "      - SUSE Linux",
            "      - Windows",
            "      - Linux/UNIX (Amazon VPC)",
            "      - SUSE Linux (Amazon VPC)",
            "      - Windows",
            "    description:",
            "      - (String) Operation system type._",
            "    required: true",
            "",
            "  rancher:",
            "    description:",
            "      - (Object) The Rancher integration configuration.;",
            "        Expects the following keys -",
            "        version (String),",
            "        access_key (String),",
            "        secret_key (String),",
            "        master_host (String)",
            "",
            "  right_scale:",
            "    description:",
            "      - (Object) The Rightscale integration configuration.;",
            "        Expects the following keys -",
            "        account_id (String),",
            "        refresh_token (String)",
            "",
            "  risk:",
            "    description:",
            "      - (Integer) required if on demand is not set. The percentage of Spot instances to launch (0 - 100).",
            "",
            "  roll_config:",
            "    description:",
            "      - (Object) Roll configuration.;",
            "        If you would like the group to roll after updating, please use this feature.",
            "        Accepts the following keys -",
            "        batch_size_percentage(Integer, Required),",
            "        grace_period - (Integer, Required),",
            "        health_check_type(String, Optional)",
            "",
            "  scheduled_tasks:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scheduled tasks to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        adjustment (Integer),",
            "        scale_target_capacity (Integer),",
            "        scale_min_capacity (Integer),",
            "        scale_max_capacity (Integer),",
            "        adjustment_percentage (Integer),",
            "        batch_size_percentage (Integer),",
            "        cron_expression (String),",
            "        frequency (String),",
            "        grace_period (Integer),",
            "        task_type (String, required),",
            "        is_enabled (Boolean)",
            "",
            "  security_group_ids:",
            "    description:",
            "      - (List of Strings) One or more security group IDs. ;",
            "        In case of update it will override the existing Security Group with the new given array",
            "    required: true",
            "",
            "  shutdown_script:",
            "    description:",
            "      - (String) The Base64-encoded shutdown script that executes prior to instance termination.",
            "        Encode before setting.",
            "",
            "  signals:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of signals to configure in the elastigroup;",
            "        keys allowed are -",
            "        name (String, required),",
            "        timeout (Integer)",
            "",
            "  spin_up_time:",
            "    description:",
            "      - (Integer) spin up time, in seconds, for the instance",
            "",
            "  spot_instance_types:",
            "    description:",
            "      - (List of Strings) Spot instance type that will be provisioned.",
            "    required: true",
            "",
            "  state:",
            "    choices:",
            "      - present",
            "      - absent",
            "    description:",
            "      - (String) create or delete the elastigroup",
            "",
            "  tags:",
            "    description:",
            "      - (List of tagKey:tagValue paris) a list of tags to configure in the elastigroup. Please specify list of keys and values (key colon value);",
            "",
            "  target:",
            "    description:",
            "      - (Integer) The number of instances to launch",
            "    required: true",
            "",
            "  target_group_arns:",
            "    description:",
            "      - (List of Strings) List of target group arns instances should be registered to",
            "",
            "  tenancy:",
            "    choices:",
            "      - default",
            "      - dedicated",
            "    description:",
            "      - (String) dedicated vs shared tenancy",
            "",
            "  terminate_at_end_of_billing_hour:",
            "    description:",
            "      - (Boolean) terminate at the end of billing hour",
            "    type: bool",
            "  unit:",
            "    choices:",
            "      - instance",
            "      - weight",
            "    description:",
            "      - (String) The capacity unit to launch instances by.",
            "    required: true",
            "",
            "  up_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions (List of Objects, Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required)",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        min_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "",
            "  down_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions ((List of Objects), Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required),",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        max_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "  target_tracking_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of target tracking policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        source (String, required),",
            "        metric_name (String, required),",
            "        statistic (String, required),",
            "        unit (String, required),",
            "        cooldown (String, required),",
            "        target (String, required)",
            "",
            "  uniqueness_by:",
            "    choices:",
            "      - id",
            "      - name",
            "    description:",
            "      - (String) If your group names are not unique, you may use this feature to update or delete a specific group.",
            "        Whenever this property is set, you must set a group_id in order to update or delete a group, otherwise a group will be created.",
            "",
            "",
            "  user_data:",
            "    description:",
            "      - (String) Base64-encoded MIME user data. Encode before setting the value.",
            "",
            "",
            "  utilize_reserved_instances:",
            "    description:",
            "      - (Boolean) In case of any available Reserved Instances,",
            "         Elastigroup will utilize your reservations before purchasing Spot instances.",
            "    type: bool",
            "",
            "  wait_for_instances:",
            "    description:",
            "      - (Boolean) Whether or not the elastigroup creation / update actions should wait for the instances to spin",
            "    type: bool",
            "",
            "  wait_timeout:",
            "    description:",
            "      - (Integer) How long the module should wait for instances before failing the action.;",
            "        Only works if wait_for_instances is True.",
            "",
            "\"\"\"",
            "EXAMPLES = '''",
            "# Basic configuration YAML example",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup and wait 600 seconds to retrieve the instances, and use their private ips",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/sda1'",
            "              ebs:",
            "                volume_size: 100",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup with multiple block device mappings, tags, and also an account id",
            "# In organizations with more than one account, it is required to specify an account_id",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              ebs:",
            "                volume_size: 60",
            "                volume_type: gp2",
            "            - device_name: '/dev/xvdb'",
            "              ebs:",
            "                volume_size: 120",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example we have set up block device mapping with ephemeral devices",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              virtual_name: ephemeral0",
            "            - device_name: '/dev/xvdb/'",
            "              virtual_name: ephemeral1",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example we create a basic group configuration with a network interface defined.",
            "# Each network interface must have a device index",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          network_interfaces:",
            "            - associate_public_ip_address: true",
            "              device_index: 0",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "",
            "# In this example we create a basic group configuration with a target tracking scaling policy defined",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          account_id: act-92d45673",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-79da021e",
            "          image_id: ami-f173cc91",
            "          fallback_to_od: true",
            "          tags:",
            "            - Creator: ValueOfCreatorTag",
            "            - Environment: ValueOfEnvironmentTag",
            "          key_pair: spotinst-labs-oregon",
            "          max_size: 10",
            "          min_size: 0",
            "          target: 2",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-1",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-46cdc13d",
            "          spot_instance_types:",
            "            - c3.large",
            "          target_tracking_policies:",
            "            - policy_name: target-tracking-1",
            "              namespace: AWS/EC2",
            "              metric_name: CPUUtilization",
            "              statistic: average",
            "              unit: percent",
            "              target: 50",
            "              cooldown: 120",
            "          do_not_update:",
            "            - image_id",
            "      register: result",
            "    - debug: var=result",
            "",
            "'''",
            "RETURN = '''",
            "---",
            "instances:",
            "    description: List of active elastigroup instances and their details.",
            "    returned: success",
            "    type: dict",
            "    sample: [",
            "         {",
            "            \"spotInstanceRequestId\": \"sir-regs25zp\",",
            "            \"instanceId\": \"i-09640ad8678234c\",",
            "            \"instanceType\": \"m4.large\",",
            "            \"product\": \"Linux/UNIX\",",
            "            \"availabilityZone\": \"us-west-2b\",",
            "            \"privateIp\": \"180.0.2.244\",",
            "            \"createdAt\": \"2017-07-17T12:46:18.000Z\",",
            "            \"status\": \"fulfilled\"",
            "        }",
            "    ]",
            "group_id:",
            "    description: Created / Updated group's ID.",
            "    returned: success",
            "    type: str",
            "    sample: \"sig-12345\"",
            "",
            "'''",
            "",
            "HAS_SPOTINST_SDK = False",
            "__metaclass__ = type",
            "",
            "import os",
            "import time",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "try:",
            "    import spotinst_sdk as spotinst",
            "    from spotinst_sdk import SpotinstClientException",
            "",
            "    HAS_SPOTINST_SDK = True",
            "",
            "except ImportError:",
            "    pass",
            "",
            "eni_fields = ('description',",
            "              'device_index',",
            "              'secondary_private_ip_address_count',",
            "              'associate_public_ip_address',",
            "              'delete_on_termination',",
            "              'groups',",
            "              'network_interface_id',",
            "              'private_ip_address',",
            "              'subnet_id',",
            "              'associate_ipv6_address')",
            "",
            "private_ip_fields = ('private_ip_address',",
            "                     'primary')",
            "",
            "capacity_fields = (dict(ansible_field_name='min_size',",
            "                        spotinst_field_name='minimum'),",
            "                   dict(ansible_field_name='max_size',",
            "                        spotinst_field_name='maximum'),",
            "                   'target',",
            "                   'unit')",
            "",
            "lspec_fields = ('user_data',",
            "                'key_pair',",
            "                'tenancy',",
            "                'shutdown_script',",
            "                'monitoring',",
            "                'ebs_optimized',",
            "                'image_id',",
            "                'health_check_type',",
            "                'health_check_grace_period',",
            "                'health_check_unhealthy_duration_before_replacement',",
            "                'security_group_ids')",
            "",
            "iam_fields = (dict(ansible_field_name='iam_role_name',",
            "                   spotinst_field_name='name'),",
            "              dict(ansible_field_name='iam_role_arn',",
            "                   spotinst_field_name='arn'))",
            "",
            "scheduled_task_fields = ('adjustment',",
            "                         'adjustment_percentage',",
            "                         'batch_size_percentage',",
            "                         'cron_expression',",
            "                         'frequency',",
            "                         'grace_period',",
            "                         'task_type',",
            "                         'is_enabled',",
            "                         'scale_target_capacity',",
            "                         'scale_min_capacity',",
            "                         'scale_max_capacity')",
            "",
            "scaling_policy_fields = ('policy_name',",
            "                         'namespace',",
            "                         'metric_name',",
            "                         'dimensions',",
            "                         'statistic',",
            "                         'evaluation_periods',",
            "                         'period',",
            "                         'threshold',",
            "                         'cooldown',",
            "                         'unit',",
            "                         'operator')",
            "",
            "tracking_policy_fields = ('policy_name',",
            "                          'namespace',",
            "                          'source',",
            "                          'metric_name',",
            "                          'statistic',",
            "                          'unit',",
            "                          'cooldown',",
            "                          'target',",
            "                          'threshold')",
            "",
            "action_fields = (dict(ansible_field_name='action_type',",
            "                      spotinst_field_name='type'),",
            "                 'adjustment',",
            "                 'min_target_capacity',",
            "                 'max_target_capacity',",
            "                 'target',",
            "                 'minimum',",
            "                 'maximum')",
            "",
            "signal_fields = ('name',",
            "                 'timeout')",
            "",
            "multai_lb_fields = ('balancer_id',",
            "                    'project_id',",
            "                    'target_set_id',",
            "                    'az_awareness',",
            "                    'auto_weight')",
            "",
            "persistence_fields = ('should_persist_root_device',",
            "                      'should_persist_block_devices',",
            "                      'should_persist_private_ip')",
            "",
            "strategy_fields = ('risk',",
            "                   'utilize_reserved_instances',",
            "                   'fallback_to_od',",
            "                   'on_demand_count',",
            "                   'availability_vs_cost',",
            "                   'draining_timeout',",
            "                   'spin_up_time',",
            "                   'lifetime_period')",
            "",
            "ebs_fields = ('delete_on_termination',",
            "              'encrypted',",
            "              'iops',",
            "              'snapshot_id',",
            "              'volume_type',",
            "              'volume_size')",
            "",
            "bdm_fields = ('device_name',",
            "              'virtual_name',",
            "              'no_device')",
            "",
            "kubernetes_fields = ('api_server',",
            "                     'token')",
            "",
            "right_scale_fields = ('account_id',",
            "                      'refresh_token')",
            "",
            "rancher_fields = ('access_key',",
            "                  'secret_key',",
            "                  'master_host',",
            "                  'version')",
            "",
            "chef_fields = ('chef_server',",
            "               'organization',",
            "               'user',",
            "               'pem_key',",
            "               'chef_version')",
            "",
            "az_fields = ('name',",
            "             'subnet_id',",
            "             'placement_group_name')",
            "",
            "opsworks_fields = ('layer_id',)",
            "",
            "scaling_strategy_fields = ('terminate_at_end_of_billing_hour',)",
            "",
            "mesosphere_fields = ('api_server',)",
            "",
            "ecs_fields = ('cluster_name',)",
            "",
            "multai_fields = ('multai_token',)",
            "",
            "",
            "def handle_elastigroup(client, module):",
            "    has_changed = False",
            "    should_create = False",
            "    group_id = None",
            "    message = 'None'",
            "",
            "    name = module.params.get('name')",
            "    state = module.params.get('state')",
            "    uniqueness_by = module.params.get('uniqueness_by')",
            "    external_group_id = module.params.get('id')",
            "",
            "    if uniqueness_by == 'id':",
            "        if external_group_id is None:",
            "            should_create = True",
            "        else:",
            "            should_create = False",
            "            group_id = external_group_id",
            "    else:",
            "        groups = client.get_elastigroups()",
            "        should_create, group_id = find_group_with_same_name(groups, name)",
            "",
            "    if should_create is True:",
            "        if state == 'present':",
            "            eg = expand_elastigroup(module, is_update=False)",
            "            module.debug(str(\" [INFO] \" + message + \"\\n\"))",
            "            group = client.create_elastigroup(group=eg)",
            "            group_id = group['id']",
            "            message = 'Created group Successfully.'",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            message = 'Cannot delete non-existent group.'",
            "            has_changed = False",
            "    else:",
            "        eg = expand_elastigroup(module, is_update=True)",
            "",
            "        if state == 'present':",
            "            group = client.update_elastigroup(group_update=eg, group_id=group_id)",
            "            message = 'Updated group successfully.'",
            "",
            "            try:",
            "                roll_config = module.params.get('roll_config')",
            "                if roll_config:",
            "                    eg_roll = spotinst.aws_elastigroup.Roll(",
            "                        batch_size_percentage=roll_config.get('batch_size_percentage'),",
            "                        grace_period=roll_config.get('grace_period'),",
            "                        health_check_type=roll_config.get('health_check_type')",
            "                    )",
            "                    roll_response = client.roll_group(group_roll=eg_roll, group_id=group_id)",
            "                    message = 'Updated and started rolling the group successfully.'",
            "",
            "            except SpotinstClientException as exc:",
            "                message = 'Updated group successfully, but failed to perform roll. Error:' + str(exc)",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            try:",
            "                client.delete_elastigroup(group_id=group_id)",
            "            except SpotinstClientException as exc:",
            "                if \"GROUP_DOESNT_EXIST\" in exc.message:",
            "                    pass",
            "                else:",
            "                    module.fail_json(msg=\"Error while attempting to delete group : \" + exc.message)",
            "",
            "            message = 'Deleted group successfully.'",
            "            has_changed = True",
            "",
            "    return group_id, message, has_changed",
            "",
            "",
            "def retrieve_group_instances(client, module, group_id):",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_for_instances = module.params.get('wait_for_instances')",
            "",
            "    health_check_type = module.params.get('health_check_type')",
            "",
            "    if wait_timeout is None:",
            "        wait_timeout = 300",
            "",
            "    wait_timeout = time.time() + wait_timeout",
            "    target = module.params.get('target')",
            "    state = module.params.get('state')",
            "    instances = list()",
            "",
            "    if state == 'present' and group_id is not None and wait_for_instances is True:",
            "",
            "        is_amount_fulfilled = False",
            "        while is_amount_fulfilled is False and wait_timeout > time.time():",
            "            instances = list()",
            "            amount_of_fulfilled_instances = 0",
            "",
            "            if health_check_type is not None:",
            "                healthy_instances = client.get_instance_healthiness(group_id=group_id)",
            "",
            "                for healthy_instance in healthy_instances:",
            "                    if(healthy_instance.get('healthStatus') == 'HEALTHY'):",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(healthy_instance)",
            "",
            "            else:",
            "                active_instances = client.get_elastigroup_active_instances(group_id=group_id)",
            "",
            "                for active_instance in active_instances:",
            "                    if active_instance.get('private_ip') is not None:",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(active_instance)",
            "",
            "            if amount_of_fulfilled_instances >= target:",
            "                is_amount_fulfilled = True",
            "",
            "            time.sleep(10)",
            "",
            "    return instances",
            "",
            "",
            "def find_group_with_same_name(groups, name):",
            "    for group in groups:",
            "        if group['name'] == name:",
            "            return False, group.get('id')",
            "",
            "    return True, None",
            "",
            "",
            "def expand_elastigroup(module, is_update):",
            "    do_not_update = module.params['do_not_update']",
            "    name = module.params.get('name')",
            "",
            "    eg = spotinst.aws_elastigroup.Elastigroup()",
            "    description = module.params.get('description')",
            "",
            "    if name is not None:",
            "        eg.name = name",
            "    if description is not None:",
            "        eg.description = description",
            "",
            "    # Capacity",
            "    expand_capacity(eg, module, is_update, do_not_update)",
            "    # Strategy",
            "    expand_strategy(eg, module)",
            "    # Scaling",
            "    expand_scaling(eg, module)",
            "    # Third party integrations",
            "    expand_integrations(eg, module)",
            "    # Compute",
            "    expand_compute(eg, module, is_update, do_not_update)",
            "    # Multai",
            "    expand_multai(eg, module)",
            "    # Scheduling",
            "    expand_scheduled_tasks(eg, module)",
            "",
            "    return eg",
            "",
            "",
            "def expand_compute(eg, module, is_update, do_not_update):",
            "    elastic_ips = module.params['elastic_ips']",
            "    on_demand_instance_type = module.params.get('on_demand_instance_type')",
            "    spot_instance_types = module.params['spot_instance_types']",
            "    ebs_volume_pool = module.params['ebs_volume_pool']",
            "    availability_zones_list = module.params['availability_zones']",
            "    product = module.params.get('product')",
            "",
            "    eg_compute = spotinst.aws_elastigroup.Compute()",
            "",
            "    if product is not None:",
            "        # Only put product on group creation",
            "        if is_update is not True:",
            "            eg_compute.product = product",
            "",
            "    if elastic_ips is not None:",
            "        eg_compute.elastic_ips = elastic_ips",
            "",
            "    if on_demand_instance_type or spot_instance_types is not None:",
            "        eg_instance_types = spotinst.aws_elastigroup.InstanceTypes()",
            "",
            "        if on_demand_instance_type is not None:",
            "            eg_instance_types.spot = spot_instance_types",
            "        if spot_instance_types is not None:",
            "            eg_instance_types.ondemand = on_demand_instance_type",
            "",
            "        if eg_instance_types.spot is not None or eg_instance_types.ondemand is not None:",
            "            eg_compute.instance_types = eg_instance_types",
            "",
            "    expand_ebs_volume_pool(eg_compute, ebs_volume_pool)",
            "",
            "    eg_compute.availability_zones = expand_list(availability_zones_list, az_fields, 'AvailabilityZone')",
            "",
            "    expand_launch_spec(eg_compute, module, is_update, do_not_update)",
            "",
            "    eg.compute = eg_compute",
            "",
            "",
            "def expand_ebs_volume_pool(eg_compute, ebs_volumes_list):",
            "    if ebs_volumes_list is not None:",
            "        eg_volumes = []",
            "",
            "        for volume in ebs_volumes_list:",
            "            eg_volume = spotinst.aws_elastigroup.EbsVolume()",
            "",
            "            if volume.get('device_name') is not None:",
            "                eg_volume.device_name = volume.get('device_name')",
            "            if volume.get('volume_ids') is not None:",
            "                eg_volume.volume_ids = volume.get('volume_ids')",
            "",
            "            if eg_volume.device_name is not None:",
            "                eg_volumes.append(eg_volume)",
            "",
            "        if len(eg_volumes) > 0:",
            "            eg_compute.ebs_volume_pool = eg_volumes",
            "",
            "",
            "def expand_launch_spec(eg_compute, module, is_update, do_not_update):",
            "    eg_launch_spec = expand_fields(lspec_fields, module.params, 'LaunchSpecification')",
            "",
            "    if module.params['iam_role_arn'] is not None or module.params['iam_role_name'] is not None:",
            "        eg_launch_spec.iam_role = expand_fields(iam_fields, module.params, 'IamRole')",
            "",
            "    tags = module.params['tags']",
            "    load_balancers = module.params['load_balancers']",
            "    target_group_arns = module.params['target_group_arns']",
            "    block_device_mappings = module.params['block_device_mappings']",
            "    network_interfaces = module.params['network_interfaces']",
            "",
            "    if is_update is True:",
            "        if 'image_id' in do_not_update:",
            "            delattr(eg_launch_spec, 'image_id')",
            "",
            "    expand_tags(eg_launch_spec, tags)",
            "",
            "    expand_load_balancers(eg_launch_spec, load_balancers, target_group_arns)",
            "",
            "    expand_block_device_mappings(eg_launch_spec, block_device_mappings)",
            "",
            "    expand_network_interfaces(eg_launch_spec, network_interfaces)",
            "",
            "    eg_compute.launch_specification = eg_launch_spec",
            "",
            "",
            "def expand_integrations(eg, module):",
            "    rancher = module.params.get('rancher')",
            "    mesosphere = module.params.get('mesosphere')",
            "    ecs = module.params.get('ecs')",
            "    kubernetes = module.params.get('kubernetes')",
            "    right_scale = module.params.get('right_scale')",
            "    opsworks = module.params.get('opsworks')",
            "    chef = module.params.get('chef')",
            "",
            "    integration_exists = False",
            "",
            "    eg_integrations = spotinst.aws_elastigroup.ThirdPartyIntegrations()",
            "",
            "    if mesosphere is not None:",
            "        eg_integrations.mesosphere = expand_fields(mesosphere_fields, mesosphere, 'Mesosphere')",
            "        integration_exists = True",
            "",
            "    if ecs is not None:",
            "        eg_integrations.ecs = expand_fields(ecs_fields, ecs, 'EcsConfiguration')",
            "        integration_exists = True",
            "",
            "    if kubernetes is not None:",
            "        eg_integrations.kubernetes = expand_fields(kubernetes_fields, kubernetes, 'KubernetesConfiguration')",
            "        integration_exists = True",
            "",
            "    if right_scale is not None:",
            "        eg_integrations.right_scale = expand_fields(right_scale_fields, right_scale, 'RightScaleConfiguration')",
            "        integration_exists = True",
            "",
            "    if opsworks is not None:",
            "        eg_integrations.opsworks = expand_fields(opsworks_fields, opsworks, 'OpsWorksConfiguration')",
            "        integration_exists = True",
            "",
            "    if rancher is not None:",
            "        eg_integrations.rancher = expand_fields(rancher_fields, rancher, 'Rancher')",
            "        integration_exists = True",
            "",
            "    if chef is not None:",
            "        eg_integrations.chef = expand_fields(chef_fields, chef, 'ChefConfiguration')",
            "        integration_exists = True",
            "",
            "    if integration_exists:",
            "        eg.third_parties_integration = eg_integrations",
            "",
            "",
            "def expand_capacity(eg, module, is_update, do_not_update):",
            "    eg_capacity = expand_fields(capacity_fields, module.params, 'Capacity')",
            "",
            "    if is_update is True:",
            "        delattr(eg_capacity, 'unit')",
            "",
            "        if 'target' in do_not_update:",
            "            delattr(eg_capacity, 'target')",
            "",
            "    eg.capacity = eg_capacity",
            "",
            "",
            "def expand_strategy(eg, module):",
            "    persistence = module.params.get('persistence')",
            "    signals = module.params.get('signals')",
            "",
            "    eg_strategy = expand_fields(strategy_fields, module.params, 'Strategy')",
            "",
            "    terminate_at_end_of_billing_hour = module.params.get('terminate_at_end_of_billing_hour')",
            "",
            "    if terminate_at_end_of_billing_hour is not None:",
            "        eg_strategy.eg_scaling_strategy = expand_fields(scaling_strategy_fields,",
            "                                                        module.params, 'ScalingStrategy')",
            "",
            "    if persistence is not None:",
            "        eg_strategy.persistence = expand_fields(persistence_fields, persistence, 'Persistence')",
            "",
            "    if signals is not None:",
            "        eg_signals = expand_list(signals, signal_fields, 'Signal')",
            "",
            "        if len(eg_signals) > 0:",
            "            eg_strategy.signals = eg_signals",
            "",
            "    eg.strategy = eg_strategy",
            "",
            "",
            "def expand_multai(eg, module):",
            "    multai_load_balancers = module.params.get('multai_load_balancers')",
            "",
            "    eg_multai = expand_fields(multai_fields, module.params, 'Multai')",
            "",
            "    if multai_load_balancers is not None:",
            "        eg_multai_load_balancers = expand_list(multai_load_balancers, multai_lb_fields, 'MultaiLoadBalancer')",
            "",
            "        if len(eg_multai_load_balancers) > 0:",
            "            eg_multai.balancers = eg_multai_load_balancers",
            "            eg.multai = eg_multai",
            "",
            "",
            "def expand_scheduled_tasks(eg, module):",
            "    scheduled_tasks = module.params.get('scheduled_tasks')",
            "",
            "    if scheduled_tasks is not None:",
            "        eg_scheduling = spotinst.aws_elastigroup.Scheduling()",
            "",
            "        eg_tasks = expand_list(scheduled_tasks, scheduled_task_fields, 'ScheduledTask')",
            "",
            "        if len(eg_tasks) > 0:",
            "            eg_scheduling.tasks = eg_tasks",
            "            eg.scheduling = eg_scheduling",
            "",
            "",
            "def expand_load_balancers(eg_launchspec, load_balancers, target_group_arns):",
            "    if load_balancers is not None or target_group_arns is not None:",
            "        eg_load_balancers_config = spotinst.aws_elastigroup.LoadBalancersConfig()",
            "        eg_total_lbs = []",
            "",
            "        if load_balancers is not None:",
            "            for elb_name in load_balancers:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if elb_name is not None:",
            "                    eg_elb.name = elb_name",
            "                    eg_elb.type = 'CLASSIC'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if target_group_arns is not None:",
            "            for target_arn in target_group_arns:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if target_arn is not None:",
            "                    eg_elb.arn = target_arn",
            "                    eg_elb.type = 'TARGET_GROUP'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if len(eg_total_lbs) > 0:",
            "            eg_load_balancers_config.load_balancers = eg_total_lbs",
            "            eg_launchspec.load_balancers_config = eg_load_balancers_config",
            "",
            "",
            "def expand_tags(eg_launchspec, tags):",
            "    if tags is not None:",
            "        eg_tags = []",
            "",
            "        for tag in tags:",
            "            eg_tag = spotinst.aws_elastigroup.Tag()",
            "            if tag.keys():",
            "                eg_tag.tag_key = tag.keys()[0]",
            "            if tag.values():",
            "                eg_tag.tag_value = tag.values()[0]",
            "",
            "            eg_tags.append(eg_tag)",
            "",
            "        if len(eg_tags) > 0:",
            "            eg_launchspec.tags = eg_tags",
            "",
            "",
            "def expand_block_device_mappings(eg_launchspec, bdms):",
            "    if bdms is not None:",
            "        eg_bdms = []",
            "",
            "        for bdm in bdms:",
            "            eg_bdm = expand_fields(bdm_fields, bdm, 'BlockDeviceMapping')",
            "",
            "            if bdm.get('ebs') is not None:",
            "                eg_bdm.ebs = expand_fields(ebs_fields, bdm.get('ebs'), 'EBS')",
            "",
            "            eg_bdms.append(eg_bdm)",
            "",
            "        if len(eg_bdms) > 0:",
            "            eg_launchspec.block_device_mappings = eg_bdms",
            "",
            "",
            "def expand_network_interfaces(eg_launchspec, enis):",
            "    if enis is not None:",
            "        eg_enis = []",
            "",
            "        for eni in enis:",
            "            eg_eni = expand_fields(eni_fields, eni, 'NetworkInterface')",
            "",
            "            eg_pias = expand_list(eni.get('private_ip_addresses'), private_ip_fields, 'PrivateIpAddress')",
            "",
            "            if eg_pias is not None:",
            "                eg_eni.private_ip_addresses = eg_pias",
            "",
            "            eg_enis.append(eg_eni)",
            "",
            "        if len(eg_enis) > 0:",
            "            eg_launchspec.network_interfaces = eg_enis",
            "",
            "",
            "def expand_scaling(eg, module):",
            "    up_scaling_policies = module.params['up_scaling_policies']",
            "    down_scaling_policies = module.params['down_scaling_policies']",
            "    target_tracking_policies = module.params['target_tracking_policies']",
            "",
            "    eg_scaling = spotinst.aws_elastigroup.Scaling()",
            "",
            "    if up_scaling_policies is not None:",
            "        eg_up_scaling_policies = expand_scaling_policies(up_scaling_policies)",
            "        if len(eg_up_scaling_policies) > 0:",
            "            eg_scaling.up = eg_up_scaling_policies",
            "",
            "    if down_scaling_policies is not None:",
            "        eg_down_scaling_policies = expand_scaling_policies(down_scaling_policies)",
            "        if len(eg_down_scaling_policies) > 0:",
            "            eg_scaling.down = eg_down_scaling_policies",
            "",
            "    if target_tracking_policies is not None:",
            "        eg_target_tracking_policies = expand_target_tracking_policies(target_tracking_policies)",
            "        if len(eg_target_tracking_policies) > 0:",
            "            eg_scaling.target = eg_target_tracking_policies",
            "",
            "    if eg_scaling.down is not None or eg_scaling.up is not None or eg_scaling.target is not None:",
            "        eg.scaling = eg_scaling",
            "",
            "",
            "def expand_list(items, fields, class_name):",
            "    if items is not None:",
            "        new_objects_list = []",
            "        for item in items:",
            "            new_obj = expand_fields(fields, item, class_name)",
            "            new_objects_list.append(new_obj)",
            "",
            "        return new_objects_list",
            "",
            "",
            "def expand_fields(fields, item, class_name):",
            "    class_ = getattr(spotinst.aws_elastigroup, class_name)",
            "    new_obj = class_()",
            "",
            "    # Handle primitive fields",
            "    if item is not None:",
            "        for field in fields:",
            "            if isinstance(field, dict):",
            "                ansible_field_name = field['ansible_field_name']",
            "                spotinst_field_name = field['spotinst_field_name']",
            "            else:",
            "                ansible_field_name = field",
            "                spotinst_field_name = field",
            "            if item.get(ansible_field_name) is not None:",
            "                setattr(new_obj, spotinst_field_name, item.get(ansible_field_name))",
            "",
            "    return new_obj",
            "",
            "",
            "def expand_scaling_policies(scaling_policies):",
            "    eg_scaling_policies = []",
            "",
            "    for policy in scaling_policies:",
            "        eg_policy = expand_fields(scaling_policy_fields, policy, 'ScalingPolicy')",
            "        eg_policy.action = expand_fields(action_fields, policy, 'ScalingPolicyAction')",
            "        eg_scaling_policies.append(eg_policy)",
            "",
            "    return eg_scaling_policies",
            "",
            "",
            "def expand_target_tracking_policies(tracking_policies):",
            "    eg_tracking_policies = []",
            "",
            "    for policy in tracking_policies:",
            "        eg_policy = expand_fields(tracking_policy_fields, policy, 'TargetTrackingPolicy')",
            "        eg_tracking_policies.append(eg_policy)",
            "",
            "    return eg_tracking_policies",
            "",
            "",
            "def main():",
            "    fields = dict(",
            "        account_id=dict(type='str'),",
            "        availability_vs_cost=dict(type='str', required=True),",
            "        availability_zones=dict(type='list', required=True),",
            "        block_device_mappings=dict(type='list'),",
            "        chef=dict(type='dict'),",
            "        credentials_path=dict(type='path', default=\"~/.spotinst/credentials\"),",
            "        do_not_update=dict(default=[], type='list'),",
            "        down_scaling_policies=dict(type='list'),",
            "        draining_timeout=dict(type='int'),",
            "        ebs_optimized=dict(type='bool'),",
            "        ebs_volume_pool=dict(type='list'),",
            "        ecs=dict(type='dict'),",
            "        elastic_beanstalk=dict(type='dict'),",
            "        elastic_ips=dict(type='list'),",
            "        fallback_to_od=dict(type='bool'),",
            "        id=dict(type='str'),",
            "        health_check_grace_period=dict(type='int'),",
            "        health_check_type=dict(type='str'),",
            "        health_check_unhealthy_duration_before_replacement=dict(type='int'),",
            "        iam_role_arn=dict(type='str'),",
            "        iam_role_name=dict(type='str'),",
            "        image_id=dict(type='str', required=True),",
            "        key_pair=dict(type='str'),",
            "        kubernetes=dict(type='dict'),",
            "        lifetime_period=dict(type='int'),",
            "        load_balancers=dict(type='list'),",
            "        max_size=dict(type='int', required=True),",
            "        mesosphere=dict(type='dict'),",
            "        min_size=dict(type='int', required=True),",
            "        monitoring=dict(type='str'),",
            "        multai_load_balancers=dict(type='list'),",
            "        multai_token=dict(type='str', no_log=True),",
            "        name=dict(type='str', required=True),",
            "        network_interfaces=dict(type='list'),",
            "        on_demand_count=dict(type='int'),",
            "        on_demand_instance_type=dict(type='str'),",
            "        opsworks=dict(type='dict'),",
            "        persistence=dict(type='dict'),",
            "        product=dict(type='str', required=True),",
            "        rancher=dict(type='dict'),",
            "        right_scale=dict(type='dict'),",
            "        risk=dict(type='int'),",
            "        roll_config=dict(type='dict'),",
            "        scheduled_tasks=dict(type='list'),",
            "        security_group_ids=dict(type='list', required=True),",
            "        shutdown_script=dict(type='str'),",
            "        signals=dict(type='list'),",
            "        spin_up_time=dict(type='int'),",
            "        spot_instance_types=dict(type='list', required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        tags=dict(type='list'),",
            "        target=dict(type='int', required=True),",
            "        target_group_arns=dict(type='list'),",
            "        tenancy=dict(type='str'),",
            "        terminate_at_end_of_billing_hour=dict(type='bool'),",
            "        token=dict(type='str', no_log=True),",
            "        unit=dict(type='str'),",
            "        user_data=dict(type='str'),",
            "        utilize_reserved_instances=dict(type='bool'),",
            "        uniqueness_by=dict(default='name', choices=['name', 'id']),",
            "        up_scaling_policies=dict(type='list'),",
            "        target_tracking_policies=dict(type='list'),",
            "        wait_for_instances=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int')",
            "    )",
            "",
            "    module = AnsibleModule(argument_spec=fields)",
            "",
            "    if not HAS_SPOTINST_SDK:",
            "        module.fail_json(msg=\"the Spotinst SDK library is required. (pip install spotinst_sdk)\")",
            "",
            "    # Retrieve creds file variables",
            "    creds_file_loaded_vars = dict()",
            "",
            "    credentials_path = module.params.get('credentials_path')",
            "",
            "    try:",
            "        with open(credentials_path, \"r\") as creds:",
            "            for line in creds:",
            "                eq_index = line.find('=')",
            "                var_name = line[:eq_index].strip()",
            "                string_value = line[eq_index + 1:].strip()",
            "                creds_file_loaded_vars[var_name] = string_value",
            "    except IOError:",
            "        pass",
            "    # End of creds file retrieval",
            "",
            "    token = module.params.get('token')",
            "    if not token:",
            "        token = os.environ.get('SPOTINST_TOKEN')",
            "    if not token:",
            "        token = creds_file_loaded_vars.get(\"token\")",
            "",
            "    account = module.params.get('account_id')",
            "    if not account:",
            "        account = os.environ.get('SPOTINST_ACCOUNT_ID') or os.environ.get('ACCOUNT')",
            "    if not account:",
            "        account = creds_file_loaded_vars.get(\"account\")",
            "",
            "    client = spotinst.SpotinstClient(auth_token=token, print_output=False)",
            "",
            "    if account is not None:",
            "        client = spotinst.SpotinstClient(auth_token=token, print_output=False, account_id=account)",
            "",
            "    group_id, message, has_changed = handle_elastigroup(client=client, module=module)",
            "",
            "    instances = retrieve_group_instances(client=client, module=module, group_id=group_id)",
            "",
            "    module.exit_json(changed=has_changed, group_id=group_id, message=message, instances=instances)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1441": [
                "main"
            ],
            "1465": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/monitoring/librato_annotation.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "     module = AnsibleModule("
            },
            "1": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "         argument_spec=dict("
            },
            "2": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "             user=dict(required=True),"
            },
            "3": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            api_key=dict(required=True),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+            api_key=dict(required=True, no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "             name=dict(required=False),"
            },
            "6": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "             title=dict(required=True),"
            },
            "7": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "             source=dict(required=False),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# (C) Seth Edwards, 2014",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: librato_annotation",
            "short_description: create an annotation in librato",
            "description:",
            "    - Create an annotation event on the given annotation stream :name. If the annotation stream does not exist, it will be created automatically",
            "version_added: \"1.6\"",
            "author: \"Seth Edwards (@Sedward)\"",
            "requirements: []",
            "options:",
            "    user:",
            "        description:",
            "           - Librato account username",
            "        required: true",
            "    api_key:",
            "        description:",
            "           - Librato account api key",
            "        required: true",
            "    name:",
            "        description:",
            "            - The annotation stream name",
            "            - If the annotation stream does not exist, it will be created automatically",
            "        required: false",
            "    title:",
            "        description:",
            "            - The title of an annotation is a string and may contain spaces",
            "            - The title should be a short, high-level summary of the annotation e.g. v45 Deployment",
            "        required: true",
            "    source:",
            "        description:",
            "            - A string which describes the originating source of an annotation when that annotation is tracked across multiple members of a population",
            "        required: false",
            "    description:",
            "        description:",
            "            - The description contains extra metadata about a particular annotation",
            "            - The description should contain specifics on the individual annotation e.g. Deployed 9b562b2 shipped new feature foo!",
            "        required: false",
            "    start_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation started",
            "        required: false",
            "    end_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation ended",
            "            - For events that have a duration, this is a useful way to annotate the duration of the event",
            "        required: false",
            "    links:",
            "        description:",
            "            - See examples",
            "        required: true",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Create a simple annotation event with a source",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXX",
            "    title: App Config Change",
            "    source: foo.bar",
            "    description: This is a detailed description of the config change",
            "",
            "# Create an annotation that includes a link",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: code.deploy",
            "    title: app code deploy",
            "    description: this is a detailed description of a deployment",
            "    links:",
            "      - rel: example",
            "        href: http://www.example.com/deploy",
            "",
            "# Create an annotation with a start_time and end_time",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: maintenance",
            "    title: Maintenance window",
            "    description: This is a detailed description of maintenance",
            "    start_time: 1395940006",
            "    end_time: 1395954406",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "",
            "def post_annotation(module):",
            "    user = module.params['user']",
            "    api_key = module.params['api_key']",
            "    name = module.params['name']",
            "    title = module.params['title']",
            "",
            "    url = 'https://metrics-api.librato.com/v1/annotations/%s' % name",
            "    params = {}",
            "    params['title'] = title",
            "",
            "    if module.params['source'] is not None:",
            "        params['source'] = module.params['source']",
            "    if module.params['description'] is not None:",
            "        params['description'] = module.params['description']",
            "    if module.params['start_time'] is not None:",
            "        params['start_time'] = module.params['start_time']",
            "    if module.params['end_time'] is not None:",
            "        params['end_time'] = module.params['end_time']",
            "    if module.params['links'] is not None:",
            "        params['links'] = module.params['links']",
            "",
            "    json_body = module.jsonify(params)",
            "",
            "    headers = {}",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Hack send parameters the way fetch_url wants them",
            "    module.params['url_username'] = user",
            "    module.params['url_password'] = api_key",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    response_body = info['body']",
            "    if info['status'] != 201:",
            "        if info['status'] >= 400:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code + \" Response body: \" + response_body)",
            "        else:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code)",
            "    response = response.read()",
            "    module.exit_json(changed=True, annotation=response)",
            "",
            "",
            "def main():",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            user=dict(required=True),",
            "            api_key=dict(required=True),",
            "            name=dict(required=False),",
            "            title=dict(required=True),",
            "            source=dict(required=False),",
            "            description=dict(required=False),",
            "            start_time=dict(required=False, default=None, type='int'),",
            "            end_time=dict(required=False, default=None, type='int'),",
            "            links=dict(type='list')",
            "        )",
            "    )",
            "",
            "    post_annotation(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# (C) Seth Edwards, 2014",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: librato_annotation",
            "short_description: create an annotation in librato",
            "description:",
            "    - Create an annotation event on the given annotation stream :name. If the annotation stream does not exist, it will be created automatically",
            "version_added: \"1.6\"",
            "author: \"Seth Edwards (@Sedward)\"",
            "requirements: []",
            "options:",
            "    user:",
            "        description:",
            "           - Librato account username",
            "        required: true",
            "    api_key:",
            "        description:",
            "           - Librato account api key",
            "        required: true",
            "    name:",
            "        description:",
            "            - The annotation stream name",
            "            - If the annotation stream does not exist, it will be created automatically",
            "        required: false",
            "    title:",
            "        description:",
            "            - The title of an annotation is a string and may contain spaces",
            "            - The title should be a short, high-level summary of the annotation e.g. v45 Deployment",
            "        required: true",
            "    source:",
            "        description:",
            "            - A string which describes the originating source of an annotation when that annotation is tracked across multiple members of a population",
            "        required: false",
            "    description:",
            "        description:",
            "            - The description contains extra metadata about a particular annotation",
            "            - The description should contain specifics on the individual annotation e.g. Deployed 9b562b2 shipped new feature foo!",
            "        required: false",
            "    start_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation started",
            "        required: false",
            "    end_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation ended",
            "            - For events that have a duration, this is a useful way to annotate the duration of the event",
            "        required: false",
            "    links:",
            "        description:",
            "            - See examples",
            "        required: true",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Create a simple annotation event with a source",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXX",
            "    title: App Config Change",
            "    source: foo.bar",
            "    description: This is a detailed description of the config change",
            "",
            "# Create an annotation that includes a link",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: code.deploy",
            "    title: app code deploy",
            "    description: this is a detailed description of a deployment",
            "    links:",
            "      - rel: example",
            "        href: http://www.example.com/deploy",
            "",
            "# Create an annotation with a start_time and end_time",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: maintenance",
            "    title: Maintenance window",
            "    description: This is a detailed description of maintenance",
            "    start_time: 1395940006",
            "    end_time: 1395954406",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "",
            "def post_annotation(module):",
            "    user = module.params['user']",
            "    api_key = module.params['api_key']",
            "    name = module.params['name']",
            "    title = module.params['title']",
            "",
            "    url = 'https://metrics-api.librato.com/v1/annotations/%s' % name",
            "    params = {}",
            "    params['title'] = title",
            "",
            "    if module.params['source'] is not None:",
            "        params['source'] = module.params['source']",
            "    if module.params['description'] is not None:",
            "        params['description'] = module.params['description']",
            "    if module.params['start_time'] is not None:",
            "        params['start_time'] = module.params['start_time']",
            "    if module.params['end_time'] is not None:",
            "        params['end_time'] = module.params['end_time']",
            "    if module.params['links'] is not None:",
            "        params['links'] = module.params['links']",
            "",
            "    json_body = module.jsonify(params)",
            "",
            "    headers = {}",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Hack send parameters the way fetch_url wants them",
            "    module.params['url_username'] = user",
            "    module.params['url_password'] = api_key",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    response_body = info['body']",
            "    if info['status'] != 201:",
            "        if info['status'] >= 400:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code + \" Response body: \" + response_body)",
            "        else:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code)",
            "    response = response.read()",
            "    module.exit_json(changed=True, annotation=response)",
            "",
            "",
            "def main():",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            user=dict(required=True),",
            "            api_key=dict(required=True, no_log=True),",
            "            name=dict(required=False),",
            "            title=dict(required=True),",
            "            source=dict(required=False),",
            "            description=dict(required=False),",
            "            start_time=dict(required=False, default=None, type='int'),",
            "            end_time=dict(required=False, default=None, type='int'),",
            "            links=dict(type='list')",
            "        )",
            "    )",
            "",
            "    post_annotation(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "149": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/monitoring/pagerduty_alert.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "             name=dict(required=False),"
            },
            "2": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "             service_id=dict(required=True),"
            },
            "3": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            service_key=dict(required=False),"
            },
            "4": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            integration_key=dict(required=False),"
            },
            "5": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            api_key=dict(required=True),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+            service_key=dict(required=False, no_log=True),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+            integration_key=dict(required=False, no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+            api_key=dict(required=True, no_log=True),"
            },
            "9": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 196,
                "PatchRowcode": "             state=dict(required=True,"
            },
            "10": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "                        choices=['triggered', 'acknowledged', 'resolved']),"
            },
            "11": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "             client=dict(required=False, default=None),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "",
            "module: pagerduty_alert",
            "short_description: Trigger, acknowledge or resolve PagerDuty incidents",
            "description:",
            "    - This module will let you trigger, acknowledge or resolve a PagerDuty incident by sending events",
            "version_added: \"1.9\"",
            "author:",
            "    - \"Amanpreet Singh (@ApsOps)\"",
            "requirements:",
            "    - PagerDuty API access",
            "options:",
            "    name:",
            "        description:",
            "            - PagerDuty unique subdomain. Obsolete. It is not used with PagerDuty REST v2 API.",
            "    service_id:",
            "        description:",
            "            - ID of PagerDuty service when incidents will be triggered, acknowledged or resolved.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    service_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services. Obsolete. Please use I(integration_key).",
            "    integration_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services.",
            "            - This is the \"integration key\" listed on a \"Integrations\" tab of PagerDuty service.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    state:",
            "        description:",
            "            - Type of event to be sent.",
            "        required: true",
            "        choices:",
            "            - 'triggered'",
            "            - 'acknowledged'",
            "            - 'resolved'",
            "    api_key:",
            "        description:",
            "            - The pagerduty API key (readonly access), generated on the pagerduty site.",
            "        required: true",
            "    desc:",
            "        description:",
            "            - For C(triggered) I(state) - Required. Short description of the problem that led to this trigger. This field (or a truncated version)",
            "              will be used when generating phone calls, SMS messages and alert emails. It will also appear on the incidents tables in the PagerDuty UI.",
            "              The maximum length is 1024 characters.",
            "            - For C(acknowledged) or C(resolved) I(state) - Text that will appear in the incident's log associated with this event.",
            "        required: false",
            "        default: Created via Ansible",
            "    incident_key:",
            "        description:",
            "            - Identifies the incident to which this I(state) should be applied.",
            "            - For C(triggered) I(state) - If there's no open (i.e. unresolved) incident with this key, a new one will be created. If there's already an",
            "              open incident with a matching key, this event will be appended to that incident's log. The event key provides an easy way to \"de-dup\"",
            "              problem reports.",
            "            - For C(acknowledged) or C(resolved) I(state) - This should be the incident_key you received back when the incident was first opened by a",
            "              trigger event. Acknowledge events referencing resolved or nonexistent incidents will be discarded.",
            "        required: false",
            "        version_added: \"2.7\"",
            "    client:",
            "        description:",
            "        - The name of the monitoring client that is triggering this event.",
            "        required: false",
            "    client_url:",
            "        description:",
            "        -  The URL of the monitoring client that is triggering this event.",
            "        required: false",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Trigger an incident with just the basic options",
            "- pagerduty_alert:",
            "    name: companyabc",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "",
            "# Trigger an incident with more options",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "    incident_key: somekey",
            "    client: Sample Monitoring Service",
            "    client_url: http://service.example.com",
            "",
            "# Acknowledge an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: acknowledged",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "",
            "# Resolve an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: resolved",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "'''",
            "import json",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlparse, urlencode, urlunparse",
            "",
            "",
            "def check(module, name, state, service_id, integration_key, api_key, incident_key=None, http_call=fetch_url):",
            "    url = 'https://api.pagerduty.com/incidents'",
            "    headers = {",
            "        \"Content-type\": \"application/json\",",
            "        \"Authorization\": \"Token token=%s\" % api_key,",
            "        'Accept': 'application/vnd.pagerduty+json;version=2'",
            "    }",
            "",
            "    params = {",
            "        'service_ids[]': service_id,",
            "        'sort_by': 'incident_number:desc',",
            "        'time_zone': 'UTC'",
            "    }",
            "    if incident_key:",
            "        params['incident_key'] = incident_key",
            "",
            "    url_parts = list(urlparse(url))",
            "    url_parts[4] = urlencode(params, True)",
            "",
            "    url = urlunparse(url_parts)",
            "",
            "    response, info = http_call(module, url, method='get', headers=headers)",
            "",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to check current incident status.\"",
            "                             \"Reason: %s\" % info['msg'])",
            "    json_out = json.loads(response.read())[\"incidents\"][0]",
            "",
            "    if state != json_out[\"status\"]:",
            "        return json_out, True",
            "    return json_out, False",
            "",
            "",
            "def send_event(module, service_key, event_type, desc,",
            "               incident_key=None, client=None, client_url=None):",
            "    url = \"https://events.pagerduty.com/generic/2010-04-15/create_event.json\"",
            "    headers = {",
            "        \"Content-type\": \"application/json\"",
            "    }",
            "",
            "    data = {",
            "        \"service_key\": service_key,",
            "        \"event_type\": event_type,",
            "        \"incident_key\": incident_key,",
            "        \"description\": desc,",
            "        \"client\": client,",
            "        \"client_url\": client_url",
            "    }",
            "",
            "    response, info = fetch_url(module, url, method='post',",
            "                               headers=headers, data=json.dumps(data))",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to %s. Reason: %s\" %",
            "                         (event_type, info['msg']))",
            "    json_out = json.loads(response.read())",
            "    return json_out",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            name=dict(required=False),",
            "            service_id=dict(required=True),",
            "            service_key=dict(required=False),",
            "            integration_key=dict(required=False),",
            "            api_key=dict(required=True),",
            "            state=dict(required=True,",
            "                       choices=['triggered', 'acknowledged', 'resolved']),",
            "            client=dict(required=False, default=None),",
            "            client_url=dict(required=False, default=None),",
            "            desc=dict(required=False, default='Created via Ansible'),",
            "            incident_key=dict(required=False, default=None)",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    name = module.params['name']",
            "    service_id = module.params['service_id']",
            "    integration_key = module.params['integration_key']",
            "    service_key = module.params['service_key']",
            "    api_key = module.params['api_key']",
            "    state = module.params['state']",
            "    client = module.params['client']",
            "    client_url = module.params['client_url']",
            "    desc = module.params['desc']",
            "    incident_key = module.params['incident_key']",
            "",
            "    if integration_key is None:",
            "        if service_key is not None:",
            "            integration_key = service_key",
            "            module.warn('\"service_key\" is obsolete parameter and will be removed.'",
            "                        ' Please, use \"integration_key\" instead')",
            "        else:",
            "            module.fail_json(msg=\"'integration_key' is required parameter\")",
            "",
            "    state_event_dict = {",
            "        'triggered': 'trigger',",
            "        'acknowledged': 'acknowledge',",
            "        'resolved': 'resolve'",
            "    }",
            "",
            "    event_type = state_event_dict[state]",
            "",
            "    if event_type != 'trigger' and incident_key is None:",
            "        module.fail_json(msg=\"incident_key is required for \"",
            "                             \"acknowledge or resolve events\")",
            "",
            "    out, changed = check(module, name, state, service_id,",
            "                         integration_key, api_key, incident_key)",
            "",
            "    if not module.check_mode and changed is True:",
            "        out = send_event(module, integration_key, event_type, desc,",
            "                         incident_key, client, client_url)",
            "",
            "    module.exit_json(result=out, changed=changed)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "",
            "module: pagerduty_alert",
            "short_description: Trigger, acknowledge or resolve PagerDuty incidents",
            "description:",
            "    - This module will let you trigger, acknowledge or resolve a PagerDuty incident by sending events",
            "version_added: \"1.9\"",
            "author:",
            "    - \"Amanpreet Singh (@ApsOps)\"",
            "requirements:",
            "    - PagerDuty API access",
            "options:",
            "    name:",
            "        description:",
            "            - PagerDuty unique subdomain. Obsolete. It is not used with PagerDuty REST v2 API.",
            "    service_id:",
            "        description:",
            "            - ID of PagerDuty service when incidents will be triggered, acknowledged or resolved.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    service_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services. Obsolete. Please use I(integration_key).",
            "    integration_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services.",
            "            - This is the \"integration key\" listed on a \"Integrations\" tab of PagerDuty service.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    state:",
            "        description:",
            "            - Type of event to be sent.",
            "        required: true",
            "        choices:",
            "            - 'triggered'",
            "            - 'acknowledged'",
            "            - 'resolved'",
            "    api_key:",
            "        description:",
            "            - The pagerduty API key (readonly access), generated on the pagerduty site.",
            "        required: true",
            "    desc:",
            "        description:",
            "            - For C(triggered) I(state) - Required. Short description of the problem that led to this trigger. This field (or a truncated version)",
            "              will be used when generating phone calls, SMS messages and alert emails. It will also appear on the incidents tables in the PagerDuty UI.",
            "              The maximum length is 1024 characters.",
            "            - For C(acknowledged) or C(resolved) I(state) - Text that will appear in the incident's log associated with this event.",
            "        required: false",
            "        default: Created via Ansible",
            "    incident_key:",
            "        description:",
            "            - Identifies the incident to which this I(state) should be applied.",
            "            - For C(triggered) I(state) - If there's no open (i.e. unresolved) incident with this key, a new one will be created. If there's already an",
            "              open incident with a matching key, this event will be appended to that incident's log. The event key provides an easy way to \"de-dup\"",
            "              problem reports.",
            "            - For C(acknowledged) or C(resolved) I(state) - This should be the incident_key you received back when the incident was first opened by a",
            "              trigger event. Acknowledge events referencing resolved or nonexistent incidents will be discarded.",
            "        required: false",
            "        version_added: \"2.7\"",
            "    client:",
            "        description:",
            "        - The name of the monitoring client that is triggering this event.",
            "        required: false",
            "    client_url:",
            "        description:",
            "        -  The URL of the monitoring client that is triggering this event.",
            "        required: false",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Trigger an incident with just the basic options",
            "- pagerduty_alert:",
            "    name: companyabc",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "",
            "# Trigger an incident with more options",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "    incident_key: somekey",
            "    client: Sample Monitoring Service",
            "    client_url: http://service.example.com",
            "",
            "# Acknowledge an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: acknowledged",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "",
            "# Resolve an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: resolved",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "'''",
            "import json",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlparse, urlencode, urlunparse",
            "",
            "",
            "def check(module, name, state, service_id, integration_key, api_key, incident_key=None, http_call=fetch_url):",
            "    url = 'https://api.pagerduty.com/incidents'",
            "    headers = {",
            "        \"Content-type\": \"application/json\",",
            "        \"Authorization\": \"Token token=%s\" % api_key,",
            "        'Accept': 'application/vnd.pagerduty+json;version=2'",
            "    }",
            "",
            "    params = {",
            "        'service_ids[]': service_id,",
            "        'sort_by': 'incident_number:desc',",
            "        'time_zone': 'UTC'",
            "    }",
            "    if incident_key:",
            "        params['incident_key'] = incident_key",
            "",
            "    url_parts = list(urlparse(url))",
            "    url_parts[4] = urlencode(params, True)",
            "",
            "    url = urlunparse(url_parts)",
            "",
            "    response, info = http_call(module, url, method='get', headers=headers)",
            "",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to check current incident status.\"",
            "                             \"Reason: %s\" % info['msg'])",
            "    json_out = json.loads(response.read())[\"incidents\"][0]",
            "",
            "    if state != json_out[\"status\"]:",
            "        return json_out, True",
            "    return json_out, False",
            "",
            "",
            "def send_event(module, service_key, event_type, desc,",
            "               incident_key=None, client=None, client_url=None):",
            "    url = \"https://events.pagerduty.com/generic/2010-04-15/create_event.json\"",
            "    headers = {",
            "        \"Content-type\": \"application/json\"",
            "    }",
            "",
            "    data = {",
            "        \"service_key\": service_key,",
            "        \"event_type\": event_type,",
            "        \"incident_key\": incident_key,",
            "        \"description\": desc,",
            "        \"client\": client,",
            "        \"client_url\": client_url",
            "    }",
            "",
            "    response, info = fetch_url(module, url, method='post',",
            "                               headers=headers, data=json.dumps(data))",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to %s. Reason: %s\" %",
            "                         (event_type, info['msg']))",
            "    json_out = json.loads(response.read())",
            "    return json_out",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            name=dict(required=False),",
            "            service_id=dict(required=True),",
            "            service_key=dict(required=False, no_log=True),",
            "            integration_key=dict(required=False, no_log=True),",
            "            api_key=dict(required=True, no_log=True),",
            "            state=dict(required=True,",
            "                       choices=['triggered', 'acknowledged', 'resolved']),",
            "            client=dict(required=False, default=None),",
            "            client_url=dict(required=False, default=None),",
            "            desc=dict(required=False, default='Created via Ansible'),",
            "            incident_key=dict(required=False, default=None)",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    name = module.params['name']",
            "    service_id = module.params['service_id']",
            "    integration_key = module.params['integration_key']",
            "    service_key = module.params['service_key']",
            "    api_key = module.params['api_key']",
            "    state = module.params['state']",
            "    client = module.params['client']",
            "    client_url = module.params['client_url']",
            "    desc = module.params['desc']",
            "    incident_key = module.params['incident_key']",
            "",
            "    if integration_key is None:",
            "        if service_key is not None:",
            "            integration_key = service_key",
            "            module.warn('\"service_key\" is obsolete parameter and will be removed.'",
            "                        ' Please, use \"integration_key\" instead')",
            "        else:",
            "            module.fail_json(msg=\"'integration_key' is required parameter\")",
            "",
            "    state_event_dict = {",
            "        'triggered': 'trigger',",
            "        'acknowledged': 'acknowledge',",
            "        'resolved': 'resolve'",
            "    }",
            "",
            "    event_type = state_event_dict[state]",
            "",
            "    if event_type != 'trigger' and incident_key is None:",
            "        module.fail_json(msg=\"incident_key is required for \"",
            "                             \"acknowledge or resolve events\")",
            "",
            "    out, changed = check(module, name, state, service_id,",
            "                         integration_key, api_key, incident_key)",
            "",
            "    if not module.check_mode and changed is True:",
            "        out = send_event(module, integration_key, event_type, desc,",
            "                         incident_key, client, client_url)",
            "",
            "    module.exit_json(result=out, changed=changed)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "193": [
                "main"
            ],
            "194": [
                "main"
            ],
            "195": [
                "main"
            ]
        },
        "addLocation": []
    }
}