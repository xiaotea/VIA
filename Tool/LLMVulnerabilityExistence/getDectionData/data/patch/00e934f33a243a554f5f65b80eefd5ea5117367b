{
    "src/zenml/artifact_stores/base_artifact_store.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " #  permissions and limitations under the License."
            },
            "1": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " \"\"\"The base interface to extend the ZenML artifact store.\"\"\""
            },
            "2": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+import inspect"
            },
            "4": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import textwrap"
            },
            "5": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from abc import abstractmethod"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+from pathlib import Path"
            },
            "7": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from typing import ("
            },
            "8": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     Any,"
            },
            "9": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "     Callable,"
            },
            "10": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " PathType = Union[bytes, str]"
            },
            "11": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _sanitize_potential_path(potential_path: Any) -> Any:"
            },
            "14": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Sanitizes the input if it is a path."
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+class _sanitize_paths:"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+    \"\"\"Sanitizes path inputs before calling the original function."
            },
            "17": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    If the input is a **remote** path, this function replaces backslash path"
            },
            "19": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    separators by forward slashes."
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+    Extra decoration layer is needed to pass in fixed artifact store root"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+    path for static methods that are called on filesystems directly."
            },
            "22": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "     Args:"
            },
            "24": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        potential_path: Value that potentially refers to a (remote) path."
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+        func: The function to decorate."
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        fixed_root_path: The fixed artifact store root path."
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+        is_static: Whether the function is static or not."
            },
            "28": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 59,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "     Returns:"
            },
            "30": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        The original input or a sanitized version of it in case of a remote"
            },
            "31": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path."
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+        Function that calls the input function with sanitized path inputs."
            },
            "33": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "     \"\"\""
            },
            "34": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if isinstance(potential_path, bytes):"
            },
            "35": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path = fileio.convert_to_str(potential_path)"
            },
            "36": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    elif isinstance(potential_path, str):"
            },
            "37": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path = potential_path"
            },
            "38": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    else:"
            },
            "39": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Neither string nor bytes, this is not a path"
            },
            "40": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return potential_path"
            },
            "41": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if io_utils.is_remote(path):"
            },
            "43": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # If we have a remote path, replace windows path separators with"
            },
            "44": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # slashes"
            },
            "45": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        import ntpath"
            },
            "46": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        import posixpath"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+    def __init__(self, func: Callable[..., Any], fixed_root_path: str) -> None:"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+        \"\"\"Initializes the decorator."
            },
            "49": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path = path.replace(ntpath.sep, posixpath.sep)"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+        Args:"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+            func: The function to decorate."
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+            fixed_root_path: The fixed artifact store root path."
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+        \"\"\""
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+        self.func = func"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+        self.fixed_root_path = fixed_root_path"
            },
            "57": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return path"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+        self.path_args: List[int] = []"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+        self.path_kwargs: List[str] = []"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+        for i, param in enumerate("
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+            inspect.signature(self.func).parameters.values()"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+        ):"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+            if param.annotation == PathType:"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+                self.path_kwargs.append(param.name)"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+                if param.default == inspect.Parameter.empty:"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+                    self.path_args.append(i)"
            },
            "68": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 83,
                "PatchRowcode": " "
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+    def _validate_path(self, path: str) -> None:"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+        \"\"\"Validates a path."
            },
            "71": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 86,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _sanitize_paths(_func: Callable[..., Any]) -> Callable[..., Any]:"
            },
            "73": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Sanitizes path inputs before calling the original function."
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+        Args:"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+            path: The path to validate."
            },
            "76": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 89,
                "PatchRowcode": " "
            },
            "77": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Args:"
            },
            "78": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        _func: The function for which to sanitize the inputs."
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+        Raises:"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            FileNotFoundError: If the path is outside of the artifact store"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+                bounds."
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+        \"\"\""
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+        if not path.startswith(self.fixed_root_path):"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+            raise FileNotFoundError("
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+                f\"File `{path}` is outside of \""
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+                f\"artifact store bounds `{self.fixed_root_path}`\""
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+            )"
            },
            "88": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 99,
                "PatchRowcode": " "
            },
            "89": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Returns:"
            },
            "90": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        Function that calls the input function with sanitized path inputs."
            },
            "91": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+    def _sanitize_potential_path(self, potential_path: Any) -> Any:"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+        \"\"\"Sanitizes the input if it is a path."
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+        If the input is a **remote** path, this function replaces backslash path"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+        separators by forward slashes."
            },
            "97": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 105,
                "PatchRowcode": " "
            },
            "98": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def inner_function(*args: Any, **kwargs: Any) -> Any:"
            },
            "99": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"\"\"Inner function."
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        Args:"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+            potential_path: Value that potentially refers to a (remote) path."
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+        Returns:"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+            The original input or a sanitized version of it in case of a remote"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+            path."
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+        \"\"\""
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+        if isinstance(potential_path, bytes):"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+            path = fileio.convert_to_str(potential_path)"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 115,
                "PatchRowcode": "+        elif isinstance(potential_path, str):"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+            path = potential_path"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        else:"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+            # Neither string nor bytes, this is not a path"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+            return potential_path"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+"
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+        if io_utils.is_remote(path):"
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+            # If we have a remote path, replace windows path separators with"
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+            # slashes"
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+            import ntpath"
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+            import posixpath"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+            path = path.replace(ntpath.sep, posixpath.sep)"
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+            self._validate_path(path)"
            },
            "123": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+        else:"
            },
            "124": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+            self._validate_path(str(Path(path).absolute().resolve()))"
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+        return path"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+    def __call__(self, *args: Any, **kwargs: Any) -> Any:"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+        \"\"\"Decorator function that sanitizes paths before calling the original function."
            },
            "130": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 136,
                "PatchRowcode": " "
            },
            "131": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "         Args:"
            },
            "132": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "             *args: Positional args."
            },
            "133": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         Returns:"
            },
            "134": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "             Output of the input function called with sanitized paths."
            },
            "135": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "         \"\"\""
            },
            "136": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        args = tuple(_sanitize_potential_path(arg) for arg in args)"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+        # verify if `self` is part of the args"
            },
            "138": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+        has_self = bool(args and isinstance(args[0], BaseArtifactStore))"
            },
            "139": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+"
            },
            "140": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+        # sanitize inputs for relevant args and kwargs, keep rest unchanged"
            },
            "141": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+        args = tuple("
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+            self._sanitize_potential_path("
            },
            "143": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+                arg,"
            },
            "144": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+            )"
            },
            "145": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+            if i + has_self in self.path_args"
            },
            "146": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+            else arg"
            },
            "147": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+            for i, arg in enumerate(args)"
            },
            "148": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+        )"
            },
            "149": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "         kwargs = {"
            },
            "150": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            key: _sanitize_potential_path(value)"
            },
            "151": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+            key: self._sanitize_potential_path("
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+                value,"
            },
            "153": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+            )"
            },
            "154": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+            if key in self.path_kwargs"
            },
            "155": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+            else value"
            },
            "156": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "             for key, value in kwargs.items()"
            },
            "157": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "         }"
            },
            "158": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 164,
                "PatchRowcode": " "
            },
            "159": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return _func(*args, **kwargs)"
            },
            "160": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "161": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return inner_function"
            },
            "162": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+        return self.func(*args, **kwargs)"
            },
            "163": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 166,
                "PatchRowcode": " "
            },
            "164": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 167,
                "PatchRowcode": " "
            },
            "165": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 168,
                "PatchRowcode": " class BaseArtifactStoreConfig(StackComponentConfig):"
            },
            "166": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             The stat descriptor."
            },
            "167": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "         \"\"\""
            },
            "168": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": 383,
                "PatchRowcode": " "
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+    @abstractmethod"
            },
            "170": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "     def size(self, path: PathType) -> Optional[int]:"
            },
            "171": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "         \"\"\"Get the size of a file in bytes."
            },
            "172": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 387,
                "PatchRowcode": " "
            },
            "173": {
                "beforePatchRowNumber": 376,
                "afterPatchRowNumber": 435,
                "PatchRowcode": "         from zenml.io.filesystem_registry import default_filesystem_registry"
            },
            "174": {
                "beforePatchRowNumber": 377,
                "afterPatchRowNumber": 436,
                "PatchRowcode": "         from zenml.io.local_filesystem import LocalFilesystem"
            },
            "175": {
                "beforePatchRowNumber": 378,
                "afterPatchRowNumber": 437,
                "PatchRowcode": " "
            },
            "176": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 438,
                "PatchRowcode": "+        overloads: Dict[str, Any] = {"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 439,
                "PatchRowcode": "+            \"SUPPORTED_SCHEMES\": self.config.SUPPORTED_SCHEMES,"
            },
            "178": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 440,
                "PatchRowcode": "+        }"
            },
            "179": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 441,
                "PatchRowcode": "+        for abc_method in inspect.getmembers(BaseArtifactStore):"
            },
            "180": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 442,
                "PatchRowcode": "+            if getattr(abc_method[1], \"__isabstractmethod__\", False):"
            },
            "181": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 443,
                "PatchRowcode": "+                sanitized_method = _sanitize_paths("
            },
            "182": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 444,
                "PatchRowcode": "+                    getattr(self, abc_method[0]), self.path"
            },
            "183": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 445,
                "PatchRowcode": "+                )"
            },
            "184": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 446,
                "PatchRowcode": "+                # prepare overloads for filesystem methods"
            },
            "185": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 447,
                "PatchRowcode": "+                overloads[abc_method[0]] = staticmethod(sanitized_method)"
            },
            "186": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 448,
                "PatchRowcode": "+"
            },
            "187": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 449,
                "PatchRowcode": "+                # decorate artifact store methods"
            },
            "188": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 450,
                "PatchRowcode": "+                setattr("
            },
            "189": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 451,
                "PatchRowcode": "+                    self,"
            },
            "190": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 452,
                "PatchRowcode": "+                    abc_method[0],"
            },
            "191": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 453,
                "PatchRowcode": "+                    sanitized_method,"
            },
            "192": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 454,
                "PatchRowcode": "+                )"
            },
            "193": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 455,
                "PatchRowcode": "+"
            },
            "194": {
                "beforePatchRowNumber": 379,
                "afterPatchRowNumber": 456,
                "PatchRowcode": "         # Local filesystem is always registered, no point in doing it again."
            },
            "195": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 457,
                "PatchRowcode": "         if isinstance(self, LocalFilesystem):"
            },
            "196": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 458,
                "PatchRowcode": "             return"
            },
            "197": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 459,
                "PatchRowcode": " "
            },
            "198": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 460,
                "PatchRowcode": "         filesystem_class = type("
            },
            "199": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.__class__.__name__,"
            },
            "200": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (BaseFilesystem,),"
            },
            "201": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {"
            },
            "202": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"SUPPORTED_SCHEMES\": self.config.SUPPORTED_SCHEMES,"
            },
            "203": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"open\": staticmethod(_sanitize_paths(self.open)),"
            },
            "204": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"copyfile\": staticmethod(_sanitize_paths(self.copyfile)),"
            },
            "205": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"exists\": staticmethod(_sanitize_paths(self.exists)),"
            },
            "206": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"glob\": staticmethod(_sanitize_paths(self.glob)),"
            },
            "207": {
                "beforePatchRowNumber": 392,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"isdir\": staticmethod(_sanitize_paths(self.isdir)),"
            },
            "208": {
                "beforePatchRowNumber": 393,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"listdir\": staticmethod(_sanitize_paths(self.listdir)),"
            },
            "209": {
                "beforePatchRowNumber": 394,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"makedirs\": staticmethod(_sanitize_paths(self.makedirs)),"
            },
            "210": {
                "beforePatchRowNumber": 395,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"mkdir\": staticmethod(_sanitize_paths(self.mkdir)),"
            },
            "211": {
                "beforePatchRowNumber": 396,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"remove\": staticmethod(_sanitize_paths(self.remove)),"
            },
            "212": {
                "beforePatchRowNumber": 397,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"rename\": staticmethod(_sanitize_paths(self.rename)),"
            },
            "213": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"rmtree\": staticmethod(_sanitize_paths(self.rmtree)),"
            },
            "214": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"size\": staticmethod(_sanitize_paths(self.size)),"
            },
            "215": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"stat\": staticmethod(_sanitize_paths(self.stat)),"
            },
            "216": {
                "beforePatchRowNumber": 401,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"walk\": staticmethod(_sanitize_paths(self.walk)),"
            },
            "217": {
                "beforePatchRowNumber": 402,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            },"
            },
            "218": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 461,
                "PatchRowcode": "+            self.__class__.__name__, (BaseFilesystem,), overloads"
            },
            "219": {
                "beforePatchRowNumber": 403,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "         )"
            },
            "220": {
                "beforePatchRowNumber": 404,
                "afterPatchRowNumber": 463,
                "PatchRowcode": " "
            },
            "221": {
                "beforePatchRowNumber": 405,
                "afterPatchRowNumber": 464,
                "PatchRowcode": "         default_filesystem_registry.register(filesystem_class)"
            }
        },
        "frontPatchFile": [
            "#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"The base interface to extend the ZenML artifact store.\"\"\"",
            "",
            "import textwrap",
            "from abc import abstractmethod",
            "from typing import (",
            "    Any,",
            "    Callable,",
            "    ClassVar,",
            "    Dict,",
            "    Iterable,",
            "    List,",
            "    Optional,",
            "    Set,",
            "    Tuple,",
            "    Type,",
            "    Union,",
            "    cast,",
            ")",
            "",
            "from pydantic import root_validator",
            "",
            "from zenml.enums import StackComponentType",
            "from zenml.exceptions import ArtifactStoreInterfaceError",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.stack import Flavor, StackComponent, StackComponentConfig",
            "from zenml.utils import io_utils",
            "",
            "logger = get_logger(__name__)",
            "",
            "PathType = Union[bytes, str]",
            "",
            "",
            "def _sanitize_potential_path(potential_path: Any) -> Any:",
            "    \"\"\"Sanitizes the input if it is a path.",
            "",
            "    If the input is a **remote** path, this function replaces backslash path",
            "    separators by forward slashes.",
            "",
            "    Args:",
            "        potential_path: Value that potentially refers to a (remote) path.",
            "",
            "    Returns:",
            "        The original input or a sanitized version of it in case of a remote",
            "        path.",
            "    \"\"\"",
            "    if isinstance(potential_path, bytes):",
            "        path = fileio.convert_to_str(potential_path)",
            "    elif isinstance(potential_path, str):",
            "        path = potential_path",
            "    else:",
            "        # Neither string nor bytes, this is not a path",
            "        return potential_path",
            "",
            "    if io_utils.is_remote(path):",
            "        # If we have a remote path, replace windows path separators with",
            "        # slashes",
            "        import ntpath",
            "        import posixpath",
            "",
            "        path = path.replace(ntpath.sep, posixpath.sep)",
            "",
            "    return path",
            "",
            "",
            "def _sanitize_paths(_func: Callable[..., Any]) -> Callable[..., Any]:",
            "    \"\"\"Sanitizes path inputs before calling the original function.",
            "",
            "    Args:",
            "        _func: The function for which to sanitize the inputs.",
            "",
            "    Returns:",
            "        Function that calls the input function with sanitized path inputs.",
            "    \"\"\"",
            "",
            "    def inner_function(*args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Inner function.",
            "",
            "        Args:",
            "            *args: Positional args.",
            "            **kwargs: Keyword args.",
            "",
            "        Returns:",
            "            Output of the input function called with sanitized paths.",
            "        \"\"\"",
            "        args = tuple(_sanitize_potential_path(arg) for arg in args)",
            "        kwargs = {",
            "            key: _sanitize_potential_path(value)",
            "            for key, value in kwargs.items()",
            "        }",
            "",
            "        return _func(*args, **kwargs)",
            "",
            "    return inner_function",
            "",
            "",
            "class BaseArtifactStoreConfig(StackComponentConfig):",
            "    \"\"\"Config class for `BaseArtifactStore`.\"\"\"",
            "",
            "    path: str",
            "",
            "    SUPPORTED_SCHEMES: ClassVar[Set[str]]",
            "",
            "    @root_validator(skip_on_failure=True)",
            "    def _ensure_artifact_store(cls, values: Dict[str, Any]) -> Any:",
            "        \"\"\"Validator function for the Artifact Stores.",
            "",
            "        Checks whether supported schemes are defined and the given path is",
            "        supported.",
            "",
            "        Args:",
            "            values: The values to validate.",
            "",
            "        Returns:",
            "            The validated values.",
            "",
            "        Raises:",
            "            ArtifactStoreInterfaceError: If the scheme is not supported.",
            "        \"\"\"",
            "        try:",
            "            getattr(cls, \"SUPPORTED_SCHEMES\")",
            "        except AttributeError:",
            "            raise ArtifactStoreInterfaceError(",
            "                textwrap.dedent(",
            "                    \"\"\"",
            "                    When you are working with any classes which subclass from",
            "                    zenml.artifact_store.BaseArtifactStore please make sure",
            "                    that your class has a ClassVar named `SUPPORTED_SCHEMES`",
            "                    which should hold a set of supported file schemes such",
            "                    as {\"s3://\"} or {\"gcs://\"}.",
            "",
            "                    Example:",
            "",
            "                    class MyArtifactStoreConfig(BaseArtifactStoreConfig):",
            "                        ...",
            "                        # Class Variables",
            "                        SUPPORTED_SCHEMES: ClassVar[Set[str]] = {\"s3://\"}",
            "                        ...",
            "                    \"\"\"",
            "                )",
            "            )",
            "        values[\"path\"] = values[\"path\"].strip(\"'\\\"`\")",
            "        if not any(",
            "            values[\"path\"].startswith(i) for i in cls.SUPPORTED_SCHEMES",
            "        ):",
            "            raise ArtifactStoreInterfaceError(",
            "                f\"The path: '{values['path']}' you defined for your \"",
            "                f\"artifact store is not supported by the implementation of \"",
            "                f\"{cls.schema()['title']}, because it does not start with \"",
            "                f\"one of its supported schemes: {cls.SUPPORTED_SCHEMES}.\"",
            "            )",
            "",
            "        return values",
            "",
            "",
            "class BaseArtifactStore(StackComponent):",
            "    \"\"\"Base class for all ZenML artifact stores.\"\"\"",
            "",
            "    @property",
            "    def config(self) -> BaseArtifactStoreConfig:",
            "        \"\"\"Returns the `BaseArtifactStoreConfig` config.",
            "",
            "        Returns:",
            "            The configuration.",
            "        \"\"\"",
            "        return cast(BaseArtifactStoreConfig, self._config)",
            "",
            "    @property",
            "    def path(self) -> str:",
            "        \"\"\"The path to the artifact store.",
            "",
            "        Returns:",
            "            The path.",
            "        \"\"\"",
            "        return self.config.path",
            "",
            "    @property",
            "    def custom_cache_key(self) -> Optional[bytes]:",
            "        \"\"\"Custom cache key.",
            "",
            "        Any artifact store can override this property in case they need",
            "        additional control over the caching behavior.",
            "",
            "        Returns:",
            "            Custom cache key.",
            "        \"\"\"",
            "        return None",
            "",
            "    # --- User interface ---",
            "    @abstractmethod",
            "    def open(self, name: PathType, mode: str = \"r\") -> Any:",
            "        \"\"\"Open a file at the given path.",
            "",
            "        Args:",
            "            name: The path of the file to open.",
            "            mode: The mode to open the file.",
            "",
            "        Returns:",
            "            The file object.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def copyfile(",
            "        self, src: PathType, dst: PathType, overwrite: bool = False",
            "    ) -> None:",
            "        \"\"\"Copy a file from the source to the destination.",
            "",
            "        Args:",
            "            src: The source path.",
            "            dst: The destination path.",
            "            overwrite: Whether to overwrite the destination file if it exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def exists(self, path: PathType) -> bool:",
            "        \"\"\"Checks if a path exists.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            `True` if the path exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def glob(self, pattern: PathType) -> List[PathType]:",
            "        \"\"\"Gets the paths that match a glob pattern.",
            "",
            "        Args:",
            "            pattern: The glob pattern.",
            "",
            "        Returns:",
            "            The list of paths that match the pattern.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def isdir(self, path: PathType) -> bool:",
            "        \"\"\"Returns whether the given path points to a directory.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            `True` if the path points to a directory.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def listdir(self, path: PathType) -> List[PathType]:",
            "        \"\"\"Returns a list of files under a given directory in the filesystem.",
            "",
            "        Args:",
            "            path: The path to list.",
            "",
            "        Returns:",
            "            The list of files under the given path.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def makedirs(self, path: PathType) -> None:",
            "        \"\"\"Make a directory at the given path, recursively creating parents.",
            "",
            "        Args:",
            "            path: The path to create.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def mkdir(self, path: PathType) -> None:",
            "        \"\"\"Make a directory at the given path; parent directory must exist.",
            "",
            "        Args:",
            "            path: The path to create.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def remove(self, path: PathType) -> None:",
            "        \"\"\"Remove the file at the given path. Dangerous operation.",
            "",
            "        Args:",
            "            path: The path to remove.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def rename(",
            "        self, src: PathType, dst: PathType, overwrite: bool = False",
            "    ) -> None:",
            "        \"\"\"Rename source file to destination file.",
            "",
            "        Args:",
            "            src: The source path.",
            "            dst: The destination path.",
            "            overwrite: Whether to overwrite the destination file if it exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def rmtree(self, path: PathType) -> None:",
            "        \"\"\"Deletes dir recursively. Dangerous operation.",
            "",
            "        Args:",
            "            path: The path to delete.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def stat(self, path: PathType) -> Any:",
            "        \"\"\"Return the stat descriptor for a given file path.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            The stat descriptor.",
            "        \"\"\"",
            "",
            "    def size(self, path: PathType) -> Optional[int]:",
            "        \"\"\"Get the size of a file in bytes.",
            "",
            "        Args:",
            "            path: The path to the file.",
            "",
            "        Returns:",
            "            The size of the file in bytes or `None` if the artifact store",
            "            does not implement the `size` method.",
            "        \"\"\"",
            "        logger.warning(",
            "            \"Cannot get size of file '%s' since the artifact store %s does not \"",
            "            \"implement the `size` method.\",",
            "            path,",
            "            self.__class__.__name__,",
            "        )",
            "        return None",
            "",
            "    @abstractmethod",
            "    def walk(",
            "        self,",
            "        top: PathType,",
            "        topdown: bool = True,",
            "        onerror: Optional[Callable[..., None]] = None,",
            "    ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:",
            "        \"\"\"Return an iterator that walks the contents of the given directory.",
            "",
            "        Args:",
            "            top: The path to walk.",
            "            topdown: Whether to walk the top-down or bottom-up.",
            "            onerror: The error handler.",
            "",
            "        Returns:",
            "            The iterator that walks the contents of the given directory.",
            "        \"\"\"",
            "",
            "    # --- Internal interface ---",
            "    def __init__(self, *args: Any, **kwargs: Any) -> None:",
            "        \"\"\"Initiate the Pydantic object and register the corresponding filesystem.",
            "",
            "        Args:",
            "            *args: The positional arguments to pass to the Pydantic object.",
            "            **kwargs: The keyword arguments to pass to the Pydantic object.",
            "        \"\"\"",
            "        super(BaseArtifactStore, self).__init__(*args, **kwargs)",
            "        self._register()",
            "",
            "    def _register(self) -> None:",
            "        \"\"\"Create and register a filesystem within the filesystem registry.\"\"\"",
            "        from zenml.io.filesystem import BaseFilesystem",
            "        from zenml.io.filesystem_registry import default_filesystem_registry",
            "        from zenml.io.local_filesystem import LocalFilesystem",
            "",
            "        # Local filesystem is always registered, no point in doing it again.",
            "        if isinstance(self, LocalFilesystem):",
            "            return",
            "",
            "        filesystem_class = type(",
            "            self.__class__.__name__,",
            "            (BaseFilesystem,),",
            "            {",
            "                \"SUPPORTED_SCHEMES\": self.config.SUPPORTED_SCHEMES,",
            "                \"open\": staticmethod(_sanitize_paths(self.open)),",
            "                \"copyfile\": staticmethod(_sanitize_paths(self.copyfile)),",
            "                \"exists\": staticmethod(_sanitize_paths(self.exists)),",
            "                \"glob\": staticmethod(_sanitize_paths(self.glob)),",
            "                \"isdir\": staticmethod(_sanitize_paths(self.isdir)),",
            "                \"listdir\": staticmethod(_sanitize_paths(self.listdir)),",
            "                \"makedirs\": staticmethod(_sanitize_paths(self.makedirs)),",
            "                \"mkdir\": staticmethod(_sanitize_paths(self.mkdir)),",
            "                \"remove\": staticmethod(_sanitize_paths(self.remove)),",
            "                \"rename\": staticmethod(_sanitize_paths(self.rename)),",
            "                \"rmtree\": staticmethod(_sanitize_paths(self.rmtree)),",
            "                \"size\": staticmethod(_sanitize_paths(self.size)),",
            "                \"stat\": staticmethod(_sanitize_paths(self.stat)),",
            "                \"walk\": staticmethod(_sanitize_paths(self.walk)),",
            "            },",
            "        )",
            "",
            "        default_filesystem_registry.register(filesystem_class)",
            "",
            "",
            "class BaseArtifactStoreFlavor(Flavor):",
            "    \"\"\"Base class for artifact store flavors.\"\"\"",
            "",
            "    @property",
            "    def type(self) -> StackComponentType:",
            "        \"\"\"Returns the flavor type.",
            "",
            "        Returns:",
            "            The flavor type.",
            "        \"\"\"",
            "        return StackComponentType.ARTIFACT_STORE",
            "",
            "    @property",
            "    def config_class(self) -> Type[StackComponentConfig]:",
            "        \"\"\"Config class for this flavor.",
            "",
            "        Returns:",
            "            The config class.",
            "        \"\"\"",
            "        return BaseArtifactStoreConfig",
            "",
            "    @property",
            "    @abstractmethod",
            "    def implementation_class(self) -> Type[\"BaseArtifactStore\"]:",
            "        \"\"\"Implementation class.",
            "",
            "        Returns:",
            "            The implementation class.",
            "        \"\"\""
        ],
        "afterPatchFile": [
            "#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"The base interface to extend the ZenML artifact store.\"\"\"",
            "",
            "import inspect",
            "import textwrap",
            "from abc import abstractmethod",
            "from pathlib import Path",
            "from typing import (",
            "    Any,",
            "    Callable,",
            "    ClassVar,",
            "    Dict,",
            "    Iterable,",
            "    List,",
            "    Optional,",
            "    Set,",
            "    Tuple,",
            "    Type,",
            "    Union,",
            "    cast,",
            ")",
            "",
            "from pydantic import root_validator",
            "",
            "from zenml.enums import StackComponentType",
            "from zenml.exceptions import ArtifactStoreInterfaceError",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.stack import Flavor, StackComponent, StackComponentConfig",
            "from zenml.utils import io_utils",
            "",
            "logger = get_logger(__name__)",
            "",
            "PathType = Union[bytes, str]",
            "",
            "",
            "class _sanitize_paths:",
            "    \"\"\"Sanitizes path inputs before calling the original function.",
            "",
            "    Extra decoration layer is needed to pass in fixed artifact store root",
            "    path for static methods that are called on filesystems directly.",
            "",
            "    Args:",
            "        func: The function to decorate.",
            "        fixed_root_path: The fixed artifact store root path.",
            "        is_static: Whether the function is static or not.",
            "",
            "    Returns:",
            "        Function that calls the input function with sanitized path inputs.",
            "    \"\"\"",
            "",
            "    def __init__(self, func: Callable[..., Any], fixed_root_path: str) -> None:",
            "        \"\"\"Initializes the decorator.",
            "",
            "        Args:",
            "            func: The function to decorate.",
            "            fixed_root_path: The fixed artifact store root path.",
            "        \"\"\"",
            "        self.func = func",
            "        self.fixed_root_path = fixed_root_path",
            "",
            "        self.path_args: List[int] = []",
            "        self.path_kwargs: List[str] = []",
            "        for i, param in enumerate(",
            "            inspect.signature(self.func).parameters.values()",
            "        ):",
            "            if param.annotation == PathType:",
            "                self.path_kwargs.append(param.name)",
            "                if param.default == inspect.Parameter.empty:",
            "                    self.path_args.append(i)",
            "",
            "    def _validate_path(self, path: str) -> None:",
            "        \"\"\"Validates a path.",
            "",
            "        Args:",
            "            path: The path to validate.",
            "",
            "        Raises:",
            "            FileNotFoundError: If the path is outside of the artifact store",
            "                bounds.",
            "        \"\"\"",
            "        if not path.startswith(self.fixed_root_path):",
            "            raise FileNotFoundError(",
            "                f\"File `{path}` is outside of \"",
            "                f\"artifact store bounds `{self.fixed_root_path}`\"",
            "            )",
            "",
            "    def _sanitize_potential_path(self, potential_path: Any) -> Any:",
            "        \"\"\"Sanitizes the input if it is a path.",
            "",
            "        If the input is a **remote** path, this function replaces backslash path",
            "        separators by forward slashes.",
            "",
            "        Args:",
            "            potential_path: Value that potentially refers to a (remote) path.",
            "",
            "        Returns:",
            "            The original input or a sanitized version of it in case of a remote",
            "            path.",
            "        \"\"\"",
            "        if isinstance(potential_path, bytes):",
            "            path = fileio.convert_to_str(potential_path)",
            "        elif isinstance(potential_path, str):",
            "            path = potential_path",
            "        else:",
            "            # Neither string nor bytes, this is not a path",
            "            return potential_path",
            "",
            "        if io_utils.is_remote(path):",
            "            # If we have a remote path, replace windows path separators with",
            "            # slashes",
            "            import ntpath",
            "            import posixpath",
            "",
            "            path = path.replace(ntpath.sep, posixpath.sep)",
            "            self._validate_path(path)",
            "        else:",
            "            self._validate_path(str(Path(path).absolute().resolve()))",
            "",
            "        return path",
            "",
            "    def __call__(self, *args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Decorator function that sanitizes paths before calling the original function.",
            "",
            "        Args:",
            "            *args: Positional args.",
            "            **kwargs: Keyword args.",
            "",
            "        Returns:",
            "            Output of the input function called with sanitized paths.",
            "        \"\"\"",
            "        # verify if `self` is part of the args",
            "        has_self = bool(args and isinstance(args[0], BaseArtifactStore))",
            "",
            "        # sanitize inputs for relevant args and kwargs, keep rest unchanged",
            "        args = tuple(",
            "            self._sanitize_potential_path(",
            "                arg,",
            "            )",
            "            if i + has_self in self.path_args",
            "            else arg",
            "            for i, arg in enumerate(args)",
            "        )",
            "        kwargs = {",
            "            key: self._sanitize_potential_path(",
            "                value,",
            "            )",
            "            if key in self.path_kwargs",
            "            else value",
            "            for key, value in kwargs.items()",
            "        }",
            "",
            "        return self.func(*args, **kwargs)",
            "",
            "",
            "class BaseArtifactStoreConfig(StackComponentConfig):",
            "    \"\"\"Config class for `BaseArtifactStore`.\"\"\"",
            "",
            "    path: str",
            "",
            "    SUPPORTED_SCHEMES: ClassVar[Set[str]]",
            "",
            "    @root_validator(skip_on_failure=True)",
            "    def _ensure_artifact_store(cls, values: Dict[str, Any]) -> Any:",
            "        \"\"\"Validator function for the Artifact Stores.",
            "",
            "        Checks whether supported schemes are defined and the given path is",
            "        supported.",
            "",
            "        Args:",
            "            values: The values to validate.",
            "",
            "        Returns:",
            "            The validated values.",
            "",
            "        Raises:",
            "            ArtifactStoreInterfaceError: If the scheme is not supported.",
            "        \"\"\"",
            "        try:",
            "            getattr(cls, \"SUPPORTED_SCHEMES\")",
            "        except AttributeError:",
            "            raise ArtifactStoreInterfaceError(",
            "                textwrap.dedent(",
            "                    \"\"\"",
            "                    When you are working with any classes which subclass from",
            "                    zenml.artifact_store.BaseArtifactStore please make sure",
            "                    that your class has a ClassVar named `SUPPORTED_SCHEMES`",
            "                    which should hold a set of supported file schemes such",
            "                    as {\"s3://\"} or {\"gcs://\"}.",
            "",
            "                    Example:",
            "",
            "                    class MyArtifactStoreConfig(BaseArtifactStoreConfig):",
            "                        ...",
            "                        # Class Variables",
            "                        SUPPORTED_SCHEMES: ClassVar[Set[str]] = {\"s3://\"}",
            "                        ...",
            "                    \"\"\"",
            "                )",
            "            )",
            "        values[\"path\"] = values[\"path\"].strip(\"'\\\"`\")",
            "        if not any(",
            "            values[\"path\"].startswith(i) for i in cls.SUPPORTED_SCHEMES",
            "        ):",
            "            raise ArtifactStoreInterfaceError(",
            "                f\"The path: '{values['path']}' you defined for your \"",
            "                f\"artifact store is not supported by the implementation of \"",
            "                f\"{cls.schema()['title']}, because it does not start with \"",
            "                f\"one of its supported schemes: {cls.SUPPORTED_SCHEMES}.\"",
            "            )",
            "",
            "        return values",
            "",
            "",
            "class BaseArtifactStore(StackComponent):",
            "    \"\"\"Base class for all ZenML artifact stores.\"\"\"",
            "",
            "    @property",
            "    def config(self) -> BaseArtifactStoreConfig:",
            "        \"\"\"Returns the `BaseArtifactStoreConfig` config.",
            "",
            "        Returns:",
            "            The configuration.",
            "        \"\"\"",
            "        return cast(BaseArtifactStoreConfig, self._config)",
            "",
            "    @property",
            "    def path(self) -> str:",
            "        \"\"\"The path to the artifact store.",
            "",
            "        Returns:",
            "            The path.",
            "        \"\"\"",
            "        return self.config.path",
            "",
            "    @property",
            "    def custom_cache_key(self) -> Optional[bytes]:",
            "        \"\"\"Custom cache key.",
            "",
            "        Any artifact store can override this property in case they need",
            "        additional control over the caching behavior.",
            "",
            "        Returns:",
            "            Custom cache key.",
            "        \"\"\"",
            "        return None",
            "",
            "    # --- User interface ---",
            "    @abstractmethod",
            "    def open(self, name: PathType, mode: str = \"r\") -> Any:",
            "        \"\"\"Open a file at the given path.",
            "",
            "        Args:",
            "            name: The path of the file to open.",
            "            mode: The mode to open the file.",
            "",
            "        Returns:",
            "            The file object.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def copyfile(",
            "        self, src: PathType, dst: PathType, overwrite: bool = False",
            "    ) -> None:",
            "        \"\"\"Copy a file from the source to the destination.",
            "",
            "        Args:",
            "            src: The source path.",
            "            dst: The destination path.",
            "            overwrite: Whether to overwrite the destination file if it exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def exists(self, path: PathType) -> bool:",
            "        \"\"\"Checks if a path exists.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            `True` if the path exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def glob(self, pattern: PathType) -> List[PathType]:",
            "        \"\"\"Gets the paths that match a glob pattern.",
            "",
            "        Args:",
            "            pattern: The glob pattern.",
            "",
            "        Returns:",
            "            The list of paths that match the pattern.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def isdir(self, path: PathType) -> bool:",
            "        \"\"\"Returns whether the given path points to a directory.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            `True` if the path points to a directory.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def listdir(self, path: PathType) -> List[PathType]:",
            "        \"\"\"Returns a list of files under a given directory in the filesystem.",
            "",
            "        Args:",
            "            path: The path to list.",
            "",
            "        Returns:",
            "            The list of files under the given path.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def makedirs(self, path: PathType) -> None:",
            "        \"\"\"Make a directory at the given path, recursively creating parents.",
            "",
            "        Args:",
            "            path: The path to create.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def mkdir(self, path: PathType) -> None:",
            "        \"\"\"Make a directory at the given path; parent directory must exist.",
            "",
            "        Args:",
            "            path: The path to create.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def remove(self, path: PathType) -> None:",
            "        \"\"\"Remove the file at the given path. Dangerous operation.",
            "",
            "        Args:",
            "            path: The path to remove.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def rename(",
            "        self, src: PathType, dst: PathType, overwrite: bool = False",
            "    ) -> None:",
            "        \"\"\"Rename source file to destination file.",
            "",
            "        Args:",
            "            src: The source path.",
            "            dst: The destination path.",
            "            overwrite: Whether to overwrite the destination file if it exists.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def rmtree(self, path: PathType) -> None:",
            "        \"\"\"Deletes dir recursively. Dangerous operation.",
            "",
            "        Args:",
            "            path: The path to delete.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def stat(self, path: PathType) -> Any:",
            "        \"\"\"Return the stat descriptor for a given file path.",
            "",
            "        Args:",
            "            path: The path to check.",
            "",
            "        Returns:",
            "            The stat descriptor.",
            "        \"\"\"",
            "",
            "    @abstractmethod",
            "    def size(self, path: PathType) -> Optional[int]:",
            "        \"\"\"Get the size of a file in bytes.",
            "",
            "        Args:",
            "            path: The path to the file.",
            "",
            "        Returns:",
            "            The size of the file in bytes or `None` if the artifact store",
            "            does not implement the `size` method.",
            "        \"\"\"",
            "        logger.warning(",
            "            \"Cannot get size of file '%s' since the artifact store %s does not \"",
            "            \"implement the `size` method.\",",
            "            path,",
            "            self.__class__.__name__,",
            "        )",
            "        return None",
            "",
            "    @abstractmethod",
            "    def walk(",
            "        self,",
            "        top: PathType,",
            "        topdown: bool = True,",
            "        onerror: Optional[Callable[..., None]] = None,",
            "    ) -> Iterable[Tuple[PathType, List[PathType], List[PathType]]]:",
            "        \"\"\"Return an iterator that walks the contents of the given directory.",
            "",
            "        Args:",
            "            top: The path to walk.",
            "            topdown: Whether to walk the top-down or bottom-up.",
            "            onerror: The error handler.",
            "",
            "        Returns:",
            "            The iterator that walks the contents of the given directory.",
            "        \"\"\"",
            "",
            "    # --- Internal interface ---",
            "    def __init__(self, *args: Any, **kwargs: Any) -> None:",
            "        \"\"\"Initiate the Pydantic object and register the corresponding filesystem.",
            "",
            "        Args:",
            "            *args: The positional arguments to pass to the Pydantic object.",
            "            **kwargs: The keyword arguments to pass to the Pydantic object.",
            "        \"\"\"",
            "        super(BaseArtifactStore, self).__init__(*args, **kwargs)",
            "        self._register()",
            "",
            "    def _register(self) -> None:",
            "        \"\"\"Create and register a filesystem within the filesystem registry.\"\"\"",
            "        from zenml.io.filesystem import BaseFilesystem",
            "        from zenml.io.filesystem_registry import default_filesystem_registry",
            "        from zenml.io.local_filesystem import LocalFilesystem",
            "",
            "        overloads: Dict[str, Any] = {",
            "            \"SUPPORTED_SCHEMES\": self.config.SUPPORTED_SCHEMES,",
            "        }",
            "        for abc_method in inspect.getmembers(BaseArtifactStore):",
            "            if getattr(abc_method[1], \"__isabstractmethod__\", False):",
            "                sanitized_method = _sanitize_paths(",
            "                    getattr(self, abc_method[0]), self.path",
            "                )",
            "                # prepare overloads for filesystem methods",
            "                overloads[abc_method[0]] = staticmethod(sanitized_method)",
            "",
            "                # decorate artifact store methods",
            "                setattr(",
            "                    self,",
            "                    abc_method[0],",
            "                    sanitized_method,",
            "                )",
            "",
            "        # Local filesystem is always registered, no point in doing it again.",
            "        if isinstance(self, LocalFilesystem):",
            "            return",
            "",
            "        filesystem_class = type(",
            "            self.__class__.__name__, (BaseFilesystem,), overloads",
            "        )",
            "",
            "        default_filesystem_registry.register(filesystem_class)",
            "",
            "",
            "class BaseArtifactStoreFlavor(Flavor):",
            "    \"\"\"Base class for artifact store flavors.\"\"\"",
            "",
            "    @property",
            "    def type(self) -> StackComponentType:",
            "        \"\"\"Returns the flavor type.",
            "",
            "        Returns:",
            "            The flavor type.",
            "        \"\"\"",
            "        return StackComponentType.ARTIFACT_STORE",
            "",
            "    @property",
            "    def config_class(self) -> Type[StackComponentConfig]:",
            "        \"\"\"Config class for this flavor.",
            "",
            "        Returns:",
            "            The config class.",
            "        \"\"\"",
            "        return BaseArtifactStoreConfig",
            "",
            "    @property",
            "    @abstractmethod",
            "    def implementation_class(self) -> Type[\"BaseArtifactStore\"]:",
            "        \"\"\"Implementation class.",
            "",
            "        Returns:",
            "            The implementation class.",
            "        \"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "47": [
                "_sanitize_potential_path"
            ],
            "48": [
                "_sanitize_potential_path"
            ],
            "50": [
                "_sanitize_potential_path"
            ],
            "51": [
                "_sanitize_potential_path"
            ],
            "54": [
                "_sanitize_potential_path"
            ],
            "57": [
                "_sanitize_potential_path"
            ],
            "58": [
                "_sanitize_potential_path"
            ],
            "60": [
                "_sanitize_potential_path"
            ],
            "61": [
                "_sanitize_potential_path"
            ],
            "62": [
                "_sanitize_potential_path"
            ],
            "63": [
                "_sanitize_potential_path"
            ],
            "64": [
                "_sanitize_potential_path"
            ],
            "65": [
                "_sanitize_potential_path"
            ],
            "66": [
                "_sanitize_potential_path"
            ],
            "68": [
                "_sanitize_potential_path"
            ],
            "69": [
                "_sanitize_potential_path"
            ],
            "70": [
                "_sanitize_potential_path"
            ],
            "71": [
                "_sanitize_potential_path"
            ],
            "72": [
                "_sanitize_potential_path"
            ],
            "74": [
                "_sanitize_potential_path"
            ],
            "76": [
                "_sanitize_potential_path"
            ],
            "79": [
                "_sanitize_paths"
            ],
            "80": [
                "_sanitize_paths"
            ],
            "82": [
                "_sanitize_paths"
            ],
            "83": [
                "_sanitize_paths"
            ],
            "85": [
                "_sanitize_paths"
            ],
            "86": [
                "_sanitize_paths"
            ],
            "87": [
                "_sanitize_paths"
            ],
            "89": [
                "_sanitize_paths",
                "inner_function"
            ],
            "90": [
                "_sanitize_paths",
                "inner_function"
            ],
            "99": [
                "_sanitize_paths",
                "inner_function"
            ],
            "101": [
                "_sanitize_paths",
                "inner_function"
            ],
            "105": [
                "_sanitize_paths",
                "inner_function"
            ],
            "106": [
                "_sanitize_paths"
            ],
            "107": [
                "_sanitize_paths"
            ],
            "384": [
                "BaseArtifactStore",
                "_register"
            ],
            "385": [
                "BaseArtifactStore",
                "_register"
            ],
            "386": [
                "BaseArtifactStore",
                "_register"
            ],
            "387": [
                "BaseArtifactStore",
                "_register"
            ],
            "388": [
                "BaseArtifactStore",
                "_register"
            ],
            "389": [
                "BaseArtifactStore",
                "_register"
            ],
            "390": [
                "BaseArtifactStore",
                "_register"
            ],
            "391": [
                "BaseArtifactStore",
                "_register"
            ],
            "392": [
                "BaseArtifactStore",
                "_register"
            ],
            "393": [
                "BaseArtifactStore",
                "_register"
            ],
            "394": [
                "BaseArtifactStore",
                "_register"
            ],
            "395": [
                "BaseArtifactStore",
                "_register"
            ],
            "396": [
                "BaseArtifactStore",
                "_register"
            ],
            "397": [
                "BaseArtifactStore",
                "_register"
            ],
            "398": [
                "BaseArtifactStore",
                "_register"
            ],
            "399": [
                "BaseArtifactStore",
                "_register"
            ],
            "400": [
                "BaseArtifactStore",
                "_register"
            ],
            "401": [
                "BaseArtifactStore",
                "_register"
            ],
            "402": [
                "BaseArtifactStore",
                "_register"
            ]
        },
        "addLocation": []
    },
    "src/zenml/artifacts/utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "     if not uri.startswith(artifact_store.path):"
            },
            "1": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "         uri = os.path.join(artifact_store.path, uri)"
            },
            "2": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if manual_save and fileio.exists(uri):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+    if manual_save and artifact_store.exists(uri):"
            },
            "5": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "         # This check is only necessary for manual saves as we already check"
            },
            "6": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "         # it when creating the directory for step output artifacts"
            },
            "7": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "         other_artifacts = client.list_artifact_versions(uri=uri, size=1)"
            },
            "8": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "                 f\"{uri} because the URI is already used by artifact \""
            },
            "9": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "                 f\"{other_artifact.name} (version {other_artifact.version}).\""
            },
            "10": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "             )"
            },
            "11": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    fileio.makedirs(uri)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+    artifact_store.makedirs(uri)"
            },
            "13": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 166,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "     # Find and initialize the right materializer class"
            },
            "15": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "     if isinstance(materializer, type):"
            },
            "16": {
                "beforePatchRowNumber": 752,
                "afterPatchRowNumber": 752,
                "PatchRowcode": "     Raises:"
            },
            "17": {
                "beforePatchRowNumber": 753,
                "afterPatchRowNumber": 753,
                "PatchRowcode": "         DoesNotExistException: If the file does not exist in the artifact store."
            },
            "18": {
                "beforePatchRowNumber": 754,
                "afterPatchRowNumber": 754,
                "PatchRowcode": "         NotImplementedError: If the artifact store cannot open the file."
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 755,
                "PatchRowcode": "+        IOError: If the artifact store rejects the request."
            },
            "20": {
                "beforePatchRowNumber": 755,
                "afterPatchRowNumber": 756,
                "PatchRowcode": "     \"\"\""
            },
            "21": {
                "beforePatchRowNumber": 756,
                "afterPatchRowNumber": 757,
                "PatchRowcode": "     try:"
            },
            "22": {
                "beforePatchRowNumber": 757,
                "afterPatchRowNumber": 758,
                "PatchRowcode": "         with artifact_store.open(uri, mode) as text_file:"
            },
            "23": {
                "beforePatchRowNumber": 761,
                "afterPatchRowNumber": 762,
                "PatchRowcode": "             f\"File '{uri}' does not exist in artifact store \""
            },
            "24": {
                "beforePatchRowNumber": 762,
                "afterPatchRowNumber": 763,
                "PatchRowcode": "             f\"'{artifact_store.name}'.\""
            },
            "25": {
                "beforePatchRowNumber": 763,
                "afterPatchRowNumber": 764,
                "PatchRowcode": "         )"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 765,
                "PatchRowcode": "+    except IOError as e:"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 766,
                "PatchRowcode": "+        raise e"
            },
            "28": {
                "beforePatchRowNumber": 764,
                "afterPatchRowNumber": 767,
                "PatchRowcode": "     except Exception as e:"
            },
            "29": {
                "beforePatchRowNumber": 765,
                "afterPatchRowNumber": 768,
                "PatchRowcode": "         logger.exception(e)"
            },
            "30": {
                "beforePatchRowNumber": 766,
                "afterPatchRowNumber": 769,
                "PatchRowcode": "         link = \"https://docs.zenml.io/stacks-and-components/component-guide/artifact-stores/custom#enabling-artifact-visualizations-with-custom-artifact-stores\""
            },
            "31": {
                "beforePatchRowNumber": 819,
                "afterPatchRowNumber": 822,
                "PatchRowcode": "         The ML model object loaded into memory."
            },
            "32": {
                "beforePatchRowNumber": 820,
                "afterPatchRowNumber": 823,
                "PatchRowcode": "     \"\"\""
            },
            "33": {
                "beforePatchRowNumber": 821,
                "afterPatchRowNumber": 824,
                "PatchRowcode": "     # Load the model from its metadata"
            },
            "34": {
                "beforePatchRowNumber": 822,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with fileio.open("
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 825,
                "PatchRowcode": "+    artifact_store = Client().active_stack.artifact_store"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 826,
                "PatchRowcode": "+    with artifact_store.open("
            },
            "37": {
                "beforePatchRowNumber": 823,
                "afterPatchRowNumber": 827,
                "PatchRowcode": "         os.path.join(model_uri, MODEL_METADATA_YAML_FILE_NAME), \"r\""
            },
            "38": {
                "beforePatchRowNumber": 824,
                "afterPatchRowNumber": 828,
                "PatchRowcode": "     ) as f:"
            },
            "39": {
                "beforePatchRowNumber": 825,
                "afterPatchRowNumber": 829,
                "PatchRowcode": "         metadata = read_yaml(f.name)"
            }
        },
        "frontPatchFile": [
            "#  Copyright (c) ZenML GmbH 2023. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"Utility functions for handling artifacts.\"\"\"",
            "",
            "import base64",
            "import contextlib",
            "import os",
            "import tempfile",
            "import time",
            "import zipfile",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union, cast",
            "from uuid import UUID, uuid4",
            "",
            "from zenml.client import Client",
            "from zenml.constants import (",
            "    MAX_RETRIES_FOR_VERSIONED_ENTITY_CREATION,",
            "    MODEL_METADATA_YAML_FILE_NAME,",
            ")",
            "from zenml.enums import (",
            "    ExecutionStatus,",
            "    MetadataResourceTypes,",
            "    StackComponentType,",
            "    VisualizationType,",
            ")",
            "from zenml.exceptions import (",
            "    DoesNotExistException,",
            "    EntityExistsError,",
            "    StepContextError,",
            ")",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.models import (",
            "    ArtifactRequest,",
            "    ArtifactVersionRequest,",
            "    ArtifactVersionResponse,",
            "    ArtifactVisualizationRequest,",
            "    LoadedVisualization,",
            "    PipelineRunResponse,",
            "    StepRunResponse,",
            "    StepRunUpdate,",
            ")",
            "from zenml.new.steps.step_context import get_step_context",
            "from zenml.stack import StackComponent",
            "from zenml.utils import source_utils",
            "from zenml.utils.yaml_utils import read_yaml, write_yaml",
            "",
            "if TYPE_CHECKING:",
            "    from zenml.artifact_stores.base_artifact_store import BaseArtifactStore",
            "    from zenml.config.source import Source",
            "    from zenml.materializers.base_materializer import BaseMaterializer",
            "    from zenml.metadata.metadata_types import MetadataType",
            "    from zenml.zen_stores.base_zen_store import BaseZenStore",
            "",
            "    MaterializerClassOrSource = Union[str, Source, Type[BaseMaterializer]]",
            "",
            "logger = get_logger(__name__)",
            "",
            "# ----------",
            "# Public API",
            "# ----------",
            "",
            "",
            "def save_artifact(",
            "    data: Any,",
            "    name: str,",
            "    version: Optional[Union[int, str]] = None,",
            "    tags: Optional[List[str]] = None,",
            "    extract_metadata: bool = True,",
            "    include_visualizations: bool = True,",
            "    has_custom_name: bool = True,",
            "    user_metadata: Optional[Dict[str, \"MetadataType\"]] = None,",
            "    materializer: Optional[\"MaterializerClassOrSource\"] = None,",
            "    uri: Optional[str] = None,",
            "    is_model_artifact: bool = False,",
            "    is_deployment_artifact: bool = False,",
            "    manual_save: bool = True,",
            ") -> \"ArtifactVersionResponse\":",
            "    \"\"\"Upload and publish an artifact.",
            "",
            "    Args:",
            "        name: The name of the artifact.",
            "        data: The artifact data.",
            "        version: The version of the artifact. If not provided, a new",
            "            auto-incremented version will be used.",
            "        tags: Tags to associate with the artifact.",
            "        extract_metadata: If artifact metadata should be extracted and returned.",
            "        include_visualizations: If artifact visualizations should be generated.",
            "        has_custom_name: If the artifact name is custom and should be listed in",
            "            the dashboard \"Artifacts\" tab.",
            "        user_metadata: User-provided metadata to store with the artifact.",
            "        materializer: The materializer to use for saving the artifact to the",
            "            artifact store.",
            "        uri: The URI within the artifact store to upload the artifact",
            "            to. If not provided, the artifact will be uploaded to",
            "            `custom_artifacts/{name}/{version}`.",
            "        is_model_artifact: If the artifact is a model artifact.",
            "        is_deployment_artifact: If the artifact is a deployment artifact.",
            "        manual_save: If this function is called manually and should therefore",
            "            link the artifact to the current step run.",
            "",
            "    Returns:",
            "        The saved artifact response.",
            "",
            "    Raises:",
            "        RuntimeError: If artifact URI already exists.",
            "        EntityExistsError: If artifact version already exists.",
            "    \"\"\"",
            "    from zenml.materializers.materializer_registry import (",
            "        materializer_registry,",
            "    )",
            "    from zenml.utils import source_utils",
            "",
            "    client = Client()",
            "",
            "    # Get or create the artifact",
            "    try:",
            "        artifact = client.list_artifacts(name=name)[0]",
            "        if artifact.has_custom_name != has_custom_name:",
            "            client.update_artifact(",
            "                name_id_or_prefix=artifact.id, has_custom_name=has_custom_name",
            "            )",
            "    except IndexError:",
            "        try:",
            "            artifact = client.zen_store.create_artifact(",
            "                ArtifactRequest(",
            "                    name=name,",
            "                    has_custom_name=has_custom_name,",
            "                    tags=tags,",
            "                )",
            "            )",
            "        except EntityExistsError:",
            "            artifact = client.list_artifacts(name=name)[0]",
            "",
            "    # Get the current artifact store",
            "    artifact_store = client.active_stack.artifact_store",
            "",
            "    # Build and check the artifact URI",
            "    if not uri:",
            "        uri = os.path.join(\"custom_artifacts\", name, str(uuid4()))",
            "    if not uri.startswith(artifact_store.path):",
            "        uri = os.path.join(artifact_store.path, uri)",
            "",
            "    if manual_save and fileio.exists(uri):",
            "        # This check is only necessary for manual saves as we already check",
            "        # it when creating the directory for step output artifacts",
            "        other_artifacts = client.list_artifact_versions(uri=uri, size=1)",
            "        if other_artifacts and (other_artifact := other_artifacts[0]):",
            "            raise RuntimeError(",
            "                f\"Cannot save new artifact {name} version to URI \"",
            "                f\"{uri} because the URI is already used by artifact \"",
            "                f\"{other_artifact.name} (version {other_artifact.version}).\"",
            "            )",
            "    fileio.makedirs(uri)",
            "",
            "    # Find and initialize the right materializer class",
            "    if isinstance(materializer, type):",
            "        materializer_class = materializer",
            "    elif materializer:",
            "        materializer_class = source_utils.load_and_validate_class(",
            "            materializer, expected_class=BaseMaterializer",
            "        )",
            "    else:",
            "        materializer_class = materializer_registry[type(data)]",
            "    materializer_object = materializer_class(uri)",
            "",
            "    # Force URIs to have forward slashes",
            "    materializer_object.uri = materializer_object.uri.replace(\"\\\\\", \"/\")",
            "",
            "    # Save the artifact to the artifact store",
            "    data_type = type(data)",
            "    materializer_object.validate_type_compatibility(data_type)",
            "    materializer_object.save(data)",
            "",
            "    # Save visualizations of the artifact",
            "    visualizations: List[ArtifactVisualizationRequest] = []",
            "    if include_visualizations:",
            "        try:",
            "            vis_data = materializer_object.save_visualizations(data)",
            "            for vis_uri, vis_type in vis_data.items():",
            "                vis_model = ArtifactVisualizationRequest(",
            "                    type=vis_type,",
            "                    uri=vis_uri,",
            "                )",
            "                visualizations.append(vis_model)",
            "        except Exception as e:",
            "            logger.warning(",
            "                f\"Failed to save visualization for output artifact '{name}': \"",
            "                f\"{e}\"",
            "            )",
            "",
            "    # Save metadata of the artifact",
            "    artifact_metadata: Dict[str, \"MetadataType\"] = {}",
            "    if extract_metadata:",
            "        try:",
            "            artifact_metadata = materializer_object.extract_full_metadata(data)",
            "            artifact_metadata.update(user_metadata or {})",
            "        except Exception as e:",
            "            logger.warning(",
            "                f\"Failed to extract metadata for output artifact '{name}': {e}\"",
            "            )",
            "",
            "    # Create the artifact version",
            "    def _create_version() -> Optional[ArtifactVersionResponse]:",
            "        artifact_version = ArtifactVersionRequest(",
            "            artifact_id=artifact.id,",
            "            version=version,",
            "            tags=tags,",
            "            type=materializer_object.ASSOCIATED_ARTIFACT_TYPE,",
            "            uri=materializer_object.uri,",
            "            materializer=source_utils.resolve(materializer_object.__class__),",
            "            data_type=source_utils.resolve(data_type),",
            "            user=Client().active_user.id,",
            "            workspace=Client().active_workspace.id,",
            "            artifact_store_id=artifact_store.id,",
            "            visualizations=visualizations,",
            "            has_custom_name=has_custom_name,",
            "        )",
            "        try:",
            "            return client.zen_store.create_artifact_version(",
            "                artifact_version=artifact_version",
            "            )",
            "        except EntityExistsError:",
            "            return None",
            "",
            "    response = None",
            "    if not version:",
            "        retries_made = 0",
            "        for i in range(MAX_RETRIES_FOR_VERSIONED_ENTITY_CREATION):",
            "            # Get new artifact version",
            "            version = _get_new_artifact_version(name)",
            "            if response := _create_version():",
            "                break",
            "            # smoothed exponential back-off, it will go as 0.2, 0.3,",
            "            # 0.45, 0.68, 1.01, 1.52, 2.28, 3.42, 5.13, 7.69, ...",
            "            sleep = 0.2 * 1.5**i",
            "            logger.debug(",
            "                f\"Failed to create artifact version `{version}` for \"",
            "                f\"artifact `{name}`. Retrying in {sleep}...\"",
            "            )",
            "            time.sleep(sleep)",
            "            retries_made += 1",
            "        if not response:",
            "            raise EntityExistsError(",
            "                f\"Failed to create new artifact version for artifact \"",
            "                f\"`{name}`. Retried {retries_made} times. \"",
            "                \"This could be driven by exceptionally high concurrency of \"",
            "                \"pipeline runs. Please, reach out to us on ZenML Slack for support.\"",
            "            )",
            "    else:",
            "        response = _create_version()",
            "        if not response:",
            "            raise EntityExistsError(",
            "                f\"Failed to create artifact version `{version}` for artifact \"",
            "                f\"`{name}`. Given version already exists.\"",
            "            )",
            "    if artifact_metadata:",
            "        client.create_run_metadata(",
            "            metadata=artifact_metadata,",
            "            resource_id=response.id,",
            "            resource_type=MetadataResourceTypes.ARTIFACT_VERSION,",
            "        )",
            "",
            "    if manual_save:",
            "        try:",
            "            error_message = \"step run\"",
            "            step_context = get_step_context()",
            "            step_run = step_context.step_run",
            "            client.zen_store.update_run_step(",
            "                step_run_id=step_run.id,",
            "                step_run_update=StepRunUpdate(",
            "                    saved_artifact_versions={name: response.id}",
            "                ),",
            "            )",
            "            error_message = \"model\"",
            "            model = step_context.model",
            "            if model:",
            "                from zenml.model.utils import link_artifact_to_model",
            "",
            "                link_artifact_to_model(",
            "                    artifact_version_id=response.id,",
            "                    model=model,",
            "                    is_model_artifact=is_model_artifact,",
            "                    is_deployment_artifact=is_deployment_artifact,",
            "                )",
            "        except (RuntimeError, StepContextError):",
            "            logger.debug(f\"Unable to link saved artifact to {error_message}.\")",
            "",
            "    return response",
            "",
            "",
            "def load_artifact(",
            "    name_or_id: Union[str, UUID],",
            "    version: Optional[str] = None,",
            ") -> Any:",
            "    \"\"\"Load an artifact.",
            "",
            "    Args:",
            "        name_or_id: The name or ID of the artifact to load.",
            "        version: The version of the artifact to load, if `name_or_id` is a",
            "            name. If not provided, the latest version will be loaded.",
            "",
            "    Returns:",
            "        The loaded artifact.",
            "    \"\"\"",
            "    artifact = Client().get_artifact_version(name_or_id, version)",
            "    try:",
            "        step_run = get_step_context().step_run",
            "        client = Client()",
            "        client.zen_store.update_run_step(",
            "            step_run_id=step_run.id,",
            "            step_run_update=StepRunUpdate(",
            "                loaded_artifact_versions={artifact.name: artifact.id}",
            "            ),",
            "        )",
            "    except RuntimeError:",
            "        pass  # Cannot link to step run if called outside of a step",
            "    return load_artifact_from_response(artifact)",
            "",
            "",
            "def log_artifact_metadata(",
            "    metadata: Dict[str, \"MetadataType\"],",
            "    artifact_name: Optional[str] = None,",
            "    artifact_version: Optional[str] = None,",
            ") -> None:",
            "    \"\"\"Log artifact metadata.",
            "",
            "    This function can be used to log metadata for either existing artifact",
            "    versions or artifact versions that are newly created in the same step.",
            "",
            "    Args:",
            "        metadata: The metadata to log.",
            "        artifact_name: The name of the artifact to log metadata for. Can",
            "            be omitted when being called inside a step with only one output.",
            "        artifact_version: The version of the artifact to log metadata for. If",
            "            not provided, when being called inside a step that produces an",
            "            artifact named `artifact_name`, the metadata will be associated to",
            "            the corresponding newly created artifact. Or, if not provided when",
            "            being called outside of a step, or in a step that does not produce",
            "            any artifact named `artifact_name`, the metadata will be associated",
            "            to the latest version of that artifact.",
            "",
            "    Raises:",
            "        ValueError: If no artifact name is provided and the function is not",
            "            called inside a step with a single output, or, if neither an",
            "            artifact nor an output with the given name exists.",
            "    \"\"\"",
            "    try:",
            "        step_context = get_step_context()",
            "        in_step_outputs = (artifact_name in step_context._outputs) or (",
            "            not artifact_name and len(step_context._outputs) == 1",
            "        )",
            "    except RuntimeError:",
            "        step_context = None",
            "        in_step_outputs = False",
            "",
            "    if not step_context or not in_step_outputs or artifact_version:",
            "        if not artifact_name:",
            "            raise ValueError(",
            "                \"Artifact name must be provided unless the function is called \"",
            "                \"inside a step with a single output.\"",
            "            )",
            "        client = Client()",
            "        response = client.get_artifact_version(artifact_name, artifact_version)",
            "        client.create_run_metadata(",
            "            metadata=metadata,",
            "            resource_id=response.id,",
            "            resource_type=MetadataResourceTypes.ARTIFACT_VERSION,",
            "        )",
            "",
            "    else:",
            "        try:",
            "            step_context.add_output_metadata(",
            "                metadata=metadata, output_name=artifact_name",
            "            )",
            "        except StepContextError as e:",
            "            raise ValueError(e)",
            "",
            "",
            "# -----------------",
            "# End of Public API",
            "# -----------------",
            "",
            "",
            "def load_artifact_visualization(",
            "    artifact: \"ArtifactVersionResponse\",",
            "    index: int = 0,",
            "    zen_store: Optional[\"BaseZenStore\"] = None,",
            "    encode_image: bool = False,",
            ") -> LoadedVisualization:",
            "    \"\"\"Load a visualization of the given artifact.",
            "",
            "    Args:",
            "        artifact: The artifact to visualize.",
            "        index: The index of the visualization to load.",
            "        zen_store: The ZenStore to use for finding the artifact store. If not",
            "            provided, the client's ZenStore will be used.",
            "        encode_image: Whether to base64 encode image visualizations.",
            "",
            "    Returns:",
            "        The loaded visualization.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the artifact does not have the requested",
            "            visualization or if the visualization was not found in the artifact",
            "            store.",
            "    \"\"\"",
            "    # Get the visualization to load",
            "    if not artifact.visualizations:",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' has no visualizations.\"",
            "        )",
            "    if index < 0 or index >= len(artifact.visualizations):",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' only has {len(artifact.visualizations)} \"",
            "            f\"visualizations, but index {index} was requested.\"",
            "        )",
            "    visualization = artifact.visualizations[index]",
            "",
            "    # Load the visualization from the artifact's artifact store",
            "    if not artifact.artifact_store_id:",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' cannot be visualized because the \"",
            "            \"underlying artifact store was deleted.\"",
            "        )",
            "    artifact_store = _load_artifact_store(",
            "        artifact_store_id=artifact.artifact_store_id, zen_store=zen_store",
            "    )",
            "    mode = \"rb\" if visualization.type == VisualizationType.IMAGE else \"r\"",
            "    value = _load_file_from_artifact_store(",
            "        uri=visualization.uri,",
            "        artifact_store=artifact_store,",
            "        mode=mode,",
            "    )",
            "",
            "    # Encode image visualizations if requested",
            "    if visualization.type == VisualizationType.IMAGE and encode_image:",
            "        value = base64.b64encode(bytes(value))",
            "",
            "    return LoadedVisualization(type=visualization.type, value=value)",
            "",
            "",
            "def load_artifact_from_response(artifact: \"ArtifactVersionResponse\") -> Any:",
            "    \"\"\"Load the given artifact into memory.",
            "",
            "    Args:",
            "        artifact: The artifact to load.",
            "",
            "    Returns:",
            "        The artifact loaded into memory.",
            "    \"\"\"",
            "    artifact_store_loaded = False",
            "    if artifact.artifact_store_id:",
            "        try:",
            "            artifact_store_model = Client().get_stack_component(",
            "                component_type=StackComponentType.ARTIFACT_STORE,",
            "                name_id_or_prefix=artifact.artifact_store_id,",
            "            )",
            "            _ = StackComponent.from_model(artifact_store_model)",
            "            artifact_store_loaded = True",
            "        except (KeyError, ImportError):",
            "            pass",
            "",
            "    if not artifact_store_loaded:",
            "        logger.warning(",
            "            \"Unable to restore artifact store while trying to load artifact \"",
            "            \"`%s`. If this artifact is stored in a remote artifact store, \"",
            "            \"this might lead to issues when trying to load the artifact.\",",
            "            artifact.id,",
            "        )",
            "",
            "    return _load_artifact_from_uri(",
            "        materializer=artifact.materializer,",
            "        data_type=artifact.data_type,",
            "        uri=artifact.uri,",
            "    )",
            "",
            "",
            "def download_artifact_files_from_response(",
            "    artifact: \"ArtifactVersionResponse\",",
            "    path: str,",
            "    overwrite: bool = False,",
            ") -> None:",
            "    \"\"\"Download the given artifact into a file.",
            "",
            "    Args:",
            "        artifact: The artifact to download.",
            "        path: The path to which to download the artifact.",
            "        overwrite: Whether to overwrite the file if it already exists.",
            "",
            "    Raises:",
            "        FileExistsError: If the file already exists and `overwrite` is `False`.",
            "        Exception: If the artifact could not be downloaded to the zip file.",
            "    \"\"\"",
            "    if not overwrite and fileio.exists(path):",
            "        raise FileExistsError(",
            "            f\"File '{path}' already exists and `overwrite` is set to `False`.\"",
            "        )",
            "    artifact_store_loaded = False",
            "    if artifact.artifact_store_id:",
            "        with contextlib.suppress(KeyError, ImportError):",
            "            _ = Client().get_stack_component(",
            "                component_type=StackComponentType.ARTIFACT_STORE,",
            "                name_id_or_prefix=artifact.artifact_store_id,",
            "            )",
            "            artifact_store_loaded = True",
            "",
            "    if not artifact_store_loaded:",
            "        logger.warning(",
            "            \"Unable to restore artifact store while trying to load artifact \"",
            "            \"`%s`. If this artifact is stored in a remote artifact store, \"",
            "            \"this might lead to issues when trying to load the artifact.\",",
            "            artifact.id,",
            "        )",
            "",
            "    artifact_store = Client().active_stack.artifact_store",
            "    if filepaths := artifact_store.listdir(artifact.uri):",
            "        # save a zipfile to 'path' containing all the files",
            "        # in 'filepaths' with compression",
            "        try:",
            "            with zipfile.ZipFile(path, \"w\", zipfile.ZIP_DEFLATED) as zipf:",
            "                for file in filepaths:",
            "                    # Ensure 'file' is a string for path operations",
            "                    # and ZIP entry naming",
            "                    file_str = (",
            "                        file.decode() if isinstance(file, bytes) else file",
            "                    )",
            "                    file_path = str(Path(artifact.uri) / file_str)",
            "                    with artifact_store.open(",
            "                        name=file_path, mode=\"rb\"",
            "                    ) as store_file:",
            "                        # Use a loop to read and write chunks of the file",
            "                        # instead of reading the entire file into memory",
            "                        CHUNK_SIZE = 8192",
            "                        while True:",
            "                            if file_content := store_file.read(CHUNK_SIZE):",
            "                                zipf.writestr(file_str, file_content)",
            "                            else:",
            "                                break",
            "        except Exception as e:",
            "            logger.error(",
            "                f\"Failed to save artifact '{artifact.id}' to zip file \"",
            "                f\" '{path}': {e}\"",
            "            )",
            "            raise",
            "",
            "",
            "def get_producer_step_of_artifact(",
            "    artifact: \"ArtifactVersionResponse\",",
            ") -> \"StepRunResponse\":",
            "    \"\"\"Get the step run that produced a given artifact.",
            "",
            "    Args:",
            "        artifact: The artifact.",
            "",
            "    Returns:",
            "        The step run that produced the artifact.",
            "",
            "    Raises:",
            "        RuntimeError: If the run that created the artifact no longer exists.",
            "    \"\"\"",
            "    if not artifact.producer_step_run_id:",
            "        raise RuntimeError(",
            "            f\"The run that produced the artifact with id '{artifact.id}' no \"",
            "            \"longer exists. This can happen if the run was deleted.\"",
            "        )",
            "    return Client().get_run_step(artifact.producer_step_run_id)",
            "",
            "",
            "def get_artifacts_versions_of_pipeline_run(",
            "    pipeline_run: \"PipelineRunResponse\", only_produced: bool = False",
            ") -> List[\"ArtifactVersionResponse\"]:",
            "    \"\"\"Get all artifact versions produced during a pipeline run.",
            "",
            "    Args:",
            "        pipeline_run: The pipeline run.",
            "        only_produced: If only artifact versions produced by the pipeline run",
            "            should be returned or also cached artifact versions.",
            "",
            "    Returns:",
            "        A list of all artifact versions produced during the pipeline run.",
            "    \"\"\"",
            "    artifact_versions: List[\"ArtifactVersionResponse\"] = []",
            "    for step in pipeline_run.steps.values():",
            "        if not only_produced or step.status == ExecutionStatus.COMPLETED:",
            "            artifact_versions.extend(step.outputs.values())",
            "    return artifact_versions",
            "",
            "",
            "# -------------------------",
            "# Internal Helper Functions",
            "# -------------------------",
            "",
            "",
            "def _load_artifact_from_uri(",
            "    materializer: Union[\"Source\", str],",
            "    data_type: Union[\"Source\", str],",
            "    uri: str,",
            ") -> Any:",
            "    \"\"\"Load an artifact using the given materializer.",
            "",
            "    Args:",
            "        materializer: The source of the materializer class to use.",
            "        data_type: The source of the artifact data type.",
            "        uri: The uri of the artifact.",
            "",
            "    Returns:",
            "        The artifact loaded into memory.",
            "",
            "    Raises:",
            "        ModuleNotFoundError: If the materializer or data type cannot be found.",
            "    \"\"\"",
            "    from zenml.materializers.base_materializer import BaseMaterializer",
            "",
            "    # Resolve the materializer class",
            "    try:",
            "        materializer_class = source_utils.load(materializer)",
            "    except (ModuleNotFoundError, AttributeError) as e:",
            "        logger.error(",
            "            f\"ZenML cannot locate and import the materializer module \"",
            "            f\"'{materializer}' which was used to write this artifact.\"",
            "        )",
            "        raise ModuleNotFoundError(e) from e",
            "",
            "    # Resolve the artifact class",
            "    try:",
            "        artifact_class = source_utils.load(data_type)",
            "    except (ModuleNotFoundError, AttributeError) as e:",
            "        logger.error(",
            "            f\"ZenML cannot locate and import the data type of this \"",
            "            f\"artifact '{data_type}'.\"",
            "        )",
            "        raise ModuleNotFoundError(e) from e",
            "",
            "    # Load the artifact",
            "    logger.debug(",
            "        \"Using '%s' to load artifact of type '%s' from '%s'.\",",
            "        materializer_class.__qualname__,",
            "        artifact_class.__qualname__,",
            "        uri,",
            "    )",
            "    materializer_object: BaseMaterializer = materializer_class(uri)",
            "    artifact = materializer_object.load(artifact_class)",
            "    logger.debug(\"Artifact loaded successfully.\")",
            "",
            "    return artifact",
            "",
            "",
            "def _load_artifact_store(",
            "    artifact_store_id: Union[str, \"UUID\"],",
            "    zen_store: Optional[\"BaseZenStore\"] = None,",
            ") -> \"BaseArtifactStore\":",
            "    \"\"\"Load an artifact store (potentially inside the server).",
            "",
            "    Args:",
            "        artifact_store_id: The id of the artifact store to load.",
            "        zen_store: The ZenStore to use for finding the artifact store. If not",
            "            provided, the client's ZenStore will be used.",
            "",
            "    Returns:",
            "        The loaded artifact store.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the artifact store does not exist or is not",
            "            an artifact store.",
            "        NotImplementedError: If the artifact store could not be loaded.",
            "    \"\"\"",
            "    if isinstance(artifact_store_id, str):",
            "        artifact_store_id = UUID(artifact_store_id)",
            "",
            "    if zen_store is None:",
            "        zen_store = Client().zen_store",
            "",
            "    try:",
            "        artifact_store_model = zen_store.get_stack_component(artifact_store_id)",
            "    except KeyError:",
            "        raise DoesNotExistException(",
            "            f\"Artifact store '{artifact_store_id}' does not exist.\"",
            "        )",
            "",
            "    if not artifact_store_model.type == StackComponentType.ARTIFACT_STORE:",
            "        raise DoesNotExistException(",
            "            f\"Stack component '{artifact_store_id}' is not an artifact store.\"",
            "        )",
            "",
            "    try:",
            "        artifact_store = cast(",
            "            \"BaseArtifactStore\",",
            "            StackComponent.from_model(artifact_store_model),",
            "        )",
            "    except ImportError:",
            "        link = \"https://docs.zenml.io/stacks-and-components/component-guide/artifact-stores/custom#enabling-artifact-visualizations-with-custom-artifact-stores\"",
            "        raise NotImplementedError(",
            "            f\"Artifact store '{artifact_store_model.name}' could not be \"",
            "            f\"instantiated. This is likely because the artifact store's \"",
            "            f\"dependencies are not installed. For more information, see {link}.\"",
            "        )",
            "",
            "    return artifact_store",
            "",
            "",
            "def _get_new_artifact_version(artifact_name: str) -> int:",
            "    \"\"\"Get the next auto-incremented version for an artifact name.",
            "",
            "    Args:",
            "        artifact_name: The name of the artifact.",
            "",
            "    Returns:",
            "        The next auto-incremented version.",
            "    \"\"\"",
            "    artifact_versions = Client().list_artifact_versions(",
            "        name=artifact_name,",
            "        sort_by=\"desc:version_number\",",
            "        size=1,",
            "    )",
            "",
            "    # If a numbered version exists, increment it",
            "    try:",
            "        return int(artifact_versions[0].version) + 1",
            "",
            "    # If no numbered versions exist yet, start at 1",
            "    except (IndexError, ValueError):",
            "        return 1",
            "",
            "",
            "def _load_file_from_artifact_store(",
            "    uri: str,",
            "    artifact_store: \"BaseArtifactStore\",",
            "    mode: str = \"rb\",",
            ") -> Any:",
            "    \"\"\"Load the given uri from the given artifact store.",
            "",
            "    Args:",
            "        uri: The uri of the file to load.",
            "        artifact_store: The artifact store from which to load the file.",
            "        mode: The mode in which to open the file.",
            "",
            "    Returns:",
            "        The loaded file.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the file does not exist in the artifact store.",
            "        NotImplementedError: If the artifact store cannot open the file.",
            "    \"\"\"",
            "    try:",
            "        with artifact_store.open(uri, mode) as text_file:",
            "            return text_file.read()",
            "    except FileNotFoundError:",
            "        raise DoesNotExistException(",
            "            f\"File '{uri}' does not exist in artifact store \"",
            "            f\"'{artifact_store.name}'.\"",
            "        )",
            "    except Exception as e:",
            "        logger.exception(e)",
            "        link = \"https://docs.zenml.io/stacks-and-components/component-guide/artifact-stores/custom#enabling-artifact-visualizations-with-custom-artifact-stores\"",
            "        raise NotImplementedError(",
            "            f\"File '{uri}' could not be loaded because the underlying artifact \"",
            "            f\"store '{artifact_store.name}' could not open the file. This is \"",
            "            f\"likely because the authentication credentials are not configured \"",
            "            f\"in the artifact store itself. For more information, see {link}.\"",
            "        )",
            "",
            "",
            "# --------------------",
            "# Model Artifact Utils",
            "# --------------------",
            "",
            "",
            "def save_model_metadata(model_artifact: \"ArtifactVersionResponse\") -> str:",
            "    \"\"\"Save a zenml model artifact metadata to a YAML file.",
            "",
            "    This function is used to extract and save information from a zenml model",
            "    artifact such as the model type and materializer. The extracted information",
            "    will be the key to loading the model into memory in the inference",
            "    environment.",
            "",
            "    datatype: the model type. This is the path to the model class.",
            "    materializer: The path to the materializer class.",
            "",
            "    Args:",
            "        model_artifact: the artifact to extract the metadata from.",
            "",
            "    Returns:",
            "        The path to the temporary file where the model metadata is saved",
            "    \"\"\"",
            "    metadata = dict()",
            "    metadata[\"datatype\"] = model_artifact.data_type",
            "    metadata[\"materializer\"] = model_artifact.materializer",
            "",
            "    with tempfile.NamedTemporaryFile(",
            "        mode=\"w\", suffix=\".yaml\", delete=False",
            "    ) as f:",
            "        write_yaml(f.name, metadata)",
            "    return f.name",
            "",
            "",
            "def load_model_from_metadata(model_uri: str) -> Any:",
            "    \"\"\"Load a zenml model artifact from a json file.",
            "",
            "    This function is used to load information from a Yaml file that was created",
            "    by the save_model_metadata function. The information in the Yaml file is",
            "    used to load the model into memory in the inference environment.",
            "",
            "    Args:",
            "        model_uri: the artifact to extract the metadata from.",
            "",
            "    Returns:",
            "        The ML model object loaded into memory.",
            "    \"\"\"",
            "    # Load the model from its metadata",
            "    with fileio.open(",
            "        os.path.join(model_uri, MODEL_METADATA_YAML_FILE_NAME), \"r\"",
            "    ) as f:",
            "        metadata = read_yaml(f.name)",
            "    data_type = metadata[\"datatype\"]",
            "    materializer = metadata[\"materializer\"]",
            "    model = _load_artifact_from_uri(",
            "        materializer=materializer, data_type=data_type, uri=model_uri",
            "    )",
            "",
            "    # Switch to eval mode if the model is a torch model",
            "    try:",
            "        import torch.nn as nn",
            "",
            "        if isinstance(model, nn.Module):",
            "            model.eval()",
            "    except ImportError:",
            "        pass",
            "",
            "    return model"
        ],
        "afterPatchFile": [
            "#  Copyright (c) ZenML GmbH 2023. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"Utility functions for handling artifacts.\"\"\"",
            "",
            "import base64",
            "import contextlib",
            "import os",
            "import tempfile",
            "import time",
            "import zipfile",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union, cast",
            "from uuid import UUID, uuid4",
            "",
            "from zenml.client import Client",
            "from zenml.constants import (",
            "    MAX_RETRIES_FOR_VERSIONED_ENTITY_CREATION,",
            "    MODEL_METADATA_YAML_FILE_NAME,",
            ")",
            "from zenml.enums import (",
            "    ExecutionStatus,",
            "    MetadataResourceTypes,",
            "    StackComponentType,",
            "    VisualizationType,",
            ")",
            "from zenml.exceptions import (",
            "    DoesNotExistException,",
            "    EntityExistsError,",
            "    StepContextError,",
            ")",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.models import (",
            "    ArtifactRequest,",
            "    ArtifactVersionRequest,",
            "    ArtifactVersionResponse,",
            "    ArtifactVisualizationRequest,",
            "    LoadedVisualization,",
            "    PipelineRunResponse,",
            "    StepRunResponse,",
            "    StepRunUpdate,",
            ")",
            "from zenml.new.steps.step_context import get_step_context",
            "from zenml.stack import StackComponent",
            "from zenml.utils import source_utils",
            "from zenml.utils.yaml_utils import read_yaml, write_yaml",
            "",
            "if TYPE_CHECKING:",
            "    from zenml.artifact_stores.base_artifact_store import BaseArtifactStore",
            "    from zenml.config.source import Source",
            "    from zenml.materializers.base_materializer import BaseMaterializer",
            "    from zenml.metadata.metadata_types import MetadataType",
            "    from zenml.zen_stores.base_zen_store import BaseZenStore",
            "",
            "    MaterializerClassOrSource = Union[str, Source, Type[BaseMaterializer]]",
            "",
            "logger = get_logger(__name__)",
            "",
            "# ----------",
            "# Public API",
            "# ----------",
            "",
            "",
            "def save_artifact(",
            "    data: Any,",
            "    name: str,",
            "    version: Optional[Union[int, str]] = None,",
            "    tags: Optional[List[str]] = None,",
            "    extract_metadata: bool = True,",
            "    include_visualizations: bool = True,",
            "    has_custom_name: bool = True,",
            "    user_metadata: Optional[Dict[str, \"MetadataType\"]] = None,",
            "    materializer: Optional[\"MaterializerClassOrSource\"] = None,",
            "    uri: Optional[str] = None,",
            "    is_model_artifact: bool = False,",
            "    is_deployment_artifact: bool = False,",
            "    manual_save: bool = True,",
            ") -> \"ArtifactVersionResponse\":",
            "    \"\"\"Upload and publish an artifact.",
            "",
            "    Args:",
            "        name: The name of the artifact.",
            "        data: The artifact data.",
            "        version: The version of the artifact. If not provided, a new",
            "            auto-incremented version will be used.",
            "        tags: Tags to associate with the artifact.",
            "        extract_metadata: If artifact metadata should be extracted and returned.",
            "        include_visualizations: If artifact visualizations should be generated.",
            "        has_custom_name: If the artifact name is custom and should be listed in",
            "            the dashboard \"Artifacts\" tab.",
            "        user_metadata: User-provided metadata to store with the artifact.",
            "        materializer: The materializer to use for saving the artifact to the",
            "            artifact store.",
            "        uri: The URI within the artifact store to upload the artifact",
            "            to. If not provided, the artifact will be uploaded to",
            "            `custom_artifacts/{name}/{version}`.",
            "        is_model_artifact: If the artifact is a model artifact.",
            "        is_deployment_artifact: If the artifact is a deployment artifact.",
            "        manual_save: If this function is called manually and should therefore",
            "            link the artifact to the current step run.",
            "",
            "    Returns:",
            "        The saved artifact response.",
            "",
            "    Raises:",
            "        RuntimeError: If artifact URI already exists.",
            "        EntityExistsError: If artifact version already exists.",
            "    \"\"\"",
            "    from zenml.materializers.materializer_registry import (",
            "        materializer_registry,",
            "    )",
            "    from zenml.utils import source_utils",
            "",
            "    client = Client()",
            "",
            "    # Get or create the artifact",
            "    try:",
            "        artifact = client.list_artifacts(name=name)[0]",
            "        if artifact.has_custom_name != has_custom_name:",
            "            client.update_artifact(",
            "                name_id_or_prefix=artifact.id, has_custom_name=has_custom_name",
            "            )",
            "    except IndexError:",
            "        try:",
            "            artifact = client.zen_store.create_artifact(",
            "                ArtifactRequest(",
            "                    name=name,",
            "                    has_custom_name=has_custom_name,",
            "                    tags=tags,",
            "                )",
            "            )",
            "        except EntityExistsError:",
            "            artifact = client.list_artifacts(name=name)[0]",
            "",
            "    # Get the current artifact store",
            "    artifact_store = client.active_stack.artifact_store",
            "",
            "    # Build and check the artifact URI",
            "    if not uri:",
            "        uri = os.path.join(\"custom_artifacts\", name, str(uuid4()))",
            "    if not uri.startswith(artifact_store.path):",
            "        uri = os.path.join(artifact_store.path, uri)",
            "",
            "    if manual_save and artifact_store.exists(uri):",
            "        # This check is only necessary for manual saves as we already check",
            "        # it when creating the directory for step output artifacts",
            "        other_artifacts = client.list_artifact_versions(uri=uri, size=1)",
            "        if other_artifacts and (other_artifact := other_artifacts[0]):",
            "            raise RuntimeError(",
            "                f\"Cannot save new artifact {name} version to URI \"",
            "                f\"{uri} because the URI is already used by artifact \"",
            "                f\"{other_artifact.name} (version {other_artifact.version}).\"",
            "            )",
            "    artifact_store.makedirs(uri)",
            "",
            "    # Find and initialize the right materializer class",
            "    if isinstance(materializer, type):",
            "        materializer_class = materializer",
            "    elif materializer:",
            "        materializer_class = source_utils.load_and_validate_class(",
            "            materializer, expected_class=BaseMaterializer",
            "        )",
            "    else:",
            "        materializer_class = materializer_registry[type(data)]",
            "    materializer_object = materializer_class(uri)",
            "",
            "    # Force URIs to have forward slashes",
            "    materializer_object.uri = materializer_object.uri.replace(\"\\\\\", \"/\")",
            "",
            "    # Save the artifact to the artifact store",
            "    data_type = type(data)",
            "    materializer_object.validate_type_compatibility(data_type)",
            "    materializer_object.save(data)",
            "",
            "    # Save visualizations of the artifact",
            "    visualizations: List[ArtifactVisualizationRequest] = []",
            "    if include_visualizations:",
            "        try:",
            "            vis_data = materializer_object.save_visualizations(data)",
            "            for vis_uri, vis_type in vis_data.items():",
            "                vis_model = ArtifactVisualizationRequest(",
            "                    type=vis_type,",
            "                    uri=vis_uri,",
            "                )",
            "                visualizations.append(vis_model)",
            "        except Exception as e:",
            "            logger.warning(",
            "                f\"Failed to save visualization for output artifact '{name}': \"",
            "                f\"{e}\"",
            "            )",
            "",
            "    # Save metadata of the artifact",
            "    artifact_metadata: Dict[str, \"MetadataType\"] = {}",
            "    if extract_metadata:",
            "        try:",
            "            artifact_metadata = materializer_object.extract_full_metadata(data)",
            "            artifact_metadata.update(user_metadata or {})",
            "        except Exception as e:",
            "            logger.warning(",
            "                f\"Failed to extract metadata for output artifact '{name}': {e}\"",
            "            )",
            "",
            "    # Create the artifact version",
            "    def _create_version() -> Optional[ArtifactVersionResponse]:",
            "        artifact_version = ArtifactVersionRequest(",
            "            artifact_id=artifact.id,",
            "            version=version,",
            "            tags=tags,",
            "            type=materializer_object.ASSOCIATED_ARTIFACT_TYPE,",
            "            uri=materializer_object.uri,",
            "            materializer=source_utils.resolve(materializer_object.__class__),",
            "            data_type=source_utils.resolve(data_type),",
            "            user=Client().active_user.id,",
            "            workspace=Client().active_workspace.id,",
            "            artifact_store_id=artifact_store.id,",
            "            visualizations=visualizations,",
            "            has_custom_name=has_custom_name,",
            "        )",
            "        try:",
            "            return client.zen_store.create_artifact_version(",
            "                artifact_version=artifact_version",
            "            )",
            "        except EntityExistsError:",
            "            return None",
            "",
            "    response = None",
            "    if not version:",
            "        retries_made = 0",
            "        for i in range(MAX_RETRIES_FOR_VERSIONED_ENTITY_CREATION):",
            "            # Get new artifact version",
            "            version = _get_new_artifact_version(name)",
            "            if response := _create_version():",
            "                break",
            "            # smoothed exponential back-off, it will go as 0.2, 0.3,",
            "            # 0.45, 0.68, 1.01, 1.52, 2.28, 3.42, 5.13, 7.69, ...",
            "            sleep = 0.2 * 1.5**i",
            "            logger.debug(",
            "                f\"Failed to create artifact version `{version}` for \"",
            "                f\"artifact `{name}`. Retrying in {sleep}...\"",
            "            )",
            "            time.sleep(sleep)",
            "            retries_made += 1",
            "        if not response:",
            "            raise EntityExistsError(",
            "                f\"Failed to create new artifact version for artifact \"",
            "                f\"`{name}`. Retried {retries_made} times. \"",
            "                \"This could be driven by exceptionally high concurrency of \"",
            "                \"pipeline runs. Please, reach out to us on ZenML Slack for support.\"",
            "            )",
            "    else:",
            "        response = _create_version()",
            "        if not response:",
            "            raise EntityExistsError(",
            "                f\"Failed to create artifact version `{version}` for artifact \"",
            "                f\"`{name}`. Given version already exists.\"",
            "            )",
            "    if artifact_metadata:",
            "        client.create_run_metadata(",
            "            metadata=artifact_metadata,",
            "            resource_id=response.id,",
            "            resource_type=MetadataResourceTypes.ARTIFACT_VERSION,",
            "        )",
            "",
            "    if manual_save:",
            "        try:",
            "            error_message = \"step run\"",
            "            step_context = get_step_context()",
            "            step_run = step_context.step_run",
            "            client.zen_store.update_run_step(",
            "                step_run_id=step_run.id,",
            "                step_run_update=StepRunUpdate(",
            "                    saved_artifact_versions={name: response.id}",
            "                ),",
            "            )",
            "            error_message = \"model\"",
            "            model = step_context.model",
            "            if model:",
            "                from zenml.model.utils import link_artifact_to_model",
            "",
            "                link_artifact_to_model(",
            "                    artifact_version_id=response.id,",
            "                    model=model,",
            "                    is_model_artifact=is_model_artifact,",
            "                    is_deployment_artifact=is_deployment_artifact,",
            "                )",
            "        except (RuntimeError, StepContextError):",
            "            logger.debug(f\"Unable to link saved artifact to {error_message}.\")",
            "",
            "    return response",
            "",
            "",
            "def load_artifact(",
            "    name_or_id: Union[str, UUID],",
            "    version: Optional[str] = None,",
            ") -> Any:",
            "    \"\"\"Load an artifact.",
            "",
            "    Args:",
            "        name_or_id: The name or ID of the artifact to load.",
            "        version: The version of the artifact to load, if `name_or_id` is a",
            "            name. If not provided, the latest version will be loaded.",
            "",
            "    Returns:",
            "        The loaded artifact.",
            "    \"\"\"",
            "    artifact = Client().get_artifact_version(name_or_id, version)",
            "    try:",
            "        step_run = get_step_context().step_run",
            "        client = Client()",
            "        client.zen_store.update_run_step(",
            "            step_run_id=step_run.id,",
            "            step_run_update=StepRunUpdate(",
            "                loaded_artifact_versions={artifact.name: artifact.id}",
            "            ),",
            "        )",
            "    except RuntimeError:",
            "        pass  # Cannot link to step run if called outside of a step",
            "    return load_artifact_from_response(artifact)",
            "",
            "",
            "def log_artifact_metadata(",
            "    metadata: Dict[str, \"MetadataType\"],",
            "    artifact_name: Optional[str] = None,",
            "    artifact_version: Optional[str] = None,",
            ") -> None:",
            "    \"\"\"Log artifact metadata.",
            "",
            "    This function can be used to log metadata for either existing artifact",
            "    versions or artifact versions that are newly created in the same step.",
            "",
            "    Args:",
            "        metadata: The metadata to log.",
            "        artifact_name: The name of the artifact to log metadata for. Can",
            "            be omitted when being called inside a step with only one output.",
            "        artifact_version: The version of the artifact to log metadata for. If",
            "            not provided, when being called inside a step that produces an",
            "            artifact named `artifact_name`, the metadata will be associated to",
            "            the corresponding newly created artifact. Or, if not provided when",
            "            being called outside of a step, or in a step that does not produce",
            "            any artifact named `artifact_name`, the metadata will be associated",
            "            to the latest version of that artifact.",
            "",
            "    Raises:",
            "        ValueError: If no artifact name is provided and the function is not",
            "            called inside a step with a single output, or, if neither an",
            "            artifact nor an output with the given name exists.",
            "    \"\"\"",
            "    try:",
            "        step_context = get_step_context()",
            "        in_step_outputs = (artifact_name in step_context._outputs) or (",
            "            not artifact_name and len(step_context._outputs) == 1",
            "        )",
            "    except RuntimeError:",
            "        step_context = None",
            "        in_step_outputs = False",
            "",
            "    if not step_context or not in_step_outputs or artifact_version:",
            "        if not artifact_name:",
            "            raise ValueError(",
            "                \"Artifact name must be provided unless the function is called \"",
            "                \"inside a step with a single output.\"",
            "            )",
            "        client = Client()",
            "        response = client.get_artifact_version(artifact_name, artifact_version)",
            "        client.create_run_metadata(",
            "            metadata=metadata,",
            "            resource_id=response.id,",
            "            resource_type=MetadataResourceTypes.ARTIFACT_VERSION,",
            "        )",
            "",
            "    else:",
            "        try:",
            "            step_context.add_output_metadata(",
            "                metadata=metadata, output_name=artifact_name",
            "            )",
            "        except StepContextError as e:",
            "            raise ValueError(e)",
            "",
            "",
            "# -----------------",
            "# End of Public API",
            "# -----------------",
            "",
            "",
            "def load_artifact_visualization(",
            "    artifact: \"ArtifactVersionResponse\",",
            "    index: int = 0,",
            "    zen_store: Optional[\"BaseZenStore\"] = None,",
            "    encode_image: bool = False,",
            ") -> LoadedVisualization:",
            "    \"\"\"Load a visualization of the given artifact.",
            "",
            "    Args:",
            "        artifact: The artifact to visualize.",
            "        index: The index of the visualization to load.",
            "        zen_store: The ZenStore to use for finding the artifact store. If not",
            "            provided, the client's ZenStore will be used.",
            "        encode_image: Whether to base64 encode image visualizations.",
            "",
            "    Returns:",
            "        The loaded visualization.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the artifact does not have the requested",
            "            visualization or if the visualization was not found in the artifact",
            "            store.",
            "    \"\"\"",
            "    # Get the visualization to load",
            "    if not artifact.visualizations:",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' has no visualizations.\"",
            "        )",
            "    if index < 0 or index >= len(artifact.visualizations):",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' only has {len(artifact.visualizations)} \"",
            "            f\"visualizations, but index {index} was requested.\"",
            "        )",
            "    visualization = artifact.visualizations[index]",
            "",
            "    # Load the visualization from the artifact's artifact store",
            "    if not artifact.artifact_store_id:",
            "        raise DoesNotExistException(",
            "            f\"Artifact '{artifact.id}' cannot be visualized because the \"",
            "            \"underlying artifact store was deleted.\"",
            "        )",
            "    artifact_store = _load_artifact_store(",
            "        artifact_store_id=artifact.artifact_store_id, zen_store=zen_store",
            "    )",
            "    mode = \"rb\" if visualization.type == VisualizationType.IMAGE else \"r\"",
            "    value = _load_file_from_artifact_store(",
            "        uri=visualization.uri,",
            "        artifact_store=artifact_store,",
            "        mode=mode,",
            "    )",
            "",
            "    # Encode image visualizations if requested",
            "    if visualization.type == VisualizationType.IMAGE and encode_image:",
            "        value = base64.b64encode(bytes(value))",
            "",
            "    return LoadedVisualization(type=visualization.type, value=value)",
            "",
            "",
            "def load_artifact_from_response(artifact: \"ArtifactVersionResponse\") -> Any:",
            "    \"\"\"Load the given artifact into memory.",
            "",
            "    Args:",
            "        artifact: The artifact to load.",
            "",
            "    Returns:",
            "        The artifact loaded into memory.",
            "    \"\"\"",
            "    artifact_store_loaded = False",
            "    if artifact.artifact_store_id:",
            "        try:",
            "            artifact_store_model = Client().get_stack_component(",
            "                component_type=StackComponentType.ARTIFACT_STORE,",
            "                name_id_or_prefix=artifact.artifact_store_id,",
            "            )",
            "            _ = StackComponent.from_model(artifact_store_model)",
            "            artifact_store_loaded = True",
            "        except (KeyError, ImportError):",
            "            pass",
            "",
            "    if not artifact_store_loaded:",
            "        logger.warning(",
            "            \"Unable to restore artifact store while trying to load artifact \"",
            "            \"`%s`. If this artifact is stored in a remote artifact store, \"",
            "            \"this might lead to issues when trying to load the artifact.\",",
            "            artifact.id,",
            "        )",
            "",
            "    return _load_artifact_from_uri(",
            "        materializer=artifact.materializer,",
            "        data_type=artifact.data_type,",
            "        uri=artifact.uri,",
            "    )",
            "",
            "",
            "def download_artifact_files_from_response(",
            "    artifact: \"ArtifactVersionResponse\",",
            "    path: str,",
            "    overwrite: bool = False,",
            ") -> None:",
            "    \"\"\"Download the given artifact into a file.",
            "",
            "    Args:",
            "        artifact: The artifact to download.",
            "        path: The path to which to download the artifact.",
            "        overwrite: Whether to overwrite the file if it already exists.",
            "",
            "    Raises:",
            "        FileExistsError: If the file already exists and `overwrite` is `False`.",
            "        Exception: If the artifact could not be downloaded to the zip file.",
            "    \"\"\"",
            "    if not overwrite and fileio.exists(path):",
            "        raise FileExistsError(",
            "            f\"File '{path}' already exists and `overwrite` is set to `False`.\"",
            "        )",
            "    artifact_store_loaded = False",
            "    if artifact.artifact_store_id:",
            "        with contextlib.suppress(KeyError, ImportError):",
            "            _ = Client().get_stack_component(",
            "                component_type=StackComponentType.ARTIFACT_STORE,",
            "                name_id_or_prefix=artifact.artifact_store_id,",
            "            )",
            "            artifact_store_loaded = True",
            "",
            "    if not artifact_store_loaded:",
            "        logger.warning(",
            "            \"Unable to restore artifact store while trying to load artifact \"",
            "            \"`%s`. If this artifact is stored in a remote artifact store, \"",
            "            \"this might lead to issues when trying to load the artifact.\",",
            "            artifact.id,",
            "        )",
            "",
            "    artifact_store = Client().active_stack.artifact_store",
            "    if filepaths := artifact_store.listdir(artifact.uri):",
            "        # save a zipfile to 'path' containing all the files",
            "        # in 'filepaths' with compression",
            "        try:",
            "            with zipfile.ZipFile(path, \"w\", zipfile.ZIP_DEFLATED) as zipf:",
            "                for file in filepaths:",
            "                    # Ensure 'file' is a string for path operations",
            "                    # and ZIP entry naming",
            "                    file_str = (",
            "                        file.decode() if isinstance(file, bytes) else file",
            "                    )",
            "                    file_path = str(Path(artifact.uri) / file_str)",
            "                    with artifact_store.open(",
            "                        name=file_path, mode=\"rb\"",
            "                    ) as store_file:",
            "                        # Use a loop to read and write chunks of the file",
            "                        # instead of reading the entire file into memory",
            "                        CHUNK_SIZE = 8192",
            "                        while True:",
            "                            if file_content := store_file.read(CHUNK_SIZE):",
            "                                zipf.writestr(file_str, file_content)",
            "                            else:",
            "                                break",
            "        except Exception as e:",
            "            logger.error(",
            "                f\"Failed to save artifact '{artifact.id}' to zip file \"",
            "                f\" '{path}': {e}\"",
            "            )",
            "            raise",
            "",
            "",
            "def get_producer_step_of_artifact(",
            "    artifact: \"ArtifactVersionResponse\",",
            ") -> \"StepRunResponse\":",
            "    \"\"\"Get the step run that produced a given artifact.",
            "",
            "    Args:",
            "        artifact: The artifact.",
            "",
            "    Returns:",
            "        The step run that produced the artifact.",
            "",
            "    Raises:",
            "        RuntimeError: If the run that created the artifact no longer exists.",
            "    \"\"\"",
            "    if not artifact.producer_step_run_id:",
            "        raise RuntimeError(",
            "            f\"The run that produced the artifact with id '{artifact.id}' no \"",
            "            \"longer exists. This can happen if the run was deleted.\"",
            "        )",
            "    return Client().get_run_step(artifact.producer_step_run_id)",
            "",
            "",
            "def get_artifacts_versions_of_pipeline_run(",
            "    pipeline_run: \"PipelineRunResponse\", only_produced: bool = False",
            ") -> List[\"ArtifactVersionResponse\"]:",
            "    \"\"\"Get all artifact versions produced during a pipeline run.",
            "",
            "    Args:",
            "        pipeline_run: The pipeline run.",
            "        only_produced: If only artifact versions produced by the pipeline run",
            "            should be returned or also cached artifact versions.",
            "",
            "    Returns:",
            "        A list of all artifact versions produced during the pipeline run.",
            "    \"\"\"",
            "    artifact_versions: List[\"ArtifactVersionResponse\"] = []",
            "    for step in pipeline_run.steps.values():",
            "        if not only_produced or step.status == ExecutionStatus.COMPLETED:",
            "            artifact_versions.extend(step.outputs.values())",
            "    return artifact_versions",
            "",
            "",
            "# -------------------------",
            "# Internal Helper Functions",
            "# -------------------------",
            "",
            "",
            "def _load_artifact_from_uri(",
            "    materializer: Union[\"Source\", str],",
            "    data_type: Union[\"Source\", str],",
            "    uri: str,",
            ") -> Any:",
            "    \"\"\"Load an artifact using the given materializer.",
            "",
            "    Args:",
            "        materializer: The source of the materializer class to use.",
            "        data_type: The source of the artifact data type.",
            "        uri: The uri of the artifact.",
            "",
            "    Returns:",
            "        The artifact loaded into memory.",
            "",
            "    Raises:",
            "        ModuleNotFoundError: If the materializer or data type cannot be found.",
            "    \"\"\"",
            "    from zenml.materializers.base_materializer import BaseMaterializer",
            "",
            "    # Resolve the materializer class",
            "    try:",
            "        materializer_class = source_utils.load(materializer)",
            "    except (ModuleNotFoundError, AttributeError) as e:",
            "        logger.error(",
            "            f\"ZenML cannot locate and import the materializer module \"",
            "            f\"'{materializer}' which was used to write this artifact.\"",
            "        )",
            "        raise ModuleNotFoundError(e) from e",
            "",
            "    # Resolve the artifact class",
            "    try:",
            "        artifact_class = source_utils.load(data_type)",
            "    except (ModuleNotFoundError, AttributeError) as e:",
            "        logger.error(",
            "            f\"ZenML cannot locate and import the data type of this \"",
            "            f\"artifact '{data_type}'.\"",
            "        )",
            "        raise ModuleNotFoundError(e) from e",
            "",
            "    # Load the artifact",
            "    logger.debug(",
            "        \"Using '%s' to load artifact of type '%s' from '%s'.\",",
            "        materializer_class.__qualname__,",
            "        artifact_class.__qualname__,",
            "        uri,",
            "    )",
            "    materializer_object: BaseMaterializer = materializer_class(uri)",
            "    artifact = materializer_object.load(artifact_class)",
            "    logger.debug(\"Artifact loaded successfully.\")",
            "",
            "    return artifact",
            "",
            "",
            "def _load_artifact_store(",
            "    artifact_store_id: Union[str, \"UUID\"],",
            "    zen_store: Optional[\"BaseZenStore\"] = None,",
            ") -> \"BaseArtifactStore\":",
            "    \"\"\"Load an artifact store (potentially inside the server).",
            "",
            "    Args:",
            "        artifact_store_id: The id of the artifact store to load.",
            "        zen_store: The ZenStore to use for finding the artifact store. If not",
            "            provided, the client's ZenStore will be used.",
            "",
            "    Returns:",
            "        The loaded artifact store.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the artifact store does not exist or is not",
            "            an artifact store.",
            "        NotImplementedError: If the artifact store could not be loaded.",
            "    \"\"\"",
            "    if isinstance(artifact_store_id, str):",
            "        artifact_store_id = UUID(artifact_store_id)",
            "",
            "    if zen_store is None:",
            "        zen_store = Client().zen_store",
            "",
            "    try:",
            "        artifact_store_model = zen_store.get_stack_component(artifact_store_id)",
            "    except KeyError:",
            "        raise DoesNotExistException(",
            "            f\"Artifact store '{artifact_store_id}' does not exist.\"",
            "        )",
            "",
            "    if not artifact_store_model.type == StackComponentType.ARTIFACT_STORE:",
            "        raise DoesNotExistException(",
            "            f\"Stack component '{artifact_store_id}' is not an artifact store.\"",
            "        )",
            "",
            "    try:",
            "        artifact_store = cast(",
            "            \"BaseArtifactStore\",",
            "            StackComponent.from_model(artifact_store_model),",
            "        )",
            "    except ImportError:",
            "        link = \"https://docs.zenml.io/stacks-and-components/component-guide/artifact-stores/custom#enabling-artifact-visualizations-with-custom-artifact-stores\"",
            "        raise NotImplementedError(",
            "            f\"Artifact store '{artifact_store_model.name}' could not be \"",
            "            f\"instantiated. This is likely because the artifact store's \"",
            "            f\"dependencies are not installed. For more information, see {link}.\"",
            "        )",
            "",
            "    return artifact_store",
            "",
            "",
            "def _get_new_artifact_version(artifact_name: str) -> int:",
            "    \"\"\"Get the next auto-incremented version for an artifact name.",
            "",
            "    Args:",
            "        artifact_name: The name of the artifact.",
            "",
            "    Returns:",
            "        The next auto-incremented version.",
            "    \"\"\"",
            "    artifact_versions = Client().list_artifact_versions(",
            "        name=artifact_name,",
            "        sort_by=\"desc:version_number\",",
            "        size=1,",
            "    )",
            "",
            "    # If a numbered version exists, increment it",
            "    try:",
            "        return int(artifact_versions[0].version) + 1",
            "",
            "    # If no numbered versions exist yet, start at 1",
            "    except (IndexError, ValueError):",
            "        return 1",
            "",
            "",
            "def _load_file_from_artifact_store(",
            "    uri: str,",
            "    artifact_store: \"BaseArtifactStore\",",
            "    mode: str = \"rb\",",
            ") -> Any:",
            "    \"\"\"Load the given uri from the given artifact store.",
            "",
            "    Args:",
            "        uri: The uri of the file to load.",
            "        artifact_store: The artifact store from which to load the file.",
            "        mode: The mode in which to open the file.",
            "",
            "    Returns:",
            "        The loaded file.",
            "",
            "    Raises:",
            "        DoesNotExistException: If the file does not exist in the artifact store.",
            "        NotImplementedError: If the artifact store cannot open the file.",
            "        IOError: If the artifact store rejects the request.",
            "    \"\"\"",
            "    try:",
            "        with artifact_store.open(uri, mode) as text_file:",
            "            return text_file.read()",
            "    except FileNotFoundError:",
            "        raise DoesNotExistException(",
            "            f\"File '{uri}' does not exist in artifact store \"",
            "            f\"'{artifact_store.name}'.\"",
            "        )",
            "    except IOError as e:",
            "        raise e",
            "    except Exception as e:",
            "        logger.exception(e)",
            "        link = \"https://docs.zenml.io/stacks-and-components/component-guide/artifact-stores/custom#enabling-artifact-visualizations-with-custom-artifact-stores\"",
            "        raise NotImplementedError(",
            "            f\"File '{uri}' could not be loaded because the underlying artifact \"",
            "            f\"store '{artifact_store.name}' could not open the file. This is \"",
            "            f\"likely because the authentication credentials are not configured \"",
            "            f\"in the artifact store itself. For more information, see {link}.\"",
            "        )",
            "",
            "",
            "# --------------------",
            "# Model Artifact Utils",
            "# --------------------",
            "",
            "",
            "def save_model_metadata(model_artifact: \"ArtifactVersionResponse\") -> str:",
            "    \"\"\"Save a zenml model artifact metadata to a YAML file.",
            "",
            "    This function is used to extract and save information from a zenml model",
            "    artifact such as the model type and materializer. The extracted information",
            "    will be the key to loading the model into memory in the inference",
            "    environment.",
            "",
            "    datatype: the model type. This is the path to the model class.",
            "    materializer: The path to the materializer class.",
            "",
            "    Args:",
            "        model_artifact: the artifact to extract the metadata from.",
            "",
            "    Returns:",
            "        The path to the temporary file where the model metadata is saved",
            "    \"\"\"",
            "    metadata = dict()",
            "    metadata[\"datatype\"] = model_artifact.data_type",
            "    metadata[\"materializer\"] = model_artifact.materializer",
            "",
            "    with tempfile.NamedTemporaryFile(",
            "        mode=\"w\", suffix=\".yaml\", delete=False",
            "    ) as f:",
            "        write_yaml(f.name, metadata)",
            "    return f.name",
            "",
            "",
            "def load_model_from_metadata(model_uri: str) -> Any:",
            "    \"\"\"Load a zenml model artifact from a json file.",
            "",
            "    This function is used to load information from a Yaml file that was created",
            "    by the save_model_metadata function. The information in the Yaml file is",
            "    used to load the model into memory in the inference environment.",
            "",
            "    Args:",
            "        model_uri: the artifact to extract the metadata from.",
            "",
            "    Returns:",
            "        The ML model object loaded into memory.",
            "    \"\"\"",
            "    # Load the model from its metadata",
            "    artifact_store = Client().active_stack.artifact_store",
            "    with artifact_store.open(",
            "        os.path.join(model_uri, MODEL_METADATA_YAML_FILE_NAME), \"r\"",
            "    ) as f:",
            "        metadata = read_yaml(f.name)",
            "    data_type = metadata[\"datatype\"]",
            "    materializer = metadata[\"materializer\"]",
            "    model = _load_artifact_from_uri(",
            "        materializer=materializer, data_type=data_type, uri=model_uri",
            "    )",
            "",
            "    # Switch to eval mode if the model is a torch model",
            "    try:",
            "        import torch.nn as nn",
            "",
            "        if isinstance(model, nn.Module):",
            "            model.eval()",
            "    except ImportError:",
            "        pass",
            "",
            "    return model"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "155": [
                "save_artifact"
            ],
            "165": [
                "save_artifact"
            ],
            "822": [
                "load_model_from_metadata"
            ]
        },
        "addLocation": []
    },
    "src/zenml/logging/step_logging.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from uuid import uuid4"
            },
            "1": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from zenml.artifact_stores import BaseArtifactStore"
            },
            "3": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from zenml.io import fileio"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+from zenml.client import Client"
            },
            "5": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from zenml.logger import get_logger"
            },
            "6": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from zenml.logging import ("
            },
            "7": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": "     STEP_LOGS_STORAGE_INTERVAL_SECONDS,"
            },
            "8": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "     Returns:"
            },
            "9": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "         The URI of the logs file."
            },
            "10": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "     \"\"\""
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+    artifact_store = Client().active_stack.artifact_store"
            },
            "12": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     if log_key is None:"
            },
            "13": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "         log_key = str(uuid4())"
            },
            "14": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 70,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "     )"
            },
            "16": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 76,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "     # Create the dir"
            },
            "18": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if not fileio.exists(logs_base_uri):"
            },
            "19": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        fileio.makedirs(logs_base_uri)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+    if not artifact_store.exists(logs_base_uri):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+        artifact_store.makedirs(logs_base_uri)"
            },
            "22": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "     # Delete the file if it already exists"
            },
            "24": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "     logs_uri = os.path.join(logs_base_uri, f\"{log_key}.log\")"
            },
            "25": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if fileio.exists(logs_uri):"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+    if artifact_store.exists(logs_uri):"
            },
            "27": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "         logger.warning("
            },
            "28": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "             f\"Logs file {logs_uri} already exists! Removing old log file...\""
            },
            "29": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "         )"
            },
            "30": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        fileio.remove(logs_uri)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+        artifact_store.remove(logs_uri)"
            },
            "32": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "     return logs_uri"
            },
            "33": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 89,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 90,
                "PatchRowcode": " "
            },
            "35": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 136,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "     def save_to_file(self) -> None:"
            },
            "37": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "         \"\"\"Method to save the buffer to the given URI.\"\"\""
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+        artifact_store = Client().active_stack.artifact_store"
            },
            "39": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         if not self.disabled:"
            },
            "40": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "             try:"
            },
            "41": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "                 self.disabled = True"
            },
            "42": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 143,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "                 if self.buffer:"
            },
            "44": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    with fileio.open(self.logs_uri, \"a\") as file:"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+                    with artifact_store.open(self.logs_uri, \"a\") as file:"
            },
            "46": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "                         for message in self.buffer:"
            },
            "47": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "                             file.write("
            },
            "48": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "                                 remove_ansi_escape_codes(message) + \"\\n\""
            }
        },
        "frontPatchFile": [
            "#  Copyright (c) ZenML GmbH 2023. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"ZenML logging handler.\"\"\"",
            "",
            "import os",
            "import re",
            "import sys",
            "import time",
            "from contextvars import ContextVar",
            "from types import TracebackType",
            "from typing import Any, Callable, List, Optional, Type",
            "from uuid import uuid4",
            "",
            "from zenml.artifact_stores import BaseArtifactStore",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.logging import (",
            "    STEP_LOGS_STORAGE_INTERVAL_SECONDS,",
            "    STEP_LOGS_STORAGE_MAX_MESSAGES,",
            ")",
            "",
            "# Get the logger",
            "logger = get_logger(__name__)",
            "",
            "redirected: ContextVar[bool] = ContextVar(\"redirected\", default=False)",
            "",
            "",
            "def remove_ansi_escape_codes(text: str) -> str:",
            "    \"\"\"Auxiliary function to remove ANSI escape codes from a given string.",
            "",
            "    Args:",
            "        text: the input string",
            "",
            "    Returns:",
            "        the version of the input string where the escape codes are removed.",
            "    \"\"\"",
            "    ansi_escape = re.compile(r\"\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])\")",
            "    return ansi_escape.sub(\"\", text)",
            "",
            "",
            "def prepare_logs_uri(",
            "    artifact_store: \"BaseArtifactStore\",",
            "    step_name: str,",
            "    log_key: Optional[str] = None,",
            ") -> str:",
            "    \"\"\"Generates and prepares a URI for the log file for a step.",
            "",
            "    Args:",
            "        artifact_store: The artifact store on which the artifact will be stored.",
            "        step_name: Name of the step.",
            "        log_key: The unique identification key of the log file.",
            "",
            "    Returns:",
            "        The URI of the logs file.",
            "    \"\"\"",
            "    if log_key is None:",
            "        log_key = str(uuid4())",
            "",
            "    logs_base_uri = os.path.join(",
            "        artifact_store.path,",
            "        step_name,",
            "        \"logs\",",
            "    )",
            "",
            "    # Create the dir",
            "    if not fileio.exists(logs_base_uri):",
            "        fileio.makedirs(logs_base_uri)",
            "",
            "    # Delete the file if it already exists",
            "    logs_uri = os.path.join(logs_base_uri, f\"{log_key}.log\")",
            "    if fileio.exists(logs_uri):",
            "        logger.warning(",
            "            f\"Logs file {logs_uri} already exists! Removing old log file...\"",
            "        )",
            "        fileio.remove(logs_uri)",
            "    return logs_uri",
            "",
            "",
            "class StepLogsStorage:",
            "    \"\"\"Helper class which buffers and stores logs to a given URI.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        logs_uri: str,",
            "        max_messages: int = STEP_LOGS_STORAGE_MAX_MESSAGES,",
            "        time_interval: int = STEP_LOGS_STORAGE_INTERVAL_SECONDS,",
            "    ) -> None:",
            "        \"\"\"Initialization.",
            "",
            "        Args:",
            "            logs_uri: the target URI to store the logs.",
            "            max_messages: the maximum number of messages to save in the buffer.",
            "            time_interval: the amount of seconds before the buffer gets saved",
            "                automatically.",
            "        \"\"\"",
            "        # Parameters",
            "        self.logs_uri = logs_uri",
            "        self.max_messages = max_messages",
            "        self.time_interval = time_interval",
            "",
            "        # State",
            "        self.buffer: List[str] = []",
            "        self.disabled_buffer: List[str] = []",
            "        self.last_save_time = time.time()",
            "        self.disabled = False",
            "",
            "    def write(self, text: str) -> None:",
            "        \"\"\"Main write method.",
            "",
            "        Args:",
            "            text: the incoming string.",
            "        \"\"\"",
            "        if text == \"\\n\":",
            "            return",
            "",
            "        if not self.disabled:",
            "            self.buffer.append(text)",
            "",
            "            if (",
            "                len(self.buffer) >= self.max_messages",
            "                or time.time() - self.last_save_time >= self.time_interval",
            "            ):",
            "                self.save_to_file()",
            "",
            "    def save_to_file(self) -> None:",
            "        \"\"\"Method to save the buffer to the given URI.\"\"\"",
            "        if not self.disabled:",
            "            try:",
            "                self.disabled = True",
            "",
            "                if self.buffer:",
            "                    with fileio.open(self.logs_uri, \"a\") as file:",
            "                        for message in self.buffer:",
            "                            file.write(",
            "                                remove_ansi_escape_codes(message) + \"\\n\"",
            "                            )",
            "",
            "            except (OSError, IOError) as e:",
            "                # This exception can be raised if there are issues with the",
            "                # underlying system calls, such as reaching the maximum number",
            "                # of open files, permission issues, file corruption, or other",
            "                # I/O errors.",
            "                logger.error(f\"Error while trying to write logs: {e}\")",
            "            finally:",
            "                self.buffer = []",
            "                self.last_save_time = time.time()",
            "",
            "                self.disabled = False",
            "",
            "",
            "class StepLogsStorageContext:",
            "    \"\"\"Context manager which patches stdout and stderr during step execution.\"\"\"",
            "",
            "    def __init__(self, logs_uri: str) -> None:",
            "        \"\"\"Initializes and prepares a storage object.",
            "",
            "        Args:",
            "            logs_uri: the URI of the logs file.",
            "        \"\"\"",
            "        self.storage = StepLogsStorage(logs_uri=logs_uri)",
            "",
            "    def __enter__(self) -> \"StepLogsStorageContext\":",
            "        \"\"\"Enter condition of the context manager.",
            "",
            "        Wraps the `write` method of both stderr and stdout, so each incoming",
            "        message gets stored in the step logs storage.",
            "",
            "        Returns:",
            "            self",
            "        \"\"\"",
            "        self.stdout_write = getattr(sys.stdout, \"write\")",
            "        self.stdout_flush = getattr(sys.stdout, \"flush\")",
            "",
            "        self.stderr_write = getattr(sys.stderr, \"write\")",
            "        self.stderr_flush = getattr(sys.stderr, \"flush\")",
            "",
            "        setattr(sys.stdout, \"write\", self._wrap_write(self.stdout_write))",
            "        setattr(sys.stdout, \"flush\", self._wrap_flush(self.stdout_flush))",
            "",
            "        setattr(sys.stderr, \"write\", self._wrap_write(self.stdout_write))",
            "        setattr(sys.stderr, \"flush\", self._wrap_flush(self.stdout_flush))",
            "",
            "        redirected.set(True)",
            "        return self",
            "",
            "    def __exit__(",
            "        self,",
            "        exc_type: Optional[Type[BaseException]],",
            "        exc_val: Optional[BaseException],",
            "        exc_tb: Optional[TracebackType],",
            "    ) -> None:",
            "        \"\"\"Exit condition of the context manager.",
            "",
            "        Args:",
            "            exc_type: The class of the exception",
            "            exc_val: The instance of the exception",
            "            exc_tb: The traceback of the exception",
            "",
            "        Restores the `write` method of both stderr and stdout.",
            "        \"\"\"",
            "        self.storage.save_to_file()",
            "",
            "        setattr(sys.stdout, \"write\", self.stdout_write)",
            "        setattr(sys.stdout, \"flush\", self.stdout_flush)",
            "",
            "        setattr(sys.stderr, \"write\", self.stderr_write)",
            "        setattr(sys.stderr, \"flush\", self.stderr_flush)",
            "",
            "        redirected.set(False)",
            "",
            "    def _wrap_write(self, method: Callable[..., Any]) -> Callable[..., Any]:",
            "        \"\"\"Wrapper function that utilizes the storage object to store logs.",
            "",
            "        Args:",
            "            method: the original write method",
            "",
            "        Returns:",
            "            the wrapped write method.",
            "        \"\"\"",
            "",
            "        def wrapped_write(*args: Any, **kwargs: Any) -> Any:",
            "            output = method(*args, **kwargs)",
            "            if args:",
            "                self.storage.write(args[0])",
            "            return output",
            "",
            "        return wrapped_write",
            "",
            "    def _wrap_flush(self, method: Callable[..., Any]) -> Callable[..., Any]:",
            "        \"\"\"Wrapper function that flushes the buffer of the storage object.",
            "",
            "        Args:",
            "            method: the original flush method",
            "",
            "        Returns:",
            "            the wrapped flush method.",
            "        \"\"\"",
            "",
            "        def wrapped_flush(*args: Any, **kwargs: Any) -> Any:",
            "            output = method(*args, **kwargs)",
            "            self.storage.save_to_file()",
            "            return output",
            "",
            "        return wrapped_flush"
        ],
        "afterPatchFile": [
            "#  Copyright (c) ZenML GmbH 2023. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"ZenML logging handler.\"\"\"",
            "",
            "import os",
            "import re",
            "import sys",
            "import time",
            "from contextvars import ContextVar",
            "from types import TracebackType",
            "from typing import Any, Callable, List, Optional, Type",
            "from uuid import uuid4",
            "",
            "from zenml.artifact_stores import BaseArtifactStore",
            "from zenml.client import Client",
            "from zenml.logger import get_logger",
            "from zenml.logging import (",
            "    STEP_LOGS_STORAGE_INTERVAL_SECONDS,",
            "    STEP_LOGS_STORAGE_MAX_MESSAGES,",
            ")",
            "",
            "# Get the logger",
            "logger = get_logger(__name__)",
            "",
            "redirected: ContextVar[bool] = ContextVar(\"redirected\", default=False)",
            "",
            "",
            "def remove_ansi_escape_codes(text: str) -> str:",
            "    \"\"\"Auxiliary function to remove ANSI escape codes from a given string.",
            "",
            "    Args:",
            "        text: the input string",
            "",
            "    Returns:",
            "        the version of the input string where the escape codes are removed.",
            "    \"\"\"",
            "    ansi_escape = re.compile(r\"\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])\")",
            "    return ansi_escape.sub(\"\", text)",
            "",
            "",
            "def prepare_logs_uri(",
            "    artifact_store: \"BaseArtifactStore\",",
            "    step_name: str,",
            "    log_key: Optional[str] = None,",
            ") -> str:",
            "    \"\"\"Generates and prepares a URI for the log file for a step.",
            "",
            "    Args:",
            "        artifact_store: The artifact store on which the artifact will be stored.",
            "        step_name: Name of the step.",
            "        log_key: The unique identification key of the log file.",
            "",
            "    Returns:",
            "        The URI of the logs file.",
            "    \"\"\"",
            "    artifact_store = Client().active_stack.artifact_store",
            "    if log_key is None:",
            "        log_key = str(uuid4())",
            "",
            "    logs_base_uri = os.path.join(",
            "        artifact_store.path,",
            "        step_name,",
            "        \"logs\",",
            "    )",
            "",
            "    # Create the dir",
            "    if not artifact_store.exists(logs_base_uri):",
            "        artifact_store.makedirs(logs_base_uri)",
            "",
            "    # Delete the file if it already exists",
            "    logs_uri = os.path.join(logs_base_uri, f\"{log_key}.log\")",
            "    if artifact_store.exists(logs_uri):",
            "        logger.warning(",
            "            f\"Logs file {logs_uri} already exists! Removing old log file...\"",
            "        )",
            "        artifact_store.remove(logs_uri)",
            "    return logs_uri",
            "",
            "",
            "class StepLogsStorage:",
            "    \"\"\"Helper class which buffers and stores logs to a given URI.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        logs_uri: str,",
            "        max_messages: int = STEP_LOGS_STORAGE_MAX_MESSAGES,",
            "        time_interval: int = STEP_LOGS_STORAGE_INTERVAL_SECONDS,",
            "    ) -> None:",
            "        \"\"\"Initialization.",
            "",
            "        Args:",
            "            logs_uri: the target URI to store the logs.",
            "            max_messages: the maximum number of messages to save in the buffer.",
            "            time_interval: the amount of seconds before the buffer gets saved",
            "                automatically.",
            "        \"\"\"",
            "        # Parameters",
            "        self.logs_uri = logs_uri",
            "        self.max_messages = max_messages",
            "        self.time_interval = time_interval",
            "",
            "        # State",
            "        self.buffer: List[str] = []",
            "        self.disabled_buffer: List[str] = []",
            "        self.last_save_time = time.time()",
            "        self.disabled = False",
            "",
            "    def write(self, text: str) -> None:",
            "        \"\"\"Main write method.",
            "",
            "        Args:",
            "            text: the incoming string.",
            "        \"\"\"",
            "        if text == \"\\n\":",
            "            return",
            "",
            "        if not self.disabled:",
            "            self.buffer.append(text)",
            "",
            "            if (",
            "                len(self.buffer) >= self.max_messages",
            "                or time.time() - self.last_save_time >= self.time_interval",
            "            ):",
            "                self.save_to_file()",
            "",
            "    def save_to_file(self) -> None:",
            "        \"\"\"Method to save the buffer to the given URI.\"\"\"",
            "        artifact_store = Client().active_stack.artifact_store",
            "        if not self.disabled:",
            "            try:",
            "                self.disabled = True",
            "",
            "                if self.buffer:",
            "                    with artifact_store.open(self.logs_uri, \"a\") as file:",
            "                        for message in self.buffer:",
            "                            file.write(",
            "                                remove_ansi_escape_codes(message) + \"\\n\"",
            "                            )",
            "",
            "            except (OSError, IOError) as e:",
            "                # This exception can be raised if there are issues with the",
            "                # underlying system calls, such as reaching the maximum number",
            "                # of open files, permission issues, file corruption, or other",
            "                # I/O errors.",
            "                logger.error(f\"Error while trying to write logs: {e}\")",
            "            finally:",
            "                self.buffer = []",
            "                self.last_save_time = time.time()",
            "",
            "                self.disabled = False",
            "",
            "",
            "class StepLogsStorageContext:",
            "    \"\"\"Context manager which patches stdout and stderr during step execution.\"\"\"",
            "",
            "    def __init__(self, logs_uri: str) -> None:",
            "        \"\"\"Initializes and prepares a storage object.",
            "",
            "        Args:",
            "            logs_uri: the URI of the logs file.",
            "        \"\"\"",
            "        self.storage = StepLogsStorage(logs_uri=logs_uri)",
            "",
            "    def __enter__(self) -> \"StepLogsStorageContext\":",
            "        \"\"\"Enter condition of the context manager.",
            "",
            "        Wraps the `write` method of both stderr and stdout, so each incoming",
            "        message gets stored in the step logs storage.",
            "",
            "        Returns:",
            "            self",
            "        \"\"\"",
            "        self.stdout_write = getattr(sys.stdout, \"write\")",
            "        self.stdout_flush = getattr(sys.stdout, \"flush\")",
            "",
            "        self.stderr_write = getattr(sys.stderr, \"write\")",
            "        self.stderr_flush = getattr(sys.stderr, \"flush\")",
            "",
            "        setattr(sys.stdout, \"write\", self._wrap_write(self.stdout_write))",
            "        setattr(sys.stdout, \"flush\", self._wrap_flush(self.stdout_flush))",
            "",
            "        setattr(sys.stderr, \"write\", self._wrap_write(self.stdout_write))",
            "        setattr(sys.stderr, \"flush\", self._wrap_flush(self.stdout_flush))",
            "",
            "        redirected.set(True)",
            "        return self",
            "",
            "    def __exit__(",
            "        self,",
            "        exc_type: Optional[Type[BaseException]],",
            "        exc_val: Optional[BaseException],",
            "        exc_tb: Optional[TracebackType],",
            "    ) -> None:",
            "        \"\"\"Exit condition of the context manager.",
            "",
            "        Args:",
            "            exc_type: The class of the exception",
            "            exc_val: The instance of the exception",
            "            exc_tb: The traceback of the exception",
            "",
            "        Restores the `write` method of both stderr and stdout.",
            "        \"\"\"",
            "        self.storage.save_to_file()",
            "",
            "        setattr(sys.stdout, \"write\", self.stdout_write)",
            "        setattr(sys.stdout, \"flush\", self.stdout_flush)",
            "",
            "        setattr(sys.stderr, \"write\", self.stderr_write)",
            "        setattr(sys.stderr, \"flush\", self.stderr_flush)",
            "",
            "        redirected.set(False)",
            "",
            "    def _wrap_write(self, method: Callable[..., Any]) -> Callable[..., Any]:",
            "        \"\"\"Wrapper function that utilizes the storage object to store logs.",
            "",
            "        Args:",
            "            method: the original write method",
            "",
            "        Returns:",
            "            the wrapped write method.",
            "        \"\"\"",
            "",
            "        def wrapped_write(*args: Any, **kwargs: Any) -> Any:",
            "            output = method(*args, **kwargs)",
            "            if args:",
            "                self.storage.write(args[0])",
            "            return output",
            "",
            "        return wrapped_write",
            "",
            "    def _wrap_flush(self, method: Callable[..., Any]) -> Callable[..., Any]:",
            "        \"\"\"Wrapper function that flushes the buffer of the storage object.",
            "",
            "        Args:",
            "            method: the original flush method",
            "",
            "        Returns:",
            "            the wrapped flush method.",
            "        \"\"\"",
            "",
            "        def wrapped_flush(*args: Any, **kwargs: Any) -> Any:",
            "            output = method(*args, **kwargs)",
            "            self.storage.save_to_file()",
            "            return output",
            "",
            "        return wrapped_flush"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "26": [],
            "77": [
                "prepare_logs_uri"
            ],
            "78": [
                "prepare_logs_uri"
            ],
            "82": [
                "prepare_logs_uri"
            ],
            "86": [
                "prepare_logs_uri"
            ],
            "143": [
                "StepLogsStorage",
                "save_to_file"
            ]
        },
        "addLocation": []
    },
    "src/zenml/materializers/base_materializer.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 156,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "         Example:"
            },
            "2": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "         ```"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+        artifact_store = Client().active_stack.artifact_store"
            },
            "4": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 160,
                "PatchRowcode": "         visualization_uri = os.path.join(self.uri, \"visualization.html\")"
            },
            "5": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        with fileio.open(visualization_uri, \"w\") as f:"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+        with artifact_store.open(visualization_uri, \"w\") as f:"
            },
            "7": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "             f.write(\"<html><body>data</body></html>\")"
            },
            "8": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 163,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "         visualization_uri_2 = os.path.join(self.uri, \"visualization.png\")"
            }
        },
        "frontPatchFile": [
            "#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"Metaclass implementation for registering ZenML BaseMaterializer subclasses.\"\"\"",
            "",
            "import inspect",
            "from typing import Any, ClassVar, Dict, Tuple, Type, cast",
            "",
            "from zenml.enums import ArtifactType, VisualizationType",
            "from zenml.exceptions import MaterializerInterfaceError",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.materializers.materializer_registry import materializer_registry",
            "from zenml.metadata.metadata_types import MetadataType",
            "",
            "logger = get_logger(__name__)",
            "",
            "",
            "class BaseMaterializerMeta(type):",
            "    \"\"\"Metaclass responsible for registering different BaseMaterializer subclasses.",
            "",
            "    Materializers are used for reading/writing artifacts.",
            "    \"\"\"",
            "",
            "    def __new__(",
            "        mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]",
            "    ) -> \"BaseMaterializerMeta\":",
            "        \"\"\"Creates a Materializer class and registers it at the `MaterializerRegistry`.",
            "",
            "        Args:",
            "            name: The name of the class.",
            "            bases: The base classes of the class.",
            "            dct: The dictionary of the class.",
            "",
            "        Returns:",
            "            The BaseMaterializerMeta class.",
            "",
            "        Raises:",
            "            MaterializerInterfaceError: If the class was improperly defined.",
            "        \"\"\"",
            "        cls = cast(",
            "            Type[\"BaseMaterializer\"], super().__new__(mcs, name, bases, dct)",
            "        )",
            "        if not cls._DOCS_BUILDING_MODE:",
            "            # Skip the following validation and registration for base classes.",
            "            if cls.SKIP_REGISTRATION:",
            "                # Reset the flag so subclasses don't have it set automatically.",
            "                cls.SKIP_REGISTRATION = False",
            "                return cls",
            "",
            "            # Validate that the class is properly defined.",
            "            if not cls.ASSOCIATED_TYPES:",
            "                raise MaterializerInterfaceError(",
            "                    f\"Invalid materializer class '{name}'. When creating a \"",
            "                    f\"custom materializer, make sure to specify at least one \"",
            "                    f\"type in its ASSOCIATED_TYPES class variable.\",",
            "                    url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                )",
            "",
            "            # Validate associated artifact type.",
            "            if cls.ASSOCIATED_ARTIFACT_TYPE:",
            "                try:",
            "                    cls.ASSOCIATED_ARTIFACT_TYPE = ArtifactType(",
            "                        cls.ASSOCIATED_ARTIFACT_TYPE",
            "                    )",
            "                except ValueError:",
            "                    raise MaterializerInterfaceError(",
            "                        f\"Invalid materializer class '{name}'. When creating a \"",
            "                        f\"custom materializer, make sure to specify a valid \"",
            "                        f\"artifact type in its ASSOCIATED_ARTIFACT_TYPE class \"",
            "                        f\"variable.\",",
            "                        url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                    )",
            "",
            "            # Validate associated data types.",
            "            for associated_type in cls.ASSOCIATED_TYPES:",
            "                if not inspect.isclass(associated_type):",
            "                    raise MaterializerInterfaceError(",
            "                        f\"Associated type {associated_type} for materializer \"",
            "                        f\"{name} is not a class.\",",
            "                        url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                    )",
            "",
            "            # Register the materializer.",
            "            for associated_type in cls.ASSOCIATED_TYPES:",
            "                materializer_registry.register_materializer_type(",
            "                    associated_type, cls",
            "                )",
            "",
            "        return cls",
            "",
            "",
            "class BaseMaterializer(metaclass=BaseMaterializerMeta):",
            "    \"\"\"Base Materializer to realize artifact data.\"\"\"",
            "",
            "    ASSOCIATED_ARTIFACT_TYPE: ClassVar[ArtifactType] = ArtifactType.BASE",
            "    ASSOCIATED_TYPES: ClassVar[Tuple[Type[Any], ...]] = ()",
            "",
            "    # `SKIP_REGISTRATION` can be set to True to not register the class in the",
            "    # materializer registry. This is primarily useful for defining base classes.",
            "    # Subclasses will automatically have this set to False unless they override",
            "    # it themselves.",
            "    SKIP_REGISTRATION: ClassVar[bool] = True",
            "",
            "    _DOCS_BUILDING_MODE: ClassVar[bool] = False",
            "",
            "    def __init__(self, uri: str):",
            "        \"\"\"Initializes a materializer with the given URI.",
            "",
            "        Args:",
            "            uri: The URI where the artifact data will be stored.",
            "        \"\"\"",
            "        self.uri = uri",
            "",
            "    # ================",
            "    # Public Interface",
            "    # ================",
            "",
            "    def load(self, data_type: Type[Any]) -> Any:",
            "        \"\"\"Write logic here to load the data of an artifact.",
            "",
            "        Args:",
            "            data_type: What type the artifact data should be loaded as.",
            "",
            "        Returns:",
            "            The data of the artifact.",
            "        \"\"\"",
            "        # read from a location inside self.uri",
            "        return None",
            "",
            "    def save(self, data: Any) -> None:",
            "        \"\"\"Write logic here to save the data of an artifact.",
            "",
            "        Args:",
            "            data: The data of the artifact to save.",
            "        \"\"\"",
            "        # write `data` into self.uri",
            "",
            "    def save_visualizations(self, data: Any) -> Dict[str, VisualizationType]:",
            "        \"\"\"Save visualizations of the given data.",
            "",
            "        If this method is not overridden, no visualizations will be saved.",
            "",
            "        When overriding this method, make sure to save all visualizations to",
            "        files within `self.uri`.",
            "",
            "        Example:",
            "        ```",
            "        visualization_uri = os.path.join(self.uri, \"visualization.html\")",
            "        with fileio.open(visualization_uri, \"w\") as f:",
            "            f.write(\"<html><body>data</body></html>\")",
            "",
            "        visualization_uri_2 = os.path.join(self.uri, \"visualization.png\")",
            "        data.save_as_png(visualization_uri_2)",
            "",
            "        return {",
            "            visualization_uri: ArtifactVisualizationType.HTML,",
            "            visualization_uri_2: ArtifactVisualizationType.IMAGE",
            "        }",
            "        ```",
            "",
            "        Args:",
            "            data: The data of the artifact to visualize.",
            "",
            "        Returns:",
            "            A dictionary of visualization URIs and their types.",
            "        \"\"\"",
            "        # Optionally, save some visualizations of `data` inside `self.uri`.",
            "        return {}",
            "",
            "    def extract_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract metadata from the given data.",
            "",
            "        This metadata will be tracked and displayed alongside the artifact.",
            "",
            "        Example:",
            "        ```",
            "        return {",
            "            \"some_attribute_i_want_to_track\": self.some_attribute,",
            "            \"pi\": 3.14,",
            "        }",
            "        ```",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        # Optionally, extract some metadata from `data` for ZenML to store.",
            "        return {}",
            "",
            "    # ================",
            "    # Internal Methods",
            "    # ================",
            "",
            "    def validate_type_compatibility(self, data_type: Type[Any]) -> None:",
            "        \"\"\"Checks whether the materializer can read/write the given type.",
            "",
            "        Args:",
            "            data_type: The type to check.",
            "",
            "        Raises:",
            "            TypeError: If the materializer cannot read/write the given type.",
            "        \"\"\"",
            "        if not self.can_handle_type(data_type):",
            "            raise TypeError(",
            "                f\"Unable to handle type {data_type}. {self.__class__.__name__} \"",
            "                f\"can only read/write artifacts of the following types: \"",
            "                f\"{self.ASSOCIATED_TYPES}.\"",
            "            )",
            "",
            "    @classmethod",
            "    def can_handle_type(cls, data_type: Type[Any]) -> bool:",
            "        \"\"\"Whether the materializer can read/write a certain type.",
            "",
            "        Args:",
            "            data_type: The type to check.",
            "",
            "        Returns:",
            "            Whether the materializer can read/write the given type.",
            "        \"\"\"",
            "        return any(",
            "            issubclass(data_type, associated_type)",
            "            for associated_type in cls.ASSOCIATED_TYPES",
            "        )",
            "",
            "    def extract_full_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract both base and custom metadata from the given data.",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        base_metadata = self._extract_base_metadata(data)",
            "        custom_metadata = self.extract_metadata(data)",
            "        return {**base_metadata, **custom_metadata}",
            "",
            "    def _extract_base_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract metadata from the given data.",
            "",
            "        This metadata will be extracted for all artifacts in addition to the",
            "        metadata extracted by the `extract_metadata` method.",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        from zenml.metadata.metadata_types import StorageSize",
            "",
            "        storage_size = fileio.size(self.uri)",
            "        if isinstance(storage_size, int):",
            "            return {\"storage_size\": StorageSize(storage_size)}",
            "        return {}"
        ],
        "afterPatchFile": [
            "#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.",
            "#",
            "#  Licensed under the Apache License, Version 2.0 (the \"License\");",
            "#  you may not use this file except in compliance with the License.",
            "#  You may obtain a copy of the License at:",
            "#",
            "#       https://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#  Unless required by applicable law or agreed to in writing, software",
            "#  distributed under the License is distributed on an \"AS IS\" BASIS,",
            "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
            "#  or implied. See the License for the specific language governing",
            "#  permissions and limitations under the License.",
            "\"\"\"Metaclass implementation for registering ZenML BaseMaterializer subclasses.\"\"\"",
            "",
            "import inspect",
            "from typing import Any, ClassVar, Dict, Tuple, Type, cast",
            "",
            "from zenml.enums import ArtifactType, VisualizationType",
            "from zenml.exceptions import MaterializerInterfaceError",
            "from zenml.io import fileio",
            "from zenml.logger import get_logger",
            "from zenml.materializers.materializer_registry import materializer_registry",
            "from zenml.metadata.metadata_types import MetadataType",
            "",
            "logger = get_logger(__name__)",
            "",
            "",
            "class BaseMaterializerMeta(type):",
            "    \"\"\"Metaclass responsible for registering different BaseMaterializer subclasses.",
            "",
            "    Materializers are used for reading/writing artifacts.",
            "    \"\"\"",
            "",
            "    def __new__(",
            "        mcs, name: str, bases: Tuple[Type[Any], ...], dct: Dict[str, Any]",
            "    ) -> \"BaseMaterializerMeta\":",
            "        \"\"\"Creates a Materializer class and registers it at the `MaterializerRegistry`.",
            "",
            "        Args:",
            "            name: The name of the class.",
            "            bases: The base classes of the class.",
            "            dct: The dictionary of the class.",
            "",
            "        Returns:",
            "            The BaseMaterializerMeta class.",
            "",
            "        Raises:",
            "            MaterializerInterfaceError: If the class was improperly defined.",
            "        \"\"\"",
            "        cls = cast(",
            "            Type[\"BaseMaterializer\"], super().__new__(mcs, name, bases, dct)",
            "        )",
            "        if not cls._DOCS_BUILDING_MODE:",
            "            # Skip the following validation and registration for base classes.",
            "            if cls.SKIP_REGISTRATION:",
            "                # Reset the flag so subclasses don't have it set automatically.",
            "                cls.SKIP_REGISTRATION = False",
            "                return cls",
            "",
            "            # Validate that the class is properly defined.",
            "            if not cls.ASSOCIATED_TYPES:",
            "                raise MaterializerInterfaceError(",
            "                    f\"Invalid materializer class '{name}'. When creating a \"",
            "                    f\"custom materializer, make sure to specify at least one \"",
            "                    f\"type in its ASSOCIATED_TYPES class variable.\",",
            "                    url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                )",
            "",
            "            # Validate associated artifact type.",
            "            if cls.ASSOCIATED_ARTIFACT_TYPE:",
            "                try:",
            "                    cls.ASSOCIATED_ARTIFACT_TYPE = ArtifactType(",
            "                        cls.ASSOCIATED_ARTIFACT_TYPE",
            "                    )",
            "                except ValueError:",
            "                    raise MaterializerInterfaceError(",
            "                        f\"Invalid materializer class '{name}'. When creating a \"",
            "                        f\"custom materializer, make sure to specify a valid \"",
            "                        f\"artifact type in its ASSOCIATED_ARTIFACT_TYPE class \"",
            "                        f\"variable.\",",
            "                        url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                    )",
            "",
            "            # Validate associated data types.",
            "            for associated_type in cls.ASSOCIATED_TYPES:",
            "                if not inspect.isclass(associated_type):",
            "                    raise MaterializerInterfaceError(",
            "                        f\"Associated type {associated_type} for materializer \"",
            "                        f\"{name} is not a class.\",",
            "                        url=\"https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\",",
            "                    )",
            "",
            "            # Register the materializer.",
            "            for associated_type in cls.ASSOCIATED_TYPES:",
            "                materializer_registry.register_materializer_type(",
            "                    associated_type, cls",
            "                )",
            "",
            "        return cls",
            "",
            "",
            "class BaseMaterializer(metaclass=BaseMaterializerMeta):",
            "    \"\"\"Base Materializer to realize artifact data.\"\"\"",
            "",
            "    ASSOCIATED_ARTIFACT_TYPE: ClassVar[ArtifactType] = ArtifactType.BASE",
            "    ASSOCIATED_TYPES: ClassVar[Tuple[Type[Any], ...]] = ()",
            "",
            "    # `SKIP_REGISTRATION` can be set to True to not register the class in the",
            "    # materializer registry. This is primarily useful for defining base classes.",
            "    # Subclasses will automatically have this set to False unless they override",
            "    # it themselves.",
            "    SKIP_REGISTRATION: ClassVar[bool] = True",
            "",
            "    _DOCS_BUILDING_MODE: ClassVar[bool] = False",
            "",
            "    def __init__(self, uri: str):",
            "        \"\"\"Initializes a materializer with the given URI.",
            "",
            "        Args:",
            "            uri: The URI where the artifact data will be stored.",
            "        \"\"\"",
            "        self.uri = uri",
            "",
            "    # ================",
            "    # Public Interface",
            "    # ================",
            "",
            "    def load(self, data_type: Type[Any]) -> Any:",
            "        \"\"\"Write logic here to load the data of an artifact.",
            "",
            "        Args:",
            "            data_type: What type the artifact data should be loaded as.",
            "",
            "        Returns:",
            "            The data of the artifact.",
            "        \"\"\"",
            "        # read from a location inside self.uri",
            "        return None",
            "",
            "    def save(self, data: Any) -> None:",
            "        \"\"\"Write logic here to save the data of an artifact.",
            "",
            "        Args:",
            "            data: The data of the artifact to save.",
            "        \"\"\"",
            "        # write `data` into self.uri",
            "",
            "    def save_visualizations(self, data: Any) -> Dict[str, VisualizationType]:",
            "        \"\"\"Save visualizations of the given data.",
            "",
            "        If this method is not overridden, no visualizations will be saved.",
            "",
            "        When overriding this method, make sure to save all visualizations to",
            "        files within `self.uri`.",
            "",
            "        Example:",
            "        ```",
            "        artifact_store = Client().active_stack.artifact_store",
            "        visualization_uri = os.path.join(self.uri, \"visualization.html\")",
            "        with artifact_store.open(visualization_uri, \"w\") as f:",
            "            f.write(\"<html><body>data</body></html>\")",
            "",
            "        visualization_uri_2 = os.path.join(self.uri, \"visualization.png\")",
            "        data.save_as_png(visualization_uri_2)",
            "",
            "        return {",
            "            visualization_uri: ArtifactVisualizationType.HTML,",
            "            visualization_uri_2: ArtifactVisualizationType.IMAGE",
            "        }",
            "        ```",
            "",
            "        Args:",
            "            data: The data of the artifact to visualize.",
            "",
            "        Returns:",
            "            A dictionary of visualization URIs and their types.",
            "        \"\"\"",
            "        # Optionally, save some visualizations of `data` inside `self.uri`.",
            "        return {}",
            "",
            "    def extract_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract metadata from the given data.",
            "",
            "        This metadata will be tracked and displayed alongside the artifact.",
            "",
            "        Example:",
            "        ```",
            "        return {",
            "            \"some_attribute_i_want_to_track\": self.some_attribute,",
            "            \"pi\": 3.14,",
            "        }",
            "        ```",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        # Optionally, extract some metadata from `data` for ZenML to store.",
            "        return {}",
            "",
            "    # ================",
            "    # Internal Methods",
            "    # ================",
            "",
            "    def validate_type_compatibility(self, data_type: Type[Any]) -> None:",
            "        \"\"\"Checks whether the materializer can read/write the given type.",
            "",
            "        Args:",
            "            data_type: The type to check.",
            "",
            "        Raises:",
            "            TypeError: If the materializer cannot read/write the given type.",
            "        \"\"\"",
            "        if not self.can_handle_type(data_type):",
            "            raise TypeError(",
            "                f\"Unable to handle type {data_type}. {self.__class__.__name__} \"",
            "                f\"can only read/write artifacts of the following types: \"",
            "                f\"{self.ASSOCIATED_TYPES}.\"",
            "            )",
            "",
            "    @classmethod",
            "    def can_handle_type(cls, data_type: Type[Any]) -> bool:",
            "        \"\"\"Whether the materializer can read/write a certain type.",
            "",
            "        Args:",
            "            data_type: The type to check.",
            "",
            "        Returns:",
            "            Whether the materializer can read/write the given type.",
            "        \"\"\"",
            "        return any(",
            "            issubclass(data_type, associated_type)",
            "            for associated_type in cls.ASSOCIATED_TYPES",
            "        )",
            "",
            "    def extract_full_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract both base and custom metadata from the given data.",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        base_metadata = self._extract_base_metadata(data)",
            "        custom_metadata = self.extract_metadata(data)",
            "        return {**base_metadata, **custom_metadata}",
            "",
            "    def _extract_base_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
            "        \"\"\"Extract metadata from the given data.",
            "",
            "        This metadata will be extracted for all artifacts in addition to the",
            "        metadata extracted by the `extract_metadata` method.",
            "",
            "        Args:",
            "            data: The data to extract metadata from.",
            "",
            "        Returns:",
            "            A dictionary of metadata.",
            "        \"\"\"",
            "        from zenml.metadata.metadata_types import StorageSize",
            "",
            "        storage_size = fileio.size(self.uri)",
            "        if isinstance(storage_size, int):",
            "            return {\"storage_size\": StorageSize(storage_size)}",
            "        return {}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "160": [
                "BaseMaterializer",
                "save_visualizations"
            ]
        },
        "addLocation": [
            "aioxmpp.xso.model"
        ]
    }
}