{
    "hpack/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " \"\"\""
            },
            "1": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from .hpack import Encoder, Decoder"
            },
            "2": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from .struct import HeaderTuple, NeverIndexedHeaderTuple"
            },
            "3": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from .exceptions import HPACKError, HPACKDecodingError, InvalidTableIndex"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from .exceptions import ("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 11,
                "PatchRowcode": "+    HPACKError, HPACKDecodingError, InvalidTableIndex, OversizedHeaderListError"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+)"
            },
            "7": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " __all__ = ["
            },
            "9": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "     'Encoder', 'Decoder', 'HPACKError', 'HPACKDecodingError',"
            },
            "10": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    'InvalidTableIndex', 'HeaderTuple', 'NeverIndexedHeaderTuple'"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+    'InvalidTableIndex', 'HeaderTuple', 'NeverIndexedHeaderTuple',"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+    'OversizedHeaderListError'"
            },
            "13": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " ]"
            },
            "14": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " __version__ = '2.2.0'"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hpack",
            "~~~~~",
            "",
            "HTTP/2 header encoding for Python.",
            "\"\"\"",
            "from .hpack import Encoder, Decoder",
            "from .struct import HeaderTuple, NeverIndexedHeaderTuple",
            "from .exceptions import HPACKError, HPACKDecodingError, InvalidTableIndex",
            "",
            "__all__ = [",
            "    'Encoder', 'Decoder', 'HPACKError', 'HPACKDecodingError',",
            "    'InvalidTableIndex', 'HeaderTuple', 'NeverIndexedHeaderTuple'",
            "]",
            "",
            "__version__ = '2.2.0'"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hpack",
            "~~~~~",
            "",
            "HTTP/2 header encoding for Python.",
            "\"\"\"",
            "from .hpack import Encoder, Decoder",
            "from .struct import HeaderTuple, NeverIndexedHeaderTuple",
            "from .exceptions import (",
            "    HPACKError, HPACKDecodingError, InvalidTableIndex, OversizedHeaderListError",
            ")",
            "",
            "__all__ = [",
            "    'Encoder', 'Decoder', 'HPACKError', 'HPACKDecodingError',",
            "    'InvalidTableIndex', 'HeaderTuple', 'NeverIndexedHeaderTuple',",
            "    'OversizedHeaderListError'",
            "]",
            "",
            "__version__ = '2.2.0'"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "10": [],
            "14": []
        },
        "addLocation": []
    },
    "hpack/exceptions.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": "     An invalid table index was received."
            },
            "1": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": "     \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "     pass"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+class OversizedHeaderListError(HPACKDecodingError):"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+    \"\"\""
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+    A header list that was larger than we allow has been received. This may be"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+    a DoS attack."
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+    .. versionadded:: 2.3.0"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+    \"\"\""
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+    pass"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hyper/http20/exceptions",
            "~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "This defines exceptions used in the HTTP/2 portion of hyper.",
            "\"\"\"",
            "",
            "",
            "class HPACKError(Exception):",
            "    \"\"\"",
            "    The base class for all ``hpack`` exceptions.",
            "    \"\"\"",
            "    pass",
            "",
            "",
            "class HPACKDecodingError(HPACKError):",
            "    \"\"\"",
            "    An error has been encountered while performing HPACK decoding.",
            "    \"\"\"",
            "    pass",
            "",
            "",
            "class InvalidTableIndex(HPACKDecodingError):",
            "    \"\"\"",
            "    An invalid table index was received.",
            "    \"\"\"",
            "    pass"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hyper/http20/exceptions",
            "~~~~~~~~~~~~~~~~~~~~~~~",
            "",
            "This defines exceptions used in the HTTP/2 portion of hyper.",
            "\"\"\"",
            "",
            "",
            "class HPACKError(Exception):",
            "    \"\"\"",
            "    The base class for all ``hpack`` exceptions.",
            "    \"\"\"",
            "    pass",
            "",
            "",
            "class HPACKDecodingError(HPACKError):",
            "    \"\"\"",
            "    An error has been encountered while performing HPACK decoding.",
            "    \"\"\"",
            "    pass",
            "",
            "",
            "class InvalidTableIndex(HPACKDecodingError):",
            "    \"\"\"",
            "    An invalid table index was received.",
            "    \"\"\"",
            "    pass",
            "",
            "",
            "class OversizedHeaderListError(HPACKDecodingError):",
            "    \"\"\"",
            "    A header list that was larger than we allow has been received. This may be",
            "    a DoS attack.",
            "",
            "    .. versionadded:: 2.3.0",
            "    \"\"\"",
            "    pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "hpack/hpack.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " \"\"\""
            },
            "1": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " import logging"
            },
            "2": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from .table import HeaderTable"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from .table import HeaderTable, table_entry_size"
            },
            "5": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from .compat import to_byte, to_bytes"
            },
            "6": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from .exceptions import HPACKDecodingError"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+from .exceptions import HPACKDecodingError, OversizedHeaderListError"
            },
            "8": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from .huffman import HuffmanEncoder"
            },
            "9": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " from .huffman_constants import ("
            },
            "10": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "     REQUEST_CODES, REQUEST_CODES_LENGTH"
            },
            "11": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": "     basestring = (str, bytes)"
            },
            "12": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+# We default the maximum header list we're willing to accept to 64kB. That's a"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+# lot of headers, but if applications want to raise it they can do."
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+DEFAULT_MAX_HEADER_LIST_SIZE = 2**16"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " def _unicode_if_needed(header, raw):"
            },
            "20": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "     \"\"\""
            },
            "21": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     Provides a header as a unicode string if raw is False, otherwise returns"
            },
            "22": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 354,
                "PatchRowcode": " class Decoder(object):"
            },
            "23": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 355,
                "PatchRowcode": "     \"\"\""
            },
            "24": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "     An HPACK decoder object."
            },
            "25": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "26": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 357,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __init__(self):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+    .. versionchanged:: 2.3.0"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+       Added ``max_header_list_size`` argument."
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+    :param max_header_list_size: The maximum decompressed size we will allow"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+        for any single header block. This is a protection against DoS attacks"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+        that attempt to force the application to expand a relatively small"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+        amount of data into a really large header list, allowing enormous"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+        amounts of memory to be allocated."
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+        If this amount of data is exceeded, a `OversizedHeaderListError"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+        <hpack.OversizedHeaderListError>` exception will be raised. At this"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+        point the connection should be shut down, as the HPACK state will no"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        longer be useable."
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+        Defaults to 64kB."
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+    :type max_header_list_size: ``int``"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 374,
                "PatchRowcode": "+    \"\"\""
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 375,
                "PatchRowcode": "+    def __init__(self, max_header_list_size=DEFAULT_MAX_HEADER_LIST_SIZE):"
            },
            "46": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "         self.header_table = HeaderTable()"
            },
            "47": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": 377,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+        #: The maximum decompressed size we will allow for any single header"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+        #: block. This is a protection against DoS attacks that attempt to"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 380,
                "PatchRowcode": "+        #: force the application to expand a relatively small amount of data"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 381,
                "PatchRowcode": "+        #: into a really large header list, allowing enormous amounts of memory"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 382,
                "PatchRowcode": "+        #: to be allocated."
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+        #:"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+        #: If this amount of data is exceeded, a `OversizedHeaderListError"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 385,
                "PatchRowcode": "+        #: <hpack.OversizedHeaderListError>` exception will be raised. At this"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 386,
                "PatchRowcode": "+        #: point the connection should be shut down, as the HPACK state will no"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+        #: longer be useable."
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+        #:"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 389,
                "PatchRowcode": "+        #: Defaults to 64kB."
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 390,
                "PatchRowcode": "+        #:"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+        #: .. versionadded:: 2.3.0"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 392,
                "PatchRowcode": "+        self.max_header_list_size = max_header_list_size"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 393,
                "PatchRowcode": "+"
            },
            "64": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": 394,
                "PatchRowcode": "     @property"
            },
            "65": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "     def header_table_size(self):"
            },
            "66": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": 396,
                "PatchRowcode": "         \"\"\""
            },
            "67": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 422,
                "PatchRowcode": "         data_mem = memoryview(data)"
            },
            "68": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 423,
                "PatchRowcode": "         headers = []"
            },
            "69": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 424,
                "PatchRowcode": "         data_len = len(data)"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 425,
                "PatchRowcode": "+        inflated_size = 0"
            },
            "71": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 426,
                "PatchRowcode": "         current_index = 0"
            },
            "72": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 427,
                "PatchRowcode": " "
            },
            "73": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 428,
                "PatchRowcode": "         while current_index < data_len:"
            },
            "74": {
                "beforePatchRowNumber": 422,
                "afterPatchRowNumber": 460,
                "PatchRowcode": " "
            },
            "75": {
                "beforePatchRowNumber": 423,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "             if header:"
            },
            "76": {
                "beforePatchRowNumber": 424,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "                 headers.append(header)"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 463,
                "PatchRowcode": "+                inflated_size += table_entry_size(*header)"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 464,
                "PatchRowcode": "+"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 465,
                "PatchRowcode": "+                if inflated_size > self.max_header_list_size:"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 466,
                "PatchRowcode": "+                    raise OversizedHeaderListError("
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 467,
                "PatchRowcode": "+                        \"A header list larger than %d has been received\" %"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 468,
                "PatchRowcode": "+                        self.max_header_list_size"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 469,
                "PatchRowcode": "+                    )"
            },
            "84": {
                "beforePatchRowNumber": 425,
                "afterPatchRowNumber": 470,
                "PatchRowcode": " "
            },
            "85": {
                "beforePatchRowNumber": 426,
                "afterPatchRowNumber": 471,
                "PatchRowcode": "             current_index += consumed"
            },
            "86": {
                "beforePatchRowNumber": 427,
                "afterPatchRowNumber": 472,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hpack/hpack",
            "~~~~~~~~~~~",
            "",
            "Implements the HPACK header compression algorithm as detailed by the IETF.",
            "\"\"\"",
            "import logging",
            "",
            "from .table import HeaderTable",
            "from .compat import to_byte, to_bytes",
            "from .exceptions import HPACKDecodingError",
            "from .huffman import HuffmanEncoder",
            "from .huffman_constants import (",
            "    REQUEST_CODES, REQUEST_CODES_LENGTH",
            ")",
            "from .huffman_table import decode_huffman",
            "from .struct import HeaderTuple, NeverIndexedHeaderTuple",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "INDEX_NONE = b'\\x00'",
            "INDEX_NEVER = b'\\x10'",
            "INDEX_INCREMENTAL = b'\\x40'",
            "",
            "try:  # pragma: no cover",
            "    basestring = basestring",
            "except NameError:  # pragma: no cover",
            "    basestring = (str, bytes)",
            "",
            "",
            "def _unicode_if_needed(header, raw):",
            "    \"\"\"",
            "    Provides a header as a unicode string if raw is False, otherwise returns",
            "    it as a bytestring.",
            "    \"\"\"",
            "    name = to_bytes(header[0])",
            "    value = to_bytes(header[1])",
            "    if not raw:",
            "        name = name.decode('utf-8')",
            "        value = value.decode('utf-8')",
            "    return header.__class__(name, value)",
            "",
            "",
            "def encode_integer(integer, prefix_bits):",
            "    \"\"\"",
            "    This encodes an integer according to the wacky integer encoding rules",
            "    defined in the HPACK spec.",
            "    \"\"\"",
            "    log.debug(\"Encoding %d with %d bits\", integer, prefix_bits)",
            "",
            "    max_number = (2 ** prefix_bits) - 1",
            "",
            "    if integer < max_number:",
            "        return bytearray([integer])  # Seriously?",
            "    else:",
            "        elements = [max_number]",
            "        integer -= max_number",
            "",
            "        while integer >= 128:",
            "            elements.append((integer % 128) + 128)",
            "            integer //= 128  # We need integer division",
            "",
            "        elements.append(integer)",
            "",
            "        return bytearray(elements)",
            "",
            "",
            "def decode_integer(data, prefix_bits):",
            "    \"\"\"",
            "    This decodes an integer according to the wacky integer encoding rules",
            "    defined in the HPACK spec. Returns a tuple of the decoded integer and the",
            "    number of bytes that were consumed from ``data`` in order to get that",
            "    integer.",
            "    \"\"\"",
            "    max_number = (2 ** prefix_bits) - 1",
            "    mask = 0xFF >> (8 - prefix_bits)",
            "    index = 0",
            "",
            "    try:",
            "        number = to_byte(data[index]) & mask",
            "",
            "        if number == max_number:",
            "",
            "            while True:",
            "                index += 1",
            "                next_byte = to_byte(data[index])",
            "",
            "                # There's some duplication here, but that's because this is a",
            "                # hot function, and incurring too many function calls here is",
            "                # a real problem. For that reason, we unrolled the maths.",
            "                if next_byte >= 128:",
            "                    number += (next_byte - 128) * (128 ** (index - 1))",
            "                else:",
            "                    number += next_byte * (128 ** (index - 1))",
            "                    break",
            "    except IndexError:",
            "        raise HPACKDecodingError(",
            "            \"Unable to decode HPACK integer representation from %r\" % data",
            "        )",
            "",
            "    log.debug(\"Decoded %d, consumed %d bytes\", number, index + 1)",
            "",
            "    return number, index + 1",
            "",
            "",
            "def _dict_to_iterable(header_dict):",
            "    \"\"\"",
            "    This converts a dictionary to an iterable of two-tuples. This is a",
            "    HPACK-specific function becuase it pulls \"special-headers\" out first and",
            "    then emits them.",
            "    \"\"\"",
            "    assert isinstance(header_dict, dict)",
            "    keys = sorted(",
            "        header_dict.keys(),",
            "        key=lambda k: not _to_bytes(k).startswith(b':')",
            "    )",
            "    for key in keys:",
            "        yield key, header_dict[key]",
            "",
            "",
            "def _to_bytes(string):",
            "    \"\"\"",
            "    Convert string to bytes.",
            "    \"\"\"",
            "    if not isinstance(string, (basestring)):  # pragma: no cover",
            "        string = str(string)",
            "",
            "    return string if isinstance(string, bytes) else string.encode('utf-8')",
            "",
            "",
            "class Encoder(object):",
            "    \"\"\"",
            "    An HPACK encoder object. This object takes HTTP headers and emits encoded",
            "    HTTP/2 header blocks.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.header_table = HeaderTable()",
            "        self.huffman_coder = HuffmanEncoder(",
            "            REQUEST_CODES, REQUEST_CODES_LENGTH",
            "        )",
            "        self.table_size_changes = []",
            "",
            "    @property",
            "    def header_table_size(self):",
            "        \"\"\"",
            "        Controls the size of the HPACK header table.",
            "        \"\"\"",
            "        return self.header_table.maxsize",
            "",
            "    @header_table_size.setter",
            "    def header_table_size(self, value):",
            "        self.header_table.maxsize = value",
            "        if self.header_table.resized:",
            "            self.table_size_changes.append(value)",
            "",
            "    def encode(self, headers, huffman=True):",
            "        \"\"\"",
            "        Takes a set of headers and encodes them into a HPACK-encoded header",
            "        block.",
            "",
            "        :param headers: The headers to encode. Must be either an iterable of",
            "                        tuples, an iterable of :class:`HeaderTuple",
            "                        <hpack.struct.HeaderTuple>`, or a ``dict``.",
            "",
            "                        If an iterable of tuples, the tuples may be either",
            "                        two-tuples or three-tuples. If they are two-tuples, the",
            "                        tuples must be of the format ``(name, value)``. If they",
            "                        are three-tuples, they must be of the format",
            "                        ``(name, value, sensitive)``, where ``sensitive`` is a",
            "                        boolean value indicating whether the header should be",
            "                        added to header tables anywhere. If not present,",
            "                        ``sensitive`` defaults to ``False``.",
            "",
            "                        If an iterable of :class:`HeaderTuple",
            "                        <hpack.struct.HeaderTuple>`, the tuples must always be",
            "                        two-tuples. Instead of using ``sensitive`` as a third",
            "                        tuple entry, use :class:`NeverIndexedHeaderTuple",
            "                        <hpack.struct.NeverIndexedHeaderTuple>` to request that",
            "                        the field never be indexed.",
            "",
            "                        .. warning:: HTTP/2 requires that all special headers",
            "                            (headers whose names begin with ``:`` characters)",
            "                            appear at the *start* of the header block. While",
            "                            this method will ensure that happens for ``dict``",
            "                            subclasses, callers using any other iterable of",
            "                            tuples **must** ensure they place their special",
            "                            headers at the start of the iterable.",
            "",
            "                            For efficiency reasons users should prefer to use",
            "                            iterables of two-tuples: fixing the ordering of",
            "                            dictionary headers is an expensive operation that",
            "                            should be avoided if possible.",
            "",
            "        :param huffman: (optional) Whether to Huffman-encode any header sent as",
            "                        a literal value. Except for use when debugging, it is",
            "                        recommended that this be left enabled.",
            "",
            "        :returns: A bytestring containing the HPACK-encoded header block.",
            "        \"\"\"",
            "        # Transforming the headers into a header block is a procedure that can",
            "        # be modeled as a chain or pipe. First, the headers are encoded. This",
            "        # encoding can be done a number of ways. If the header name-value pair",
            "        # are already in the header table we can represent them using the",
            "        # indexed representation: the same is true if they are in the static",
            "        # table. Otherwise, a literal representation will be used.",
            "        log.debug(\"HPACK encoding %s\", headers)",
            "        header_block = []",
            "",
            "        # Turn the headers into a list of tuples if possible. This is the",
            "        # natural way to interact with them in HPACK. Because dictionaries are",
            "        # un-ordered, we need to make sure we grab the \"special\" headers first.",
            "        if isinstance(headers, dict):",
            "            headers = _dict_to_iterable(headers)",
            "",
            "        # Before we begin, if the header table size has been changed we need",
            "        # to signal all changes since last emission appropriately.",
            "        if self.header_table.resized:",
            "            header_block.append(self._encode_table_size_change())",
            "            self.header_table.resized = False",
            "",
            "        # Add each header to the header block",
            "        for header in headers:",
            "            sensitive = False",
            "            if isinstance(header, HeaderTuple):",
            "                sensitive = not header.indexable",
            "            elif len(header) > 2:",
            "                sensitive = header[2]",
            "",
            "            header = (_to_bytes(header[0]), _to_bytes(header[1]))",
            "            header_block.append(self.add(header, sensitive, huffman))",
            "",
            "        header_block = b''.join(header_block)",
            "",
            "        log.debug(\"Encoded header block to %s\", header_block)",
            "",
            "        return header_block",
            "",
            "    def add(self, to_add, sensitive, huffman=False):",
            "        \"\"\"",
            "        This function takes a header key-value tuple and serializes it.",
            "        \"\"\"",
            "        log.debug(\"Adding %s to the header table\", to_add)",
            "",
            "        name, value = to_add",
            "",
            "        # Set our indexing mode",
            "        indexbit = INDEX_INCREMENTAL if not sensitive else INDEX_NEVER",
            "",
            "        # Search for a matching header in the header table.",
            "        match = self.header_table.search(name, value)",
            "",
            "        if match is None:",
            "            # Not in the header table. Encode using the literal syntax,",
            "            # and add it to the header table.",
            "            encoded = self._encode_literal(name, value, indexbit, huffman)",
            "            if not sensitive:",
            "                self.header_table.add(name, value)",
            "            return encoded",
            "",
            "        # The header is in the table, break out the values. If we matched",
            "        # perfectly, we can use the indexed representation: otherwise we",
            "        # can use the indexed literal.",
            "        index, name, perfect = match",
            "",
            "        if perfect:",
            "            # Indexed representation.",
            "            encoded = self._encode_indexed(index)",
            "        else:",
            "            # Indexed literal. We are going to add header to the",
            "            # header table unconditionally. It is a future todo to",
            "            # filter out headers which are known to be ineffective for",
            "            # indexing since they just take space in the table and",
            "            # pushed out other valuable headers.",
            "            encoded = self._encode_indexed_literal(",
            "                index, value, indexbit, huffman",
            "            )",
            "            if not sensitive:",
            "                self.header_table.add(name, value)",
            "",
            "        return encoded",
            "",
            "    def _encode_indexed(self, index):",
            "        \"\"\"",
            "        Encodes a header using the indexed representation.",
            "        \"\"\"",
            "        field = encode_integer(index, 7)",
            "        field[0] |= 0x80  # we set the top bit",
            "        return bytes(field)",
            "",
            "    def _encode_literal(self, name, value, indexbit, huffman=False):",
            "        \"\"\"",
            "        Encodes a header with a literal name and literal value. If ``indexing``",
            "        is True, the header will be added to the header table: otherwise it",
            "        will not.",
            "        \"\"\"",
            "        if huffman:",
            "            name = self.huffman_coder.encode(name)",
            "            value = self.huffman_coder.encode(value)",
            "",
            "        name_len = encode_integer(len(name), 7)",
            "        value_len = encode_integer(len(value), 7)",
            "",
            "        if huffman:",
            "            name_len[0] |= 0x80",
            "            value_len[0] |= 0x80",
            "",
            "        return b''.join(",
            "            [indexbit, bytes(name_len), name, bytes(value_len), value]",
            "        )",
            "",
            "    def _encode_indexed_literal(self, index, value, indexbit, huffman=False):",
            "        \"\"\"",
            "        Encodes a header with an indexed name and a literal value and performs",
            "        incremental indexing.",
            "        \"\"\"",
            "        if indexbit != INDEX_INCREMENTAL:",
            "            prefix = encode_integer(index, 4)",
            "        else:",
            "            prefix = encode_integer(index, 6)",
            "",
            "        prefix[0] |= ord(indexbit)",
            "",
            "        if huffman:",
            "            value = self.huffman_coder.encode(value)",
            "",
            "        value_len = encode_integer(len(value), 7)",
            "",
            "        if huffman:",
            "            value_len[0] |= 0x80",
            "",
            "        return b''.join([bytes(prefix), bytes(value_len), value])",
            "",
            "    def _encode_table_size_change(self):",
            "        \"\"\"",
            "        Produces the encoded form of all header table size change context",
            "        updates.",
            "        \"\"\"",
            "        block = b''",
            "        for size_bytes in self.table_size_changes:",
            "            size_bytes = encode_integer(size_bytes, 5)",
            "            size_bytes[0] |= 0x20",
            "            block += bytes(size_bytes)",
            "        self.table_size_changes = []",
            "        return block",
            "",
            "",
            "class Decoder(object):",
            "    \"\"\"",
            "    An HPACK decoder object.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.header_table = HeaderTable()",
            "",
            "    @property",
            "    def header_table_size(self):",
            "        \"\"\"",
            "        Controls the size of the HPACK header table.",
            "        \"\"\"",
            "        return self.header_table.maxsize",
            "",
            "    @header_table_size.setter",
            "    def header_table_size(self, value):",
            "        self.header_table.maxsize = value",
            "",
            "    def decode(self, data, raw=False):",
            "        \"\"\"",
            "        Takes an HPACK-encoded header block and decodes it into a header set.",
            "",
            "        :param data: A bytestring representing a complete HPACK-encoded header",
            "                     block.",
            "        :param raw: (optional) Whether to return the headers as tuples of raw",
            "                    byte strings or to decode them as UTF-8 before returning",
            "                    them. The default value is False, which returns tuples of",
            "                    Unicode strings",
            "        :returns: A list of two-tuples of ``(name, value)`` representing the",
            "                  HPACK-encoded headers, in the order they were decoded.",
            "        :raises HPACKDecodingError: If an error is encountered while decoding",
            "                                    the header block.",
            "        \"\"\"",
            "        log.debug(\"Decoding %s\", data)",
            "",
            "        data_mem = memoryview(data)",
            "        headers = []",
            "        data_len = len(data)",
            "        current_index = 0",
            "",
            "        while current_index < data_len:",
            "            # Work out what kind of header we're decoding.",
            "            # If the high bit is 1, it's an indexed field.",
            "            current = to_byte(data[current_index])",
            "            indexed = bool(current & 0x80)",
            "",
            "            # Otherwise, if the second-highest bit is 1 it's a field that does",
            "            # alter the header table.",
            "            literal_index = bool(current & 0x40)",
            "",
            "            # Otherwise, if the third-highest bit is 1 it's an encoding context",
            "            # update.",
            "            encoding_update = bool(current & 0x20)",
            "",
            "            if indexed:",
            "                header, consumed = self._decode_indexed(",
            "                    data_mem[current_index:]",
            "                )",
            "            elif literal_index:",
            "                # It's a literal header that does affect the header table.",
            "                header, consumed = self._decode_literal_index(",
            "                    data_mem[current_index:]",
            "                )",
            "            elif encoding_update:",
            "                # It's an update to the encoding context.",
            "                consumed = self._update_encoding_context(data_mem)",
            "                header = None",
            "            else:",
            "                # It's a literal header that does not affect the header table.",
            "                header, consumed = self._decode_literal_no_index(",
            "                    data_mem[current_index:]",
            "                )",
            "",
            "            if header:",
            "                headers.append(header)",
            "",
            "            current_index += consumed",
            "",
            "        try:",
            "            return [_unicode_if_needed(h, raw) for h in headers]",
            "        except UnicodeDecodeError:",
            "            raise HPACKDecodingError(\"Unable to decode headers as UTF-8.\")",
            "",
            "    def _update_encoding_context(self, data):",
            "        \"\"\"",
            "        Handles a byte that updates the encoding context.",
            "        \"\"\"",
            "        # We've been asked to resize the header table.",
            "        new_size, consumed = decode_integer(data, 5)",
            "        self.header_table_size = new_size",
            "        return consumed",
            "",
            "    def _decode_indexed(self, data):",
            "        \"\"\"",
            "        Decodes a header represented using the indexed representation.",
            "        \"\"\"",
            "        index, consumed = decode_integer(data, 7)",
            "        header = HeaderTuple(*self.header_table.get_by_index(index))",
            "        log.debug(\"Decoded %s, consumed %d\", header, consumed)",
            "        return header, consumed",
            "",
            "    def _decode_literal_no_index(self, data):",
            "        return self._decode_literal(data, False)",
            "",
            "    def _decode_literal_index(self, data):",
            "        return self._decode_literal(data, True)",
            "",
            "    def _decode_literal(self, data, should_index):",
            "        \"\"\"",
            "        Decodes a header represented with a literal.",
            "        \"\"\"",
            "        total_consumed = 0",
            "",
            "        # When should_index is true, if the low six bits of the first byte are",
            "        # nonzero, the header name is indexed.",
            "        # When should_index is false, if the low four bits of the first byte",
            "        # are nonzero the header name is indexed.",
            "        if should_index:",
            "            indexed_name = to_byte(data[0]) & 0x3F",
            "            name_len = 6",
            "            not_indexable = False",
            "        else:",
            "            high_byte = to_byte(data[0])",
            "            indexed_name = high_byte & 0x0F",
            "            name_len = 4",
            "            not_indexable = high_byte & 0x10",
            "",
            "        if indexed_name:",
            "            # Indexed header name.",
            "            index, consumed = decode_integer(data, name_len)",
            "            name = self.header_table.get_by_index(index)[0]",
            "",
            "            total_consumed = consumed",
            "            length = 0",
            "        else:",
            "            # Literal header name. The first byte was consumed, so we need to",
            "            # move forward.",
            "            data = data[1:]",
            "",
            "            length, consumed = decode_integer(data, 7)",
            "            name = data[consumed:consumed + length]",
            "",
            "            if to_byte(data[0]) & 0x80:",
            "                name = decode_huffman(name)",
            "            total_consumed = consumed + length + 1  # Since we moved forward 1.",
            "",
            "        data = data[consumed + length:]",
            "",
            "        # The header value is definitely length-based.",
            "        length, consumed = decode_integer(data, 7)",
            "        value = data[consumed:consumed + length]",
            "",
            "        if to_byte(data[0]) & 0x80:",
            "            value = decode_huffman(value)",
            "",
            "        # Updated the total consumed length.",
            "        total_consumed += length + consumed",
            "",
            "        # If we have been told never to index the header field, encode that in",
            "        # the tuple we use.",
            "        if not_indexable:",
            "            header = NeverIndexedHeaderTuple(name, value)",
            "        else:",
            "            header = HeaderTuple(name, value)",
            "",
            "        # If we've been asked to index this, add it to the header table.",
            "        if should_index:",
            "            self.header_table.add(name, value)",
            "",
            "        log.debug(",
            "            \"Decoded %s, total consumed %d bytes, indexed %s\",",
            "            header,",
            "            total_consumed,",
            "            should_index",
            "        )",
            "",
            "        return header, total_consumed"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "hpack/hpack",
            "~~~~~~~~~~~",
            "",
            "Implements the HPACK header compression algorithm as detailed by the IETF.",
            "\"\"\"",
            "import logging",
            "",
            "from .table import HeaderTable, table_entry_size",
            "from .compat import to_byte, to_bytes",
            "from .exceptions import HPACKDecodingError, OversizedHeaderListError",
            "from .huffman import HuffmanEncoder",
            "from .huffman_constants import (",
            "    REQUEST_CODES, REQUEST_CODES_LENGTH",
            ")",
            "from .huffman_table import decode_huffman",
            "from .struct import HeaderTuple, NeverIndexedHeaderTuple",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "INDEX_NONE = b'\\x00'",
            "INDEX_NEVER = b'\\x10'",
            "INDEX_INCREMENTAL = b'\\x40'",
            "",
            "try:  # pragma: no cover",
            "    basestring = basestring",
            "except NameError:  # pragma: no cover",
            "    basestring = (str, bytes)",
            "",
            "",
            "# We default the maximum header list we're willing to accept to 64kB. That's a",
            "# lot of headers, but if applications want to raise it they can do.",
            "DEFAULT_MAX_HEADER_LIST_SIZE = 2**16",
            "",
            "",
            "def _unicode_if_needed(header, raw):",
            "    \"\"\"",
            "    Provides a header as a unicode string if raw is False, otherwise returns",
            "    it as a bytestring.",
            "    \"\"\"",
            "    name = to_bytes(header[0])",
            "    value = to_bytes(header[1])",
            "    if not raw:",
            "        name = name.decode('utf-8')",
            "        value = value.decode('utf-8')",
            "    return header.__class__(name, value)",
            "",
            "",
            "def encode_integer(integer, prefix_bits):",
            "    \"\"\"",
            "    This encodes an integer according to the wacky integer encoding rules",
            "    defined in the HPACK spec.",
            "    \"\"\"",
            "    log.debug(\"Encoding %d with %d bits\", integer, prefix_bits)",
            "",
            "    max_number = (2 ** prefix_bits) - 1",
            "",
            "    if integer < max_number:",
            "        return bytearray([integer])  # Seriously?",
            "    else:",
            "        elements = [max_number]",
            "        integer -= max_number",
            "",
            "        while integer >= 128:",
            "            elements.append((integer % 128) + 128)",
            "            integer //= 128  # We need integer division",
            "",
            "        elements.append(integer)",
            "",
            "        return bytearray(elements)",
            "",
            "",
            "def decode_integer(data, prefix_bits):",
            "    \"\"\"",
            "    This decodes an integer according to the wacky integer encoding rules",
            "    defined in the HPACK spec. Returns a tuple of the decoded integer and the",
            "    number of bytes that were consumed from ``data`` in order to get that",
            "    integer.",
            "    \"\"\"",
            "    max_number = (2 ** prefix_bits) - 1",
            "    mask = 0xFF >> (8 - prefix_bits)",
            "    index = 0",
            "",
            "    try:",
            "        number = to_byte(data[index]) & mask",
            "",
            "        if number == max_number:",
            "",
            "            while True:",
            "                index += 1",
            "                next_byte = to_byte(data[index])",
            "",
            "                # There's some duplication here, but that's because this is a",
            "                # hot function, and incurring too many function calls here is",
            "                # a real problem. For that reason, we unrolled the maths.",
            "                if next_byte >= 128:",
            "                    number += (next_byte - 128) * (128 ** (index - 1))",
            "                else:",
            "                    number += next_byte * (128 ** (index - 1))",
            "                    break",
            "    except IndexError:",
            "        raise HPACKDecodingError(",
            "            \"Unable to decode HPACK integer representation from %r\" % data",
            "        )",
            "",
            "    log.debug(\"Decoded %d, consumed %d bytes\", number, index + 1)",
            "",
            "    return number, index + 1",
            "",
            "",
            "def _dict_to_iterable(header_dict):",
            "    \"\"\"",
            "    This converts a dictionary to an iterable of two-tuples. This is a",
            "    HPACK-specific function becuase it pulls \"special-headers\" out first and",
            "    then emits them.",
            "    \"\"\"",
            "    assert isinstance(header_dict, dict)",
            "    keys = sorted(",
            "        header_dict.keys(),",
            "        key=lambda k: not _to_bytes(k).startswith(b':')",
            "    )",
            "    for key in keys:",
            "        yield key, header_dict[key]",
            "",
            "",
            "def _to_bytes(string):",
            "    \"\"\"",
            "    Convert string to bytes.",
            "    \"\"\"",
            "    if not isinstance(string, (basestring)):  # pragma: no cover",
            "        string = str(string)",
            "",
            "    return string if isinstance(string, bytes) else string.encode('utf-8')",
            "",
            "",
            "class Encoder(object):",
            "    \"\"\"",
            "    An HPACK encoder object. This object takes HTTP headers and emits encoded",
            "    HTTP/2 header blocks.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.header_table = HeaderTable()",
            "        self.huffman_coder = HuffmanEncoder(",
            "            REQUEST_CODES, REQUEST_CODES_LENGTH",
            "        )",
            "        self.table_size_changes = []",
            "",
            "    @property",
            "    def header_table_size(self):",
            "        \"\"\"",
            "        Controls the size of the HPACK header table.",
            "        \"\"\"",
            "        return self.header_table.maxsize",
            "",
            "    @header_table_size.setter",
            "    def header_table_size(self, value):",
            "        self.header_table.maxsize = value",
            "        if self.header_table.resized:",
            "            self.table_size_changes.append(value)",
            "",
            "    def encode(self, headers, huffman=True):",
            "        \"\"\"",
            "        Takes a set of headers and encodes them into a HPACK-encoded header",
            "        block.",
            "",
            "        :param headers: The headers to encode. Must be either an iterable of",
            "                        tuples, an iterable of :class:`HeaderTuple",
            "                        <hpack.struct.HeaderTuple>`, or a ``dict``.",
            "",
            "                        If an iterable of tuples, the tuples may be either",
            "                        two-tuples or three-tuples. If they are two-tuples, the",
            "                        tuples must be of the format ``(name, value)``. If they",
            "                        are three-tuples, they must be of the format",
            "                        ``(name, value, sensitive)``, where ``sensitive`` is a",
            "                        boolean value indicating whether the header should be",
            "                        added to header tables anywhere. If not present,",
            "                        ``sensitive`` defaults to ``False``.",
            "",
            "                        If an iterable of :class:`HeaderTuple",
            "                        <hpack.struct.HeaderTuple>`, the tuples must always be",
            "                        two-tuples. Instead of using ``sensitive`` as a third",
            "                        tuple entry, use :class:`NeverIndexedHeaderTuple",
            "                        <hpack.struct.NeverIndexedHeaderTuple>` to request that",
            "                        the field never be indexed.",
            "",
            "                        .. warning:: HTTP/2 requires that all special headers",
            "                            (headers whose names begin with ``:`` characters)",
            "                            appear at the *start* of the header block. While",
            "                            this method will ensure that happens for ``dict``",
            "                            subclasses, callers using any other iterable of",
            "                            tuples **must** ensure they place their special",
            "                            headers at the start of the iterable.",
            "",
            "                            For efficiency reasons users should prefer to use",
            "                            iterables of two-tuples: fixing the ordering of",
            "                            dictionary headers is an expensive operation that",
            "                            should be avoided if possible.",
            "",
            "        :param huffman: (optional) Whether to Huffman-encode any header sent as",
            "                        a literal value. Except for use when debugging, it is",
            "                        recommended that this be left enabled.",
            "",
            "        :returns: A bytestring containing the HPACK-encoded header block.",
            "        \"\"\"",
            "        # Transforming the headers into a header block is a procedure that can",
            "        # be modeled as a chain or pipe. First, the headers are encoded. This",
            "        # encoding can be done a number of ways. If the header name-value pair",
            "        # are already in the header table we can represent them using the",
            "        # indexed representation: the same is true if they are in the static",
            "        # table. Otherwise, a literal representation will be used.",
            "        log.debug(\"HPACK encoding %s\", headers)",
            "        header_block = []",
            "",
            "        # Turn the headers into a list of tuples if possible. This is the",
            "        # natural way to interact with them in HPACK. Because dictionaries are",
            "        # un-ordered, we need to make sure we grab the \"special\" headers first.",
            "        if isinstance(headers, dict):",
            "            headers = _dict_to_iterable(headers)",
            "",
            "        # Before we begin, if the header table size has been changed we need",
            "        # to signal all changes since last emission appropriately.",
            "        if self.header_table.resized:",
            "            header_block.append(self._encode_table_size_change())",
            "            self.header_table.resized = False",
            "",
            "        # Add each header to the header block",
            "        for header in headers:",
            "            sensitive = False",
            "            if isinstance(header, HeaderTuple):",
            "                sensitive = not header.indexable",
            "            elif len(header) > 2:",
            "                sensitive = header[2]",
            "",
            "            header = (_to_bytes(header[0]), _to_bytes(header[1]))",
            "            header_block.append(self.add(header, sensitive, huffman))",
            "",
            "        header_block = b''.join(header_block)",
            "",
            "        log.debug(\"Encoded header block to %s\", header_block)",
            "",
            "        return header_block",
            "",
            "    def add(self, to_add, sensitive, huffman=False):",
            "        \"\"\"",
            "        This function takes a header key-value tuple and serializes it.",
            "        \"\"\"",
            "        log.debug(\"Adding %s to the header table\", to_add)",
            "",
            "        name, value = to_add",
            "",
            "        # Set our indexing mode",
            "        indexbit = INDEX_INCREMENTAL if not sensitive else INDEX_NEVER",
            "",
            "        # Search for a matching header in the header table.",
            "        match = self.header_table.search(name, value)",
            "",
            "        if match is None:",
            "            # Not in the header table. Encode using the literal syntax,",
            "            # and add it to the header table.",
            "            encoded = self._encode_literal(name, value, indexbit, huffman)",
            "            if not sensitive:",
            "                self.header_table.add(name, value)",
            "            return encoded",
            "",
            "        # The header is in the table, break out the values. If we matched",
            "        # perfectly, we can use the indexed representation: otherwise we",
            "        # can use the indexed literal.",
            "        index, name, perfect = match",
            "",
            "        if perfect:",
            "            # Indexed representation.",
            "            encoded = self._encode_indexed(index)",
            "        else:",
            "            # Indexed literal. We are going to add header to the",
            "            # header table unconditionally. It is a future todo to",
            "            # filter out headers which are known to be ineffective for",
            "            # indexing since they just take space in the table and",
            "            # pushed out other valuable headers.",
            "            encoded = self._encode_indexed_literal(",
            "                index, value, indexbit, huffman",
            "            )",
            "            if not sensitive:",
            "                self.header_table.add(name, value)",
            "",
            "        return encoded",
            "",
            "    def _encode_indexed(self, index):",
            "        \"\"\"",
            "        Encodes a header using the indexed representation.",
            "        \"\"\"",
            "        field = encode_integer(index, 7)",
            "        field[0] |= 0x80  # we set the top bit",
            "        return bytes(field)",
            "",
            "    def _encode_literal(self, name, value, indexbit, huffman=False):",
            "        \"\"\"",
            "        Encodes a header with a literal name and literal value. If ``indexing``",
            "        is True, the header will be added to the header table: otherwise it",
            "        will not.",
            "        \"\"\"",
            "        if huffman:",
            "            name = self.huffman_coder.encode(name)",
            "            value = self.huffman_coder.encode(value)",
            "",
            "        name_len = encode_integer(len(name), 7)",
            "        value_len = encode_integer(len(value), 7)",
            "",
            "        if huffman:",
            "            name_len[0] |= 0x80",
            "            value_len[0] |= 0x80",
            "",
            "        return b''.join(",
            "            [indexbit, bytes(name_len), name, bytes(value_len), value]",
            "        )",
            "",
            "    def _encode_indexed_literal(self, index, value, indexbit, huffman=False):",
            "        \"\"\"",
            "        Encodes a header with an indexed name and a literal value and performs",
            "        incremental indexing.",
            "        \"\"\"",
            "        if indexbit != INDEX_INCREMENTAL:",
            "            prefix = encode_integer(index, 4)",
            "        else:",
            "            prefix = encode_integer(index, 6)",
            "",
            "        prefix[0] |= ord(indexbit)",
            "",
            "        if huffman:",
            "            value = self.huffman_coder.encode(value)",
            "",
            "        value_len = encode_integer(len(value), 7)",
            "",
            "        if huffman:",
            "            value_len[0] |= 0x80",
            "",
            "        return b''.join([bytes(prefix), bytes(value_len), value])",
            "",
            "    def _encode_table_size_change(self):",
            "        \"\"\"",
            "        Produces the encoded form of all header table size change context",
            "        updates.",
            "        \"\"\"",
            "        block = b''",
            "        for size_bytes in self.table_size_changes:",
            "            size_bytes = encode_integer(size_bytes, 5)",
            "            size_bytes[0] |= 0x20",
            "            block += bytes(size_bytes)",
            "        self.table_size_changes = []",
            "        return block",
            "",
            "",
            "class Decoder(object):",
            "    \"\"\"",
            "    An HPACK decoder object.",
            "",
            "    .. versionchanged:: 2.3.0",
            "       Added ``max_header_list_size`` argument.",
            "",
            "    :param max_header_list_size: The maximum decompressed size we will allow",
            "        for any single header block. This is a protection against DoS attacks",
            "        that attempt to force the application to expand a relatively small",
            "        amount of data into a really large header list, allowing enormous",
            "        amounts of memory to be allocated.",
            "",
            "        If this amount of data is exceeded, a `OversizedHeaderListError",
            "        <hpack.OversizedHeaderListError>` exception will be raised. At this",
            "        point the connection should be shut down, as the HPACK state will no",
            "        longer be useable.",
            "",
            "        Defaults to 64kB.",
            "    :type max_header_list_size: ``int``",
            "    \"\"\"",
            "    def __init__(self, max_header_list_size=DEFAULT_MAX_HEADER_LIST_SIZE):",
            "        self.header_table = HeaderTable()",
            "",
            "        #: The maximum decompressed size we will allow for any single header",
            "        #: block. This is a protection against DoS attacks that attempt to",
            "        #: force the application to expand a relatively small amount of data",
            "        #: into a really large header list, allowing enormous amounts of memory",
            "        #: to be allocated.",
            "        #:",
            "        #: If this amount of data is exceeded, a `OversizedHeaderListError",
            "        #: <hpack.OversizedHeaderListError>` exception will be raised. At this",
            "        #: point the connection should be shut down, as the HPACK state will no",
            "        #: longer be useable.",
            "        #:",
            "        #: Defaults to 64kB.",
            "        #:",
            "        #: .. versionadded:: 2.3.0",
            "        self.max_header_list_size = max_header_list_size",
            "",
            "    @property",
            "    def header_table_size(self):",
            "        \"\"\"",
            "        Controls the size of the HPACK header table.",
            "        \"\"\"",
            "        return self.header_table.maxsize",
            "",
            "    @header_table_size.setter",
            "    def header_table_size(self, value):",
            "        self.header_table.maxsize = value",
            "",
            "    def decode(self, data, raw=False):",
            "        \"\"\"",
            "        Takes an HPACK-encoded header block and decodes it into a header set.",
            "",
            "        :param data: A bytestring representing a complete HPACK-encoded header",
            "                     block.",
            "        :param raw: (optional) Whether to return the headers as tuples of raw",
            "                    byte strings or to decode them as UTF-8 before returning",
            "                    them. The default value is False, which returns tuples of",
            "                    Unicode strings",
            "        :returns: A list of two-tuples of ``(name, value)`` representing the",
            "                  HPACK-encoded headers, in the order they were decoded.",
            "        :raises HPACKDecodingError: If an error is encountered while decoding",
            "                                    the header block.",
            "        \"\"\"",
            "        log.debug(\"Decoding %s\", data)",
            "",
            "        data_mem = memoryview(data)",
            "        headers = []",
            "        data_len = len(data)",
            "        inflated_size = 0",
            "        current_index = 0",
            "",
            "        while current_index < data_len:",
            "            # Work out what kind of header we're decoding.",
            "            # If the high bit is 1, it's an indexed field.",
            "            current = to_byte(data[current_index])",
            "            indexed = bool(current & 0x80)",
            "",
            "            # Otherwise, if the second-highest bit is 1 it's a field that does",
            "            # alter the header table.",
            "            literal_index = bool(current & 0x40)",
            "",
            "            # Otherwise, if the third-highest bit is 1 it's an encoding context",
            "            # update.",
            "            encoding_update = bool(current & 0x20)",
            "",
            "            if indexed:",
            "                header, consumed = self._decode_indexed(",
            "                    data_mem[current_index:]",
            "                )",
            "            elif literal_index:",
            "                # It's a literal header that does affect the header table.",
            "                header, consumed = self._decode_literal_index(",
            "                    data_mem[current_index:]",
            "                )",
            "            elif encoding_update:",
            "                # It's an update to the encoding context.",
            "                consumed = self._update_encoding_context(data_mem)",
            "                header = None",
            "            else:",
            "                # It's a literal header that does not affect the header table.",
            "                header, consumed = self._decode_literal_no_index(",
            "                    data_mem[current_index:]",
            "                )",
            "",
            "            if header:",
            "                headers.append(header)",
            "                inflated_size += table_entry_size(*header)",
            "",
            "                if inflated_size > self.max_header_list_size:",
            "                    raise OversizedHeaderListError(",
            "                        \"A header list larger than %d has been received\" %",
            "                        self.max_header_list_size",
            "                    )",
            "",
            "            current_index += consumed",
            "",
            "        try:",
            "            return [_unicode_if_needed(h, raw) for h in headers]",
            "        except UnicodeDecodeError:",
            "            raise HPACKDecodingError(\"Unable to decode headers as UTF-8.\")",
            "",
            "    def _update_encoding_context(self, data):",
            "        \"\"\"",
            "        Handles a byte that updates the encoding context.",
            "        \"\"\"",
            "        # We've been asked to resize the header table.",
            "        new_size, consumed = decode_integer(data, 5)",
            "        self.header_table_size = new_size",
            "        return consumed",
            "",
            "    def _decode_indexed(self, data):",
            "        \"\"\"",
            "        Decodes a header represented using the indexed representation.",
            "        \"\"\"",
            "        index, consumed = decode_integer(data, 7)",
            "        header = HeaderTuple(*self.header_table.get_by_index(index))",
            "        log.debug(\"Decoded %s, consumed %d\", header, consumed)",
            "        return header, consumed",
            "",
            "    def _decode_literal_no_index(self, data):",
            "        return self._decode_literal(data, False)",
            "",
            "    def _decode_literal_index(self, data):",
            "        return self._decode_literal(data, True)",
            "",
            "    def _decode_literal(self, data, should_index):",
            "        \"\"\"",
            "        Decodes a header represented with a literal.",
            "        \"\"\"",
            "        total_consumed = 0",
            "",
            "        # When should_index is true, if the low six bits of the first byte are",
            "        # nonzero, the header name is indexed.",
            "        # When should_index is false, if the low four bits of the first byte",
            "        # are nonzero the header name is indexed.",
            "        if should_index:",
            "            indexed_name = to_byte(data[0]) & 0x3F",
            "            name_len = 6",
            "            not_indexable = False",
            "        else:",
            "            high_byte = to_byte(data[0])",
            "            indexed_name = high_byte & 0x0F",
            "            name_len = 4",
            "            not_indexable = high_byte & 0x10",
            "",
            "        if indexed_name:",
            "            # Indexed header name.",
            "            index, consumed = decode_integer(data, name_len)",
            "            name = self.header_table.get_by_index(index)[0]",
            "",
            "            total_consumed = consumed",
            "            length = 0",
            "        else:",
            "            # Literal header name. The first byte was consumed, so we need to",
            "            # move forward.",
            "            data = data[1:]",
            "",
            "            length, consumed = decode_integer(data, 7)",
            "            name = data[consumed:consumed + length]",
            "",
            "            if to_byte(data[0]) & 0x80:",
            "                name = decode_huffman(name)",
            "            total_consumed = consumed + length + 1  # Since we moved forward 1.",
            "",
            "        data = data[consumed + length:]",
            "",
            "        # The header value is definitely length-based.",
            "        length, consumed = decode_integer(data, 7)",
            "        value = data[consumed:consumed + length]",
            "",
            "        if to_byte(data[0]) & 0x80:",
            "            value = decode_huffman(value)",
            "",
            "        # Updated the total consumed length.",
            "        total_consumed += length + consumed",
            "",
            "        # If we have been told never to index the header field, encode that in",
            "        # the tuple we use.",
            "        if not_indexable:",
            "            header = NeverIndexedHeaderTuple(name, value)",
            "        else:",
            "            header = HeaderTuple(name, value)",
            "",
            "        # If we've been asked to index this, add it to the header table.",
            "        if should_index:",
            "            self.header_table.add(name, value)",
            "",
            "        log.debug(",
            "            \"Decoded %s, total consumed %d bytes, indexed %s\",",
            "            header,",
            "            total_consumed,",
            "            should_index",
            "        )",
            "",
            "        return header, total_consumed"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "10": [],
            "12": [],
            "352": [
                "Decoder"
            ],
            "354": [
                "Decoder",
                "__init__"
            ]
        },
        "addLocation": []
    }
}