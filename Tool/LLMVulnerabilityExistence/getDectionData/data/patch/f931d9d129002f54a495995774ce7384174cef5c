{
    "label_studio/core/settings/base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import re"
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " from datetime import timedelta"
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from label_studio.core.utils.params import get_bool_env"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+from label_studio.core.utils.params import get_bool_env, get_env_list"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " formatter = 'standard'"
            },
            "7": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " JSON_LOG = get_bool_env('JSON_LOG', False)"
            },
            "8": {
                "beforePatchRowNumber": 667,
                "afterPatchRowNumber": 667,
                "PatchRowcode": " REAL_HOSTNAME = os.getenv('HOSTNAME')  # we have to use getenv, because we don't use LABEL_STUDIO_ prefix"
            },
            "9": {
                "beforePatchRowNumber": 668,
                "afterPatchRowNumber": 668,
                "PatchRowcode": " GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS = get_bool_env('GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS', False)"
            },
            "10": {
                "beforePatchRowNumber": 669,
                "afterPatchRowNumber": 669,
                "PatchRowcode": " PUBLIC_API_DOCS = get_bool_env('PUBLIC_API_DOCS', False)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 670,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 671,
                "PatchRowcode": "+# By default, we disallow filters with foreign keys in data manager for security reasons."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 672,
                "PatchRowcode": "+# Add to this list (either here in code, or via the env) to allow specific filters that rely on foreign keys."
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 673,
                "PatchRowcode": "+DATA_MANAGER_FILTER_ALLOWLIST = list("
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 674,
                "PatchRowcode": "+    set(get_env_list('DATA_MANAGER_FILTER_ALLOWLIST') + ['updated_by__active_organization'])"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 675,
                "PatchRowcode": "+)"
            }
        },
        "frontPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "\"\"\"",
            "Django Base settings for Label Studio.",
            "",
            "For more information on this file, see",
            "https://docs.djangoproject.com/en/3.1/topics/settings/",
            "",
            "For the full list of settings and their values, see",
            "https://docs.djangoproject.com/en/3.1/ref/settings/",
            "\"\"\"",
            "import json",
            "import logging",
            "import os",
            "import re",
            "from datetime import timedelta",
            "",
            "from label_studio.core.utils.params import get_bool_env",
            "",
            "formatter = 'standard'",
            "JSON_LOG = get_bool_env('JSON_LOG', False)",
            "if JSON_LOG:",
            "    formatter = 'json'",
            "",
            "LOGGING = {",
            "    'version': 1,",
            "    'disable_existing_loggers': False,",
            "    'formatters': {",
            "        'json': {",
            "            '()': 'label_studio.core.utils.formatter.CustomJsonFormatter',",
            "            'format': '[%(asctime)s] [%(name)s::%(funcName)s::%(lineno)d] [%(levelname)s] [%(user_id)s] %(message)s',",
            "            'datefmt': '%d/%b/%Y:%H:%M:%S %z',",
            "        },",
            "        'standard': {",
            "            'format': '[%(asctime)s] [%(name)s::%(funcName)s::%(lineno)d] [%(levelname)s] %(message)s',",
            "        },",
            "    },",
            "    'handlers': {",
            "        'console': {",
            "            'class': 'logging.StreamHandler',",
            "            'formatter': formatter,",
            "        },",
            "    },",
            "    'root': {",
            "        'handlers': ['console'],",
            "        'level': os.environ.get('LOG_LEVEL', 'DEBUG'),",
            "    },",
            "    'loggers': {",
            "        'pykwalify': {'level': 'ERROR', 'propagate': False},",
            "        'tavern': {'level': 'ERROR', 'propagate': False},",
            "        'asyncio': {'level': 'WARNING'},",
            "        'rules': {'level': 'WARNING'},",
            "        'django': {",
            "            'handlers': ['console'],",
            "            # 'propagate': True,",
            "        },",
            "        'django_auth_ldap': {'level': os.environ.get('LOG_LEVEL', 'DEBUG')},",
            "        'rq.worker': {",
            "            'handlers': ['console'],",
            "            'level': os.environ.get('LOG_LEVEL', 'INFO'),",
            "        },",
            "        'ddtrace': {",
            "            'handlers': ['console'],",
            "            'level': 'WARNING',",
            "        },",
            "        'ldclient.util': {",
            "            'handlers': ['console'],",
            "            'level': 'ERROR',",
            "        },",
            "    },",
            "}",
            "",
            "# for printing messages before main logging config applied",
            "if not logging.getLogger().hasHandlers():",
            "    logging.basicConfig(level=logging.DEBUG, format='%(message)s')",
            "",
            "from label_studio.core.utils.io import get_data_dir",
            "from label_studio.core.utils.params import get_bool_env, get_env",
            "",
            "logger = logging.getLogger(__name__)",
            "SILENCED_SYSTEM_CHECKS = []",
            "",
            "# Hostname is used for proper path generation to the resources, pages, etc",
            "HOSTNAME = get_env('HOST', '')",
            "if HOSTNAME:",
            "    if not HOSTNAME.startswith('http://') and not HOSTNAME.startswith('https://'):",
            "        logger.info(",
            "            '! HOST variable found in environment, but it must start with http:// or https://, ignore it: %s', HOSTNAME",
            "        )",
            "        HOSTNAME = ''",
            "    else:",
            "        logger.info('=> Hostname correctly is set to: %s', HOSTNAME)",
            "        if HOSTNAME.endswith('/'):",
            "            HOSTNAME = HOSTNAME[0:-1]",
            "",
            "        # for django url resolver",
            "        if HOSTNAME:",
            "            # http[s]://domain.com:8080/script_name => /script_name",
            "            pattern = re.compile(r'^http[s]?:\\/\\/([^:\\/\\s]+(:\\d*)?)(.*)?')",
            "            match = pattern.match(HOSTNAME)",
            "            FORCE_SCRIPT_NAME = match.group(3)",
            "            if FORCE_SCRIPT_NAME:",
            "                logger.info('=> Django URL prefix is set to: %s', FORCE_SCRIPT_NAME)",
            "",
            "INTERNAL_PORT = '8080'",
            "",
            "# SECURITY WARNING: don't run with debug turned on in production!",
            "DEBUG = get_bool_env('DEBUG', True)",
            "DEBUG_MODAL_EXCEPTIONS = get_bool_env('DEBUG_MODAL_EXCEPTIONS', True)",
            "",
            "# Whether to verify SSL certs when making external requests, eg in the uploader",
            "# \u26a0\ufe0f Turning this off means assuming risk. \u26a0\ufe0f",
            "# Overridable at organization level via Organization#verify_ssl_certs",
            "VERIFY_SSL_CERTS = get_bool_env('VERIFY_SSL_CERTS', True)",
            "",
            "# 'sqlite-dll-<arch>-<version>.zip' should be hosted at this prefix",
            "WINDOWS_SQLITE_BINARY_HOST_PREFIX = get_env('WINDOWS_SQLITE_BINARY_HOST_PREFIX', 'https://www.sqlite.org/2023/')",
            "",
            "# Build paths inside the project like this: os.path.join(BASE_DIR, ...)",
            "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))",
            "",
            "# Base path for media root and other uploaded files",
            "BASE_DATA_DIR = get_env('BASE_DATA_DIR', get_data_dir())",
            "os.makedirs(BASE_DATA_DIR, exist_ok=True)",
            "logger.info('=> Database and media directory: %s', BASE_DATA_DIR)",
            "",
            "# Databases",
            "# https://docs.djangoproject.com/en/2.1/ref/settings/#databases",
            "DJANGO_DB_MYSQL = 'mysql'",
            "DJANGO_DB_SQLITE = 'sqlite'",
            "DJANGO_DB_POSTGRESQL = 'postgresql'",
            "DJANGO_DB = 'default'",
            "DATABASE_NAME_DEFAULT = os.path.join(BASE_DATA_DIR, 'label_studio.sqlite3')",
            "DATABASE_NAME = get_env('DATABASE_NAME', DATABASE_NAME_DEFAULT)",
            "DATABASES_ALL = {",
            "    DJANGO_DB_POSTGRESQL: {",
            "        'ENGINE': 'django.db.backends.postgresql',",
            "        'USER': get_env('POSTGRE_USER', 'postgres'),",
            "        'PASSWORD': get_env('POSTGRE_PASSWORD', 'postgres'),",
            "        'NAME': get_env('POSTGRE_NAME', 'postgres'),",
            "        'HOST': get_env('POSTGRE_HOST', 'localhost'),",
            "        'PORT': int(get_env('POSTGRE_PORT', '5432')),",
            "    },",
            "    DJANGO_DB_MYSQL: {",
            "        'ENGINE': 'django.db.backends.mysql',",
            "        'USER': get_env('MYSQL_USER', 'root'),",
            "        'PASSWORD': get_env('MYSQL_PASSWORD', ''),",
            "        'NAME': get_env('MYSQL_NAME', 'labelstudio'),",
            "        'HOST': get_env('MYSQL_HOST', 'localhost'),",
            "        'PORT': int(get_env('MYSQL_PORT', '3306')),",
            "    },",
            "    DJANGO_DB_SQLITE: {",
            "        'ENGINE': 'django.db.backends.sqlite3',",
            "        'NAME': DATABASE_NAME,",
            "        'OPTIONS': {",
            "            # 'timeout': 20,",
            "        },",
            "    },",
            "}",
            "DATABASES_ALL['default'] = DATABASES_ALL[DJANGO_DB_POSTGRESQL]",
            "DATABASES = {'default': DATABASES_ALL.get(get_env('DJANGO_DB', 'default'))}",
            "",
            "DEFAULT_AUTO_FIELD = 'django.db.models.AutoField'",
            "",
            "if get_bool_env('GOOGLE_LOGGING_ENABLED', False):",
            "    logging.info('Google Cloud Logging handler is enabled.')",
            "    try:",
            "        import google.cloud.logging",
            "        from google.auth.exceptions import GoogleAuthError",
            "",
            "        client = google.cloud.logging.Client()",
            "        client.setup_logging()",
            "",
            "        LOGGING['handlers']['google_cloud_logging'] = {",
            "            'level': get_env('LOG_LEVEL', 'WARNING'),",
            "            'class': 'google.cloud.logging.handlers.CloudLoggingHandler',",
            "            'client': client,",
            "        }",
            "        LOGGING['root']['handlers'].append('google_cloud_logging')",
            "    except GoogleAuthError:",
            "        logger.exception('Google Cloud Logging handler could not be setup.')",
            "",
            "INSTALLED_APPS = [",
            "    'django.contrib.admin',",
            "    'django.contrib.auth',",
            "    'django.contrib.contenttypes',",
            "    'django.contrib.sessions',",
            "    'django.contrib.messages',",
            "    'django.contrib.staticfiles',",
            "    'django.contrib.humanize',",
            "    'drf_yasg',",
            "    'corsheaders',",
            "    'django_extensions',",
            "    'django_rq',",
            "    'django_filters',",
            "    'rules',",
            "    'annoying',",
            "    'rest_framework',",
            "    'rest_framework.authtoken',",
            "    'drf_generators',",
            "    'core',",
            "    'users',",
            "    'organizations',",
            "    'data_import',",
            "    'data_export',",
            "    'projects',",
            "    'tasks',",
            "    'data_manager',",
            "    'io_storages',",
            "    'ml',",
            "    'webhooks',",
            "    'labels_manager',",
            "]",
            "",
            "MIDDLEWARE = [",
            "    'corsheaders.middleware.CorsMiddleware',",
            "    'django.middleware.security.SecurityMiddleware',",
            "    'django.contrib.sessions.middleware.SessionMiddleware',",
            "    'django.middleware.locale.LocaleMiddleware',",
            "    'core.middleware.DisableCSRF',",
            "    'django.middleware.csrf.CsrfViewMiddleware',",
            "    'django.contrib.auth.middleware.AuthenticationMiddleware',",
            "    'django.contrib.messages.middleware.MessageMiddleware',",
            "    'core.middleware.CommonMiddlewareAppendSlashWithoutRedirect',  # instead of 'CommonMiddleware'",
            "    'core.middleware.CommonMiddleware',",
            "    'django_user_agents.middleware.UserAgentMiddleware',",
            "    'core.middleware.SetSessionUIDMiddleware',",
            "    'core.middleware.ContextLogMiddleware',",
            "    'core.middleware.DatabaseIsLockedRetryMiddleware',",
            "    'core.current_request.ThreadLocalMiddleware',",
            "]",
            "",
            "REST_FRAMEWORK = {",
            "    'DEFAULT_FILTER_BACKENDS': ['django_filters.rest_framework.DjangoFilterBackend'],",
            "    'DEFAULT_AUTHENTICATION_CLASSES': (",
            "        'rest_framework.authentication.TokenAuthentication',",
            "        'rest_framework.authentication.SessionAuthentication',",
            "    ),",
            "    'DEFAULT_PERMISSION_CLASSES': [",
            "        'core.api_permissions.HasObjectPermission',",
            "        'rest_framework.permissions.IsAuthenticated',",
            "    ],",
            "    'EXCEPTION_HANDLER': 'core.utils.common.custom_exception_handler',",
            "    'DEFAULT_RENDERER_CLASSES': ('rest_framework.renderers.JSONRenderer',),",
            "    'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.NamespaceVersioning',",
            "    'PAGE_SIZE': 100,",
            "    # 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination'",
            "}",
            "SILENCED_SYSTEM_CHECKS += ['rest_framework.W001']",
            "",
            "# CORS & Host settings",
            "INTERNAL_IPS = [  # django debug toolbar for django==2.2 requirement",
            "    '127.0.0.1',",
            "    'localhost',",
            "]",
            "CORS_ORIGIN_ALLOW_ALL = True",
            "CORS_ALLOW_METHODS = [",
            "    'DELETE',",
            "    'GET',",
            "    'OPTIONS',",
            "    'PATCH',",
            "    'POST',",
            "    'PUT',",
            "]",
            "ALLOWED_HOSTS = ['*']",
            "",
            "# Auth modules",
            "AUTH_USER_MODEL = 'users.User'",
            "AUTHENTICATION_BACKENDS = [",
            "    'rules.permissions.ObjectPermissionBackend',",
            "    'django.contrib.auth.backends.ModelBackend',",
            "]",
            "USE_USERNAME_FOR_LOGIN = False",
            "",
            "DISABLE_SIGNUP_WITHOUT_LINK = get_bool_env('DISABLE_SIGNUP_WITHOUT_LINK', False)",
            "",
            "# Password validation:",
            "# https://docs.djangoproject.com/en/2.1/ref/settings/#auth-password-validators",
            "AUTH_PASSWORD_VALIDATORS = [",
            "    {'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator'},",
            "]",
            "",
            "# Django templates",
            "TEMPLATES_DIR = os.path.join(os.path.dirname(BASE_DIR), 'templates')  # ../../from_this = 'web' dir",
            "TEMPLATES = [",
            "    {",
            "        'BACKEND': 'django.template.backends.django.DjangoTemplates',",
            "        'DIRS': [TEMPLATES_DIR],",
            "        'APP_DIRS': True,",
            "        'OPTIONS': {",
            "            'context_processors': [",
            "                'django.template.context_processors.debug',",
            "                'django.template.context_processors.request',",
            "                'django.contrib.auth.context_processors.auth',",
            "                'django.contrib.messages.context_processors.messages',",
            "                'core.context_processors.settings',",
            "            ],",
            "            'builtins': ['django.templatetags.i18n'],",
            "        },",
            "    }",
            "]",
            "",
            "# RQ",
            "RQ_QUEUES = {",
            "    'critical': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'high': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'default': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'low': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "}",
            "",
            "# Swagger: automatic API documentation",
            "SWAGGER_SETTINGS = {",
            "    'SECURITY_DEFINITIONS': {",
            "        'Token': {",
            "            'type': 'apiKey',",
            "            'name': 'Authorization',",
            "            'in': 'header',",
            "            'description': 'The token (or API key) must be passed as a request header. '",
            "            'You can find your user token on the User Account page in Label Studio. Example: '",
            "            '<br><pre><code class=\"language-bash\">'",
            "            'curl https://label-studio-host/api/projects -H \"Authorization: Token [your-token]\"'",
            "            '</code></pre>',",
            "        }",
            "    },",
            "    'APIS_SORTER': 'alpha',",
            "    'SUPPORTED_SUBMIT_METHODS': ['get', 'post', 'put', 'delete', 'patch'],",
            "    'OPERATIONS_SORTER': 'alpha',",
            "}",
            "",
            "SENTRY_DSN = get_env('SENTRY_DSN', None)",
            "SENTRY_RATE = float(get_env('SENTRY_RATE', 0.25))",
            "SENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'stage.opensource')",
            "SENTRY_REDIS_ENABLED = False",
            "FRONTEND_SENTRY_DSN = get_env('FRONTEND_SENTRY_DSN', None)",
            "FRONTEND_SENTRY_RATE = get_env('FRONTEND_SENTRY_RATE', 0.1)",
            "FRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'stage.opensource')",
            "",
            "ROOT_URLCONF = 'core.urls'",
            "WSGI_APPLICATION = 'core.wsgi.application'",
            "GRAPHIQL = True",
            "",
            "# Internationalization",
            "# https://docs.djangoproject.com/en/2.1/topics/i18n/",
            "LANGUAGE_CODE = 'en-us'",
            "TIME_ZONE = 'UTC'",
            "USE_I18N = False",
            "USE_L10N = True",
            "USE_TZ = True",
            "",
            "# Static files (CSS, JavaScript, Images)",
            "# https://docs.djangoproject.com/en/2.1/howto/static-files/",
            "STATIC_URL = '/static/'",
            "# if FORCE_SCRIPT_NAME:",
            "#    STATIC_URL = FORCE_SCRIPT_NAME + STATIC_URL",
            "logger.info(f'=> Static URL is set to: {STATIC_URL}')",
            "",
            "STATIC_ROOT = os.path.join(BASE_DIR, 'static_build')",
            "STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static')]",
            "STATICFILES_FINDERS = (",
            "    'django.contrib.staticfiles.finders.FileSystemFinder',",
            "    'django.contrib.staticfiles.finders.AppDirectoriesFinder',",
            ")",
            "STATICFILES_STORAGE = 'core.storage.SkipMissedManifestStaticFilesStorage'",
            "",
            "# Sessions and CSRF",
            "SESSION_COOKIE_SECURE = bool(int(get_env('SESSION_COOKIE_SECURE', False)))",
            "SESSION_COOKIE_SAMESITE = get_env('SESSION_COOKIE_SAMESITE', 'Lax')",
            "",
            "CSRF_COOKIE_SECURE = bool(int(get_env('CSRF_COOKIE_SECURE', SESSION_COOKIE_SECURE)))",
            "CSRF_COOKIE_HTTPONLY = bool(int(get_env('CSRF_COOKIE_HTTPONLY', SESSION_COOKIE_SECURE)))",
            "CSRF_COOKIE_SAMESITE = get_env('CSRF_COOKIE_SAMESITE', 'Lax')",
            "",
            "# Inactivity user sessions",
            "INACTIVITY_SESSION_TIMEOUT_ENABLED = bool(int(get_env('INACTIVITY_SESSION_TIMEOUT_ENABLED', True)))",
            "# The most time a login will last, regardless of activity",
            "MAX_SESSION_AGE = int(get_env('MAX_SESSION_AGE', timedelta(days=14).total_seconds()))",
            "# The most time that can elapse between activity with the server before the user is logged out",
            "MAX_TIME_BETWEEN_ACTIVITY = int(get_env('MAX_TIME_BETWEEN_ACTIVITY', timedelta(days=5).total_seconds()))",
            "",
            "SSRF_PROTECTION_ENABLED = get_bool_env('SSRF_PROTECTION_ENABLED', False)",
            "",
            "# user media files",
            "MEDIA_ROOT = os.path.join(BASE_DATA_DIR, 'media')",
            "os.makedirs(MEDIA_ROOT, exist_ok=True)",
            "MEDIA_URL = '/data/'",
            "UPLOAD_DIR = 'upload'",
            "AVATAR_PATH = 'avatars'",
            "",
            "SUPPORTED_EXTENSIONS = set(",
            "    [",
            "        '.bmp',",
            "        '.csv',",
            "        '.flac',",
            "        '.gif',",
            "        '.htm',",
            "        '.html',",
            "        '.jpg',",
            "        '.jpeg',",
            "        '.json',",
            "        '.m4a',",
            "        '.mp3',",
            "        '.ogg',",
            "        '.png',",
            "        '.svg',",
            "        '.tsv',",
            "        '.txt',",
            "        '.wav',",
            "        '.xml',",
            "        '.mp4',",
            "        '.webm',",
            "        '.webp',",
            "    ]",
            ")",
            "",
            "# directory for files created during unit tests",
            "TEST_DATA_ROOT = os.path.join(BASE_DATA_DIR, 'test_data')",
            "os.makedirs(TEST_DATA_ROOT, exist_ok=True)",
            "",
            "# project exports",
            "EXPORT_DIR = os.path.join(BASE_DATA_DIR, 'export')",
            "EXPORT_URL_ROOT = '/export/'",
            "EXPORT_MIXIN = 'data_export.mixins.ExportMixin'",
            "# old export dir",
            "os.makedirs(EXPORT_DIR, exist_ok=True)",
            "# dir for delayed export",
            "DELAYED_EXPORT_DIR = 'export'",
            "os.makedirs(os.path.join(BASE_DATA_DIR, MEDIA_ROOT, DELAYED_EXPORT_DIR), exist_ok=True)",
            "",
            "# file / task size limits",
            "DATA_UPLOAD_MAX_MEMORY_SIZE = int(get_env('DATA_UPLOAD_MAX_MEMORY_SIZE', 250 * 1024 * 1024))",
            "DATA_UPLOAD_MAX_NUMBER_FILES = int(get_env('DATA_UPLOAD_MAX_NUMBER_FILES', 100))",
            "TASKS_MAX_NUMBER = 1000000",
            "TASKS_MAX_FILE_SIZE = DATA_UPLOAD_MAX_MEMORY_SIZE",
            "",
            "TASK_LOCK_TTL = int(get_env('TASK_LOCK_TTL', default=86400))",
            "",
            "LABEL_STREAM_HISTORY_LIMIT = int(get_env('LABEL_STREAM_HISTORY_LIMIT', default=100))",
            "",
            "RANDOM_NEXT_TASK_SAMPLE_SIZE = int(get_env('RANDOM_NEXT_TASK_SAMPLE_SIZE', 50))",
            "",
            "TASK_API_PAGE_SIZE_MAX = int(get_env('TASK_API_PAGE_SIZE_MAX', 0)) or None",
            "",
            "# Email backend",
            "FROM_EMAIL = get_env('FROM_EMAIL', 'Label Studio <hello@labelstud.io>')",
            "EMAIL_BACKEND = get_env('EMAIL_BACKEND', 'django.core.mail.backends.dummy.EmailBackend')",
            "",
            "ENABLE_LOCAL_FILES_STORAGE = get_bool_env('ENABLE_LOCAL_FILES_STORAGE', default=True)",
            "LOCAL_FILES_SERVING_ENABLED = get_bool_env('LOCAL_FILES_SERVING_ENABLED', default=False)",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env('LOCAL_FILES_DOCUMENT_ROOT', default=os.path.abspath(os.sep))",
            "",
            "SYNC_ON_TARGET_STORAGE_CREATION = get_bool_env('SYNC_ON_TARGET_STORAGE_CREATION', default=True)",
            "",
            "ALLOW_IMPORT_TASKS_WITH_UNKNOWN_EMAILS = get_bool_env('ALLOW_IMPORT_TASKS_WITH_UNKNOWN_EMAILS', default=False)",
            "",
            "\"\"\" React Libraries: do not forget to change this dir in /etc/nginx/nginx.conf \"\"\"",
            "# EDITOR = label-studio-frontend repository",
            "EDITOR_ROOT = os.path.join(BASE_DIR, '../frontend/dist/lsf')",
            "# DM = data manager (included into FRONTEND due npm building, we need only version.json file from there)",
            "DM_ROOT = os.path.join(BASE_DIR, '../frontend/dist/dm')",
            "# FRONTEND = GUI for django backend",
            "REACT_APP_ROOT = os.path.join(BASE_DIR, '../frontend/dist/react-app')",
            "",
            "# per project settings",
            "BATCH_SIZE = 1000",
            "PROJECT_TITLE_MIN_LEN = 3",
            "PROJECT_TITLE_MAX_LEN = 50",
            "LOGIN_REDIRECT_URL = '/'",
            "LOGIN_URL = '/'",
            "MIN_GROUND_TRUTH = 10",
            "DATA_UNDEFINED_NAME = '$undefined$'",
            "LICENSE = {}",
            "VERSIONS = {}",
            "VERSION_EDITION = 'Community'",
            "LATEST_VERSION_CHECK = True",
            "VERSIONS_CHECK_TIME = 0",
            "ALLOW_ORGANIZATION_WEBHOOKS = get_bool_env('ALLOW_ORGANIZATION_WEBHOOKS', False)",
            "CONVERTER_DOWNLOAD_RESOURCES = get_bool_env('CONVERTER_DOWNLOAD_RESOURCES', True)",
            "EXPERIMENTAL_FEATURES = get_bool_env('EXPERIMENTAL_FEATURES', False)",
            "USE_ENFORCE_CSRF_CHECKS = get_bool_env('USE_ENFORCE_CSRF_CHECKS', True)  # False is for tests",
            "CLOUD_FILE_STORAGE_ENABLED = False",
            "",
            "IO_STORAGES_IMPORT_LINK_NAMES = [",
            "    'io_storages_s3importstoragelink',",
            "    'io_storages_gcsimportstoragelink',",
            "    'io_storages_azureblobimportstoragelink',",
            "    'io_storages_localfilesimportstoragelink',",
            "    'io_storages_redisimportstoragelink',",
            "]",
            "",
            "CREATE_ORGANIZATION = 'organizations.functions.create_organization'",
            "SAVE_USER = 'users.functions.save_user'",
            "POST_PROCESS_REIMPORT = 'core.utils.common.empty'",
            "USER_SERIALIZER = 'users.serializers.BaseUserSerializer'",
            "USER_SERIALIZER_UPDATE = 'users.serializers.BaseUserSerializerUpdate'",
            "TASK_SERIALIZER = 'tasks.serializers.BaseTaskSerializer'",
            "EXPORT_DATA_SERIALIZER = 'data_export.serializers.BaseExportDataSerializer'",
            "DATA_MANAGER_GET_ALL_COLUMNS = 'data_manager.functions.get_all_columns'",
            "DATA_MANAGER_ANNOTATIONS_MAP = {}",
            "DATA_MANAGER_ACTIONS = {}",
            "DATA_MANAGER_CUSTOM_FILTER_EXPRESSIONS = 'data_manager.functions.custom_filter_expressions'",
            "DATA_MANAGER_PREPROCESS_FILTER = 'data_manager.functions.preprocess_filter'",
            "USER_LOGIN_FORM = 'users.forms.LoginForm'",
            "PROJECT_MIXIN = 'projects.mixins.ProjectMixin'",
            "TASK_MIXIN = 'tasks.mixins.TaskMixin'",
            "ANNOTATION_MIXIN = 'tasks.mixins.AnnotationMixin'",
            "ORGANIZATION_MIXIN = 'organizations.mixins.OrganizationMixin'",
            "USER_MIXIN = 'users.mixins.UserMixin'",
            "USER_PERM = 'core.api_permissions.HasOwnerPermission'",
            "RECALCULATE_ALL_STATS = None",
            "GET_STORAGE_LIST = 'io_storages.functions.get_storage_list'",
            "STORAGE_ANNOTATION_SERIALIZER = 'io_storages.serializers.StorageAnnotationSerializer'",
            "TASK_SERIALIZER_BULK = 'tasks.serializers.BaseTaskSerializerBulk'",
            "PREPROCESS_FIELD_NAME = 'data_manager.functions.preprocess_field_name'",
            "INTERACTIVE_DATA_SERIALIZER = 'data_export.serializers.BaseExportDataSerializerForInteractive'",
            "DELETE_TASKS_ANNOTATIONS_POSTPROCESS = None",
            "",
            "",
            "def project_delete(project):",
            "    project.delete()",
            "",
            "",
            "def user_auth(user_model, email, password):",
            "    return None",
            "",
            "",
            "def collect_versions_dummy(**kwargs):",
            "    return {}",
            "",
            "",
            "PROJECT_DELETE = project_delete",
            "USER_AUTH = user_auth",
            "COLLECT_VERSIONS = collect_versions_dummy",
            "",
            "WEBHOOK_TIMEOUT = float(get_env('WEBHOOK_TIMEOUT', 1.0))",
            "WEBHOOK_BATCH_SIZE = int(get_env('WEBHOOK_BATCH_SIZE', 100))",
            "WEBHOOK_SERIALIZERS = {",
            "    'project': 'webhooks.serializers_for_hooks.ProjectWebhookSerializer',",
            "    'task': 'webhooks.serializers_for_hooks.TaskWebhookSerializer',",
            "    'annotation': 'webhooks.serializers_for_hooks.AnnotationWebhookSerializer',",
            "    'label': 'labels_manager.serializers.LabelSerializer',",
            "    'label_link': 'labels_manager.serializers.LabelLinkSerializer',",
            "}",
            "",
            "EDITOR_KEYMAP = json.dumps(get_env('EDITOR_KEYMAP'))",
            "",
            "# fix a problem with Windows mimetypes for JS and PNG",
            "import mimetypes",
            "",
            "mimetypes.add_type('application/javascript', '.js', True)",
            "mimetypes.add_type('image/png', '.png', True)",
            "",
            "# fields name was used in DM api before",
            "REST_FLEX_FIELDS = {'FIELDS_PARAM': 'include'}",
            "",
            "INTERPOLATE_KEY_FRAMES = get_env('INTERPOLATE_KEY_FRAMES', False)",
            "",
            "# Feature Flags",
            "FEATURE_FLAGS_API_KEY = get_env('FEATURE_FLAGS_API_KEY', default='any key')",
            "",
            "# we may set feature flags from file",
            "FEATURE_FLAGS_FROM_FILE = get_bool_env('FEATURE_FLAGS_FROM_FILE', False)",
            "FEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')",
            "# or if file is not set, default is using offline mode",
            "FEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)",
            "# default value for feature flags (if not overridden by environment or client)",
            "FEATURE_FLAGS_DEFAULT_VALUE = False",
            "",
            "# Whether to send analytics telemetry data",
            "COLLECT_ANALYTICS = get_bool_env('collect_analytics', True)",
            "",
            "# Strip harmful content from SVG files by default",
            "SVG_SECURITY_CLEANUP = get_bool_env('SVG_SECURITY_CLEANUP', False)",
            "",
            "ML_BLOCK_LOCAL_IP = get_bool_env('ML_BLOCK_LOCAL_IP', False)",
            "",
            "RQ_LONG_JOB_TIMEOUT = int(get_env('RQ_LONG_JOB_TIMEOUT', 36000))",
            "",
            "APP_WEBSERVER = get_env('APP_WEBSERVER', 'django')",
            "",
            "BATCH_JOB_RETRY_TIMEOUT = int(get_env('BATCH_JOB_RETRY_TIMEOUT', 60))",
            "",
            "FUTURE_SAVE_TASK_TO_STORAGE = get_bool_env('FUTURE_SAVE_TASK_TO_STORAGE', default=False)",
            "FUTURE_SAVE_TASK_TO_STORAGE_JSON_EXT = get_bool_env('FUTURE_SAVE_TASK_TO_STORAGE_JSON_EXT', default=True)",
            "STORAGE_IN_PROGRESS_TIMER = float(get_env('STORAGE_IN_PROGRESS_TIMER', 5.0))",
            "",
            "USE_NGINX_FOR_EXPORT_DOWNLOADS = get_bool_env('USE_NGINX_FOR_EXPORT_DOWNLOADS', False)",
            "",
            "if get_env('MINIO_STORAGE_ENDPOINT') and not get_bool_env('MINIO_SKIP', False):",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'",
            "    AWS_STORAGE_BUCKET_NAME = get_env('MINIO_STORAGE_BUCKET_NAME')",
            "    AWS_ACCESS_KEY_ID = get_env('MINIO_STORAGE_ACCESS_KEY')",
            "    AWS_SECRET_ACCESS_KEY = get_env('MINIO_STORAGE_SECRET_KEY')",
            "    AWS_S3_ENDPOINT_URL = get_env('MINIO_STORAGE_ENDPOINT')",
            "    AWS_QUERYSTRING_AUTH = False",
            "    # make domain for FileUpload.file",
            "    AWS_S3_SECURE_URLS = False",
            "    AWS_S3_URL_PROTOCOL = 'http:' if HOSTNAME.startswith('http://') else 'https:'",
            "    AWS_S3_CUSTOM_DOMAIN = HOSTNAME.replace('http://', '').replace('https://', '') + '/data'",
            "",
            "if get_env('STORAGE_TYPE') == 's3':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'core.storage.CustomS3Boto3Storage'",
            "    if get_env('STORAGE_AWS_ACCESS_KEY_ID'):",
            "        AWS_ACCESS_KEY_ID = get_env('STORAGE_AWS_ACCESS_KEY_ID')",
            "    if get_env('STORAGE_AWS_SECRET_ACCESS_KEY'):",
            "        AWS_SECRET_ACCESS_KEY = get_env('STORAGE_AWS_SECRET_ACCESS_KEY')",
            "    AWS_STORAGE_BUCKET_NAME = get_env('STORAGE_AWS_BUCKET_NAME')",
            "    AWS_S3_REGION_NAME = get_env('STORAGE_AWS_REGION_NAME', None)",
            "    AWS_S3_ENDPOINT_URL = get_env('STORAGE_AWS_ENDPOINT_URL', None)",
            "    if get_env('STORAGE_AWS_OBJECT_PARAMETERS'):",
            "        AWS_S3_OBJECT_PARAMETERS = json.loads(get_env('STORAGE_AWS_OBJECT_PARAMETERS'))",
            "    AWS_QUERYSTRING_EXPIRE = int(get_env('STORAGE_AWS_X_AMZ_EXPIRES', '86400'))",
            "    AWS_LOCATION = get_env('STORAGE_AWS_FOLDER', default='')",
            "    AWS_S3_USE_SSL = get_bool_env('STORAGE_AWS_S3_USE_SSL', True)",
            "    AWS_S3_VERIFY = get_env('STORAGE_AWS_S3_VERIFY', None)",
            "    if AWS_S3_VERIFY == 'false' or AWS_S3_VERIFY == 'False' or AWS_S3_VERIFY == '0':",
            "        AWS_S3_VERIFY = False",
            "    AWS_S3_SIGNATURE_VERSION = get_env('STORAGE_AWS_S3_SIGNATURE_VERSION', None)",
            "",
            "if get_env('STORAGE_TYPE') == 'azure':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'core.storage.CustomAzureStorage'",
            "    AZURE_ACCOUNT_NAME = get_env('STORAGE_AZURE_ACCOUNT_NAME')",
            "    AZURE_ACCOUNT_KEY = get_env('STORAGE_AZURE_ACCOUNT_KEY')",
            "    AZURE_CONTAINER = get_env('STORAGE_AZURE_CONTAINER_NAME')",
            "    AZURE_URL_EXPIRATION_SECS = int(get_env('STORAGE_AZURE_URL_EXPIRATION_SECS', '86400'))",
            "    AZURE_LOCATION = get_env('STORAGE_AZURE_FOLDER', default='')",
            "",
            "if get_env('STORAGE_TYPE') == 'gcs':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    # DEFAULT_FILE_STORAGE = 'storages.backends.gcloud.GoogleCloudStorage'",
            "    DEFAULT_FILE_STORAGE = 'core.storage.AlternativeGoogleCloudStorage'",
            "    GS_PROJECT_ID = get_env('STORAGE_GCS_PROJECT_ID')",
            "    GS_BUCKET_NAME = get_env('STORAGE_GCS_BUCKET_NAME')",
            "    GS_EXPIRATION = timedelta(seconds=int(get_env('STORAGE_GCS_EXPIRATION_SECS', '86400')))",
            "    GS_LOCATION = get_env('STORAGE_GCS_FOLDER', default='')",
            "    GS_CUSTOM_ENDPOINT = get_env('STORAGE_GCS_ENDPOINT')",
            "",
            "CSRF_TRUSTED_ORIGINS = get_env('CSRF_TRUSTED_ORIGINS', [])",
            "if CSRF_TRUSTED_ORIGINS:",
            "    CSRF_TRUSTED_ORIGINS = CSRF_TRUSTED_ORIGINS.split(',')",
            "",
            "REAL_HOSTNAME = os.getenv('HOSTNAME')  # we have to use getenv, because we don't use LABEL_STUDIO_ prefix",
            "GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS = get_bool_env('GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS', False)",
            "PUBLIC_API_DOCS = get_bool_env('PUBLIC_API_DOCS', False)"
        ],
        "afterPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "\"\"\"",
            "Django Base settings for Label Studio.",
            "",
            "For more information on this file, see",
            "https://docs.djangoproject.com/en/3.1/topics/settings/",
            "",
            "For the full list of settings and their values, see",
            "https://docs.djangoproject.com/en/3.1/ref/settings/",
            "\"\"\"",
            "import json",
            "import logging",
            "import os",
            "import re",
            "from datetime import timedelta",
            "",
            "from label_studio.core.utils.params import get_bool_env, get_env_list",
            "",
            "formatter = 'standard'",
            "JSON_LOG = get_bool_env('JSON_LOG', False)",
            "if JSON_LOG:",
            "    formatter = 'json'",
            "",
            "LOGGING = {",
            "    'version': 1,",
            "    'disable_existing_loggers': False,",
            "    'formatters': {",
            "        'json': {",
            "            '()': 'label_studio.core.utils.formatter.CustomJsonFormatter',",
            "            'format': '[%(asctime)s] [%(name)s::%(funcName)s::%(lineno)d] [%(levelname)s] [%(user_id)s] %(message)s',",
            "            'datefmt': '%d/%b/%Y:%H:%M:%S %z',",
            "        },",
            "        'standard': {",
            "            'format': '[%(asctime)s] [%(name)s::%(funcName)s::%(lineno)d] [%(levelname)s] %(message)s',",
            "        },",
            "    },",
            "    'handlers': {",
            "        'console': {",
            "            'class': 'logging.StreamHandler',",
            "            'formatter': formatter,",
            "        },",
            "    },",
            "    'root': {",
            "        'handlers': ['console'],",
            "        'level': os.environ.get('LOG_LEVEL', 'DEBUG'),",
            "    },",
            "    'loggers': {",
            "        'pykwalify': {'level': 'ERROR', 'propagate': False},",
            "        'tavern': {'level': 'ERROR', 'propagate': False},",
            "        'asyncio': {'level': 'WARNING'},",
            "        'rules': {'level': 'WARNING'},",
            "        'django': {",
            "            'handlers': ['console'],",
            "            # 'propagate': True,",
            "        },",
            "        'django_auth_ldap': {'level': os.environ.get('LOG_LEVEL', 'DEBUG')},",
            "        'rq.worker': {",
            "            'handlers': ['console'],",
            "            'level': os.environ.get('LOG_LEVEL', 'INFO'),",
            "        },",
            "        'ddtrace': {",
            "            'handlers': ['console'],",
            "            'level': 'WARNING',",
            "        },",
            "        'ldclient.util': {",
            "            'handlers': ['console'],",
            "            'level': 'ERROR',",
            "        },",
            "    },",
            "}",
            "",
            "# for printing messages before main logging config applied",
            "if not logging.getLogger().hasHandlers():",
            "    logging.basicConfig(level=logging.DEBUG, format='%(message)s')",
            "",
            "from label_studio.core.utils.io import get_data_dir",
            "from label_studio.core.utils.params import get_bool_env, get_env",
            "",
            "logger = logging.getLogger(__name__)",
            "SILENCED_SYSTEM_CHECKS = []",
            "",
            "# Hostname is used for proper path generation to the resources, pages, etc",
            "HOSTNAME = get_env('HOST', '')",
            "if HOSTNAME:",
            "    if not HOSTNAME.startswith('http://') and not HOSTNAME.startswith('https://'):",
            "        logger.info(",
            "            '! HOST variable found in environment, but it must start with http:// or https://, ignore it: %s', HOSTNAME",
            "        )",
            "        HOSTNAME = ''",
            "    else:",
            "        logger.info('=> Hostname correctly is set to: %s', HOSTNAME)",
            "        if HOSTNAME.endswith('/'):",
            "            HOSTNAME = HOSTNAME[0:-1]",
            "",
            "        # for django url resolver",
            "        if HOSTNAME:",
            "            # http[s]://domain.com:8080/script_name => /script_name",
            "            pattern = re.compile(r'^http[s]?:\\/\\/([^:\\/\\s]+(:\\d*)?)(.*)?')",
            "            match = pattern.match(HOSTNAME)",
            "            FORCE_SCRIPT_NAME = match.group(3)",
            "            if FORCE_SCRIPT_NAME:",
            "                logger.info('=> Django URL prefix is set to: %s', FORCE_SCRIPT_NAME)",
            "",
            "INTERNAL_PORT = '8080'",
            "",
            "# SECURITY WARNING: don't run with debug turned on in production!",
            "DEBUG = get_bool_env('DEBUG', True)",
            "DEBUG_MODAL_EXCEPTIONS = get_bool_env('DEBUG_MODAL_EXCEPTIONS', True)",
            "",
            "# Whether to verify SSL certs when making external requests, eg in the uploader",
            "# \u26a0\ufe0f Turning this off means assuming risk. \u26a0\ufe0f",
            "# Overridable at organization level via Organization#verify_ssl_certs",
            "VERIFY_SSL_CERTS = get_bool_env('VERIFY_SSL_CERTS', True)",
            "",
            "# 'sqlite-dll-<arch>-<version>.zip' should be hosted at this prefix",
            "WINDOWS_SQLITE_BINARY_HOST_PREFIX = get_env('WINDOWS_SQLITE_BINARY_HOST_PREFIX', 'https://www.sqlite.org/2023/')",
            "",
            "# Build paths inside the project like this: os.path.join(BASE_DIR, ...)",
            "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))",
            "",
            "# Base path for media root and other uploaded files",
            "BASE_DATA_DIR = get_env('BASE_DATA_DIR', get_data_dir())",
            "os.makedirs(BASE_DATA_DIR, exist_ok=True)",
            "logger.info('=> Database and media directory: %s', BASE_DATA_DIR)",
            "",
            "# Databases",
            "# https://docs.djangoproject.com/en/2.1/ref/settings/#databases",
            "DJANGO_DB_MYSQL = 'mysql'",
            "DJANGO_DB_SQLITE = 'sqlite'",
            "DJANGO_DB_POSTGRESQL = 'postgresql'",
            "DJANGO_DB = 'default'",
            "DATABASE_NAME_DEFAULT = os.path.join(BASE_DATA_DIR, 'label_studio.sqlite3')",
            "DATABASE_NAME = get_env('DATABASE_NAME', DATABASE_NAME_DEFAULT)",
            "DATABASES_ALL = {",
            "    DJANGO_DB_POSTGRESQL: {",
            "        'ENGINE': 'django.db.backends.postgresql',",
            "        'USER': get_env('POSTGRE_USER', 'postgres'),",
            "        'PASSWORD': get_env('POSTGRE_PASSWORD', 'postgres'),",
            "        'NAME': get_env('POSTGRE_NAME', 'postgres'),",
            "        'HOST': get_env('POSTGRE_HOST', 'localhost'),",
            "        'PORT': int(get_env('POSTGRE_PORT', '5432')),",
            "    },",
            "    DJANGO_DB_MYSQL: {",
            "        'ENGINE': 'django.db.backends.mysql',",
            "        'USER': get_env('MYSQL_USER', 'root'),",
            "        'PASSWORD': get_env('MYSQL_PASSWORD', ''),",
            "        'NAME': get_env('MYSQL_NAME', 'labelstudio'),",
            "        'HOST': get_env('MYSQL_HOST', 'localhost'),",
            "        'PORT': int(get_env('MYSQL_PORT', '3306')),",
            "    },",
            "    DJANGO_DB_SQLITE: {",
            "        'ENGINE': 'django.db.backends.sqlite3',",
            "        'NAME': DATABASE_NAME,",
            "        'OPTIONS': {",
            "            # 'timeout': 20,",
            "        },",
            "    },",
            "}",
            "DATABASES_ALL['default'] = DATABASES_ALL[DJANGO_DB_POSTGRESQL]",
            "DATABASES = {'default': DATABASES_ALL.get(get_env('DJANGO_DB', 'default'))}",
            "",
            "DEFAULT_AUTO_FIELD = 'django.db.models.AutoField'",
            "",
            "if get_bool_env('GOOGLE_LOGGING_ENABLED', False):",
            "    logging.info('Google Cloud Logging handler is enabled.')",
            "    try:",
            "        import google.cloud.logging",
            "        from google.auth.exceptions import GoogleAuthError",
            "",
            "        client = google.cloud.logging.Client()",
            "        client.setup_logging()",
            "",
            "        LOGGING['handlers']['google_cloud_logging'] = {",
            "            'level': get_env('LOG_LEVEL', 'WARNING'),",
            "            'class': 'google.cloud.logging.handlers.CloudLoggingHandler',",
            "            'client': client,",
            "        }",
            "        LOGGING['root']['handlers'].append('google_cloud_logging')",
            "    except GoogleAuthError:",
            "        logger.exception('Google Cloud Logging handler could not be setup.')",
            "",
            "INSTALLED_APPS = [",
            "    'django.contrib.admin',",
            "    'django.contrib.auth',",
            "    'django.contrib.contenttypes',",
            "    'django.contrib.sessions',",
            "    'django.contrib.messages',",
            "    'django.contrib.staticfiles',",
            "    'django.contrib.humanize',",
            "    'drf_yasg',",
            "    'corsheaders',",
            "    'django_extensions',",
            "    'django_rq',",
            "    'django_filters',",
            "    'rules',",
            "    'annoying',",
            "    'rest_framework',",
            "    'rest_framework.authtoken',",
            "    'drf_generators',",
            "    'core',",
            "    'users',",
            "    'organizations',",
            "    'data_import',",
            "    'data_export',",
            "    'projects',",
            "    'tasks',",
            "    'data_manager',",
            "    'io_storages',",
            "    'ml',",
            "    'webhooks',",
            "    'labels_manager',",
            "]",
            "",
            "MIDDLEWARE = [",
            "    'corsheaders.middleware.CorsMiddleware',",
            "    'django.middleware.security.SecurityMiddleware',",
            "    'django.contrib.sessions.middleware.SessionMiddleware',",
            "    'django.middleware.locale.LocaleMiddleware',",
            "    'core.middleware.DisableCSRF',",
            "    'django.middleware.csrf.CsrfViewMiddleware',",
            "    'django.contrib.auth.middleware.AuthenticationMiddleware',",
            "    'django.contrib.messages.middleware.MessageMiddleware',",
            "    'core.middleware.CommonMiddlewareAppendSlashWithoutRedirect',  # instead of 'CommonMiddleware'",
            "    'core.middleware.CommonMiddleware',",
            "    'django_user_agents.middleware.UserAgentMiddleware',",
            "    'core.middleware.SetSessionUIDMiddleware',",
            "    'core.middleware.ContextLogMiddleware',",
            "    'core.middleware.DatabaseIsLockedRetryMiddleware',",
            "    'core.current_request.ThreadLocalMiddleware',",
            "]",
            "",
            "REST_FRAMEWORK = {",
            "    'DEFAULT_FILTER_BACKENDS': ['django_filters.rest_framework.DjangoFilterBackend'],",
            "    'DEFAULT_AUTHENTICATION_CLASSES': (",
            "        'rest_framework.authentication.TokenAuthentication',",
            "        'rest_framework.authentication.SessionAuthentication',",
            "    ),",
            "    'DEFAULT_PERMISSION_CLASSES': [",
            "        'core.api_permissions.HasObjectPermission',",
            "        'rest_framework.permissions.IsAuthenticated',",
            "    ],",
            "    'EXCEPTION_HANDLER': 'core.utils.common.custom_exception_handler',",
            "    'DEFAULT_RENDERER_CLASSES': ('rest_framework.renderers.JSONRenderer',),",
            "    'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.NamespaceVersioning',",
            "    'PAGE_SIZE': 100,",
            "    # 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination'",
            "}",
            "SILENCED_SYSTEM_CHECKS += ['rest_framework.W001']",
            "",
            "# CORS & Host settings",
            "INTERNAL_IPS = [  # django debug toolbar for django==2.2 requirement",
            "    '127.0.0.1',",
            "    'localhost',",
            "]",
            "CORS_ORIGIN_ALLOW_ALL = True",
            "CORS_ALLOW_METHODS = [",
            "    'DELETE',",
            "    'GET',",
            "    'OPTIONS',",
            "    'PATCH',",
            "    'POST',",
            "    'PUT',",
            "]",
            "ALLOWED_HOSTS = ['*']",
            "",
            "# Auth modules",
            "AUTH_USER_MODEL = 'users.User'",
            "AUTHENTICATION_BACKENDS = [",
            "    'rules.permissions.ObjectPermissionBackend',",
            "    'django.contrib.auth.backends.ModelBackend',",
            "]",
            "USE_USERNAME_FOR_LOGIN = False",
            "",
            "DISABLE_SIGNUP_WITHOUT_LINK = get_bool_env('DISABLE_SIGNUP_WITHOUT_LINK', False)",
            "",
            "# Password validation:",
            "# https://docs.djangoproject.com/en/2.1/ref/settings/#auth-password-validators",
            "AUTH_PASSWORD_VALIDATORS = [",
            "    {'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'},",
            "    {'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator'},",
            "]",
            "",
            "# Django templates",
            "TEMPLATES_DIR = os.path.join(os.path.dirname(BASE_DIR), 'templates')  # ../../from_this = 'web' dir",
            "TEMPLATES = [",
            "    {",
            "        'BACKEND': 'django.template.backends.django.DjangoTemplates',",
            "        'DIRS': [TEMPLATES_DIR],",
            "        'APP_DIRS': True,",
            "        'OPTIONS': {",
            "            'context_processors': [",
            "                'django.template.context_processors.debug',",
            "                'django.template.context_processors.request',",
            "                'django.contrib.auth.context_processors.auth',",
            "                'django.contrib.messages.context_processors.messages',",
            "                'core.context_processors.settings',",
            "            ],",
            "            'builtins': ['django.templatetags.i18n'],",
            "        },",
            "    }",
            "]",
            "",
            "# RQ",
            "RQ_QUEUES = {",
            "    'critical': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'high': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'default': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "    'low': {",
            "        'HOST': 'localhost',",
            "        'PORT': 6379,",
            "        'DB': 0,",
            "        'DEFAULT_TIMEOUT': 180,",
            "    },",
            "}",
            "",
            "# Swagger: automatic API documentation",
            "SWAGGER_SETTINGS = {",
            "    'SECURITY_DEFINITIONS': {",
            "        'Token': {",
            "            'type': 'apiKey',",
            "            'name': 'Authorization',",
            "            'in': 'header',",
            "            'description': 'The token (or API key) must be passed as a request header. '",
            "            'You can find your user token on the User Account page in Label Studio. Example: '",
            "            '<br><pre><code class=\"language-bash\">'",
            "            'curl https://label-studio-host/api/projects -H \"Authorization: Token [your-token]\"'",
            "            '</code></pre>',",
            "        }",
            "    },",
            "    'APIS_SORTER': 'alpha',",
            "    'SUPPORTED_SUBMIT_METHODS': ['get', 'post', 'put', 'delete', 'patch'],",
            "    'OPERATIONS_SORTER': 'alpha',",
            "}",
            "",
            "SENTRY_DSN = get_env('SENTRY_DSN', None)",
            "SENTRY_RATE = float(get_env('SENTRY_RATE', 0.25))",
            "SENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'stage.opensource')",
            "SENTRY_REDIS_ENABLED = False",
            "FRONTEND_SENTRY_DSN = get_env('FRONTEND_SENTRY_DSN', None)",
            "FRONTEND_SENTRY_RATE = get_env('FRONTEND_SENTRY_RATE', 0.1)",
            "FRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'stage.opensource')",
            "",
            "ROOT_URLCONF = 'core.urls'",
            "WSGI_APPLICATION = 'core.wsgi.application'",
            "GRAPHIQL = True",
            "",
            "# Internationalization",
            "# https://docs.djangoproject.com/en/2.1/topics/i18n/",
            "LANGUAGE_CODE = 'en-us'",
            "TIME_ZONE = 'UTC'",
            "USE_I18N = False",
            "USE_L10N = True",
            "USE_TZ = True",
            "",
            "# Static files (CSS, JavaScript, Images)",
            "# https://docs.djangoproject.com/en/2.1/howto/static-files/",
            "STATIC_URL = '/static/'",
            "# if FORCE_SCRIPT_NAME:",
            "#    STATIC_URL = FORCE_SCRIPT_NAME + STATIC_URL",
            "logger.info(f'=> Static URL is set to: {STATIC_URL}')",
            "",
            "STATIC_ROOT = os.path.join(BASE_DIR, 'static_build')",
            "STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static')]",
            "STATICFILES_FINDERS = (",
            "    'django.contrib.staticfiles.finders.FileSystemFinder',",
            "    'django.contrib.staticfiles.finders.AppDirectoriesFinder',",
            ")",
            "STATICFILES_STORAGE = 'core.storage.SkipMissedManifestStaticFilesStorage'",
            "",
            "# Sessions and CSRF",
            "SESSION_COOKIE_SECURE = bool(int(get_env('SESSION_COOKIE_SECURE', False)))",
            "SESSION_COOKIE_SAMESITE = get_env('SESSION_COOKIE_SAMESITE', 'Lax')",
            "",
            "CSRF_COOKIE_SECURE = bool(int(get_env('CSRF_COOKIE_SECURE', SESSION_COOKIE_SECURE)))",
            "CSRF_COOKIE_HTTPONLY = bool(int(get_env('CSRF_COOKIE_HTTPONLY', SESSION_COOKIE_SECURE)))",
            "CSRF_COOKIE_SAMESITE = get_env('CSRF_COOKIE_SAMESITE', 'Lax')",
            "",
            "# Inactivity user sessions",
            "INACTIVITY_SESSION_TIMEOUT_ENABLED = bool(int(get_env('INACTIVITY_SESSION_TIMEOUT_ENABLED', True)))",
            "# The most time a login will last, regardless of activity",
            "MAX_SESSION_AGE = int(get_env('MAX_SESSION_AGE', timedelta(days=14).total_seconds()))",
            "# The most time that can elapse between activity with the server before the user is logged out",
            "MAX_TIME_BETWEEN_ACTIVITY = int(get_env('MAX_TIME_BETWEEN_ACTIVITY', timedelta(days=5).total_seconds()))",
            "",
            "SSRF_PROTECTION_ENABLED = get_bool_env('SSRF_PROTECTION_ENABLED', False)",
            "",
            "# user media files",
            "MEDIA_ROOT = os.path.join(BASE_DATA_DIR, 'media')",
            "os.makedirs(MEDIA_ROOT, exist_ok=True)",
            "MEDIA_URL = '/data/'",
            "UPLOAD_DIR = 'upload'",
            "AVATAR_PATH = 'avatars'",
            "",
            "SUPPORTED_EXTENSIONS = set(",
            "    [",
            "        '.bmp',",
            "        '.csv',",
            "        '.flac',",
            "        '.gif',",
            "        '.htm',",
            "        '.html',",
            "        '.jpg',",
            "        '.jpeg',",
            "        '.json',",
            "        '.m4a',",
            "        '.mp3',",
            "        '.ogg',",
            "        '.png',",
            "        '.svg',",
            "        '.tsv',",
            "        '.txt',",
            "        '.wav',",
            "        '.xml',",
            "        '.mp4',",
            "        '.webm',",
            "        '.webp',",
            "    ]",
            ")",
            "",
            "# directory for files created during unit tests",
            "TEST_DATA_ROOT = os.path.join(BASE_DATA_DIR, 'test_data')",
            "os.makedirs(TEST_DATA_ROOT, exist_ok=True)",
            "",
            "# project exports",
            "EXPORT_DIR = os.path.join(BASE_DATA_DIR, 'export')",
            "EXPORT_URL_ROOT = '/export/'",
            "EXPORT_MIXIN = 'data_export.mixins.ExportMixin'",
            "# old export dir",
            "os.makedirs(EXPORT_DIR, exist_ok=True)",
            "# dir for delayed export",
            "DELAYED_EXPORT_DIR = 'export'",
            "os.makedirs(os.path.join(BASE_DATA_DIR, MEDIA_ROOT, DELAYED_EXPORT_DIR), exist_ok=True)",
            "",
            "# file / task size limits",
            "DATA_UPLOAD_MAX_MEMORY_SIZE = int(get_env('DATA_UPLOAD_MAX_MEMORY_SIZE', 250 * 1024 * 1024))",
            "DATA_UPLOAD_MAX_NUMBER_FILES = int(get_env('DATA_UPLOAD_MAX_NUMBER_FILES', 100))",
            "TASKS_MAX_NUMBER = 1000000",
            "TASKS_MAX_FILE_SIZE = DATA_UPLOAD_MAX_MEMORY_SIZE",
            "",
            "TASK_LOCK_TTL = int(get_env('TASK_LOCK_TTL', default=86400))",
            "",
            "LABEL_STREAM_HISTORY_LIMIT = int(get_env('LABEL_STREAM_HISTORY_LIMIT', default=100))",
            "",
            "RANDOM_NEXT_TASK_SAMPLE_SIZE = int(get_env('RANDOM_NEXT_TASK_SAMPLE_SIZE', 50))",
            "",
            "TASK_API_PAGE_SIZE_MAX = int(get_env('TASK_API_PAGE_SIZE_MAX', 0)) or None",
            "",
            "# Email backend",
            "FROM_EMAIL = get_env('FROM_EMAIL', 'Label Studio <hello@labelstud.io>')",
            "EMAIL_BACKEND = get_env('EMAIL_BACKEND', 'django.core.mail.backends.dummy.EmailBackend')",
            "",
            "ENABLE_LOCAL_FILES_STORAGE = get_bool_env('ENABLE_LOCAL_FILES_STORAGE', default=True)",
            "LOCAL_FILES_SERVING_ENABLED = get_bool_env('LOCAL_FILES_SERVING_ENABLED', default=False)",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env('LOCAL_FILES_DOCUMENT_ROOT', default=os.path.abspath(os.sep))",
            "",
            "SYNC_ON_TARGET_STORAGE_CREATION = get_bool_env('SYNC_ON_TARGET_STORAGE_CREATION', default=True)",
            "",
            "ALLOW_IMPORT_TASKS_WITH_UNKNOWN_EMAILS = get_bool_env('ALLOW_IMPORT_TASKS_WITH_UNKNOWN_EMAILS', default=False)",
            "",
            "\"\"\" React Libraries: do not forget to change this dir in /etc/nginx/nginx.conf \"\"\"",
            "# EDITOR = label-studio-frontend repository",
            "EDITOR_ROOT = os.path.join(BASE_DIR, '../frontend/dist/lsf')",
            "# DM = data manager (included into FRONTEND due npm building, we need only version.json file from there)",
            "DM_ROOT = os.path.join(BASE_DIR, '../frontend/dist/dm')",
            "# FRONTEND = GUI for django backend",
            "REACT_APP_ROOT = os.path.join(BASE_DIR, '../frontend/dist/react-app')",
            "",
            "# per project settings",
            "BATCH_SIZE = 1000",
            "PROJECT_TITLE_MIN_LEN = 3",
            "PROJECT_TITLE_MAX_LEN = 50",
            "LOGIN_REDIRECT_URL = '/'",
            "LOGIN_URL = '/'",
            "MIN_GROUND_TRUTH = 10",
            "DATA_UNDEFINED_NAME = '$undefined$'",
            "LICENSE = {}",
            "VERSIONS = {}",
            "VERSION_EDITION = 'Community'",
            "LATEST_VERSION_CHECK = True",
            "VERSIONS_CHECK_TIME = 0",
            "ALLOW_ORGANIZATION_WEBHOOKS = get_bool_env('ALLOW_ORGANIZATION_WEBHOOKS', False)",
            "CONVERTER_DOWNLOAD_RESOURCES = get_bool_env('CONVERTER_DOWNLOAD_RESOURCES', True)",
            "EXPERIMENTAL_FEATURES = get_bool_env('EXPERIMENTAL_FEATURES', False)",
            "USE_ENFORCE_CSRF_CHECKS = get_bool_env('USE_ENFORCE_CSRF_CHECKS', True)  # False is for tests",
            "CLOUD_FILE_STORAGE_ENABLED = False",
            "",
            "IO_STORAGES_IMPORT_LINK_NAMES = [",
            "    'io_storages_s3importstoragelink',",
            "    'io_storages_gcsimportstoragelink',",
            "    'io_storages_azureblobimportstoragelink',",
            "    'io_storages_localfilesimportstoragelink',",
            "    'io_storages_redisimportstoragelink',",
            "]",
            "",
            "CREATE_ORGANIZATION = 'organizations.functions.create_organization'",
            "SAVE_USER = 'users.functions.save_user'",
            "POST_PROCESS_REIMPORT = 'core.utils.common.empty'",
            "USER_SERIALIZER = 'users.serializers.BaseUserSerializer'",
            "USER_SERIALIZER_UPDATE = 'users.serializers.BaseUserSerializerUpdate'",
            "TASK_SERIALIZER = 'tasks.serializers.BaseTaskSerializer'",
            "EXPORT_DATA_SERIALIZER = 'data_export.serializers.BaseExportDataSerializer'",
            "DATA_MANAGER_GET_ALL_COLUMNS = 'data_manager.functions.get_all_columns'",
            "DATA_MANAGER_ANNOTATIONS_MAP = {}",
            "DATA_MANAGER_ACTIONS = {}",
            "DATA_MANAGER_CUSTOM_FILTER_EXPRESSIONS = 'data_manager.functions.custom_filter_expressions'",
            "DATA_MANAGER_PREPROCESS_FILTER = 'data_manager.functions.preprocess_filter'",
            "USER_LOGIN_FORM = 'users.forms.LoginForm'",
            "PROJECT_MIXIN = 'projects.mixins.ProjectMixin'",
            "TASK_MIXIN = 'tasks.mixins.TaskMixin'",
            "ANNOTATION_MIXIN = 'tasks.mixins.AnnotationMixin'",
            "ORGANIZATION_MIXIN = 'organizations.mixins.OrganizationMixin'",
            "USER_MIXIN = 'users.mixins.UserMixin'",
            "USER_PERM = 'core.api_permissions.HasOwnerPermission'",
            "RECALCULATE_ALL_STATS = None",
            "GET_STORAGE_LIST = 'io_storages.functions.get_storage_list'",
            "STORAGE_ANNOTATION_SERIALIZER = 'io_storages.serializers.StorageAnnotationSerializer'",
            "TASK_SERIALIZER_BULK = 'tasks.serializers.BaseTaskSerializerBulk'",
            "PREPROCESS_FIELD_NAME = 'data_manager.functions.preprocess_field_name'",
            "INTERACTIVE_DATA_SERIALIZER = 'data_export.serializers.BaseExportDataSerializerForInteractive'",
            "DELETE_TASKS_ANNOTATIONS_POSTPROCESS = None",
            "",
            "",
            "def project_delete(project):",
            "    project.delete()",
            "",
            "",
            "def user_auth(user_model, email, password):",
            "    return None",
            "",
            "",
            "def collect_versions_dummy(**kwargs):",
            "    return {}",
            "",
            "",
            "PROJECT_DELETE = project_delete",
            "USER_AUTH = user_auth",
            "COLLECT_VERSIONS = collect_versions_dummy",
            "",
            "WEBHOOK_TIMEOUT = float(get_env('WEBHOOK_TIMEOUT', 1.0))",
            "WEBHOOK_BATCH_SIZE = int(get_env('WEBHOOK_BATCH_SIZE', 100))",
            "WEBHOOK_SERIALIZERS = {",
            "    'project': 'webhooks.serializers_for_hooks.ProjectWebhookSerializer',",
            "    'task': 'webhooks.serializers_for_hooks.TaskWebhookSerializer',",
            "    'annotation': 'webhooks.serializers_for_hooks.AnnotationWebhookSerializer',",
            "    'label': 'labels_manager.serializers.LabelSerializer',",
            "    'label_link': 'labels_manager.serializers.LabelLinkSerializer',",
            "}",
            "",
            "EDITOR_KEYMAP = json.dumps(get_env('EDITOR_KEYMAP'))",
            "",
            "# fix a problem with Windows mimetypes for JS and PNG",
            "import mimetypes",
            "",
            "mimetypes.add_type('application/javascript', '.js', True)",
            "mimetypes.add_type('image/png', '.png', True)",
            "",
            "# fields name was used in DM api before",
            "REST_FLEX_FIELDS = {'FIELDS_PARAM': 'include'}",
            "",
            "INTERPOLATE_KEY_FRAMES = get_env('INTERPOLATE_KEY_FRAMES', False)",
            "",
            "# Feature Flags",
            "FEATURE_FLAGS_API_KEY = get_env('FEATURE_FLAGS_API_KEY', default='any key')",
            "",
            "# we may set feature flags from file",
            "FEATURE_FLAGS_FROM_FILE = get_bool_env('FEATURE_FLAGS_FROM_FILE', False)",
            "FEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')",
            "# or if file is not set, default is using offline mode",
            "FEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)",
            "# default value for feature flags (if not overridden by environment or client)",
            "FEATURE_FLAGS_DEFAULT_VALUE = False",
            "",
            "# Whether to send analytics telemetry data",
            "COLLECT_ANALYTICS = get_bool_env('collect_analytics', True)",
            "",
            "# Strip harmful content from SVG files by default",
            "SVG_SECURITY_CLEANUP = get_bool_env('SVG_SECURITY_CLEANUP', False)",
            "",
            "ML_BLOCK_LOCAL_IP = get_bool_env('ML_BLOCK_LOCAL_IP', False)",
            "",
            "RQ_LONG_JOB_TIMEOUT = int(get_env('RQ_LONG_JOB_TIMEOUT', 36000))",
            "",
            "APP_WEBSERVER = get_env('APP_WEBSERVER', 'django')",
            "",
            "BATCH_JOB_RETRY_TIMEOUT = int(get_env('BATCH_JOB_RETRY_TIMEOUT', 60))",
            "",
            "FUTURE_SAVE_TASK_TO_STORAGE = get_bool_env('FUTURE_SAVE_TASK_TO_STORAGE', default=False)",
            "FUTURE_SAVE_TASK_TO_STORAGE_JSON_EXT = get_bool_env('FUTURE_SAVE_TASK_TO_STORAGE_JSON_EXT', default=True)",
            "STORAGE_IN_PROGRESS_TIMER = float(get_env('STORAGE_IN_PROGRESS_TIMER', 5.0))",
            "",
            "USE_NGINX_FOR_EXPORT_DOWNLOADS = get_bool_env('USE_NGINX_FOR_EXPORT_DOWNLOADS', False)",
            "",
            "if get_env('MINIO_STORAGE_ENDPOINT') and not get_bool_env('MINIO_SKIP', False):",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'",
            "    AWS_STORAGE_BUCKET_NAME = get_env('MINIO_STORAGE_BUCKET_NAME')",
            "    AWS_ACCESS_KEY_ID = get_env('MINIO_STORAGE_ACCESS_KEY')",
            "    AWS_SECRET_ACCESS_KEY = get_env('MINIO_STORAGE_SECRET_KEY')",
            "    AWS_S3_ENDPOINT_URL = get_env('MINIO_STORAGE_ENDPOINT')",
            "    AWS_QUERYSTRING_AUTH = False",
            "    # make domain for FileUpload.file",
            "    AWS_S3_SECURE_URLS = False",
            "    AWS_S3_URL_PROTOCOL = 'http:' if HOSTNAME.startswith('http://') else 'https:'",
            "    AWS_S3_CUSTOM_DOMAIN = HOSTNAME.replace('http://', '').replace('https://', '') + '/data'",
            "",
            "if get_env('STORAGE_TYPE') == 's3':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'core.storage.CustomS3Boto3Storage'",
            "    if get_env('STORAGE_AWS_ACCESS_KEY_ID'):",
            "        AWS_ACCESS_KEY_ID = get_env('STORAGE_AWS_ACCESS_KEY_ID')",
            "    if get_env('STORAGE_AWS_SECRET_ACCESS_KEY'):",
            "        AWS_SECRET_ACCESS_KEY = get_env('STORAGE_AWS_SECRET_ACCESS_KEY')",
            "    AWS_STORAGE_BUCKET_NAME = get_env('STORAGE_AWS_BUCKET_NAME')",
            "    AWS_S3_REGION_NAME = get_env('STORAGE_AWS_REGION_NAME', None)",
            "    AWS_S3_ENDPOINT_URL = get_env('STORAGE_AWS_ENDPOINT_URL', None)",
            "    if get_env('STORAGE_AWS_OBJECT_PARAMETERS'):",
            "        AWS_S3_OBJECT_PARAMETERS = json.loads(get_env('STORAGE_AWS_OBJECT_PARAMETERS'))",
            "    AWS_QUERYSTRING_EXPIRE = int(get_env('STORAGE_AWS_X_AMZ_EXPIRES', '86400'))",
            "    AWS_LOCATION = get_env('STORAGE_AWS_FOLDER', default='')",
            "    AWS_S3_USE_SSL = get_bool_env('STORAGE_AWS_S3_USE_SSL', True)",
            "    AWS_S3_VERIFY = get_env('STORAGE_AWS_S3_VERIFY', None)",
            "    if AWS_S3_VERIFY == 'false' or AWS_S3_VERIFY == 'False' or AWS_S3_VERIFY == '0':",
            "        AWS_S3_VERIFY = False",
            "    AWS_S3_SIGNATURE_VERSION = get_env('STORAGE_AWS_S3_SIGNATURE_VERSION', None)",
            "",
            "if get_env('STORAGE_TYPE') == 'azure':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    DEFAULT_FILE_STORAGE = 'core.storage.CustomAzureStorage'",
            "    AZURE_ACCOUNT_NAME = get_env('STORAGE_AZURE_ACCOUNT_NAME')",
            "    AZURE_ACCOUNT_KEY = get_env('STORAGE_AZURE_ACCOUNT_KEY')",
            "    AZURE_CONTAINER = get_env('STORAGE_AZURE_CONTAINER_NAME')",
            "    AZURE_URL_EXPIRATION_SECS = int(get_env('STORAGE_AZURE_URL_EXPIRATION_SECS', '86400'))",
            "    AZURE_LOCATION = get_env('STORAGE_AZURE_FOLDER', default='')",
            "",
            "if get_env('STORAGE_TYPE') == 'gcs':",
            "    CLOUD_FILE_STORAGE_ENABLED = True",
            "    # DEFAULT_FILE_STORAGE = 'storages.backends.gcloud.GoogleCloudStorage'",
            "    DEFAULT_FILE_STORAGE = 'core.storage.AlternativeGoogleCloudStorage'",
            "    GS_PROJECT_ID = get_env('STORAGE_GCS_PROJECT_ID')",
            "    GS_BUCKET_NAME = get_env('STORAGE_GCS_BUCKET_NAME')",
            "    GS_EXPIRATION = timedelta(seconds=int(get_env('STORAGE_GCS_EXPIRATION_SECS', '86400')))",
            "    GS_LOCATION = get_env('STORAGE_GCS_FOLDER', default='')",
            "    GS_CUSTOM_ENDPOINT = get_env('STORAGE_GCS_ENDPOINT')",
            "",
            "CSRF_TRUSTED_ORIGINS = get_env('CSRF_TRUSTED_ORIGINS', [])",
            "if CSRF_TRUSTED_ORIGINS:",
            "    CSRF_TRUSTED_ORIGINS = CSRF_TRUSTED_ORIGINS.split(',')",
            "",
            "REAL_HOSTNAME = os.getenv('HOSTNAME')  # we have to use getenv, because we don't use LABEL_STUDIO_ prefix",
            "GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS = get_bool_env('GCS_CLOUD_STORAGE_FORCE_DEFAULT_CREDENTIALS', False)",
            "PUBLIC_API_DOCS = get_bool_env('PUBLIC_API_DOCS', False)",
            "",
            "# By default, we disallow filters with foreign keys in data manager for security reasons.",
            "# Add to this list (either here in code, or via the env) to allow specific filters that rely on foreign keys.",
            "DATA_MANAGER_FILTER_ALLOWLIST = list(",
            "    set(get_env_list('DATA_MANAGER_FILTER_ALLOWLIST') + ['updated_by__active_organization'])",
            ")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "18": []
        },
        "addLocation": []
    },
    "label_studio/core/utils/params.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import os"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+from typing import Callable, Optional, Sequence, TypeVar"
            },
            "2": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from rest_framework.exceptions import ValidationError"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "     return get_env(key, default, is_bool=True)"
            },
            "6": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 127,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def get_env_list_int(key, default=None):"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+T = TypeVar('T')"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+def get_env_list("
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+    key: str, default: Optional[Sequence[T]] = None, value_transform: Callable[[str], T] = str"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+) -> Sequence[T]:"
            },
            "15": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "     \"\"\""
            },
            "16": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"1,2,3\" in env variable => [1, 2, 3] in python"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+    \"foo,bar,baz\" in env variable => [\"foo\", \"bar\", \"baz\"] in python."
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+    Use value_transform to convert the strings to any other type."
            },
            "19": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "     \"\"\""
            },
            "20": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "     value = get_env(key)"
            },
            "21": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "     if not value:"
            },
            "22": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         if default is None:"
            },
            "23": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "             return []"
            },
            "24": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "         return default"
            },
            "25": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return [int(el) for el in value.split(',')]"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+    return [value_transform(el) for el in value.split(',')]"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+def get_env_list_int(key, default=None) -> Sequence[int]:"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+    return get_env_list(key, default=default, value_transform=int)"
            },
            "32": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 151,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 152,
                "PatchRowcode": " def get_all_env_with_prefix(prefix=None, is_bool=True, default_value=None):"
            }
        },
        "frontPatchFile": [
            "import os",
            "",
            "from rest_framework.exceptions import ValidationError",
            "",
            "",
            "def cast_bool_from_str(value):",
            "    if isinstance(value, str):",
            "        if value.lower() in ['true', 'yes', 'on', '1']:",
            "            value = True",
            "        elif value.lower() in ['false', 'no', 'not', 'off', '0']:",
            "            value = False",
            "        else:",
            "            raise ValueError(f'Incorrect bool value \"{value}\". ' f'It should be one of [1, 0, true, false, yes, no]')",
            "    return value",
            "",
            "",
            "def bool_from_request(params, key, default):",
            "    \"\"\"Get boolean value from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: boolean",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    try:",
            "        if isinstance(value, str):",
            "            value = cast_bool_from_str(value)",
            "        return bool(int(value))",
            "    except Exception as e:",
            "        raise ValidationError({key: str(e)})",
            "",
            "",
            "def int_from_request(params, key, default):",
            "    \"\"\"Get integer from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: int",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    # str",
            "    if isinstance(value, str):",
            "        try:",
            "            return int(value)",
            "        except ValueError:",
            "            raise ValidationError({key: f'Incorrect value in key \"{key}\" = \"{value}\". It should be digit string.'})",
            "        except Exception as e:",
            "            raise ValidationError({key: str(e)})",
            "    # int",
            "    elif isinstance(value, int):",
            "        return value",
            "    # other",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or integer.'}",
            "        )",
            "",
            "",
            "def float_from_request(params, key, default):",
            "    \"\"\"Get float from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: float",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    # str",
            "    if isinstance(value, str):",
            "        try:",
            "            return float(value)",
            "        except ValueError:",
            "            raise ValidationError({key: f'Incorrect value in key \"{key}\" = \"{value}\". It should be digit string.'})",
            "    # float",
            "    elif isinstance(value, float) or isinstance(value, int):",
            "        return float(value)",
            "    # other",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or float.'}",
            "        )",
            "",
            "",
            "def list_of_strings_from_request(params, key, default):",
            "    \"\"\"Get list of strings from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: float",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "    if value is None:",
            "        return",
            "    splitters = (',', ';', '|')",
            "    # str",
            "    if isinstance(value, str):",
            "        for splitter in splitters:",
            "            if splitter in value:",
            "                return value.split(splitter)",
            "        return [value]",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or float.'}",
            "        )",
            "",
            "",
            "def get_env(name, default=None, is_bool=False):",
            "    for env_key in ['LABEL_STUDIO_' + name, 'HEARTEX_' + name, name]:",
            "        value = os.environ.get(env_key)",
            "        if value is not None:",
            "            if is_bool:",
            "                return bool_from_request(os.environ, env_key, default)",
            "            else:",
            "                return value",
            "    return default",
            "",
            "",
            "def get_bool_env(key, default):",
            "    return get_env(key, default, is_bool=True)",
            "",
            "",
            "def get_env_list_int(key, default=None):",
            "    \"\"\"",
            "    \"1,2,3\" in env variable => [1, 2, 3] in python",
            "    \"\"\"",
            "    value = get_env(key)",
            "    if not value:",
            "        if default is None:",
            "            return []",
            "        return default",
            "    return [int(el) for el in value.split(',')]",
            "",
            "",
            "def get_all_env_with_prefix(prefix=None, is_bool=True, default_value=None):",
            "    out = {}",
            "    for key in os.environ.keys():",
            "        if not key.startswith(prefix):",
            "            continue",
            "        if is_bool:",
            "            out[key] = bool_from_request(os.environ, key, default_value)",
            "        else:",
            "            out[key] = os.environ[key]",
            "    return out"
        ],
        "afterPatchFile": [
            "import os",
            "from typing import Callable, Optional, Sequence, TypeVar",
            "",
            "from rest_framework.exceptions import ValidationError",
            "",
            "",
            "def cast_bool_from_str(value):",
            "    if isinstance(value, str):",
            "        if value.lower() in ['true', 'yes', 'on', '1']:",
            "            value = True",
            "        elif value.lower() in ['false', 'no', 'not', 'off', '0']:",
            "            value = False",
            "        else:",
            "            raise ValueError(f'Incorrect bool value \"{value}\". ' f'It should be one of [1, 0, true, false, yes, no]')",
            "    return value",
            "",
            "",
            "def bool_from_request(params, key, default):",
            "    \"\"\"Get boolean value from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: boolean",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    try:",
            "        if isinstance(value, str):",
            "            value = cast_bool_from_str(value)",
            "        return bool(int(value))",
            "    except Exception as e:",
            "        raise ValidationError({key: str(e)})",
            "",
            "",
            "def int_from_request(params, key, default):",
            "    \"\"\"Get integer from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: int",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    # str",
            "    if isinstance(value, str):",
            "        try:",
            "            return int(value)",
            "        except ValueError:",
            "            raise ValidationError({key: f'Incorrect value in key \"{key}\" = \"{value}\". It should be digit string.'})",
            "        except Exception as e:",
            "            raise ValidationError({key: str(e)})",
            "    # int",
            "    elif isinstance(value, int):",
            "        return value",
            "    # other",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or integer.'}",
            "        )",
            "",
            "",
            "def float_from_request(params, key, default):",
            "    \"\"\"Get float from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: float",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "",
            "    # str",
            "    if isinstance(value, str):",
            "        try:",
            "            return float(value)",
            "        except ValueError:",
            "            raise ValidationError({key: f'Incorrect value in key \"{key}\" = \"{value}\". It should be digit string.'})",
            "    # float",
            "    elif isinstance(value, float) or isinstance(value, int):",
            "        return float(value)",
            "    # other",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or float.'}",
            "        )",
            "",
            "",
            "def list_of_strings_from_request(params, key, default):",
            "    \"\"\"Get list of strings from request GET, POST, etc",
            "",
            "    :param params: dict POST, GET, etc",
            "    :param key: key to find",
            "    :param default: default value",
            "    :return: float",
            "    \"\"\"",
            "    value = params.get(key, default)",
            "    if value is None:",
            "        return",
            "    splitters = (',', ';', '|')",
            "    # str",
            "    if isinstance(value, str):",
            "        for splitter in splitters:",
            "            if splitter in value:",
            "                return value.split(splitter)",
            "        return [value]",
            "    else:",
            "        raise ValidationError(",
            "            {key: f'Incorrect value type in key \"{key}\" = \"{value}\". ' f'It should be digit string or float.'}",
            "        )",
            "",
            "",
            "def get_env(name, default=None, is_bool=False):",
            "    for env_key in ['LABEL_STUDIO_' + name, 'HEARTEX_' + name, name]:",
            "        value = os.environ.get(env_key)",
            "        if value is not None:",
            "            if is_bool:",
            "                return bool_from_request(os.environ, env_key, default)",
            "            else:",
            "                return value",
            "    return default",
            "",
            "",
            "def get_bool_env(key, default):",
            "    return get_env(key, default, is_bool=True)",
            "",
            "",
            "T = TypeVar('T')",
            "",
            "",
            "def get_env_list(",
            "    key: str, default: Optional[Sequence[T]] = None, value_transform: Callable[[str], T] = str",
            ") -> Sequence[T]:",
            "    \"\"\"",
            "    \"foo,bar,baz\" in env variable => [\"foo\", \"bar\", \"baz\"] in python.",
            "    Use value_transform to convert the strings to any other type.",
            "    \"\"\"",
            "    value = get_env(key)",
            "    if not value:",
            "        if default is None:",
            "            return []",
            "        return default",
            "",
            "    return [value_transform(el) for el in value.split(',')]",
            "",
            "",
            "def get_env_list_int(key, default=None) -> Sequence[int]:",
            "    return get_env_list(key, default=default, value_transform=int)",
            "",
            "",
            "def get_all_env_with_prefix(prefix=None, is_bool=True, default_value=None):",
            "    out = {}",
            "    for key in os.environ.keys():",
            "        if not key.startswith(prefix):",
            "            continue",
            "        if is_bool:",
            "            out[key] = bool_from_request(os.environ, key, default_value)",
            "        else:",
            "            out[key] = os.environ[key]",
            "    return out"
        ],
        "action": [
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "128": [
                "get_env_list_int"
            ],
            "130": [
                "get_env_list_int"
            ],
            "137": [
                "get_env_list_int"
            ]
        },
        "addLocation": []
    },
    "label_studio/data_manager/functions.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " \"\"\""
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import logging"
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from collections import OrderedDict"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 5,
                "PatchRowcode": "+from typing import Tuple"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from urllib.parse import unquote"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " import ujson as json"
            },
            "7": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "     return _filter"
            },
            "8": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 339,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 340,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def preprocess_field_name(raw_field_name, only_undefined_field=False):"
            },
            "11": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    field_name = raw_field_name.replace('filter:', '')"
            },
            "12": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    field_name = field_name.replace('tasks:', '')"
            },
            "13": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ascending = False if field_name[0] == '-' else True  # detect direction"
            },
            "14": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    field_name = field_name[1:] if field_name[0] == '-' else field_name  # remove direction"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+def preprocess_field_name(raw_field_name, only_undefined_field=False) -> Tuple[str, bool]:"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+    \"\"\"Transform a field name (as specified in the datamanager views endpoint) to"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 343,
                "PatchRowcode": "+    a django ORM field name. Also handle dotted accesses to task.data."
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 344,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+    Edit with care; it's critical that this function not be changed in ways that"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+    introduce vulnerabilities in the vein of the ORM Leak (see #5012). In particular"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+    it is not advisable to use `replace` or other calls that replace all instances"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+    of a string within this function."
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 350,
                "PatchRowcode": "+    Returns: Django ORM field name: str, Sort is ascending: bool"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+    \"\"\""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 352,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+    field_name = raw_field_name"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+    ascending = True"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+    # Descending marker `-` may come at the beginning of the string"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+    if field_name.startswith('-'):"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+        ascending = False"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+        field_name = field_name[1:]"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+    # For security reasons, these must only be removed when they fall at the beginning of the string (or after `-`)."
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+    optional_prefixes = ['filter:', 'tasks:']"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+    for prefix in optional_prefixes:"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+        if field_name.startswith(prefix):"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+            field_name = field_name[len(prefix) :]"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+    # Descending marker may also come after other prefixes. Double negative is not allowed."
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+    if ascending and field_name.startswith('-'):"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+        ascending = False"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        field_name = field_name[1:]"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": 372,
                "PatchRowcode": "     if field_name.startswith('data.'):"
            },
            "47": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 373,
                "PatchRowcode": "         if only_undefined_field:"
            },
            "48": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "             field_name = f'data__{settings.DATA_UNDEFINED_NAME}'"
            }
        },
        "frontPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "import logging",
            "from collections import OrderedDict",
            "from urllib.parse import unquote",
            "",
            "import ujson as json",
            "from core.feature_flags import flag_set",
            "from core.utils.common import int_from_request",
            "from data_manager.models import View",
            "from data_manager.prepare_params import PrepareParams",
            "from django.conf import settings",
            "from rest_framework.generics import get_object_or_404",
            "from tasks.models import Task",
            "",
            "TASKS = 'tasks:'",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DataManagerException(Exception):",
            "    pass",
            "",
            "",
            "def get_all_columns(project, *_):",
            "    \"\"\"Make columns info for the frontend data manager\"\"\"",
            "    result = {'columns': []}",
            "",
            "    # frontend uses MST data model, so we need two directional referencing parent <-> child",
            "    task_data_children = []",
            "    i = 0",
            "",
            "    data_types = OrderedDict()",
            "",
            "    # add data types from config again",
            "    project_data_types = {}",
            "    for key, value in project.data_types.items():",
            "        # skip keys from Repeater tag, because we already have its base data,",
            "        # e.g.: skip 'image[{{idx}}]' because we have 'image' list already",
            "        if '[' not in key:",
            "            project_data_types[key] = value",
            "    data_types.update(project_data_types.items())",
            "",
            "    # all data types from import data",
            "    all_data_columns = project.summary.all_data_columns",
            "    if all_data_columns:",
            "        data_types.update({key: 'Unknown' for key in all_data_columns if key not in data_types})",
            "",
            "    # remove $undefined$ if there is one type at least in labeling config, because it will be resolved automatically",
            "    if len(project_data_types) > 0:",
            "        data_types.pop(settings.DATA_UNDEFINED_NAME, None)",
            "",
            "    for key, data_type in list(data_types.items()):  # make data types from labeling config first",
            "        column = {",
            "            'id': key,",
            "            'title': key if key != settings.DATA_UNDEFINED_NAME else 'data',",
            "            'type': data_type if data_type in ['Image', 'Audio', 'AudioPlus', 'Video', 'Unknown'] else 'String',",
            "            'target': 'tasks',",
            "            'parent': 'data',",
            "            'visibility_defaults': {",
            "                'explore': True,",
            "                'labeling': key in project_data_types or key == settings.DATA_UNDEFINED_NAME,",
            "            },",
            "            'project_defined': True,",
            "        }",
            "        result['columns'].append(column)",
            "        task_data_children.append(column['id'])",
            "        i += 1",
            "",
            "    # --- Data root ---",
            "    data_root = {",
            "        'id': 'data',",
            "        'title': 'data',",
            "        'type': 'List',",
            "        'target': 'tasks',",
            "        'children': task_data_children,",
            "        'project_defined': False,",
            "    }",
            "",
            "    result['columns'] += [",
            "        # --- Tasks ---",
            "        {",
            "            'id': 'id',",
            "            'title': 'ID',",
            "            'type': 'Number',",
            "            'help': 'Task ID',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        }",
            "    ]",
            "",
            "    if flag_set('ff_back_2070_inner_id_12052022_short', user=project.organization.created_by):",
            "        result['columns'] += [",
            "            {",
            "                'id': 'inner_id',",
            "                'title': 'Inner ID',",
            "                'type': 'Number',",
            "                'help': 'Internal task ID starting from 1 for the current project',",
            "                'target': 'tasks',",
            "                'visibility_defaults': {'explore': False, 'labeling': False},",
            "                'project_defined': False,",
            "            }",
            "        ]",
            "",
            "    if flag_set('fflag_fix_back_lsdv_4648_annotator_filter_29052023_short', user=project.organization.created_by):",
            "        project_members = project.all_members.values_list('id', flat=True)",
            "    else:",
            "        project_members = project.organization.members.values_list('user__id', flat=True)",
            "",
            "    result['columns'] += [",
            "        {",
            "            'id': 'completed_at',",
            "            'title': 'Completed',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Last annotation date',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'total_annotations',",
            "            'title': 'Annotations',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total annotations per task',",
            "            'visibility_defaults': {'explore': True, 'labeling': True},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'cancelled_annotations',",
            "            'title': 'Cancelled',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total cancelled (skipped) annotations',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'total_predictions',",
            "            'title': 'Predictions',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total predictions per task',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotators',",
            "            'title': 'Annotated by',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'All users who completed the task',",
            "            'schema': {'items': project_members},",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotations_results',",
            "            'title': 'Annotation results',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Annotation results stacked over all annotations',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotations_ids',",
            "            'title': 'Annotation IDs',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Annotation IDs stacked over all annotations',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_score',",
            "            'title': 'Prediction score',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Average prediction score over all task predictions',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_model_versions',",
            "            'title': 'Prediction model versions',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'Model versions aggregated over all predictions',",
            "            'schema': {'items': project.get_model_versions()},",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_results',",
            "            'title': 'Prediction results',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Prediction results stacked over all predictions',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'file_upload',",
            "            'title': 'Upload filename',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Filename of uploaded file',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'storage_filename',",
            "            'title': 'Storage filename',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Filename from import storage',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'created_at',",
            "            'title': 'Created at',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Task creation time',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'updated_at',",
            "            'title': 'Updated at',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Task update time',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'updated_by',",
            "            'title': 'Updated by',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'User who did the last task update',",
            "            'schema': {'items': project_members},",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'avg_lead_time',",
            "            'title': 'Lead Time',",
            "            'type': 'Number',",
            "            'help': 'Average lead time over all annotations (seconds)',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'draft_exists',",
            "            'title': 'Drafts',",
            "            'type': 'Boolean',",
            "            'help': 'True if at least one draft exists for the task',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "    ]",
            "",
            "    result['columns'].append(data_root)",
            "",
            "    return result",
            "",
            "",
            "def get_prepare_params(request, project):",
            "    \"\"\"This function extract prepare_params from",
            "    * view_id if it's inside of request data",
            "    * selectedItems, filters, ordering if they are in request and there is no view id",
            "    \"\"\"",
            "    # use filters and selected items from view",
            "    view_id = int_from_request(request.GET, 'view', 0) or int_from_request(request.data, 'view', 0)",
            "    if view_id > 0:",
            "        view = get_object_or_404(View, pk=view_id)",
            "        if view.project.pk != project.pk:",
            "            raise DataManagerException('Project and View mismatch')",
            "        prepare_params = view.get_prepare_tasks_params(add_selected_items=True)",
            "        prepare_params.request = request",
            "",
            "    # use filters and selected items from request if it's specified",
            "    else:",
            "        # query arguments from url",
            "        if 'query' in request.GET:",
            "            data = json.loads(unquote(request.GET['query']))",
            "        # data payload from body",
            "        else:",
            "            data = request.data",
            "",
            "        selected = data.get('selectedItems', {'all': True, 'excluded': []})",
            "        if not isinstance(selected, dict):",
            "            raise DataManagerException(",
            "                'selectedItems must be dict: {\"all\": [true|false], ' '\"excluded | included\": [...task_ids...]}'",
            "            )",
            "        filters = data.get('filters', None)",
            "        ordering = data.get('ordering', [])",
            "        prepare_params = PrepareParams(",
            "            project=project.id, selectedItems=selected, data=data, filters=filters, ordering=ordering, request=request",
            "        )",
            "    return prepare_params",
            "",
            "",
            "def get_prepared_queryset(request, project):",
            "    prepare_params = get_prepare_params(request, project)",
            "    queryset = Task.prepared.only_filtered(prepare_params=prepare_params)",
            "    return queryset",
            "",
            "",
            "def evaluate_predictions(tasks):",
            "    \"\"\"Call ML backend for prediction evaluation of the task queryset\"\"\"",
            "    if not tasks:",
            "        return",
            "",
            "    project = tasks[0].project",
            "",
            "    for ml_backend in project.ml_backends.all():",
            "        # tasks = tasks.filter(~Q(predictions__model_version=ml_backend.model_version))",
            "        ml_backend.predict_tasks(tasks)",
            "",
            "",
            "def filters_ordering_selected_items_exist(data):",
            "    return data.get('filters') or data.get('ordering') or data.get('selectedItems')",
            "",
            "",
            "def custom_filter_expressions(*args, **kwargs):",
            "    pass",
            "",
            "",
            "def preprocess_filter(_filter, *_):",
            "    return _filter",
            "",
            "",
            "def preprocess_field_name(raw_field_name, only_undefined_field=False):",
            "    field_name = raw_field_name.replace('filter:', '')",
            "    field_name = field_name.replace('tasks:', '')",
            "    ascending = False if field_name[0] == '-' else True  # detect direction",
            "    field_name = field_name[1:] if field_name[0] == '-' else field_name  # remove direction",
            "    if field_name.startswith('data.'):",
            "        if only_undefined_field:",
            "            field_name = f'data__{settings.DATA_UNDEFINED_NAME}'",
            "        else:",
            "            field_name = field_name.replace('data.', 'data__')",
            "    return field_name, ascending"
        ],
        "afterPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "import logging",
            "from collections import OrderedDict",
            "from typing import Tuple",
            "from urllib.parse import unquote",
            "",
            "import ujson as json",
            "from core.feature_flags import flag_set",
            "from core.utils.common import int_from_request",
            "from data_manager.models import View",
            "from data_manager.prepare_params import PrepareParams",
            "from django.conf import settings",
            "from rest_framework.generics import get_object_or_404",
            "from tasks.models import Task",
            "",
            "TASKS = 'tasks:'",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DataManagerException(Exception):",
            "    pass",
            "",
            "",
            "def get_all_columns(project, *_):",
            "    \"\"\"Make columns info for the frontend data manager\"\"\"",
            "    result = {'columns': []}",
            "",
            "    # frontend uses MST data model, so we need two directional referencing parent <-> child",
            "    task_data_children = []",
            "    i = 0",
            "",
            "    data_types = OrderedDict()",
            "",
            "    # add data types from config again",
            "    project_data_types = {}",
            "    for key, value in project.data_types.items():",
            "        # skip keys from Repeater tag, because we already have its base data,",
            "        # e.g.: skip 'image[{{idx}}]' because we have 'image' list already",
            "        if '[' not in key:",
            "            project_data_types[key] = value",
            "    data_types.update(project_data_types.items())",
            "",
            "    # all data types from import data",
            "    all_data_columns = project.summary.all_data_columns",
            "    if all_data_columns:",
            "        data_types.update({key: 'Unknown' for key in all_data_columns if key not in data_types})",
            "",
            "    # remove $undefined$ if there is one type at least in labeling config, because it will be resolved automatically",
            "    if len(project_data_types) > 0:",
            "        data_types.pop(settings.DATA_UNDEFINED_NAME, None)",
            "",
            "    for key, data_type in list(data_types.items()):  # make data types from labeling config first",
            "        column = {",
            "            'id': key,",
            "            'title': key if key != settings.DATA_UNDEFINED_NAME else 'data',",
            "            'type': data_type if data_type in ['Image', 'Audio', 'AudioPlus', 'Video', 'Unknown'] else 'String',",
            "            'target': 'tasks',",
            "            'parent': 'data',",
            "            'visibility_defaults': {",
            "                'explore': True,",
            "                'labeling': key in project_data_types or key == settings.DATA_UNDEFINED_NAME,",
            "            },",
            "            'project_defined': True,",
            "        }",
            "        result['columns'].append(column)",
            "        task_data_children.append(column['id'])",
            "        i += 1",
            "",
            "    # --- Data root ---",
            "    data_root = {",
            "        'id': 'data',",
            "        'title': 'data',",
            "        'type': 'List',",
            "        'target': 'tasks',",
            "        'children': task_data_children,",
            "        'project_defined': False,",
            "    }",
            "",
            "    result['columns'] += [",
            "        # --- Tasks ---",
            "        {",
            "            'id': 'id',",
            "            'title': 'ID',",
            "            'type': 'Number',",
            "            'help': 'Task ID',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        }",
            "    ]",
            "",
            "    if flag_set('ff_back_2070_inner_id_12052022_short', user=project.organization.created_by):",
            "        result['columns'] += [",
            "            {",
            "                'id': 'inner_id',",
            "                'title': 'Inner ID',",
            "                'type': 'Number',",
            "                'help': 'Internal task ID starting from 1 for the current project',",
            "                'target': 'tasks',",
            "                'visibility_defaults': {'explore': False, 'labeling': False},",
            "                'project_defined': False,",
            "            }",
            "        ]",
            "",
            "    if flag_set('fflag_fix_back_lsdv_4648_annotator_filter_29052023_short', user=project.organization.created_by):",
            "        project_members = project.all_members.values_list('id', flat=True)",
            "    else:",
            "        project_members = project.organization.members.values_list('user__id', flat=True)",
            "",
            "    result['columns'] += [",
            "        {",
            "            'id': 'completed_at',",
            "            'title': 'Completed',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Last annotation date',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'total_annotations',",
            "            'title': 'Annotations',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total annotations per task',",
            "            'visibility_defaults': {'explore': True, 'labeling': True},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'cancelled_annotations',",
            "            'title': 'Cancelled',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total cancelled (skipped) annotations',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'total_predictions',",
            "            'title': 'Predictions',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Total predictions per task',",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotators',",
            "            'title': 'Annotated by',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'All users who completed the task',",
            "            'schema': {'items': project_members},",
            "            'visibility_defaults': {'explore': True, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotations_results',",
            "            'title': 'Annotation results',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Annotation results stacked over all annotations',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'annotations_ids',",
            "            'title': 'Annotation IDs',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Annotation IDs stacked over all annotations',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_score',",
            "            'title': 'Prediction score',",
            "            'type': 'Number',",
            "            'target': 'tasks',",
            "            'help': 'Average prediction score over all task predictions',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_model_versions',",
            "            'title': 'Prediction model versions',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'Model versions aggregated over all predictions',",
            "            'schema': {'items': project.get_model_versions()},",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'predictions_results',",
            "            'title': 'Prediction results',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Prediction results stacked over all predictions',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'file_upload',",
            "            'title': 'Upload filename',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Filename of uploaded file',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'storage_filename',",
            "            'title': 'Storage filename',",
            "            'type': 'String',",
            "            'target': 'tasks',",
            "            'help': 'Filename from import storage',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'created_at',",
            "            'title': 'Created at',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Task creation time',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'updated_at',",
            "            'title': 'Updated at',",
            "            'type': 'Datetime',",
            "            'target': 'tasks',",
            "            'help': 'Task update time',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'updated_by',",
            "            'title': 'Updated by',",
            "            'type': 'List',",
            "            'target': 'tasks',",
            "            'help': 'User who did the last task update',",
            "            'schema': {'items': project_members},",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'avg_lead_time',",
            "            'title': 'Lead Time',",
            "            'type': 'Number',",
            "            'help': 'Average lead time over all annotations (seconds)',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "        {",
            "            'id': 'draft_exists',",
            "            'title': 'Drafts',",
            "            'type': 'Boolean',",
            "            'help': 'True if at least one draft exists for the task',",
            "            'target': 'tasks',",
            "            'visibility_defaults': {'explore': False, 'labeling': False},",
            "            'project_defined': False,",
            "        },",
            "    ]",
            "",
            "    result['columns'].append(data_root)",
            "",
            "    return result",
            "",
            "",
            "def get_prepare_params(request, project):",
            "    \"\"\"This function extract prepare_params from",
            "    * view_id if it's inside of request data",
            "    * selectedItems, filters, ordering if they are in request and there is no view id",
            "    \"\"\"",
            "    # use filters and selected items from view",
            "    view_id = int_from_request(request.GET, 'view', 0) or int_from_request(request.data, 'view', 0)",
            "    if view_id > 0:",
            "        view = get_object_or_404(View, pk=view_id)",
            "        if view.project.pk != project.pk:",
            "            raise DataManagerException('Project and View mismatch')",
            "        prepare_params = view.get_prepare_tasks_params(add_selected_items=True)",
            "        prepare_params.request = request",
            "",
            "    # use filters and selected items from request if it's specified",
            "    else:",
            "        # query arguments from url",
            "        if 'query' in request.GET:",
            "            data = json.loads(unquote(request.GET['query']))",
            "        # data payload from body",
            "        else:",
            "            data = request.data",
            "",
            "        selected = data.get('selectedItems', {'all': True, 'excluded': []})",
            "        if not isinstance(selected, dict):",
            "            raise DataManagerException(",
            "                'selectedItems must be dict: {\"all\": [true|false], ' '\"excluded | included\": [...task_ids...]}'",
            "            )",
            "        filters = data.get('filters', None)",
            "        ordering = data.get('ordering', [])",
            "        prepare_params = PrepareParams(",
            "            project=project.id, selectedItems=selected, data=data, filters=filters, ordering=ordering, request=request",
            "        )",
            "    return prepare_params",
            "",
            "",
            "def get_prepared_queryset(request, project):",
            "    prepare_params = get_prepare_params(request, project)",
            "    queryset = Task.prepared.only_filtered(prepare_params=prepare_params)",
            "    return queryset",
            "",
            "",
            "def evaluate_predictions(tasks):",
            "    \"\"\"Call ML backend for prediction evaluation of the task queryset\"\"\"",
            "    if not tasks:",
            "        return",
            "",
            "    project = tasks[0].project",
            "",
            "    for ml_backend in project.ml_backends.all():",
            "        # tasks = tasks.filter(~Q(predictions__model_version=ml_backend.model_version))",
            "        ml_backend.predict_tasks(tasks)",
            "",
            "",
            "def filters_ordering_selected_items_exist(data):",
            "    return data.get('filters') or data.get('ordering') or data.get('selectedItems')",
            "",
            "",
            "def custom_filter_expressions(*args, **kwargs):",
            "    pass",
            "",
            "",
            "def preprocess_filter(_filter, *_):",
            "    return _filter",
            "",
            "",
            "def preprocess_field_name(raw_field_name, only_undefined_field=False) -> Tuple[str, bool]:",
            "    \"\"\"Transform a field name (as specified in the datamanager views endpoint) to",
            "    a django ORM field name. Also handle dotted accesses to task.data.",
            "",
            "    Edit with care; it's critical that this function not be changed in ways that",
            "    introduce vulnerabilities in the vein of the ORM Leak (see #5012). In particular",
            "    it is not advisable to use `replace` or other calls that replace all instances",
            "    of a string within this function.",
            "",
            "    Returns: Django ORM field name: str, Sort is ascending: bool",
            "    \"\"\"",
            "",
            "    field_name = raw_field_name",
            "    ascending = True",
            "",
            "    # Descending marker `-` may come at the beginning of the string",
            "    if field_name.startswith('-'):",
            "        ascending = False",
            "        field_name = field_name[1:]",
            "",
            "    # For security reasons, these must only be removed when they fall at the beginning of the string (or after `-`).",
            "    optional_prefixes = ['filter:', 'tasks:']",
            "    for prefix in optional_prefixes:",
            "        if field_name.startswith(prefix):",
            "            field_name = field_name[len(prefix) :]",
            "",
            "    # Descending marker may also come after other prefixes. Double negative is not allowed.",
            "    if ascending and field_name.startswith('-'):",
            "        ascending = False",
            "        field_name = field_name[1:]",
            "",
            "    if field_name.startswith('data.'):",
            "        if only_undefined_field:",
            "            field_name = f'data__{settings.DATA_UNDEFINED_NAME}'",
            "        else:",
            "            field_name = field_name.replace('data.', 'data__')",
            "    return field_name, ascending"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "340": [
                "preprocess_field_name"
            ],
            "341": [
                "preprocess_field_name"
            ],
            "342": [
                "preprocess_field_name"
            ],
            "343": [
                "preprocess_field_name"
            ],
            "344": [
                "preprocess_field_name"
            ]
        },
        "addLocation": []
    },
    "label_studio/data_manager/serializers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import ujson as json"
            },
            "2": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from data_manager.models import Filter, FilterGroup, View"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from django.conf import settings"
            },
            "4": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from django.db import transaction"
            },
            "5": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from projects.models import Project"
            },
            "6": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from rest_framework import serializers"
            },
            "7": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": "         model = Filter"
            },
            "8": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": "         fields = '__all__'"
            },
            "9": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+    def validate_column(self, column: str) -> str:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+        \"\"\""
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+        Ensure that the passed filter expression starts with 'filter:tasks:' and contains"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+        no foreign key traversals. This means either the filter expression contains no '__'"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+        substrings, or that it's the task.data json field that's accessed."
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+        Users depending on foreign key traversals in views can allowlist them via the"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+        DATA_MANAGER_FILTER_ALLOWLIST setting in the env."
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+        Edit with care. The validations below are critical for security."
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        \"\"\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+        column_copy = column"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+        # We may support 'filter:annotations:' in the future, but we don't as of yet."
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+        required_prefix = 'filter:tasks:'"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+        optional_prefix = '-'"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+        if not column_copy.startswith(required_prefix):"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+            raise serializers.ValidationError(f'Filter \"{column}\" should start with \"{required_prefix}\"')"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+        column_copy = column_copy[len(required_prefix) :]"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+        if column_copy.startswith(optional_prefix):"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+            column_copy = column_copy[len(optional_prefix) :]"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+        if column_copy.startswith('data.'):"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+            # Allow underscores if the filter is based on the `task.data` JSONField, because these don't leverage foreign keys."
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+            return column"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+        # Specific filters relying on foreign keys can be allowlisted"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+        if column_copy in settings.DATA_MANAGER_FILTER_ALLOWLIST:"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+            return column"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+        # But in general, we don't allow foreign keys"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        if '__' in column_copy:"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+            raise serializers.ValidationError("
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+                f'\"__\" is not generally allowed in filters. Consider asking your administrator to add \"{column_copy}\" '"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+                'to DATA_MANAGER_FILTER_ALLOWLIST, but note that some filter expressions may pose a security risk'"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+            )"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+        return column"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+"
            },
            "53": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " "
            },
            "54": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " class FilterGroupSerializer(serializers.ModelSerializer):"
            },
            "55": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "     filters = FilterSerializer(many=True)"
            }
        },
        "frontPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "import os",
            "",
            "import ujson as json",
            "from data_manager.models import Filter, FilterGroup, View",
            "from django.db import transaction",
            "from projects.models import Project",
            "from rest_framework import serializers",
            "from tasks.models import Task",
            "from tasks.serializers import AnnotationDraftSerializer, AnnotationSerializer, PredictionSerializer, TaskSerializer",
            "",
            "from label_studio.core.utils.common import round_floats",
            "",
            "",
            "class FilterSerializer(serializers.ModelSerializer):",
            "    class Meta:",
            "        model = Filter",
            "        fields = '__all__'",
            "",
            "",
            "class FilterGroupSerializer(serializers.ModelSerializer):",
            "    filters = FilterSerializer(many=True)",
            "",
            "    class Meta:",
            "        model = FilterGroup",
            "        fields = '__all__'",
            "",
            "",
            "class ViewSerializer(serializers.ModelSerializer):",
            "    filter_group = FilterGroupSerializer(required=False)",
            "",
            "    class Meta:",
            "        model = View",
            "        fields = '__all__'",
            "",
            "    def to_internal_value(self, data):",
            "        \"\"\"",
            "        map old filters structure to models",
            "        \"filters\": {  ===> FilterGroup model",
            "            \"conjunction\": \"or\",",
            "            \"items\":[  ===> \"filters\" in FilterGroup",
            "                 {  ==> Filter model",
            "                   \"filter\":\"filter:tasks:data.image\", ==> column",
            "                    \"operator\":\"contains\",",
            "                    \"type\":\"Image\",",
            "                    \"value\": <string: \"XXX\" | int: 123 | dict | list>",
            "                 },",
            "                  {",
            "                    \"filter\":\"filter:tasks:data.image\",",
            "                    \"operator\":\"equal\",",
            "                    \"type\":\"Image\",",
            "                    \"value\": <string: \"XXX\" | int: 123 | dict | list>",
            "                 }",
            "              ]",
            "           }",
            "        }",
            "        \"\"\"",
            "        _data = data.get('data', {})",
            "",
            "        filters = _data.pop('filters', {})",
            "        conjunction = filters.get('conjunction')",
            "        if 'filter_group' not in data and conjunction:",
            "            data['filter_group'] = {'conjunction': conjunction, 'filters': []}",
            "            if 'items' in filters:",
            "                for f in filters['items']:",
            "                    data['filter_group']['filters'].append(",
            "                        {",
            "                            'column': f.get('filter', ''),",
            "                            'operator': f.get('operator', ''),",
            "                            'type': f.get('type', ''),",
            "                            'value': f.get('value', {}),",
            "                        }",
            "                    )",
            "",
            "        ordering = _data.pop('ordering', {})",
            "        data['ordering'] = ordering",
            "",
            "        return super().to_internal_value(data)",
            "",
            "    def to_representation(self, instance):",
            "        result = super().to_representation(instance)",
            "        filters = result.pop('filter_group', {})",
            "        if filters:",
            "            filters['items'] = []",
            "            filters.pop('filters', [])",
            "            filters.pop('id', None)",
            "",
            "            for f in instance.filter_group.filters.order_by('index'):",
            "                filters['items'].append(",
            "                    {",
            "                        'filter': f.column,",
            "                        'operator': f.operator,",
            "                        'type': f.type,",
            "                        'value': f.value,",
            "                    }",
            "                )",
            "            result['data']['filters'] = filters",
            "",
            "        selected_items = result.pop('selected_items', {})",
            "        if selected_items:",
            "            result['data']['selectedItems'] = selected_items",
            "",
            "        ordering = result.pop('ordering', {})",
            "        if ordering:",
            "            result['data']['ordering'] = ordering",
            "        return result",
            "",
            "    @staticmethod",
            "    def _create_filters(filter_group, filters_data):",
            "        filter_index = 0",
            "        for filter_data in filters_data:",
            "            filter_data['index'] = filter_index",
            "            filter_group.filters.add(Filter.objects.create(**filter_data))",
            "            filter_index += 1",
            "",
            "    def create(self, validated_data):",
            "        with transaction.atomic():",
            "            filter_group_data = validated_data.pop('filter_group', None)",
            "            if filter_group_data:",
            "                filters_data = filter_group_data.pop('filters', [])",
            "                filter_group = FilterGroup.objects.create(**filter_group_data)",
            "",
            "                self._create_filters(filter_group=filter_group, filters_data=filters_data)",
            "",
            "                validated_data['filter_group_id'] = filter_group.id",
            "            view = self.Meta.model.objects.create(**validated_data)",
            "",
            "            return view",
            "",
            "    def update(self, instance, validated_data):",
            "        with transaction.atomic():",
            "            filter_group_data = validated_data.pop('filter_group', None)",
            "            if filter_group_data:",
            "                filters_data = filter_group_data.pop('filters', [])",
            "",
            "                filter_group = instance.filter_group",
            "                if filter_group is None:",
            "                    filter_group = FilterGroup.objects.create(**filter_group_data)",
            "",
            "                conjunction = filter_group_data.get('conjunction')",
            "                if conjunction and filter_group.conjunction != conjunction:",
            "                    filter_group.conjunction = conjunction",
            "                    filter_group.save()",
            "",
            "                filter_group.filters.clear()",
            "                self._create_filters(filter_group=filter_group, filters_data=filters_data)",
            "",
            "            ordering = validated_data.pop('ordering', None)",
            "            if ordering and ordering != instance.ordering:",
            "                instance.ordering = ordering",
            "                instance.save()",
            "",
            "            if validated_data['data'] != instance.data:",
            "                instance.data = validated_data['data']",
            "                instance.save()",
            "",
            "            return instance",
            "",
            "",
            "class DataManagerTaskSerializer(TaskSerializer):",
            "    predictions = serializers.SerializerMethodField(required=False, read_only=True)",
            "    annotations = AnnotationSerializer(required=False, many=True, default=[], read_only=True)",
            "    drafts = serializers.SerializerMethodField(required=False, read_only=True)",
            "    annotators = serializers.SerializerMethodField(required=False, read_only=True)",
            "",
            "    inner_id = serializers.IntegerField(required=False)",
            "    cancelled_annotations = serializers.IntegerField(required=False)",
            "    total_annotations = serializers.IntegerField(required=False)",
            "    total_predictions = serializers.IntegerField(required=False)",
            "    completed_at = serializers.DateTimeField(required=False)",
            "    annotations_results = serializers.SerializerMethodField(required=False)",
            "    predictions_results = serializers.SerializerMethodField(required=False)",
            "    predictions_score = serializers.FloatField(required=False)",
            "    file_upload = serializers.SerializerMethodField(required=False)",
            "    storage_filename = serializers.SerializerMethodField(required=False)",
            "    annotations_ids = serializers.SerializerMethodField(required=False)",
            "    predictions_model_versions = serializers.SerializerMethodField(required=False)",
            "    avg_lead_time = serializers.FloatField(required=False)",
            "    draft_exists = serializers.BooleanField(required=False)",
            "    updated_by = serializers.SerializerMethodField(required=False, read_only=True)",
            "",
            "    CHAR_LIMITS = 500",
            "",
            "    class Meta:",
            "        model = Task",
            "        ref_name = 'data_manager_task_serializer'",
            "        fields = '__all__'",
            "        expandable_fields = {'annotations': (AnnotationSerializer, {'many': True})}",
            "",
            "    def to_representation(self, obj):",
            "        \"\"\"Dynamically manage including of some fields in the API result\"\"\"",
            "        ret = super(DataManagerTaskSerializer, self).to_representation(obj)",
            "        if not self.context.get('annotations'):",
            "            ret.pop('annotations', None)",
            "        if not self.context.get('predictions'):",
            "            ret.pop('predictions', None)",
            "        return ret",
            "",
            "    def _pretty_results(self, task, field, unique=False):",
            "        if not hasattr(task, field) or getattr(task, field) is None:",
            "            return ''",
            "",
            "        result = getattr(task, field)",
            "        if isinstance(result, str):",
            "            output = result",
            "            if unique:",
            "                output = list(set(output.split(',')))",
            "                output = ','.join(output)",
            "",
            "        elif isinstance(result, int):",
            "            output = str(result)",
            "        else:",
            "            result = [r for r in result if r is not None]",
            "            if unique:",
            "                result = list(set(result))",
            "            result = round_floats(result)",
            "            output = json.dumps(result, ensure_ascii=False)[1:-1]  # remove brackets [ ]",
            "",
            "        return output[: self.CHAR_LIMITS].replace(',\"', ', \"').replace('],[', '] [').replace('\"', '')",
            "",
            "    def get_annotations_results(self, task):",
            "        return self._pretty_results(task, 'annotations_results')",
            "",
            "    def get_predictions_results(self, task):",
            "        return self._pretty_results(task, 'predictions_results')",
            "",
            "    def get_predictions(self, task):",
            "        return PredictionSerializer(task.predictions, many=True, default=[], read_only=True).data",
            "",
            "    @staticmethod",
            "    def get_file_upload(task):",
            "        if hasattr(task, 'file_upload_field'):",
            "            file_upload = task.file_upload_field",
            "            return os.path.basename(task.file_upload_field) if file_upload else None",
            "        return None",
            "",
            "    @staticmethod",
            "    def get_storage_filename(task):",
            "        return task.storage_filename",
            "",
            "    @staticmethod",
            "    def get_updated_by(obj):",
            "        return [{'user_id': obj.updated_by_id}] if obj.updated_by_id else []",
            "",
            "    @staticmethod",
            "    def get_annotators(obj):",
            "        if not hasattr(obj, 'annotators'):",
            "            return []",
            "",
            "        annotators = obj.annotators",
            "        if not annotators:",
            "            return []",
            "        if isinstance(annotators, str):",
            "            annotators = [int(v) for v in annotators.split(',')]",
            "",
            "        annotators = list(set(annotators))",
            "        annotators = [a for a in annotators if a is not None]",
            "        return annotators if hasattr(obj, 'annotators') and annotators else []",
            "",
            "    def get_annotations_ids(self, task):",
            "        return self._pretty_results(task, 'annotations_ids', unique=True)",
            "",
            "    def get_predictions_model_versions(self, task):",
            "        return self._pretty_results(task, 'predictions_model_versions', unique=True)",
            "",
            "    def get_drafts_serializer(self):",
            "        return AnnotationDraftSerializer",
            "",
            "    def get_drafts_queryset(self, user, drafts):",
            "        \"\"\"Get all user's draft\"\"\"",
            "        return drafts.filter(user=user)",
            "",
            "    def get_drafts(self, task):",
            "        \"\"\"Return drafts only for the current user\"\"\"",
            "        # it's for swagger documentation",
            "        if not isinstance(task, Task) or not self.context.get('drafts'):",
            "            return []",
            "",
            "        drafts = task.drafts",
            "        if 'request' in self.context and hasattr(self.context['request'], 'user'):",
            "            user = self.context['request'].user",
            "            drafts = self.get_drafts_queryset(user, drafts)",
            "",
            "        serializer_class = self.get_drafts_serializer()",
            "        return serializer_class(drafts, many=True, read_only=True, default=True, context=self.context).data",
            "",
            "",
            "class SelectedItemsSerializer(serializers.Serializer):",
            "    all = serializers.BooleanField()",
            "    included = serializers.ListField(child=serializers.IntegerField(), required=False)",
            "    excluded = serializers.ListField(child=serializers.IntegerField(), required=False)",
            "",
            "    def validate(self, data):",
            "        if data['all'] is True and data.get('included'):",
            "            raise serializers.ValidationError('included not allowed with all==true')",
            "        if data['all'] is False and data.get('excluded'):",
            "            raise serializers.ValidationError('excluded not allowed with all==false')",
            "",
            "        view = self.context.get('view')",
            "        request = self.context.get('request')",
            "        if view and request and request.method in ('PATCH', 'DELETE'):",
            "            all_value = view.selected_items.get('all')",
            "            if all_value and all_value != data['all']:",
            "                raise serializers.ValidationError('changing all value possible only with POST method')",
            "",
            "        return data",
            "",
            "",
            "class ViewResetSerializer(serializers.Serializer):",
            "    project = serializers.PrimaryKeyRelatedField(queryset=Project.objects.all())"
        ],
        "afterPatchFile": [
            "\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.",
            "\"\"\"",
            "import os",
            "",
            "import ujson as json",
            "from data_manager.models import Filter, FilterGroup, View",
            "from django.conf import settings",
            "from django.db import transaction",
            "from projects.models import Project",
            "from rest_framework import serializers",
            "from tasks.models import Task",
            "from tasks.serializers import AnnotationDraftSerializer, AnnotationSerializer, PredictionSerializer, TaskSerializer",
            "",
            "from label_studio.core.utils.common import round_floats",
            "",
            "",
            "class FilterSerializer(serializers.ModelSerializer):",
            "    class Meta:",
            "        model = Filter",
            "        fields = '__all__'",
            "",
            "    def validate_column(self, column: str) -> str:",
            "        \"\"\"",
            "        Ensure that the passed filter expression starts with 'filter:tasks:' and contains",
            "        no foreign key traversals. This means either the filter expression contains no '__'",
            "        substrings, or that it's the task.data json field that's accessed.",
            "",
            "        Users depending on foreign key traversals in views can allowlist them via the",
            "        DATA_MANAGER_FILTER_ALLOWLIST setting in the env.",
            "",
            "        Edit with care. The validations below are critical for security.",
            "        \"\"\"",
            "",
            "        column_copy = column",
            "",
            "        # We may support 'filter:annotations:' in the future, but we don't as of yet.",
            "        required_prefix = 'filter:tasks:'",
            "        optional_prefix = '-'",
            "",
            "        if not column_copy.startswith(required_prefix):",
            "            raise serializers.ValidationError(f'Filter \"{column}\" should start with \"{required_prefix}\"')",
            "",
            "        column_copy = column_copy[len(required_prefix) :]",
            "",
            "        if column_copy.startswith(optional_prefix):",
            "            column_copy = column_copy[len(optional_prefix) :]",
            "",
            "        if column_copy.startswith('data.'):",
            "            # Allow underscores if the filter is based on the `task.data` JSONField, because these don't leverage foreign keys.",
            "            return column",
            "",
            "        # Specific filters relying on foreign keys can be allowlisted",
            "        if column_copy in settings.DATA_MANAGER_FILTER_ALLOWLIST:",
            "            return column",
            "",
            "        # But in general, we don't allow foreign keys",
            "        if '__' in column_copy:",
            "            raise serializers.ValidationError(",
            "                f'\"__\" is not generally allowed in filters. Consider asking your administrator to add \"{column_copy}\" '",
            "                'to DATA_MANAGER_FILTER_ALLOWLIST, but note that some filter expressions may pose a security risk'",
            "            )",
            "",
            "        return column",
            "",
            "",
            "class FilterGroupSerializer(serializers.ModelSerializer):",
            "    filters = FilterSerializer(many=True)",
            "",
            "    class Meta:",
            "        model = FilterGroup",
            "        fields = '__all__'",
            "",
            "",
            "class ViewSerializer(serializers.ModelSerializer):",
            "    filter_group = FilterGroupSerializer(required=False)",
            "",
            "    class Meta:",
            "        model = View",
            "        fields = '__all__'",
            "",
            "    def to_internal_value(self, data):",
            "        \"\"\"",
            "        map old filters structure to models",
            "        \"filters\": {  ===> FilterGroup model",
            "            \"conjunction\": \"or\",",
            "            \"items\":[  ===> \"filters\" in FilterGroup",
            "                 {  ==> Filter model",
            "                   \"filter\":\"filter:tasks:data.image\", ==> column",
            "                    \"operator\":\"contains\",",
            "                    \"type\":\"Image\",",
            "                    \"value\": <string: \"XXX\" | int: 123 | dict | list>",
            "                 },",
            "                  {",
            "                    \"filter\":\"filter:tasks:data.image\",",
            "                    \"operator\":\"equal\",",
            "                    \"type\":\"Image\",",
            "                    \"value\": <string: \"XXX\" | int: 123 | dict | list>",
            "                 }",
            "              ]",
            "           }",
            "        }",
            "        \"\"\"",
            "        _data = data.get('data', {})",
            "",
            "        filters = _data.pop('filters', {})",
            "        conjunction = filters.get('conjunction')",
            "        if 'filter_group' not in data and conjunction:",
            "            data['filter_group'] = {'conjunction': conjunction, 'filters': []}",
            "            if 'items' in filters:",
            "                for f in filters['items']:",
            "                    data['filter_group']['filters'].append(",
            "                        {",
            "                            'column': f.get('filter', ''),",
            "                            'operator': f.get('operator', ''),",
            "                            'type': f.get('type', ''),",
            "                            'value': f.get('value', {}),",
            "                        }",
            "                    )",
            "",
            "        ordering = _data.pop('ordering', {})",
            "        data['ordering'] = ordering",
            "",
            "        return super().to_internal_value(data)",
            "",
            "    def to_representation(self, instance):",
            "        result = super().to_representation(instance)",
            "        filters = result.pop('filter_group', {})",
            "        if filters:",
            "            filters['items'] = []",
            "            filters.pop('filters', [])",
            "            filters.pop('id', None)",
            "",
            "            for f in instance.filter_group.filters.order_by('index'):",
            "                filters['items'].append(",
            "                    {",
            "                        'filter': f.column,",
            "                        'operator': f.operator,",
            "                        'type': f.type,",
            "                        'value': f.value,",
            "                    }",
            "                )",
            "            result['data']['filters'] = filters",
            "",
            "        selected_items = result.pop('selected_items', {})",
            "        if selected_items:",
            "            result['data']['selectedItems'] = selected_items",
            "",
            "        ordering = result.pop('ordering', {})",
            "        if ordering:",
            "            result['data']['ordering'] = ordering",
            "        return result",
            "",
            "    @staticmethod",
            "    def _create_filters(filter_group, filters_data):",
            "        filter_index = 0",
            "        for filter_data in filters_data:",
            "            filter_data['index'] = filter_index",
            "            filter_group.filters.add(Filter.objects.create(**filter_data))",
            "            filter_index += 1",
            "",
            "    def create(self, validated_data):",
            "        with transaction.atomic():",
            "            filter_group_data = validated_data.pop('filter_group', None)",
            "            if filter_group_data:",
            "                filters_data = filter_group_data.pop('filters', [])",
            "                filter_group = FilterGroup.objects.create(**filter_group_data)",
            "",
            "                self._create_filters(filter_group=filter_group, filters_data=filters_data)",
            "",
            "                validated_data['filter_group_id'] = filter_group.id",
            "            view = self.Meta.model.objects.create(**validated_data)",
            "",
            "            return view",
            "",
            "    def update(self, instance, validated_data):",
            "        with transaction.atomic():",
            "            filter_group_data = validated_data.pop('filter_group', None)",
            "            if filter_group_data:",
            "                filters_data = filter_group_data.pop('filters', [])",
            "",
            "                filter_group = instance.filter_group",
            "                if filter_group is None:",
            "                    filter_group = FilterGroup.objects.create(**filter_group_data)",
            "",
            "                conjunction = filter_group_data.get('conjunction')",
            "                if conjunction and filter_group.conjunction != conjunction:",
            "                    filter_group.conjunction = conjunction",
            "                    filter_group.save()",
            "",
            "                filter_group.filters.clear()",
            "                self._create_filters(filter_group=filter_group, filters_data=filters_data)",
            "",
            "            ordering = validated_data.pop('ordering', None)",
            "            if ordering and ordering != instance.ordering:",
            "                instance.ordering = ordering",
            "                instance.save()",
            "",
            "            if validated_data['data'] != instance.data:",
            "                instance.data = validated_data['data']",
            "                instance.save()",
            "",
            "            return instance",
            "",
            "",
            "class DataManagerTaskSerializer(TaskSerializer):",
            "    predictions = serializers.SerializerMethodField(required=False, read_only=True)",
            "    annotations = AnnotationSerializer(required=False, many=True, default=[], read_only=True)",
            "    drafts = serializers.SerializerMethodField(required=False, read_only=True)",
            "    annotators = serializers.SerializerMethodField(required=False, read_only=True)",
            "",
            "    inner_id = serializers.IntegerField(required=False)",
            "    cancelled_annotations = serializers.IntegerField(required=False)",
            "    total_annotations = serializers.IntegerField(required=False)",
            "    total_predictions = serializers.IntegerField(required=False)",
            "    completed_at = serializers.DateTimeField(required=False)",
            "    annotations_results = serializers.SerializerMethodField(required=False)",
            "    predictions_results = serializers.SerializerMethodField(required=False)",
            "    predictions_score = serializers.FloatField(required=False)",
            "    file_upload = serializers.SerializerMethodField(required=False)",
            "    storage_filename = serializers.SerializerMethodField(required=False)",
            "    annotations_ids = serializers.SerializerMethodField(required=False)",
            "    predictions_model_versions = serializers.SerializerMethodField(required=False)",
            "    avg_lead_time = serializers.FloatField(required=False)",
            "    draft_exists = serializers.BooleanField(required=False)",
            "    updated_by = serializers.SerializerMethodField(required=False, read_only=True)",
            "",
            "    CHAR_LIMITS = 500",
            "",
            "    class Meta:",
            "        model = Task",
            "        ref_name = 'data_manager_task_serializer'",
            "        fields = '__all__'",
            "        expandable_fields = {'annotations': (AnnotationSerializer, {'many': True})}",
            "",
            "    def to_representation(self, obj):",
            "        \"\"\"Dynamically manage including of some fields in the API result\"\"\"",
            "        ret = super(DataManagerTaskSerializer, self).to_representation(obj)",
            "        if not self.context.get('annotations'):",
            "            ret.pop('annotations', None)",
            "        if not self.context.get('predictions'):",
            "            ret.pop('predictions', None)",
            "        return ret",
            "",
            "    def _pretty_results(self, task, field, unique=False):",
            "        if not hasattr(task, field) or getattr(task, field) is None:",
            "            return ''",
            "",
            "        result = getattr(task, field)",
            "        if isinstance(result, str):",
            "            output = result",
            "            if unique:",
            "                output = list(set(output.split(',')))",
            "                output = ','.join(output)",
            "",
            "        elif isinstance(result, int):",
            "            output = str(result)",
            "        else:",
            "            result = [r for r in result if r is not None]",
            "            if unique:",
            "                result = list(set(result))",
            "            result = round_floats(result)",
            "            output = json.dumps(result, ensure_ascii=False)[1:-1]  # remove brackets [ ]",
            "",
            "        return output[: self.CHAR_LIMITS].replace(',\"', ', \"').replace('],[', '] [').replace('\"', '')",
            "",
            "    def get_annotations_results(self, task):",
            "        return self._pretty_results(task, 'annotations_results')",
            "",
            "    def get_predictions_results(self, task):",
            "        return self._pretty_results(task, 'predictions_results')",
            "",
            "    def get_predictions(self, task):",
            "        return PredictionSerializer(task.predictions, many=True, default=[], read_only=True).data",
            "",
            "    @staticmethod",
            "    def get_file_upload(task):",
            "        if hasattr(task, 'file_upload_field'):",
            "            file_upload = task.file_upload_field",
            "            return os.path.basename(task.file_upload_field) if file_upload else None",
            "        return None",
            "",
            "    @staticmethod",
            "    def get_storage_filename(task):",
            "        return task.storage_filename",
            "",
            "    @staticmethod",
            "    def get_updated_by(obj):",
            "        return [{'user_id': obj.updated_by_id}] if obj.updated_by_id else []",
            "",
            "    @staticmethod",
            "    def get_annotators(obj):",
            "        if not hasattr(obj, 'annotators'):",
            "            return []",
            "",
            "        annotators = obj.annotators",
            "        if not annotators:",
            "            return []",
            "        if isinstance(annotators, str):",
            "            annotators = [int(v) for v in annotators.split(',')]",
            "",
            "        annotators = list(set(annotators))",
            "        annotators = [a for a in annotators if a is not None]",
            "        return annotators if hasattr(obj, 'annotators') and annotators else []",
            "",
            "    def get_annotations_ids(self, task):",
            "        return self._pretty_results(task, 'annotations_ids', unique=True)",
            "",
            "    def get_predictions_model_versions(self, task):",
            "        return self._pretty_results(task, 'predictions_model_versions', unique=True)",
            "",
            "    def get_drafts_serializer(self):",
            "        return AnnotationDraftSerializer",
            "",
            "    def get_drafts_queryset(self, user, drafts):",
            "        \"\"\"Get all user's draft\"\"\"",
            "        return drafts.filter(user=user)",
            "",
            "    def get_drafts(self, task):",
            "        \"\"\"Return drafts only for the current user\"\"\"",
            "        # it's for swagger documentation",
            "        if not isinstance(task, Task) or not self.context.get('drafts'):",
            "            return []",
            "",
            "        drafts = task.drafts",
            "        if 'request' in self.context and hasattr(self.context['request'], 'user'):",
            "            user = self.context['request'].user",
            "            drafts = self.get_drafts_queryset(user, drafts)",
            "",
            "        serializer_class = self.get_drafts_serializer()",
            "        return serializer_class(drafts, many=True, read_only=True, default=True, context=self.context).data",
            "",
            "",
            "class SelectedItemsSerializer(serializers.Serializer):",
            "    all = serializers.BooleanField()",
            "    included = serializers.ListField(child=serializers.IntegerField(), required=False)",
            "    excluded = serializers.ListField(child=serializers.IntegerField(), required=False)",
            "",
            "    def validate(self, data):",
            "        if data['all'] is True and data.get('included'):",
            "            raise serializers.ValidationError('included not allowed with all==true')",
            "        if data['all'] is False and data.get('excluded'):",
            "            raise serializers.ValidationError('excluded not allowed with all==false')",
            "",
            "        view = self.context.get('view')",
            "        request = self.context.get('request')",
            "        if view and request and request.method in ('PATCH', 'DELETE'):",
            "            all_value = view.selected_items.get('all')",
            "            if all_value and all_value != data['all']:",
            "                raise serializers.ValidationError('changing all value possible only with POST method')",
            "",
            "        return data",
            "",
            "",
            "class ViewResetSerializer(serializers.Serializer):",
            "    project = serializers.PrimaryKeyRelatedField(queryset=Project.objects.all())"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "aioxmpp.xso.model"
        ]
    }
}