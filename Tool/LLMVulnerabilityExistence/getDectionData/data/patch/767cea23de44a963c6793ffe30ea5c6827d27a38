{
    "neutron/api/v2/attributes.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 766,
                "afterPatchRowNumber": 766,
                "PatchRowcode": "                       'is_visible': True},"
            },
            "1": {
                "beforePatchRowNumber": 767,
                "afterPatchRowNumber": 767,
                "PatchRowcode": "         'device_owner': {'allow_post': True, 'allow_put': True,"
            },
            "2": {
                "beforePatchRowNumber": 768,
                "afterPatchRowNumber": 768,
                "PatchRowcode": "                          'validate': {'type:string': DEVICE_OWNER_MAX_LEN},"
            },
            "3": {
                "beforePatchRowNumber": 769,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                         'default': '',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 769,
                "PatchRowcode": "+                         'default': '', 'enforce_policy': True,"
            },
            "5": {
                "beforePatchRowNumber": 770,
                "afterPatchRowNumber": 770,
                "PatchRowcode": "                          'is_visible': True},"
            },
            "6": {
                "beforePatchRowNumber": 771,
                "afterPatchRowNumber": 771,
                "PatchRowcode": "         'tenant_id': {'allow_post': True, 'allow_put': False,"
            },
            "7": {
                "beforePatchRowNumber": 772,
                "afterPatchRowNumber": 772,
                "PatchRowcode": "                       'validate': {'type:string': TENANT_ID_MAX_LEN},"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import re",
            "",
            "import netaddr",
            "from oslo_log import log as logging",
            "",
            "from neutron.common import constants",
            "from neutron.common import exceptions as n_exc",
            "from neutron.openstack.common import uuidutils",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "ATTR_NOT_SPECIFIED = object()",
            "# Defining a constant to avoid repeating string literal in several modules",
            "SHARED = 'shared'",
            "",
            "# Used by range check to indicate no limit for a bound.",
            "UNLIMITED = None",
            "",
            "# TODO(watanabe.isao): A fix like in neutron/db/models_v2.py needs to be",
            "# done in other db modules, to reuse the following constants.",
            "# Common definitions for maximum string field length",
            "NAME_MAX_LEN = 255",
            "TENANT_ID_MAX_LEN = 255",
            "DESCRIPTION_MAX_LEN = 255",
            "DEVICE_ID_MAX_LEN = 255",
            "DEVICE_OWNER_MAX_LEN = 255",
            "",
            "",
            "def _verify_dict_keys(expected_keys, target_dict, strict=True):",
            "    \"\"\"Allows to verify keys in a dictionary.",
            "",
            "    :param expected_keys: A list of keys expected to be present.",
            "    :param target_dict: The dictionary which should be verified.",
            "    :param strict: Specifies whether additional keys are allowed to be present.",
            "    :return: True, if keys in the dictionary correspond to the specification.",
            "    \"\"\"",
            "    if not isinstance(target_dict, dict):",
            "        msg = (_(\"Invalid input. '%(target_dict)s' must be a dictionary \"",
            "                 \"with keys: %(expected_keys)s\") %",
            "               {'target_dict': target_dict, 'expected_keys': expected_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = set(expected_keys)",
            "    provided_keys = set(target_dict.keys())",
            "",
            "    predicate = expected_keys.__eq__ if strict else expected_keys.issubset",
            "",
            "    if not predicate(provided_keys):",
            "        msg = (_(\"Validation of dictionary's keys failed. \"",
            "                 \"Expected keys: %(expected_keys)s \"",
            "                 \"Provided keys: %(provided_keys)s\") %",
            "               {'expected_keys': expected_keys,",
            "                'provided_keys': provided_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def is_attr_set(attribute):",
            "    return not (attribute is None or attribute is ATTR_NOT_SPECIFIED)",
            "",
            "",
            "def _validate_values(data, valid_values=None):",
            "    if data not in valid_values:",
            "        msg = (_(\"'%(data)s' is not in %(valid_values)s\") %",
            "               {'data': data, 'valid_values': valid_values})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_not_empty_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_not_empty_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_not_empty_string(data, max_len=None):",
            "    msg = _validate_string(data, max_len=max_len)",
            "    if msg:",
            "        return msg",
            "    if not data.strip():",
            "        msg = _(\"'%s' Blank strings are not permitted\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_string(data, max_len=None):",
            "    if not isinstance(data, basestring):",
            "        msg = _(\"'%s' is not a valid string\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if max_len is not None and len(data) > max_len:",
            "        msg = (_(\"'%(data)s' exceeds maximum length of %(max_len)s\") %",
            "               {'data': data, 'max_len': max_len})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_boolean(data, valid_values=None):",
            "    try:",
            "        convert_to_boolean(data)",
            "    except n_exc.InvalidInput:",
            "        msg = _(\"'%s' is not a valid boolean value\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_range(data, valid_values=None):",
            "    \"\"\"Check that integer value is within a range provided.",
            "",
            "    Test is inclusive. Allows either limit to be ignored, to allow",
            "    checking ranges where only the lower or upper limit matter.",
            "    It is expected that the limits provided are valid integers or",
            "    the value None.",
            "    \"\"\"",
            "",
            "    min_value = valid_values[0]",
            "    max_value = valid_values[1]",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    if min_value is not UNLIMITED and data < min_value:",
            "        msg = _(\"'%(data)s' is too small - must be at least \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': min_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "    if max_value is not UNLIMITED and data > max_value:",
            "        msg = _(\"'%(data)s' is too large - must be no larger than \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': max_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_no_whitespace(data):",
            "    \"\"\"Validates that input has no whitespace.\"\"\"",
            "    if re.search(r'\\s', data):",
            "        msg = _(\"'%s' contains whitespace\") % data",
            "        LOG.debug(msg)",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return data",
            "",
            "",
            "def _validate_mac_address(data, valid_values=None):",
            "    try:",
            "        valid_mac = netaddr.valid_mac(_validate_no_whitespace(data))",
            "    except Exception:",
            "        valid_mac = False",
            "    # TODO(arosen): The code in this file should be refactored",
            "    # so it catches the correct exceptions. _validate_no_whitespace",
            "    # raises AttributeError if data is None.",
            "    if not valid_mac:",
            "        msg = _(\"'%s' is not a valid MAC address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_mac_address_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_mac_address(data, valid_values)",
            "",
            "",
            "def _validate_ip_address(data, valid_values=None):",
            "    try:",
            "        netaddr.IPAddress(_validate_no_whitespace(data))",
            "        # The followings are quick checks for IPv6 (has ':') and",
            "        # IPv4.  (has 3 periods like 'xx.xx.xx.xx')",
            "        # NOTE(yamamoto): netaddr uses libraries provided by the underlying",
            "        # platform to convert addresses.  For example, inet_aton(3).",
            "        # Some platforms, including NetBSD and OS X, have inet_aton",
            "        # implementation which accepts more varying forms of addresses than",
            "        # we want to accept here.  The following check is to reject such",
            "        # addresses.  For Example:",
            "        #   >>> netaddr.IPAddress('1' * 59)",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>> netaddr.IPAddress(str(int('1' * 59) & 0xffffffff))",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>>",
            "        if ':' not in data and data.count('.') != 3:",
            "            raise ValueError()",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_ip_pools(data, valid_values=None):",
            "    \"\"\"Validate that start and end IP addresses are present.",
            "",
            "    In addition to this the IP addresses will also be validated",
            "    \"\"\"",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for IP pool: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['start', 'end']",
            "    for ip_pool in data:",
            "        msg = _verify_dict_keys(expected_keys, ip_pool)",
            "        if msg:",
            "            return msg",
            "        for k in expected_keys:",
            "            msg = _validate_ip_address(ip_pool[k])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_fixed_ips(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for fixed IP: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    ips = []",
            "    for fixed_ip in data:",
            "        if not isinstance(fixed_ip, dict):",
            "            msg = _(\"Invalid data format for fixed IP: '%s'\") % fixed_ip",
            "            LOG.debug(msg)",
            "            return msg",
            "        if 'ip_address' in fixed_ip:",
            "            # Ensure that duplicate entries are not set - just checking IP",
            "            # suffices. Duplicate subnet_id's are legitimate.",
            "            fixed_ip_address = fixed_ip['ip_address']",
            "            if fixed_ip_address in ips:",
            "                msg = _(\"Duplicate IP address '%s'\") % fixed_ip_address",
            "                LOG.debug(msg)",
            "            else:",
            "                msg = _validate_ip_address(fixed_ip_address)",
            "            if msg:",
            "                return msg",
            "            ips.append(fixed_ip_address)",
            "        if 'subnet_id' in fixed_ip:",
            "            msg = _validate_uuid(fixed_ip['subnet_id'])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_ip_or_hostname(host):",
            "    ip_err = _validate_ip_address(host)",
            "    if not ip_err:",
            "        return",
            "    name_err = _validate_hostname(host)",
            "    if not name_err:",
            "        return",
            "    msg = _(\"%(host)s is not a valid IP or hostname. Details: \"",
            "            \"%(ip_err)s, %(name_err)s\") % {'ip_err': ip_err, 'host': host,",
            "                                           'name_err': name_err}",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_nameservers(data, valid_values=None):",
            "    if not hasattr(data, '__iter__'):",
            "        msg = _(\"Invalid data format for nameserver: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    hosts = []",
            "    for host in data:",
            "        # This may be an IP or a hostname",
            "        msg = _validate_ip_or_hostname(host)",
            "        if msg:",
            "            msg = _(\"'%(host)s' is not a valid nameserver. %(msg)s\") % {",
            "                'host': host, 'msg': msg}",
            "            LOG.debug(msg)",
            "            return msg",
            "        if host in hosts:",
            "            msg = _(\"Duplicate nameserver '%s'\") % host",
            "            LOG.debug(msg)",
            "            return msg",
            "        hosts.append(host)",
            "",
            "",
            "def _validate_hostroutes(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for hostroute: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['destination', 'nexthop']",
            "    hostroutes = []",
            "    for hostroute in data:",
            "        msg = _verify_dict_keys(expected_keys, hostroute)",
            "        if msg:",
            "            return msg",
            "        msg = _validate_subnet(hostroute['destination'])",
            "        if msg:",
            "            return msg",
            "        msg = _validate_ip_address(hostroute['nexthop'])",
            "        if msg:",
            "            return msg",
            "        if hostroute in hostroutes:",
            "            msg = _(\"Duplicate hostroute '%s'\") % hostroute",
            "            LOG.debug(msg)",
            "            return msg",
            "        hostroutes.append(hostroute)",
            "",
            "",
            "def _validate_ip_address_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return None",
            "    return _validate_ip_address(data, valid_values)",
            "",
            "",
            "def _validate_subnet(data, valid_values=None):",
            "    msg = None",
            "    try:",
            "        net = netaddr.IPNetwork(_validate_no_whitespace(data))",
            "        if '/' not in data:",
            "            msg = _(\"'%(data)s' isn't a recognized IP subnet cidr,\"",
            "                    \" '%(cidr)s' is recommended\") % {\"data\": data,",
            "                                                     \"cidr\": net.cidr}",
            "        else:",
            "            return",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP subnet\") % data",
            "    if msg:",
            "        LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_subnet_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_subnet(item)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_subnet_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_subnet(data, valid_values)",
            "",
            "",
            "def _validate_hostname(data):",
            "    # NOTE: An individual name regex instead of an entire FQDN was used",
            "    # because its easier to make correct. Feel free to replace with a",
            "    # full regex solution. The logic should validate that the hostname",
            "    # matches RFC 1123 (section 2.1) and RFC 952.",
            "    hostname_pattern = \"[a-zA-Z0-9-]{1,63}$\"",
            "    try:",
            "        # Trailing periods are allowed to indicate that a name is fully",
            "        # qualified per RFC 1034 (page 7).",
            "        trimmed = data if data[-1] != '.' else data[:-1]",
            "        if len(trimmed) > 255:",
            "            raise TypeError(",
            "                _(\"'%s' exceeds the 255 character hostname limit\") % trimmed)",
            "        names = trimmed.split('.')",
            "        for name in names:",
            "            if not name:",
            "                raise TypeError(_(\"Encountered an empty component.\"))",
            "            if name[-1] == '-' or name[0] == '-':",
            "                raise TypeError(",
            "                    _(\"Name '%s' must not start or end with a hyphen.\") % name)",
            "            if not re.match(hostname_pattern, name):",
            "                raise TypeError(",
            "                    _(\"Name '%s' must be 1-63 characters long, each of \"",
            "                      \"which can only be alphanumeric or a hyphen.\") % name)",
            "        # RFC 1123 hints that a TLD can't be all numeric. last is a TLD if",
            "        # it's an FQDN.",
            "        if len(names) > 1 and re.match(\"^[0-9]+$\", names[-1]):",
            "            raise TypeError(_(\"TLD '%s' must not be all numeric\") % names[-1])",
            "    except TypeError as e:",
            "        msg = _(\"'%(data)s' is not a valid hostname. Reason: %(reason)s\") % {",
            "            'data': data, 'reason': e.message}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_regex(data, valid_values=None):",
            "    try:",
            "        if re.match(valid_values, data):",
            "            return",
            "    except TypeError:",
            "        pass",
            "",
            "    msg = _(\"'%s' is not a valid input\") % data",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_regex_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_regex(data, valid_values)",
            "",
            "",
            "def _validate_uuid(data, valid_values=None):",
            "    if not uuidutils.is_uuid_like(data):",
            "        msg = _(\"'%s' is not a valid UUID\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_uuid_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_uuid(data)",
            "",
            "",
            "def _validate_uuid_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_uuid(item)",
            "        if msg:",
            "            return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_dict_item(key, key_validator, data):",
            "    # Find conversion function, if any, and apply it",
            "    conv_func = key_validator.get('convert_to')",
            "    if conv_func:",
            "        data[key] = conv_func(data.get(key))",
            "    # Find validator function",
            "    # TODO(salv-orlando): Structure of dict attributes should be improved",
            "    # to avoid iterating over items",
            "    val_func = val_params = None",
            "    for (k, v) in key_validator.iteritems():",
            "        if k.startswith('type:'):",
            "            # ask forgiveness, not permission",
            "            try:",
            "                val_func = validators[k]",
            "            except KeyError:",
            "                msg = _(\"Validator '%s' does not exist.\") % k",
            "                LOG.debug(msg)",
            "                return msg",
            "            val_params = v",
            "            break",
            "    # Process validation",
            "    if val_func:",
            "        return val_func(data.get(key), val_params)",
            "",
            "",
            "def _validate_dict(data, key_specs=None):",
            "    if not isinstance(data, dict):",
            "        msg = _(\"'%s' is not a dictionary\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    # Do not perform any further validation, if no constraints are supplied",
            "    if not key_specs:",
            "        return",
            "",
            "    # Check whether all required keys are present",
            "    required_keys = [key for key, spec in key_specs.iteritems()",
            "                     if spec.get('required')]",
            "",
            "    if required_keys:",
            "        msg = _verify_dict_keys(required_keys, data, False)",
            "        if msg:",
            "            return msg",
            "",
            "    # Perform validation and conversion of all values",
            "    # according to the specifications.",
            "    for key, key_validator in [(k, v) for k, v in key_specs.iteritems()",
            "                               if k in data]:",
            "        msg = _validate_dict_item(key, key_validator, data)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_dict_or_none(data, key_specs=None):",
            "    if data is not None:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_empty(data, key_specs=None):",
            "    if data != {}:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_nodata(data, key_specs=None):",
            "    if data:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_non_negative(data, valid_values=None):",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if data < 0:",
            "        msg = _(\"'%s' should be non-negative\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def convert_to_boolean(data):",
            "    if isinstance(data, basestring):",
            "        val = data.lower()",
            "        if val == \"true\" or val == \"1\":",
            "            return True",
            "        if val == \"false\" or val == \"0\":",
            "            return False",
            "    elif isinstance(data, bool):",
            "        return data",
            "    elif isinstance(data, int):",
            "        if data == 0:",
            "            return False",
            "        elif data == 1:",
            "            return True",
            "    msg = _(\"'%s' cannot be converted to boolean\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_boolean_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_boolean(data)",
            "",
            "",
            "def convert_to_int(data):",
            "    try:",
            "        return int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not a integer\") % data",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_int_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_int(data)",
            "    return data",
            "",
            "",
            "def convert_to_positive_float_or_none(val):",
            "    # NOTE(salv-orlando): This conversion function is currently used by",
            "    # a vendor specific extension only at the moment  It is used for",
            "    # port's RXTX factor in neutron.plugins.vmware.extensions.qos.",
            "    # It is deemed however generic enough to be in this module as it",
            "    # might be used in future for other API attributes.",
            "    if val is None:",
            "        return",
            "    try:",
            "        val = float(val)",
            "        if val < 0:",
            "            raise ValueError()",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' must be a non negative decimal.\") % val",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return val",
            "",
            "",
            "def convert_kvp_str_to_list(data):",
            "    \"\"\"Convert a value of the form 'key=value' to ['key', 'value'].",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key).",
            "    \"\"\"",
            "    kvp = [x.strip() for x in data.split('=', 1)]",
            "    if len(kvp) == 2 and kvp[0]:",
            "        return kvp",
            "    msg = _(\"'%s' is not of the form <key>=[value]\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_kvp_list_to_dict(kvp_list):",
            "    \"\"\"Convert a list of 'key=value' strings to a dict.",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key) or if any",
            "                                of the keys appear more than once.",
            "    \"\"\"",
            "    if kvp_list == ['True']:",
            "        # No values were provided (i.e. '--flag-name')",
            "        return {}",
            "    kvp_map = {}",
            "    for kvp_str in kvp_list:",
            "        key, value = convert_kvp_str_to_list(kvp_str)",
            "        kvp_map.setdefault(key, set())",
            "        kvp_map[key].add(value)",
            "    return dict((x, list(y)) for x, y in kvp_map.iteritems())",
            "",
            "",
            "def convert_none_to_empty_list(value):",
            "    return [] if value is None else value",
            "",
            "",
            "def convert_none_to_empty_dict(value):",
            "    return {} if value is None else value",
            "",
            "",
            "def convert_to_list(data):",
            "    if data is None:",
            "        return []",
            "    elif hasattr(data, '__iter__'):",
            "        return list(data)",
            "    else:",
            "        return [data]",
            "",
            "",
            "HEX_ELEM = '[0-9A-Fa-f]'",
            "UUID_PATTERN = '-'.join([HEX_ELEM + '{8}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{4}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{12}'])",
            "# Note: In order to ensure that the MAC address is unicast the first byte",
            "# must be even.",
            "MAC_PATTERN = \"^%s[aceACE02468](:%s{2}){5}$\" % (HEX_ELEM, HEX_ELEM)",
            "",
            "# Dictionary that maintains a list of validation functions",
            "validators = {'type:dict': _validate_dict,",
            "              'type:dict_or_none': _validate_dict_or_none,",
            "              'type:dict_or_empty': _validate_dict_or_empty,",
            "              'type:dict_or_nodata': _validate_dict_or_nodata,",
            "              'type:fixed_ips': _validate_fixed_ips,",
            "              'type:hostroutes': _validate_hostroutes,",
            "              'type:ip_address': _validate_ip_address,",
            "              'type:ip_address_or_none': _validate_ip_address_or_none,",
            "              'type:ip_pools': _validate_ip_pools,",
            "              'type:mac_address': _validate_mac_address,",
            "              'type:mac_address_or_none': _validate_mac_address_or_none,",
            "              'type:nameservers': _validate_nameservers,",
            "              'type:non_negative': _validate_non_negative,",
            "              'type:range': _validate_range,",
            "              'type:regex': _validate_regex,",
            "              'type:regex_or_none': _validate_regex_or_none,",
            "              'type:string': _validate_string,",
            "              'type:string_or_none': _validate_string_or_none,",
            "              'type:not_empty_string': _validate_not_empty_string,",
            "              'type:not_empty_string_or_none':",
            "              _validate_not_empty_string_or_none,",
            "              'type:subnet': _validate_subnet,",
            "              'type:subnet_list': _validate_subnet_list,",
            "              'type:subnet_or_none': _validate_subnet_or_none,",
            "              'type:uuid': _validate_uuid,",
            "              'type:uuid_or_none': _validate_uuid_or_none,",
            "              'type:uuid_list': _validate_uuid_list,",
            "              'type:values': _validate_values,",
            "              'type:boolean': _validate_boolean}",
            "",
            "# Define constants for base resource name",
            "NETWORK = 'network'",
            "NETWORKS = '%ss' % NETWORK",
            "PORT = 'port'",
            "PORTS = '%ss' % PORT",
            "SUBNET = 'subnet'",
            "SUBNETS = '%ss' % SUBNET",
            "SUBNETPOOL = 'subnetpool'",
            "SUBNETPOOLS = '%ss' % SUBNETPOOL",
            "# Note: a default of ATTR_NOT_SPECIFIED indicates that an",
            "# attribute is not required, but will be generated by the plugin",
            "# if it is not specified.  Particularly, a value of ATTR_NOT_SPECIFIED",
            "# is different from an attribute that has been specified with a value of",
            "# None.  For example, if 'gateway_ip' is omitted in a request to",
            "# create a subnet, the plugin will receive ATTR_NOT_SPECIFIED",
            "# and the default gateway_ip will be generated.",
            "# However, if gateway_ip is specified as None, this means that",
            "# the subnet does not have a gateway IP.",
            "# The following is a short reference for understanding attribute info:",
            "# default: default value of the attribute (if missing, the attribute",
            "# becomes mandatory.",
            "# allow_post: the attribute can be used on POST requests.",
            "# allow_put: the attribute can be used on PUT requests.",
            "# validate: specifies rules for validating data in the attribute.",
            "# convert_to: transformation to apply to the value before it is returned",
            "# is_visible: the attribute is returned in GET responses.",
            "# required_by_policy: the attribute is required by the policy engine and",
            "# should therefore be filled by the API layer even if not present in",
            "# request body.",
            "# enforce_policy: the attribute is actively part of the policy enforcing",
            "# mechanism, ie: there might be rules which refer to this attribute.",
            "",
            "RESOURCE_ATTRIBUTE_MAP = {",
            "    NETWORKS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True,",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'default': '', 'is_visible': True},",
            "        'subnets': {'allow_post': False, 'allow_put': False,",
            "                    'default': [],",
            "                    'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    PORTS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'mac_address': {'allow_post': True, 'allow_put': True,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:mac_address': None},",
            "                        'enforce_policy': True,",
            "                        'is_visible': True},",
            "        'fixed_ips': {'allow_post': True, 'allow_put': True,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'convert_list_to': convert_kvp_list_to_dict,",
            "                      'validate': {'type:fixed_ips': None},",
            "                      'enforce_policy': True,",
            "                      'is_visible': True},",
            "        'device_id': {'allow_post': True, 'allow_put': True,",
            "                      'validate': {'type:string': DEVICE_ID_MAX_LEN},",
            "                      'default': '',",
            "                      'is_visible': True},",
            "        'device_owner': {'allow_post': True, 'allow_put': True,",
            "                         'validate': {'type:string': DEVICE_OWNER_MAX_LEN},",
            "                         'default': '',",
            "                         'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "    },",
            "    SUBNETS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'ip_version': {'allow_post': True, 'allow_put': False,",
            "                       'convert_to': convert_to_int,",
            "                       'validate': {'type:values': [4, 6]},",
            "                       'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'subnetpool_id': {'allow_post': True,",
            "                          'allow_put': False,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'required_by_policy': False,",
            "                          'validate': {'type:uuid_or_none': None},",
            "                          'is_visible': True},",
            "        'prefixlen': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:non_negative': None},",
            "                      'convert_to': convert_to_int,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'required_by_policy': False,",
            "                      'is_visible': False},",
            "        'cidr': {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': ATTR_NOT_SPECIFIED,",
            "                 'validate': {'type:subnet_or_none': None},",
            "                 'required_by_policy': False,",
            "                 'is_visible': True},",
            "        'gateway_ip': {'allow_post': True, 'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:ip_address_or_none': None},",
            "                       'is_visible': True},",
            "        'allocation_pools': {'allow_post': True, 'allow_put': True,",
            "                             'default': ATTR_NOT_SPECIFIED,",
            "                             'validate': {'type:ip_pools': None},",
            "                             'is_visible': True},",
            "        'dns_nameservers': {'allow_post': True, 'allow_put': True,",
            "                            'convert_to': convert_none_to_empty_list,",
            "                            'default': ATTR_NOT_SPECIFIED,",
            "                            'validate': {'type:nameservers': None},",
            "                            'is_visible': True},",
            "        'host_routes': {'allow_post': True, 'allow_put': True,",
            "                        'convert_to': convert_none_to_empty_list,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:hostroutes': None},",
            "                        'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'enable_dhcp': {'allow_post': True, 'allow_put': True,",
            "                        'default': True,",
            "                        'convert_to': convert_to_boolean,",
            "                        'is_visible': True},",
            "        'ipv6_ra_mode': {'allow_post': True, 'allow_put': False,",
            "                         'default': ATTR_NOT_SPECIFIED,",
            "                         'validate': {'type:values': constants.IPV6_MODES},",
            "                         'is_visible': True},",
            "        'ipv6_address_mode': {'allow_post': True, 'allow_put': False,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'validate': {'type:values':",
            "                                           constants.IPV6_MODES},",
            "                              'is_visible': True},",
            "        SHARED: {'allow_post': False,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': False,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    SUBNETPOOLS: {",
            "        'id': {'allow_post': False,",
            "               'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'validate': {'type:not_empty_string': None},",
            "                 'is_visible': True},",
            "        'tenant_id': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:string': None},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'prefixes': {'allow_post': True,",
            "                     'allow_put': True,",
            "                     'validate': {'type:subnet_list': None},",
            "                     'is_visible': True},",
            "        'default_quota': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'is_visible': True},",
            "        'ip_version': {'allow_post': False,",
            "                       'allow_put': False,",
            "                       'is_visible': True},",
            "        'default_prefixlen': {'allow_post': True,",
            "                           'allow_put': True,",
            "                           'validate': {'type:non_negative': None},",
            "                           'convert_to': convert_to_int,",
            "                           'default': ATTR_NOT_SPECIFIED,",
            "                           'is_visible': True},",
            "        'min_prefixlen': {'allow_post': True,",
            "                       'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:non_negative': None},",
            "                       'convert_to': convert_to_int,",
            "                       'is_visible': True},",
            "        'max_prefixlen': {'allow_post': True,",
            "                       'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:non_negative': None},",
            "                       'convert_to': convert_to_int,",
            "                       'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    }",
            "}",
            "",
            "# Identify the attribute used by a resource to reference another resource",
            "",
            "RESOURCE_FOREIGN_KEYS = {",
            "    NETWORKS: 'network_id'",
            "}",
            "",
            "PLURALS = {NETWORKS: NETWORK,",
            "           PORTS: PORT,",
            "           SUBNETS: SUBNET,",
            "           SUBNETPOOLS: SUBNETPOOL,",
            "           'dns_nameservers': 'dns_nameserver',",
            "           'host_routes': 'host_route',",
            "           'allocation_pools': 'allocation_pool',",
            "           'fixed_ips': 'fixed_ip',",
            "           'extensions': 'extension'}"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import re",
            "",
            "import netaddr",
            "from oslo_log import log as logging",
            "",
            "from neutron.common import constants",
            "from neutron.common import exceptions as n_exc",
            "from neutron.openstack.common import uuidutils",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "ATTR_NOT_SPECIFIED = object()",
            "# Defining a constant to avoid repeating string literal in several modules",
            "SHARED = 'shared'",
            "",
            "# Used by range check to indicate no limit for a bound.",
            "UNLIMITED = None",
            "",
            "# TODO(watanabe.isao): A fix like in neutron/db/models_v2.py needs to be",
            "# done in other db modules, to reuse the following constants.",
            "# Common definitions for maximum string field length",
            "NAME_MAX_LEN = 255",
            "TENANT_ID_MAX_LEN = 255",
            "DESCRIPTION_MAX_LEN = 255",
            "DEVICE_ID_MAX_LEN = 255",
            "DEVICE_OWNER_MAX_LEN = 255",
            "",
            "",
            "def _verify_dict_keys(expected_keys, target_dict, strict=True):",
            "    \"\"\"Allows to verify keys in a dictionary.",
            "",
            "    :param expected_keys: A list of keys expected to be present.",
            "    :param target_dict: The dictionary which should be verified.",
            "    :param strict: Specifies whether additional keys are allowed to be present.",
            "    :return: True, if keys in the dictionary correspond to the specification.",
            "    \"\"\"",
            "    if not isinstance(target_dict, dict):",
            "        msg = (_(\"Invalid input. '%(target_dict)s' must be a dictionary \"",
            "                 \"with keys: %(expected_keys)s\") %",
            "               {'target_dict': target_dict, 'expected_keys': expected_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = set(expected_keys)",
            "    provided_keys = set(target_dict.keys())",
            "",
            "    predicate = expected_keys.__eq__ if strict else expected_keys.issubset",
            "",
            "    if not predicate(provided_keys):",
            "        msg = (_(\"Validation of dictionary's keys failed. \"",
            "                 \"Expected keys: %(expected_keys)s \"",
            "                 \"Provided keys: %(provided_keys)s\") %",
            "               {'expected_keys': expected_keys,",
            "                'provided_keys': provided_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def is_attr_set(attribute):",
            "    return not (attribute is None or attribute is ATTR_NOT_SPECIFIED)",
            "",
            "",
            "def _validate_values(data, valid_values=None):",
            "    if data not in valid_values:",
            "        msg = (_(\"'%(data)s' is not in %(valid_values)s\") %",
            "               {'data': data, 'valid_values': valid_values})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_not_empty_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_not_empty_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_not_empty_string(data, max_len=None):",
            "    msg = _validate_string(data, max_len=max_len)",
            "    if msg:",
            "        return msg",
            "    if not data.strip():",
            "        msg = _(\"'%s' Blank strings are not permitted\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_string(data, max_len=None):",
            "    if not isinstance(data, basestring):",
            "        msg = _(\"'%s' is not a valid string\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if max_len is not None and len(data) > max_len:",
            "        msg = (_(\"'%(data)s' exceeds maximum length of %(max_len)s\") %",
            "               {'data': data, 'max_len': max_len})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_boolean(data, valid_values=None):",
            "    try:",
            "        convert_to_boolean(data)",
            "    except n_exc.InvalidInput:",
            "        msg = _(\"'%s' is not a valid boolean value\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_range(data, valid_values=None):",
            "    \"\"\"Check that integer value is within a range provided.",
            "",
            "    Test is inclusive. Allows either limit to be ignored, to allow",
            "    checking ranges where only the lower or upper limit matter.",
            "    It is expected that the limits provided are valid integers or",
            "    the value None.",
            "    \"\"\"",
            "",
            "    min_value = valid_values[0]",
            "    max_value = valid_values[1]",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    if min_value is not UNLIMITED and data < min_value:",
            "        msg = _(\"'%(data)s' is too small - must be at least \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': min_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "    if max_value is not UNLIMITED and data > max_value:",
            "        msg = _(\"'%(data)s' is too large - must be no larger than \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': max_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_no_whitespace(data):",
            "    \"\"\"Validates that input has no whitespace.\"\"\"",
            "    if re.search(r'\\s', data):",
            "        msg = _(\"'%s' contains whitespace\") % data",
            "        LOG.debug(msg)",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return data",
            "",
            "",
            "def _validate_mac_address(data, valid_values=None):",
            "    try:",
            "        valid_mac = netaddr.valid_mac(_validate_no_whitespace(data))",
            "    except Exception:",
            "        valid_mac = False",
            "    # TODO(arosen): The code in this file should be refactored",
            "    # so it catches the correct exceptions. _validate_no_whitespace",
            "    # raises AttributeError if data is None.",
            "    if not valid_mac:",
            "        msg = _(\"'%s' is not a valid MAC address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_mac_address_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_mac_address(data, valid_values)",
            "",
            "",
            "def _validate_ip_address(data, valid_values=None):",
            "    try:",
            "        netaddr.IPAddress(_validate_no_whitespace(data))",
            "        # The followings are quick checks for IPv6 (has ':') and",
            "        # IPv4.  (has 3 periods like 'xx.xx.xx.xx')",
            "        # NOTE(yamamoto): netaddr uses libraries provided by the underlying",
            "        # platform to convert addresses.  For example, inet_aton(3).",
            "        # Some platforms, including NetBSD and OS X, have inet_aton",
            "        # implementation which accepts more varying forms of addresses than",
            "        # we want to accept here.  The following check is to reject such",
            "        # addresses.  For Example:",
            "        #   >>> netaddr.IPAddress('1' * 59)",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>> netaddr.IPAddress(str(int('1' * 59) & 0xffffffff))",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>>",
            "        if ':' not in data and data.count('.') != 3:",
            "            raise ValueError()",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_ip_pools(data, valid_values=None):",
            "    \"\"\"Validate that start and end IP addresses are present.",
            "",
            "    In addition to this the IP addresses will also be validated",
            "    \"\"\"",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for IP pool: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['start', 'end']",
            "    for ip_pool in data:",
            "        msg = _verify_dict_keys(expected_keys, ip_pool)",
            "        if msg:",
            "            return msg",
            "        for k in expected_keys:",
            "            msg = _validate_ip_address(ip_pool[k])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_fixed_ips(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for fixed IP: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    ips = []",
            "    for fixed_ip in data:",
            "        if not isinstance(fixed_ip, dict):",
            "            msg = _(\"Invalid data format for fixed IP: '%s'\") % fixed_ip",
            "            LOG.debug(msg)",
            "            return msg",
            "        if 'ip_address' in fixed_ip:",
            "            # Ensure that duplicate entries are not set - just checking IP",
            "            # suffices. Duplicate subnet_id's are legitimate.",
            "            fixed_ip_address = fixed_ip['ip_address']",
            "            if fixed_ip_address in ips:",
            "                msg = _(\"Duplicate IP address '%s'\") % fixed_ip_address",
            "                LOG.debug(msg)",
            "            else:",
            "                msg = _validate_ip_address(fixed_ip_address)",
            "            if msg:",
            "                return msg",
            "            ips.append(fixed_ip_address)",
            "        if 'subnet_id' in fixed_ip:",
            "            msg = _validate_uuid(fixed_ip['subnet_id'])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_ip_or_hostname(host):",
            "    ip_err = _validate_ip_address(host)",
            "    if not ip_err:",
            "        return",
            "    name_err = _validate_hostname(host)",
            "    if not name_err:",
            "        return",
            "    msg = _(\"%(host)s is not a valid IP or hostname. Details: \"",
            "            \"%(ip_err)s, %(name_err)s\") % {'ip_err': ip_err, 'host': host,",
            "                                           'name_err': name_err}",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_nameservers(data, valid_values=None):",
            "    if not hasattr(data, '__iter__'):",
            "        msg = _(\"Invalid data format for nameserver: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    hosts = []",
            "    for host in data:",
            "        # This may be an IP or a hostname",
            "        msg = _validate_ip_or_hostname(host)",
            "        if msg:",
            "            msg = _(\"'%(host)s' is not a valid nameserver. %(msg)s\") % {",
            "                'host': host, 'msg': msg}",
            "            LOG.debug(msg)",
            "            return msg",
            "        if host in hosts:",
            "            msg = _(\"Duplicate nameserver '%s'\") % host",
            "            LOG.debug(msg)",
            "            return msg",
            "        hosts.append(host)",
            "",
            "",
            "def _validate_hostroutes(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for hostroute: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['destination', 'nexthop']",
            "    hostroutes = []",
            "    for hostroute in data:",
            "        msg = _verify_dict_keys(expected_keys, hostroute)",
            "        if msg:",
            "            return msg",
            "        msg = _validate_subnet(hostroute['destination'])",
            "        if msg:",
            "            return msg",
            "        msg = _validate_ip_address(hostroute['nexthop'])",
            "        if msg:",
            "            return msg",
            "        if hostroute in hostroutes:",
            "            msg = _(\"Duplicate hostroute '%s'\") % hostroute",
            "            LOG.debug(msg)",
            "            return msg",
            "        hostroutes.append(hostroute)",
            "",
            "",
            "def _validate_ip_address_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return None",
            "    return _validate_ip_address(data, valid_values)",
            "",
            "",
            "def _validate_subnet(data, valid_values=None):",
            "    msg = None",
            "    try:",
            "        net = netaddr.IPNetwork(_validate_no_whitespace(data))",
            "        if '/' not in data:",
            "            msg = _(\"'%(data)s' isn't a recognized IP subnet cidr,\"",
            "                    \" '%(cidr)s' is recommended\") % {\"data\": data,",
            "                                                     \"cidr\": net.cidr}",
            "        else:",
            "            return",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP subnet\") % data",
            "    if msg:",
            "        LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_subnet_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_subnet(item)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_subnet_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_subnet(data, valid_values)",
            "",
            "",
            "def _validate_hostname(data):",
            "    # NOTE: An individual name regex instead of an entire FQDN was used",
            "    # because its easier to make correct. Feel free to replace with a",
            "    # full regex solution. The logic should validate that the hostname",
            "    # matches RFC 1123 (section 2.1) and RFC 952.",
            "    hostname_pattern = \"[a-zA-Z0-9-]{1,63}$\"",
            "    try:",
            "        # Trailing periods are allowed to indicate that a name is fully",
            "        # qualified per RFC 1034 (page 7).",
            "        trimmed = data if data[-1] != '.' else data[:-1]",
            "        if len(trimmed) > 255:",
            "            raise TypeError(",
            "                _(\"'%s' exceeds the 255 character hostname limit\") % trimmed)",
            "        names = trimmed.split('.')",
            "        for name in names:",
            "            if not name:",
            "                raise TypeError(_(\"Encountered an empty component.\"))",
            "            if name[-1] == '-' or name[0] == '-':",
            "                raise TypeError(",
            "                    _(\"Name '%s' must not start or end with a hyphen.\") % name)",
            "            if not re.match(hostname_pattern, name):",
            "                raise TypeError(",
            "                    _(\"Name '%s' must be 1-63 characters long, each of \"",
            "                      \"which can only be alphanumeric or a hyphen.\") % name)",
            "        # RFC 1123 hints that a TLD can't be all numeric. last is a TLD if",
            "        # it's an FQDN.",
            "        if len(names) > 1 and re.match(\"^[0-9]+$\", names[-1]):",
            "            raise TypeError(_(\"TLD '%s' must not be all numeric\") % names[-1])",
            "    except TypeError as e:",
            "        msg = _(\"'%(data)s' is not a valid hostname. Reason: %(reason)s\") % {",
            "            'data': data, 'reason': e.message}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_regex(data, valid_values=None):",
            "    try:",
            "        if re.match(valid_values, data):",
            "            return",
            "    except TypeError:",
            "        pass",
            "",
            "    msg = _(\"'%s' is not a valid input\") % data",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_regex_or_none(data, valid_values=None):",
            "    if data is None:",
            "        return",
            "    return _validate_regex(data, valid_values)",
            "",
            "",
            "def _validate_uuid(data, valid_values=None):",
            "    if not uuidutils.is_uuid_like(data):",
            "        msg = _(\"'%s' is not a valid UUID\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_uuid_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_uuid(data)",
            "",
            "",
            "def _validate_uuid_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_uuid(item)",
            "        if msg:",
            "            return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_dict_item(key, key_validator, data):",
            "    # Find conversion function, if any, and apply it",
            "    conv_func = key_validator.get('convert_to')",
            "    if conv_func:",
            "        data[key] = conv_func(data.get(key))",
            "    # Find validator function",
            "    # TODO(salv-orlando): Structure of dict attributes should be improved",
            "    # to avoid iterating over items",
            "    val_func = val_params = None",
            "    for (k, v) in key_validator.iteritems():",
            "        if k.startswith('type:'):",
            "            # ask forgiveness, not permission",
            "            try:",
            "                val_func = validators[k]",
            "            except KeyError:",
            "                msg = _(\"Validator '%s' does not exist.\") % k",
            "                LOG.debug(msg)",
            "                return msg",
            "            val_params = v",
            "            break",
            "    # Process validation",
            "    if val_func:",
            "        return val_func(data.get(key), val_params)",
            "",
            "",
            "def _validate_dict(data, key_specs=None):",
            "    if not isinstance(data, dict):",
            "        msg = _(\"'%s' is not a dictionary\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    # Do not perform any further validation, if no constraints are supplied",
            "    if not key_specs:",
            "        return",
            "",
            "    # Check whether all required keys are present",
            "    required_keys = [key for key, spec in key_specs.iteritems()",
            "                     if spec.get('required')]",
            "",
            "    if required_keys:",
            "        msg = _verify_dict_keys(required_keys, data, False)",
            "        if msg:",
            "            return msg",
            "",
            "    # Perform validation and conversion of all values",
            "    # according to the specifications.",
            "    for key, key_validator in [(k, v) for k, v in key_specs.iteritems()",
            "                               if k in data]:",
            "        msg = _validate_dict_item(key, key_validator, data)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_dict_or_none(data, key_specs=None):",
            "    if data is not None:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_empty(data, key_specs=None):",
            "    if data != {}:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_nodata(data, key_specs=None):",
            "    if data:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_non_negative(data, valid_values=None):",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if data < 0:",
            "        msg = _(\"'%s' should be non-negative\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def convert_to_boolean(data):",
            "    if isinstance(data, basestring):",
            "        val = data.lower()",
            "        if val == \"true\" or val == \"1\":",
            "            return True",
            "        if val == \"false\" or val == \"0\":",
            "            return False",
            "    elif isinstance(data, bool):",
            "        return data",
            "    elif isinstance(data, int):",
            "        if data == 0:",
            "            return False",
            "        elif data == 1:",
            "            return True",
            "    msg = _(\"'%s' cannot be converted to boolean\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_boolean_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_boolean(data)",
            "",
            "",
            "def convert_to_int(data):",
            "    try:",
            "        return int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not a integer\") % data",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_int_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_int(data)",
            "    return data",
            "",
            "",
            "def convert_to_positive_float_or_none(val):",
            "    # NOTE(salv-orlando): This conversion function is currently used by",
            "    # a vendor specific extension only at the moment  It is used for",
            "    # port's RXTX factor in neutron.plugins.vmware.extensions.qos.",
            "    # It is deemed however generic enough to be in this module as it",
            "    # might be used in future for other API attributes.",
            "    if val is None:",
            "        return",
            "    try:",
            "        val = float(val)",
            "        if val < 0:",
            "            raise ValueError()",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' must be a non negative decimal.\") % val",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return val",
            "",
            "",
            "def convert_kvp_str_to_list(data):",
            "    \"\"\"Convert a value of the form 'key=value' to ['key', 'value'].",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key).",
            "    \"\"\"",
            "    kvp = [x.strip() for x in data.split('=', 1)]",
            "    if len(kvp) == 2 and kvp[0]:",
            "        return kvp",
            "    msg = _(\"'%s' is not of the form <key>=[value]\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_kvp_list_to_dict(kvp_list):",
            "    \"\"\"Convert a list of 'key=value' strings to a dict.",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key) or if any",
            "                                of the keys appear more than once.",
            "    \"\"\"",
            "    if kvp_list == ['True']:",
            "        # No values were provided (i.e. '--flag-name')",
            "        return {}",
            "    kvp_map = {}",
            "    for kvp_str in kvp_list:",
            "        key, value = convert_kvp_str_to_list(kvp_str)",
            "        kvp_map.setdefault(key, set())",
            "        kvp_map[key].add(value)",
            "    return dict((x, list(y)) for x, y in kvp_map.iteritems())",
            "",
            "",
            "def convert_none_to_empty_list(value):",
            "    return [] if value is None else value",
            "",
            "",
            "def convert_none_to_empty_dict(value):",
            "    return {} if value is None else value",
            "",
            "",
            "def convert_to_list(data):",
            "    if data is None:",
            "        return []",
            "    elif hasattr(data, '__iter__'):",
            "        return list(data)",
            "    else:",
            "        return [data]",
            "",
            "",
            "HEX_ELEM = '[0-9A-Fa-f]'",
            "UUID_PATTERN = '-'.join([HEX_ELEM + '{8}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{4}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{12}'])",
            "# Note: In order to ensure that the MAC address is unicast the first byte",
            "# must be even.",
            "MAC_PATTERN = \"^%s[aceACE02468](:%s{2}){5}$\" % (HEX_ELEM, HEX_ELEM)",
            "",
            "# Dictionary that maintains a list of validation functions",
            "validators = {'type:dict': _validate_dict,",
            "              'type:dict_or_none': _validate_dict_or_none,",
            "              'type:dict_or_empty': _validate_dict_or_empty,",
            "              'type:dict_or_nodata': _validate_dict_or_nodata,",
            "              'type:fixed_ips': _validate_fixed_ips,",
            "              'type:hostroutes': _validate_hostroutes,",
            "              'type:ip_address': _validate_ip_address,",
            "              'type:ip_address_or_none': _validate_ip_address_or_none,",
            "              'type:ip_pools': _validate_ip_pools,",
            "              'type:mac_address': _validate_mac_address,",
            "              'type:mac_address_or_none': _validate_mac_address_or_none,",
            "              'type:nameservers': _validate_nameservers,",
            "              'type:non_negative': _validate_non_negative,",
            "              'type:range': _validate_range,",
            "              'type:regex': _validate_regex,",
            "              'type:regex_or_none': _validate_regex_or_none,",
            "              'type:string': _validate_string,",
            "              'type:string_or_none': _validate_string_or_none,",
            "              'type:not_empty_string': _validate_not_empty_string,",
            "              'type:not_empty_string_or_none':",
            "              _validate_not_empty_string_or_none,",
            "              'type:subnet': _validate_subnet,",
            "              'type:subnet_list': _validate_subnet_list,",
            "              'type:subnet_or_none': _validate_subnet_or_none,",
            "              'type:uuid': _validate_uuid,",
            "              'type:uuid_or_none': _validate_uuid_or_none,",
            "              'type:uuid_list': _validate_uuid_list,",
            "              'type:values': _validate_values,",
            "              'type:boolean': _validate_boolean}",
            "",
            "# Define constants for base resource name",
            "NETWORK = 'network'",
            "NETWORKS = '%ss' % NETWORK",
            "PORT = 'port'",
            "PORTS = '%ss' % PORT",
            "SUBNET = 'subnet'",
            "SUBNETS = '%ss' % SUBNET",
            "SUBNETPOOL = 'subnetpool'",
            "SUBNETPOOLS = '%ss' % SUBNETPOOL",
            "# Note: a default of ATTR_NOT_SPECIFIED indicates that an",
            "# attribute is not required, but will be generated by the plugin",
            "# if it is not specified.  Particularly, a value of ATTR_NOT_SPECIFIED",
            "# is different from an attribute that has been specified with a value of",
            "# None.  For example, if 'gateway_ip' is omitted in a request to",
            "# create a subnet, the plugin will receive ATTR_NOT_SPECIFIED",
            "# and the default gateway_ip will be generated.",
            "# However, if gateway_ip is specified as None, this means that",
            "# the subnet does not have a gateway IP.",
            "# The following is a short reference for understanding attribute info:",
            "# default: default value of the attribute (if missing, the attribute",
            "# becomes mandatory.",
            "# allow_post: the attribute can be used on POST requests.",
            "# allow_put: the attribute can be used on PUT requests.",
            "# validate: specifies rules for validating data in the attribute.",
            "# convert_to: transformation to apply to the value before it is returned",
            "# is_visible: the attribute is returned in GET responses.",
            "# required_by_policy: the attribute is required by the policy engine and",
            "# should therefore be filled by the API layer even if not present in",
            "# request body.",
            "# enforce_policy: the attribute is actively part of the policy enforcing",
            "# mechanism, ie: there might be rules which refer to this attribute.",
            "",
            "RESOURCE_ATTRIBUTE_MAP = {",
            "    NETWORKS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True,",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'default': '', 'is_visible': True},",
            "        'subnets': {'allow_post': False, 'allow_put': False,",
            "                    'default': [],",
            "                    'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    PORTS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'mac_address': {'allow_post': True, 'allow_put': True,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:mac_address': None},",
            "                        'enforce_policy': True,",
            "                        'is_visible': True},",
            "        'fixed_ips': {'allow_post': True, 'allow_put': True,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'convert_list_to': convert_kvp_list_to_dict,",
            "                      'validate': {'type:fixed_ips': None},",
            "                      'enforce_policy': True,",
            "                      'is_visible': True},",
            "        'device_id': {'allow_post': True, 'allow_put': True,",
            "                      'validate': {'type:string': DEVICE_ID_MAX_LEN},",
            "                      'default': '',",
            "                      'is_visible': True},",
            "        'device_owner': {'allow_post': True, 'allow_put': True,",
            "                         'validate': {'type:string': DEVICE_OWNER_MAX_LEN},",
            "                         'default': '', 'enforce_policy': True,",
            "                         'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "    },",
            "    SUBNETS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'ip_version': {'allow_post': True, 'allow_put': False,",
            "                       'convert_to': convert_to_int,",
            "                       'validate': {'type:values': [4, 6]},",
            "                       'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'subnetpool_id': {'allow_post': True,",
            "                          'allow_put': False,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'required_by_policy': False,",
            "                          'validate': {'type:uuid_or_none': None},",
            "                          'is_visible': True},",
            "        'prefixlen': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:non_negative': None},",
            "                      'convert_to': convert_to_int,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'required_by_policy': False,",
            "                      'is_visible': False},",
            "        'cidr': {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': ATTR_NOT_SPECIFIED,",
            "                 'validate': {'type:subnet_or_none': None},",
            "                 'required_by_policy': False,",
            "                 'is_visible': True},",
            "        'gateway_ip': {'allow_post': True, 'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:ip_address_or_none': None},",
            "                       'is_visible': True},",
            "        'allocation_pools': {'allow_post': True, 'allow_put': True,",
            "                             'default': ATTR_NOT_SPECIFIED,",
            "                             'validate': {'type:ip_pools': None},",
            "                             'is_visible': True},",
            "        'dns_nameservers': {'allow_post': True, 'allow_put': True,",
            "                            'convert_to': convert_none_to_empty_list,",
            "                            'default': ATTR_NOT_SPECIFIED,",
            "                            'validate': {'type:nameservers': None},",
            "                            'is_visible': True},",
            "        'host_routes': {'allow_post': True, 'allow_put': True,",
            "                        'convert_to': convert_none_to_empty_list,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:hostroutes': None},",
            "                        'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'enable_dhcp': {'allow_post': True, 'allow_put': True,",
            "                        'default': True,",
            "                        'convert_to': convert_to_boolean,",
            "                        'is_visible': True},",
            "        'ipv6_ra_mode': {'allow_post': True, 'allow_put': False,",
            "                         'default': ATTR_NOT_SPECIFIED,",
            "                         'validate': {'type:values': constants.IPV6_MODES},",
            "                         'is_visible': True},",
            "        'ipv6_address_mode': {'allow_post': True, 'allow_put': False,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'validate': {'type:values':",
            "                                           constants.IPV6_MODES},",
            "                              'is_visible': True},",
            "        SHARED: {'allow_post': False,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': False,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    SUBNETPOOLS: {",
            "        'id': {'allow_post': False,",
            "               'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'validate': {'type:not_empty_string': None},",
            "                 'is_visible': True},",
            "        'tenant_id': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:string': None},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'prefixes': {'allow_post': True,",
            "                     'allow_put': True,",
            "                     'validate': {'type:subnet_list': None},",
            "                     'is_visible': True},",
            "        'default_quota': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'is_visible': True},",
            "        'ip_version': {'allow_post': False,",
            "                       'allow_put': False,",
            "                       'is_visible': True},",
            "        'default_prefixlen': {'allow_post': True,",
            "                           'allow_put': True,",
            "                           'validate': {'type:non_negative': None},",
            "                           'convert_to': convert_to_int,",
            "                           'default': ATTR_NOT_SPECIFIED,",
            "                           'is_visible': True},",
            "        'min_prefixlen': {'allow_post': True,",
            "                       'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:non_negative': None},",
            "                       'convert_to': convert_to_int,",
            "                       'is_visible': True},",
            "        'max_prefixlen': {'allow_post': True,",
            "                       'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:non_negative': None},",
            "                       'convert_to': convert_to_int,",
            "                       'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    }",
            "}",
            "",
            "# Identify the attribute used by a resource to reference another resource",
            "",
            "RESOURCE_FOREIGN_KEYS = {",
            "    NETWORKS: 'network_id'",
            "}",
            "",
            "PLURALS = {NETWORKS: NETWORK,",
            "           PORTS: PORT,",
            "           SUBNETS: SUBNET,",
            "           SUBNETPOOLS: SUBNETPOOL,",
            "           'dns_nameservers': 'dns_nameserver',",
            "           'host_routes': 'host_route',",
            "           'allocation_pools': 'allocation_pool',",
            "           'fixed_ips': 'fixed_ip',",
            "           'extensions': 'extension'}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "769": []
        },
        "addLocation": []
    },
    "neutron/policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 335,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "         self.field = field"
            },
            "2": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 337,
                "PatchRowcode": "         self.value = conv_func(value)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+        self.regex = re.compile(value[1:]) if value.startswith('~') else None"
            },
            "4": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 339,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "     def __call__(self, target_dict, cred_dict, enforcer):"
            },
            "6": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": 341,
                "PatchRowcode": "         target_value = target_dict.get(self.field)"
            },
            "7": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 345,
                "PatchRowcode": "                       \"%(target_dict)s\","
            },
            "8": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": 346,
                "PatchRowcode": "                       {'field': self.field, 'target_dict': target_dict})"
            },
            "9": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 347,
                "PatchRowcode": "             return False"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+        if self.regex:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+            return bool(self.regex.match(target_value))"
            },
            "12": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "         return target_value == self.value"
            },
            "13": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 351,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 352,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"",
            "Policy engine for neutron.  Largely copied from nova.",
            "\"\"\"",
            "",
            "import collections",
            "import itertools",
            "import logging as std_logging",
            "import re",
            "",
            "from oslo_log import log as logging",
            "from oslo_utils import excutils",
            "from oslo_utils import importutils",
            "",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron.i18n import _LE, _LI, _LW",
            "from neutron.openstack.common import policy",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "_ENFORCER = None",
            "ADMIN_CTX_POLICY = 'context_is_admin'",
            "ADVSVC_CTX_POLICY = 'context_is_advsvc'",
            "# Maps deprecated 'extension' policies to new-style policies",
            "DEPRECATED_POLICY_MAP = {",
            "    'extension:provider_network':",
            "    ['network:provider:network_type',",
            "     'network:provider:physical_network',",
            "     'network:provider:segmentation_id'],",
            "    'extension:router':",
            "    ['network:router:external'],",
            "    'extension:port_binding':",
            "    ['port:binding:vif_type', 'port:binding:vif_details',",
            "     'port:binding:profile', 'port:binding:host_id']",
            "}",
            "DEPRECATED_ACTION_MAP = {",
            "    'view': ['get'],",
            "    'set': ['create', 'update']",
            "}",
            "",
            "",
            "def reset():",
            "    global _ENFORCER",
            "    if _ENFORCER:",
            "        _ENFORCER.clear()",
            "        _ENFORCER = None",
            "",
            "",
            "def init():",
            "    \"\"\"Init an instance of the Enforcer class.\"\"\"",
            "",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        _ENFORCER = policy.Enforcer()",
            "        _ENFORCER.load_rules(True)",
            "",
            "",
            "def refresh():",
            "    \"\"\"Reset policy and init a new instance of Enforcer.\"\"\"",
            "    reset()",
            "    init()",
            "",
            "",
            "def get_resource_and_action(action, pluralized=None):",
            "    \"\"\"Extract resource and action (write, read) from api operation.\"\"\"",
            "    data = action.split(':', 1)[0].split('_', 1)",
            "    resource = pluralized or (\"%ss\" % data[-1])",
            "    return (resource, data[0] != 'get')",
            "",
            "",
            "def set_rules(policies, overwrite=True):",
            "    \"\"\"Set rules based on the provided dict of rules.",
            "",
            "    :param policies: New policies to use. It should be an instance of dict.",
            "    :param overwrite: Whether to overwrite current rules or update them",
            "                          with the new rules.",
            "    \"\"\"",
            "",
            "    LOG.debug(\"Loading policies from file: %s\", _ENFORCER.policy_path)",
            "    # Ensure backward compatibility with folsom/grizzly convention",
            "    # for extension rules",
            "    for pol in policies.keys():",
            "        if any([pol.startswith(depr_pol) for depr_pol in",
            "                DEPRECATED_POLICY_MAP.keys()]):",
            "            LOG.warn(_LW(\"Found deprecated policy rule:%s. Please consider \"",
            "                         \"upgrading your policy configuration file\"), pol)",
            "            pol_name, action = pol.rsplit(':', 1)",
            "            try:",
            "                new_actions = DEPRECATED_ACTION_MAP[action]",
            "                new_policies = DEPRECATED_POLICY_MAP[pol_name]",
            "                # bind new actions and policies together",
            "                for actual_policy in ['_'.join(item) for item in",
            "                                      itertools.product(new_actions,",
            "                                                        new_policies)]:",
            "                    if actual_policy not in policies:",
            "                        # New policy, same rule",
            "                        LOG.info(_LI(\"Inserting policy:%(new_policy)s in \"",
            "                                     \"place of deprecated \"",
            "                                     \"policy:%(old_policy)s\"),",
            "                                 {'new_policy': actual_policy,",
            "                                  'old_policy': pol})",
            "                        policies[actual_policy] = policies[pol]",
            "                # Remove old-style policy",
            "                del policies[pol]",
            "            except KeyError:",
            "                LOG.error(_LE(\"Backward compatibility unavailable for \"",
            "                              \"deprecated policy %s. The policy will \"",
            "                              \"not be enforced\"), pol)",
            "    init()",
            "    _ENFORCER.set_rules(policies, overwrite)",
            "",
            "",
            "def _is_attribute_explicitly_set(attribute_name, resource, target, action):",
            "    \"\"\"Verify that an attribute is present and is explicitly set.\"\"\"",
            "    if 'update' in action:",
            "        # In the case of update, the function should not pay attention to a",
            "        # default value of an attribute, but check whether it was explicitly",
            "        # marked as being updated instead.",
            "        return (attribute_name in target[const.ATTRIBUTES_TO_UPDATE] and",
            "                target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED)",
            "    return ('default' in resource[attribute_name] and",
            "            attribute_name in target and",
            "            target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED and",
            "            target[attribute_name] != resource[attribute_name]['default'])",
            "",
            "",
            "def _should_validate_sub_attributes(attribute, sub_attr):",
            "    \"\"\"Verify that sub-attributes are iterable and should be validated.\"\"\"",
            "    validate = attribute.get('validate')",
            "    return (validate and isinstance(sub_attr, collections.Iterable) and",
            "            any([k.startswith('type:dict') and",
            "                 v for (k, v) in validate.iteritems()]))",
            "",
            "",
            "def _build_subattr_match_rule(attr_name, attr, action, target):",
            "    \"\"\"Create the rule to match for sub-attribute policy checks.\"\"\"",
            "    # TODO(salv-orlando): Instead of relying on validator info, introduce",
            "    # typing for API attributes",
            "    # Expect a dict as type descriptor",
            "    validate = attr['validate']",
            "    key = filter(lambda k: k.startswith('type:dict'), validate.keys())",
            "    if not key:",
            "        LOG.warn(_LW(\"Unable to find data type descriptor for attribute %s\"),",
            "                 attr_name)",
            "        return",
            "    data = validate[key[0]]",
            "    if not isinstance(data, dict):",
            "        LOG.debug(\"Attribute type descriptor is not a dict. Unable to \"",
            "                  \"generate any sub-attr policy rule for %s.\",",
            "                  attr_name)",
            "        return",
            "    sub_attr_rules = [policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                       (action, attr_name,",
            "                                        sub_attr_name)) for",
            "                      sub_attr_name in data if sub_attr_name in",
            "                      target[attr_name]]",
            "    return policy.AndCheck(sub_attr_rules)",
            "",
            "",
            "def _process_rules_list(rules, match_rule):",
            "    \"\"\"Recursively walk a policy rule to extract a list of match entries.\"\"\"",
            "    if isinstance(match_rule, policy.RuleCheck):",
            "        rules.append(match_rule.match)",
            "    elif isinstance(match_rule, policy.AndCheck):",
            "        for rule in match_rule.rules:",
            "            _process_rules_list(rules, rule)",
            "    return rules",
            "",
            "",
            "def _build_match_rule(action, target, pluralized):",
            "    \"\"\"Create the rule to match for a given action.",
            "",
            "    The policy rule to be matched is built in the following way:",
            "    1) add entries for matching permission on objects",
            "    2) add an entry for the specific action (e.g.: create_network)",
            "    3) add an entry for attributes of a resource for which the action",
            "       is being executed (e.g.: create_network:shared)",
            "    4) add an entry for sub-attributes of a resource for which the",
            "       action is being executed",
            "       (e.g.: create_router:external_gateway_info:network_id)",
            "    \"\"\"",
            "    match_rule = policy.RuleCheck('rule', action)",
            "    resource, is_write = get_resource_and_action(action, pluralized)",
            "    # Attribute-based checks shall not be enforced on GETs",
            "    if is_write:",
            "        # assigning to variable with short name for improving readability",
            "        res_map = attributes.RESOURCE_ATTRIBUTE_MAP",
            "        if resource in res_map:",
            "            for attribute_name in res_map[resource]:",
            "                if _is_attribute_explicitly_set(attribute_name,",
            "                                                res_map[resource],",
            "                                                target, action):",
            "                    attribute = res_map[resource][attribute_name]",
            "                    if 'enforce_policy' in attribute:",
            "                        attr_rule = policy.RuleCheck('rule', '%s:%s' %",
            "                                                     (action, attribute_name))",
            "                        # Build match entries for sub-attributes",
            "                        if _should_validate_sub_attributes(",
            "                                attribute, target[attribute_name]):",
            "                            attr_rule = policy.AndCheck(",
            "                                [attr_rule, _build_subattr_match_rule(",
            "                                    attribute_name, attribute,",
            "                                    action, target)])",
            "                        match_rule = policy.AndCheck([match_rule, attr_rule])",
            "    return match_rule",
            "",
            "",
            "# This check is registered as 'tenant_id' so that it can override",
            "# GenericCheck which was used for validating parent resource ownership.",
            "# This will prevent us from having to handling backward compatibility",
            "# for policy.json",
            "# TODO(salv-orlando): Reinstate GenericCheck for simple tenant_id checks",
            "@policy.register('tenant_id')",
            "class OwnerCheck(policy.Check):",
            "    \"\"\"Resource ownership check.",
            "",
            "    This check verifies the owner of the current resource, or of another",
            "    resource referenced by the one under analysis.",
            "    In the former case it falls back to a regular GenericCheck, whereas",
            "    in the latter case it leverages the plugin to load the referenced",
            "    resource and perform the check.",
            "    \"\"\"",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        try:",
            "            self.target_field = re.findall(r'^\\%\\((.*)\\)s$',",
            "                                           match)[0]",
            "        except IndexError:",
            "            err_reason = (_(\"Unable to identify a target field from:%s. \"",
            "                            \"Match should be in the form %%(<field_name>)s\") %",
            "                          match)",
            "            LOG.exception(err_reason)",
            "            raise exceptions.PolicyInitError(",
            "                policy=\"%s:%s\" % (kind, match),",
            "                reason=err_reason)",
            "        super(OwnerCheck, self).__init__(kind, match)",
            "",
            "    def __call__(self, target, creds, enforcer):",
            "        if self.target_field not in target:",
            "            # policy needs a plugin check",
            "            # target field is in the form resource:field",
            "            # however if they're not separated by a colon, use an underscore",
            "            # as a separator for backward compatibility",
            "",
            "            def do_split(separator):",
            "                parent_res, parent_field = self.target_field.split(",
            "                    separator, 1)",
            "                return parent_res, parent_field",
            "",
            "            for separator in (':', '_'):",
            "                try:",
            "                    parent_res, parent_field = do_split(separator)",
            "                    break",
            "                except ValueError:",
            "                    LOG.debug(\"Unable to find ':' as separator in %s.\",",
            "                              self.target_field)",
            "            else:",
            "                # If we are here split failed with both separators",
            "                err_reason = (_(\"Unable to find resource name in %s\") %",
            "                              self.target_field)",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            parent_foreign_key = attributes.RESOURCE_FOREIGN_KEYS.get(",
            "                \"%ss\" % parent_res, None)",
            "            if not parent_foreign_key:",
            "                err_reason = (_(\"Unable to verify match:%(match)s as the \"",
            "                                \"parent resource: %(res)s was not found\") %",
            "                              {'match': self.match, 'res': parent_res})",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            # NOTE(salv-orlando): This check currently assumes the parent",
            "            # resource is handled by the core plugin. It might be worth",
            "            # having a way to map resources to plugins so to make this",
            "            # check more general",
            "            # NOTE(ihrachys): if import is put in global, circular",
            "            # import failure occurs",
            "            manager = importutils.import_module('neutron.manager')",
            "            f = getattr(manager.NeutronManager.get_instance().plugin,",
            "                        'get_%s' % parent_res)",
            "            # f *must* exist, if not found it is better to let neutron",
            "            # explode. Check will be performed with admin context",
            "            context = importutils.import_module('neutron.context')",
            "            try:",
            "                data = f(context.get_admin_context(),",
            "                         target[parent_foreign_key],",
            "                         fields=[parent_field])",
            "                target[self.target_field] = data[parent_field]",
            "            except Exception:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.exception(_LE('Policy check error while calling %s!'),",
            "                                  f)",
            "        match = self.match % target",
            "        if self.kind in creds:",
            "            return match == unicode(creds[self.kind])",
            "        return False",
            "",
            "",
            "@policy.register('field')",
            "class FieldCheck(policy.Check):",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        resource, field_value = match.split(':', 1)",
            "        field, value = field_value.split('=', 1)",
            "",
            "        super(FieldCheck, self).__init__(kind, '%s:%s:%s' %",
            "                                         (resource, field, value))",
            "",
            "        # Value might need conversion - we need help from the attribute map",
            "        try:",
            "            attr = attributes.RESOURCE_ATTRIBUTE_MAP[resource][field]",
            "            conv_func = attr['convert_to']",
            "        except KeyError:",
            "            conv_func = lambda x: x",
            "",
            "        self.field = field",
            "        self.value = conv_func(value)",
            "",
            "    def __call__(self, target_dict, cred_dict, enforcer):",
            "        target_value = target_dict.get(self.field)",
            "        # target_value might be a boolean, explicitly compare with None",
            "        if target_value is None:",
            "            LOG.debug(\"Unable to find requested field: %(field)s in target: \"",
            "                      \"%(target_dict)s\",",
            "                      {'field': self.field, 'target_dict': target_dict})",
            "            return False",
            "        return target_value == self.value",
            "",
            "",
            "def _prepare_check(context, action, target, pluralized):",
            "    \"\"\"Prepare rule, target, and credentials for the policy engine.\"\"\"",
            "    # Compare with None to distinguish case in which target is {}",
            "    if target is None:",
            "        target = {}",
            "    match_rule = _build_match_rule(action, target, pluralized)",
            "    credentials = context.to_dict()",
            "    return match_rule, target, credentials",
            "",
            "",
            "def log_rule_list(match_rule):",
            "    if LOG.isEnabledFor(std_logging.DEBUG):",
            "        rules = _process_rules_list([], match_rule)",
            "        LOG.debug(\"Enforcing rules: %s\", rules)",
            "",
            "",
            "def check(context, action, target, plugin=None, might_not_exist=False,",
            "          pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param might_not_exist: If True the policy check is skipped (and the",
            "        function returns True) if the specified policy does not exist.",
            "        Defaults to false.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :return: Returns True if access is permitted else False.",
            "    \"\"\"",
            "    if might_not_exist and not (_ENFORCER.rules and action in _ENFORCER.rules):",
            "        return True",
            "    match_rule, target, credentials = _prepare_check(context,",
            "                                                     action,",
            "                                                     target,",
            "                                                     pluralized)",
            "    result = _ENFORCER.enforce(match_rule,",
            "                               target,",
            "                               credentials,",
            "                               pluralized=pluralized)",
            "    # logging applied rules in case of failure",
            "    if not result:",
            "        log_rule_list(match_rule)",
            "    return result",
            "",
            "",
            "def enforce(context, action, target, plugin=None, pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :raises neutron.openstack.common.policy.PolicyNotAuthorized:",
            "            if verification fails.",
            "    \"\"\"",
            "    rule, target, credentials = _prepare_check(context,",
            "                                               action,",
            "                                               target,",
            "                                               pluralized)",
            "    try:",
            "        result = _ENFORCER.enforce(rule, target, credentials, action=action,",
            "                                   do_raise=True)",
            "    except policy.PolicyNotAuthorized:",
            "        with excutils.save_and_reraise_exception():",
            "            log_rule_list(rule)",
            "            LOG.debug(\"Failed policy check for '%s'\", action)",
            "    return result",
            "",
            "",
            "def check_is_admin(context):",
            "    \"\"\"Verify context has admin rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    target = credentials",
            "    # Backward compatibility: if ADMIN_CTX_POLICY is not",
            "    # found, default to validating role:admin",
            "    admin_policy = (ADMIN_CTX_POLICY if ADMIN_CTX_POLICY in _ENFORCER.rules",
            "                    else 'role:admin')",
            "    return _ENFORCER.enforce(admin_policy, target, credentials)",
            "",
            "",
            "def check_is_advsvc(context):",
            "    \"\"\"Verify context has advsvc rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    target = credentials",
            "    # Backward compatibility: if ADVSVC_CTX_POLICY is not",
            "    # found, default to validating role:advsvc",
            "    advsvc_policy = (ADVSVC_CTX_POLICY in _ENFORCER.rules",
            "                    and ADVSVC_CTX_POLICY or 'role:advsvc')",
            "    return _ENFORCER.enforce(advsvc_policy, target, credentials)",
            "",
            "",
            "def _extract_roles(rule, roles):",
            "    if isinstance(rule, policy.RoleCheck):",
            "        roles.append(rule.match.lower())",
            "    elif isinstance(rule, policy.RuleCheck):",
            "        _extract_roles(_ENFORCER.rules[rule.match], roles)",
            "    elif hasattr(rule, 'rules'):",
            "        for rule in rule.rules:",
            "            _extract_roles(rule, roles)",
            "",
            "",
            "def get_admin_roles():",
            "    \"\"\"Return a list of roles which are granted admin rights according",
            "    to policy settings.",
            "    \"\"\"",
            "    # NOTE(salvatore-orlando): This function provides a solution for",
            "    # populating implicit contexts with the appropriate roles so that",
            "    # they correctly pass policy checks, and will become superseded",
            "    # once all explicit policy checks are removed from db logic and",
            "    # plugin modules. For backward compatibility it returns the literal",
            "    # admin if ADMIN_CTX_POLICY is not defined",
            "    init()",
            "    if not _ENFORCER.rules or ADMIN_CTX_POLICY not in _ENFORCER.rules:",
            "        return ['admin']",
            "    try:",
            "        admin_ctx_rule = _ENFORCER.rules[ADMIN_CTX_POLICY]",
            "    except (KeyError, TypeError):",
            "        return",
            "    roles = []",
            "    _extract_roles(admin_ctx_rule, roles)",
            "    return roles"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"",
            "Policy engine for neutron.  Largely copied from nova.",
            "\"\"\"",
            "",
            "import collections",
            "import itertools",
            "import logging as std_logging",
            "import re",
            "",
            "from oslo_log import log as logging",
            "from oslo_utils import excutils",
            "from oslo_utils import importutils",
            "",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron.i18n import _LE, _LI, _LW",
            "from neutron.openstack.common import policy",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "_ENFORCER = None",
            "ADMIN_CTX_POLICY = 'context_is_admin'",
            "ADVSVC_CTX_POLICY = 'context_is_advsvc'",
            "# Maps deprecated 'extension' policies to new-style policies",
            "DEPRECATED_POLICY_MAP = {",
            "    'extension:provider_network':",
            "    ['network:provider:network_type',",
            "     'network:provider:physical_network',",
            "     'network:provider:segmentation_id'],",
            "    'extension:router':",
            "    ['network:router:external'],",
            "    'extension:port_binding':",
            "    ['port:binding:vif_type', 'port:binding:vif_details',",
            "     'port:binding:profile', 'port:binding:host_id']",
            "}",
            "DEPRECATED_ACTION_MAP = {",
            "    'view': ['get'],",
            "    'set': ['create', 'update']",
            "}",
            "",
            "",
            "def reset():",
            "    global _ENFORCER",
            "    if _ENFORCER:",
            "        _ENFORCER.clear()",
            "        _ENFORCER = None",
            "",
            "",
            "def init():",
            "    \"\"\"Init an instance of the Enforcer class.\"\"\"",
            "",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        _ENFORCER = policy.Enforcer()",
            "        _ENFORCER.load_rules(True)",
            "",
            "",
            "def refresh():",
            "    \"\"\"Reset policy and init a new instance of Enforcer.\"\"\"",
            "    reset()",
            "    init()",
            "",
            "",
            "def get_resource_and_action(action, pluralized=None):",
            "    \"\"\"Extract resource and action (write, read) from api operation.\"\"\"",
            "    data = action.split(':', 1)[0].split('_', 1)",
            "    resource = pluralized or (\"%ss\" % data[-1])",
            "    return (resource, data[0] != 'get')",
            "",
            "",
            "def set_rules(policies, overwrite=True):",
            "    \"\"\"Set rules based on the provided dict of rules.",
            "",
            "    :param policies: New policies to use. It should be an instance of dict.",
            "    :param overwrite: Whether to overwrite current rules or update them",
            "                          with the new rules.",
            "    \"\"\"",
            "",
            "    LOG.debug(\"Loading policies from file: %s\", _ENFORCER.policy_path)",
            "    # Ensure backward compatibility with folsom/grizzly convention",
            "    # for extension rules",
            "    for pol in policies.keys():",
            "        if any([pol.startswith(depr_pol) for depr_pol in",
            "                DEPRECATED_POLICY_MAP.keys()]):",
            "            LOG.warn(_LW(\"Found deprecated policy rule:%s. Please consider \"",
            "                         \"upgrading your policy configuration file\"), pol)",
            "            pol_name, action = pol.rsplit(':', 1)",
            "            try:",
            "                new_actions = DEPRECATED_ACTION_MAP[action]",
            "                new_policies = DEPRECATED_POLICY_MAP[pol_name]",
            "                # bind new actions and policies together",
            "                for actual_policy in ['_'.join(item) for item in",
            "                                      itertools.product(new_actions,",
            "                                                        new_policies)]:",
            "                    if actual_policy not in policies:",
            "                        # New policy, same rule",
            "                        LOG.info(_LI(\"Inserting policy:%(new_policy)s in \"",
            "                                     \"place of deprecated \"",
            "                                     \"policy:%(old_policy)s\"),",
            "                                 {'new_policy': actual_policy,",
            "                                  'old_policy': pol})",
            "                        policies[actual_policy] = policies[pol]",
            "                # Remove old-style policy",
            "                del policies[pol]",
            "            except KeyError:",
            "                LOG.error(_LE(\"Backward compatibility unavailable for \"",
            "                              \"deprecated policy %s. The policy will \"",
            "                              \"not be enforced\"), pol)",
            "    init()",
            "    _ENFORCER.set_rules(policies, overwrite)",
            "",
            "",
            "def _is_attribute_explicitly_set(attribute_name, resource, target, action):",
            "    \"\"\"Verify that an attribute is present and is explicitly set.\"\"\"",
            "    if 'update' in action:",
            "        # In the case of update, the function should not pay attention to a",
            "        # default value of an attribute, but check whether it was explicitly",
            "        # marked as being updated instead.",
            "        return (attribute_name in target[const.ATTRIBUTES_TO_UPDATE] and",
            "                target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED)",
            "    return ('default' in resource[attribute_name] and",
            "            attribute_name in target and",
            "            target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED and",
            "            target[attribute_name] != resource[attribute_name]['default'])",
            "",
            "",
            "def _should_validate_sub_attributes(attribute, sub_attr):",
            "    \"\"\"Verify that sub-attributes are iterable and should be validated.\"\"\"",
            "    validate = attribute.get('validate')",
            "    return (validate and isinstance(sub_attr, collections.Iterable) and",
            "            any([k.startswith('type:dict') and",
            "                 v for (k, v) in validate.iteritems()]))",
            "",
            "",
            "def _build_subattr_match_rule(attr_name, attr, action, target):",
            "    \"\"\"Create the rule to match for sub-attribute policy checks.\"\"\"",
            "    # TODO(salv-orlando): Instead of relying on validator info, introduce",
            "    # typing for API attributes",
            "    # Expect a dict as type descriptor",
            "    validate = attr['validate']",
            "    key = filter(lambda k: k.startswith('type:dict'), validate.keys())",
            "    if not key:",
            "        LOG.warn(_LW(\"Unable to find data type descriptor for attribute %s\"),",
            "                 attr_name)",
            "        return",
            "    data = validate[key[0]]",
            "    if not isinstance(data, dict):",
            "        LOG.debug(\"Attribute type descriptor is not a dict. Unable to \"",
            "                  \"generate any sub-attr policy rule for %s.\",",
            "                  attr_name)",
            "        return",
            "    sub_attr_rules = [policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                       (action, attr_name,",
            "                                        sub_attr_name)) for",
            "                      sub_attr_name in data if sub_attr_name in",
            "                      target[attr_name]]",
            "    return policy.AndCheck(sub_attr_rules)",
            "",
            "",
            "def _process_rules_list(rules, match_rule):",
            "    \"\"\"Recursively walk a policy rule to extract a list of match entries.\"\"\"",
            "    if isinstance(match_rule, policy.RuleCheck):",
            "        rules.append(match_rule.match)",
            "    elif isinstance(match_rule, policy.AndCheck):",
            "        for rule in match_rule.rules:",
            "            _process_rules_list(rules, rule)",
            "    return rules",
            "",
            "",
            "def _build_match_rule(action, target, pluralized):",
            "    \"\"\"Create the rule to match for a given action.",
            "",
            "    The policy rule to be matched is built in the following way:",
            "    1) add entries for matching permission on objects",
            "    2) add an entry for the specific action (e.g.: create_network)",
            "    3) add an entry for attributes of a resource for which the action",
            "       is being executed (e.g.: create_network:shared)",
            "    4) add an entry for sub-attributes of a resource for which the",
            "       action is being executed",
            "       (e.g.: create_router:external_gateway_info:network_id)",
            "    \"\"\"",
            "    match_rule = policy.RuleCheck('rule', action)",
            "    resource, is_write = get_resource_and_action(action, pluralized)",
            "    # Attribute-based checks shall not be enforced on GETs",
            "    if is_write:",
            "        # assigning to variable with short name for improving readability",
            "        res_map = attributes.RESOURCE_ATTRIBUTE_MAP",
            "        if resource in res_map:",
            "            for attribute_name in res_map[resource]:",
            "                if _is_attribute_explicitly_set(attribute_name,",
            "                                                res_map[resource],",
            "                                                target, action):",
            "                    attribute = res_map[resource][attribute_name]",
            "                    if 'enforce_policy' in attribute:",
            "                        attr_rule = policy.RuleCheck('rule', '%s:%s' %",
            "                                                     (action, attribute_name))",
            "                        # Build match entries for sub-attributes",
            "                        if _should_validate_sub_attributes(",
            "                                attribute, target[attribute_name]):",
            "                            attr_rule = policy.AndCheck(",
            "                                [attr_rule, _build_subattr_match_rule(",
            "                                    attribute_name, attribute,",
            "                                    action, target)])",
            "                        match_rule = policy.AndCheck([match_rule, attr_rule])",
            "    return match_rule",
            "",
            "",
            "# This check is registered as 'tenant_id' so that it can override",
            "# GenericCheck which was used for validating parent resource ownership.",
            "# This will prevent us from having to handling backward compatibility",
            "# for policy.json",
            "# TODO(salv-orlando): Reinstate GenericCheck for simple tenant_id checks",
            "@policy.register('tenant_id')",
            "class OwnerCheck(policy.Check):",
            "    \"\"\"Resource ownership check.",
            "",
            "    This check verifies the owner of the current resource, or of another",
            "    resource referenced by the one under analysis.",
            "    In the former case it falls back to a regular GenericCheck, whereas",
            "    in the latter case it leverages the plugin to load the referenced",
            "    resource and perform the check.",
            "    \"\"\"",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        try:",
            "            self.target_field = re.findall(r'^\\%\\((.*)\\)s$',",
            "                                           match)[0]",
            "        except IndexError:",
            "            err_reason = (_(\"Unable to identify a target field from:%s. \"",
            "                            \"Match should be in the form %%(<field_name>)s\") %",
            "                          match)",
            "            LOG.exception(err_reason)",
            "            raise exceptions.PolicyInitError(",
            "                policy=\"%s:%s\" % (kind, match),",
            "                reason=err_reason)",
            "        super(OwnerCheck, self).__init__(kind, match)",
            "",
            "    def __call__(self, target, creds, enforcer):",
            "        if self.target_field not in target:",
            "            # policy needs a plugin check",
            "            # target field is in the form resource:field",
            "            # however if they're not separated by a colon, use an underscore",
            "            # as a separator for backward compatibility",
            "",
            "            def do_split(separator):",
            "                parent_res, parent_field = self.target_field.split(",
            "                    separator, 1)",
            "                return parent_res, parent_field",
            "",
            "            for separator in (':', '_'):",
            "                try:",
            "                    parent_res, parent_field = do_split(separator)",
            "                    break",
            "                except ValueError:",
            "                    LOG.debug(\"Unable to find ':' as separator in %s.\",",
            "                              self.target_field)",
            "            else:",
            "                # If we are here split failed with both separators",
            "                err_reason = (_(\"Unable to find resource name in %s\") %",
            "                              self.target_field)",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            parent_foreign_key = attributes.RESOURCE_FOREIGN_KEYS.get(",
            "                \"%ss\" % parent_res, None)",
            "            if not parent_foreign_key:",
            "                err_reason = (_(\"Unable to verify match:%(match)s as the \"",
            "                                \"parent resource: %(res)s was not found\") %",
            "                              {'match': self.match, 'res': parent_res})",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            # NOTE(salv-orlando): This check currently assumes the parent",
            "            # resource is handled by the core plugin. It might be worth",
            "            # having a way to map resources to plugins so to make this",
            "            # check more general",
            "            # NOTE(ihrachys): if import is put in global, circular",
            "            # import failure occurs",
            "            manager = importutils.import_module('neutron.manager')",
            "            f = getattr(manager.NeutronManager.get_instance().plugin,",
            "                        'get_%s' % parent_res)",
            "            # f *must* exist, if not found it is better to let neutron",
            "            # explode. Check will be performed with admin context",
            "            context = importutils.import_module('neutron.context')",
            "            try:",
            "                data = f(context.get_admin_context(),",
            "                         target[parent_foreign_key],",
            "                         fields=[parent_field])",
            "                target[self.target_field] = data[parent_field]",
            "            except Exception:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.exception(_LE('Policy check error while calling %s!'),",
            "                                  f)",
            "        match = self.match % target",
            "        if self.kind in creds:",
            "            return match == unicode(creds[self.kind])",
            "        return False",
            "",
            "",
            "@policy.register('field')",
            "class FieldCheck(policy.Check):",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        resource, field_value = match.split(':', 1)",
            "        field, value = field_value.split('=', 1)",
            "",
            "        super(FieldCheck, self).__init__(kind, '%s:%s:%s' %",
            "                                         (resource, field, value))",
            "",
            "        # Value might need conversion - we need help from the attribute map",
            "        try:",
            "            attr = attributes.RESOURCE_ATTRIBUTE_MAP[resource][field]",
            "            conv_func = attr['convert_to']",
            "        except KeyError:",
            "            conv_func = lambda x: x",
            "",
            "        self.field = field",
            "        self.value = conv_func(value)",
            "        self.regex = re.compile(value[1:]) if value.startswith('~') else None",
            "",
            "    def __call__(self, target_dict, cred_dict, enforcer):",
            "        target_value = target_dict.get(self.field)",
            "        # target_value might be a boolean, explicitly compare with None",
            "        if target_value is None:",
            "            LOG.debug(\"Unable to find requested field: %(field)s in target: \"",
            "                      \"%(target_dict)s\",",
            "                      {'field': self.field, 'target_dict': target_dict})",
            "            return False",
            "        if self.regex:",
            "            return bool(self.regex.match(target_value))",
            "        return target_value == self.value",
            "",
            "",
            "def _prepare_check(context, action, target, pluralized):",
            "    \"\"\"Prepare rule, target, and credentials for the policy engine.\"\"\"",
            "    # Compare with None to distinguish case in which target is {}",
            "    if target is None:",
            "        target = {}",
            "    match_rule = _build_match_rule(action, target, pluralized)",
            "    credentials = context.to_dict()",
            "    return match_rule, target, credentials",
            "",
            "",
            "def log_rule_list(match_rule):",
            "    if LOG.isEnabledFor(std_logging.DEBUG):",
            "        rules = _process_rules_list([], match_rule)",
            "        LOG.debug(\"Enforcing rules: %s\", rules)",
            "",
            "",
            "def check(context, action, target, plugin=None, might_not_exist=False,",
            "          pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param might_not_exist: If True the policy check is skipped (and the",
            "        function returns True) if the specified policy does not exist.",
            "        Defaults to false.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :return: Returns True if access is permitted else False.",
            "    \"\"\"",
            "    if might_not_exist and not (_ENFORCER.rules and action in _ENFORCER.rules):",
            "        return True",
            "    match_rule, target, credentials = _prepare_check(context,",
            "                                                     action,",
            "                                                     target,",
            "                                                     pluralized)",
            "    result = _ENFORCER.enforce(match_rule,",
            "                               target,",
            "                               credentials,",
            "                               pluralized=pluralized)",
            "    # logging applied rules in case of failure",
            "    if not result:",
            "        log_rule_list(match_rule)",
            "    return result",
            "",
            "",
            "def enforce(context, action, target, plugin=None, pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :raises neutron.openstack.common.policy.PolicyNotAuthorized:",
            "            if verification fails.",
            "    \"\"\"",
            "    rule, target, credentials = _prepare_check(context,",
            "                                               action,",
            "                                               target,",
            "                                               pluralized)",
            "    try:",
            "        result = _ENFORCER.enforce(rule, target, credentials, action=action,",
            "                                   do_raise=True)",
            "    except policy.PolicyNotAuthorized:",
            "        with excutils.save_and_reraise_exception():",
            "            log_rule_list(rule)",
            "            LOG.debug(\"Failed policy check for '%s'\", action)",
            "    return result",
            "",
            "",
            "def check_is_admin(context):",
            "    \"\"\"Verify context has admin rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    target = credentials",
            "    # Backward compatibility: if ADMIN_CTX_POLICY is not",
            "    # found, default to validating role:admin",
            "    admin_policy = (ADMIN_CTX_POLICY if ADMIN_CTX_POLICY in _ENFORCER.rules",
            "                    else 'role:admin')",
            "    return _ENFORCER.enforce(admin_policy, target, credentials)",
            "",
            "",
            "def check_is_advsvc(context):",
            "    \"\"\"Verify context has advsvc rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    target = credentials",
            "    # Backward compatibility: if ADVSVC_CTX_POLICY is not",
            "    # found, default to validating role:advsvc",
            "    advsvc_policy = (ADVSVC_CTX_POLICY in _ENFORCER.rules",
            "                    and ADVSVC_CTX_POLICY or 'role:advsvc')",
            "    return _ENFORCER.enforce(advsvc_policy, target, credentials)",
            "",
            "",
            "def _extract_roles(rule, roles):",
            "    if isinstance(rule, policy.RoleCheck):",
            "        roles.append(rule.match.lower())",
            "    elif isinstance(rule, policy.RuleCheck):",
            "        _extract_roles(_ENFORCER.rules[rule.match], roles)",
            "    elif hasattr(rule, 'rules'):",
            "        for rule in rule.rules:",
            "            _extract_roles(rule, roles)",
            "",
            "",
            "def get_admin_roles():",
            "    \"\"\"Return a list of roles which are granted admin rights according",
            "    to policy settings.",
            "    \"\"\"",
            "    # NOTE(salvatore-orlando): This function provides a solution for",
            "    # populating implicit contexts with the appropriate roles so that",
            "    # they correctly pass policy checks, and will become superseded",
            "    # once all explicit policy checks are removed from db logic and",
            "    # plugin modules. For backward compatibility it returns the literal",
            "    # admin if ADMIN_CTX_POLICY is not defined",
            "    init()",
            "    if not _ENFORCER.rules or ADMIN_CTX_POLICY not in _ENFORCER.rules:",
            "        return ['admin']",
            "    try:",
            "        admin_ctx_rule = _ENFORCER.rules[ADMIN_CTX_POLICY]",
            "    except (KeyError, TypeError):",
            "        return",
            "    roles = []",
            "    _extract_roles(admin_ctx_rule, roles)",
            "    return roles"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "neutron.policy.FieldCheck",
            "neutron.policy.FieldCheck.__init__.conv_func"
        ]
    },
    "neutron/tests/unit/test_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "             \"regular_user\": \"role:user\","
            },
            "1": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 233,
                "PatchRowcode": "             \"shared\": \"field:networks:shared=True\","
            },
            "2": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "             \"external\": \"field:networks:router:external=True\","
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+            \"network_device\": \"field:port:device_owner=~^network:\","
            },
            "4": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "             \"default\": '@',"
            },
            "5": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 237,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "             \"create_network\": \"rule:admin_or_owner\","
            },
            "7": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "             \"create_subnet\": \"rule:admin_or_network_owner\","
            },
            "8": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 245,
                "PatchRowcode": "             \"create_port:mac\": \"rule:admin_or_network_owner or \""
            },
            "9": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 246,
                "PatchRowcode": "                                \"rule:context_is_advsvc\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+            \"create_port:device_owner\": \"not rule:network_device\","
            },
            "11": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 248,
                "PatchRowcode": "             \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "12": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": 249,
                "PatchRowcode": "             \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "13": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": 250,
                "PatchRowcode": "             \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "14": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": 314,
                "PatchRowcode": "         self._test_nonadmin_action_on_attr('create', 'shared', True,"
            },
            "15": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": 315,
                "PatchRowcode": "                                            common_policy.PolicyNotAuthorized)"
            },
            "16": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 316,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+    def test_create_port_device_owner_regex(self):"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 318,
                "PatchRowcode": "+        blocked_values = ('network:', 'network:abdef', 'network:dhcp',"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 319,
                "PatchRowcode": "+                          'network:router_interface')"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 320,
                "PatchRowcode": "+        for val in blocked_values:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 321,
                "PatchRowcode": "+            self._test_advsvc_action_on_attr("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 322,
                "PatchRowcode": "+                'create', 'port', 'device_owner', val,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 323,
                "PatchRowcode": "+                common_policy.PolicyNotAuthorized"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 324,
                "PatchRowcode": "+            )"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 325,
                "PatchRowcode": "+        ok_values = ('network', 'networks', 'my_network:test', 'my_network:')"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 326,
                "PatchRowcode": "+        for val in ok_values:"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 327,
                "PatchRowcode": "+            self._test_advsvc_action_on_attr("
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 328,
                "PatchRowcode": "+                'create', 'port', 'device_owner', val"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 329,
                "PatchRowcode": "+            )"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "     def test_advsvc_get_network_works(self):"
            },
            "32": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 332,
                "PatchRowcode": "         self._test_advsvc_action_on_attr('get', 'network', 'shared', False)"
            },
            "33": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": 333,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Test of Policy Engine For Neutron\"\"\"",
            "",
            "import contextlib",
            "import StringIO",
            "import urllib2",
            "",
            "import mock",
            "from oslo_config import cfg",
            "from oslo_serialization import jsonutils",
            "from oslo_utils import importutils",
            "import six",
            "import six.moves.urllib.request as urlrequest",
            "",
            "import neutron",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron import context",
            "from neutron import manager",
            "from neutron.openstack.common import policy as common_policy",
            "from neutron import policy",
            "from neutron.tests import base",
            "",
            "",
            "class PolicyFileTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyFileTestCase, self).setUp()",
            "        self.context = context.Context('fake', 'fake', is_admin=False)",
            "        self.target = {'tenant_id': 'fake'}",
            "",
            "    def test_modified_policy_reloads(self):",
            "        tmpfilename = self.get_temp_file_path('policy')",
            "        action = \"example:test\"",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"\"}\"\"\")",
            "        cfg.CONF.set_override('policy_file', tmpfilename)",
            "        policy.refresh()",
            "        policy.enforce(self.context, action, self.target)",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"!\"}\"\"\")",
            "        policy.refresh()",
            "        self.target = {'tenant_id': 'fake_tenant'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized,",
            "                          policy.enforce,",
            "                          self.context,",
            "                          action,",
            "                          self.target)",
            "",
            "",
            "class PolicyTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyTestCase, self).setUp()",
            "        # NOTE(vish): preload rules to circumvent reloading from file",
            "        rules = {",
            "            \"true\": '@',",
            "            \"example:allowed\": '@',",
            "            \"example:denied\": '!',",
            "            \"example:get_http\": \"http:http://www.example.com\",",
            "            \"example:my_file\": \"role:compute_admin or tenant_id:%(tenant_id)s\",",
            "            \"example:early_and_fail\": \"! and @\",",
            "            \"example:early_or_success\": \"@ or !\",",
            "            \"example:lowercase_admin\": \"role:admin or role:sysadmin\",",
            "            \"example:uppercase_admin\": \"role:ADMIN or role:sysadmin\",",
            "        }",
            "        policy.refresh()",
            "        # NOTE(vish): then overload underlying rules",
            "        policy.set_rules(dict((k, common_policy.parse_rule(v))",
            "                              for k, v in rules.items()))",
            "        self.context = context.Context('fake', 'fake', roles=['member'])",
            "        self.target = {}",
            "",
            "    def test_enforce_nonexistent_action_throws(self):",
            "        action = \"example:noexist\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_enforce_bad_action_throws(self):",
            "        action = \"example:denied\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_check_bad_action_noraise(self):",
            "        action = \"example:denied\"",
            "        result = policy.check(self.context, action, self.target)",
            "        self.assertEqual(result, False)",
            "",
            "    def test_check_non_existent_action(self):",
            "        action = \"example:idonotexist\"",
            "        result_1 = policy.check(self.context, action, self.target)",
            "        self.assertFalse(result_1)",
            "        result_2 = policy.check(self.context, action, self.target,",
            "                                might_not_exist=True)",
            "        self.assertTrue(result_2)",
            "",
            "    def test_enforce_good_action(self):",
            "        action = \"example:allowed\"",
            "        result = policy.enforce(self.context, action, self.target)",
            "        self.assertEqual(result, True)",
            "",
            "    @mock.patch.object(urlrequest, 'urlopen',",
            "                       return_value=StringIO.StringIO(\"True\"))",
            "    def test_enforce_http_true(self, mock_urlrequest):",
            "        action = \"example:get_http\"",
            "        target = {}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_http_false(self):",
            "",
            "        def fakeurlopen(url, post_data):",
            "            return six.StringIO(\"False\")",
            "",
            "        with mock.patch.object(urllib2, 'urlopen', new=fakeurlopen):",
            "            action = \"example:get_http\"",
            "            target = {}",
            "            self.assertRaises(common_policy.PolicyNotAuthorized,",
            "                              policy.enforce, self.context,",
            "                              action, target)",
            "",
            "    def test_templatized_enforcement(self):",
            "        target_mine = {'tenant_id': 'fake'}",
            "        target_not_mine = {'tenant_id': 'another'}",
            "        action = \"example:my_file\"",
            "        policy.enforce(self.context, action, target_mine)",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target_not_mine)",
            "",
            "    def test_early_AND_enforcement(self):",
            "        action = \"example:early_and_fail\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_early_OR_enforcement(self):",
            "        action = \"example:early_or_success\"",
            "        policy.enforce(self.context, action, self.target)",
            "",
            "    def test_ignore_case_role_check(self):",
            "        lowercase_action = \"example:lowercase_admin\"",
            "        uppercase_action = \"example:uppercase_admin\"",
            "        # NOTE(dprince) we mix case in the Admin role here to ensure",
            "        # case is ignored",
            "        admin_context = context.Context('admin', 'fake', roles=['AdMiN'])",
            "        policy.enforce(admin_context, lowercase_action, self.target)",
            "        policy.enforce(admin_context, uppercase_action, self.target)",
            "",
            "",
            "class DefaultPolicyTestCase(base.BaseTestCase):",
            "",
            "    def setUp(self):",
            "        super(DefaultPolicyTestCase, self).setUp()",
            "        tmpfilename = self.get_temp_file_path('policy.json')",
            "        self.rules = {",
            "            \"default\": '',",
            "            \"example:exist\": '!',",
            "        }",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            jsonutils.dump(self.rules, policyfile)",
            "        cfg.CONF.set_override('policy_file', tmpfilename)",
            "        policy.refresh()",
            "",
            "        self.context = context.Context('fake', 'fake')",
            "",
            "    def test_policy_called(self):",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, \"example:exist\", {})",
            "",
            "    def test_not_found_policy_calls_default(self):",
            "        policy.enforce(self.context, \"example:noexist\", {})",
            "",
            "",
            "FAKE_RESOURCE_NAME = 'fake_resource'",
            "FAKE_SPECIAL_RESOURCE_NAME = 'fake_policy'",
            "FAKE_RESOURCES = {\"%ss\" % FAKE_RESOURCE_NAME:",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }},",
            "                  # special plural name",
            "                  \"%s\" % FAKE_SPECIAL_RESOURCE_NAME.replace('y', 'ies'):",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }}}",
            "",
            "",
            "class NeutronPolicyTestCase(base.BaseTestCase):",
            "",
            "    def fakepolicyinit(self, **kwargs):",
            "        enf = policy._ENFORCER",
            "        enf.set_rules(common_policy.Rules(self.rules))",
            "",
            "    def setUp(self):",
            "        super(NeutronPolicyTestCase, self).setUp()",
            "        policy.refresh()",
            "        self.admin_only_legacy = \"role:admin\"",
            "        self.admin_or_owner_legacy = \"role:admin or tenant_id:%(tenant_id)s\"",
            "        # Add Fake resources to RESOURCE_ATTRIBUTE_MAP",
            "        attributes.RESOURCE_ATTRIBUTE_MAP.update(FAKE_RESOURCES)",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            \"context_is_admin\": \"role:admin\",",
            "            \"context_is_advsvc\": \"role:advsvc\",",
            "            \"admin_or_network_owner\": \"rule:context_is_admin or \"",
            "                                      \"tenant_id:%(network:tenant_id)s\",",
            "            \"admin_or_owner\": (\"rule:context_is_admin or \"",
            "                               \"tenant_id:%(tenant_id)s\"),",
            "            \"admin_only\": \"rule:context_is_admin\",",
            "            \"regular_user\": \"role:user\",",
            "            \"shared\": \"field:networks:shared=True\",",
            "            \"external\": \"field:networks:router:external=True\",",
            "            \"default\": '@',",
            "",
            "            \"create_network\": \"rule:admin_or_owner\",",
            "            \"create_network:shared\": \"rule:admin_only\",",
            "            \"update_network\": '@',",
            "            \"update_network:shared\": \"rule:admin_only\",",
            "            \"get_network\": \"rule:admin_or_owner or rule:shared or \"",
            "                           \"rule:external or rule:context_is_advsvc\",",
            "            \"create_subnet\": \"rule:admin_or_network_owner\",",
            "            \"create_port:mac\": \"rule:admin_or_network_owner or \"",
            "                               \"rule:context_is_advsvc\",",
            "            \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"create_fake_resource\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_1\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_2\": \"rule:admin_only\",",
            "",
            "            \"create_fake_policy:\": \"rule:admin_or_owner\",",
            "            \"get_firewall_policy\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "            \"get_firewall_rule\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\"",
            "        }.items())",
            "",
            "        def remove_fake_resource():",
            "            del attributes.RESOURCE_ATTRIBUTE_MAP[\"%ss\" % FAKE_RESOURCE_NAME]",
            "",
            "        self.patcher = mock.patch.object(neutron.policy,",
            "                                         'init',",
            "                                         new=self.fakepolicyinit)",
            "        self.patcher.start()",
            "        self.addCleanup(remove_fake_resource)",
            "        self.context = context.Context('fake', 'fake', roles=['user'])",
            "        plugin_klass = importutils.import_class(",
            "            \"neutron.db.db_base_plugin_v2.NeutronDbPluginV2\")",
            "        self.manager_patcher = mock.patch('neutron.manager.NeutronManager')",
            "        fake_manager = self.manager_patcher.start()",
            "        fake_manager_instance = fake_manager.return_value",
            "        fake_manager_instance.plugin = plugin_klass()",
            "",
            "    def _test_action_on_attr(self, context, action, obj, attr, value,",
            "                             exception=None, **kwargs):",
            "        action = \"%s_%s\" % (action, obj)",
            "        target = {'tenant_id': 'the_owner', attr: value}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        if exception:",
            "            self.assertRaises(exception, policy.enforce,",
            "                              context, action, target)",
            "        else:",
            "            result = policy.enforce(context, action, target)",
            "            self.assertEqual(result, True)",
            "",
            "    def _test_nonadmin_action_on_attr(self, action, attr, value,",
            "                                      exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\", roles=['user'])",
            "        self._test_action_on_attr(user_context, action, \"network\", attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def _test_advsvc_action_on_attr(self, action, obj, attr, value,",
            "                                    exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\",",
            "                                       roles=['user', 'advsvc'])",
            "        self._test_action_on_attr(user_context, action, obj, attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def test_nonadmin_write_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_write_on_shared_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', True,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_get_network_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'network', 'shared', False)",
            "",
            "    def test_advsvc_create_network_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'network', 'shared', False,",
            "                                         common_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_create_port_works(self):",
            "        self._test_advsvc_action_on_attr('create', 'port:mac', 'shared', False)",
            "",
            "    def test_advsvc_get_port_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'port', 'shared', False)",
            "",
            "    def test_advsvc_update_port_works(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_advsvc_action_on_attr('update', 'port', 'shared', True,",
            "                                         **kwargs)",
            "",
            "    def test_advsvc_delete_port_works(self):",
            "        self._test_advsvc_action_on_attr('delete', 'port', 'shared', False)",
            "",
            "    def test_advsvc_create_subnet_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'subnet', 'shared', False,",
            "                                         common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_shared_succeeds(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', True)",
            "",
            "    def _test_enforce_adminonly_attribute(self, action, **kwargs):",
            "        admin_context = context.get_admin_context()",
            "        target = {'shared': True}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        result = policy.enforce(admin_context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_adminonly_attribute_create(self):",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_update(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_enforce_adminonly_attribute('update_network', **kwargs)",
            "",
            "    def test_reset_adminonly_attr_to_default_fails(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_nonadmin_action_on_attr('update', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized,",
            "                                           **kwargs)",
            "",
            "    def test_enforce_adminonly_attribute_no_context_is_admin_policy(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        self.rules['admin_only'] = common_policy.parse_rule(",
            "            self.admin_only_legacy)",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(",
            "            self.admin_or_owner_legacy)",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_nonadminctx_returns_403(self):",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_adminonly_nonadminctx_no_ctx_is_admin_policy_403(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        self.rules['admin_only'] = common_policy.parse_rule(",
            "            self.admin_only_legacy)",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(",
            "            self.admin_or_owner_legacy)",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def _test_build_subattribute_match_rule(self, validate_value):",
            "        bk = FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate']",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = (",
            "            validate_value)",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        self.assertFalse(policy._build_subattr_match_rule(",
            "            'attr',",
            "            FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr'],",
            "            action,",
            "            target))",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = bk",
            "",
            "    def test_build_subattribute_match_rule_empty_dict_validator(self):",
            "        self._test_build_subattribute_match_rule({})",
            "",
            "    def test_build_subattribute_match_rule_wrong_validation_info(self):",
            "        self._test_build_subattribute_match_rule(",
            "            {'type:dict': 'wrong_stuff'})",
            "",
            "    def test_build_match_rule_special_pluralized(self):",
            "        action = \"create_\" + FAKE_SPECIAL_RESOURCE_NAME",
            "        pluralized = \"create_fake_policies\"",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, pluralized)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_build_match_rule_normal_pluralized_when_create(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, None)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_enforce_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        result = policy.enforce(self.context, action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        result = policy.enforce(context.get_admin_context(),",
            "                                action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute_nonadminctx_returns_403(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target, None)",
            "",
            "    def test_enforce_regularuser_on_read(self):",
            "        action = \"get_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_policy_shared(self):",
            "        action = \"get_firewall_policy\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_rule_shared(self):",
            "        action = \"get_firewall_rule\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check(self):",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_enforce_plugin_failure(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            raise NotImplementedError('Blast!')",
            "",
            "        # the policy check and plugin method we use in this test are irrelevant",
            "        # so long that we verify that, if *f* blows up, the behavior of the",
            "        # policy engine to propagate the exception is preserved",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            self.assertRaises(NotImplementedError,",
            "                              policy.enforce,",
            "                              self.context,",
            "                              action,",
            "                              target)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource_bw_compatibility(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        del self.rules['admin_or_network_owner']",
            "        self.rules['admin_or_network_owner'] = common_policy.parse_rule(",
            "            \"role:admin or tenant_id:%(network_tenant_id)s\")",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_tenant_id_check_no_target_field_raises(self):",
            "        # Try and add a bad rule",
            "        self.assertRaises(",
            "            exceptions.PolicyInitError,",
            "            common_policy.parse_rule,",
            "            'tenant_id:(wrong_stuff)')",
            "",
            "    def _test_enforce_tenant_id_raises(self, bad_rule):",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(bad_rule)",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        self.fakepolicyinit()",
            "        self.assertRaises(exceptions.PolicyCheckError,",
            "                          policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_tenant_id_check_malformed_target_field_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(malformed_field)s')",
            "",
            "    def test_enforce_tenant_id_check_invalid_parent_resource_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(foobaz_tenant_id)s')",
            "",
            "    def test_get_roles_context_is_admin_rule_missing(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            \"some_other_rule\": \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        # 'admin' role is expected for bw compatibility",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_role_check(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_rule_check(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"rule:some_other_rule\",",
            "            \"some_other_rule\": \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_or_check(self):",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"rule:rule1 or rule:rule2\",",
            "            \"rule1\": \"role:admin_1\",",
            "            \"rule2\": \"role:admin_2\"",
            "        }.items())",
            "        self.assertEqual(['admin_1', 'admin_2'],",
            "                         policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_other_rules(self):",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"role:xxx or other:value\",",
            "        }.items())",
            "        self.assertEqual(['xxx'], policy.get_admin_roles())",
            "",
            "    def _test_set_rules_with_deprecated_policy(self, input_rules,",
            "                                               expected_rules):",
            "        policy.set_rules(input_rules.copy())",
            "        # verify deprecated policy has been removed",
            "        for pol in input_rules.keys():",
            "            self.assertNotIn(pol, policy._ENFORCER.rules)",
            "        # verify deprecated policy was correctly translated. Iterate",
            "        # over items for compatibility with unittest2 in python 2.6",
            "        for rule in expected_rules:",
            "            self.assertIn(rule, policy._ENFORCER.rules)",
            "            self.assertEqual(str(policy._ENFORCER.rules[rule]),",
            "                             expected_rules[rule])",
            "",
            "    def test_set_rules_with_deprecated_view_policy(self):",
            "        self._test_set_rules_with_deprecated_policy(",
            "            {'extension:router:view': 'rule:admin_or_owner'},",
            "            {'get_network:router:external': 'rule:admin_or_owner'})",
            "",
            "    def test_set_rules_with_deprecated_set_policy(self):",
            "        expected_policies = ['create_network:provider:network_type',",
            "                             'create_network:provider:physical_network',",
            "                             'create_network:provider:segmentation_id',",
            "                             'update_network:provider:network_type',",
            "                             'update_network:provider:physical_network',",
            "                             'update_network:provider:segmentation_id']",
            "        self._test_set_rules_with_deprecated_policy(",
            "            {'extension:provider_network:set': 'rule:admin_only'},",
            "            dict((policy, 'rule:admin_only') for policy in",
            "                 expected_policies))",
            "",
            "    def test_process_rules(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        # Construct RuleChecks for an action, attribute and subattribute",
            "        match_rule = common_policy.RuleCheck('rule', action)",
            "        attr_rule = common_policy.RuleCheck('rule', '%s:%ss' %",
            "                                                    (action,",
            "                                                     FAKE_RESOURCE_NAME))",
            "        sub_attr_rules = [common_policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                                          (action, 'attr',",
            "                                                           'sub_attr_1'))]",
            "        # Build an AndCheck from the given RuleChecks",
            "        # Make the checks nested to better check the recursion",
            "        sub_attr_rules = common_policy.AndCheck(sub_attr_rules)",
            "        attr_rule = common_policy.AndCheck(",
            "            [attr_rule, sub_attr_rules])",
            "",
            "        match_rule = common_policy.AndCheck([match_rule, attr_rule])",
            "        # Assert that the rules are correctly extracted from the match_rule",
            "        rules = policy._process_rules_list([], match_rule)",
            "        self.assertEqual(['create_fake_resource',",
            "                          'create_fake_resource:fake_resources',",
            "                          'create_fake_resource:attr:sub_attr_1'], rules)",
            "",
            "    def test_log_rule_list(self):",
            "        with contextlib.nested(",
            "            mock.patch.object(policy.LOG, 'isEnabledFor', return_value=True),",
            "            mock.patch.object(policy.LOG, 'debug')",
            "        ) as (is_e, dbg):",
            "            policy.log_rule_list(common_policy.RuleCheck('rule', 'create_'))",
            "            self.assertTrue(is_e.called)",
            "            self.assertTrue(dbg.called)"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Test of Policy Engine For Neutron\"\"\"",
            "",
            "import contextlib",
            "import StringIO",
            "import urllib2",
            "",
            "import mock",
            "from oslo_config import cfg",
            "from oslo_serialization import jsonutils",
            "from oslo_utils import importutils",
            "import six",
            "import six.moves.urllib.request as urlrequest",
            "",
            "import neutron",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron import context",
            "from neutron import manager",
            "from neutron.openstack.common import policy as common_policy",
            "from neutron import policy",
            "from neutron.tests import base",
            "",
            "",
            "class PolicyFileTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyFileTestCase, self).setUp()",
            "        self.context = context.Context('fake', 'fake', is_admin=False)",
            "        self.target = {'tenant_id': 'fake'}",
            "",
            "    def test_modified_policy_reloads(self):",
            "        tmpfilename = self.get_temp_file_path('policy')",
            "        action = \"example:test\"",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"\"}\"\"\")",
            "        cfg.CONF.set_override('policy_file', tmpfilename)",
            "        policy.refresh()",
            "        policy.enforce(self.context, action, self.target)",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"!\"}\"\"\")",
            "        policy.refresh()",
            "        self.target = {'tenant_id': 'fake_tenant'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized,",
            "                          policy.enforce,",
            "                          self.context,",
            "                          action,",
            "                          self.target)",
            "",
            "",
            "class PolicyTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyTestCase, self).setUp()",
            "        # NOTE(vish): preload rules to circumvent reloading from file",
            "        rules = {",
            "            \"true\": '@',",
            "            \"example:allowed\": '@',",
            "            \"example:denied\": '!',",
            "            \"example:get_http\": \"http:http://www.example.com\",",
            "            \"example:my_file\": \"role:compute_admin or tenant_id:%(tenant_id)s\",",
            "            \"example:early_and_fail\": \"! and @\",",
            "            \"example:early_or_success\": \"@ or !\",",
            "            \"example:lowercase_admin\": \"role:admin or role:sysadmin\",",
            "            \"example:uppercase_admin\": \"role:ADMIN or role:sysadmin\",",
            "        }",
            "        policy.refresh()",
            "        # NOTE(vish): then overload underlying rules",
            "        policy.set_rules(dict((k, common_policy.parse_rule(v))",
            "                              for k, v in rules.items()))",
            "        self.context = context.Context('fake', 'fake', roles=['member'])",
            "        self.target = {}",
            "",
            "    def test_enforce_nonexistent_action_throws(self):",
            "        action = \"example:noexist\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_enforce_bad_action_throws(self):",
            "        action = \"example:denied\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_check_bad_action_noraise(self):",
            "        action = \"example:denied\"",
            "        result = policy.check(self.context, action, self.target)",
            "        self.assertEqual(result, False)",
            "",
            "    def test_check_non_existent_action(self):",
            "        action = \"example:idonotexist\"",
            "        result_1 = policy.check(self.context, action, self.target)",
            "        self.assertFalse(result_1)",
            "        result_2 = policy.check(self.context, action, self.target,",
            "                                might_not_exist=True)",
            "        self.assertTrue(result_2)",
            "",
            "    def test_enforce_good_action(self):",
            "        action = \"example:allowed\"",
            "        result = policy.enforce(self.context, action, self.target)",
            "        self.assertEqual(result, True)",
            "",
            "    @mock.patch.object(urlrequest, 'urlopen',",
            "                       return_value=StringIO.StringIO(\"True\"))",
            "    def test_enforce_http_true(self, mock_urlrequest):",
            "        action = \"example:get_http\"",
            "        target = {}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_http_false(self):",
            "",
            "        def fakeurlopen(url, post_data):",
            "            return six.StringIO(\"False\")",
            "",
            "        with mock.patch.object(urllib2, 'urlopen', new=fakeurlopen):",
            "            action = \"example:get_http\"",
            "            target = {}",
            "            self.assertRaises(common_policy.PolicyNotAuthorized,",
            "                              policy.enforce, self.context,",
            "                              action, target)",
            "",
            "    def test_templatized_enforcement(self):",
            "        target_mine = {'tenant_id': 'fake'}",
            "        target_not_mine = {'tenant_id': 'another'}",
            "        action = \"example:my_file\"",
            "        policy.enforce(self.context, action, target_mine)",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target_not_mine)",
            "",
            "    def test_early_AND_enforcement(self):",
            "        action = \"example:early_and_fail\"",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_early_OR_enforcement(self):",
            "        action = \"example:early_or_success\"",
            "        policy.enforce(self.context, action, self.target)",
            "",
            "    def test_ignore_case_role_check(self):",
            "        lowercase_action = \"example:lowercase_admin\"",
            "        uppercase_action = \"example:uppercase_admin\"",
            "        # NOTE(dprince) we mix case in the Admin role here to ensure",
            "        # case is ignored",
            "        admin_context = context.Context('admin', 'fake', roles=['AdMiN'])",
            "        policy.enforce(admin_context, lowercase_action, self.target)",
            "        policy.enforce(admin_context, uppercase_action, self.target)",
            "",
            "",
            "class DefaultPolicyTestCase(base.BaseTestCase):",
            "",
            "    def setUp(self):",
            "        super(DefaultPolicyTestCase, self).setUp()",
            "        tmpfilename = self.get_temp_file_path('policy.json')",
            "        self.rules = {",
            "            \"default\": '',",
            "            \"example:exist\": '!',",
            "        }",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            jsonutils.dump(self.rules, policyfile)",
            "        cfg.CONF.set_override('policy_file', tmpfilename)",
            "        policy.refresh()",
            "",
            "        self.context = context.Context('fake', 'fake')",
            "",
            "    def test_policy_called(self):",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, \"example:exist\", {})",
            "",
            "    def test_not_found_policy_calls_default(self):",
            "        policy.enforce(self.context, \"example:noexist\", {})",
            "",
            "",
            "FAKE_RESOURCE_NAME = 'fake_resource'",
            "FAKE_SPECIAL_RESOURCE_NAME = 'fake_policy'",
            "FAKE_RESOURCES = {\"%ss\" % FAKE_RESOURCE_NAME:",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }},",
            "                  # special plural name",
            "                  \"%s\" % FAKE_SPECIAL_RESOURCE_NAME.replace('y', 'ies'):",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }}}",
            "",
            "",
            "class NeutronPolicyTestCase(base.BaseTestCase):",
            "",
            "    def fakepolicyinit(self, **kwargs):",
            "        enf = policy._ENFORCER",
            "        enf.set_rules(common_policy.Rules(self.rules))",
            "",
            "    def setUp(self):",
            "        super(NeutronPolicyTestCase, self).setUp()",
            "        policy.refresh()",
            "        self.admin_only_legacy = \"role:admin\"",
            "        self.admin_or_owner_legacy = \"role:admin or tenant_id:%(tenant_id)s\"",
            "        # Add Fake resources to RESOURCE_ATTRIBUTE_MAP",
            "        attributes.RESOURCE_ATTRIBUTE_MAP.update(FAKE_RESOURCES)",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            \"context_is_admin\": \"role:admin\",",
            "            \"context_is_advsvc\": \"role:advsvc\",",
            "            \"admin_or_network_owner\": \"rule:context_is_admin or \"",
            "                                      \"tenant_id:%(network:tenant_id)s\",",
            "            \"admin_or_owner\": (\"rule:context_is_admin or \"",
            "                               \"tenant_id:%(tenant_id)s\"),",
            "            \"admin_only\": \"rule:context_is_admin\",",
            "            \"regular_user\": \"role:user\",",
            "            \"shared\": \"field:networks:shared=True\",",
            "            \"external\": \"field:networks:router:external=True\",",
            "            \"network_device\": \"field:port:device_owner=~^network:\",",
            "            \"default\": '@',",
            "",
            "            \"create_network\": \"rule:admin_or_owner\",",
            "            \"create_network:shared\": \"rule:admin_only\",",
            "            \"update_network\": '@',",
            "            \"update_network:shared\": \"rule:admin_only\",",
            "            \"get_network\": \"rule:admin_or_owner or rule:shared or \"",
            "                           \"rule:external or rule:context_is_advsvc\",",
            "            \"create_subnet\": \"rule:admin_or_network_owner\",",
            "            \"create_port:mac\": \"rule:admin_or_network_owner or \"",
            "                               \"rule:context_is_advsvc\",",
            "            \"create_port:device_owner\": \"not rule:network_device\",",
            "            \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"create_fake_resource\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_1\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_2\": \"rule:admin_only\",",
            "",
            "            \"create_fake_policy:\": \"rule:admin_or_owner\",",
            "            \"get_firewall_policy\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "            \"get_firewall_rule\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\"",
            "        }.items())",
            "",
            "        def remove_fake_resource():",
            "            del attributes.RESOURCE_ATTRIBUTE_MAP[\"%ss\" % FAKE_RESOURCE_NAME]",
            "",
            "        self.patcher = mock.patch.object(neutron.policy,",
            "                                         'init',",
            "                                         new=self.fakepolicyinit)",
            "        self.patcher.start()",
            "        self.addCleanup(remove_fake_resource)",
            "        self.context = context.Context('fake', 'fake', roles=['user'])",
            "        plugin_klass = importutils.import_class(",
            "            \"neutron.db.db_base_plugin_v2.NeutronDbPluginV2\")",
            "        self.manager_patcher = mock.patch('neutron.manager.NeutronManager')",
            "        fake_manager = self.manager_patcher.start()",
            "        fake_manager_instance = fake_manager.return_value",
            "        fake_manager_instance.plugin = plugin_klass()",
            "",
            "    def _test_action_on_attr(self, context, action, obj, attr, value,",
            "                             exception=None, **kwargs):",
            "        action = \"%s_%s\" % (action, obj)",
            "        target = {'tenant_id': 'the_owner', attr: value}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        if exception:",
            "            self.assertRaises(exception, policy.enforce,",
            "                              context, action, target)",
            "        else:",
            "            result = policy.enforce(context, action, target)",
            "            self.assertEqual(result, True)",
            "",
            "    def _test_nonadmin_action_on_attr(self, action, attr, value,",
            "                                      exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\", roles=['user'])",
            "        self._test_action_on_attr(user_context, action, \"network\", attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def _test_advsvc_action_on_attr(self, action, obj, attr, value,",
            "                                    exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\",",
            "                                       roles=['user', 'advsvc'])",
            "        self._test_action_on_attr(user_context, action, obj, attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def test_nonadmin_write_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_write_on_shared_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', True,",
            "                                           common_policy.PolicyNotAuthorized)",
            "",
            "    def test_create_port_device_owner_regex(self):",
            "        blocked_values = ('network:', 'network:abdef', 'network:dhcp',",
            "                          'network:router_interface')",
            "        for val in blocked_values:",
            "            self._test_advsvc_action_on_attr(",
            "                'create', 'port', 'device_owner', val,",
            "                common_policy.PolicyNotAuthorized",
            "            )",
            "        ok_values = ('network', 'networks', 'my_network:test', 'my_network:')",
            "        for val in ok_values:",
            "            self._test_advsvc_action_on_attr(",
            "                'create', 'port', 'device_owner', val",
            "            )",
            "",
            "    def test_advsvc_get_network_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'network', 'shared', False)",
            "",
            "    def test_advsvc_create_network_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'network', 'shared', False,",
            "                                         common_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_create_port_works(self):",
            "        self._test_advsvc_action_on_attr('create', 'port:mac', 'shared', False)",
            "",
            "    def test_advsvc_get_port_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'port', 'shared', False)",
            "",
            "    def test_advsvc_update_port_works(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_advsvc_action_on_attr('update', 'port', 'shared', True,",
            "                                         **kwargs)",
            "",
            "    def test_advsvc_delete_port_works(self):",
            "        self._test_advsvc_action_on_attr('delete', 'port', 'shared', False)",
            "",
            "    def test_advsvc_create_subnet_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'subnet', 'shared', False,",
            "                                         common_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_shared_succeeds(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', True)",
            "",
            "    def _test_enforce_adminonly_attribute(self, action, **kwargs):",
            "        admin_context = context.get_admin_context()",
            "        target = {'shared': True}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        result = policy.enforce(admin_context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_adminonly_attribute_create(self):",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_update(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_enforce_adminonly_attribute('update_network', **kwargs)",
            "",
            "    def test_reset_adminonly_attr_to_default_fails(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_nonadmin_action_on_attr('update', 'shared', False,",
            "                                           common_policy.PolicyNotAuthorized,",
            "                                           **kwargs)",
            "",
            "    def test_enforce_adminonly_attribute_no_context_is_admin_policy(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        self.rules['admin_only'] = common_policy.parse_rule(",
            "            self.admin_only_legacy)",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(",
            "            self.admin_or_owner_legacy)",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_nonadminctx_returns_403(self):",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_adminonly_nonadminctx_no_ctx_is_admin_policy_403(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        self.rules['admin_only'] = common_policy.parse_rule(",
            "            self.admin_only_legacy)",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(",
            "            self.admin_or_owner_legacy)",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def _test_build_subattribute_match_rule(self, validate_value):",
            "        bk = FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate']",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = (",
            "            validate_value)",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        self.assertFalse(policy._build_subattr_match_rule(",
            "            'attr',",
            "            FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr'],",
            "            action,",
            "            target))",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = bk",
            "",
            "    def test_build_subattribute_match_rule_empty_dict_validator(self):",
            "        self._test_build_subattribute_match_rule({})",
            "",
            "    def test_build_subattribute_match_rule_wrong_validation_info(self):",
            "        self._test_build_subattribute_match_rule(",
            "            {'type:dict': 'wrong_stuff'})",
            "",
            "    def test_build_match_rule_special_pluralized(self):",
            "        action = \"create_\" + FAKE_SPECIAL_RESOURCE_NAME",
            "        pluralized = \"create_fake_policies\"",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, pluralized)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_build_match_rule_normal_pluralized_when_create(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, None)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_enforce_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        result = policy.enforce(self.context, action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        result = policy.enforce(context.get_admin_context(),",
            "                                action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute_nonadminctx_returns_403(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        self.assertRaises(common_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target, None)",
            "",
            "    def test_enforce_regularuser_on_read(self):",
            "        action = \"get_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_policy_shared(self):",
            "        action = \"get_firewall_policy\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_rule_shared(self):",
            "        action = \"get_firewall_rule\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check(self):",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_enforce_plugin_failure(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            raise NotImplementedError('Blast!')",
            "",
            "        # the policy check and plugin method we use in this test are irrelevant",
            "        # so long that we verify that, if *f* blows up, the behavior of the",
            "        # policy engine to propagate the exception is preserved",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            self.assertRaises(NotImplementedError,",
            "                              policy.enforce,",
            "                              self.context,",
            "                              action,",
            "                              target)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource_bw_compatibility(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        del self.rules['admin_or_network_owner']",
            "        self.rules['admin_or_network_owner'] = common_policy.parse_rule(",
            "            \"role:admin or tenant_id:%(network_tenant_id)s\")",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_tenant_id_check_no_target_field_raises(self):",
            "        # Try and add a bad rule",
            "        self.assertRaises(",
            "            exceptions.PolicyInitError,",
            "            common_policy.parse_rule,",
            "            'tenant_id:(wrong_stuff)')",
            "",
            "    def _test_enforce_tenant_id_raises(self, bad_rule):",
            "        self.rules['admin_or_owner'] = common_policy.parse_rule(bad_rule)",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        self.fakepolicyinit()",
            "        self.assertRaises(exceptions.PolicyCheckError,",
            "                          policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_tenant_id_check_malformed_target_field_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(malformed_field)s')",
            "",
            "    def test_enforce_tenant_id_check_invalid_parent_resource_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(foobaz_tenant_id)s')",
            "",
            "    def test_get_roles_context_is_admin_rule_missing(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            \"some_other_rule\": \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        # 'admin' role is expected for bw compatibility",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_role_check(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_rule_check(self):",
            "        rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"rule:some_other_rule\",",
            "            \"some_other_rule\": \"role:admin\",",
            "        }.items())",
            "        policy.set_rules(common_policy.Rules(rules))",
            "        self.assertEqual(['admin'], policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_or_check(self):",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"rule:rule1 or rule:rule2\",",
            "            \"rule1\": \"role:admin_1\",",
            "            \"rule2\": \"role:admin_2\"",
            "        }.items())",
            "        self.assertEqual(['admin_1', 'admin_2'],",
            "                         policy.get_admin_roles())",
            "",
            "    def test_get_roles_with_other_rules(self):",
            "        self.rules = dict((k, common_policy.parse_rule(v)) for k, v in {",
            "            policy.ADMIN_CTX_POLICY: \"role:xxx or other:value\",",
            "        }.items())",
            "        self.assertEqual(['xxx'], policy.get_admin_roles())",
            "",
            "    def _test_set_rules_with_deprecated_policy(self, input_rules,",
            "                                               expected_rules):",
            "        policy.set_rules(input_rules.copy())",
            "        # verify deprecated policy has been removed",
            "        for pol in input_rules.keys():",
            "            self.assertNotIn(pol, policy._ENFORCER.rules)",
            "        # verify deprecated policy was correctly translated. Iterate",
            "        # over items for compatibility with unittest2 in python 2.6",
            "        for rule in expected_rules:",
            "            self.assertIn(rule, policy._ENFORCER.rules)",
            "            self.assertEqual(str(policy._ENFORCER.rules[rule]),",
            "                             expected_rules[rule])",
            "",
            "    def test_set_rules_with_deprecated_view_policy(self):",
            "        self._test_set_rules_with_deprecated_policy(",
            "            {'extension:router:view': 'rule:admin_or_owner'},",
            "            {'get_network:router:external': 'rule:admin_or_owner'})",
            "",
            "    def test_set_rules_with_deprecated_set_policy(self):",
            "        expected_policies = ['create_network:provider:network_type',",
            "                             'create_network:provider:physical_network',",
            "                             'create_network:provider:segmentation_id',",
            "                             'update_network:provider:network_type',",
            "                             'update_network:provider:physical_network',",
            "                             'update_network:provider:segmentation_id']",
            "        self._test_set_rules_with_deprecated_policy(",
            "            {'extension:provider_network:set': 'rule:admin_only'},",
            "            dict((policy, 'rule:admin_only') for policy in",
            "                 expected_policies))",
            "",
            "    def test_process_rules(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        # Construct RuleChecks for an action, attribute and subattribute",
            "        match_rule = common_policy.RuleCheck('rule', action)",
            "        attr_rule = common_policy.RuleCheck('rule', '%s:%ss' %",
            "                                                    (action,",
            "                                                     FAKE_RESOURCE_NAME))",
            "        sub_attr_rules = [common_policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                                          (action, 'attr',",
            "                                                           'sub_attr_1'))]",
            "        # Build an AndCheck from the given RuleChecks",
            "        # Make the checks nested to better check the recursion",
            "        sub_attr_rules = common_policy.AndCheck(sub_attr_rules)",
            "        attr_rule = common_policy.AndCheck(",
            "            [attr_rule, sub_attr_rules])",
            "",
            "        match_rule = common_policy.AndCheck([match_rule, attr_rule])",
            "        # Assert that the rules are correctly extracted from the match_rule",
            "        rules = policy._process_rules_list([], match_rule)",
            "        self.assertEqual(['create_fake_resource',",
            "                          'create_fake_resource:fake_resources',",
            "                          'create_fake_resource:attr:sub_attr_1'], rules)",
            "",
            "    def test_log_rule_list(self):",
            "        with contextlib.nested(",
            "            mock.patch.object(policy.LOG, 'isEnabledFor', return_value=True),",
            "            mock.patch.object(policy.LOG, 'debug')",
            "        ) as (is_e, dbg):",
            "            policy.log_rule_list(common_policy.RuleCheck('rule', 'create_'))",
            "            self.assertTrue(is_e.called)",
            "            self.assertTrue(dbg.called)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase.self"
        ]
    }
}