{
    "airflow/contrib/auth/backends/ldap_auth.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": " def get_ldap_connection(dn=None, password=None):"
            },
            "3": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    tls_configuration = None"
            },
            "4": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    use_ssl = False"
            },
            "5": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "     try:"
            },
            "6": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "         cacert = configuration.conf.get(\"ldap\", \"cacert\")"
            },
            "7": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        tls_configuration = Tls(validate=ssl.CERT_REQUIRED, ca_certs_file=cacert)"
            },
            "8": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        use_ssl = True"
            },
            "9": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    except Exception:"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+    except AirflowConfigException:"
            },
            "11": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         pass"
            },
            "12": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    server = Server(configuration.conf.get(\"ldap\", \"uri\"), use_ssl, tls_configuration)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+    tls_configuration = Tls(validate=ssl.CERT_REQUIRED,"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+                            ca_certs_file=cacert)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+    server = Server(configuration.conf.get(\"ldap\", \"uri\"),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+                    use_ssl=True,"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+                    tls=tls_configuration)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+"
            },
            "21": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "     conn = Connection(server, native(dn), native(password))"
            },
            "22": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 72,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 73,
                "PatchRowcode": "     if not conn.bind():"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from future.utils import native",
            "",
            "import flask_login",
            "from flask_login import login_required, current_user, logout_user",
            "from flask import flash",
            "from wtforms import (",
            "    Form, PasswordField, StringField)",
            "from wtforms.validators import InputRequired",
            "",
            "from ldap3 import Server, Connection, Tls, LEVEL, SUBTREE, BASE",
            "import ssl",
            "",
            "from flask import url_for, redirect",
            "",
            "from airflow import models",
            "from airflow import configuration",
            "from airflow.configuration import AirflowConfigException",
            "from airflow.utils.db import provide_session",
            "",
            "import traceback",
            "import re",
            "",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "",
            "login_manager = flask_login.LoginManager()",
            "login_manager.login_view = 'airflow.login'  # Calls login() below",
            "login_manager.login_message = None",
            "",
            "log = LoggingMixin().log",
            "",
            "",
            "class AuthenticationError(Exception):",
            "    pass",
            "",
            "",
            "class LdapException(Exception):",
            "    pass",
            "",
            "",
            "def get_ldap_connection(dn=None, password=None):",
            "    tls_configuration = None",
            "    use_ssl = False",
            "    try:",
            "        cacert = configuration.conf.get(\"ldap\", \"cacert\")",
            "        tls_configuration = Tls(validate=ssl.CERT_REQUIRED, ca_certs_file=cacert)",
            "        use_ssl = True",
            "    except Exception:",
            "        pass",
            "",
            "    server = Server(configuration.conf.get(\"ldap\", \"uri\"), use_ssl, tls_configuration)",
            "    conn = Connection(server, native(dn), native(password))",
            "",
            "    if not conn.bind():",
            "        log.error(\"Cannot bind to ldap server: %s \", conn.last_error)",
            "        raise AuthenticationError(\"Cannot bind to ldap server\")",
            "",
            "    return conn",
            "",
            "",
            "def group_contains_user(conn, search_base, group_filter, user_name_attr, username):",
            "    search_filter = '(&({0}))'.format(group_filter)",
            "",
            "    if not conn.search(native(search_base), native(search_filter),",
            "                       attributes=[native(user_name_attr)]):",
            "        log.warning(\"Unable to find group for %s %s\", search_base, search_filter)",
            "    else:",
            "        for entry in conn.entries:",
            "            if username.lower() in map(lambda attr: attr.lower(),",
            "                                       getattr(entry, user_name_attr).values):",
            "                return True",
            "",
            "    return False",
            "",
            "",
            "def groups_user(conn, search_base, user_filter, user_name_att, username):",
            "    search_filter = \"(&({0})({1}={2}))\".format(user_filter, user_name_att, username)",
            "    try:",
            "        memberof_attr = configuration.conf.get(\"ldap\", \"group_member_attr\")",
            "    except Exception:",
            "        memberof_attr = \"memberOf\"",
            "    res = conn.search(native(search_base), native(search_filter),",
            "                      attributes=[native(memberof_attr)])",
            "    if not res:",
            "        log.info(\"Cannot find user %s\", username)",
            "        raise AuthenticationError(\"Invalid username or password\")",
            "",
            "    if conn.response and memberof_attr not in conn.response[0][\"attributes\"]:",
            "        log.warning(\"\"\"Missing attribute \"%s\" when looked-up in Ldap database.",
            "        The user does not seem to be a member of a group and therefore won't see any dag",
            "        if the option filter_by_owner=True and owner_mode=ldapgroup are set\"\"\",",
            "                    memberof_attr)",
            "        return []",
            "",
            "    user_groups = conn.response[0][\"attributes\"][memberof_attr]",
            "",
            "    regex = re.compile(\"cn=([^,]*).*\", re.IGNORECASE)",
            "    groups_list = []",
            "    try:",
            "        groups_list = [regex.search(i).group(1) for i in user_groups]",
            "    except IndexError:",
            "        log.warning(\"Parsing error when retrieving the user's group(s).\"",
            "                    \" Check if the user belongs to at least one group\"",
            "                    \" or if the user's groups name do not contain special characters\")",
            "",
            "    return groups_list",
            "",
            "",
            "class LdapUser(models.User):",
            "    def __init__(self, user):",
            "        self.user = user",
            "        self.ldap_groups = []",
            "",
            "        # Load and cache superuser and data_profiler settings.",
            "        conn = get_ldap_connection(configuration.conf.get(\"ldap\", \"bind_user\"),",
            "                                   configuration.conf.get(\"ldap\", \"bind_password\"))",
            "",
            "        superuser_filter = None",
            "        data_profiler_filter = None",
            "        try:",
            "            superuser_filter = configuration.conf.get(\"ldap\", \"superuser_filter\")",
            "        except AirflowConfigException:",
            "            pass",
            "",
            "        if not superuser_filter:",
            "            self.superuser = True",
            "            log.debug(\"Missing configuration for superuser settings or empty. Skipping.\")",
            "        else:",
            "            self.superuser = group_contains_user(conn,",
            "                                                 configuration.conf.get(\"ldap\", \"basedn\"),",
            "                                                 superuser_filter,",
            "                                                 configuration.conf.get(\"ldap\",",
            "                                                                        \"user_name_attr\"),",
            "                                                 user.username)",
            "",
            "        try:",
            "            data_profiler_filter = configuration.conf.get(\"ldap\", \"data_profiler_filter\")",
            "        except AirflowConfigException:",
            "            pass",
            "",
            "        if not data_profiler_filter:",
            "            self.data_profiler = True",
            "            log.debug(\"Missing configuration for data profiler settings or empty. \"",
            "                      \"Skipping.\")",
            "        else:",
            "            self.data_profiler = group_contains_user(",
            "                conn,",
            "                configuration.conf.get(\"ldap\", \"basedn\"),",
            "                data_profiler_filter,",
            "                configuration.conf.get(\"ldap\",",
            "                                       \"user_name_attr\"),",
            "                user.username",
            "            )",
            "",
            "        # Load the ldap group(s) a user belongs to",
            "        try:",
            "            self.ldap_groups = groups_user(",
            "                conn,",
            "                configuration.conf.get(\"ldap\", \"basedn\"),",
            "                configuration.conf.get(\"ldap\", \"user_filter\"),",
            "                configuration.conf.get(\"ldap\", \"user_name_attr\"),",
            "                user.username",
            "            )",
            "        except AirflowConfigException:",
            "            log.debug(\"Missing configuration for ldap settings. Skipping\")",
            "",
            "    @staticmethod",
            "    def try_login(username, password):",
            "        conn = get_ldap_connection(configuration.conf.get(\"ldap\", \"bind_user\"),",
            "                                   configuration.conf.get(\"ldap\", \"bind_password\"))",
            "",
            "        search_filter = \"(&({0})({1}={2}))\".format(",
            "            configuration.conf.get(\"ldap\", \"user_filter\"),",
            "            configuration.conf.get(\"ldap\", \"user_name_attr\"),",
            "            username",
            "        )",
            "",
            "        search_scope = LEVEL",
            "        if configuration.conf.has_option(\"ldap\", \"search_scope\"):",
            "            if configuration.conf.get(\"ldap\", \"search_scope\") == \"SUBTREE\":",
            "                search_scope = SUBTREE",
            "            else:",
            "                search_scope = LEVEL",
            "",
            "        # todo: BASE or ONELEVEL?",
            "",
            "        res = conn.search(native(configuration.conf.get(\"ldap\", \"basedn\")),",
            "                          native(search_filter),",
            "                          search_scope=native(search_scope))",
            "",
            "        # todo: use list or result?",
            "        if not res:",
            "            log.info(\"Cannot find user %s\", username)",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "        entry = conn.response[0]",
            "",
            "        conn.unbind()",
            "",
            "        if 'dn' not in entry:",
            "            # The search filter for the user did not return any values, so an",
            "            # invalid user was used for credentials.",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "        try:",
            "            conn = get_ldap_connection(entry['dn'], password)",
            "        except KeyError:",
            "            log.error(\"\"\"",
            "            Unable to parse LDAP structure. If you're using Active Directory",
            "            and not specifying an OU, you must set search_scope=SUBTREE in airflow.cfg.",
            "            %s",
            "            \"\"\" % traceback.format_exc())",
            "            raise LdapException(",
            "                \"Could not parse LDAP structure. \"",
            "                \"Try setting search_scope in airflow.cfg, or check logs\"",
            "            )",
            "",
            "        if not conn:",
            "            log.info(\"Password incorrect for user %s\", username)",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "    @property",
            "    def is_active(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return True",
            "",
            "    @property",
            "    def is_authenticated(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return True",
            "",
            "    @property",
            "    def is_anonymous(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return False",
            "",
            "    def get_id(self):",
            "        \"\"\"Returns the current user id as required by flask_login\"\"\"",
            "        return self.user.get_id()",
            "",
            "    def data_profiling(self):",
            "        \"\"\"Provides access to data profiling tools\"\"\"",
            "        return self.data_profiler",
            "",
            "    def is_superuser(self):",
            "        \"\"\"Access all the things\"\"\"",
            "        return self.superuser",
            "",
            "",
            "@login_manager.user_loader",
            "@provide_session",
            "def load_user(userid, session=None):",
            "    log.debug(\"Loading user %s\", userid)",
            "    if not userid or userid == 'None':",
            "        return None",
            "",
            "    user = session.query(models.User).filter(models.User.id == int(userid)).first()",
            "    return LdapUser(user)",
            "",
            "",
            "@provide_session",
            "def login(self, request, session=None):",
            "    if current_user.is_authenticated:",
            "        flash(\"You are already logged in\")",
            "        return redirect(url_for('admin.index'))",
            "",
            "    username = None",
            "    password = None",
            "",
            "    form = LoginForm(request.form)",
            "",
            "    if request.method == 'POST' and form.validate():",
            "        username = request.form.get(\"username\")",
            "        password = request.form.get(\"password\")",
            "",
            "    if not username or not password:",
            "        return self.render('airflow/login.html',",
            "                           title=\"Airflow - Login\",",
            "                           form=form)",
            "",
            "    try:",
            "        LdapUser.try_login(username, password)",
            "        log.info(\"User %s successfully authenticated\", username)",
            "",
            "        user = session.query(models.User).filter(",
            "            models.User.username == username).first()",
            "",
            "        if not user:",
            "            user = models.User(",
            "                username=username,",
            "                is_superuser=False)",
            "            session.add(user)",
            "",
            "        session.commit()",
            "        session.merge(user)",
            "        flask_login.login_user(LdapUser(user))",
            "        session.commit()",
            "",
            "        return redirect(request.args.get(\"next\") or url_for(\"admin.index\"))",
            "    except (LdapException, AuthenticationError) as e:",
            "        if type(e) == LdapException:",
            "            flash(e, \"error\")",
            "        else:",
            "            flash(\"Incorrect login details\")",
            "        return self.render('airflow/login.html',",
            "                           title=\"Airflow - Login\",",
            "                           form=form)",
            "",
            "",
            "class LoginForm(Form):",
            "    username = StringField('Username', [InputRequired()])",
            "    password = PasswordField('Password', [InputRequired()])"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from future.utils import native",
            "",
            "import flask_login",
            "from flask_login import login_required, current_user, logout_user",
            "from flask import flash",
            "from wtforms import (",
            "    Form, PasswordField, StringField)",
            "from wtforms.validators import InputRequired",
            "",
            "from ldap3 import Server, Connection, Tls, LEVEL, SUBTREE, BASE",
            "import ssl",
            "",
            "from flask import url_for, redirect",
            "",
            "from airflow import models",
            "from airflow import configuration",
            "from airflow.configuration import AirflowConfigException",
            "from airflow.utils.db import provide_session",
            "",
            "import traceback",
            "import re",
            "",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "",
            "login_manager = flask_login.LoginManager()",
            "login_manager.login_view = 'airflow.login'  # Calls login() below",
            "login_manager.login_message = None",
            "",
            "log = LoggingMixin().log",
            "",
            "",
            "class AuthenticationError(Exception):",
            "    pass",
            "",
            "",
            "class LdapException(Exception):",
            "    pass",
            "",
            "",
            "def get_ldap_connection(dn=None, password=None):",
            "    try:",
            "        cacert = configuration.conf.get(\"ldap\", \"cacert\")",
            "    except AirflowConfigException:",
            "        pass",
            "",
            "    tls_configuration = Tls(validate=ssl.CERT_REQUIRED,",
            "                            ca_certs_file=cacert)",
            "",
            "    server = Server(configuration.conf.get(\"ldap\", \"uri\"),",
            "                    use_ssl=True,",
            "                    tls=tls_configuration)",
            "",
            "    conn = Connection(server, native(dn), native(password))",
            "",
            "    if not conn.bind():",
            "        log.error(\"Cannot bind to ldap server: %s \", conn.last_error)",
            "        raise AuthenticationError(\"Cannot bind to ldap server\")",
            "",
            "    return conn",
            "",
            "",
            "def group_contains_user(conn, search_base, group_filter, user_name_attr, username):",
            "    search_filter = '(&({0}))'.format(group_filter)",
            "",
            "    if not conn.search(native(search_base), native(search_filter),",
            "                       attributes=[native(user_name_attr)]):",
            "        log.warning(\"Unable to find group for %s %s\", search_base, search_filter)",
            "    else:",
            "        for entry in conn.entries:",
            "            if username.lower() in map(lambda attr: attr.lower(),",
            "                                       getattr(entry, user_name_attr).values):",
            "                return True",
            "",
            "    return False",
            "",
            "",
            "def groups_user(conn, search_base, user_filter, user_name_att, username):",
            "    search_filter = \"(&({0})({1}={2}))\".format(user_filter, user_name_att, username)",
            "    try:",
            "        memberof_attr = configuration.conf.get(\"ldap\", \"group_member_attr\")",
            "    except Exception:",
            "        memberof_attr = \"memberOf\"",
            "    res = conn.search(native(search_base), native(search_filter),",
            "                      attributes=[native(memberof_attr)])",
            "    if not res:",
            "        log.info(\"Cannot find user %s\", username)",
            "        raise AuthenticationError(\"Invalid username or password\")",
            "",
            "    if conn.response and memberof_attr not in conn.response[0][\"attributes\"]:",
            "        log.warning(\"\"\"Missing attribute \"%s\" when looked-up in Ldap database.",
            "        The user does not seem to be a member of a group and therefore won't see any dag",
            "        if the option filter_by_owner=True and owner_mode=ldapgroup are set\"\"\",",
            "                    memberof_attr)",
            "        return []",
            "",
            "    user_groups = conn.response[0][\"attributes\"][memberof_attr]",
            "",
            "    regex = re.compile(\"cn=([^,]*).*\", re.IGNORECASE)",
            "    groups_list = []",
            "    try:",
            "        groups_list = [regex.search(i).group(1) for i in user_groups]",
            "    except IndexError:",
            "        log.warning(\"Parsing error when retrieving the user's group(s).\"",
            "                    \" Check if the user belongs to at least one group\"",
            "                    \" or if the user's groups name do not contain special characters\")",
            "",
            "    return groups_list",
            "",
            "",
            "class LdapUser(models.User):",
            "    def __init__(self, user):",
            "        self.user = user",
            "        self.ldap_groups = []",
            "",
            "        # Load and cache superuser and data_profiler settings.",
            "        conn = get_ldap_connection(configuration.conf.get(\"ldap\", \"bind_user\"),",
            "                                   configuration.conf.get(\"ldap\", \"bind_password\"))",
            "",
            "        superuser_filter = None",
            "        data_profiler_filter = None",
            "        try:",
            "            superuser_filter = configuration.conf.get(\"ldap\", \"superuser_filter\")",
            "        except AirflowConfigException:",
            "            pass",
            "",
            "        if not superuser_filter:",
            "            self.superuser = True",
            "            log.debug(\"Missing configuration for superuser settings or empty. Skipping.\")",
            "        else:",
            "            self.superuser = group_contains_user(conn,",
            "                                                 configuration.conf.get(\"ldap\", \"basedn\"),",
            "                                                 superuser_filter,",
            "                                                 configuration.conf.get(\"ldap\",",
            "                                                                        \"user_name_attr\"),",
            "                                                 user.username)",
            "",
            "        try:",
            "            data_profiler_filter = configuration.conf.get(\"ldap\", \"data_profiler_filter\")",
            "        except AirflowConfigException:",
            "            pass",
            "",
            "        if not data_profiler_filter:",
            "            self.data_profiler = True",
            "            log.debug(\"Missing configuration for data profiler settings or empty. \"",
            "                      \"Skipping.\")",
            "        else:",
            "            self.data_profiler = group_contains_user(",
            "                conn,",
            "                configuration.conf.get(\"ldap\", \"basedn\"),",
            "                data_profiler_filter,",
            "                configuration.conf.get(\"ldap\",",
            "                                       \"user_name_attr\"),",
            "                user.username",
            "            )",
            "",
            "        # Load the ldap group(s) a user belongs to",
            "        try:",
            "            self.ldap_groups = groups_user(",
            "                conn,",
            "                configuration.conf.get(\"ldap\", \"basedn\"),",
            "                configuration.conf.get(\"ldap\", \"user_filter\"),",
            "                configuration.conf.get(\"ldap\", \"user_name_attr\"),",
            "                user.username",
            "            )",
            "        except AirflowConfigException:",
            "            log.debug(\"Missing configuration for ldap settings. Skipping\")",
            "",
            "    @staticmethod",
            "    def try_login(username, password):",
            "        conn = get_ldap_connection(configuration.conf.get(\"ldap\", \"bind_user\"),",
            "                                   configuration.conf.get(\"ldap\", \"bind_password\"))",
            "",
            "        search_filter = \"(&({0})({1}={2}))\".format(",
            "            configuration.conf.get(\"ldap\", \"user_filter\"),",
            "            configuration.conf.get(\"ldap\", \"user_name_attr\"),",
            "            username",
            "        )",
            "",
            "        search_scope = LEVEL",
            "        if configuration.conf.has_option(\"ldap\", \"search_scope\"):",
            "            if configuration.conf.get(\"ldap\", \"search_scope\") == \"SUBTREE\":",
            "                search_scope = SUBTREE",
            "            else:",
            "                search_scope = LEVEL",
            "",
            "        # todo: BASE or ONELEVEL?",
            "",
            "        res = conn.search(native(configuration.conf.get(\"ldap\", \"basedn\")),",
            "                          native(search_filter),",
            "                          search_scope=native(search_scope))",
            "",
            "        # todo: use list or result?",
            "        if not res:",
            "            log.info(\"Cannot find user %s\", username)",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "        entry = conn.response[0]",
            "",
            "        conn.unbind()",
            "",
            "        if 'dn' not in entry:",
            "            # The search filter for the user did not return any values, so an",
            "            # invalid user was used for credentials.",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "        try:",
            "            conn = get_ldap_connection(entry['dn'], password)",
            "        except KeyError:",
            "            log.error(\"\"\"",
            "            Unable to parse LDAP structure. If you're using Active Directory",
            "            and not specifying an OU, you must set search_scope=SUBTREE in airflow.cfg.",
            "            %s",
            "            \"\"\" % traceback.format_exc())",
            "            raise LdapException(",
            "                \"Could not parse LDAP structure. \"",
            "                \"Try setting search_scope in airflow.cfg, or check logs\"",
            "            )",
            "",
            "        if not conn:",
            "            log.info(\"Password incorrect for user %s\", username)",
            "            raise AuthenticationError(\"Invalid username or password\")",
            "",
            "    @property",
            "    def is_active(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return True",
            "",
            "    @property",
            "    def is_authenticated(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return True",
            "",
            "    @property",
            "    def is_anonymous(self):",
            "        \"\"\"Required by flask_login\"\"\"",
            "        return False",
            "",
            "    def get_id(self):",
            "        \"\"\"Returns the current user id as required by flask_login\"\"\"",
            "        return self.user.get_id()",
            "",
            "    def data_profiling(self):",
            "        \"\"\"Provides access to data profiling tools\"\"\"",
            "        return self.data_profiler",
            "",
            "    def is_superuser(self):",
            "        \"\"\"Access all the things\"\"\"",
            "        return self.superuser",
            "",
            "",
            "@login_manager.user_loader",
            "@provide_session",
            "def load_user(userid, session=None):",
            "    log.debug(\"Loading user %s\", userid)",
            "    if not userid or userid == 'None':",
            "        return None",
            "",
            "    user = session.query(models.User).filter(models.User.id == int(userid)).first()",
            "    return LdapUser(user)",
            "",
            "",
            "@provide_session",
            "def login(self, request, session=None):",
            "    if current_user.is_authenticated:",
            "        flash(\"You are already logged in\")",
            "        return redirect(url_for('admin.index'))",
            "",
            "    username = None",
            "    password = None",
            "",
            "    form = LoginForm(request.form)",
            "",
            "    if request.method == 'POST' and form.validate():",
            "        username = request.form.get(\"username\")",
            "        password = request.form.get(\"password\")",
            "",
            "    if not username or not password:",
            "        return self.render('airflow/login.html',",
            "                           title=\"Airflow - Login\",",
            "                           form=form)",
            "",
            "    try:",
            "        LdapUser.try_login(username, password)",
            "        log.info(\"User %s successfully authenticated\", username)",
            "",
            "        user = session.query(models.User).filter(",
            "            models.User.username == username).first()",
            "",
            "        if not user:",
            "            user = models.User(",
            "                username=username,",
            "                is_superuser=False)",
            "            session.add(user)",
            "",
            "        session.commit()",
            "        session.merge(user)",
            "        flask_login.login_user(LdapUser(user))",
            "        session.commit()",
            "",
            "        return redirect(request.args.get(\"next\") or url_for(\"admin.index\"))",
            "    except (LdapException, AuthenticationError) as e:",
            "        if type(e) == LdapException:",
            "            flash(e, \"error\")",
            "        else:",
            "            flash(\"Incorrect login details\")",
            "        return self.render('airflow/login.html',",
            "                           title=\"Airflow - Login\",",
            "                           form=form)",
            "",
            "",
            "class LoginForm(Form):",
            "    username = StringField('Username', [InputRequired()])",
            "    password = PasswordField('Password', [InputRequired()])"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "59": [
                "get_ldap_connection"
            ],
            "60": [
                "get_ldap_connection"
            ],
            "63": [
                "get_ldap_connection"
            ],
            "64": [
                "get_ldap_connection"
            ],
            "65": [
                "get_ldap_connection"
            ],
            "68": [
                "get_ldap_connection"
            ]
        },
        "addLocation": []
    },
    "setup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "             'snakebite[kerberos]>=2.7.8']"
            },
            "1": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 189,
                "PatchRowcode": " kubernetes = ['kubernetes>=3.0.0',"
            },
            "2": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "               'cryptography>=2.0.0']"
            },
            "3": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-ldap = ['ldap3>=0.9.9.1']"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 191,
                "PatchRowcode": "+ldap = ['ldap3>=2.5.1']"
            },
            "5": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 192,
                "PatchRowcode": " mssql = ['pymssql>=2.1.1']"
            },
            "6": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 193,
                "PatchRowcode": " mysql = ['mysqlclient>=1.3.6']"
            },
            "7": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 194,
                "PatchRowcode": " oracle = ['cx_Oracle>=5.1.2']"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "from setuptools import setup, find_packages, Command",
            "from setuptools.command.test import test as TestCommand",
            "",
            "import imp",
            "import logging",
            "import os",
            "import sys",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "# Kept manually in sync with airflow.__version__",
            "version = imp.load_source(",
            "    'airflow.version', os.path.join('airflow', 'version.py')).version",
            "",
            "PY3 = sys.version_info[0] == 3",
            "",
            "",
            "# See LEGAL-362",
            "def verify_gpl_dependency():",
            "    # The Read the Docs build environment [1] does a pip install of Airflow which cannot",
            "    # be overridden with custom environment variables, so we detect the READTHEDOCS env",
            "    # var they provide to set the env var that avoids the GPL dependency on install when",
            "    # building the docs site.",
            "    # [1]: http://docs.readthedocs.io/en/latest/builds.html#build-environment",
            "    if os.getenv(\"READTHEDOCS\") == \"True\":",
            "        os.environ[\"SLUGIFY_USES_TEXT_UNIDECODE\"] = \"yes\"",
            "",
            "    if (not os.getenv(\"AIRFLOW_GPL_UNIDECODE\")",
            "            and not os.getenv(\"SLUGIFY_USES_TEXT_UNIDECODE\") == \"yes\"):",
            "        raise RuntimeError(\"By default one of Airflow's dependencies installs a GPL \"",
            "                           \"dependency (unidecode). To avoid this dependency set \"",
            "                           \"SLUGIFY_USES_TEXT_UNIDECODE=yes in your environment when you \"",
            "                           \"install or upgrade Airflow. To force installing the GPL \"",
            "                           \"version set AIRFLOW_GPL_UNIDECODE\")",
            "",
            "",
            "class Tox(TestCommand):",
            "    user_options = [('tox-args=', None, \"Arguments to pass to tox\")]",
            "",
            "    def initialize_options(self):",
            "        TestCommand.initialize_options(self)",
            "        self.tox_args = ''",
            "",
            "    def finalize_options(self):",
            "        TestCommand.finalize_options(self)",
            "        self.test_args = []",
            "        self.test_suite = True",
            "",
            "    def run_tests(self):",
            "        # import here, cause outside the eggs aren't loaded",
            "        import tox",
            "        errno = tox.cmdline(args=self.tox_args.split())",
            "        sys.exit(errno)",
            "",
            "",
            "class CleanCommand(Command):",
            "    \"\"\"Custom clean command to tidy up the project root.\"\"\"",
            "    user_options = []",
            "",
            "    def initialize_options(self):",
            "        pass",
            "",
            "    def finalize_options(self):",
            "        pass",
            "",
            "    def run(self):",
            "        os.system('rm -vrf ./build ./dist ./*.pyc ./*.tgz ./*.egg-info')",
            "",
            "",
            "def git_version(version):",
            "    \"\"\"",
            "    Return a version to identify the state of the underlying git repo. The version will",
            "    indicate whether the head of the current git-backed working directory is tied to a",
            "    release tag or not : it will indicate the former with a 'release:{version}' prefix",
            "    and the latter with a 'dev0' prefix. Following the prefix will be a sha of the current",
            "    branch head. Finally, a \"dirty\" suffix is appended to indicate that uncommitted",
            "    changes are present.",
            "    \"\"\"",
            "    repo = None",
            "    try:",
            "        import git",
            "        repo = git.Repo('.git')",
            "    except ImportError:",
            "        logger.warning('gitpython not found: Cannot compute the git version.')",
            "        return ''",
            "    except Exception as e:",
            "        logger.warning('Cannot compute the git version. {}'.format(e))",
            "        return ''",
            "    if repo:",
            "        sha = repo.head.commit.hexsha",
            "        if repo.is_dirty():",
            "            return '.dev0+{sha}.dirty'.format(sha=sha)",
            "        # commit is clean",
            "        return '.release:{version}+{sha}'.format(version=version, sha=sha)",
            "    else:",
            "        return 'no_git_version'",
            "",
            "",
            "def write_version(filename=os.path.join(*['airflow',",
            "                                          'git_version'])):",
            "    text = \"{}\".format(git_version(version))",
            "    with open(filename, 'w') as a:",
            "        a.write(text)",
            "",
            "",
            "async_packages = [",
            "    'greenlet>=0.4.9',",
            "    'eventlet>= 0.9.7',",
            "    'gevent>=0.13'",
            "]",
            "atlas = ['atlasclient>=0.1.2']",
            "azure_blob_storage = ['azure-storage>=0.34.0']",
            "azure_data_lake = [",
            "    'azure-mgmt-resource==1.2.2',",
            "    'azure-mgmt-datalake-store==0.4.0',",
            "    'azure-datalake-store==0.0.19'",
            "]",
            "cassandra = ['cassandra-driver>=3.13.0']",
            "celery = [",
            "    'celery>=4.1.1, <4.2.0',",
            "    'flower>=0.7.3, <1.0'",
            "]",
            "cgroups = [",
            "    'cgroupspy>=0.1.4',",
            "]",
            "# major update coming soon, clamp to 0.x",
            "cloudant = ['cloudant>=0.5.9,<2.0']",
            "crypto = ['cryptography>=0.9.3']",
            "dask = [",
            "    'distributed>=1.17.1, <2'",
            "]",
            "databricks = ['requests>=2.5.1, <3']",
            "datadog = ['datadog>=0.14.0']",
            "doc = [",
            "    'mock',",
            "    'sphinx>=1.2.3',",
            "    'sphinx-argparse>=0.1.13',",
            "    'sphinx-rtd-theme>=0.1.6',",
            "    'Sphinx-PyPI-upload>=0.2.1'",
            "]",
            "docker = ['docker>=3.0.0']",
            "druid = ['pydruid>=0.4.1']",
            "elasticsearch = [",
            "    'elasticsearch>=5.0.0,<6.0.0',",
            "    'elasticsearch-dsl>=5.0.0,<6.0.0'",
            "]",
            "emr = ['boto3>=1.0.0, <1.8.0']",
            "gcp_api = [",
            "    'httplib2>=0.9.2',",
            "    'google-api-python-client>=1.6.0, <2.0.0dev',",
            "    'google-auth>=1.0.0, <2.0.0dev',",
            "    'google-auth-httplib2>=0.0.1',",
            "    'google-cloud-container>=0.1.1',",
            "    'PyOpenSSL',",
            "    'pandas-gbq'",
            "]",
            "github_enterprise = ['Flask-OAuthlib>=0.9.1']",
            "hdfs = ['snakebite>=2.7.8']",
            "hive = [",
            "    'hmsclient>=0.1.0',",
            "    'pyhive>=0.6.0',",
            "]",
            "jdbc = ['jaydebeapi>=1.1.1']",
            "jenkins = ['python-jenkins>=0.4.15']",
            "jira = ['JIRA>1.0.7']",
            "kerberos = ['pykerberos>=1.1.13',",
            "            'requests_kerberos>=0.10.0',",
            "            'thrift_sasl>=0.2.0',",
            "            'snakebite[kerberos]>=2.7.8']",
            "kubernetes = ['kubernetes>=3.0.0',",
            "              'cryptography>=2.0.0']",
            "ldap = ['ldap3>=0.9.9.1']",
            "mssql = ['pymssql>=2.1.1']",
            "mysql = ['mysqlclient>=1.3.6']",
            "oracle = ['cx_Oracle>=5.1.2']",
            "password = [",
            "    'bcrypt>=2.0.0',",
            "    'flask-bcrypt>=0.7.1',",
            "]",
            "pinot = ['pinotdb>=0.1.1']",
            "postgres = ['psycopg2-binary>=2.7.4']",
            "qds = ['qds-sdk>=1.9.6']",
            "rabbitmq = ['librabbitmq>=1.6.1']",
            "redis = ['redis>=2.10.5']",
            "s3 = ['boto3>=1.7.0, <1.8.0']",
            "salesforce = ['simple-salesforce>=0.72']",
            "samba = ['pysmbclient>=0.1.3']",
            "segment = ['analytics-python>=1.2.9']",
            "sendgrid = ['sendgrid>=5.2.0']",
            "slack = ['slackclient>=1.0.0']",
            "mongo = ['pymongo>=3.6.0']",
            "snowflake = ['snowflake-connector-python>=1.5.2',",
            "             'snowflake-sqlalchemy>=1.1.0']",
            "ssh = ['paramiko>=2.1.1', 'pysftp>=0.2.9', 'sshtunnel>=0.1.4,<0.2']",
            "statsd = ['statsd>=3.0.1, <4.0']",
            "vertica = ['vertica-python>=0.5.1']",
            "webhdfs = ['hdfs[dataframe,avro,kerberos]>=2.0.4']",
            "winrm = ['pywinrm==0.2.2']",
            "zendesk = ['zdesk']",
            "",
            "all_dbs = postgres + mysql + hive + mssql + hdfs + vertica + cloudant + druid + pinot \\",
            "    + cassandra + mongo",
            "",
            "devel = [",
            "    'click==6.7',",
            "    'freezegun',",
            "    'jira',",
            "    'lxml>=3.3.4',",
            "    'mock',",
            "    'mongomock',",
            "    'moto==1.1.19',",
            "    'nose',",
            "    'nose-ignore-docstring==0.2',",
            "    'nose-timer',",
            "    'parameterized',",
            "    'paramiko',",
            "    'pysftp',",
            "    'pywinrm',",
            "    'qds-sdk>=1.9.6',",
            "    'rednose',",
            "    'requests_mock'",
            "]",
            "devel_minreq = devel + kubernetes + mysql + doc + password + s3 + cgroups",
            "devel_hadoop = devel_minreq + hive + hdfs + webhdfs + kerberos",
            "devel_all = (sendgrid + devel + all_dbs + doc + samba + s3 + slack + crypto + oracle +",
            "             docker + ssh + kubernetes + celery + azure_blob_storage + redis + gcp_api +",
            "             datadog + zendesk + jdbc + ldap + kerberos + password + webhdfs + jenkins +",
            "             druid + pinot + segment + snowflake + elasticsearch + azure_data_lake +",
            "             atlas)",
            "",
            "# Snakebite & Google Cloud Dataflow are not Python 3 compatible :'(",
            "if PY3:",
            "    devel_ci = [package for package in devel_all if package not in",
            "                ['snakebite>=2.7.8', 'snakebite[kerberos]>=2.7.8']]",
            "else:",
            "    devel_ci = devel_all + ['unittest2']",
            "",
            "",
            "def do_setup():",
            "    verify_gpl_dependency()",
            "    write_version()",
            "    setup(",
            "        name='apache-airflow',",
            "        description='Programmatically author, schedule and monitor data pipelines',",
            "        license='Apache License 2.0',",
            "        version=version,",
            "        packages=find_packages(exclude=['tests*']),",
            "        package_data={'': ['airflow/alembic.ini', \"airflow/git_version\"]},",
            "        include_package_data=True,",
            "        zip_safe=False,",
            "        scripts=['airflow/bin/airflow'],",
            "        install_requires=[",
            "            'alembic>=0.8.3, <0.9',",
            "            'bleach~=2.1.3',",
            "            'configparser>=3.5.0, <3.6.0',",
            "            'croniter>=0.3.17, <0.4',",
            "            'dill>=0.2.2, <0.3',",
            "            'flask>=0.12.4, <0.13',",
            "            'flask-appbuilder>=1.12, <2.0.0',",
            "            'flask-admin==1.4.1',",
            "            'flask-caching>=1.3.3, <1.4.0',",
            "            'flask-login>=0.3, <0.5',",
            "            'flask-swagger==0.2.13',",
            "            'flask-wtf>=0.14.2, <0.15',",
            "            'funcsigs==1.0.0',",
            "            'future>=0.16.0, <0.17',",
            "            'gitpython>=2.0.2',",
            "            'gunicorn>=19.4.0, <20.0',",
            "            'iso8601>=0.1.12',",
            "            'jinja2>=2.7.3, <2.9.0',",
            "            'lxml>=3.6.0, <4.0',",
            "            'markdown>=2.5.2, <3.0',",
            "            'pandas>=0.17.1, <1.0.0',",
            "            'pendulum==1.4.4',",
            "            'psutil>=4.2.0, <5.0.0',",
            "            'pygments>=2.0.1, <3.0',",
            "            'python-daemon>=2.1.1, <2.2',",
            "            'python-dateutil>=2.3, <3',",
            "            'python-nvd3==0.15.0',",
            "            'requests>=2.5.1, <3',",
            "            'setproctitle>=1.1.8, <2',",
            "            'sqlalchemy>=1.1.15, <1.2.0',",
            "            'tabulate>=0.7.5, <=0.8.2',",
            "            'tenacity==4.8.0',",
            "            'thrift>=0.9.2',",
            "            'tzlocal>=1.4',",
            "            'unicodecsv>=0.14.1',",
            "            'werkzeug>=0.14.1, <0.15.0',",
            "            'zope.deprecation>=4.0, <5.0',",
            "        ],",
            "        setup_requires=[",
            "            'docutils>=0.14, <1.0',",
            "        ],",
            "        extras_require={",
            "            'all': devel_all,",
            "            'devel_ci': devel_ci,",
            "            'all_dbs': all_dbs,",
            "            'atlas': atlas,",
            "            'async': async_packages,",
            "            'azure_blob_storage': azure_blob_storage,",
            "            'azure_data_lake': azure_data_lake,",
            "            'cassandra': cassandra,",
            "            'celery': celery,",
            "            'cgroups': cgroups,",
            "            'cloudant': cloudant,",
            "            'crypto': crypto,",
            "            'dask': dask,",
            "            'databricks': databricks,",
            "            'datadog': datadog,",
            "            'devel': devel_minreq,",
            "            'devel_hadoop': devel_hadoop,",
            "            'doc': doc,",
            "            'docker': docker,",
            "            'druid': druid,",
            "            'elasticsearch': elasticsearch,",
            "            'emr': emr,",
            "            'gcp_api': gcp_api,",
            "            'github_enterprise': github_enterprise,",
            "            'hdfs': hdfs,",
            "            'hive': hive,",
            "            'jdbc': jdbc,",
            "            'jira': jira,",
            "            'kerberos': kerberos,",
            "            'kubernetes': kubernetes,",
            "            'ldap': ldap,",
            "            'mongo': mongo,",
            "            'mssql': mssql,",
            "            'mysql': mysql,",
            "            'oracle': oracle,",
            "            'password': password,",
            "            'pinot': pinot,",
            "            'postgres': postgres,",
            "            'qds': qds,",
            "            'rabbitmq': rabbitmq,",
            "            'redis': redis,",
            "            's3': s3,",
            "            'salesforce': salesforce,",
            "            'samba': samba,",
            "            'sendgrid': sendgrid,",
            "            'segment': segment,",
            "            'slack': slack,",
            "            'snowflake': snowflake,",
            "            'ssh': ssh,",
            "            'statsd': statsd,",
            "            'vertica': vertica,",
            "            'webhdfs': webhdfs,",
            "            'winrm': winrm",
            "        },",
            "        classifiers=[",
            "            'Development Status :: 5 - Production/Stable',",
            "            'Environment :: Console',",
            "            'Environment :: Web Environment',",
            "            'Intended Audience :: Developers',",
            "            'Intended Audience :: System Administrators',",
            "            'License :: OSI Approved :: Apache Software License',",
            "            'Programming Language :: Python :: 2.7',",
            "            'Programming Language :: Python :: 3.4',",
            "            'Programming Language :: Python :: 3.5',",
            "            'Topic :: System :: Monitoring',",
            "        ],",
            "        author='Apache Software Foundation',",
            "        author_email='dev@airflow.incubator.apache.org',",
            "        url='http://airflow.incubator.apache.org/',",
            "        download_url=(",
            "            'https://dist.apache.org/repos/dist/release/incubator/airflow/' + version),",
            "        cmdclass={",
            "            'test': Tox,",
            "            'extra_clean': CleanCommand,",
            "        },",
            "        python_requires='>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*',",
            "    )",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    do_setup()"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "from setuptools import setup, find_packages, Command",
            "from setuptools.command.test import test as TestCommand",
            "",
            "import imp",
            "import logging",
            "import os",
            "import sys",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "# Kept manually in sync with airflow.__version__",
            "version = imp.load_source(",
            "    'airflow.version', os.path.join('airflow', 'version.py')).version",
            "",
            "PY3 = sys.version_info[0] == 3",
            "",
            "",
            "# See LEGAL-362",
            "def verify_gpl_dependency():",
            "    # The Read the Docs build environment [1] does a pip install of Airflow which cannot",
            "    # be overridden with custom environment variables, so we detect the READTHEDOCS env",
            "    # var they provide to set the env var that avoids the GPL dependency on install when",
            "    # building the docs site.",
            "    # [1]: http://docs.readthedocs.io/en/latest/builds.html#build-environment",
            "    if os.getenv(\"READTHEDOCS\") == \"True\":",
            "        os.environ[\"SLUGIFY_USES_TEXT_UNIDECODE\"] = \"yes\"",
            "",
            "    if (not os.getenv(\"AIRFLOW_GPL_UNIDECODE\")",
            "            and not os.getenv(\"SLUGIFY_USES_TEXT_UNIDECODE\") == \"yes\"):",
            "        raise RuntimeError(\"By default one of Airflow's dependencies installs a GPL \"",
            "                           \"dependency (unidecode). To avoid this dependency set \"",
            "                           \"SLUGIFY_USES_TEXT_UNIDECODE=yes in your environment when you \"",
            "                           \"install or upgrade Airflow. To force installing the GPL \"",
            "                           \"version set AIRFLOW_GPL_UNIDECODE\")",
            "",
            "",
            "class Tox(TestCommand):",
            "    user_options = [('tox-args=', None, \"Arguments to pass to tox\")]",
            "",
            "    def initialize_options(self):",
            "        TestCommand.initialize_options(self)",
            "        self.tox_args = ''",
            "",
            "    def finalize_options(self):",
            "        TestCommand.finalize_options(self)",
            "        self.test_args = []",
            "        self.test_suite = True",
            "",
            "    def run_tests(self):",
            "        # import here, cause outside the eggs aren't loaded",
            "        import tox",
            "        errno = tox.cmdline(args=self.tox_args.split())",
            "        sys.exit(errno)",
            "",
            "",
            "class CleanCommand(Command):",
            "    \"\"\"Custom clean command to tidy up the project root.\"\"\"",
            "    user_options = []",
            "",
            "    def initialize_options(self):",
            "        pass",
            "",
            "    def finalize_options(self):",
            "        pass",
            "",
            "    def run(self):",
            "        os.system('rm -vrf ./build ./dist ./*.pyc ./*.tgz ./*.egg-info')",
            "",
            "",
            "def git_version(version):",
            "    \"\"\"",
            "    Return a version to identify the state of the underlying git repo. The version will",
            "    indicate whether the head of the current git-backed working directory is tied to a",
            "    release tag or not : it will indicate the former with a 'release:{version}' prefix",
            "    and the latter with a 'dev0' prefix. Following the prefix will be a sha of the current",
            "    branch head. Finally, a \"dirty\" suffix is appended to indicate that uncommitted",
            "    changes are present.",
            "    \"\"\"",
            "    repo = None",
            "    try:",
            "        import git",
            "        repo = git.Repo('.git')",
            "    except ImportError:",
            "        logger.warning('gitpython not found: Cannot compute the git version.')",
            "        return ''",
            "    except Exception as e:",
            "        logger.warning('Cannot compute the git version. {}'.format(e))",
            "        return ''",
            "    if repo:",
            "        sha = repo.head.commit.hexsha",
            "        if repo.is_dirty():",
            "            return '.dev0+{sha}.dirty'.format(sha=sha)",
            "        # commit is clean",
            "        return '.release:{version}+{sha}'.format(version=version, sha=sha)",
            "    else:",
            "        return 'no_git_version'",
            "",
            "",
            "def write_version(filename=os.path.join(*['airflow',",
            "                                          'git_version'])):",
            "    text = \"{}\".format(git_version(version))",
            "    with open(filename, 'w') as a:",
            "        a.write(text)",
            "",
            "",
            "async_packages = [",
            "    'greenlet>=0.4.9',",
            "    'eventlet>= 0.9.7',",
            "    'gevent>=0.13'",
            "]",
            "atlas = ['atlasclient>=0.1.2']",
            "azure_blob_storage = ['azure-storage>=0.34.0']",
            "azure_data_lake = [",
            "    'azure-mgmt-resource==1.2.2',",
            "    'azure-mgmt-datalake-store==0.4.0',",
            "    'azure-datalake-store==0.0.19'",
            "]",
            "cassandra = ['cassandra-driver>=3.13.0']",
            "celery = [",
            "    'celery>=4.1.1, <4.2.0',",
            "    'flower>=0.7.3, <1.0'",
            "]",
            "cgroups = [",
            "    'cgroupspy>=0.1.4',",
            "]",
            "# major update coming soon, clamp to 0.x",
            "cloudant = ['cloudant>=0.5.9,<2.0']",
            "crypto = ['cryptography>=0.9.3']",
            "dask = [",
            "    'distributed>=1.17.1, <2'",
            "]",
            "databricks = ['requests>=2.5.1, <3']",
            "datadog = ['datadog>=0.14.0']",
            "doc = [",
            "    'mock',",
            "    'sphinx>=1.2.3',",
            "    'sphinx-argparse>=0.1.13',",
            "    'sphinx-rtd-theme>=0.1.6',",
            "    'Sphinx-PyPI-upload>=0.2.1'",
            "]",
            "docker = ['docker>=3.0.0']",
            "druid = ['pydruid>=0.4.1']",
            "elasticsearch = [",
            "    'elasticsearch>=5.0.0,<6.0.0',",
            "    'elasticsearch-dsl>=5.0.0,<6.0.0'",
            "]",
            "emr = ['boto3>=1.0.0, <1.8.0']",
            "gcp_api = [",
            "    'httplib2>=0.9.2',",
            "    'google-api-python-client>=1.6.0, <2.0.0dev',",
            "    'google-auth>=1.0.0, <2.0.0dev',",
            "    'google-auth-httplib2>=0.0.1',",
            "    'google-cloud-container>=0.1.1',",
            "    'PyOpenSSL',",
            "    'pandas-gbq'",
            "]",
            "github_enterprise = ['Flask-OAuthlib>=0.9.1']",
            "hdfs = ['snakebite>=2.7.8']",
            "hive = [",
            "    'hmsclient>=0.1.0',",
            "    'pyhive>=0.6.0',",
            "]",
            "jdbc = ['jaydebeapi>=1.1.1']",
            "jenkins = ['python-jenkins>=0.4.15']",
            "jira = ['JIRA>1.0.7']",
            "kerberos = ['pykerberos>=1.1.13',",
            "            'requests_kerberos>=0.10.0',",
            "            'thrift_sasl>=0.2.0',",
            "            'snakebite[kerberos]>=2.7.8']",
            "kubernetes = ['kubernetes>=3.0.0',",
            "              'cryptography>=2.0.0']",
            "ldap = ['ldap3>=2.5.1']",
            "mssql = ['pymssql>=2.1.1']",
            "mysql = ['mysqlclient>=1.3.6']",
            "oracle = ['cx_Oracle>=5.1.2']",
            "password = [",
            "    'bcrypt>=2.0.0',",
            "    'flask-bcrypt>=0.7.1',",
            "]",
            "pinot = ['pinotdb>=0.1.1']",
            "postgres = ['psycopg2-binary>=2.7.4']",
            "qds = ['qds-sdk>=1.9.6']",
            "rabbitmq = ['librabbitmq>=1.6.1']",
            "redis = ['redis>=2.10.5']",
            "s3 = ['boto3>=1.7.0, <1.8.0']",
            "salesforce = ['simple-salesforce>=0.72']",
            "samba = ['pysmbclient>=0.1.3']",
            "segment = ['analytics-python>=1.2.9']",
            "sendgrid = ['sendgrid>=5.2.0']",
            "slack = ['slackclient>=1.0.0']",
            "mongo = ['pymongo>=3.6.0']",
            "snowflake = ['snowflake-connector-python>=1.5.2',",
            "             'snowflake-sqlalchemy>=1.1.0']",
            "ssh = ['paramiko>=2.1.1', 'pysftp>=0.2.9', 'sshtunnel>=0.1.4,<0.2']",
            "statsd = ['statsd>=3.0.1, <4.0']",
            "vertica = ['vertica-python>=0.5.1']",
            "webhdfs = ['hdfs[dataframe,avro,kerberos]>=2.0.4']",
            "winrm = ['pywinrm==0.2.2']",
            "zendesk = ['zdesk']",
            "",
            "all_dbs = postgres + mysql + hive + mssql + hdfs + vertica + cloudant + druid + pinot \\",
            "    + cassandra + mongo",
            "",
            "devel = [",
            "    'click==6.7',",
            "    'freezegun',",
            "    'jira',",
            "    'lxml>=3.3.4',",
            "    'mock',",
            "    'mongomock',",
            "    'moto==1.1.19',",
            "    'nose',",
            "    'nose-ignore-docstring==0.2',",
            "    'nose-timer',",
            "    'parameterized',",
            "    'paramiko',",
            "    'pysftp',",
            "    'pywinrm',",
            "    'qds-sdk>=1.9.6',",
            "    'rednose',",
            "    'requests_mock'",
            "]",
            "devel_minreq = devel + kubernetes + mysql + doc + password + s3 + cgroups",
            "devel_hadoop = devel_minreq + hive + hdfs + webhdfs + kerberos",
            "devel_all = (sendgrid + devel + all_dbs + doc + samba + s3 + slack + crypto + oracle +",
            "             docker + ssh + kubernetes + celery + azure_blob_storage + redis + gcp_api +",
            "             datadog + zendesk + jdbc + ldap + kerberos + password + webhdfs + jenkins +",
            "             druid + pinot + segment + snowflake + elasticsearch + azure_data_lake +",
            "             atlas)",
            "",
            "# Snakebite & Google Cloud Dataflow are not Python 3 compatible :'(",
            "if PY3:",
            "    devel_ci = [package for package in devel_all if package not in",
            "                ['snakebite>=2.7.8', 'snakebite[kerberos]>=2.7.8']]",
            "else:",
            "    devel_ci = devel_all + ['unittest2']",
            "",
            "",
            "def do_setup():",
            "    verify_gpl_dependency()",
            "    write_version()",
            "    setup(",
            "        name='apache-airflow',",
            "        description='Programmatically author, schedule and monitor data pipelines',",
            "        license='Apache License 2.0',",
            "        version=version,",
            "        packages=find_packages(exclude=['tests*']),",
            "        package_data={'': ['airflow/alembic.ini', \"airflow/git_version\"]},",
            "        include_package_data=True,",
            "        zip_safe=False,",
            "        scripts=['airflow/bin/airflow'],",
            "        install_requires=[",
            "            'alembic>=0.8.3, <0.9',",
            "            'bleach~=2.1.3',",
            "            'configparser>=3.5.0, <3.6.0',",
            "            'croniter>=0.3.17, <0.4',",
            "            'dill>=0.2.2, <0.3',",
            "            'flask>=0.12.4, <0.13',",
            "            'flask-appbuilder>=1.12, <2.0.0',",
            "            'flask-admin==1.4.1',",
            "            'flask-caching>=1.3.3, <1.4.0',",
            "            'flask-login>=0.3, <0.5',",
            "            'flask-swagger==0.2.13',",
            "            'flask-wtf>=0.14.2, <0.15',",
            "            'funcsigs==1.0.0',",
            "            'future>=0.16.0, <0.17',",
            "            'gitpython>=2.0.2',",
            "            'gunicorn>=19.4.0, <20.0',",
            "            'iso8601>=0.1.12',",
            "            'jinja2>=2.7.3, <2.9.0',",
            "            'lxml>=3.6.0, <4.0',",
            "            'markdown>=2.5.2, <3.0',",
            "            'pandas>=0.17.1, <1.0.0',",
            "            'pendulum==1.4.4',",
            "            'psutil>=4.2.0, <5.0.0',",
            "            'pygments>=2.0.1, <3.0',",
            "            'python-daemon>=2.1.1, <2.2',",
            "            'python-dateutil>=2.3, <3',",
            "            'python-nvd3==0.15.0',",
            "            'requests>=2.5.1, <3',",
            "            'setproctitle>=1.1.8, <2',",
            "            'sqlalchemy>=1.1.15, <1.2.0',",
            "            'tabulate>=0.7.5, <=0.8.2',",
            "            'tenacity==4.8.0',",
            "            'thrift>=0.9.2',",
            "            'tzlocal>=1.4',",
            "            'unicodecsv>=0.14.1',",
            "            'werkzeug>=0.14.1, <0.15.0',",
            "            'zope.deprecation>=4.0, <5.0',",
            "        ],",
            "        setup_requires=[",
            "            'docutils>=0.14, <1.0',",
            "        ],",
            "        extras_require={",
            "            'all': devel_all,",
            "            'devel_ci': devel_ci,",
            "            'all_dbs': all_dbs,",
            "            'atlas': atlas,",
            "            'async': async_packages,",
            "            'azure_blob_storage': azure_blob_storage,",
            "            'azure_data_lake': azure_data_lake,",
            "            'cassandra': cassandra,",
            "            'celery': celery,",
            "            'cgroups': cgroups,",
            "            'cloudant': cloudant,",
            "            'crypto': crypto,",
            "            'dask': dask,",
            "            'databricks': databricks,",
            "            'datadog': datadog,",
            "            'devel': devel_minreq,",
            "            'devel_hadoop': devel_hadoop,",
            "            'doc': doc,",
            "            'docker': docker,",
            "            'druid': druid,",
            "            'elasticsearch': elasticsearch,",
            "            'emr': emr,",
            "            'gcp_api': gcp_api,",
            "            'github_enterprise': github_enterprise,",
            "            'hdfs': hdfs,",
            "            'hive': hive,",
            "            'jdbc': jdbc,",
            "            'jira': jira,",
            "            'kerberos': kerberos,",
            "            'kubernetes': kubernetes,",
            "            'ldap': ldap,",
            "            'mongo': mongo,",
            "            'mssql': mssql,",
            "            'mysql': mysql,",
            "            'oracle': oracle,",
            "            'password': password,",
            "            'pinot': pinot,",
            "            'postgres': postgres,",
            "            'qds': qds,",
            "            'rabbitmq': rabbitmq,",
            "            'redis': redis,",
            "            's3': s3,",
            "            'salesforce': salesforce,",
            "            'samba': samba,",
            "            'sendgrid': sendgrid,",
            "            'segment': segment,",
            "            'slack': slack,",
            "            'snowflake': snowflake,",
            "            'ssh': ssh,",
            "            'statsd': statsd,",
            "            'vertica': vertica,",
            "            'webhdfs': webhdfs,",
            "            'winrm': winrm",
            "        },",
            "        classifiers=[",
            "            'Development Status :: 5 - Production/Stable',",
            "            'Environment :: Console',",
            "            'Environment :: Web Environment',",
            "            'Intended Audience :: Developers',",
            "            'Intended Audience :: System Administrators',",
            "            'License :: OSI Approved :: Apache Software License',",
            "            'Programming Language :: Python :: 2.7',",
            "            'Programming Language :: Python :: 3.4',",
            "            'Programming Language :: Python :: 3.5',",
            "            'Topic :: System :: Monitoring',",
            "        ],",
            "        author='Apache Software Foundation',",
            "        author_email='dev@airflow.incubator.apache.org',",
            "        url='http://airflow.incubator.apache.org/',",
            "        download_url=(",
            "            'https://dist.apache.org/repos/dist/release/incubator/airflow/' + version),",
            "        cmdclass={",
            "            'test': Tox,",
            "            'extra_clean': CleanCommand,",
            "        },",
            "        python_requires='>=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*',",
            "    )",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    do_setup()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "191": [
                "ldap"
            ]
        },
        "addLocation": []
    }
}