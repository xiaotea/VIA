{
    "bikeshed/InputSource.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import requests"
            },
            "1": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " import tenacity"
            },
            "2": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+from . import config"
            },
            "4": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from .Line import Line"
            },
            "5": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     manager for temporarily switching to the directory of a file InputSource."
            },
            "8": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 41,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __new__(cls, sourceName: str):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    def __new__(cls, sourceName: str, **kwargs):"
            },
            "12": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "         \"\"\"Dispatches to the right subclass.\"\"\""
            },
            "13": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         if cls != InputSource:"
            },
            "14": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "             # Only take control of calls to InputSource(...) itself."
            },
            "15": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "             return super().__new__(cls)"
            },
            "16": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "         if sourceName == \"-\":"
            },
            "18": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return StdinInputSource(sourceName)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+            return StdinInputSource(sourceName, **kwargs)"
            },
            "20": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         if sourceName.startswith(\"https:\"):"
            },
            "21": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return UrlInputSource(sourceName)"
            },
            "22": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return FileInputSource(sourceName)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+            return UrlInputSource(sourceName, **kwargs)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+        return FileInputSource(sourceName, **kwargs)"
            },
            "25": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 53,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "     @abstractmethod"
            },
            "27": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "     def __str__(self) -> str:"
            },
            "28": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 158,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 159,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 160,
                "PatchRowcode": " class FileInputSource(InputSource):"
            },
            "31": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __init__(self, sourceName: str):"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+    def __init__(self, sourceName: str, *, chroot: bool, chrootPath: Optional[str] = None):"
            },
            "33": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "         self.sourceName = sourceName"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+        self.chrootPath = chrootPath"
            },
            "35": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "         self.type = \"file\""
            },
            "36": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         self.content = None"
            },
            "37": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 166,
                "PatchRowcode": " "
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+        if chroot and self.chrootPath is None:"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+            self.chrootPath = self.directory()"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+        if self.chrootPath is not None:"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+            self.sourceName = config.chrootPath(self.chrootPath, self.sourceName)"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+"
            },
            "43": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "     def __str__(self) -> str:"
            },
            "44": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "         return self.sourceName"
            },
            "45": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 174,
                "PatchRowcode": " "
            },
            "46": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "         return os.path.dirname(os.path.abspath(self.sourceName))"
            },
            "47": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 187,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "     def relative(self, relativePath) -> FileInputSource:"
            },
            "49": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return FileInputSource(os.path.join(self.directory(), relativePath))"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+        return FileInputSource(os.path.join(self.directory(), relativePath), chroot=False, chrootPath=self.chrootPath)"
            },
            "51": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 190,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "     def cheaplyExists(self, relativePath) -> bool:"
            },
            "53": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "         return os.access(self.relative(relativePath).sourceName, os.R_OK)"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import email.utils",
            "import errno",
            "import os",
            "import sys",
            "import urllib.parse",
            "from abc import abstractmethod",
            "from datetime import datetime",
            "from typing import List, Optional",
            "",
            "import attr",
            "import requests",
            "import tenacity",
            "",
            "from .Line import Line",
            "",
            "",
            "@attr.s(auto_attribs=True)",
            "class InputContent:",
            "    rawLines: List[str]",
            "    date: Optional[datetime.date]",
            "",
            "    @property",
            "    def lines(self) -> List[Line]:",
            "        return [Line(i, line) for i, line in enumerate(self.rawLines, 1)]",
            "",
            "    @property",
            "    def content(self) -> str:",
            "        return \"\".join(self.rawLines)",
            "",
            "",
            "class InputSource:",
            "    \"\"\"Represents a thing that can produce specification input text.",
            "",
            "    Input can be read from stdin (\"-\"), an HTTPS URL, or a file. Other",
            "    InputSources can be found relative to URLs and files, and there's a context",
            "    manager for temporarily switching to the directory of a file InputSource.",
            "    \"\"\"",
            "",
            "    def __new__(cls, sourceName: str):",
            "        \"\"\"Dispatches to the right subclass.\"\"\"",
            "        if cls != InputSource:",
            "            # Only take control of calls to InputSource(...) itself.",
            "            return super().__new__(cls)",
            "",
            "        if sourceName == \"-\":",
            "            return StdinInputSource(sourceName)",
            "        if sourceName.startswith(\"https:\"):",
            "            return UrlInputSource(sourceName)",
            "        return FileInputSource(sourceName)",
            "",
            "    @abstractmethod",
            "    def __str__(self) -> str:",
            "        pass",
            "",
            "    def __repr__(self) -> str:",
            "        return \"{}({!r})\".format(self.__class__.__name__, str(self))",
            "",
            "    def __hash__(self):",
            "        return hash(str(self))",
            "",
            "    def __eq__(self, other):",
            "        return str(self) == str(other)",
            "",
            "    @abstractmethod",
            "    def read(self) -> InputContent:",
            "        \"\"\"Fully reads the source.\"\"\"",
            "",
            "    def hasDirectory(self) -> bool:",
            "        \"\"\"Only some InputSources have a directory.\"\"\"",
            "        return False",
            "",
            "    def directory(self) -> str:",
            "        \"\"\"Suitable for passing to subprocess(cwd=).\"\"\"",
            "        raise TypeError(\"{} instances don't have directories.\".format(type(self)))",
            "",
            "    def relative(self, _) -> Optional[InputSource]:",
            "        \"\"\"Resolves relativePath relative to this InputSource.",
            "",
            "        For example, InputSource(\"/foo/bar/baz.txt\").relative(\"quux/fuzzy.txt\")",
            "        will be InputSource(\"/foo/bar/quux/fuzzy.txt\").",
            "",
            "        If this source type can't find others relative to itself, returns None.",
            "        \"\"\"",
            "        return None",
            "",
            "    def mtime(self) -> Optional[float]:",
            "        \"\"\"Returns the last modification time of this source, if that's known.\"\"\"",
            "        return None",
            "",
            "    def cheaplyExists(self, _) -> Optional[bool]:",
            "        \"\"\"If it's cheap to determine, returns whether relativePath exists.",
            "",
            "        Otherwise, returns None.",
            "        \"\"\"",
            "        return None",
            "",
            "    def __getattr__(self, name):",
            "        \"\"\"Hack to make pylint happy, since all the attrs are defined",
            "        on the subclasses that __new__ dynamically dispatches to.",
            "        See https://stackoverflow.com/a/60731663/455535",
            "        \"\"\"",
            "        print(f\"No member '{name}' contained in InputSource.\")",
            "        return \"\"",
            "",
            "",
            "class StdinInputSource(InputSource):",
            "    def __init__(self, sourceName: str):",
            "        assert sourceName == \"-\"",
            "        self.type = \"stdin\"",
            "        self.sourceName = sourceName",
            "        self.content = None",
            "",
            "    def __str__(self) -> str:",
            "        return \"-\"",
            "",
            "    def read(self) -> InputContent:",
            "        return InputContent(sys.stdin.readlines(), None)",
            "",
            "",
            "class UrlInputSource(InputSource):",
            "    def __init__(self, sourceName: str):",
            "        assert sourceName.startswith(\"https:\")",
            "        self.sourceName = sourceName",
            "        self.type = \"url\"",
            "",
            "    def __str__(self) -> str:",
            "        return self.sourceName",
            "",
            "    @tenacity.retry(",
            "        reraise=True,",
            "        stop=tenacity.stop_after_attempt(3),",
            "        wait=tenacity.wait_random(1, 2),",
            "    )",
            "    def _fetch(self):",
            "        response = requests.get(self.sourceName, timeout=10)",
            "        if response.status_code == 404:",
            "            # This matches the OSErrors expected by older uses of",
            "            # FileInputSource. It skips the retry, since the server has given us",
            "            # a concrete, expected answer.",
            "            raise FileNotFoundError(errno.ENOENT, response.text, self.sourceName)",
            "        response.raise_for_status()",
            "        return response",
            "",
            "    def read(self) -> InputContent:",
            "        response = self._fetch()",
            "        date = None",
            "        if \"Date\" in response.headers:",
            "            # Use the response's Date header, although servers don't always set",
            "            # this according to the last change to the file.",
            "            date = email.utils.parsedate_to_datetime(response.headers[\"Date\"]).date()",
            "        return InputContent(response.text.splitlines(True), date)",
            "",
            "    def relative(self, relativePath) -> UrlInputSource:",
            "        return UrlInputSource(urllib.parse.urljoin(self.sourceName, relativePath))",
            "",
            "",
            "class FileInputSource(InputSource):",
            "    def __init__(self, sourceName: str):",
            "        self.sourceName = sourceName",
            "        self.type = \"file\"",
            "        self.content = None",
            "",
            "    def __str__(self) -> str:",
            "        return self.sourceName",
            "",
            "    def read(self) -> InputContent:",
            "        with open(self.sourceName, encoding=\"utf-8\") as f:",
            "            return InputContent(",
            "                f.readlines(),",
            "                datetime.fromtimestamp(os.path.getmtime(self.sourceName)).date(),",
            "            )",
            "",
            "    def hasDirectory(self) -> bool:",
            "        return True",
            "",
            "    def directory(self) -> str:",
            "        return os.path.dirname(os.path.abspath(self.sourceName))",
            "",
            "    def relative(self, relativePath) -> FileInputSource:",
            "        return FileInputSource(os.path.join(self.directory(), relativePath))",
            "",
            "    def cheaplyExists(self, relativePath) -> bool:",
            "        return os.access(self.relative(relativePath).sourceName, os.R_OK)",
            "",
            "    def mtime(self) -> Optional[float]:",
            "        \"\"\"Returns the last modification time of this file, or None if it doesn't exist.\"\"\"",
            "        try:",
            "            return os.stat(self.sourceName).st_mtime",
            "        except FileNotFoundError:",
            "            return None"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import email.utils",
            "import errno",
            "import os",
            "import sys",
            "import urllib.parse",
            "from abc import abstractmethod",
            "from datetime import datetime",
            "from typing import List, Optional",
            "",
            "import attr",
            "import requests",
            "import tenacity",
            "",
            "from . import config",
            "from .Line import Line",
            "",
            "",
            "@attr.s(auto_attribs=True)",
            "class InputContent:",
            "    rawLines: List[str]",
            "    date: Optional[datetime.date]",
            "",
            "    @property",
            "    def lines(self) -> List[Line]:",
            "        return [Line(i, line) for i, line in enumerate(self.rawLines, 1)]",
            "",
            "    @property",
            "    def content(self) -> str:",
            "        return \"\".join(self.rawLines)",
            "",
            "",
            "class InputSource:",
            "    \"\"\"Represents a thing that can produce specification input text.",
            "",
            "    Input can be read from stdin (\"-\"), an HTTPS URL, or a file. Other",
            "    InputSources can be found relative to URLs and files, and there's a context",
            "    manager for temporarily switching to the directory of a file InputSource.",
            "    \"\"\"",
            "",
            "    def __new__(cls, sourceName: str, **kwargs):",
            "        \"\"\"Dispatches to the right subclass.\"\"\"",
            "        if cls != InputSource:",
            "            # Only take control of calls to InputSource(...) itself.",
            "            return super().__new__(cls)",
            "",
            "        if sourceName == \"-\":",
            "            return StdinInputSource(sourceName, **kwargs)",
            "        if sourceName.startswith(\"https:\"):",
            "            return UrlInputSource(sourceName, **kwargs)",
            "        return FileInputSource(sourceName, **kwargs)",
            "",
            "    @abstractmethod",
            "    def __str__(self) -> str:",
            "        pass",
            "",
            "    def __repr__(self) -> str:",
            "        return \"{}({!r})\".format(self.__class__.__name__, str(self))",
            "",
            "    def __hash__(self):",
            "        return hash(str(self))",
            "",
            "    def __eq__(self, other):",
            "        return str(self) == str(other)",
            "",
            "    @abstractmethod",
            "    def read(self) -> InputContent:",
            "        \"\"\"Fully reads the source.\"\"\"",
            "",
            "    def hasDirectory(self) -> bool:",
            "        \"\"\"Only some InputSources have a directory.\"\"\"",
            "        return False",
            "",
            "    def directory(self) -> str:",
            "        \"\"\"Suitable for passing to subprocess(cwd=).\"\"\"",
            "        raise TypeError(\"{} instances don't have directories.\".format(type(self)))",
            "",
            "    def relative(self, _) -> Optional[InputSource]:",
            "        \"\"\"Resolves relativePath relative to this InputSource.",
            "",
            "        For example, InputSource(\"/foo/bar/baz.txt\").relative(\"quux/fuzzy.txt\")",
            "        will be InputSource(\"/foo/bar/quux/fuzzy.txt\").",
            "",
            "        If this source type can't find others relative to itself, returns None.",
            "        \"\"\"",
            "        return None",
            "",
            "    def mtime(self) -> Optional[float]:",
            "        \"\"\"Returns the last modification time of this source, if that's known.\"\"\"",
            "        return None",
            "",
            "    def cheaplyExists(self, _) -> Optional[bool]:",
            "        \"\"\"If it's cheap to determine, returns whether relativePath exists.",
            "",
            "        Otherwise, returns None.",
            "        \"\"\"",
            "        return None",
            "",
            "    def __getattr__(self, name):",
            "        \"\"\"Hack to make pylint happy, since all the attrs are defined",
            "        on the subclasses that __new__ dynamically dispatches to.",
            "        See https://stackoverflow.com/a/60731663/455535",
            "        \"\"\"",
            "        print(f\"No member '{name}' contained in InputSource.\")",
            "        return \"\"",
            "",
            "",
            "class StdinInputSource(InputSource):",
            "    def __init__(self, sourceName: str):",
            "        assert sourceName == \"-\"",
            "        self.type = \"stdin\"",
            "        self.sourceName = sourceName",
            "        self.content = None",
            "",
            "    def __str__(self) -> str:",
            "        return \"-\"",
            "",
            "    def read(self) -> InputContent:",
            "        return InputContent(sys.stdin.readlines(), None)",
            "",
            "",
            "class UrlInputSource(InputSource):",
            "    def __init__(self, sourceName: str):",
            "        assert sourceName.startswith(\"https:\")",
            "        self.sourceName = sourceName",
            "        self.type = \"url\"",
            "",
            "    def __str__(self) -> str:",
            "        return self.sourceName",
            "",
            "    @tenacity.retry(",
            "        reraise=True,",
            "        stop=tenacity.stop_after_attempt(3),",
            "        wait=tenacity.wait_random(1, 2),",
            "    )",
            "    def _fetch(self):",
            "        response = requests.get(self.sourceName, timeout=10)",
            "        if response.status_code == 404:",
            "            # This matches the OSErrors expected by older uses of",
            "            # FileInputSource. It skips the retry, since the server has given us",
            "            # a concrete, expected answer.",
            "            raise FileNotFoundError(errno.ENOENT, response.text, self.sourceName)",
            "        response.raise_for_status()",
            "        return response",
            "",
            "    def read(self) -> InputContent:",
            "        response = self._fetch()",
            "        date = None",
            "        if \"Date\" in response.headers:",
            "            # Use the response's Date header, although servers don't always set",
            "            # this according to the last change to the file.",
            "            date = email.utils.parsedate_to_datetime(response.headers[\"Date\"]).date()",
            "        return InputContent(response.text.splitlines(True), date)",
            "",
            "    def relative(self, relativePath) -> UrlInputSource:",
            "        return UrlInputSource(urllib.parse.urljoin(self.sourceName, relativePath))",
            "",
            "",
            "class FileInputSource(InputSource):",
            "    def __init__(self, sourceName: str, *, chroot: bool, chrootPath: Optional[str] = None):",
            "        self.sourceName = sourceName",
            "        self.chrootPath = chrootPath",
            "        self.type = \"file\"",
            "        self.content = None",
            "",
            "        if chroot and self.chrootPath is None:",
            "            self.chrootPath = self.directory()",
            "        if self.chrootPath is not None:",
            "            self.sourceName = config.chrootPath(self.chrootPath, self.sourceName)",
            "",
            "    def __str__(self) -> str:",
            "        return self.sourceName",
            "",
            "    def read(self) -> InputContent:",
            "        with open(self.sourceName, encoding=\"utf-8\") as f:",
            "            return InputContent(",
            "                f.readlines(),",
            "                datetime.fromtimestamp(os.path.getmtime(self.sourceName)).date(),",
            "            )",
            "",
            "    def hasDirectory(self) -> bool:",
            "        return True",
            "",
            "    def directory(self) -> str:",
            "        return os.path.dirname(os.path.abspath(self.sourceName))",
            "",
            "    def relative(self, relativePath) -> FileInputSource:",
            "        return FileInputSource(os.path.join(self.directory(), relativePath), chroot=False, chrootPath=self.chrootPath)",
            "",
            "    def cheaplyExists(self, relativePath) -> bool:",
            "        return os.access(self.relative(relativePath).sourceName, os.R_OK)",
            "",
            "    def mtime(self) -> Optional[float]:",
            "        \"\"\"Returns the last modification time of this file, or None if it doesn't exist.\"\"\"",
            "        try:",
            "            return os.stat(self.sourceName).st_mtime",
            "        except FileNotFoundError:",
            "            return None"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "41": [
                "InputSource",
                "__new__"
            ],
            "48": [
                "InputSource",
                "__new__"
            ],
            "50": [
                "InputSource",
                "__new__"
            ],
            "51": [
                "InputSource",
                "__new__"
            ],
            "160": [
                "FileInputSource",
                "__init__"
            ],
            "182": [
                "FileInputSource",
                "relative"
            ]
        },
        "addLocation": []
    },
    "bikeshed/Spec.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "                 \"No input file specified, and no *.bs or *.src.html files found in current directory.\\nPlease specify an input file, or use - to pipe from STDIN.\""
            },
            "1": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "             )"
            },
            "2": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "             return"
            },
            "3": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.inputSource = InputSource(inputFilename)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+        self.inputSource = InputSource(inputFilename, chroot=constants.chroot)"
            },
            "5": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         self.transitiveDependencies = set()"
            },
            "6": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "         self.debug = debug"
            },
            "7": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         self.token = token"
            }
        },
        "frontPatchFile": [
            "import glob",
            "import os",
            "import sys",
            "from collections import defaultdict",
            "from functools import partial as curry",
            "",
            "from . import (",
            "    biblio,",
            "    boilerplate,",
            "    caniuse,",
            "    conditional,",
            "    config,",
            "    constants,",
            "    datablocks,",
            "    dfns,",
            "    extensions,",
            "    fingerprinting,",
            "    h,",
            "    headings,",
            "    highlight,",
            "    idl,",
            "    includes,",
            "    inlineTags,",
            "    lint,",
            "    markdown,",
            "    mdnspeclinks,",
            "    metadata,",
            "    shorthands,",
            "    wpt,",
            ")",
            "from .func import Functor",
            "from .h import *",
            "from .InputSource import FileInputSource, InputSource",
            "from .messages import *",
            "from .refs import ReferenceManager",
            "from .unsortedJunk import *",
            "",
            "",
            "class Spec:",
            "    def __init__(",
            "        self,",
            "        inputFilename,",
            "        debug=False,",
            "        token=None,",
            "        lineNumbers=False,",
            "        fileRequester=None,",
            "        testing=False,",
            "    ):",
            "        self.valid = False",
            "        self.lineNumbers = lineNumbers",
            "        if lineNumbers:",
            "            # line-numbers are too hacky, so force this to be a dry run",
            "            constants.dryRun = True",
            "        if inputFilename is None:",
            "            inputFilename = findImplicitInputFile()",
            "        if inputFilename is None:  # still",
            "            die(",
            "                \"No input file specified, and no *.bs or *.src.html files found in current directory.\\nPlease specify an input file, or use - to pipe from STDIN.\"",
            "            )",
            "            return",
            "        self.inputSource = InputSource(inputFilename)",
            "        self.transitiveDependencies = set()",
            "        self.debug = debug",
            "        self.token = token",
            "        self.testing = testing",
            "        if fileRequester is None:",
            "            self.dataFile = config.defaultRequester",
            "        else:",
            "            self.dataFile = fileRequester",
            "",
            "        self.md = None",
            "        self.mdBaseline = None",
            "        self.mdDocument = None",
            "        self.mdCommandLine = None",
            "        self.mdDefaults = None",
            "        self.mdOverridingDefaults = None",
            "        self.lines = []",
            "        self.document = None",
            "        self.html = None",
            "        self.head = None",
            "        self.body = None",
            "        self.fillContainers = None",
            "        self.valid = self.initializeState()",
            "",
            "    def initializeState(self):",
            "        self.normativeRefs = {}",
            "        self.informativeRefs = {}",
            "        self.refs = ReferenceManager(fileRequester=self.dataFile, testing=self.testing)",
            "        self.externalRefsUsed = defaultdict(lambda: defaultdict(dict))",
            "        self.md = None",
            "        self.mdBaseline = metadata.MetadataManager()",
            "        self.mdDocument = None",
            "        self.mdCommandLine = metadata.MetadataManager()",
            "        self.mdDefaults = None",
            "        self.mdOverridingDefaults = None",
            "        self.biblios = {}",
            "        self.typeExpansions = {}",
            "        self.macros = defaultdict(lambda x: \"???\")",
            "        self.canIUse = {}",
            "        self.mdnSpecLinks = {}",
            "        self.widl = idl.getParser()",
            "        self.testSuites = json.loads(self.dataFile.fetch(\"test-suites.json\", str=True))",
            "        self.languages = json.loads(self.dataFile.fetch(\"languages.json\", str=True))",
            "        self.extraStyles = defaultdict(str)",
            "        self.extraStyles[\"style-colors\"] = styleColors",
            "        self.extraStyles[\"style-darkmode\"] = styleDarkMode",
            "        self.extraStyles[\"style-md-lists\"] = styleMdLists",
            "        self.extraStyles[\"style-autolinks\"] = styleAutolinks",
            "        self.extraStyles[\"style-selflinks\"] = styleSelflinks",
            "        self.extraStyles[\"style-counters\"] = styleCounters",
            "        self.extraScripts = defaultdict(str)",
            "",
            "        try:",
            "            inputContent = self.inputSource.read()",
            "            self.lines = inputContent.lines",
            "            if inputContent.date is not None:",
            "                self.mdBaseline.addParsedData(\"Date\", inputContent.date)",
            "        except FileNotFoundError:",
            "            die(",
            "                \"Couldn't find the input file at the specified location '{0}'.\",",
            "                self.inputSource,",
            "            )",
            "            return False",
            "        except OSError:",
            "            die(\"Couldn't open the input file '{0}'.\", self.inputSource)",
            "            return False",
            "",
            "        return True",
            "",
            "    def recordDependencies(self, *inputSources):",
            "        self.transitiveDependencies.update(inputSources)",
            "",
            "    def preprocess(self):",
            "        self.transitiveDependencies.clear()",
            "        self.assembleDocument()",
            "        self.processDocument()",
            "",
            "    def assembleDocument(self):",
            "        # Textual hacks",
            "        stripBOM(self)",
            "        if self.lineNumbers:",
            "            self.lines = hackyLineNumbers(self.lines)",
            "        self.lines = markdown.stripComments(self.lines)",
            "        self.recordDependencies(self.inputSource)",
            "        # Extract and process metadata",
            "        self.lines, self.mdDocument = metadata.parse(lines=self.lines)",
            "        # First load the metadata sources from 'local' data",
            "        self.md = metadata.join(self.mdBaseline, self.mdDocument, self.mdCommandLine)",
            "        # Using that to determine the Group and Status, load the correct defaults.include boilerplate",
            "        self.mdDefaults = metadata.fromJson(",
            "            data=config.retrieveBoilerplateFile(self, \"defaults\", error=True),",
            "            source=\"defaults\",",
            "        )",
            "        self.md = metadata.join(",
            "            self.mdBaseline, self.mdDefaults, self.mdDocument, self.mdCommandLine",
            "        )",
            "        # Using all of that, load up the text macros so I can sub them into the computed-metadata file.",
            "        self.md.fillTextMacros(self.macros, doc=self)",
            "        jsonEscapedMacros = {k: json.dumps(v)[1:-1] for k, v in self.macros.items()}",
            "        computedMdText = replaceMacros(",
            "            config.retrieveBoilerplateFile(self, \"computed-metadata\", error=True),",
            "            macros=jsonEscapedMacros,",
            "        )",
            "        self.mdOverridingDefaults = metadata.fromJson(",
            "            data=computedMdText, source=\"computed-metadata\"",
            "        )",
            "        self.md = metadata.join(",
            "            self.mdBaseline,",
            "            self.mdDefaults,",
            "            self.mdOverridingDefaults,",
            "            self.mdDocument,",
            "            self.mdCommandLine,",
            "        )",
            "        # Finally, compute the \"implicit\" things.",
            "        self.md.computeImplicitMetadata(doc=self)",
            "        # And compute macros again, in case the preceding steps changed them.",
            "        self.md.fillTextMacros(self.macros, doc=self)",
            "        self.md.validate()",
            "        extensions.load(self)",
            "",
            "        # Initialize things",
            "        self.refs.initializeRefs(self)",
            "        self.refs.initializeBiblio()",
            "",
            "        # Deal with further <pre> blocks, and markdown",
            "        self.lines = datablocks.transformDataBlocks(self, self.lines)",
            "        self.lines = markdown.parse(",
            "            self.lines,",
            "            self.md.indent,",
            "            opaqueElements=self.md.opaqueElements,",
            "            blockElements=self.md.blockElements,",
            "        )",
            "        # Note that, currently, markdown.parse returns an array of strings, not of Line objects.",
            "",
            "        self.refs.setSpecData(self.md)",
            "",
            "        # Convert to a single string of html now, for convenience.",
            "        self.html = \"\".join(line.text for line in self.lines)",
            "        boilerplate.addHeaderFooter(self)",
            "        self.html = self.fixText(self.html)",
            "",
            "        # Build the document",
            "        self.document = parseDocument(self.html)",
            "        self.head = find(\"head\", self)",
            "        self.body = find(\"body\", self)",
            "        correctH1(self)",
            "        includes.processInclusions(self)",
            "        metadata.parseDoc(self)",
            "",
            "    def processDocument(self):",
            "        # Fill in and clean up a bunch of data",
            "        conditional.processConditionals(self)",
            "        self.fillContainers = locateFillContainers(self)",
            "        lint.exampleIDs(self)",
            "        boilerplate.addBikeshedVersion(self)",
            "        boilerplate.addCanonicalURL(self)",
            "        boilerplate.addFavicon(self)",
            "        boilerplate.addSpecVersion(self)",
            "        boilerplate.addStatusSection(self)",
            "        boilerplate.addLogo(self)",
            "        boilerplate.addCopyright(self)",
            "        boilerplate.addSpecMetadataSection(self)",
            "        boilerplate.addAbstract(self)",
            "        boilerplate.addExpiryNotice(self)",
            "        boilerplate.addObsoletionNotice(self)",
            "        boilerplate.addAtRisk(self)",
            "        addNoteHeaders(self)",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        wpt.processWptElements(self)",
            "        shorthands.run(self)",
            "        inlineTags.processTags(self)",
            "        canonicalizeShortcuts(self)",
            "        addImplicitAlgorithms(self)",
            "        fixManualDefTables(self)",
            "        headings.processHeadings(self)",
            "        checkVarHygiene(self)",
            "        processIssuesAndExamples(self)",
            "        idl.markupIDL(self)",
            "        inlineRemoteIssues(self)",
            "        addImageSize(self)",
            "",
            "        # Handle all the links",
            "        processBiblioLinks(self)",
            "        processDfns(self)",
            "        idl.processIDL(self)",
            "        dfns.annotateDfns(self)",
            "        formatArgumentdefTables(self)",
            "        formatElementdefTables(self)",
            "        processAutolinks(self)",
            "        biblio.dedupBiblioReferences(self)",
            "        verifyUsageOfAllLocalBiblios(self)",
            "        caniuse.addCanIUsePanels(self)",
            "        boilerplate.addIndexSection(self)",
            "        boilerplate.addExplicitIndexes(self)",
            "        boilerplate.addStyles(self)",
            "        boilerplate.addReferencesSection(self)",
            "        boilerplate.addPropertyIndex(self)",
            "        boilerplate.addIDLSection(self)",
            "        boilerplate.addIssuesSection(self)",
            "        boilerplate.addCustomBoilerplate(self)",
            "        headings.processHeadings(self, \"all\")  # again",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        boilerplate.addTOCSection(self)",
            "        addSelfLinks(self)",
            "        processAutolinks(self)",
            "        boilerplate.addAnnotations(self)",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        # Add MDN panels after all IDs/anchors have been added",
            "        mdnspeclinks.addMdnPanels(self)",
            "        highlight.addSyntaxHighlighting(self)",
            "        boilerplate.addBikeshedBoilerplate(self)",
            "        fingerprinting.addTrackingVector(self)",
            "        fixIntraDocumentReferences(self)",
            "        fixInterDocumentReferences(self)",
            "        removeMultipleLinks(self)",
            "        forceCrossorigin(self)",
            "        lint.brokenLinks(self)",
            "        lint.accidental2119(self)",
            "        lint.missingExposed(self)",
            "        lint.requiredIDs(self)",
            "        lint.unusedInternalDfns(self)",
            "",
            "        # Any final HTML cleanups",
            "        cleanupHTML(self)",
            "        if self.md.prepTR:",
            "            # Don't try and override the W3C's icon.",
            "            for el in findAll(\"[rel ~= 'icon']\", self):",
            "                removeNode(el)",
            "            # Make sure the W3C stylesheet is after all other styles.",
            "            for el in findAll(\"link\", self):",
            "                if el.get(\"href\").startswith(\"https://www.w3.org/StyleSheets/TR\"):",
            "                    appendChild(find(\"head\", self), el)",
            "            # Ensure that all W3C links are https.",
            "            for el in findAll(\"a\", self):",
            "                href = el.get(\"href\", \"\")",
            "                if href.startswith(\"http://www.w3.org\") or href.startswith(",
            "                    \"http://lists.w3.org\"",
            "                ):",
            "                    el.set(\"href\", \"https\" + href[4:])",
            "                text = el.text or \"\"",
            "                if text.startswith(\"http://www.w3.org\") or text.startswith(",
            "                    \"http://lists.w3.org\"",
            "                ):",
            "                    el.text = \"https\" + text[4:]",
            "            # Loaded from .include files",
            "            extensions.BSPrepTR(self)  # pylint: disable=no-member",
            "",
            "        return self",
            "",
            "    def serialize(self):",
            "        try:",
            "            rendered = h.Serializer(",
            "                self.md.opaqueElements, self.md.blockElements",
            "            ).serialize(self.document)",
            "        except Exception as e:",
            "            die(\"{0}\", e)",
            "            return",
            "        rendered = finalHackyCleanup(rendered)",
            "        return rendered",
            "",
            "    def fixMissingOutputFilename(self, outputFilename):",
            "        if outputFilename is None:",
            "            # More sensible defaults!",
            "            if not isinstance(self.inputSource, FileInputSource):",
            "                outputFilename = \"-\"",
            "            elif self.inputSource.sourceName.endswith(\".bs\"):",
            "                outputFilename = self.inputSource.sourceName[0:-3] + \".html\"",
            "            elif self.inputSource.sourceName.endswith(\".src.html\"):",
            "                outputFilename = self.inputSource.sourceName[0:-9] + \".html\"",
            "            else:",
            "                outputFilename = \"-\"",
            "        return outputFilename",
            "",
            "    def finish(self, outputFilename=None, newline=None):",
            "        self.printResultMessage()",
            "        outputFilename = self.fixMissingOutputFilename(outputFilename)",
            "        rendered = self.serialize()",
            "        if not constants.dryRun:",
            "            try:",
            "                if outputFilename == \"-\":",
            "                    sys.stdout.write(rendered)",
            "                else:",
            "                    with open(",
            "                        outputFilename, \"w\", encoding=\"utf-8\", newline=newline",
            "                    ) as f:",
            "                        f.write(rendered)",
            "            except Exception as e:",
            "                die(",
            "                    \"Something prevented me from saving the output document to {0}:\\n{1}\",",
            "                    outputFilename,",
            "                    e,",
            "                )",
            "",
            "    def printResultMessage(self):",
            "        # If I reach this point, I've succeeded, but maybe with reservations.",
            "        fatals = messageCounts[\"fatal\"]",
            "        links = messageCounts[\"linkerror\"]",
            "        warnings = messageCounts[\"warning\"]",
            "        if self.lineNumbers:",
            "            warn(\"Because --line-numbers was used, no output was saved.\")",
            "        if fatals:",
            "            success(\"Successfully generated, but fatal errors were suppressed\")",
            "            return",
            "        if links:",
            "            success(\"Successfully generated, with {0} linking errors\", links)",
            "            return",
            "        if warnings:",
            "            success(\"Successfully generated, with warnings\")",
            "            return",
            "",
            "    def watch(self, outputFilename, port=None, localhost=False):",
            "        import time",
            "",
            "        outputFilename = self.fixMissingOutputFilename(outputFilename)",
            "        if self.inputSource.mtime() is None:",
            "            die(f\"Watch mode doesn't support {self.inputSource}\")",
            "        if outputFilename == \"-\":",
            "            die(\"Watch mode doesn't support streaming to STDOUT.\")",
            "            return",
            "",
            "        if port:",
            "            # Serve the folder on an HTTP server",
            "            import http.server",
            "            import socketserver",
            "            import threading",
            "",
            "            class SilentServer(http.server.SimpleHTTPRequestHandler):",
            "                def log_message(self, format, *args):",
            "                    pass",
            "",
            "            socketserver.TCPServer.allow_reuse_address = True",
            "            server = socketserver.TCPServer(",
            "                (\"localhost\" if localhost else \"\", port), SilentServer",
            "            )",
            "",
            "            print(f\"Serving at port {port}\")",
            "            thread = threading.Thread(target=server.serve_forever)",
            "            thread.daemon = True",
            "            thread.start()",
            "        else:",
            "            server = None",
            "",
            "        mdCommandLine = self.mdCommandLine",
            "",
            "        try:",
            "            self.preprocess()",
            "            self.finish(outputFilename)",
            "            lastInputModified = {",
            "                dep: dep.mtime() for dep in self.transitiveDependencies",
            "            }",
            "            p(\"==============DONE==============\")",
            "            try:",
            "                while True:",
            "                    # Comparing mtimes with \"!=\" handles when a file starts or",
            "                    # stops existing, and it's fine to rebuild if an mtime",
            "                    # somehow gets older.",
            "                    if any(",
            "                        input.mtime() != lastModified",
            "                        for input, lastModified in lastInputModified.items()",
            "                    ):",
            "                        resetSeenMessages()",
            "                        p(\"Source file modified. Rebuilding...\")",
            "                        self.initializeState()",
            "                        self.mdCommandLine = mdCommandLine",
            "                        self.preprocess()",
            "                        self.finish(outputFilename)",
            "                        lastInputModified = {",
            "                            dep: dep.mtime() for dep in self.transitiveDependencies",
            "                        }",
            "                        p(\"==============DONE==============\")",
            "                    time.sleep(1)",
            "            except KeyboardInterrupt:",
            "                p(\"Exiting~\")",
            "                if server:",
            "                    server.shutdown()",
            "                    thread.join()",
            "                sys.exit(0)",
            "        except Exception as e:",
            "            die(\"Something went wrong while watching the file:\\n{0}\", e)",
            "",
            "    def fixText(self, text, moreMacros={}):",
            "        # Do several textual replacements that need to happen *before* the document is parsed as h.",
            "",
            "        # If markdown shorthands are on, remove all `foo`s while processing,",
            "        # so their contents don't accidentally trigger other stuff.",
            "        # Also handle markdown escapes.",
            "        if \"markdown\" in self.md.markupShorthands:",
            "            textFunctor = MarkdownCodeSpans(text)",
            "        else:",
            "            textFunctor = Functor(text)",
            "",
            "        macros = dict(self.macros, **moreMacros)",
            "        textFunctor = textFunctor.map(curry(replaceMacros, macros=macros))",
            "        textFunctor = textFunctor.map(fixTypography)",
            "        if \"css\" in self.md.markupShorthands:",
            "            textFunctor = textFunctor.map(replaceAwkwardCSSShorthands)",
            "",
            "        return textFunctor.extract()",
            "",
            "    def printTargets(self):",
            "        p(\"Exported terms:\")",
            "        for el in findAll(\"[data-export]\", self):",
            "            for term in config.linkTextsFromElement(el):",
            "                p(\"  \" + term)",
            "        p(\"Unexported terms:\")",
            "        for el in findAll(\"[data-noexport]\", self):",
            "            for term in config.linkTextsFromElement(el):",
            "                p(\"  \" + term)",
            "",
            "    def isOpaqueElement(self, el):",
            "        if el.tag in self.md.opaqueElements:",
            "            return True",
            "        if el.get(\"data-opaque\") is not None:",
            "            return True",
            "        return False",
            "",
            "",
            "def findImplicitInputFile():",
            "    \"\"\"",
            "    Find what input file the user *probably* wants to use,",
            "    by scanning the current folder.",
            "    In preference order:",
            "    1. index.bs",
            "    2. Overview.bs",
            "    3. the first file with a .bs extension",
            "    4. the first file with a .src.html extension",
            "    \"\"\"",
            "",
            "    if os.path.isfile(\"index.bs\"):",
            "        return \"index.bs\"",
            "    if os.path.isfile(\"Overview.bs\"):",
            "        return \"Overview.bs\"",
            "",
            "    allBs = glob.glob(\"*.bs\")",
            "    if allBs:",
            "        return allBs[0]",
            "",
            "    allHtml = glob.glob(\"*.src.html\")",
            "    if allHtml:",
            "        return allHtml[0]",
            "",
            "    return None",
            "",
            "",
            "constants.specClass = Spec",
            "",
            "styleColors = \"\"\"",
            "/* Any --*-text not paired with a --*-bg is assumed to have a transparent bg */",
            ":root {",
            "    color-scheme: light dark;",
            "",
            "    --text: black;",
            "    --bg: white;",
            "",
            "    --unofficial-watermark: url(https://www.w3.org/StyleSheets/TR/2016/logos/UD-watermark);",
            "",
            "    --logo-bg: #1a5e9a;",
            "    --logo-active-bg: #c00;",
            "    --logo-text: white;",
            "",
            "    --tocnav-normal-text: #707070;",
            "    --tocnav-normal-bg: var(--bg);",
            "    --tocnav-hover-text: var(--tocnav-normal-text);",
            "    --tocnav-hover-bg: #f8f8f8;",
            "    --tocnav-active-text: #c00;",
            "    --tocnav-active-bg: var(--tocnav-normal-bg);",
            "",
            "    --tocsidebar-text: var(--text);",
            "    --tocsidebar-bg: #f7f8f9;",
            "    --tocsidebar-shadow: rgba(0,0,0,.1);",
            "    --tocsidebar-heading-text: hsla(203,20%,40%,.7);",
            "",
            "    --toclink-text: var(--text);",
            "    --toclink-underline: #3980b5;",
            "    --toclink-visited-text: var(--toclink-text);",
            "    --toclink-visited-underline: #054572;",
            "",
            "    --heading-text: #005a9c;",
            "",
            "    --hr-text: var(--text);",
            "",
            "    --algo-border: #def;",
            "",
            "    --del-text: red;",
            "    --del-bg: transparent;",
            "    --ins-text: #080;",
            "    --ins-bg: transparent;",
            "",
            "    --a-normal-text: #034575;",
            "    --a-normal-underline: #bbb;",
            "    --a-visited-text: var(--a-normal-text);",
            "    --a-visited-underline: #707070;",
            "    --a-hover-bg: rgba(75%, 75%, 75%, .25);",
            "    --a-active-text: #c00;",
            "    --a-active-underline: #c00;",
            "",
            "    --blockquote-border: silver;",
            "    --blockquote-bg: transparent;",
            "    --blockquote-text: currentcolor;",
            "",
            "    --issue-border: #e05252;",
            "    --issue-bg: #fbe9e9;",
            "    --issue-text: var(--text);",
            "    --issueheading-text: #831616;",
            "",
            "    --example-border: #e0cb52;",
            "    --example-bg: #fcfaee;",
            "    --example-text: var(--text);",
            "    --exampleheading-text: #574b0f;",
            "",
            "    --note-border: #52e052;",
            "    --note-bg: #e9fbe9;",
            "    --note-text: var(--text);",
            "    --noteheading-text: hsl(120, 70%, 30%);",
            "    --notesummary-underline: silver;",
            "",
            "    --assertion-border: #aaa;",
            "    --assertion-bg: #eee;",
            "    --assertion-text: black;",
            "",
            "    --advisement-border: orange;",
            "    --advisement-bg: #fec;",
            "    --advisement-text: var(--text);",
            "    --advisementheading-text: #b35f00;",
            "",
            "    --warning-border: red;",
            "    --warning-bg: hsla(40,100%,50%,0.95);",
            "    --warning-text: var(--text);",
            "",
            "    --amendment-border: #330099;",
            "    --amendment-bg: #F5F0FF;",
            "    --amendment-text: var(--text);",
            "    --amendmentheading-text: #220066;",
            "",
            "    --def-border: #8ccbf2;",
            "    --def-bg: #def;",
            "    --def-text: var(--text);",
            "    --defrow-border: #bbd7e9;",
            "",
            "    --datacell-border: silver;",
            "",
            "    --indexinfo-text: #707070;",
            "",
            "    --indextable-hover-text: black;",
            "    --indextable-hover-bg: #f7f8f9;",
            "",
            "    --outdatedspec-bg: rgba(0, 0, 0, .5);",
            "    --outdatedspec-text: black;",
            "    --outdated-bg: maroon;",
            "    --outdated-text: white;",
            "    --outdated-shadow: red;",
            "",
            "    --editedrec-bg: darkorange;",
            "}\"\"\"",
            "",
            "styleDarkMode = \"\"\"",
            "@media (prefers-color-scheme: dark) {",
            "    :root {",
            "        --text: #ddd;",
            "        --bg: black;",
            "",
            "        --unofficial-watermark: url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400'%3E%3Cg fill='%23100808' transform='translate(200 200) rotate(-45) translate(-200 -200)' stroke='%23100808' stroke-width='3'%3E%3Ctext x='50%25' y='220' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EUNOFFICIAL%3C/text%3E%3Ctext x='50%25' y='305' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EDRAFT%3C/text%3E%3C/g%3E%3C/svg%3E\");",
            "",
            "        --logo-bg: #1a5e9a;",
            "        --logo-active-bg: #c00;",
            "        --logo-text: white;",
            "",
            "        --tocnav-normal-text: #999;",
            "        --tocnav-normal-bg: var(--bg);",
            "        --tocnav-hover-text: var(--tocnav-normal-text);",
            "        --tocnav-hover-bg: #080808;",
            "        --tocnav-active-text: #f44;",
            "        --tocnav-active-bg: var(--tocnav-normal-bg);",
            "",
            "        --tocsidebar-text: var(--text);",
            "        --tocsidebar-bg: #080808;",
            "        --tocsidebar-shadow: rgba(255,255,255,.1);",
            "        --tocsidebar-heading-text: hsla(203,20%,40%,.7);",
            "",
            "        --toclink-text: var(--text);",
            "        --toclink-underline: #6af;",
            "        --toclink-visited-text: var(--toclink-text);",
            "        --toclink-visited-underline: #054572;",
            "",
            "        --heading-text: #8af;",
            "",
            "        --hr-text: var(--text);",
            "",
            "        --algo-border: #456;",
            "",
            "        --del-text: #f44;",
            "        --del-bg: transparent;",
            "        --ins-text: #4a4;",
            "        --ins-bg: transparent;",
            "",
            "        --a-normal-text: #6af;",
            "        --a-normal-underline: #555;",
            "        --a-visited-text: var(--a-normal-text);",
            "        --a-visited-underline: var(--a-normal-underline);",
            "        --a-hover-bg: rgba(25%, 25%, 25%, .2);",
            "        --a-active-text: #f44;",
            "        --a-active-underline: var(--a-active-text);",
            "",
            "        --borderedblock-bg: rgba(255, 255, 255, .05);",
            "",
            "        --blockquote-border: silver;",
            "        --blockquote-bg: var(--borderedblock-bg);",
            "        --blockquote-text: currentcolor;",
            "",
            "        --issue-border: #e05252;",
            "        --issue-bg: var(--borderedblock-bg);",
            "        --issue-text: var(--text);",
            "        --issueheading-text: hsl(0deg, 70%, 70%);",
            "",
            "        --example-border: hsl(50deg, 90%, 60%);",
            "        --example-bg: var(--borderedblock-bg);",
            "        --example-text: var(--text);",
            "        --exampleheading-text: hsl(50deg, 70%, 70%);",
            "",
            "        --note-border: hsl(120deg, 100%, 35%);",
            "        --note-bg: var(--borderedblock-bg);",
            "        --note-text: var(--text);",
            "        --noteheading-text: hsl(120, 70%, 70%);",
            "        --notesummary-underline: silver;",
            "",
            "        --assertion-border: #444;",
            "        --assertion-bg: var(--borderedblock-bg);",
            "        --assertion-text: var(--text);",
            "",
            "        --advisement-border: orange;",
            "        --advisement-bg: #222218;",
            "        --advisement-text: var(--text);",
            "        --advisementheading-text: #f84;",
            "",
            "        --warning-border: red;",
            "        --warning-bg: hsla(40,100%,20%,0.95);",
            "        --warning-text: var(--text);",
            "",
            "        --amendment-border: #330099;",
            "        --amendment-bg: #080010;",
            "        --amendment-text: var(--text);",
            "        --amendmentheading-text: #cc00ff;",
            "",
            "        --def-border: #8ccbf2;",
            "        --def-bg: #080818;",
            "        --def-text: var(--text);",
            "        --defrow-border: #136;",
            "",
            "        --datacell-border: silver;",
            "",
            "        --indexinfo-text: #aaa;",
            "",
            "        --indextable-hover-text: var(--text);",
            "        --indextable-hover-bg: #181818;",
            "",
            "        --outdatedspec-bg: rgba(255, 255, 255, .5);",
            "        --outdatedspec-text: black;",
            "        --outdated-bg: maroon;",
            "        --outdated-text: white;",
            "        --outdated-shadow: red;",
            "",
            "        --editedrec-bg: darkorange;",
            "    }",
            "    /* In case a transparent-bg image doesn't expect to be on a dark bg,",
            "       which is quite common in practice... */",
            "    img { background: white; }",
            "}\"\"\"",
            "",
            "styleMdLists = \"\"\"",
            "/* This is a weird hack for me not yet following the commonmark spec",
            "   regarding paragraph and lists. */",
            "[data-md] > :first-child {",
            "    margin-top: 0;",
            "}",
            "[data-md] > :last-child {",
            "    margin-bottom: 0;",
            "}\"\"\"",
            "",
            "styleAutolinks = \"\"\"",
            ".css.css, .property.property, .descriptor.descriptor {",
            "    color: var(--a-normal-text);",
            "    font-size: inherit;",
            "    font-family: inherit;",
            "}",
            ".css::before, .property::before, .descriptor::before {",
            "    content: \"\u2018\";",
            "}",
            ".css::after, .property::after, .descriptor::after {",
            "    content: \"\u2019\";",
            "}",
            ".property, .descriptor {",
            "    /* Don't wrap property and descriptor names */",
            "    white-space: nowrap;",
            "}",
            ".type { /* CSS value <type> */",
            "    font-style: italic;",
            "}",
            "pre .property::before, pre .property::after {",
            "    content: \"\";",
            "}",
            "[data-link-type=\"property\"]::before,",
            "[data-link-type=\"propdesc\"]::before,",
            "[data-link-type=\"descriptor\"]::before,",
            "[data-link-type=\"value\"]::before,",
            "[data-link-type=\"function\"]::before,",
            "[data-link-type=\"at-rule\"]::before,",
            "[data-link-type=\"selector\"]::before,",
            "[data-link-type=\"maybe\"]::before {",
            "    content: \"\u2018\";",
            "}",
            "[data-link-type=\"property\"]::after,",
            "[data-link-type=\"propdesc\"]::after,",
            "[data-link-type=\"descriptor\"]::after,",
            "[data-link-type=\"value\"]::after,",
            "[data-link-type=\"function\"]::after,",
            "[data-link-type=\"at-rule\"]::after,",
            "[data-link-type=\"selector\"]::after,",
            "[data-link-type=\"maybe\"]::after {",
            "    content: \"\u2019\";",
            "}",
            "",
            "[data-link-type].production::before,",
            "[data-link-type].production::after,",
            ".prod [data-link-type]::before,",
            ".prod [data-link-type]::after {",
            "    content: \"\";",
            "}",
            "",
            "[data-link-type=element],",
            "[data-link-type=element-attr] {",
            "    font-family: Menlo, Consolas, \"DejaVu Sans Mono\", monospace;",
            "    font-size: .9em;",
            "}",
            "[data-link-type=element]::before { content: \"<\" }",
            "[data-link-type=element]::after  { content: \">\" }",
            "",
            "[data-link-type=biblio] {",
            "    white-space: pre;",
            "}\"\"\"",
            "",
            "styleSelflinks = \"\"\"",
            ":root {",
            "    --selflink-text: white;",
            "    --selflink-bg: gray;",
            "    --selflink-hover-text: black;",
            "}",
            ".heading, .issue, .note, .example, li, dt {",
            "    position: relative;",
            "}",
            "a.self-link {",
            "    position: absolute;",
            "    top: 0;",
            "    left: calc(-1 * (3.5rem - 26px));",
            "    width: calc(3.5rem - 26px);",
            "    height: 2em;",
            "    text-align: center;",
            "    border: none;",
            "    transition: opacity .2s;",
            "    opacity: .5;",
            "}",
            "a.self-link:hover {",
            "    opacity: 1;",
            "}",
            ".heading > a.self-link {",
            "    font-size: 83%;",
            "}",
            "li > a.self-link {",
            "    left: calc(-1 * (3.5rem - 26px) - 2em);",
            "}",
            "dfn > a.self-link {",
            "    top: auto;",
            "    left: auto;",
            "    opacity: 0;",
            "    width: 1.5em;",
            "    height: 1.5em;",
            "    background: var(--selflink-bg);",
            "    color: var(--selflink-text);",
            "    font-style: normal;",
            "    transition: opacity .2s, background-color .2s, color .2s;",
            "}",
            "dfn:hover > a.self-link {",
            "    opacity: 1;",
            "}",
            "dfn > a.self-link:hover {",
            "    color: var(--selflink-hover-text);",
            "}",
            "",
            "a.self-link::before            { content: \"\u00b6\"; }",
            ".heading > a.self-link::before { content: \"\u00a7\"; }",
            "dfn > a.self-link::before      { content: \"#\"; }",
            "\"\"\"",
            "styleDarkMode += \"\"\"",
            "@media (prefers-color-scheme: dark) {",
            "    :root {",
            "        --selflink-text: black;",
            "        --selflink-bg: silver;",
            "        --selflink-hover-text: white;",
            "    }",
            "}",
            "\"\"\"",
            "",
            "",
            "styleCounters = \"\"\"",
            "body {",
            "    counter-reset: example figure issue;",
            "}",
            ".issue {",
            "    counter-increment: issue;",
            "}",
            ".issue:not(.no-marker)::before {",
            "    content: \"Issue \" counter(issue);",
            "}",
            "",
            ".example {",
            "    counter-increment: example;",
            "}",
            ".example:not(.no-marker)::before {",
            "    content: \"Example \" counter(example);",
            "}",
            ".invalid.example:not(.no-marker)::before,",
            ".illegal.example:not(.no-marker)::before {",
            "    content: \"Invalid Example\" counter(example);",
            "}",
            "",
            "figcaption {",
            "    counter-increment: figure;",
            "}",
            "figcaption:not(.no-marker)::before {",
            "    content: \"Figure \" counter(figure) \" \";",
            "}\"\"\""
        ],
        "afterPatchFile": [
            "import glob",
            "import os",
            "import sys",
            "from collections import defaultdict",
            "from functools import partial as curry",
            "",
            "from . import (",
            "    biblio,",
            "    boilerplate,",
            "    caniuse,",
            "    conditional,",
            "    config,",
            "    constants,",
            "    datablocks,",
            "    dfns,",
            "    extensions,",
            "    fingerprinting,",
            "    h,",
            "    headings,",
            "    highlight,",
            "    idl,",
            "    includes,",
            "    inlineTags,",
            "    lint,",
            "    markdown,",
            "    mdnspeclinks,",
            "    metadata,",
            "    shorthands,",
            "    wpt,",
            ")",
            "from .func import Functor",
            "from .h import *",
            "from .InputSource import FileInputSource, InputSource",
            "from .messages import *",
            "from .refs import ReferenceManager",
            "from .unsortedJunk import *",
            "",
            "",
            "class Spec:",
            "    def __init__(",
            "        self,",
            "        inputFilename,",
            "        debug=False,",
            "        token=None,",
            "        lineNumbers=False,",
            "        fileRequester=None,",
            "        testing=False,",
            "    ):",
            "        self.valid = False",
            "        self.lineNumbers = lineNumbers",
            "        if lineNumbers:",
            "            # line-numbers are too hacky, so force this to be a dry run",
            "            constants.dryRun = True",
            "        if inputFilename is None:",
            "            inputFilename = findImplicitInputFile()",
            "        if inputFilename is None:  # still",
            "            die(",
            "                \"No input file specified, and no *.bs or *.src.html files found in current directory.\\nPlease specify an input file, or use - to pipe from STDIN.\"",
            "            )",
            "            return",
            "        self.inputSource = InputSource(inputFilename, chroot=constants.chroot)",
            "        self.transitiveDependencies = set()",
            "        self.debug = debug",
            "        self.token = token",
            "        self.testing = testing",
            "        if fileRequester is None:",
            "            self.dataFile = config.defaultRequester",
            "        else:",
            "            self.dataFile = fileRequester",
            "",
            "        self.md = None",
            "        self.mdBaseline = None",
            "        self.mdDocument = None",
            "        self.mdCommandLine = None",
            "        self.mdDefaults = None",
            "        self.mdOverridingDefaults = None",
            "        self.lines = []",
            "        self.document = None",
            "        self.html = None",
            "        self.head = None",
            "        self.body = None",
            "        self.fillContainers = None",
            "        self.valid = self.initializeState()",
            "",
            "    def initializeState(self):",
            "        self.normativeRefs = {}",
            "        self.informativeRefs = {}",
            "        self.refs = ReferenceManager(fileRequester=self.dataFile, testing=self.testing)",
            "        self.externalRefsUsed = defaultdict(lambda: defaultdict(dict))",
            "        self.md = None",
            "        self.mdBaseline = metadata.MetadataManager()",
            "        self.mdDocument = None",
            "        self.mdCommandLine = metadata.MetadataManager()",
            "        self.mdDefaults = None",
            "        self.mdOverridingDefaults = None",
            "        self.biblios = {}",
            "        self.typeExpansions = {}",
            "        self.macros = defaultdict(lambda x: \"???\")",
            "        self.canIUse = {}",
            "        self.mdnSpecLinks = {}",
            "        self.widl = idl.getParser()",
            "        self.testSuites = json.loads(self.dataFile.fetch(\"test-suites.json\", str=True))",
            "        self.languages = json.loads(self.dataFile.fetch(\"languages.json\", str=True))",
            "        self.extraStyles = defaultdict(str)",
            "        self.extraStyles[\"style-colors\"] = styleColors",
            "        self.extraStyles[\"style-darkmode\"] = styleDarkMode",
            "        self.extraStyles[\"style-md-lists\"] = styleMdLists",
            "        self.extraStyles[\"style-autolinks\"] = styleAutolinks",
            "        self.extraStyles[\"style-selflinks\"] = styleSelflinks",
            "        self.extraStyles[\"style-counters\"] = styleCounters",
            "        self.extraScripts = defaultdict(str)",
            "",
            "        try:",
            "            inputContent = self.inputSource.read()",
            "            self.lines = inputContent.lines",
            "            if inputContent.date is not None:",
            "                self.mdBaseline.addParsedData(\"Date\", inputContent.date)",
            "        except FileNotFoundError:",
            "            die(",
            "                \"Couldn't find the input file at the specified location '{0}'.\",",
            "                self.inputSource,",
            "            )",
            "            return False",
            "        except OSError:",
            "            die(\"Couldn't open the input file '{0}'.\", self.inputSource)",
            "            return False",
            "",
            "        return True",
            "",
            "    def recordDependencies(self, *inputSources):",
            "        self.transitiveDependencies.update(inputSources)",
            "",
            "    def preprocess(self):",
            "        self.transitiveDependencies.clear()",
            "        self.assembleDocument()",
            "        self.processDocument()",
            "",
            "    def assembleDocument(self):",
            "        # Textual hacks",
            "        stripBOM(self)",
            "        if self.lineNumbers:",
            "            self.lines = hackyLineNumbers(self.lines)",
            "        self.lines = markdown.stripComments(self.lines)",
            "        self.recordDependencies(self.inputSource)",
            "        # Extract and process metadata",
            "        self.lines, self.mdDocument = metadata.parse(lines=self.lines)",
            "        # First load the metadata sources from 'local' data",
            "        self.md = metadata.join(self.mdBaseline, self.mdDocument, self.mdCommandLine)",
            "        # Using that to determine the Group and Status, load the correct defaults.include boilerplate",
            "        self.mdDefaults = metadata.fromJson(",
            "            data=config.retrieveBoilerplateFile(self, \"defaults\", error=True),",
            "            source=\"defaults\",",
            "        )",
            "        self.md = metadata.join(",
            "            self.mdBaseline, self.mdDefaults, self.mdDocument, self.mdCommandLine",
            "        )",
            "        # Using all of that, load up the text macros so I can sub them into the computed-metadata file.",
            "        self.md.fillTextMacros(self.macros, doc=self)",
            "        jsonEscapedMacros = {k: json.dumps(v)[1:-1] for k, v in self.macros.items()}",
            "        computedMdText = replaceMacros(",
            "            config.retrieveBoilerplateFile(self, \"computed-metadata\", error=True),",
            "            macros=jsonEscapedMacros,",
            "        )",
            "        self.mdOverridingDefaults = metadata.fromJson(",
            "            data=computedMdText, source=\"computed-metadata\"",
            "        )",
            "        self.md = metadata.join(",
            "            self.mdBaseline,",
            "            self.mdDefaults,",
            "            self.mdOverridingDefaults,",
            "            self.mdDocument,",
            "            self.mdCommandLine,",
            "        )",
            "        # Finally, compute the \"implicit\" things.",
            "        self.md.computeImplicitMetadata(doc=self)",
            "        # And compute macros again, in case the preceding steps changed them.",
            "        self.md.fillTextMacros(self.macros, doc=self)",
            "        self.md.validate()",
            "        extensions.load(self)",
            "",
            "        # Initialize things",
            "        self.refs.initializeRefs(self)",
            "        self.refs.initializeBiblio()",
            "",
            "        # Deal with further <pre> blocks, and markdown",
            "        self.lines = datablocks.transformDataBlocks(self, self.lines)",
            "        self.lines = markdown.parse(",
            "            self.lines,",
            "            self.md.indent,",
            "            opaqueElements=self.md.opaqueElements,",
            "            blockElements=self.md.blockElements,",
            "        )",
            "        # Note that, currently, markdown.parse returns an array of strings, not of Line objects.",
            "",
            "        self.refs.setSpecData(self.md)",
            "",
            "        # Convert to a single string of html now, for convenience.",
            "        self.html = \"\".join(line.text for line in self.lines)",
            "        boilerplate.addHeaderFooter(self)",
            "        self.html = self.fixText(self.html)",
            "",
            "        # Build the document",
            "        self.document = parseDocument(self.html)",
            "        self.head = find(\"head\", self)",
            "        self.body = find(\"body\", self)",
            "        correctH1(self)",
            "        includes.processInclusions(self)",
            "        metadata.parseDoc(self)",
            "",
            "    def processDocument(self):",
            "        # Fill in and clean up a bunch of data",
            "        conditional.processConditionals(self)",
            "        self.fillContainers = locateFillContainers(self)",
            "        lint.exampleIDs(self)",
            "        boilerplate.addBikeshedVersion(self)",
            "        boilerplate.addCanonicalURL(self)",
            "        boilerplate.addFavicon(self)",
            "        boilerplate.addSpecVersion(self)",
            "        boilerplate.addStatusSection(self)",
            "        boilerplate.addLogo(self)",
            "        boilerplate.addCopyright(self)",
            "        boilerplate.addSpecMetadataSection(self)",
            "        boilerplate.addAbstract(self)",
            "        boilerplate.addExpiryNotice(self)",
            "        boilerplate.addObsoletionNotice(self)",
            "        boilerplate.addAtRisk(self)",
            "        addNoteHeaders(self)",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        wpt.processWptElements(self)",
            "        shorthands.run(self)",
            "        inlineTags.processTags(self)",
            "        canonicalizeShortcuts(self)",
            "        addImplicitAlgorithms(self)",
            "        fixManualDefTables(self)",
            "        headings.processHeadings(self)",
            "        checkVarHygiene(self)",
            "        processIssuesAndExamples(self)",
            "        idl.markupIDL(self)",
            "        inlineRemoteIssues(self)",
            "        addImageSize(self)",
            "",
            "        # Handle all the links",
            "        processBiblioLinks(self)",
            "        processDfns(self)",
            "        idl.processIDL(self)",
            "        dfns.annotateDfns(self)",
            "        formatArgumentdefTables(self)",
            "        formatElementdefTables(self)",
            "        processAutolinks(self)",
            "        biblio.dedupBiblioReferences(self)",
            "        verifyUsageOfAllLocalBiblios(self)",
            "        caniuse.addCanIUsePanels(self)",
            "        boilerplate.addIndexSection(self)",
            "        boilerplate.addExplicitIndexes(self)",
            "        boilerplate.addStyles(self)",
            "        boilerplate.addReferencesSection(self)",
            "        boilerplate.addPropertyIndex(self)",
            "        boilerplate.addIDLSection(self)",
            "        boilerplate.addIssuesSection(self)",
            "        boilerplate.addCustomBoilerplate(self)",
            "        headings.processHeadings(self, \"all\")  # again",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        boilerplate.addTOCSection(self)",
            "        addSelfLinks(self)",
            "        processAutolinks(self)",
            "        boilerplate.addAnnotations(self)",
            "        boilerplate.removeUnwantedBoilerplate(self)",
            "        # Add MDN panels after all IDs/anchors have been added",
            "        mdnspeclinks.addMdnPanels(self)",
            "        highlight.addSyntaxHighlighting(self)",
            "        boilerplate.addBikeshedBoilerplate(self)",
            "        fingerprinting.addTrackingVector(self)",
            "        fixIntraDocumentReferences(self)",
            "        fixInterDocumentReferences(self)",
            "        removeMultipleLinks(self)",
            "        forceCrossorigin(self)",
            "        lint.brokenLinks(self)",
            "        lint.accidental2119(self)",
            "        lint.missingExposed(self)",
            "        lint.requiredIDs(self)",
            "        lint.unusedInternalDfns(self)",
            "",
            "        # Any final HTML cleanups",
            "        cleanupHTML(self)",
            "        if self.md.prepTR:",
            "            # Don't try and override the W3C's icon.",
            "            for el in findAll(\"[rel ~= 'icon']\", self):",
            "                removeNode(el)",
            "            # Make sure the W3C stylesheet is after all other styles.",
            "            for el in findAll(\"link\", self):",
            "                if el.get(\"href\").startswith(\"https://www.w3.org/StyleSheets/TR\"):",
            "                    appendChild(find(\"head\", self), el)",
            "            # Ensure that all W3C links are https.",
            "            for el in findAll(\"a\", self):",
            "                href = el.get(\"href\", \"\")",
            "                if href.startswith(\"http://www.w3.org\") or href.startswith(",
            "                    \"http://lists.w3.org\"",
            "                ):",
            "                    el.set(\"href\", \"https\" + href[4:])",
            "                text = el.text or \"\"",
            "                if text.startswith(\"http://www.w3.org\") or text.startswith(",
            "                    \"http://lists.w3.org\"",
            "                ):",
            "                    el.text = \"https\" + text[4:]",
            "            # Loaded from .include files",
            "            extensions.BSPrepTR(self)  # pylint: disable=no-member",
            "",
            "        return self",
            "",
            "    def serialize(self):",
            "        try:",
            "            rendered = h.Serializer(",
            "                self.md.opaqueElements, self.md.blockElements",
            "            ).serialize(self.document)",
            "        except Exception as e:",
            "            die(\"{0}\", e)",
            "            return",
            "        rendered = finalHackyCleanup(rendered)",
            "        return rendered",
            "",
            "    def fixMissingOutputFilename(self, outputFilename):",
            "        if outputFilename is None:",
            "            # More sensible defaults!",
            "            if not isinstance(self.inputSource, FileInputSource):",
            "                outputFilename = \"-\"",
            "            elif self.inputSource.sourceName.endswith(\".bs\"):",
            "                outputFilename = self.inputSource.sourceName[0:-3] + \".html\"",
            "            elif self.inputSource.sourceName.endswith(\".src.html\"):",
            "                outputFilename = self.inputSource.sourceName[0:-9] + \".html\"",
            "            else:",
            "                outputFilename = \"-\"",
            "        return outputFilename",
            "",
            "    def finish(self, outputFilename=None, newline=None):",
            "        self.printResultMessage()",
            "        outputFilename = self.fixMissingOutputFilename(outputFilename)",
            "        rendered = self.serialize()",
            "        if not constants.dryRun:",
            "            try:",
            "                if outputFilename == \"-\":",
            "                    sys.stdout.write(rendered)",
            "                else:",
            "                    with open(",
            "                        outputFilename, \"w\", encoding=\"utf-8\", newline=newline",
            "                    ) as f:",
            "                        f.write(rendered)",
            "            except Exception as e:",
            "                die(",
            "                    \"Something prevented me from saving the output document to {0}:\\n{1}\",",
            "                    outputFilename,",
            "                    e,",
            "                )",
            "",
            "    def printResultMessage(self):",
            "        # If I reach this point, I've succeeded, but maybe with reservations.",
            "        fatals = messageCounts[\"fatal\"]",
            "        links = messageCounts[\"linkerror\"]",
            "        warnings = messageCounts[\"warning\"]",
            "        if self.lineNumbers:",
            "            warn(\"Because --line-numbers was used, no output was saved.\")",
            "        if fatals:",
            "            success(\"Successfully generated, but fatal errors were suppressed\")",
            "            return",
            "        if links:",
            "            success(\"Successfully generated, with {0} linking errors\", links)",
            "            return",
            "        if warnings:",
            "            success(\"Successfully generated, with warnings\")",
            "            return",
            "",
            "    def watch(self, outputFilename, port=None, localhost=False):",
            "        import time",
            "",
            "        outputFilename = self.fixMissingOutputFilename(outputFilename)",
            "        if self.inputSource.mtime() is None:",
            "            die(f\"Watch mode doesn't support {self.inputSource}\")",
            "        if outputFilename == \"-\":",
            "            die(\"Watch mode doesn't support streaming to STDOUT.\")",
            "            return",
            "",
            "        if port:",
            "            # Serve the folder on an HTTP server",
            "            import http.server",
            "            import socketserver",
            "            import threading",
            "",
            "            class SilentServer(http.server.SimpleHTTPRequestHandler):",
            "                def log_message(self, format, *args):",
            "                    pass",
            "",
            "            socketserver.TCPServer.allow_reuse_address = True",
            "            server = socketserver.TCPServer(",
            "                (\"localhost\" if localhost else \"\", port), SilentServer",
            "            )",
            "",
            "            print(f\"Serving at port {port}\")",
            "            thread = threading.Thread(target=server.serve_forever)",
            "            thread.daemon = True",
            "            thread.start()",
            "        else:",
            "            server = None",
            "",
            "        mdCommandLine = self.mdCommandLine",
            "",
            "        try:",
            "            self.preprocess()",
            "            self.finish(outputFilename)",
            "            lastInputModified = {",
            "                dep: dep.mtime() for dep in self.transitiveDependencies",
            "            }",
            "            p(\"==============DONE==============\")",
            "            try:",
            "                while True:",
            "                    # Comparing mtimes with \"!=\" handles when a file starts or",
            "                    # stops existing, and it's fine to rebuild if an mtime",
            "                    # somehow gets older.",
            "                    if any(",
            "                        input.mtime() != lastModified",
            "                        for input, lastModified in lastInputModified.items()",
            "                    ):",
            "                        resetSeenMessages()",
            "                        p(\"Source file modified. Rebuilding...\")",
            "                        self.initializeState()",
            "                        self.mdCommandLine = mdCommandLine",
            "                        self.preprocess()",
            "                        self.finish(outputFilename)",
            "                        lastInputModified = {",
            "                            dep: dep.mtime() for dep in self.transitiveDependencies",
            "                        }",
            "                        p(\"==============DONE==============\")",
            "                    time.sleep(1)",
            "            except KeyboardInterrupt:",
            "                p(\"Exiting~\")",
            "                if server:",
            "                    server.shutdown()",
            "                    thread.join()",
            "                sys.exit(0)",
            "        except Exception as e:",
            "            die(\"Something went wrong while watching the file:\\n{0}\", e)",
            "",
            "    def fixText(self, text, moreMacros={}):",
            "        # Do several textual replacements that need to happen *before* the document is parsed as h.",
            "",
            "        # If markdown shorthands are on, remove all `foo`s while processing,",
            "        # so their contents don't accidentally trigger other stuff.",
            "        # Also handle markdown escapes.",
            "        if \"markdown\" in self.md.markupShorthands:",
            "            textFunctor = MarkdownCodeSpans(text)",
            "        else:",
            "            textFunctor = Functor(text)",
            "",
            "        macros = dict(self.macros, **moreMacros)",
            "        textFunctor = textFunctor.map(curry(replaceMacros, macros=macros))",
            "        textFunctor = textFunctor.map(fixTypography)",
            "        if \"css\" in self.md.markupShorthands:",
            "            textFunctor = textFunctor.map(replaceAwkwardCSSShorthands)",
            "",
            "        return textFunctor.extract()",
            "",
            "    def printTargets(self):",
            "        p(\"Exported terms:\")",
            "        for el in findAll(\"[data-export]\", self):",
            "            for term in config.linkTextsFromElement(el):",
            "                p(\"  \" + term)",
            "        p(\"Unexported terms:\")",
            "        for el in findAll(\"[data-noexport]\", self):",
            "            for term in config.linkTextsFromElement(el):",
            "                p(\"  \" + term)",
            "",
            "    def isOpaqueElement(self, el):",
            "        if el.tag in self.md.opaqueElements:",
            "            return True",
            "        if el.get(\"data-opaque\") is not None:",
            "            return True",
            "        return False",
            "",
            "",
            "def findImplicitInputFile():",
            "    \"\"\"",
            "    Find what input file the user *probably* wants to use,",
            "    by scanning the current folder.",
            "    In preference order:",
            "    1. index.bs",
            "    2. Overview.bs",
            "    3. the first file with a .bs extension",
            "    4. the first file with a .src.html extension",
            "    \"\"\"",
            "",
            "    if os.path.isfile(\"index.bs\"):",
            "        return \"index.bs\"",
            "    if os.path.isfile(\"Overview.bs\"):",
            "        return \"Overview.bs\"",
            "",
            "    allBs = glob.glob(\"*.bs\")",
            "    if allBs:",
            "        return allBs[0]",
            "",
            "    allHtml = glob.glob(\"*.src.html\")",
            "    if allHtml:",
            "        return allHtml[0]",
            "",
            "    return None",
            "",
            "",
            "constants.specClass = Spec",
            "",
            "styleColors = \"\"\"",
            "/* Any --*-text not paired with a --*-bg is assumed to have a transparent bg */",
            ":root {",
            "    color-scheme: light dark;",
            "",
            "    --text: black;",
            "    --bg: white;",
            "",
            "    --unofficial-watermark: url(https://www.w3.org/StyleSheets/TR/2016/logos/UD-watermark);",
            "",
            "    --logo-bg: #1a5e9a;",
            "    --logo-active-bg: #c00;",
            "    --logo-text: white;",
            "",
            "    --tocnav-normal-text: #707070;",
            "    --tocnav-normal-bg: var(--bg);",
            "    --tocnav-hover-text: var(--tocnav-normal-text);",
            "    --tocnav-hover-bg: #f8f8f8;",
            "    --tocnav-active-text: #c00;",
            "    --tocnav-active-bg: var(--tocnav-normal-bg);",
            "",
            "    --tocsidebar-text: var(--text);",
            "    --tocsidebar-bg: #f7f8f9;",
            "    --tocsidebar-shadow: rgba(0,0,0,.1);",
            "    --tocsidebar-heading-text: hsla(203,20%,40%,.7);",
            "",
            "    --toclink-text: var(--text);",
            "    --toclink-underline: #3980b5;",
            "    --toclink-visited-text: var(--toclink-text);",
            "    --toclink-visited-underline: #054572;",
            "",
            "    --heading-text: #005a9c;",
            "",
            "    --hr-text: var(--text);",
            "",
            "    --algo-border: #def;",
            "",
            "    --del-text: red;",
            "    --del-bg: transparent;",
            "    --ins-text: #080;",
            "    --ins-bg: transparent;",
            "",
            "    --a-normal-text: #034575;",
            "    --a-normal-underline: #bbb;",
            "    --a-visited-text: var(--a-normal-text);",
            "    --a-visited-underline: #707070;",
            "    --a-hover-bg: rgba(75%, 75%, 75%, .25);",
            "    --a-active-text: #c00;",
            "    --a-active-underline: #c00;",
            "",
            "    --blockquote-border: silver;",
            "    --blockquote-bg: transparent;",
            "    --blockquote-text: currentcolor;",
            "",
            "    --issue-border: #e05252;",
            "    --issue-bg: #fbe9e9;",
            "    --issue-text: var(--text);",
            "    --issueheading-text: #831616;",
            "",
            "    --example-border: #e0cb52;",
            "    --example-bg: #fcfaee;",
            "    --example-text: var(--text);",
            "    --exampleheading-text: #574b0f;",
            "",
            "    --note-border: #52e052;",
            "    --note-bg: #e9fbe9;",
            "    --note-text: var(--text);",
            "    --noteheading-text: hsl(120, 70%, 30%);",
            "    --notesummary-underline: silver;",
            "",
            "    --assertion-border: #aaa;",
            "    --assertion-bg: #eee;",
            "    --assertion-text: black;",
            "",
            "    --advisement-border: orange;",
            "    --advisement-bg: #fec;",
            "    --advisement-text: var(--text);",
            "    --advisementheading-text: #b35f00;",
            "",
            "    --warning-border: red;",
            "    --warning-bg: hsla(40,100%,50%,0.95);",
            "    --warning-text: var(--text);",
            "",
            "    --amendment-border: #330099;",
            "    --amendment-bg: #F5F0FF;",
            "    --amendment-text: var(--text);",
            "    --amendmentheading-text: #220066;",
            "",
            "    --def-border: #8ccbf2;",
            "    --def-bg: #def;",
            "    --def-text: var(--text);",
            "    --defrow-border: #bbd7e9;",
            "",
            "    --datacell-border: silver;",
            "",
            "    --indexinfo-text: #707070;",
            "",
            "    --indextable-hover-text: black;",
            "    --indextable-hover-bg: #f7f8f9;",
            "",
            "    --outdatedspec-bg: rgba(0, 0, 0, .5);",
            "    --outdatedspec-text: black;",
            "    --outdated-bg: maroon;",
            "    --outdated-text: white;",
            "    --outdated-shadow: red;",
            "",
            "    --editedrec-bg: darkorange;",
            "}\"\"\"",
            "",
            "styleDarkMode = \"\"\"",
            "@media (prefers-color-scheme: dark) {",
            "    :root {",
            "        --text: #ddd;",
            "        --bg: black;",
            "",
            "        --unofficial-watermark: url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400'%3E%3Cg fill='%23100808' transform='translate(200 200) rotate(-45) translate(-200 -200)' stroke='%23100808' stroke-width='3'%3E%3Ctext x='50%25' y='220' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EUNOFFICIAL%3C/text%3E%3Ctext x='50%25' y='305' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EDRAFT%3C/text%3E%3C/g%3E%3C/svg%3E\");",
            "",
            "        --logo-bg: #1a5e9a;",
            "        --logo-active-bg: #c00;",
            "        --logo-text: white;",
            "",
            "        --tocnav-normal-text: #999;",
            "        --tocnav-normal-bg: var(--bg);",
            "        --tocnav-hover-text: var(--tocnav-normal-text);",
            "        --tocnav-hover-bg: #080808;",
            "        --tocnav-active-text: #f44;",
            "        --tocnav-active-bg: var(--tocnav-normal-bg);",
            "",
            "        --tocsidebar-text: var(--text);",
            "        --tocsidebar-bg: #080808;",
            "        --tocsidebar-shadow: rgba(255,255,255,.1);",
            "        --tocsidebar-heading-text: hsla(203,20%,40%,.7);",
            "",
            "        --toclink-text: var(--text);",
            "        --toclink-underline: #6af;",
            "        --toclink-visited-text: var(--toclink-text);",
            "        --toclink-visited-underline: #054572;",
            "",
            "        --heading-text: #8af;",
            "",
            "        --hr-text: var(--text);",
            "",
            "        --algo-border: #456;",
            "",
            "        --del-text: #f44;",
            "        --del-bg: transparent;",
            "        --ins-text: #4a4;",
            "        --ins-bg: transparent;",
            "",
            "        --a-normal-text: #6af;",
            "        --a-normal-underline: #555;",
            "        --a-visited-text: var(--a-normal-text);",
            "        --a-visited-underline: var(--a-normal-underline);",
            "        --a-hover-bg: rgba(25%, 25%, 25%, .2);",
            "        --a-active-text: #f44;",
            "        --a-active-underline: var(--a-active-text);",
            "",
            "        --borderedblock-bg: rgba(255, 255, 255, .05);",
            "",
            "        --blockquote-border: silver;",
            "        --blockquote-bg: var(--borderedblock-bg);",
            "        --blockquote-text: currentcolor;",
            "",
            "        --issue-border: #e05252;",
            "        --issue-bg: var(--borderedblock-bg);",
            "        --issue-text: var(--text);",
            "        --issueheading-text: hsl(0deg, 70%, 70%);",
            "",
            "        --example-border: hsl(50deg, 90%, 60%);",
            "        --example-bg: var(--borderedblock-bg);",
            "        --example-text: var(--text);",
            "        --exampleheading-text: hsl(50deg, 70%, 70%);",
            "",
            "        --note-border: hsl(120deg, 100%, 35%);",
            "        --note-bg: var(--borderedblock-bg);",
            "        --note-text: var(--text);",
            "        --noteheading-text: hsl(120, 70%, 70%);",
            "        --notesummary-underline: silver;",
            "",
            "        --assertion-border: #444;",
            "        --assertion-bg: var(--borderedblock-bg);",
            "        --assertion-text: var(--text);",
            "",
            "        --advisement-border: orange;",
            "        --advisement-bg: #222218;",
            "        --advisement-text: var(--text);",
            "        --advisementheading-text: #f84;",
            "",
            "        --warning-border: red;",
            "        --warning-bg: hsla(40,100%,20%,0.95);",
            "        --warning-text: var(--text);",
            "",
            "        --amendment-border: #330099;",
            "        --amendment-bg: #080010;",
            "        --amendment-text: var(--text);",
            "        --amendmentheading-text: #cc00ff;",
            "",
            "        --def-border: #8ccbf2;",
            "        --def-bg: #080818;",
            "        --def-text: var(--text);",
            "        --defrow-border: #136;",
            "",
            "        --datacell-border: silver;",
            "",
            "        --indexinfo-text: #aaa;",
            "",
            "        --indextable-hover-text: var(--text);",
            "        --indextable-hover-bg: #181818;",
            "",
            "        --outdatedspec-bg: rgba(255, 255, 255, .5);",
            "        --outdatedspec-text: black;",
            "        --outdated-bg: maroon;",
            "        --outdated-text: white;",
            "        --outdated-shadow: red;",
            "",
            "        --editedrec-bg: darkorange;",
            "    }",
            "    /* In case a transparent-bg image doesn't expect to be on a dark bg,",
            "       which is quite common in practice... */",
            "    img { background: white; }",
            "}\"\"\"",
            "",
            "styleMdLists = \"\"\"",
            "/* This is a weird hack for me not yet following the commonmark spec",
            "   regarding paragraph and lists. */",
            "[data-md] > :first-child {",
            "    margin-top: 0;",
            "}",
            "[data-md] > :last-child {",
            "    margin-bottom: 0;",
            "}\"\"\"",
            "",
            "styleAutolinks = \"\"\"",
            ".css.css, .property.property, .descriptor.descriptor {",
            "    color: var(--a-normal-text);",
            "    font-size: inherit;",
            "    font-family: inherit;",
            "}",
            ".css::before, .property::before, .descriptor::before {",
            "    content: \"\u2018\";",
            "}",
            ".css::after, .property::after, .descriptor::after {",
            "    content: \"\u2019\";",
            "}",
            ".property, .descriptor {",
            "    /* Don't wrap property and descriptor names */",
            "    white-space: nowrap;",
            "}",
            ".type { /* CSS value <type> */",
            "    font-style: italic;",
            "}",
            "pre .property::before, pre .property::after {",
            "    content: \"\";",
            "}",
            "[data-link-type=\"property\"]::before,",
            "[data-link-type=\"propdesc\"]::before,",
            "[data-link-type=\"descriptor\"]::before,",
            "[data-link-type=\"value\"]::before,",
            "[data-link-type=\"function\"]::before,",
            "[data-link-type=\"at-rule\"]::before,",
            "[data-link-type=\"selector\"]::before,",
            "[data-link-type=\"maybe\"]::before {",
            "    content: \"\u2018\";",
            "}",
            "[data-link-type=\"property\"]::after,",
            "[data-link-type=\"propdesc\"]::after,",
            "[data-link-type=\"descriptor\"]::after,",
            "[data-link-type=\"value\"]::after,",
            "[data-link-type=\"function\"]::after,",
            "[data-link-type=\"at-rule\"]::after,",
            "[data-link-type=\"selector\"]::after,",
            "[data-link-type=\"maybe\"]::after {",
            "    content: \"\u2019\";",
            "}",
            "",
            "[data-link-type].production::before,",
            "[data-link-type].production::after,",
            ".prod [data-link-type]::before,",
            ".prod [data-link-type]::after {",
            "    content: \"\";",
            "}",
            "",
            "[data-link-type=element],",
            "[data-link-type=element-attr] {",
            "    font-family: Menlo, Consolas, \"DejaVu Sans Mono\", monospace;",
            "    font-size: .9em;",
            "}",
            "[data-link-type=element]::before { content: \"<\" }",
            "[data-link-type=element]::after  { content: \">\" }",
            "",
            "[data-link-type=biblio] {",
            "    white-space: pre;",
            "}\"\"\"",
            "",
            "styleSelflinks = \"\"\"",
            ":root {",
            "    --selflink-text: white;",
            "    --selflink-bg: gray;",
            "    --selflink-hover-text: black;",
            "}",
            ".heading, .issue, .note, .example, li, dt {",
            "    position: relative;",
            "}",
            "a.self-link {",
            "    position: absolute;",
            "    top: 0;",
            "    left: calc(-1 * (3.5rem - 26px));",
            "    width: calc(3.5rem - 26px);",
            "    height: 2em;",
            "    text-align: center;",
            "    border: none;",
            "    transition: opacity .2s;",
            "    opacity: .5;",
            "}",
            "a.self-link:hover {",
            "    opacity: 1;",
            "}",
            ".heading > a.self-link {",
            "    font-size: 83%;",
            "}",
            "li > a.self-link {",
            "    left: calc(-1 * (3.5rem - 26px) - 2em);",
            "}",
            "dfn > a.self-link {",
            "    top: auto;",
            "    left: auto;",
            "    opacity: 0;",
            "    width: 1.5em;",
            "    height: 1.5em;",
            "    background: var(--selflink-bg);",
            "    color: var(--selflink-text);",
            "    font-style: normal;",
            "    transition: opacity .2s, background-color .2s, color .2s;",
            "}",
            "dfn:hover > a.self-link {",
            "    opacity: 1;",
            "}",
            "dfn > a.self-link:hover {",
            "    color: var(--selflink-hover-text);",
            "}",
            "",
            "a.self-link::before            { content: \"\u00b6\"; }",
            ".heading > a.self-link::before { content: \"\u00a7\"; }",
            "dfn > a.self-link::before      { content: \"#\"; }",
            "\"\"\"",
            "styleDarkMode += \"\"\"",
            "@media (prefers-color-scheme: dark) {",
            "    :root {",
            "        --selflink-text: black;",
            "        --selflink-bg: silver;",
            "        --selflink-hover-text: white;",
            "    }",
            "}",
            "\"\"\"",
            "",
            "",
            "styleCounters = \"\"\"",
            "body {",
            "    counter-reset: example figure issue;",
            "}",
            ".issue {",
            "    counter-increment: issue;",
            "}",
            ".issue:not(.no-marker)::before {",
            "    content: \"Issue \" counter(issue);",
            "}",
            "",
            ".example {",
            "    counter-increment: example;",
            "}",
            ".example:not(.no-marker)::before {",
            "    content: \"Example \" counter(example);",
            "}",
            ".invalid.example:not(.no-marker)::before,",
            ".illegal.example:not(.no-marker)::before {",
            "    content: \"Invalid Example\" counter(example);",
            "}",
            "",
            "figcaption {",
            "    counter-increment: figure;",
            "}",
            "figcaption:not(.no-marker)::before {",
            "    content: \"Figure \" counter(figure) \" \";",
            "}\"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "61": [
                "Spec",
                "__init__"
            ]
        },
        "addLocation": []
    },
    "bikeshed/cli.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         choices=[\"nothing\", \"fatal\", \"link-error\", \"warning\", \"everything\"],"
            },
            "1": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "         help=\"Determines what sorts of errors cause Bikeshed to die (quit immediately with an error status code). Default is 'fatal'; the -f flag is a shorthand for 'nothing'\","
            },
            "2": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "     )"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+    argparser.add_argument("
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+        \"--allow-nonlocal-files\","
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+        dest=\"allowNonlocalFiles\","
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+        action=\"store_true\","
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+        help=\"Allows Bikeshed to see/include files from folders higher than the one your source document is in.\""
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+    )"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+    argparser.add_argument("
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+        \"--allow-execute\","
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+        dest=\"allowExecute\","
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+        action=\"store_true\","
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        help=\"Allow some features to execute arbitrary code from outside the Bikeshed codebase.\""
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+    )"
            },
            "15": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 90,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "     subparsers = argparser.add_subparsers(title=\"Subcommands\", dest=\"subparserName\")"
            },
            "17": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 92,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": 456,
                "PatchRowcode": "             constants.printMode = \"console\""
            },
            "19": {
                "beforePatchRowNumber": 445,
                "afterPatchRowNumber": 457,
                "PatchRowcode": "     else:"
            },
            "20": {
                "beforePatchRowNumber": 446,
                "afterPatchRowNumber": 458,
                "PatchRowcode": "         constants.printMode = options.printMode"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 459,
                "PatchRowcode": "+    constants.chroot = not options.allowNonlocalFiles"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 460,
                "PatchRowcode": "+    constants.executeCode = options.allowExecute"
            },
            "23": {
                "beforePatchRowNumber": 447,
                "afterPatchRowNumber": 461,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 448,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "     update.fixupDataFiles()"
            },
            "25": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 463,
                "PatchRowcode": "     if options.subparserName == \"update\":"
            }
        },
        "frontPatchFile": [
            "import argparse",
            "import json",
            "import os",
            "import sys",
            "",
            "from . import config, constants, update",
            "from .config.printjson import getjson",
            "from .messages import *",
            "",
            "",
            "def main():",
            "    # Hack around argparse's lack of optional subparsers",
            "    if len(sys.argv) == 1:",
            "        sys.argv.append(\"spec\")",
            "",
            "    try:",
            "        with open(config.scriptPath(\"..\", \"semver.txt\")) as fh:",
            "            semver = fh.read().strip()",
            "            semverText = f\"Bikeshed v{semver}: \"",
            "    except FileNotFoundError:",
            "        semver = \"???\"",
            "        semverText = \"\"",
            "",
            "    argparser = argparse.ArgumentParser(",
            "        description=f\"{semverText}Processes spec source files into valid HTML.\"",
            "    )",
            "    argparser.add_argument(\"--version\", action=\"version\", version=semver)",
            "    argparser.add_argument(",
            "        \"-q\",",
            "        \"--quiet\",",
            "        dest=\"quiet\",",
            "        action=\"count\",",
            "        default=0,",
            "        help=\"Silences one level of message, least-important first.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-s\",",
            "        \"--silent\",",
            "        dest=\"silent\",",
            "        action=\"store_true\",",
            "        help=\"Shorthand for 'as many -q as you need to shut it up'\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-f\",",
            "        \"--force\",",
            "        dest=\"errorLevel\",",
            "        action=\"store_const\",",
            "        const=\"nothing\",",
            "        help=\"Force the preprocessor to run to completion; fatal errors don't stop processing.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-d\",",
            "        \"--dry-run\",",
            "        dest=\"dryRun\",",
            "        action=\"store_true\",",
            "        help=\"Prevents the processor from actually saving anything to disk, but otherwise fully runs.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-a\",",
            "        \"--ascii-only\",",
            "        dest=\"asciiOnly\",",
            "        action=\"store_true\",",
            "        help=\"Force all Bikeshed messages to be ASCII-only.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"--print\",",
            "        dest=\"printMode\",",
            "        action=\"store\",",
            "        default=None,",
            "        help=\"Print mode. Options are 'plain' (just text), 'console' (colored with console color codes), 'markup', and 'json'. Defaults to 'console'.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"--die-on\",",
            "        dest=\"errorLevel\",",
            "        choices=[\"nothing\", \"fatal\", \"link-error\", \"warning\", \"everything\"],",
            "        help=\"Determines what sorts of errors cause Bikeshed to die (quit immediately with an error status code). Default is 'fatal'; the -f flag is a shorthand for 'nothing'\",",
            "    )",
            "",
            "    subparsers = argparser.add_subparsers(title=\"Subcommands\", dest=\"subparserName\")",
            "",
            "    specParser = subparsers.add_parser(",
            "        \"spec\", help=\"Process a spec source file into a valid output file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"--debug\",",
            "        dest=\"debug\",",
            "        action=\"store_true\",",
            "        help=\"Switches on some debugging tools. Don't use for production!\",",
            "    )",
            "    specParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    specParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "    specParser.add_argument(",
            "        \"-l\",",
            "        \"--line-numbers\",",
            "        dest=\"lineNumbers\",",
            "        action=\"store_true\",",
            "        help=\"Hacky support for outputting line numbers on all error messages. Disables output, as this is hacky and might mess up your source.\",",
            "    )",
            "",
            "    echidnaParser = subparsers.add_parser(",
            "        \"echidna\",",
            "        help=\"Process a spec source file into a valid output file and publish it according to certain automatic protocols.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--u\", dest=\"un\", metavar=\"USERNAME\", required=False, help=\"W3C username.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--p\", dest=\"pw\", metavar=\"PASSWORD\", required=False, help=\"W3C password.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--decision\",",
            "        dest=\"decision\",",
            "        metavar=\"DECISION_URL\",",
            "        required=False,",
            "        help=\"URL recording the decision to publish.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--editorial\",",
            "        dest=\"editorial\",",
            "        action=\"store_true\",",
            "        required=False,",
            "        help=\"Flags update as editorial.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--cc\",",
            "        dest=\"cc\",",
            "        metavar=\"EMAIL\",",
            "        required=False,",
            "        help=\"Comma-separated list of email addresses to ping with the publication status when complete.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--additional-directories\",",
            "        dest=\"additionalDirectories\",",
            "        required=False,",
            "        nargs=\"*\",",
            "        help=\"Directories to bundle in the tar file. Defaults to examples/, diagrams/, and images/.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--self-contained\",",
            "        dest=\"selfContained\",",
            "        action=\"store_true\",",
            "        help=\"The spec is self-contained, do not bundle any extra directories in the tar file.\",",
            "    )",
            "    echidnaParser.add_argument(\"--just-tar\", dest=\"justTar\", action=\"store_true\")",
            "",
            "    watchParser = subparsers.add_parser(",
            "        \"watch\",",
            "        help=\"Process a spec source file into a valid output file, automatically rebuilding when it changes.\",",
            "    )",
            "    watchParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    watchParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    watchParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    watchParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "",
            "    serveParser = subparsers.add_parser(",
            "        \"serve\", help=\"Identical to 'watch', but also serves the folder on localhost.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"--port\",",
            "        dest=\"port\",",
            "        nargs=\"?\",",
            "        default=\"8000\",",
            "        help=\"Specify the port to serve it over.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--localhost\",",
            "        dest=\"localhost\",",
            "        action=\"store_true\",",
            "        help=\"Only allow connections from localhost.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "",
            "    updateParser = subparsers.add_parser(",
            "        \"update\",",
            "        help=\"Update supporting files (those in /spec-data).\",",
            "        epilog=\"If no options are specified, everything is downloaded.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--skip-manifest\",",
            "        dest=\"force\",",
            "        action=\"store_true\",",
            "        help=\"Forces Bikeshed to do a full update manually, rather than using the manifest to get the preprocessed update (which can be several minutes old).\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--anchors\", action=\"store_true\", help=\"Download crossref anchor data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--backrefs\", action=\"store_true\", help=\"Download link backref data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--biblio\", action=\"store_true\", help=\"Download biblio data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--caniuse\", action=\"store_true\", help=\"Download Can I Use... data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--mdn\", action=\"store_true\", help=\"Download MDN Spec Links... data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--link-defaults\",",
            "        dest=\"linkDefaults\",",
            "        action=\"store_true\",",
            "        help=\"Download link default data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--test-suites\",",
            "        dest=\"testSuites\",",
            "        action=\"store_true\",",
            "        help=\"Download test suite data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--languages\",",
            "        dest=\"languages\",",
            "        action=\"store_true\",",
            "        help=\"Download language/translation data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--wpt\",",
            "        dest=\"wpt\",",
            "        action=\"store_true\",",
            "        help=\"Download web-platform-tests data.\",",
            "    )",
            "",
            "    issueParser = subparsers.add_parser(",
            "        \"issues-list\",",
            "        help=\"Process a plain-text issues file into HTML. Call with no args to see an example input text.\",",
            "    )",
            "    issueParser.add_argument(",
            "        \"-t\",",
            "        dest=\"printTemplate\",",
            "        action=\"store_true\",",
            "        help=\"Output example Issues List template.\",",
            "    )",
            "    issueParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the plain-text issue file.\"",
            "    )",
            "    issueParser.add_argument(",
            "        \"outfile\",",
            "        nargs=\"?\",",
            "        default=None,",
            "        help=\"Path to the output file. Default is file of the same name as input, with .html.\",",
            "    )",
            "",
            "    debugParser = subparsers.add_parser(\"debug\", help=\"Run various debugging commands.\")",
            "    debugParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    debugCommands = debugParser.add_mutually_exclusive_group(required=True)",
            "    debugCommands.add_argument(",
            "        \"--print-exports\",",
            "        dest=\"printExports\",",
            "        action=\"store_true\",",
            "        help=\"Prints those terms that will be exported for cross-ref purposes.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print-refs-for\",",
            "        dest=\"linkText\",",
            "        help=\"Prints the ref data for a given link text.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print\", dest=\"code\", help=\"Runs the specified code and prints it.\"",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print-json\",",
            "        dest=\"jsonCode\",",
            "        help=\"Runs the specified code and prints it as formatted JSON.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--refresh-data\",",
            "        dest=\"refreshData\",",
            "        action=\"store_true\",",
            "        help=\"Clobbers the readonly data files with the mutable ones.\",",
            "    )",
            "",
            "    refParser = subparsers.add_parser(\"refs\", help=\"Search Bikeshed's ref database.\")",
            "    refParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    refParser.add_argument(\"--text\", dest=\"text\", default=None)",
            "    refParser.add_argument(\"--type\", dest=\"linkType\", default=None)",
            "    refParser.add_argument(\"--for\", dest=\"linkFor\", default=None)",
            "    refParser.add_argument(\"--spec\", dest=\"spec\", default=None)",
            "    refParser.add_argument(\"--status\", dest=\"status\", default=None)",
            "    refParser.add_argument(",
            "        \"--exact\",",
            "        dest=\"exact\",",
            "        action=\"store_true\",",
            "        help=\"Only search for the exact text provided; don't apply Bikeshed's automatic conjugation help for plurals/etc.\",",
            "    )",
            "    refParser.add_argument(",
            "        \"--latest-only\",",
            "        dest=\"latestOnly\",",
            "        action=\"store_true\",",
            "        help=\"Apply Bikeshed's logic for only returning the latest version of a given ref when it exists in multiple levels of a spec.\",",
            "    )",
            "",
            "    sourceParser = subparsers.add_parser(",
            "        \"source\", help=\"Tools for formatting the *source* document.\"",
            "    )",
            "    sourceParser.add_argument(",
            "        \"--big-text\",",
            "        dest=\"bigText\",",
            "        action=\"store_true\",",
            "        help=\"Finds HTML comments containing 'Big Text: foo' and turns them into comments containing 'foo' in big text.\",",
            "    )",
            "    sourceParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    sourceParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "",
            "    testParser = subparsers.add_parser(",
            "        \"test\", help=\"Tools for running Bikeshed's testsuite.\"",
            "    )",
            "    testParser.add_argument(",
            "        \"--rebase\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Rebase the specified files.\",",
            "    )",
            "    testParser.add_argument(",
            "        \"--manual-only\",",
            "        dest=\"manualOnly\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Skip testing the real-world files in the repo, and only run the manually-written ones.\",",
            "    )",
            "    testParser.add_argument(",
            "        \"testFiles\",",
            "        default=[],",
            "        metavar=\"FILE\",",
            "        nargs=\"*\",",
            "        help=\"Run these tests. If called with no args, tests everything.\",",
            "    )",
            "",
            "    profileParser = subparsers.add_parser(",
            "        \"profile\",",
            "        help=\"Profiling Bikeshed. Needs graphviz, gprof2dot, and xdot installed.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--root\",",
            "        dest=\"root\",",
            "        default=None,",
            "        metavar=\"ROOTFUNC\",",
            "        help=\"Prune the graph to start with the specified root node.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--leaf\",",
            "        dest=\"leaf\",",
            "        default=None,",
            "        metavar=\"LEAFFUNC\",",
            "        help=\"Prune the graph to only show ancestors of the specified leaf node.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--svg\",",
            "        dest=\"svgFile\",",
            "        default=None,",
            "        help=\"Save the graph to a specified SVG file, rather than outputting with xdot immediately.\",",
            "    )",
            "",
            "    subparsers.add_parser(",
            "        \"template\", help=\"Outputs a skeleton .bs file for you to start with.\"",
            "    )",
            "",
            "    wptParser = subparsers.add_parser(",
            "        \"wpt\", help=\"Tools for writing Web Platform Tests.\"",
            "    )",
            "    wptParser.add_argument(",
            "        \"--template\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Outputs a skeleton WPT file for you to start with.\",",
            "    )",
            "",
            "    options, extras = argparser.parse_known_args()",
            "",
            "    constants.quiet = options.quiet",
            "    if options.silent:",
            "        constants.quiet = float(\"infinity\")",
            "    constants.setErrorLevel(options.errorLevel)",
            "    constants.dryRun = options.dryRun",
            "    constants.asciiOnly = options.asciiOnly",
            "    if options.printMode is None:",
            "        if \"NO_COLOR\" in os.environ or os.environ.get(\"TERM\") == \"dumb\":",
            "            constants.printMode = \"plain\"",
            "        else:",
            "            constants.printMode = \"console\"",
            "    else:",
            "        constants.printMode = options.printMode",
            "",
            "    update.fixupDataFiles()",
            "    if options.subparserName == \"update\":",
            "        handleUpdate(options)",
            "    elif options.subparserName == \"spec\":",
            "        handleSpec(options, extras)",
            "    elif options.subparserName == \"echidna\":",
            "        handleEchidna(options, extras)",
            "    elif options.subparserName == \"watch\":",
            "        handleWatch(options, extras)",
            "    elif options.subparserName == \"serve\":",
            "        handleServe(options, extras)",
            "    elif options.subparserName == \"debug\":",
            "        handleDebug(options, extras)",
            "    elif options.subparserName == \"refs\":",
            "        handleRefs(options, extras)",
            "    elif options.subparserName == \"issues-list\":",
            "        handleIssuesList(options)",
            "    elif options.subparserName == \"source\":",
            "        handleSource(options)",
            "    elif options.subparserName == \"test\":",
            "        handleTest(options, extras)",
            "    elif options.subparserName == \"profile\":",
            "        handleProfile(options)",
            "    elif options.subparserName == \"template\":",
            "        handleTemplate()",
            "    elif options.subparserName == \"wpt\":",
            "        handleWpt(options)",
            "",
            "",
            "def handleUpdate(options):",
            "    update.update(",
            "        anchors=options.anchors,",
            "        backrefs=options.backrefs,",
            "        biblio=options.biblio,",
            "        caniuse=options.caniuse,",
            "        mdn=options.mdn,",
            "        linkDefaults=options.linkDefaults,",
            "        testSuites=options.testSuites,",
            "        languages=options.languages,",
            "        wpt=options.wpt,",
            "        dryRun=constants.dryRun,",
            "        force=options.force,",
            "    )",
            "",
            "",
            "def handleSpec(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    doc = Spec(",
            "        inputFilename=options.infile,",
            "        debug=options.debug,",
            "        token=options.ghToken,",
            "        lineNumbers=options.lineNumbers,",
            "    )",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.preprocess()",
            "    doc.finish(outputFilename=options.outfile)",
            "",
            "",
            "def handleEchidna(options, extras):",
            "    from . import metadata, publish",
            "    from .Spec import Spec",
            "",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    doc.mdCommandLine.addData(\"Prepare For TR\", \"yes\")",
            "    doc.preprocess()",
            "    addDirs = [] if options.selfContained else options.additionalDirectories",
            "    if options.justTar:",
            "        publish.prepareTar(doc, visibleTar=True, additionalDirectories=addDirs)",
            "    else:",
            "        publish.publishEchidna(",
            "            doc,",
            "            username=options.un,",
            "            password=options.pw,",
            "            decision=options.decision,",
            "            additionalDirectories=addDirs,",
            "            cc=options.cc,",
            "            editorial=options.editorial,",
            "        )",
            "",
            "",
            "def handleWatch(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    # Can't have an error killing the watcher",
            "    constants.setErrorLevel(\"nothing\")",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.watch(outputFilename=options.outfile)",
            "",
            "",
            "def handleServe(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.watch(outputFilename=options.outfile, port=int(options.port))",
            "",
            "",
            "def handleDebug(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 2",
            "    if options.printExports:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        doc.printTargets()",
            "    elif options.jsonCode:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        exec(f\"print(config.printjson({options.jsonCode}))\")",
            "    elif options.code:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        exec(f\"print({options.code})\")",
            "    elif options.linkText:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        refs = doc.refs[options.linkText] + doc.refs[options.linkText + \"\\n\"]",
            "        constants.quiet = options.quiet",
            "        if not constants.quiet:",
            "            p(f\"Refs for '{options.linkText}':\")",
            "        # Get ready for JSONing",
            "        for ref in refs:",
            "            ref[\"level\"] = str(ref[\"level\"])",
            "        p(config.printjson(refs))",
            "    elif options.refreshData:",
            "        constants.quiet = 0",
            "        update.updateReadonlyDataFiles()",
            "        warn(\"Don't forget to bump the version number!\")",
            "",
            "",
            "def handleRefs(options, extras):",
            "    from . import metadata",
            "    from .refs.ReferenceManager import ReferenceManager",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 10",
            "    doc = Spec(inputFilename=options.infile)",
            "    if doc.valid:",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        rm = doc.refs",
            "    else:",
            "        rm = ReferenceManager()",
            "        rm.initializeRefs()",
            "    if options.text:",
            "        options.text = options.text",
            "    refs = rm.queryAllRefs(",
            "        text=options.text,",
            "        linkFor=options.linkFor,",
            "        linkType=options.linkType,",
            "        status=options.status,",
            "        spec=options.spec,",
            "        latestOnly=options.latestOnly,",
            "        exact=options.exact,",
            "    )",
            "    if constants.printMode == \"json\":",
            "        p(json.dumps(refs, indent=2, default=getjson))",
            "    else:",
            "        p(config.printjson(refs))",
            "",
            "",
            "def handleIssuesList(options):",
            "    from . import issuelist",
            "",
            "    if options.printTemplate:",
            "        issuelist.printHelpMessage()",
            "    else:",
            "        issuelist.printIssueList(options.infile, options.outfile)",
            "",
            "",
            "def handleSource(options):",
            "    if not options.bigText:  # If no options are given, do all options.",
            "        options.bigText = True",
            "    if options.bigText:",
            "        from . import fonts",
            "",
            "        font = fonts.Font()",
            "        fonts.replaceComments(",
            "            font=font, inputFilename=options.infile, outputFilename=options.outfile",
            "        )",
            "",
            "",
            "def handleTest(options, extras):",
            "    from . import metadata, test",
            "",
            "    md = metadata.fromCommandLine(extras)",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 100",
            "    if options.rebase:",
            "        test.rebase(options.testFiles, md=md)",
            "    else:",
            "        result = test.runAllTests(",
            "            options.testFiles, manualOnly=options.manualOnly, md=md",
            "        )",
            "        sys.exit(0 if result else 1)",
            "",
            "",
            "def handleProfile(options):",
            "    root = f'--root=\"{options.root}\"' if options.root else \"\"",
            "    leaf = f'--leaf=\"{options.leaf}\"' if options.leaf else \"\"",
            "    if options.svgFile:",
            "        os.system(",
            "            \"time python -m cProfile -o stat.prof -m bikeshed -f spec && gprof2dot -f pstats --skew=.0001 {root} {leaf} stat.prof | dot -Tsvg -o {svg} && rm stat.prof\".format(",
            "                root=root, leaf=leaf, svg=options.svgFile",
            "            )",
            "        )",
            "    else:",
            "        os.system(",
            "            \"time python -m cProfile -o /tmp/stat.prof -m bikeshed -f spec && gprof2dot -f pstats --skew=.0001 {root} {leaf} /tmp/stat.prof | xdot &\".format(",
            "                root=root, leaf=leaf",
            "            )",
            "        )",
            "",
            "",
            "def handleTemplate():",
            "    p(",
            "        \"\"\"<pre class='metadata'>",
            "Title: Your Spec Title",
            "Shortname: your-spec",
            "Level: 1",
            "Status: ED",
            "Group: WGNAMEORWHATEVER",
            "URL: http://example.com/url-this-spec-will-live-at",
            "Editor: Your Name, Your Company http://example.com/your-company, your-email@example.com, http://example.com/your-personal-website",
            "Abstract: A short description of your spec, one or two sentences.",
            "</pre>",
            "",
            "Introduction {#intro}",
            "=====================",
            "",
            "Introduction here.",
            "\"\"\"",
            "    )",
            "",
            "",
            "def handleWpt(options):",
            "    if options.template:",
            "        p(",
            "            \"\"\"",
            "<!DOCTYPE html>",
            "<meta charset=utf-8>",
            "<title>window.offscreenBuffering</title>",
            "<link rel=author title=\"AUTHOR NAME HERE\" href=\"mailto:AUTHOR EMAIL HERE\">",
            "<link rel=help href=\"LINK TO ROUGHLY WHAT'S BEING TESTED HERE\">",
            "<script src=\"/resources/testharness.js\"></script>",
            "<script src=\"/resources/testharnessreport.js\"></script>",
            "<script>",
            "/* Choose the test type you want: */",
            "",
            "",
            "/* Standard, synchronous test */",
            "test(function() {",
            "    /* test code here */",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "",
            "",
            "/* Async test */",
            "let t = async_test(\"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "somethingWithACallback( function(){ t.step(()=>{ /* test code here */}) );",
            "something.addEventListener('foo', t.step_func(()=>{ /* test code here */}));",
            "t.done(); // when all tests are finished running",
            "// or call the following if there's only one test, automatically does .done() for you",
            "something.addEventListener('foo', t.step_func_done(()=>{ /* test code here */}));",
            "",
            "",
            "/* Promise test */",
            "promise_test(function(){",
            "    return somePromiseFunc().then(()=>{ /* test code here */ });",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "// auto-finishes when the returned promise fulfills",
            "// or if promise should reject:",
            "promise_test(function(t){",
            "    return promise_rejects(t, new ExpectedError(), somePromiseCode());",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "",
            "",
            "/* \"test code here\" Asserts */",
            "// Only use inside of /* test code here */ regions",
            "assert_true(VALUE HERE, \"TEST DESCRIPTION\");",
            "assert_equals(ACTUAL VALUE HERE, EXPECTED VALUE HERE, \"TEST DESCRIPTION\");",
            "// lots more at http://web-platform-tests.org/writing-tests/testharness-api.html#list-of-assertions",
            "</script>",
            "\"\"\"",
            "        )"
        ],
        "afterPatchFile": [
            "import argparse",
            "import json",
            "import os",
            "import sys",
            "",
            "from . import config, constants, update",
            "from .config.printjson import getjson",
            "from .messages import *",
            "",
            "",
            "def main():",
            "    # Hack around argparse's lack of optional subparsers",
            "    if len(sys.argv) == 1:",
            "        sys.argv.append(\"spec\")",
            "",
            "    try:",
            "        with open(config.scriptPath(\"..\", \"semver.txt\")) as fh:",
            "            semver = fh.read().strip()",
            "            semverText = f\"Bikeshed v{semver}: \"",
            "    except FileNotFoundError:",
            "        semver = \"???\"",
            "        semverText = \"\"",
            "",
            "    argparser = argparse.ArgumentParser(",
            "        description=f\"{semverText}Processes spec source files into valid HTML.\"",
            "    )",
            "    argparser.add_argument(\"--version\", action=\"version\", version=semver)",
            "    argparser.add_argument(",
            "        \"-q\",",
            "        \"--quiet\",",
            "        dest=\"quiet\",",
            "        action=\"count\",",
            "        default=0,",
            "        help=\"Silences one level of message, least-important first.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-s\",",
            "        \"--silent\",",
            "        dest=\"silent\",",
            "        action=\"store_true\",",
            "        help=\"Shorthand for 'as many -q as you need to shut it up'\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-f\",",
            "        \"--force\",",
            "        dest=\"errorLevel\",",
            "        action=\"store_const\",",
            "        const=\"nothing\",",
            "        help=\"Force the preprocessor to run to completion; fatal errors don't stop processing.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-d\",",
            "        \"--dry-run\",",
            "        dest=\"dryRun\",",
            "        action=\"store_true\",",
            "        help=\"Prevents the processor from actually saving anything to disk, but otherwise fully runs.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"-a\",",
            "        \"--ascii-only\",",
            "        dest=\"asciiOnly\",",
            "        action=\"store_true\",",
            "        help=\"Force all Bikeshed messages to be ASCII-only.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"--print\",",
            "        dest=\"printMode\",",
            "        action=\"store\",",
            "        default=None,",
            "        help=\"Print mode. Options are 'plain' (just text), 'console' (colored with console color codes), 'markup', and 'json'. Defaults to 'console'.\",",
            "    )",
            "    argparser.add_argument(",
            "        \"--die-on\",",
            "        dest=\"errorLevel\",",
            "        choices=[\"nothing\", \"fatal\", \"link-error\", \"warning\", \"everything\"],",
            "        help=\"Determines what sorts of errors cause Bikeshed to die (quit immediately with an error status code). Default is 'fatal'; the -f flag is a shorthand for 'nothing'\",",
            "    )",
            "    argparser.add_argument(",
            "        \"--allow-nonlocal-files\",",
            "        dest=\"allowNonlocalFiles\",",
            "        action=\"store_true\",",
            "        help=\"Allows Bikeshed to see/include files from folders higher than the one your source document is in.\"",
            "    )",
            "    argparser.add_argument(",
            "        \"--allow-execute\",",
            "        dest=\"allowExecute\",",
            "        action=\"store_true\",",
            "        help=\"Allow some features to execute arbitrary code from outside the Bikeshed codebase.\"",
            "    )",
            "",
            "    subparsers = argparser.add_subparsers(title=\"Subcommands\", dest=\"subparserName\")",
            "",
            "    specParser = subparsers.add_parser(",
            "        \"spec\", help=\"Process a spec source file into a valid output file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    specParser.add_argument(",
            "        \"--debug\",",
            "        dest=\"debug\",",
            "        action=\"store_true\",",
            "        help=\"Switches on some debugging tools. Don't use for production!\",",
            "    )",
            "    specParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    specParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "    specParser.add_argument(",
            "        \"-l\",",
            "        \"--line-numbers\",",
            "        dest=\"lineNumbers\",",
            "        action=\"store_true\",",
            "        help=\"Hacky support for outputting line numbers on all error messages. Disables output, as this is hacky and might mess up your source.\",",
            "    )",
            "",
            "    echidnaParser = subparsers.add_parser(",
            "        \"echidna\",",
            "        help=\"Process a spec source file into a valid output file and publish it according to certain automatic protocols.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--u\", dest=\"un\", metavar=\"USERNAME\", required=False, help=\"W3C username.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--p\", dest=\"pw\", metavar=\"PASSWORD\", required=False, help=\"W3C password.\"",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--decision\",",
            "        dest=\"decision\",",
            "        metavar=\"DECISION_URL\",",
            "        required=False,",
            "        help=\"URL recording the decision to publish.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--editorial\",",
            "        dest=\"editorial\",",
            "        action=\"store_true\",",
            "        required=False,",
            "        help=\"Flags update as editorial.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--cc\",",
            "        dest=\"cc\",",
            "        metavar=\"EMAIL\",",
            "        required=False,",
            "        help=\"Comma-separated list of email addresses to ping with the publication status when complete.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--additional-directories\",",
            "        dest=\"additionalDirectories\",",
            "        required=False,",
            "        nargs=\"*\",",
            "        help=\"Directories to bundle in the tar file. Defaults to examples/, diagrams/, and images/.\",",
            "    )",
            "    echidnaParser.add_argument(",
            "        \"--self-contained\",",
            "        dest=\"selfContained\",",
            "        action=\"store_true\",",
            "        help=\"The spec is self-contained, do not bundle any extra directories in the tar file.\",",
            "    )",
            "    echidnaParser.add_argument(\"--just-tar\", dest=\"justTar\", action=\"store_true\")",
            "",
            "    watchParser = subparsers.add_parser(",
            "        \"watch\",",
            "        help=\"Process a spec source file into a valid output file, automatically rebuilding when it changes.\",",
            "    )",
            "    watchParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    watchParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    watchParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    watchParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "",
            "    serveParser = subparsers.add_parser(",
            "        \"serve\", help=\"Identical to 'watch', but also serves the folder on localhost.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "    serveParser.add_argument(",
            "        \"--port\",",
            "        dest=\"port\",",
            "        nargs=\"?\",",
            "        default=\"8000\",",
            "        help=\"Specify the port to serve it over.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--localhost\",",
            "        dest=\"localhost\",",
            "        action=\"store_true\",",
            "        help=\"Only allow connections from localhost.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--gh-token\",",
            "        dest=\"ghToken\",",
            "        nargs=\"?\",",
            "        help=\"GitHub access token. Useful to avoid API rate limits. Generate tokens: https://github.com/settings/tokens.\",",
            "    )",
            "    serveParser.add_argument(",
            "        \"--byos\",",
            "        dest=\"byos\",",
            "        action=\"store_true\",",
            "        help=\"Bring-Your-Own-Spec: turns off all the Bikeshed auto-niceties, so you can piecemeal its features into your existing doc instead. Experimental, let me know if things get crashy or weird.\",",
            "    )",
            "",
            "    updateParser = subparsers.add_parser(",
            "        \"update\",",
            "        help=\"Update supporting files (those in /spec-data).\",",
            "        epilog=\"If no options are specified, everything is downloaded.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--skip-manifest\",",
            "        dest=\"force\",",
            "        action=\"store_true\",",
            "        help=\"Forces Bikeshed to do a full update manually, rather than using the manifest to get the preprocessed update (which can be several minutes old).\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--anchors\", action=\"store_true\", help=\"Download crossref anchor data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--backrefs\", action=\"store_true\", help=\"Download link backref data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--biblio\", action=\"store_true\", help=\"Download biblio data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--caniuse\", action=\"store_true\", help=\"Download Can I Use... data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--mdn\", action=\"store_true\", help=\"Download MDN Spec Links... data.\"",
            "    )",
            "    updateParser.add_argument(",
            "        \"--link-defaults\",",
            "        dest=\"linkDefaults\",",
            "        action=\"store_true\",",
            "        help=\"Download link default data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--test-suites\",",
            "        dest=\"testSuites\",",
            "        action=\"store_true\",",
            "        help=\"Download test suite data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--languages\",",
            "        dest=\"languages\",",
            "        action=\"store_true\",",
            "        help=\"Download language/translation data.\",",
            "    )",
            "    updateParser.add_argument(",
            "        \"--wpt\",",
            "        dest=\"wpt\",",
            "        action=\"store_true\",",
            "        help=\"Download web-platform-tests data.\",",
            "    )",
            "",
            "    issueParser = subparsers.add_parser(",
            "        \"issues-list\",",
            "        help=\"Process a plain-text issues file into HTML. Call with no args to see an example input text.\",",
            "    )",
            "    issueParser.add_argument(",
            "        \"-t\",",
            "        dest=\"printTemplate\",",
            "        action=\"store_true\",",
            "        help=\"Output example Issues List template.\",",
            "    )",
            "    issueParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the plain-text issue file.\"",
            "    )",
            "    issueParser.add_argument(",
            "        \"outfile\",",
            "        nargs=\"?\",",
            "        default=None,",
            "        help=\"Path to the output file. Default is file of the same name as input, with .html.\",",
            "    )",
            "",
            "    debugParser = subparsers.add_parser(\"debug\", help=\"Run various debugging commands.\")",
            "    debugParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    debugCommands = debugParser.add_mutually_exclusive_group(required=True)",
            "    debugCommands.add_argument(",
            "        \"--print-exports\",",
            "        dest=\"printExports\",",
            "        action=\"store_true\",",
            "        help=\"Prints those terms that will be exported for cross-ref purposes.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print-refs-for\",",
            "        dest=\"linkText\",",
            "        help=\"Prints the ref data for a given link text.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print\", dest=\"code\", help=\"Runs the specified code and prints it.\"",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--print-json\",",
            "        dest=\"jsonCode\",",
            "        help=\"Runs the specified code and prints it as formatted JSON.\",",
            "    )",
            "    debugCommands.add_argument(",
            "        \"--refresh-data\",",
            "        dest=\"refreshData\",",
            "        action=\"store_true\",",
            "        help=\"Clobbers the readonly data files with the mutable ones.\",",
            "    )",
            "",
            "    refParser = subparsers.add_parser(\"refs\", help=\"Search Bikeshed's ref database.\")",
            "    refParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    refParser.add_argument(\"--text\", dest=\"text\", default=None)",
            "    refParser.add_argument(\"--type\", dest=\"linkType\", default=None)",
            "    refParser.add_argument(\"--for\", dest=\"linkFor\", default=None)",
            "    refParser.add_argument(\"--spec\", dest=\"spec\", default=None)",
            "    refParser.add_argument(\"--status\", dest=\"status\", default=None)",
            "    refParser.add_argument(",
            "        \"--exact\",",
            "        dest=\"exact\",",
            "        action=\"store_true\",",
            "        help=\"Only search for the exact text provided; don't apply Bikeshed's automatic conjugation help for plurals/etc.\",",
            "    )",
            "    refParser.add_argument(",
            "        \"--latest-only\",",
            "        dest=\"latestOnly\",",
            "        action=\"store_true\",",
            "        help=\"Apply Bikeshed's logic for only returning the latest version of a given ref when it exists in multiple levels of a spec.\",",
            "    )",
            "",
            "    sourceParser = subparsers.add_parser(",
            "        \"source\", help=\"Tools for formatting the *source* document.\"",
            "    )",
            "    sourceParser.add_argument(",
            "        \"--big-text\",",
            "        dest=\"bigText\",",
            "        action=\"store_true\",",
            "        help=\"Finds HTML comments containing 'Big Text: foo' and turns them into comments containing 'foo' in big text.\",",
            "    )",
            "    sourceParser.add_argument(",
            "        \"infile\", nargs=\"?\", default=None, help=\"Path to the source file.\"",
            "    )",
            "    sourceParser.add_argument(",
            "        \"outfile\", nargs=\"?\", default=None, help=\"Path to the output file.\"",
            "    )",
            "",
            "    testParser = subparsers.add_parser(",
            "        \"test\", help=\"Tools for running Bikeshed's testsuite.\"",
            "    )",
            "    testParser.add_argument(",
            "        \"--rebase\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Rebase the specified files.\",",
            "    )",
            "    testParser.add_argument(",
            "        \"--manual-only\",",
            "        dest=\"manualOnly\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Skip testing the real-world files in the repo, and only run the manually-written ones.\",",
            "    )",
            "    testParser.add_argument(",
            "        \"testFiles\",",
            "        default=[],",
            "        metavar=\"FILE\",",
            "        nargs=\"*\",",
            "        help=\"Run these tests. If called with no args, tests everything.\",",
            "    )",
            "",
            "    profileParser = subparsers.add_parser(",
            "        \"profile\",",
            "        help=\"Profiling Bikeshed. Needs graphviz, gprof2dot, and xdot installed.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--root\",",
            "        dest=\"root\",",
            "        default=None,",
            "        metavar=\"ROOTFUNC\",",
            "        help=\"Prune the graph to start with the specified root node.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--leaf\",",
            "        dest=\"leaf\",",
            "        default=None,",
            "        metavar=\"LEAFFUNC\",",
            "        help=\"Prune the graph to only show ancestors of the specified leaf node.\",",
            "    )",
            "    profileParser.add_argument(",
            "        \"--svg\",",
            "        dest=\"svgFile\",",
            "        default=None,",
            "        help=\"Save the graph to a specified SVG file, rather than outputting with xdot immediately.\",",
            "    )",
            "",
            "    subparsers.add_parser(",
            "        \"template\", help=\"Outputs a skeleton .bs file for you to start with.\"",
            "    )",
            "",
            "    wptParser = subparsers.add_parser(",
            "        \"wpt\", help=\"Tools for writing Web Platform Tests.\"",
            "    )",
            "    wptParser.add_argument(",
            "        \"--template\",",
            "        default=False,",
            "        action=\"store_true\",",
            "        help=\"Outputs a skeleton WPT file for you to start with.\",",
            "    )",
            "",
            "    options, extras = argparser.parse_known_args()",
            "",
            "    constants.quiet = options.quiet",
            "    if options.silent:",
            "        constants.quiet = float(\"infinity\")",
            "    constants.setErrorLevel(options.errorLevel)",
            "    constants.dryRun = options.dryRun",
            "    constants.asciiOnly = options.asciiOnly",
            "    if options.printMode is None:",
            "        if \"NO_COLOR\" in os.environ or os.environ.get(\"TERM\") == \"dumb\":",
            "            constants.printMode = \"plain\"",
            "        else:",
            "            constants.printMode = \"console\"",
            "    else:",
            "        constants.printMode = options.printMode",
            "    constants.chroot = not options.allowNonlocalFiles",
            "    constants.executeCode = options.allowExecute",
            "",
            "    update.fixupDataFiles()",
            "    if options.subparserName == \"update\":",
            "        handleUpdate(options)",
            "    elif options.subparserName == \"spec\":",
            "        handleSpec(options, extras)",
            "    elif options.subparserName == \"echidna\":",
            "        handleEchidna(options, extras)",
            "    elif options.subparserName == \"watch\":",
            "        handleWatch(options, extras)",
            "    elif options.subparserName == \"serve\":",
            "        handleServe(options, extras)",
            "    elif options.subparserName == \"debug\":",
            "        handleDebug(options, extras)",
            "    elif options.subparserName == \"refs\":",
            "        handleRefs(options, extras)",
            "    elif options.subparserName == \"issues-list\":",
            "        handleIssuesList(options)",
            "    elif options.subparserName == \"source\":",
            "        handleSource(options)",
            "    elif options.subparserName == \"test\":",
            "        handleTest(options, extras)",
            "    elif options.subparserName == \"profile\":",
            "        handleProfile(options)",
            "    elif options.subparserName == \"template\":",
            "        handleTemplate()",
            "    elif options.subparserName == \"wpt\":",
            "        handleWpt(options)",
            "",
            "",
            "def handleUpdate(options):",
            "    update.update(",
            "        anchors=options.anchors,",
            "        backrefs=options.backrefs,",
            "        biblio=options.biblio,",
            "        caniuse=options.caniuse,",
            "        mdn=options.mdn,",
            "        linkDefaults=options.linkDefaults,",
            "        testSuites=options.testSuites,",
            "        languages=options.languages,",
            "        wpt=options.wpt,",
            "        dryRun=constants.dryRun,",
            "        force=options.force,",
            "    )",
            "",
            "",
            "def handleSpec(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    doc = Spec(",
            "        inputFilename=options.infile,",
            "        debug=options.debug,",
            "        token=options.ghToken,",
            "        lineNumbers=options.lineNumbers,",
            "    )",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.preprocess()",
            "    doc.finish(outputFilename=options.outfile)",
            "",
            "",
            "def handleEchidna(options, extras):",
            "    from . import metadata, publish",
            "    from .Spec import Spec",
            "",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    doc.mdCommandLine.addData(\"Prepare For TR\", \"yes\")",
            "    doc.preprocess()",
            "    addDirs = [] if options.selfContained else options.additionalDirectories",
            "    if options.justTar:",
            "        publish.prepareTar(doc, visibleTar=True, additionalDirectories=addDirs)",
            "    else:",
            "        publish.publishEchidna(",
            "            doc,",
            "            username=options.un,",
            "            password=options.pw,",
            "            decision=options.decision,",
            "            additionalDirectories=addDirs,",
            "            cc=options.cc,",
            "            editorial=options.editorial,",
            "        )",
            "",
            "",
            "def handleWatch(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    # Can't have an error killing the watcher",
            "    constants.setErrorLevel(\"nothing\")",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.watch(outputFilename=options.outfile)",
            "",
            "",
            "def handleServe(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    doc = Spec(inputFilename=options.infile, token=options.ghToken)",
            "    doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "    if options.byos:",
            "        doc.mdCommandLine.addData(\"Group\", \"byos\")",
            "    doc.watch(outputFilename=options.outfile, port=int(options.port))",
            "",
            "",
            "def handleDebug(options, extras):",
            "    from . import metadata",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 2",
            "    if options.printExports:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        doc.printTargets()",
            "    elif options.jsonCode:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        exec(f\"print(config.printjson({options.jsonCode}))\")",
            "    elif options.code:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        exec(f\"print({options.code})\")",
            "    elif options.linkText:",
            "        doc = Spec(inputFilename=options.infile)",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        refs = doc.refs[options.linkText] + doc.refs[options.linkText + \"\\n\"]",
            "        constants.quiet = options.quiet",
            "        if not constants.quiet:",
            "            p(f\"Refs for '{options.linkText}':\")",
            "        # Get ready for JSONing",
            "        for ref in refs:",
            "            ref[\"level\"] = str(ref[\"level\"])",
            "        p(config.printjson(refs))",
            "    elif options.refreshData:",
            "        constants.quiet = 0",
            "        update.updateReadonlyDataFiles()",
            "        warn(\"Don't forget to bump the version number!\")",
            "",
            "",
            "def handleRefs(options, extras):",
            "    from . import metadata",
            "    from .refs.ReferenceManager import ReferenceManager",
            "    from .Spec import Spec",
            "",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 10",
            "    doc = Spec(inputFilename=options.infile)",
            "    if doc.valid:",
            "        doc.mdCommandLine = metadata.fromCommandLine(extras)",
            "        doc.preprocess()",
            "        rm = doc.refs",
            "    else:",
            "        rm = ReferenceManager()",
            "        rm.initializeRefs()",
            "    if options.text:",
            "        options.text = options.text",
            "    refs = rm.queryAllRefs(",
            "        text=options.text,",
            "        linkFor=options.linkFor,",
            "        linkType=options.linkType,",
            "        status=options.status,",
            "        spec=options.spec,",
            "        latestOnly=options.latestOnly,",
            "        exact=options.exact,",
            "    )",
            "    if constants.printMode == \"json\":",
            "        p(json.dumps(refs, indent=2, default=getjson))",
            "    else:",
            "        p(config.printjson(refs))",
            "",
            "",
            "def handleIssuesList(options):",
            "    from . import issuelist",
            "",
            "    if options.printTemplate:",
            "        issuelist.printHelpMessage()",
            "    else:",
            "        issuelist.printIssueList(options.infile, options.outfile)",
            "",
            "",
            "def handleSource(options):",
            "    if not options.bigText:  # If no options are given, do all options.",
            "        options.bigText = True",
            "    if options.bigText:",
            "        from . import fonts",
            "",
            "        font = fonts.Font()",
            "        fonts.replaceComments(",
            "            font=font, inputFilename=options.infile, outputFilename=options.outfile",
            "        )",
            "",
            "",
            "def handleTest(options, extras):",
            "    from . import metadata, test",
            "",
            "    md = metadata.fromCommandLine(extras)",
            "    constants.setErrorLevel(\"nothing\")",
            "    constants.quiet = 100",
            "    if options.rebase:",
            "        test.rebase(options.testFiles, md=md)",
            "    else:",
            "        result = test.runAllTests(",
            "            options.testFiles, manualOnly=options.manualOnly, md=md",
            "        )",
            "        sys.exit(0 if result else 1)",
            "",
            "",
            "def handleProfile(options):",
            "    root = f'--root=\"{options.root}\"' if options.root else \"\"",
            "    leaf = f'--leaf=\"{options.leaf}\"' if options.leaf else \"\"",
            "    if options.svgFile:",
            "        os.system(",
            "            \"time python -m cProfile -o stat.prof -m bikeshed -f spec && gprof2dot -f pstats --skew=.0001 {root} {leaf} stat.prof | dot -Tsvg -o {svg} && rm stat.prof\".format(",
            "                root=root, leaf=leaf, svg=options.svgFile",
            "            )",
            "        )",
            "    else:",
            "        os.system(",
            "            \"time python -m cProfile -o /tmp/stat.prof -m bikeshed -f spec && gprof2dot -f pstats --skew=.0001 {root} {leaf} /tmp/stat.prof | xdot &\".format(",
            "                root=root, leaf=leaf",
            "            )",
            "        )",
            "",
            "",
            "def handleTemplate():",
            "    p(",
            "        \"\"\"<pre class='metadata'>",
            "Title: Your Spec Title",
            "Shortname: your-spec",
            "Level: 1",
            "Status: ED",
            "Group: WGNAMEORWHATEVER",
            "URL: http://example.com/url-this-spec-will-live-at",
            "Editor: Your Name, Your Company http://example.com/your-company, your-email@example.com, http://example.com/your-personal-website",
            "Abstract: A short description of your spec, one or two sentences.",
            "</pre>",
            "",
            "Introduction {#intro}",
            "=====================",
            "",
            "Introduction here.",
            "\"\"\"",
            "    )",
            "",
            "",
            "def handleWpt(options):",
            "    if options.template:",
            "        p(",
            "            \"\"\"",
            "<!DOCTYPE html>",
            "<meta charset=utf-8>",
            "<title>window.offscreenBuffering</title>",
            "<link rel=author title=\"AUTHOR NAME HERE\" href=\"mailto:AUTHOR EMAIL HERE\">",
            "<link rel=help href=\"LINK TO ROUGHLY WHAT'S BEING TESTED HERE\">",
            "<script src=\"/resources/testharness.js\"></script>",
            "<script src=\"/resources/testharnessreport.js\"></script>",
            "<script>",
            "/* Choose the test type you want: */",
            "",
            "",
            "/* Standard, synchronous test */",
            "test(function() {",
            "    /* test code here */",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "",
            "",
            "/* Async test */",
            "let t = async_test(\"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "somethingWithACallback( function(){ t.step(()=>{ /* test code here */}) );",
            "something.addEventListener('foo', t.step_func(()=>{ /* test code here */}));",
            "t.done(); // when all tests are finished running",
            "// or call the following if there's only one test, automatically does .done() for you",
            "something.addEventListener('foo', t.step_func_done(()=>{ /* test code here */}));",
            "",
            "",
            "/* Promise test */",
            "promise_test(function(){",
            "    return somePromiseFunc().then(()=>{ /* test code here */ });",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "// auto-finishes when the returned promise fulfills",
            "// or if promise should reject:",
            "promise_test(function(t){",
            "    return promise_rejects(t, new ExpectedError(), somePromiseCode());",
            "}, \"TEST NAME HERE / SHORT DESCRIPTION PHRASE\");",
            "",
            "",
            "/* \"test code here\" Asserts */",
            "// Only use inside of /* test code here */ regions",
            "assert_true(VALUE HERE, \"TEST DESCRIPTION\");",
            "assert_equals(ACTUAL VALUE HERE, EXPECTED VALUE HERE, \"TEST DESCRIPTION\");",
            "// lots more at http://web-platform-tests.org/writing-tests/testharness-api.html#list-of-assertions",
            "</script>",
            "\"\"\"",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "jinja2.nodes.Const.from_untrusted"
        ]
    },
    "bikeshed/config/main.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import lxml"
            },
            "2": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from .. import constants"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+from .. import messages"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " def englishFromList(items, conjunction=\"or\"):"
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 12,
                "PatchRowcode": "     # Format a list of strings into an English list."
            },
            "9": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 171,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 172,
                "PatchRowcode": " def scriptPath(*pathSegs):"
            },
            "11": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "     startPath = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))"
            },
            "12": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return os.path.join(startPath, *pathSegs)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+    path = os.path.join(startPath, *pathSegs)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+    return path"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 178,
                "PatchRowcode": "+def chrootPath(chrootPath, path):"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 179,
                "PatchRowcode": "+    chrootPath = os.path.abspath(chrootPath)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+    path = os.path.abspath(path)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+    if not path.startswith(chrootPath):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+        messages.die(f\"Attempted to access a file ({path}) outside the source document's directory ({chrootPath}). See --allow-nonlocal-files.\")"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+        raise Exception()"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+    else:"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+        return path"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 186,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 187,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 188,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 189,
                "PatchRowcode": " def doEvery(s, action, lastTime=None):"
            }
        },
        "frontPatchFile": [
            "import collections",
            "import os",
            "import re",
            "",
            "import lxml",
            "",
            "",
            "def englishFromList(items, conjunction=\"or\"):",
            "    # Format a list of strings into an English list.",
            "    items = list(items)",
            "    if len(items) == 1:",
            "        return items[0]",
            "    if len(items) == 2:",
            "        return \"{0} {2} {1}\".format(items[0], items[1], conjunction)",
            "    return \"{0}, {2} {1}\".format(\", \".join(items[:-1]), items[-1], conjunction)",
            "",
            "",
            "def intersperse(iterable, delimiter):",
            "    it = iter(iterable)",
            "    yield next(it)",
            "    for x in it:",
            "        yield delimiter",
            "        yield x",
            "",
            "",
            "def processTextNodes(nodes, regex, replacer):",
            "    \"\"\"",
            "    Takes an array of alternating text/objects,",
            "    and runs reSubObject on the text parts,",
            "    splicing them into the passed-in array.",
            "    Mutates!",
            "    \"\"\"",
            "    for i, node in enumerate(nodes):",
            "        # Node list always alternates between text and elements",
            "        if i % 2 == 0:",
            "            nodes[i : i + 1] = reSubObject(regex, node, replacer)",
            "    return nodes",
            "",
            "",
            "def reSubObject(pattern, string, repl=None):",
            "    \"\"\"",
            "    like re.sub, but replacements don't have to be text;",
            "    returns an array of alternating unmatched text and match objects instead.",
            "    If repl is specified, it's called with each match object,",
            "    and the result then shows up in the array instead.",
            "    \"\"\"",
            "    lastEnd = 0",
            "    pieces = []",
            "    for match in pattern.finditer(string):",
            "        pieces.append(string[lastEnd : match.start()])",
            "        if repl:",
            "            pieces.append(repl(match))",
            "        else:",
            "            pieces.append(match)",
            "        lastEnd = match.end()",
            "    pieces.append(string[lastEnd:])",
            "    return pieces",
            "",
            "",
            "def simplifyText(text):",
            "    # Remove anything that's not a name character.",
            "    text = text.strip().lower()",
            "    # I convert ( to - so foo(bar) becomes foo-bar,",
            "    # but then I have to remove () because there's nothing to separate,",
            "    # otherwise I get a double-dash in some cases.",
            "    text = re.sub(r\"\\(\\)\", \"\", text)",
            "    text = re.sub(r\"[\\s/(,]+\", \"-\", text)",
            "    text = re.sub(r\"[^a-z0-9_-]\", \"\", text)",
            "    text = text.rstrip(\"-\")",
            "    return text",
            "",
            "",
            "def linkTextsFromElement(el):",
            "    from ..h import find, textContent",
            "",
            "    if el.get(\"data-lt\") == \"\":",
            "        return []",
            "    elif el.get(\"data-lt\"):",
            "        rawText = el.get(\"data-lt\")",
            "        if rawText in [\"|\", \"||\", \"|||\"]:",
            "            texts = [rawText]",
            "        else:",
            "            texts = [x.strip() for x in rawText.split(\"|\")]",
            "    else:",
            "        if el.tag in (\"dfn\", \"a\"):",
            "            texts = [textContent(el).strip()]",
            "        elif el.tag in (\"h2\", \"h3\", \"h4\", \"h5\", \"h6\"):",
            "            texts = [textContent(find(\".content\", el)).strip()]",
            "    if el.get(\"data-local-lt\"):",
            "        localTexts = [x.strip() for x in el.get(\"data-local-lt\").split(\"|\")]",
            "        for text in localTexts:",
            "            if text in texts:",
            "                # lt and local-lt both specify the same thing",
            "                raise DuplicatedLinkText(text, texts + localTexts, el)",
            "        texts += localTexts",
            "",
            "    texts = [re.sub(r\"\\s+\", \" \", x) for x in texts if x != \"\"]",
            "    return texts",
            "",
            "",
            "class DuplicatedLinkText(Exception):",
            "    def __init__(self, offendingText, allTexts, el):",
            "        super().__init__()",
            "        self.offendingText = offendingText",
            "        self.allTexts = allTexts",
            "        self.el = el",
            "",
            "    def __unicode__(self):",
            "        return f\"<Text '{self.offendingText}' shows up in both lt and local-lt>\"",
            "",
            "",
            "def firstLinkTextFromElement(el):",
            "    try:",
            "        texts = linkTextsFromElement(el)",
            "    except DuplicatedLinkText as e:",
            "        texts = e.allTexts",
            "    return texts[0] if len(texts) > 0 else None",
            "",
            "",
            "def splitForValues(forValues):",
            "    \"\"\"",
            "    Splits a string of 1+ \"for\" values into an array of individual value.",
            "    Respects function args, etc.",
            "    Currently, for values are separated by commas.",
            "    \"\"\"",
            "    if forValues is None:",
            "        return None",
            "    forValues = re.sub(r\"\\s+\", \" \", forValues)",
            "    return [",
            "        value.strip()",
            "        for value in re.split(r\",(?![^()]*\\))\", forValues)",
            "        if value.strip()",
            "    ]",
            "",
            "",
            "def groupFromKey(key, length=2):",
            "    \"\"\"Generates a filename-safe \"group\" from a key, of a specified length.\"\"\"",
            "    if key in _groupFromKeyCache:",
            "        return _groupFromKeyCache[key]",
            "    safeChars = frozenset(\"abcdefghijklmnopqrstuvwxyz0123456789\")",
            "    group = \"\"",
            "    for char in key.lower():",
            "        if len(group) == length:",
            "            _groupFromKeyCache[key] = group",
            "            return group",
            "        if char in safeChars:",
            "            group += char",
            "    else:",
            "        group = group.ljust(length, \"_\")",
            "        _groupFromKeyCache[key] = group",
            "        return group",
            "",
            "",
            "_groupFromKeyCache = {}",
            "",
            "",
            "def flatten(arr):",
            "    for el in arr:",
            "        if (",
            "            isinstance(el, collections.Iterable)",
            "            and not isinstance(el, str)",
            "            and not lxml.etree.iselement(el)",
            "        ):",
            "            yield from flatten(el)",
            "        else:",
            "            yield el",
            "",
            "",
            "def scriptPath(*pathSegs):",
            "    startPath = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))",
            "    return os.path.join(startPath, *pathSegs)",
            "",
            "",
            "def doEvery(s, action, lastTime=None):",
            "    # Takes an action every N seconds.",
            "    # Pass it the duration and the last time it took the action;",
            "    # it returns the time it last took the action",
            "    # (possibly just now).",
            "    # If you want to take action on first call,",
            "    # pass 0 as lastTime;",
            "    # otherwise it won't take action until N seconds.",
            "    import time",
            "",
            "    newTime = time.time()",
            "    if lastTime is None:",
            "        lastTime = newTime",
            "    if lastTime == 0 or newTime - lastTime > s:",
            "        action()",
            "        return newTime",
            "    return lastTime"
        ],
        "afterPatchFile": [
            "import collections",
            "import os",
            "import re",
            "",
            "import lxml",
            "",
            "from .. import constants",
            "from .. import messages",
            "",
            "",
            "def englishFromList(items, conjunction=\"or\"):",
            "    # Format a list of strings into an English list.",
            "    items = list(items)",
            "    if len(items) == 1:",
            "        return items[0]",
            "    if len(items) == 2:",
            "        return \"{0} {2} {1}\".format(items[0], items[1], conjunction)",
            "    return \"{0}, {2} {1}\".format(\", \".join(items[:-1]), items[-1], conjunction)",
            "",
            "",
            "def intersperse(iterable, delimiter):",
            "    it = iter(iterable)",
            "    yield next(it)",
            "    for x in it:",
            "        yield delimiter",
            "        yield x",
            "",
            "",
            "def processTextNodes(nodes, regex, replacer):",
            "    \"\"\"",
            "    Takes an array of alternating text/objects,",
            "    and runs reSubObject on the text parts,",
            "    splicing them into the passed-in array.",
            "    Mutates!",
            "    \"\"\"",
            "    for i, node in enumerate(nodes):",
            "        # Node list always alternates between text and elements",
            "        if i % 2 == 0:",
            "            nodes[i : i + 1] = reSubObject(regex, node, replacer)",
            "    return nodes",
            "",
            "",
            "def reSubObject(pattern, string, repl=None):",
            "    \"\"\"",
            "    like re.sub, but replacements don't have to be text;",
            "    returns an array of alternating unmatched text and match objects instead.",
            "    If repl is specified, it's called with each match object,",
            "    and the result then shows up in the array instead.",
            "    \"\"\"",
            "    lastEnd = 0",
            "    pieces = []",
            "    for match in pattern.finditer(string):",
            "        pieces.append(string[lastEnd : match.start()])",
            "        if repl:",
            "            pieces.append(repl(match))",
            "        else:",
            "            pieces.append(match)",
            "        lastEnd = match.end()",
            "    pieces.append(string[lastEnd:])",
            "    return pieces",
            "",
            "",
            "def simplifyText(text):",
            "    # Remove anything that's not a name character.",
            "    text = text.strip().lower()",
            "    # I convert ( to - so foo(bar) becomes foo-bar,",
            "    # but then I have to remove () because there's nothing to separate,",
            "    # otherwise I get a double-dash in some cases.",
            "    text = re.sub(r\"\\(\\)\", \"\", text)",
            "    text = re.sub(r\"[\\s/(,]+\", \"-\", text)",
            "    text = re.sub(r\"[^a-z0-9_-]\", \"\", text)",
            "    text = text.rstrip(\"-\")",
            "    return text",
            "",
            "",
            "def linkTextsFromElement(el):",
            "    from ..h import find, textContent",
            "",
            "    if el.get(\"data-lt\") == \"\":",
            "        return []",
            "    elif el.get(\"data-lt\"):",
            "        rawText = el.get(\"data-lt\")",
            "        if rawText in [\"|\", \"||\", \"|||\"]:",
            "            texts = [rawText]",
            "        else:",
            "            texts = [x.strip() for x in rawText.split(\"|\")]",
            "    else:",
            "        if el.tag in (\"dfn\", \"a\"):",
            "            texts = [textContent(el).strip()]",
            "        elif el.tag in (\"h2\", \"h3\", \"h4\", \"h5\", \"h6\"):",
            "            texts = [textContent(find(\".content\", el)).strip()]",
            "    if el.get(\"data-local-lt\"):",
            "        localTexts = [x.strip() for x in el.get(\"data-local-lt\").split(\"|\")]",
            "        for text in localTexts:",
            "            if text in texts:",
            "                # lt and local-lt both specify the same thing",
            "                raise DuplicatedLinkText(text, texts + localTexts, el)",
            "        texts += localTexts",
            "",
            "    texts = [re.sub(r\"\\s+\", \" \", x) for x in texts if x != \"\"]",
            "    return texts",
            "",
            "",
            "class DuplicatedLinkText(Exception):",
            "    def __init__(self, offendingText, allTexts, el):",
            "        super().__init__()",
            "        self.offendingText = offendingText",
            "        self.allTexts = allTexts",
            "        self.el = el",
            "",
            "    def __unicode__(self):",
            "        return f\"<Text '{self.offendingText}' shows up in both lt and local-lt>\"",
            "",
            "",
            "def firstLinkTextFromElement(el):",
            "    try:",
            "        texts = linkTextsFromElement(el)",
            "    except DuplicatedLinkText as e:",
            "        texts = e.allTexts",
            "    return texts[0] if len(texts) > 0 else None",
            "",
            "",
            "def splitForValues(forValues):",
            "    \"\"\"",
            "    Splits a string of 1+ \"for\" values into an array of individual value.",
            "    Respects function args, etc.",
            "    Currently, for values are separated by commas.",
            "    \"\"\"",
            "    if forValues is None:",
            "        return None",
            "    forValues = re.sub(r\"\\s+\", \" \", forValues)",
            "    return [",
            "        value.strip()",
            "        for value in re.split(r\",(?![^()]*\\))\", forValues)",
            "        if value.strip()",
            "    ]",
            "",
            "",
            "def groupFromKey(key, length=2):",
            "    \"\"\"Generates a filename-safe \"group\" from a key, of a specified length.\"\"\"",
            "    if key in _groupFromKeyCache:",
            "        return _groupFromKeyCache[key]",
            "    safeChars = frozenset(\"abcdefghijklmnopqrstuvwxyz0123456789\")",
            "    group = \"\"",
            "    for char in key.lower():",
            "        if len(group) == length:",
            "            _groupFromKeyCache[key] = group",
            "            return group",
            "        if char in safeChars:",
            "            group += char",
            "    else:",
            "        group = group.ljust(length, \"_\")",
            "        _groupFromKeyCache[key] = group",
            "        return group",
            "",
            "",
            "_groupFromKeyCache = {}",
            "",
            "",
            "def flatten(arr):",
            "    for el in arr:",
            "        if (",
            "            isinstance(el, collections.Iterable)",
            "            and not isinstance(el, str)",
            "            and not lxml.etree.iselement(el)",
            "        ):",
            "            yield from flatten(el)",
            "        else:",
            "            yield el",
            "",
            "",
            "def scriptPath(*pathSegs):",
            "    startPath = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))",
            "    path = os.path.join(startPath, *pathSegs)",
            "    return path",
            "",
            "",
            "def chrootPath(chrootPath, path):",
            "    chrootPath = os.path.abspath(chrootPath)",
            "    path = os.path.abspath(path)",
            "    if not path.startswith(chrootPath):",
            "        messages.die(f\"Attempted to access a file ({path}) outside the source document's directory ({chrootPath}). See --allow-nonlocal-files.\")",
            "        raise Exception()",
            "    else:",
            "        return path",
            "",
            "",
            "",
            "def doEvery(s, action, lastTime=None):",
            "    # Takes an action every N seconds.",
            "    # Pass it the duration and the last time it took the action;",
            "    # it returns the time it last took the action",
            "    # (possibly just now).",
            "    # If you want to take action on first call,",
            "    # pass 0 as lastTime;",
            "    # otherwise it won't take action until N seconds.",
            "    import time",
            "",
            "    newTime = time.time()",
            "    if lastTime is None:",
            "        lastTime = newTime",
            "    if lastTime == 0 or newTime - lastTime > s:",
            "        action()",
            "        return newTime",
            "    return lastTime"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "171": [
                "scriptPath"
            ]
        },
        "addLocation": []
    },
    "bikeshed/config/retrieve.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " )"
            },
            "1": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True, allowLocal=True):"
            },
            "5": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "     # Looks in three or four locations, in order:"
            },
            "6": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     # the folder the spec source is in, the group's boilerplate folder, the megagroup's boilerplate folder, and the generic boilerplate folder."
            },
            "7": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "     # In each location, it first looks for the file specialized on status, and then for the generic file."
            },
            "8": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "             status = doc.md.rawStatus"
            },
            "9": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 78,
                "PatchRowcode": "     megaGroup, status = splitStatus(status)"
            },
            "10": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 79,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    searchLocally = doc.md.localBoilerplate[name]"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+    searchLocally = allowLocal and doc.md.localBoilerplate[name]"
            },
            "13": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 81,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "     def boilerplatePath(*segs):"
            },
            "15": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "         return scriptPath(\"boilerplate\", *segs)"
            },
            "16": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "                 # We should remove this after giving specs time to react to the warning:"
            },
            "17": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "                 sources.append(doc.inputSource.relative(f))"
            },
            "18": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "     if group:"
            },
            "19": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sources.append(InputSource(boilerplatePath(group, statusFile)))"
            },
            "20": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sources.append(InputSource(boilerplatePath(group, genericFile)))"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+        sources.append(InputSource(boilerplatePath(group, statusFile), chroot=False))"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+        sources.append(InputSource(boilerplatePath(group, genericFile), chroot=False))"
            },
            "23": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "     if megaGroup:"
            },
            "24": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sources.append(InputSource(boilerplatePath(megaGroup, statusFile)))"
            },
            "25": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sources.append(InputSource(boilerplatePath(megaGroup, genericFile)))"
            },
            "26": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    sources.append(InputSource(boilerplatePath(statusFile)))"
            },
            "27": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    sources.append(InputSource(boilerplatePath(genericFile)))"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+        sources.append(InputSource(boilerplatePath(megaGroup, statusFile), chroot=False))"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+        sources.append(InputSource(boilerplatePath(megaGroup, genericFile), chroot=False))"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+    sources.append(InputSource(boilerplatePath(statusFile), chroot=False))"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+    sources.append(InputSource(boilerplatePath(genericFile), chroot=False))"
            },
            "32": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 111,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 112,
                "PatchRowcode": "     # Watch all the possible sources, not just the one that got used, because if"
            },
            "34": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 113,
                "PatchRowcode": "     # an earlier one appears, we want to rebuild."
            }
        },
        "frontPatchFile": [
            "# pylint: disable=R1732",
            "",
            "import io",
            "import os",
            "",
            "from ..InputSource import InputSource",
            "from ..messages import *",
            "from .main import scriptPath",
            "from .status import splitStatus",
            "",
            "",
            "class DataFileRequester:",
            "    def __init__(self, type=None, fallback=None):",
            "        self.type = type",
            "        if self.type not in (\"readonly\", \"latest\"):",
            "            raise Exception(f\"Bad value for DataFileRequester.type, got '{type}'.\")",
            "        # fallback is another requester, used if the main one fails.",
            "        self.fallback = fallback",
            "",
            "    def fetch(self, *segs, **kwargs):",
            "        str = kwargs.get(\"str\", False)",
            "        okayToFail = kwargs.get(\"okayToFail\", False)",
            "        fileType = kwargs.get(\"type\", self.type)",
            "        location = self._buildPath(segs=segs, fileType=fileType)",
            "        try:",
            "            if str:",
            "                with open(location, encoding=\"utf-8\") as fh:",
            "                    return fh.read()",
            "            else:",
            "                return open(location, encoding=\"utf-8\")",
            "        except OSError:",
            "            if self.fallback:",
            "                try:",
            "                    return self.fallback.fetch(*segs, str=str, okayToFail=okayToFail)",
            "                except OSError:",
            "                    return self._fail(location, str, okayToFail)",
            "            return self._fail(location, str, okayToFail)",
            "",
            "    def walkFiles(self, *segs, **kwargs):",
            "        fileType = kwargs.get(\"type\", self.type)",
            "        for _, _, files in os.walk(self._buildPath(segs, fileType=fileType)):",
            "            yield from files",
            "",
            "    def _buildPath(self, segs, fileType=None):",
            "        if fileType is None:",
            "            fileType = self.type",
            "        if fileType == \"readonly\":",
            "            return scriptPath(\"spec-data\", \"readonly\", *segs)",
            "        else:",
            "            return scriptPath(\"spec-data\", *segs)",
            "",
            "    def _fail(self, location, str, okayToFail):",
            "        if okayToFail:",
            "            if str:",
            "                return \"\"",
            "            else:",
            "                return io.StringIO(\"\")",
            "        raise OSError(f\"Couldn't find file '{location}'\")",
            "",
            "",
            "defaultRequester = DataFileRequester(",
            "    type=\"latest\", fallback=DataFileRequester(type=\"readonly\")",
            ")",
            "",
            "",
            "def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True):",
            "    # Looks in three or four locations, in order:",
            "    # the folder the spec source is in, the group's boilerplate folder, the megagroup's boilerplate folder, and the generic boilerplate folder.",
            "    # In each location, it first looks for the file specialized on status, and then for the generic file.",
            "    # Filenames must be of the format NAME.include or NAME-STATUS.include",
            "    if group is None and doc.md.group is not None:",
            "        group = doc.md.group.lower()",
            "    if status is None:",
            "        if doc.md.status is not None:",
            "            status = doc.md.status",
            "        elif doc.md.rawStatus is not None:",
            "            status = doc.md.rawStatus",
            "    megaGroup, status = splitStatus(status)",
            "",
            "    searchLocally = doc.md.localBoilerplate[name]",
            "",
            "    def boilerplatePath(*segs):",
            "        return scriptPath(\"boilerplate\", *segs)",
            "",
            "    statusFile = f\"{name}-{status}.include\"",
            "    genericFile = f\"{name}.include\"",
            "    sources = []",
            "    if searchLocally:",
            "        sources.append(doc.inputSource.relative(statusFile))  # Can be None.",
            "        sources.append(doc.inputSource.relative(genericFile))",
            "    else:",
            "        for f in (statusFile, genericFile):",
            "            if doc.inputSource.cheaplyExists(f):",
            "                warn(",
            "                    (",
            "                        \"Found {0} next to the specification without a matching\\n\"",
            "                        + \"Local Boilerplate: {1} yes\\n\"",
            "                        + \"in the metadata. This include won't be found when building via a URL.\"",
            "                    ).format(f, name)",
            "                )",
            "                # We should remove this after giving specs time to react to the warning:",
            "                sources.append(doc.inputSource.relative(f))",
            "    if group:",
            "        sources.append(InputSource(boilerplatePath(group, statusFile)))",
            "        sources.append(InputSource(boilerplatePath(group, genericFile)))",
            "    if megaGroup:",
            "        sources.append(InputSource(boilerplatePath(megaGroup, statusFile)))",
            "        sources.append(InputSource(boilerplatePath(megaGroup, genericFile)))",
            "    sources.append(InputSource(boilerplatePath(statusFile)))",
            "    sources.append(InputSource(boilerplatePath(genericFile)))",
            "",
            "    # Watch all the possible sources, not just the one that got used, because if",
            "    # an earlier one appears, we want to rebuild.",
            "    doc.recordDependencies(*sources)",
            "",
            "    for source in sources:",
            "        if source is not None:",
            "            try:",
            "                return source.read().content",
            "            except OSError:",
            "                # That input doesn't exist.",
            "                pass",
            "    else:",
            "        if error:",
            "            die(",
            "                \"Couldn't find an appropriate include file for the {0} inclusion, given group='{1}' and status='{2}'.\",",
            "                name,",
            "                group,",
            "                status,",
            "            )",
            "        return \"\""
        ],
        "afterPatchFile": [
            "# pylint: disable=R1732",
            "",
            "import io",
            "import os",
            "",
            "from ..InputSource import InputSource",
            "from ..messages import *",
            "from .main import scriptPath",
            "from .status import splitStatus",
            "",
            "",
            "class DataFileRequester:",
            "    def __init__(self, type=None, fallback=None):",
            "        self.type = type",
            "        if self.type not in (\"readonly\", \"latest\"):",
            "            raise Exception(f\"Bad value for DataFileRequester.type, got '{type}'.\")",
            "        # fallback is another requester, used if the main one fails.",
            "        self.fallback = fallback",
            "",
            "    def fetch(self, *segs, **kwargs):",
            "        str = kwargs.get(\"str\", False)",
            "        okayToFail = kwargs.get(\"okayToFail\", False)",
            "        fileType = kwargs.get(\"type\", self.type)",
            "        location = self._buildPath(segs=segs, fileType=fileType)",
            "        try:",
            "            if str:",
            "                with open(location, encoding=\"utf-8\") as fh:",
            "                    return fh.read()",
            "            else:",
            "                return open(location, encoding=\"utf-8\")",
            "        except OSError:",
            "            if self.fallback:",
            "                try:",
            "                    return self.fallback.fetch(*segs, str=str, okayToFail=okayToFail)",
            "                except OSError:",
            "                    return self._fail(location, str, okayToFail)",
            "            return self._fail(location, str, okayToFail)",
            "",
            "    def walkFiles(self, *segs, **kwargs):",
            "        fileType = kwargs.get(\"type\", self.type)",
            "        for _, _, files in os.walk(self._buildPath(segs, fileType=fileType)):",
            "            yield from files",
            "",
            "    def _buildPath(self, segs, fileType=None):",
            "        if fileType is None:",
            "            fileType = self.type",
            "        if fileType == \"readonly\":",
            "            return scriptPath(\"spec-data\", \"readonly\", *segs)",
            "        else:",
            "            return scriptPath(\"spec-data\", *segs)",
            "",
            "    def _fail(self, location, str, okayToFail):",
            "        if okayToFail:",
            "            if str:",
            "                return \"\"",
            "            else:",
            "                return io.StringIO(\"\")",
            "        raise OSError(f\"Couldn't find file '{location}'\")",
            "",
            "",
            "defaultRequester = DataFileRequester(",
            "    type=\"latest\", fallback=DataFileRequester(type=\"readonly\")",
            ")",
            "",
            "",
            "def retrieveBoilerplateFile(doc, name, group=None, status=None, error=True, allowLocal=True):",
            "    # Looks in three or four locations, in order:",
            "    # the folder the spec source is in, the group's boilerplate folder, the megagroup's boilerplate folder, and the generic boilerplate folder.",
            "    # In each location, it first looks for the file specialized on status, and then for the generic file.",
            "    # Filenames must be of the format NAME.include or NAME-STATUS.include",
            "    if group is None and doc.md.group is not None:",
            "        group = doc.md.group.lower()",
            "    if status is None:",
            "        if doc.md.status is not None:",
            "            status = doc.md.status",
            "        elif doc.md.rawStatus is not None:",
            "            status = doc.md.rawStatus",
            "    megaGroup, status = splitStatus(status)",
            "",
            "    searchLocally = allowLocal and doc.md.localBoilerplate[name]",
            "",
            "    def boilerplatePath(*segs):",
            "        return scriptPath(\"boilerplate\", *segs)",
            "",
            "    statusFile = f\"{name}-{status}.include\"",
            "    genericFile = f\"{name}.include\"",
            "    sources = []",
            "    if searchLocally:",
            "        sources.append(doc.inputSource.relative(statusFile))  # Can be None.",
            "        sources.append(doc.inputSource.relative(genericFile))",
            "    else:",
            "        for f in (statusFile, genericFile):",
            "            if doc.inputSource.cheaplyExists(f):",
            "                warn(",
            "                    (",
            "                        \"Found {0} next to the specification without a matching\\n\"",
            "                        + \"Local Boilerplate: {1} yes\\n\"",
            "                        + \"in the metadata. This include won't be found when building via a URL.\"",
            "                    ).format(f, name)",
            "                )",
            "                # We should remove this after giving specs time to react to the warning:",
            "                sources.append(doc.inputSource.relative(f))",
            "    if group:",
            "        sources.append(InputSource(boilerplatePath(group, statusFile), chroot=False))",
            "        sources.append(InputSource(boilerplatePath(group, genericFile), chroot=False))",
            "    if megaGroup:",
            "        sources.append(InputSource(boilerplatePath(megaGroup, statusFile), chroot=False))",
            "        sources.append(InputSource(boilerplatePath(megaGroup, genericFile), chroot=False))",
            "    sources.append(InputSource(boilerplatePath(statusFile), chroot=False))",
            "    sources.append(InputSource(boilerplatePath(genericFile), chroot=False))",
            "",
            "    # Watch all the possible sources, not just the one that got used, because if",
            "    # an earlier one appears, we want to rebuild.",
            "    doc.recordDependencies(*sources)",
            "",
            "    for source in sources:",
            "        if source is not None:",
            "            try:",
            "                return source.read().content",
            "            except OSError:",
            "                # That input doesn't exist.",
            "                pass",
            "    else:",
            "        if error:",
            "            die(",
            "                \"Couldn't find an appropriate include file for the {0} inclusion, given group='{1}' and status='{2}'.\",",
            "                name,",
            "                group,",
            "                status,",
            "            )",
            "        return \"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "66": [
                "retrieveBoilerplateFile"
            ],
            "80": [
                "retrieveBoilerplateFile"
            ],
            "104": [
                "retrieveBoilerplateFile"
            ],
            "105": [
                "retrieveBoilerplateFile"
            ],
            "107": [
                "retrieveBoilerplateFile"
            ],
            "108": [
                "retrieveBoilerplateFile"
            ],
            "109": [
                "retrieveBoilerplateFile"
            ],
            "110": [
                "retrieveBoilerplateFile"
            ]
        },
        "addLocation": []
    },
    "bikeshed/constants.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " biblioDisplay = StringEnum(\"index\", \"inline\")"
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " specClass = None"
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " testAnnotationURL = \"https://test.csswg.org/harness/annotate.js\""
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+chroot = True"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 13,
                "PatchRowcode": "+executeCode = False"
            },
            "5": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " def errorLevelAt(target):"
            }
        },
        "frontPatchFile": [
            "from .stringEnum import StringEnum",
            "",
            "dryRun = False",
            "errorLevel = [\"fatal\"]",
            "printMode = \"console\"",
            "quiet = True",
            "asciiOnly = False",
            "refStatus = StringEnum(\"current\", \"snapshot\")",
            "biblioDisplay = StringEnum(\"index\", \"inline\")",
            "specClass = None",
            "testAnnotationURL = \"https://test.csswg.org/harness/annotate.js\"",
            "",
            "",
            "def errorLevelAt(target):",
            "    levels = {",
            "        \"nothing\": 0,",
            "        \"fatal\": 1,",
            "        \"link-error\": 2,",
            "        \"warning\": 3,",
            "        \"everything\": 1000,",
            "    }",
            "    currentLevel = levels[errorLevel[0]]",
            "    targetLevel = levels[target]",
            "    return currentLevel >= targetLevel",
            "",
            "",
            "def setErrorLevel(level=None):",
            "    if level is None:",
            "        level = \"fatal\"",
            "    errorLevel[0] = level"
        ],
        "afterPatchFile": [
            "from .stringEnum import StringEnum",
            "",
            "dryRun = False",
            "errorLevel = [\"fatal\"]",
            "printMode = \"console\"",
            "quiet = True",
            "asciiOnly = False",
            "refStatus = StringEnum(\"current\", \"snapshot\")",
            "biblioDisplay = StringEnum(\"index\", \"inline\")",
            "specClass = None",
            "testAnnotationURL = \"https://test.csswg.org/harness/annotate.js\"",
            "chroot = True",
            "executeCode = False",
            "",
            "",
            "def errorLevelAt(target):",
            "    levels = {",
            "        \"nothing\": 0,",
            "        \"fatal\": 1,",
            "        \"link-error\": 2,",
            "        \"warning\": 3,",
            "        \"everything\": 1000,",
            "    }",
            "    currentLevel = levels[errorLevel[0]]",
            "    targetLevel = levels[target]",
            "    return currentLevel >= targetLevel",
            "",
            "",
            "def setErrorLevel(level=None):",
            "    if level is None:",
            "        level = \"fatal\"",
            "    errorLevel[0] = level"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "bikeshed/extensions.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from . import config"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+from . import constants"
            },
            "2": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from .h import *  # noqa: F401"
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from .messages import *  # noqa: F401"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " def load(doc):"
            },
            "7": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    code = config.retrieveBoilerplateFile(doc, \"bs-extensions\")"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+    code = config.retrieveBoilerplateFile(doc, \"bs-extensions\", allowLocal=constants.executeCode)"
            },
            "9": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": "     exec(code, globals())"
            }
        },
        "frontPatchFile": [
            "from . import config",
            "from .h import *  # noqa: F401",
            "from .messages import *  # noqa: F401",
            "",
            "",
            "def load(doc):",
            "    code = config.retrieveBoilerplateFile(doc, \"bs-extensions\")",
            "    exec(code, globals())"
        ],
        "afterPatchFile": [
            "from . import config",
            "from . import constants",
            "from .h import *  # noqa: F401",
            "from .messages import *  # noqa: F401",
            "",
            "",
            "def load(doc):",
            "    code = config.retrieveBoilerplateFile(doc, \"bs-extensions\", allowLocal=constants.executeCode)",
            "    exec(code, globals())"
        ],
        "action": [
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0"
        ],
        "dele_reviseLocation": {
            "7": [
                "load"
            ]
        },
        "addLocation": []
    },
    "bikeshed/inlineTags/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from subprocess import PIPE, Popen"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3,
                "PatchRowcode": "+from .. import constants"
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from ..h import *"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from ..messages import *"
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " def processTags(doc):"
            },
            "8": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": "     for el in findAll(\"[data-span-tag]\", doc):"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+        if not constants.executeCode:"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 11,
                "PatchRowcode": "+            die(\"Found an inline code tag, but arbitrary code execution isn't allowed. See the --allow-execute flag.\")"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+            return"
            },
            "12": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 13,
                "PatchRowcode": "         tag = el.get(\"data-span-tag\")"
            },
            "13": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 14,
                "PatchRowcode": "         if tag not in doc.md.inlineTagCommands:"
            },
            "14": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "             die(\"Unknown inline tag '{0}' found:\\n  {1}\", tag, outerHTML(el), el=el)"
            }
        },
        "frontPatchFile": [
            "from subprocess import PIPE, Popen",
            "",
            "from ..h import *",
            "from ..messages import *",
            "",
            "",
            "def processTags(doc):",
            "    for el in findAll(\"[data-span-tag]\", doc):",
            "        tag = el.get(\"data-span-tag\")",
            "        if tag not in doc.md.inlineTagCommands:",
            "            die(\"Unknown inline tag '{0}' found:\\n  {1}\", tag, outerHTML(el), el=el)",
            "            continue",
            "        command = doc.md.inlineTagCommands[tag]",
            "        with Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True) as p:",
            "            out, err = p.communicate(innerHTML(el).encode(\"utf-8\"))",
            "            try:",
            "                out = out.decode(\"utf-8\")",
            "            except UnicodeDecodeError as e:",
            "                die(",
            "                    \"When trying to process {0}, got invalid unicode in stdout:\\n{1}\",",
            "                    outerHTML(el),",
            "                    e,",
            "                    el=el,",
            "                )",
            "            try:",
            "                err = err.decode(\"utf-8\")",
            "            except UnicodeDecodeError as e:",
            "                die(",
            "                    \"When trying to process {0}, got invalid unicode in stderr:\\n{1}\",",
            "                    outerHTML(el),",
            "                    e,",
            "                    el=el,",
            "                )",
            "            if p.returncode:",
            "                die(",
            "                    \"When trying to process {0}, got return code {1} and the following stderr:\\n{2}\",",
            "                    outerHTML(el),",
            "                    p.returncode,",
            "                    err,",
            "                    el=el,",
            "                )",
            "                continue",
            "            replaceContents(el, parseHTML(out))"
        ],
        "afterPatchFile": [
            "from subprocess import PIPE, Popen",
            "",
            "from .. import constants",
            "from ..h import *",
            "from ..messages import *",
            "",
            "",
            "def processTags(doc):",
            "    for el in findAll(\"[data-span-tag]\", doc):",
            "        if not constants.executeCode:",
            "            die(\"Found an inline code tag, but arbitrary code execution isn't allowed. See the --allow-execute flag.\")",
            "            return",
            "        tag = el.get(\"data-span-tag\")",
            "        if tag not in doc.md.inlineTagCommands:",
            "            die(\"Unknown inline tag '{0}' found:\\n  {1}\", tag, outerHTML(el), el=el)",
            "            continue",
            "        command = doc.md.inlineTagCommands[tag]",
            "        with Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True) as p:",
            "            out, err = p.communicate(innerHTML(el).encode(\"utf-8\"))",
            "            try:",
            "                out = out.decode(\"utf-8\")",
            "            except UnicodeDecodeError as e:",
            "                die(",
            "                    \"When trying to process {0}, got invalid unicode in stdout:\\n{1}\",",
            "                    outerHTML(el),",
            "                    e,",
            "                    el=el,",
            "                )",
            "            try:",
            "                err = err.decode(\"utf-8\")",
            "            except UnicodeDecodeError as e:",
            "                die(",
            "                    \"When trying to process {0}, got invalid unicode in stderr:\\n{1}\",",
            "                    outerHTML(el),",
            "                    e,",
            "                    el=el,",
            "                )",
            "            if p.returncode:",
            "                die(",
            "                    \"When trying to process {0}, got return code {1} and the following stderr:\\n{2}\",",
            "                    outerHTML(el),",
            "                    p.returncode,",
            "                    err,",
            "                    el=el,",
            "                )",
            "                continue",
            "            replaceContents(el, parseHTML(out))"
        ],
        "action": [
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "jinja2.nodes.Const.from_untrusted"
        ]
    }
}