{
    "keylime/cloud_verifier_tornado.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from keylime import config"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from keylime import json"
            },
            "3": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from keylime import registrar_client"
            },
            "4": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from keylime.agentstates import AgentAttestStates"
            },
            "5": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from keylime.common import states, validators, retry"
            },
            "6": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from keylime.db.verifier_db import VerfierMain"
            },
            "7": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": 443,
                "PatchRowcode": "                     agent_data['accept_tpm_encryption_algs'] = json_body['accept_tpm_encryption_algs']"
            },
            "8": {
                "beforePatchRowNumber": 445,
                "afterPatchRowNumber": 444,
                "PatchRowcode": "                     agent_data['accept_tpm_signing_algs'] = json_body['accept_tpm_signing_algs']"
            },
            "9": {
                "beforePatchRowNumber": 446,
                "afterPatchRowNumber": 445,
                "PatchRowcode": "                     agent_data['supported_version'] = json_body['supported_version']"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 446,
                "PatchRowcode": "+                    agent_data['ak_tpm'] = json_body['ak_tpm']"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 447,
                "PatchRowcode": "+                    agent_data['mtls_cert'] = json_body.get('mtls_cert', None)"
            },
            "12": {
                "beforePatchRowNumber": 447,
                "afterPatchRowNumber": 448,
                "PatchRowcode": "                     agent_data['hash_alg'] = \"\""
            },
            "13": {
                "beforePatchRowNumber": 448,
                "afterPatchRowNumber": 449,
                "PatchRowcode": "                     agent_data['enc_alg'] = \"\""
            },
            "14": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 450,
                "PatchRowcode": "                     agent_data['sign_alg'] = \"\""
            },
            "15": {
                "beforePatchRowNumber": 457,
                "afterPatchRowNumber": 458,
                "PatchRowcode": "                     agent_data['verifier_ip'] = config.get('cloud_verifier', 'cloudverifier_ip')"
            },
            "16": {
                "beforePatchRowNumber": 458,
                "afterPatchRowNumber": 459,
                "PatchRowcode": "                     agent_data['verifier_port'] = config.get('cloud_verifier', 'cloudverifier_port')"
            },
            "17": {
                "beforePatchRowNumber": 459,
                "afterPatchRowNumber": 460,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 460,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # We fetch the registrar data directly here because we require it for connecting to the agent"
            },
            "19": {
                "beforePatchRowNumber": 461,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # using mTLS"
            },
            "20": {
                "beforePatchRowNumber": 462,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    registrar_client.init_client_tls('cloud_verifier')"
            },
            "21": {
                "beforePatchRowNumber": 463,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    registrar_data = registrar_client.getData(config.get(\"cloud_verifier\", \"registrar_ip\"),"
            },
            "22": {
                "beforePatchRowNumber": 464,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                                              config.get(\"cloud_verifier\", \"registrar_port\"), agent_id)"
            },
            "23": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    if registrar_data is None:"
            },
            "24": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        web_util.echo_json_response(self, 400,"
            },
            "25": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                                    f\"Data for agent {agent_id} could not be found in registrar!\")"
            },
            "26": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        logger.warning(\"Data for agent %s could not be found in registrar!\", agent_id)"
            },
            "27": {
                "beforePatchRowNumber": 469,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        return"
            },
            "28": {
                "beforePatchRowNumber": 470,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "29": {
                "beforePatchRowNumber": 471,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    agent_data['mtls_cert'] = registrar_data.get('mtls_cert', None)"
            },
            "30": {
                "beforePatchRowNumber": 472,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    agent_data['ak_tpm'] = registrar_data['aik_tpm']"
            },
            "31": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "32": {
                "beforePatchRowNumber": 474,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "                     # TODO: Always error for v1.0 version after initial upgrade"
            },
            "33": {
                "beforePatchRowNumber": 475,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    if registrar_data.get('mtls_cert', None) is None and agent_data['supported_version'] != \"1.0\":"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 462,
                "PatchRowcode": "+                    if agent_data['mtls_cert'] is None and agent_data['supported_version'] != \"1.0\":"
            },
            "35": {
                "beforePatchRowNumber": 476,
                "afterPatchRowNumber": 463,
                "PatchRowcode": "                         web_util.echo_json_response(self, 400, \"mTLS certificate for agent is required!\")"
            },
            "36": {
                "beforePatchRowNumber": 477,
                "afterPatchRowNumber": 464,
                "PatchRowcode": "                         return"
            },
            "37": {
                "beforePatchRowNumber": 478,
                "afterPatchRowNumber": 465,
                "PatchRowcode": " "
            },
            "38": {
                "beforePatchRowNumber": 510,
                "afterPatchRowNumber": 497,
                "PatchRowcode": " "
            },
            "39": {
                "beforePatchRowNumber": 511,
                "afterPatchRowNumber": 498,
                "PatchRowcode": "                         # Prepare SSLContext for mTLS connections"
            },
            "40": {
                "beforePatchRowNumber": 512,
                "afterPatchRowNumber": 499,
                "PatchRowcode": "                         agent_mtls_cert_enabled = config.getboolean('cloud_verifier', 'agent_mtls_cert_enabled', fallback=False)"
            },
            "41": {
                "beforePatchRowNumber": 513,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        mtls_cert = registrar_data.get('mtls_cert', None)"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 500,
                "PatchRowcode": "+                        mtls_cert = agent_data['mtls_cert']"
            },
            "43": {
                "beforePatchRowNumber": 514,
                "afterPatchRowNumber": 501,
                "PatchRowcode": "                         agent_data['ssl_context'] = None"
            },
            "44": {
                "beforePatchRowNumber": 515,
                "afterPatchRowNumber": 502,
                "PatchRowcode": "                         if agent_mtls_cert_enabled and mtls_cert:"
            },
            "45": {
                "beforePatchRowNumber": 516,
                "afterPatchRowNumber": 503,
                "PatchRowcode": "                             agent_data['ssl_context'] = web_util.generate_agent_mtls_context(mtls_cert, self.mtls_options)"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python3",
            "'''",
            "SPDX-License-Identifier: Apache-2.0",
            "Copyright 2017 Massachusetts Institute of Technology.",
            "'''",
            "import signal",
            "import traceback",
            "import sys",
            "import functools",
            "import asyncio",
            "import os",
            "from multiprocessing import Process",
            "",
            "",
            "from sqlalchemy.exc import SQLAlchemyError",
            "from sqlalchemy.orm.exc import NoResultFound",
            "import tornado.ioloop",
            "import tornado.web",
            "",
            "from keylime import config",
            "from keylime import json",
            "from keylime import registrar_client",
            "from keylime.agentstates import AgentAttestStates",
            "from keylime.common import states, validators, retry",
            "from keylime.db.verifier_db import VerfierMain",
            "from keylime.db.verifier_db import VerifierAllowlist",
            "from keylime.db.keylime_db import DBEngineManager, SessionManager",
            "from keylime import keylime_logging",
            "from keylime import cloud_verifier_common",
            "from keylime import revocation_notifier",
            "from keylime import web_util",
            "from keylime import tornado_requests",
            "from keylime import api_version as keylime_api_version",
            "from keylime.failure import MAX_SEVERITY_LABEL, Failure, Component",
            "",
            "logger = keylime_logging.init_logging('cloudverifier')",
            "",
            "",
            "try:",
            "    engine = DBEngineManager().make_engine('cloud_verifier')",
            "except SQLAlchemyError as err:",
            "    logger.error('Error creating SQL engine or session: %s', err)",
            "    sys.exit(1)",
            "",
            "",
            "def get_session():",
            "    return SessionManager().make_session(engine)",
            "",
            "",
            "def get_AgentAttestStates():",
            "    return AgentAttestStates.get_instance()",
            "",
            "",
            "# The \"exclude_db\" dict values are removed from the response before adding the dict to the DB",
            "# This is because we want these values to remain ephemeral and not stored in the database.",
            "exclude_db = {",
            "    'registrar_data': '',",
            "    'nonce': '',",
            "    'b64_encrypted_V': '',",
            "    'provide_V': True,",
            "    'num_retries': 0,",
            "    'pending_event': None,",
            "    'first_verified': False,",
            "    # the following 3 items are updated to VerifierDB only when the AgentState is stored",
            "    'boottime': '',",
            "    'ima_pcrs': [],",
            "    'pcr10': '',",
            "    'next_ima_ml_entry': 0,",
            "    'learned_ima_keyrings': {},",
            "    'ssl_context': None,",
            "}",
            "",
            "",
            "def _from_db_obj(agent_db_obj):",
            "    fields = [ 'agent_id', \\",
            "                'v', \\",
            "                'ip', \\",
            "                'port', \\",
            "                'operational_state', \\",
            "                'public_key', \\",
            "                'tpm_policy', \\",
            "                'meta_data', \\",
            "                'mb_refstate', \\",
            "                'allowlist', \\",
            "                'ima_sign_verification_keys', \\",
            "                'revocation_key', \\",
            "                'accept_tpm_hash_algs', \\",
            "                'accept_tpm_encryption_algs', \\",
            "                'accept_tpm_signing_algs', \\",
            "                'hash_alg', \\",
            "                'enc_alg', \\",
            "                'sign_alg', \\",
            "                'boottime', \\",
            "                'ima_pcrs', \\",
            "                'pcr10', \\",
            "                'next_ima_ml_entry', \\",
            "                'learned_ima_keyrings',",
            "                'supported_version',",
            "                'mtls_cert',",
            "                'ak_tpm',",
            "               ]",
            "    agent_dict = {}",
            "    for field in fields:",
            "        agent_dict[field] = getattr(agent_db_obj, field, None)",
            "",
            "    # add default fields that are ephemeral",
            "    for key,val in exclude_db.items():",
            "        agent_dict[key] = val",
            "",
            "    return agent_dict",
            "",
            "",
            "def verifier_db_delete_agent(session, agent_id):",
            "    get_AgentAttestStates().delete_by_agent_id(agent_id)",
            "    session.query(VerfierMain).filter_by(",
            "                  agent_id=agent_id).delete()",
            "    session.commit()",
            "",
            "",
            "def store_attestation_state(agentAttestState):",
            "    # Only store if IMA log was evaluated",
            "    if agentAttestState.get_ima_pcrs():",
            "        session = get_session()",
            "        try:",
            "            update_agent = session.query(VerfierMain).get(agentAttestState.get_agent_id())",
            "            update_agent.boottime = agentAttestState.get_boottime()",
            "            update_agent.next_ima_ml_entry = agentAttestState.get_next_ima_ml_entry()",
            "            ima_pcrs_dict = agentAttestState.get_ima_pcrs()",
            "            update_agent.ima_pcrs = list(ima_pcrs_dict.keys())",
            "            for pcr_num, value in ima_pcrs_dict.items():",
            "                setattr(update_agent, f'pcr{pcr_num}', value)",
            "            update_agent.learned_ima_keyrings = agentAttestState.get_ima_keyrings().to_json()",
            "            try:",
            "                session.add(update_agent)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error on storing attestation state: %s', e)",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error on storing attestation state: %s', e)",
            "",
            "",
            "class BaseHandler(tornado.web.RequestHandler):",
            "    def prepare(self):  # pylint: disable=W0235",
            "        super().prepare()",
            "",
            "    def write_error(self, status_code, **kwargs):",
            "",
            "        self.set_header('Content-Type', 'text/json')",
            "        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:",
            "            # in debug mode, try to send a traceback",
            "            lines = []",
            "            for line in traceback.format_exception(*kwargs[\"exc_info\"]):",
            "                lines.append(line)",
            "            self.finish(json.dumps({",
            "                'code': status_code,",
            "                'status': self._reason,",
            "                'traceback': lines,",
            "                'results': {},",
            "            }))",
            "        else:",
            "            self.finish(json.dumps({",
            "                'code': status_code,",
            "                'status': self._reason,",
            "                'results': {},",
            "            }))",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class MainHandler(tornado.web.RequestHandler):",
            "",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def get(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def delete(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def post(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "class VersionHandler(BaseHandler):",
            "",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def get(self):",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(self, 405, \"Not Implemented\")",
            "            return",
            "",
            "        if \"version\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"URI not supported\")",
            "            logger.warning('GET returning 400 response. URI not supported: %s', self.request.path)",
            "            return",
            "",
            "        version_info = {",
            "            \"current_version\": keylime_api_version.current_version(),",
            "            \"supported_versions\": keylime_api_version.all_versions(),",
            "        }",
            "",
            "        web_util.echo_json_response(self, 200, \"Success\", version_info)",
            "",
            "    def delete(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def post(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class AgentsHandler(BaseHandler):",
            "    mtls_options = None  # Stores the cert, key and password used by the verifier for mTLS connections",
            "",
            "    def initialize(self, mtls_options):",
            "        self.mtls_options = mtls_options",
            "",
            "    def head(self):",
            "        \"\"\"HEAD not supported\"\"\"",
            "        web_util.echo_json_response(self, 405, \"HEAD not supported\")",
            "",
            "    def get(self):",
            "        \"\"\"This method handles the GET requests to retrieve status on agents from the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for GETing, i.e. /agents. All other GET uri's",
            "        will return errors. Agents requests require a single agent_id parameter which identifies the",
            "        agent to be returned. If the agent_id is not found, a 404 response is returned.  If the agent_id",
            "        was not found, it either completed successfully, or failed.  If found, the agent_id is still polling",
            "        to contact the Cloud Agent.",
            "        \"\"\"",
            "        session = get_session()",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(",
            "                self, 405, \"Not Implemented: Use /agents/ interface\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        if \"agents\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            logger.warning('GET returning 400 response. uri not supported: %s', self.request.path)",
            "            return",
            "",
            "        agent_id = rest_params[\"agents\"]",
            "",
            "        if (agent_id is not None) and (agent_id != ''):",
            "            # If the agent ID is not valid (wrong set of characters),",
            "            # just do nothing.",
            "            if not validators.valid_agent_id(agent_id):",
            "                web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                logger.error(\"GET received an invalid agent ID: %s\", agent_id)",
            "                return",
            "",
            "            try:",
            "                agent = session.query(VerfierMain).filter_by(",
            "                    agent_id=agent_id).one_or_none()",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "",
            "            if agent is not None:",
            "                response = cloud_verifier_common.process_get_status(agent)",
            "                web_util.echo_json_response(self, 200, \"Success\", response)",
            "            else:",
            "                web_util.echo_json_response(self, 404, \"agent id not found\")",
            "        else:",
            "            json_response = None",
            "            if \"bulk\" in rest_params:",
            "                agent_list = None",
            "",
            "                if (\"verifier\" in rest_params) and (rest_params[\"verifier\"] != ''):",
            "                    agent_list = session.query(VerfierMain).filter_by(verifier_id=rest_params[\"verifier\"]).all()",
            "                else:",
            "                    agent_list = session.query(VerfierMain).all()",
            "",
            "                json_response = {}",
            "                for agent in agent_list:",
            "                    json_response[agent.agent_id] = cloud_verifier_common.process_get_status(agent)",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\", json_response)",
            "            else:",
            "                if (\"verifier\" in rest_params) and (rest_params[\"verifier\"] != ''):",
            "                    json_response = session.query(VerfierMain.agent_id).filter_by(",
            "                        verifier_id=rest_params[\"verifier\"]).all()",
            "                else:",
            "                    json_response = session.query(VerfierMain.agent_id).all()",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\", {",
            "                    'uuids': json_response})",
            "",
            "            logger.info('GET returning 200 response for agent_id list')",
            "",
            "    def delete(self):",
            "        \"\"\"This method handles the DELETE requests to remove agents from the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for DELETEing, i.e. /agents. All other DELETE uri's will return errors.",
            "        agents requests require a single agent_id parameter which identifies the agent to be deleted.",
            "        \"\"\"",
            "        session = get_session()",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(",
            "                self, 405, \"Not Implemented: Use /agents/ interface\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        if \"agents\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            return",
            "",
            "        agent_id = rest_params[\"agents\"]",
            "",
            "        if agent_id is None:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            logger.warning('DELETE returning 400 response. uri not supported: %s', self.request.path)",
            "            return",
            "",
            "        # If the agent ID is not valid (wrong set of characters), just",
            "        # do nothing.",
            "        if not validators.valid_agent_id(agent_id):",
            "            web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "            logger.error(\"DELETE received an invalid agent ID: %s\", agent_id)",
            "            return",
            "",
            "        try:",
            "            agent = session.query(VerfierMain).filter_by(",
            "                agent_id=agent_id).first()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        if agent is None:",
            "            web_util.echo_json_response(self, 404, \"agent id not found\")",
            "            logger.info('DELETE returning 404 response. agent id: %s not found.', agent_id)",
            "            return",
            "",
            "        verifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "        if verifier_id != agent.verifier_id:",
            "            web_util.echo_json_response(self, 404, \"agent id associated to this verifier\")",
            "            logger.info('DELETE returning 404 response. agent id: %s not associated to this verifer.', agent_id)",
            "            return",
            "",
            "        op_state = agent.operational_state",
            "        if op_state in (states.SAVED, states.FAILED, states.TERMINATED,",
            "                        states.TENANT_FAILED, states.INVALID_QUOTE):",
            "            try:",
            "                verifier_db_delete_agent(session, agent_id)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 200, \"Success\")",
            "            logger.info('DELETE returning 200 response for agent id: %s', agent_id)",
            "        else:",
            "            try:",
            "                update_agent = session.query(VerfierMain).get(agent_id)",
            "                update_agent.operational_state = states.TERMINATED",
            "                try:",
            "                    session.add(update_agent)",
            "                except SQLAlchemyError as e:",
            "                    logger.error('SQLAlchemy Error: %s', e)",
            "                session.commit()",
            "                web_util.echo_json_response(self, 202, \"Accepted\")",
            "                logger.info('DELETE returning 202 response for agent id: %s', agent_id)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "",
            "    def post(self):",
            "        \"\"\"This method handles the POST requests to add agents to the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for POSTing, i.e. /agents. All other POST uri's will return errors.",
            "        agents requests require a json block sent in the body",
            "        \"\"\"",
            "        session = get_session()",
            "        try:",
            "            rest_params = web_util.get_restful_params(self.request.uri)",
            "            if rest_params is None:",
            "                web_util.echo_json_response(",
            "                    self, 405, \"Not Implemented: Use /agents/ interface\")",
            "                return",
            "",
            "            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "                return",
            "",
            "            if \"agents\" not in rest_params:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning('POST returning 400 response. uri not supported: %s', self.request.path)",
            "                return",
            "",
            "            agent_id = rest_params[\"agents\"]",
            "",
            "            if agent_id is not None:",
            "                # If the agent ID is not valid (wrong set of",
            "                # characters), just do nothing.",
            "                if not validators.valid_agent_id(agent_id):",
            "                    web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                    logger.error(\"POST received an invalid agent ID: %s\", agent_id)",
            "                    return",
            "",
            "                content_length = len(self.request.body)",
            "                if content_length == 0:",
            "                    web_util.echo_json_response(",
            "                        self, 400, \"Expected non zero content length\")",
            "                    logger.warning('POST returning 400 response. Expected non zero content length.')",
            "                else:",
            "                    json_body = json.loads(self.request.body)",
            "                    agent_data = {}",
            "                    agent_data['v'] = json_body['v']",
            "                    agent_data['ip'] = json_body['cloudagent_ip']",
            "                    agent_data['port'] = int(json_body['cloudagent_port'])",
            "                    agent_data['operational_state'] = states.START",
            "                    agent_data['public_key'] = \"\"",
            "                    agent_data['tpm_policy'] = json_body['tpm_policy']",
            "                    agent_data['meta_data'] = json_body['metadata']",
            "                    agent_data['allowlist'] = json_body['allowlist']",
            "                    agent_data['mb_refstate'] = json_body['mb_refstate']",
            "                    agent_data['ima_sign_verification_keys'] = json_body['ima_sign_verification_keys']",
            "                    agent_data['revocation_key'] = json_body['revocation_key']",
            "                    agent_data['accept_tpm_hash_algs'] = json_body['accept_tpm_hash_algs']",
            "                    agent_data['accept_tpm_encryption_algs'] = json_body['accept_tpm_encryption_algs']",
            "                    agent_data['accept_tpm_signing_algs'] = json_body['accept_tpm_signing_algs']",
            "                    agent_data['supported_version'] = json_body['supported_version']",
            "                    agent_data['hash_alg'] = \"\"",
            "                    agent_data['enc_alg'] = \"\"",
            "                    agent_data['sign_alg'] = \"\"",
            "                    agent_data['agent_id'] = agent_id",
            "                    agent_data['boottime'] = 0",
            "                    agent_data['ima_pcrs'] = []",
            "                    agent_data['pcr10'] = None",
            "                    agent_data['next_ima_ml_entry'] = 0",
            "                    agent_data['learned_ima_keyrings'] = {}",
            "                    agent_data['verifier_id'] = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "                    agent_data['verifier_ip'] = config.get('cloud_verifier', 'cloudverifier_ip')",
            "                    agent_data['verifier_port'] = config.get('cloud_verifier', 'cloudverifier_port')",
            "",
            "                    # We fetch the registrar data directly here because we require it for connecting to the agent",
            "                    # using mTLS",
            "                    registrar_client.init_client_tls('cloud_verifier')",
            "                    registrar_data = registrar_client.getData(config.get(\"cloud_verifier\", \"registrar_ip\"),",
            "                                                              config.get(\"cloud_verifier\", \"registrar_port\"), agent_id)",
            "                    if registrar_data is None:",
            "                        web_util.echo_json_response(self, 400,",
            "                                                    f\"Data for agent {agent_id} could not be found in registrar!\")",
            "                        logger.warning(\"Data for agent %s could not be found in registrar!\", agent_id)",
            "                        return",
            "",
            "                    agent_data['mtls_cert'] = registrar_data.get('mtls_cert', None)",
            "                    agent_data['ak_tpm'] = registrar_data['aik_tpm']",
            "",
            "                    # TODO: Always error for v1.0 version after initial upgrade",
            "                    if registrar_data.get('mtls_cert', None) is None and agent_data['supported_version'] != \"1.0\":",
            "                        web_util.echo_json_response(self, 400, \"mTLS certificate for agent is required!\")",
            "                        return",
            "",
            "                    is_valid, err_msg = cloud_verifier_common.validate_agent_data(agent_data)",
            "                    if not is_valid:",
            "                        web_util.echo_json_response(self, 400, err_msg)",
            "                        logger.warning(err_msg)",
            "                        return",
            "",
            "                    try:",
            "                        new_agent_count = session.query(",
            "                            VerfierMain).filter_by(agent_id=agent_id).count()",
            "                    except SQLAlchemyError as e:",
            "                        logger.error('SQLAlchemy Error: %s', e)",
            "                        raise e",
            "",
            "                    # don't allow overwriting",
            "",
            "                    if new_agent_count > 0:",
            "                        web_util.echo_json_response(",
            "                            self, 409, f\"Agent of uuid {agent_id} already exists\")",
            "                        logger.warning(\"Agent of uuid %s already exists\", agent_id)",
            "                    else:",
            "                        try:",
            "                            # Add the agent and data",
            "                            session.add(VerfierMain(**agent_data))",
            "                            session.commit()",
            "                        except SQLAlchemyError as e:",
            "                            logger.error('SQLAlchemy Error: %s', e)",
            "                            raise e",
            "",
            "                        # add default fields that are ephemeral",
            "                        for key,val in exclude_db.items():",
            "                            agent_data[key] = val",
            "",
            "                        # Prepare SSLContext for mTLS connections",
            "                        agent_mtls_cert_enabled = config.getboolean('cloud_verifier', 'agent_mtls_cert_enabled', fallback=False)",
            "                        mtls_cert = registrar_data.get('mtls_cert', None)",
            "                        agent_data['ssl_context'] = None",
            "                        if agent_mtls_cert_enabled and mtls_cert:",
            "                            agent_data['ssl_context'] = web_util.generate_agent_mtls_context(mtls_cert, self.mtls_options)",
            "",
            "                        if agent_data['ssl_context'] is None:",
            "                            logger.warning('Connecting to agent without mTLS: %s', agent_id)",
            "",
            "                        asyncio.ensure_future(",
            "                            process_agent(agent_data, states.GET_QUOTE))",
            "                        web_util.echo_json_response(self, 200, \"Success\")",
            "                        logger.info('POST returning 200 response for adding agent id: %s', agent_id)",
            "            else:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"POST returning 400 response. uri not supported\")",
            "        except Exception as e:",
            "            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")",
            "            logger.warning(\"POST returning 400 response. Exception error: %s\", e)",
            "            logger.exception(e)",
            "",
            "    def put(self):",
            "        \"\"\"This method handles the PUT requests to add agents to the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for PUTing, i.e. /agents. All other PUT uri's will return errors.",
            "        agents requests require a json block sent in the body",
            "        \"\"\"",
            "        session = get_session()",
            "        try:",
            "            rest_params = web_util.get_restful_params(self.request.uri)",
            "            if rest_params is None:",
            "                web_util.echo_json_response(",
            "                    self, 405, \"Not Implemented: Use /agents/ interface\")",
            "                return",
            "",
            "            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "                return",
            "",
            "            if \"agents\" not in rest_params:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning('PUT returning 400 response. uri not supported: %s', self.request.path)",
            "                return",
            "",
            "            agent_id = rest_params[\"agents\"]",
            "",
            "            if agent_id is None:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"PUT returning 400 response. uri not supported\")",
            "",
            "            # If the agent ID is not valid (wrong set of characters),",
            "            # just do nothing.",
            "            if not validators.valid_agent_id(agent_id):",
            "                web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                logger.error(\"PUT received an invalid agent ID: %s\", agent_id)",
            "                return",
            "",
            "            try:",
            "                verifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "                agent = session.query(VerfierMain).filter_by(",
            "                    agent_id=agent_id, verifier_id=verifier_id).one()",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "                raise e",
            "",
            "            if agent is None:",
            "                web_util.echo_json_response(self, 404, \"agent id not found\")",
            "                logger.info('PUT returning 404 response. agent id: %s not found.', agent_id)",
            "                return",
            "",
            "            if \"reactivate\" in rest_params:",
            "                if not isinstance(agent, dict):",
            "                    agent = _from_db_obj(agent)",
            "                if agent[\"mtls_cert\"]:",
            "                    agent['ssl_context'] = web_util.generate_agent_mtls_context(agent[\"mtls_cert\"], self.mtls_options)",
            "                agent[\"operational_state\"] = states.START",
            "                asyncio.ensure_future(",
            "                    process_agent(agent, states.GET_QUOTE))",
            "                web_util.echo_json_response(self, 200, \"Success\")",
            "                logger.info('PUT returning 200 response for agent id: %s', agent_id)",
            "            elif \"stop\" in rest_params:",
            "                # do stuff for terminate",
            "                logger.debug(\"Stopping polling on %s\", agent_id)",
            "                try:",
            "                    session.query(VerfierMain).filter(VerfierMain.agent_id == agent_id).update(",
            "                        {'operational_state': states.TENANT_FAILED})",
            "                    session.commit()",
            "                except SQLAlchemyError as e:",
            "                    logger.error('SQLAlchemy Error: %s', e)",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\")",
            "                logger.info('PUT returning 200 response for agent id: %s', agent_id)",
            "            else:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"PUT returning 400 response. uri not supported\")",
            "",
            "        except Exception as e:",
            "            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")",
            "            logger.warning(\"PUT returning 400 response. Exception error: %s\", e)",
            "            logger.exception(e)",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class AllowlistHandler(BaseHandler):",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 400, \"Allowlist handler: HEAD Not Implemented\")",
            "",
            "    def get(self):",
            "        \"\"\"Get an allowlist",
            "",
            "        GET /allowlists/{name}",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            logger.warning(",
            "                'GET returning 400 response: %s', self.request.path)",
            "            return",
            "",
            "        session = get_session()",
            "        try:",
            "            allowlist = session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).one()",
            "        except NoResultFound:",
            "            web_util.echo_json_response(self, 404, f\"Allowlist {allowlist_name} not found\")",
            "            return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        response = {}",
            "        for field in ('name', 'tpm_policy', 'ima_policy'):",
            "            response[field] = getattr(allowlist, field, None)",
            "        web_util.echo_json_response(self, 200, 'Success', response)",
            "",
            "    def delete(self):",
            "        \"\"\"Delete an allowlist",
            "",
            "        DELETE /allowlists/{name}",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            logger.warning(",
            "                'DELETE returning 400 response: %s', self.request.path)",
            "            return",
            "",
            "        session = get_session()",
            "        try:",
            "            session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).one()",
            "        except NoResultFound:",
            "            web_util.echo_json_response(self, 404, f\"Allowlist {allowlist_name} not found\")",
            "            return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        try:",
            "            session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).delete()",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        # NOTE(kaifeng) 204 Can not have response body, but current helper",
            "        # doesn't support this case.",
            "        self.set_status(204)",
            "        self.set_header('Content-Type', 'application/json')",
            "        self.finish()",
            "        logger.info(",
            "            'DELETE returning 204 response for allowlist: %s', allowlist_name)",
            "",
            "    def post(self):",
            "        \"\"\"Create an allowlist",
            "",
            "        POST /allowlists/{name}",
            "        body: {\"tpm_policy\": {..} ...",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        content_length = len(self.request.body)",
            "        if content_length == 0:",
            "            web_util.echo_json_response(",
            "                self, 400, \"Expected non zero content length\")",
            "            logger.warning(",
            "                'POST returning 400 response. Expected non zero content length.')",
            "            return",
            "",
            "        allowlist = {}",
            "        json_body = json.loads(self.request.body)",
            "        allowlist['name'] = allowlist_name",
            "        tpm_policy = json_body.get('tpm_policy')",
            "        if tpm_policy:",
            "            allowlist['tpm_policy'] = tpm_policy",
            "        ima_policy = json_body.get('ima_policy')",
            "        if ima_policy:",
            "            allowlist['ima_policy'] = ima_policy",
            "",
            "        session = get_session()",
            "        # don't allow overwritting",
            "        try:",
            "            al_count = session.query(",
            "                VerifierAllowlist).filter_by(name=allowlist_name).count()",
            "            if al_count > 0:",
            "                web_util.echo_json_response(",
            "                    self, 409, f\"Allowlist with name {allowlist_name} already exists\")",
            "                logger.warning(",
            "                    \"Allowlist with name %s already exists\", allowlist_name)",
            "                return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            raise",
            "",
            "        try:",
            "            # Add the agent and data",
            "            session.add(VerifierAllowlist(**allowlist))",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            raise",
            "",
            "        web_util.echo_json_response(self, 201)",
            "        logger.info('POST returning 201')",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 400, \"Allowlist handler: PUT Not Implemented\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "async def invoke_get_quote(agent, need_pubkey):",
            "    failure = Failure(Component.INTERNAL, [\"verifier\"])",
            "    if agent is None:",
            "        raise Exception(\"agent deleted while being processed\")",
            "    params = cloud_verifier_common.prepare_get_quote(agent)",
            "",
            "    partial_req = \"1\"",
            "    if need_pubkey:",
            "        partial_req = \"0\"",
            "",
            "    # TODO: remove special handling after initial upgrade",
            "    if agent['ssl_context']:",
            "        res = tornado_requests.request(\"GET\",",
            "                                       f\"https://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/quotes/integrity\"",
            "                                       f\"?nonce={params['nonce']}&mask={params['mask']}\"",
            "                                       f\"&partial={partial_req}&ima_ml_entry={params['ima_ml_entry']}\",",
            "                                       context=agent['ssl_context'])",
            "    else:",
            "        res = tornado_requests.request(\"GET\",",
            "                                       f\"http://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/quotes/integrity\"",
            "                                       f\"?nonce={params['nonce']}&mask={params['mask']}\"",
            "                                       f\"&partial={partial_req}&ima_ml_entry={params['ima_ml_entry']}\")",
            "    response = await res",
            "",
            "    if response.status_code != 200:",
            "        # this is a connection error, retry get quote",
            "        if response.status_code in [500, 599]:",
            "            asyncio.ensure_future(process_agent(",
            "                agent, states.GET_QUOTE_RETRY))",
            "        else:",
            "            # catastrophic error, do not continue",
            "            logger.critical(\"Unexpected Get Quote response error for cloud agent %s, Error: %s\", agent['agent_id'], response.status_code)",
            "            failure.add_event(\"no_quote\", \"Unexpected Get Quote reponse from agent\", False)",
            "            asyncio.ensure_future(process_agent(agent, states.FAILED, failure))",
            "    else:",
            "        try:",
            "            json_response = json.loads(response.body)",
            "",
            "            # validate the cloud agent response",
            "            if 'provide_V' not in agent :",
            "                agent['provide_V'] = True",
            "            agentAttestState = get_AgentAttestStates().get_by_agent_id(agent['agent_id'])",
            "            failure = cloud_verifier_common.process_quote_response(agent, json_response['results'], agentAttestState)",
            "            if not failure:",
            "                if agent['provide_V']:",
            "                    asyncio.ensure_future(process_agent(agent, states.PROVIDE_V))",
            "                else:",
            "                    asyncio.ensure_future(process_agent(agent, states.GET_QUOTE))",
            "            else:",
            "                asyncio.ensure_future(process_agent(agent, states.INVALID_QUOTE, failure))",
            "",
            "            # store the attestation state",
            "            store_attestation_state(agentAttestState)",
            "",
            "        except Exception as e:",
            "            logger.exception(e)",
            "",
            "",
            "async def invoke_provide_v(agent):",
            "    failure = Failure(Component.INTERNAL, [\"verifier\"])",
            "    if agent is None:",
            "        raise Exception(\"Agent deleted while being processed\")",
            "    try:",
            "        if agent['pending_event'] is not None:",
            "            agent['pending_event'] = None",
            "    except KeyError:",
            "        pass",
            "    v_json_message = cloud_verifier_common.prepare_v(agent)",
            "",
            "    # TODO: remove special handling after initial upgrade",
            "    if agent['ssl_context']:",
            "        res = tornado_requests.request(",
            "            \"POST\", f\"https://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/keys/vkey\",",
            "            data=v_json_message, context=agent['ssl_context'])",
            "    else:",
            "        res = tornado_requests.request(",
            "            \"POST\", f\"http://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/keys/vkey\",",
            "            data=v_json_message)",
            "",
            "    response = await res",
            "",
            "    if response.status_code != 200:",
            "        if response.status_code in [500, 599]:",
            "            asyncio.ensure_future(",
            "                process_agent(agent, states.PROVIDE_V_RETRY))",
            "        else:",
            "            # catastrophic error, do not continue",
            "            logger.critical(\"Unexpected Provide V response error for cloud agent %s, Error: %s\", agent['agent_id'], response.status_code)",
            "            failure.add_event(\"no_v\", {\"message\": \"Unexpected provide V response\", \"data\": response.status_code}, False)",
            "            asyncio.ensure_future(process_agent(agent, states.FAILED, failure))",
            "    else:",
            "        asyncio.ensure_future(process_agent(agent, states.GET_QUOTE))",
            "",
            "",
            "async def process_agent(agent, new_operational_state, failure=Failure(Component.INTERNAL, [\"verifier\"])):",
            "    # Convert to dict if the agent arg is a db object",
            "    if not isinstance(agent, dict):",
            "        agent = _from_db_obj(agent)",
            "",
            "    session = get_session()",
            "    try:  # pylint: disable=R1702",
            "        main_agent_operational_state = agent['operational_state']",
            "        try:",
            "            stored_agent = session.query(VerfierMain).filter_by(",
            "                agent_id=str(agent['agent_id'])).first()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        # if the user did terminated this agent",
            "        if stored_agent.operational_state == states.TERMINATED:",
            "            logger.warning(\"Agent %s terminated by user.\", agent['agent_id'])",
            "            if agent['pending_event'] is not None:",
            "                tornado.ioloop.IOLoop.current().remove_timeout(",
            "                    agent['pending_event'])",
            "            verifier_db_delete_agent(session, agent['agent_id'])",
            "            return",
            "",
            "        # if the user tells us to stop polling because the tenant quote check failed",
            "        if stored_agent.operational_state == states.TENANT_FAILED:",
            "            logger.warning(\"Agent %s has failed tenant quote. Stopping polling\",  agent['agent_id'])",
            "            if agent['pending_event'] is not None:",
            "                tornado.ioloop.IOLoop.current().remove_timeout(",
            "                    agent['pending_event'])",
            "            return",
            "",
            "        # If failed during processing, log regardless and drop it on the floor",
            "        # The administration application (tenant) can GET the status and act accordingly (delete/retry/etc).",
            "        if new_operational_state in (states.FAILED, states.INVALID_QUOTE):",
            "            assert failure, \"States FAILED and INVALID QUOTE should only be reached with a failure message\"",
            "",
            "            if agent.get('severity_level') is None or agent['severity_level'] < failure.highest_severity.severity:",
            "                agent['severity_level'] = failure.highest_severity.severity",
            "                agent['last_event_id'] = failure.highest_severity_event.event_id",
            "                agent['operational_state'] = new_operational_state",
            "",
            "                # issue notification for invalid quotes",
            "                if new_operational_state == states.INVALID_QUOTE:",
            "                    cloud_verifier_common.notify_error(agent, event=failure.highest_severity_event)",
            "",
            "                # When the failure is irrecoverable we stop polling the agent",
            "                if not failure.recoverable or failure.highest_severity == MAX_SEVERITY_LABEL:",
            "                    if agent['pending_event'] is not None:",
            "                        tornado.ioloop.IOLoop.current().remove_timeout(",
            "                            agent['pending_event'])",
            "                    for key in exclude_db:",
            "                        if key in agent:",
            "                            del agent[key]",
            "                    session.query(VerfierMain).filter_by(",
            "                        agent_id=agent['agent_id']).update(agent)",
            "                    session.commit()",
            "",
            "        # propagate all state, but remove none DB keys first (using exclude_db)",
            "        try:",
            "            agent_db = dict(agent)",
            "            for key in exclude_db:",
            "                if key in agent_db:",
            "                    del agent_db[key]",
            "",
            "            session.query(VerfierMain).filter_by(",
            "                agent_id=agent_db['agent_id']).update(agent_db)",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        # If agent was in a failed state we check if we either stop polling",
            "        # or just add it again to the event loop",
            "        if new_operational_state in [states.FAILED, states.INVALID_QUOTE]:",
            "            if not failure.recoverable or failure.highest_severity == MAX_SEVERITY_LABEL:",
            "                logger.warning(\"Agent %s failed, stopping polling\", agent['agent_id'])",
            "                return",
            "",
            "            await invoke_get_quote(agent, False)",
            "            return",
            "",
            "        # if new, get a quote",
            "        if (main_agent_operational_state == states.START and",
            "                new_operational_state == states.GET_QUOTE):",
            "            agent['num_retries'] = 0",
            "            agent['operational_state'] = states.GET_QUOTE",
            "            await invoke_get_quote(agent, True)",
            "            return",
            "",
            "        if (main_agent_operational_state == states.GET_QUOTE and",
            "                new_operational_state == states.PROVIDE_V):",
            "            agent['num_retries'] = 0",
            "            agent['operational_state'] = states.PROVIDE_V",
            "            await invoke_provide_v(agent)",
            "            return",
            "",
            "        if (main_agent_operational_state in (states.PROVIDE_V, states.GET_QUOTE) and",
            "                new_operational_state == states.GET_QUOTE):",
            "            agent['num_retries'] = 0",
            "            interval = config.getfloat('cloud_verifier', 'quote_interval')",
            "            agent['operational_state'] = states.GET_QUOTE",
            "            if interval == 0:",
            "                await invoke_get_quote(agent, False)",
            "            else:",
            "                logger.debug(\"Setting up callback to check again in %f seconds\", interval)",
            "                # set up a call back to check again",
            "                cb = functools.partial(invoke_get_quote, agent, False)",
            "                pending = tornado.ioloop.IOLoop.current().call_later(interval, cb)",
            "                agent['pending_event'] = pending",
            "            return",
            "",
            "        maxr = config.getint('cloud_verifier', 'max_retries')",
            "        interval = config.getfloat('cloud_verifier', 'retry_interval')",
            "        exponential_backoff = config.getboolean('cloud_verifier', 'exponential_backoff')",
            "",
            "        if (main_agent_operational_state == states.GET_QUOTE and",
            "                new_operational_state == states.GET_QUOTE_RETRY):",
            "            if agent['num_retries'] >= maxr:",
            "                logger.warning(\"Agent %s was not reachable for quote in %d tries, setting state to FAILED\", agent['agent_id'], maxr)",
            "                failure.add_event(\"not_reachable\", \"agent was not reachable from verifier\", False)",
            "                if agent['first_verified']:  # only notify on previously good agents",
            "                    cloud_verifier_common.notify_error(",
            "                        agent, msgtype='comm_error', event=failure.highest_severity_event)",
            "                else:",
            "                    logger.debug(\"Communication error for new agent. No notification will be sent\")",
            "                await process_agent(agent, states.FAILED, failure)",
            "            else:",
            "                agent['operational_state'] = states.GET_QUOTE",
            "                cb = functools.partial(invoke_get_quote, agent, True)",
            "                agent['num_retries'] += 1",
            "                next_retry = retry.retry_time(exponential_backoff, interval, agent['num_retries'], logger)",
            "                logger.info(\"Connection to %s refused after %d/%d tries, trying again in %f seconds\", agent['ip'], agent['num_retries'], maxr, next_retry)",
            "                tornado.ioloop.IOLoop.current().call_later(next_retry, cb)",
            "            return",
            "",
            "        if (main_agent_operational_state == states.PROVIDE_V and",
            "                new_operational_state == states.PROVIDE_V_RETRY):",
            "            if agent['num_retries'] >= maxr:",
            "                logger.warning(\"Agent %s was not reachable to provide v in %d tries, setting state to FAILED\", agent['agent_id'], maxr)",
            "                failure.add_event(\"not_reachable_v\", \"agent was not reachable to provide V\", False)",
            "                cloud_verifier_common.notify_error(",
            "                    agent, msgtype='comm_error', event=failure.highest_severity_event)",
            "                await process_agent(agent, states.FAILED, failure)",
            "            else:",
            "                agent['operational_state'] = states.PROVIDE_V",
            "                cb = functools.partial(invoke_provide_v, agent)",
            "                agent['num_retries'] += 1",
            "                next_retry = retry.retry_time(exponential_backoff, interval, agent['num_retries'], logger)",
            "                logger.info(\"Connection to %s refused after %d/%d tries, trying again in %f seconds\", agent['ip'], agent['num_retries'], maxr, next_retry)",
            "                tornado.ioloop.IOLoop.current().call_later(next_retry, cb)",
            "            return",
            "        raise Exception(\"nothing should ever fall out of this!\")",
            "",
            "    except Exception as e:",
            "        logger.error(\"Polling thread error: %s\", e)",
            "        logger.exception(e)",
            "",
            "",
            "async def activate_agents(verifier_id, verifier_ip, verifier_port, mtls_options):",
            "    session = get_session()",
            "    aas = get_AgentAttestStates()",
            "    try:",
            "        agents = session.query(VerfierMain).filter_by(",
            "            verifier_id=verifier_id).all()",
            "        for agent in agents:",
            "            agent.verifier_ip = verifier_ip",
            "            agent.verifier_host = verifier_port",
            "            agent_run = _from_db_obj(agent)",
            "            if agent_run[\"mtls_cert\"]:",
            "                agent_run[\"ssl_context\"] = web_util.generate_agent_mtls_context(agent_run[\"mtls_cert\"], mtls_options)",
            "            if agent.operational_state == states.START:",
            "                asyncio.ensure_future(process_agent(agent_run, states.GET_QUOTE))",
            "            if agent.boottime:",
            "                ima_pcrs_dict = {}",
            "                for pcr_num in agent.ima_pcrs:",
            "                    ima_pcrs_dict[pcr_num] = getattr(agent, f'pcr{pcr_num}')",
            "                aas.add(agent.agent_id, agent.boottime, ima_pcrs_dict, agent.next_ima_ml_entry, agent.learned_ima_keyrings)",
            "        session.commit()",
            "    except SQLAlchemyError as e:",
            "        logger.error('SQLAlchemy Error: %s', e)",
            "",
            "",
            "def main():",
            "    \"\"\"Main method of the Cloud Verifier Server.  This method is encapsulated in a function for packaging to allow it to be",
            "    called as a function by an external program.\"\"\"",
            "",
            "    cloudverifier_port = config.get('cloud_verifier', 'cloudverifier_port')",
            "    cloudverifier_host = config.get('cloud_verifier', 'cloudverifier_ip')",
            "    cloudverifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "",
            "    # allow tornado's max upload size to be configurable",
            "    max_upload_size = None",
            "    if config.has_option('cloud_verifier', 'max_upload_size'):",
            "        max_upload_size = int(config.get('cloud_verifier', 'max_upload_size'))",
            "",
            "    # set a conservative general umask",
            "    os.umask(0o077)",
            "",
            "    VerfierMain.metadata.create_all(engine, checkfirst=True)",
            "    session = get_session()",
            "    try:",
            "        query_all = session.query(VerfierMain).all()",
            "        for row in query_all:",
            "            if row.operational_state in states.APPROVED_REACTIVATE_STATES:",
            "                row.operational_state = states.START",
            "        session.commit()",
            "    except SQLAlchemyError as e:",
            "        logger.error('SQLAlchemy Error: %s', e)",
            "",
            "    num = session.query(VerfierMain.agent_id).count()",
            "    if num > 0:",
            "        agent_ids = session.query(VerfierMain.agent_id).all()",
            "        logger.info(\"Agent ids in db loaded from file: %s\", agent_ids)",
            "",
            "    logger.info('Starting Cloud Verifier (tornado) on port %s, use <Ctrl-C> to stop', cloudverifier_port)",
            "",
            "    # print out API versions we support",
            "    keylime_api_version.log_api_versions(logger)",
            "",
            "    context, mtls_options = web_util.init_mtls(logger=logger)",
            "",
            "    # Check for user defined CA to connect to agent",
            "    agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)",
            "    agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)",
            "    agent_mtls_private_key_pw = config.get(\"cloud_verifier\", \"agent_mtls_private_key_pw\", fallback=None)",
            "",
            "    # Only set custom options if the cert should not be the same as used by the verifier",
            "    if agent_mtls_cert != \"CV\":",
            "        mtls_options = (agent_mtls_cert, agent_mtls_private_key, agent_mtls_private_key_pw)",
            "",
            "    app = tornado.web.Application([",
            "        (r\"/v?[0-9]+(?:\\.[0-9]+)?/agents/.*\", AgentsHandler, {\"mtls_options\": mtls_options}),",
            "        (r\"/v?[0-9]+(?:\\.[0-9]+)?/allowlists/.*\", AllowlistHandler),",
            "        (r\"/versions?\", VersionHandler),",
            "        (r\".*\", MainHandler),",
            "    ])",
            "",
            "    sockets = tornado.netutil.bind_sockets(",
            "        int(cloudverifier_port), address=cloudverifier_host)",
            "",
            "    def server_process(task_id):",
            "        logger.info(\"Starting server of process %s\", task_id)",
            "        engine.dispose()",
            "        server = tornado.httpserver.HTTPServer(app, ssl_options=context, max_buffer_size=max_upload_size)",
            "        server.add_sockets(sockets)",
            "",
            "        def server_sig_handler(*_):",
            "            logger.info(\"Shutting down server %s..\", task_id)",
            "            # Stop server to not accept new incoming connections",
            "            server.stop()",
            "",
            "            # Wait for all connections to be closed and then stop ioloop",
            "            async def stop():",
            "                await server.close_all_connections()",
            "                tornado.ioloop.IOLoop.current().stop()",
            "            asyncio.ensure_future(stop())",
            "",
            "        # Attach signal handler to ioloop.",
            "        # Do not use signal.signal(..) for that because it does not work!",
            "        loop = asyncio.get_event_loop()",
            "        loop.add_signal_handler(signal.SIGINT, server_sig_handler)",
            "        loop.add_signal_handler(signal.SIGTERM, server_sig_handler)",
            "",
            "        server.start()",
            "        if task_id == 0:",
            "            # Reactivate agents",
            "            asyncio.ensure_future(activate_agents(cloudverifier_id, cloudverifier_host, cloudverifier_port, mtls_options))",
            "        tornado.ioloop.IOLoop.current().start()",
            "        logger.debug(\"Server %s stopped.\", task_id)",
            "        sys.exit(0)",
            "",
            "    processes = []",
            "",
            "    def sig_handler(*_):",
            "        if config.getboolean('cloud_verifier', 'revocation_notifier'):",
            "            revocation_notifier.stop_broker()",
            "        for p in processes:",
            "            p.join()",
            "        sys.exit(0)",
            "",
            "    signal.signal(signal.SIGINT, sig_handler)",
            "    signal.signal(signal.SIGTERM, sig_handler)",
            "    if config.getboolean('cloud_verifier', 'revocation_notifier'):",
            "        logger.info(\"Starting service for revocation notifications on port %s\",",
            "                    config.getint('cloud_verifier', 'revocation_notifier_port'))",
            "        revocation_notifier.start_broker()",
            "",
            "    num_workers = config.getint(",
            "        'cloud_verifier', 'multiprocessing_pool_num_workers')",
            "    if num_workers <= 0:",
            "        num_workers = tornado.process.cpu_count()",
            "    for task_id in range(0, num_workers):",
            "        process = Process(target=server_process, args=(task_id,))",
            "        process.start()",
            "        processes.append(process)"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python3",
            "'''",
            "SPDX-License-Identifier: Apache-2.0",
            "Copyright 2017 Massachusetts Institute of Technology.",
            "'''",
            "import signal",
            "import traceback",
            "import sys",
            "import functools",
            "import asyncio",
            "import os",
            "from multiprocessing import Process",
            "",
            "",
            "from sqlalchemy.exc import SQLAlchemyError",
            "from sqlalchemy.orm.exc import NoResultFound",
            "import tornado.ioloop",
            "import tornado.web",
            "",
            "from keylime import config",
            "from keylime import json",
            "from keylime.agentstates import AgentAttestStates",
            "from keylime.common import states, validators, retry",
            "from keylime.db.verifier_db import VerfierMain",
            "from keylime.db.verifier_db import VerifierAllowlist",
            "from keylime.db.keylime_db import DBEngineManager, SessionManager",
            "from keylime import keylime_logging",
            "from keylime import cloud_verifier_common",
            "from keylime import revocation_notifier",
            "from keylime import web_util",
            "from keylime import tornado_requests",
            "from keylime import api_version as keylime_api_version",
            "from keylime.failure import MAX_SEVERITY_LABEL, Failure, Component",
            "",
            "logger = keylime_logging.init_logging('cloudverifier')",
            "",
            "",
            "try:",
            "    engine = DBEngineManager().make_engine('cloud_verifier')",
            "except SQLAlchemyError as err:",
            "    logger.error('Error creating SQL engine or session: %s', err)",
            "    sys.exit(1)",
            "",
            "",
            "def get_session():",
            "    return SessionManager().make_session(engine)",
            "",
            "",
            "def get_AgentAttestStates():",
            "    return AgentAttestStates.get_instance()",
            "",
            "",
            "# The \"exclude_db\" dict values are removed from the response before adding the dict to the DB",
            "# This is because we want these values to remain ephemeral and not stored in the database.",
            "exclude_db = {",
            "    'registrar_data': '',",
            "    'nonce': '',",
            "    'b64_encrypted_V': '',",
            "    'provide_V': True,",
            "    'num_retries': 0,",
            "    'pending_event': None,",
            "    'first_verified': False,",
            "    # the following 3 items are updated to VerifierDB only when the AgentState is stored",
            "    'boottime': '',",
            "    'ima_pcrs': [],",
            "    'pcr10': '',",
            "    'next_ima_ml_entry': 0,",
            "    'learned_ima_keyrings': {},",
            "    'ssl_context': None,",
            "}",
            "",
            "",
            "def _from_db_obj(agent_db_obj):",
            "    fields = [ 'agent_id', \\",
            "                'v', \\",
            "                'ip', \\",
            "                'port', \\",
            "                'operational_state', \\",
            "                'public_key', \\",
            "                'tpm_policy', \\",
            "                'meta_data', \\",
            "                'mb_refstate', \\",
            "                'allowlist', \\",
            "                'ima_sign_verification_keys', \\",
            "                'revocation_key', \\",
            "                'accept_tpm_hash_algs', \\",
            "                'accept_tpm_encryption_algs', \\",
            "                'accept_tpm_signing_algs', \\",
            "                'hash_alg', \\",
            "                'enc_alg', \\",
            "                'sign_alg', \\",
            "                'boottime', \\",
            "                'ima_pcrs', \\",
            "                'pcr10', \\",
            "                'next_ima_ml_entry', \\",
            "                'learned_ima_keyrings',",
            "                'supported_version',",
            "                'mtls_cert',",
            "                'ak_tpm',",
            "               ]",
            "    agent_dict = {}",
            "    for field in fields:",
            "        agent_dict[field] = getattr(agent_db_obj, field, None)",
            "",
            "    # add default fields that are ephemeral",
            "    for key,val in exclude_db.items():",
            "        agent_dict[key] = val",
            "",
            "    return agent_dict",
            "",
            "",
            "def verifier_db_delete_agent(session, agent_id):",
            "    get_AgentAttestStates().delete_by_agent_id(agent_id)",
            "    session.query(VerfierMain).filter_by(",
            "                  agent_id=agent_id).delete()",
            "    session.commit()",
            "",
            "",
            "def store_attestation_state(agentAttestState):",
            "    # Only store if IMA log was evaluated",
            "    if agentAttestState.get_ima_pcrs():",
            "        session = get_session()",
            "        try:",
            "            update_agent = session.query(VerfierMain).get(agentAttestState.get_agent_id())",
            "            update_agent.boottime = agentAttestState.get_boottime()",
            "            update_agent.next_ima_ml_entry = agentAttestState.get_next_ima_ml_entry()",
            "            ima_pcrs_dict = agentAttestState.get_ima_pcrs()",
            "            update_agent.ima_pcrs = list(ima_pcrs_dict.keys())",
            "            for pcr_num, value in ima_pcrs_dict.items():",
            "                setattr(update_agent, f'pcr{pcr_num}', value)",
            "            update_agent.learned_ima_keyrings = agentAttestState.get_ima_keyrings().to_json()",
            "            try:",
            "                session.add(update_agent)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error on storing attestation state: %s', e)",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error on storing attestation state: %s', e)",
            "",
            "",
            "class BaseHandler(tornado.web.RequestHandler):",
            "    def prepare(self):  # pylint: disable=W0235",
            "        super().prepare()",
            "",
            "    def write_error(self, status_code, **kwargs):",
            "",
            "        self.set_header('Content-Type', 'text/json')",
            "        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:",
            "            # in debug mode, try to send a traceback",
            "            lines = []",
            "            for line in traceback.format_exception(*kwargs[\"exc_info\"]):",
            "                lines.append(line)",
            "            self.finish(json.dumps({",
            "                'code': status_code,",
            "                'status': self._reason,",
            "                'traceback': lines,",
            "                'results': {},",
            "            }))",
            "        else:",
            "            self.finish(json.dumps({",
            "                'code': status_code,",
            "                'status': self._reason,",
            "                'results': {},",
            "            }))",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class MainHandler(tornado.web.RequestHandler):",
            "",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def get(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def delete(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def post(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use /agents/ interface instead\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "class VersionHandler(BaseHandler):",
            "",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def get(self):",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(self, 405, \"Not Implemented\")",
            "            return",
            "",
            "        if \"version\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"URI not supported\")",
            "            logger.warning('GET returning 400 response. URI not supported: %s', self.request.path)",
            "            return",
            "",
            "        version_info = {",
            "            \"current_version\": keylime_api_version.current_version(),",
            "            \"supported_versions\": keylime_api_version.all_versions(),",
            "        }",
            "",
            "        web_util.echo_json_response(self, 200, \"Success\", version_info)",
            "",
            "    def delete(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def post(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 405, \"Not Implemented: Use GET interface instead\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class AgentsHandler(BaseHandler):",
            "    mtls_options = None  # Stores the cert, key and password used by the verifier for mTLS connections",
            "",
            "    def initialize(self, mtls_options):",
            "        self.mtls_options = mtls_options",
            "",
            "    def head(self):",
            "        \"\"\"HEAD not supported\"\"\"",
            "        web_util.echo_json_response(self, 405, \"HEAD not supported\")",
            "",
            "    def get(self):",
            "        \"\"\"This method handles the GET requests to retrieve status on agents from the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for GETing, i.e. /agents. All other GET uri's",
            "        will return errors. Agents requests require a single agent_id parameter which identifies the",
            "        agent to be returned. If the agent_id is not found, a 404 response is returned.  If the agent_id",
            "        was not found, it either completed successfully, or failed.  If found, the agent_id is still polling",
            "        to contact the Cloud Agent.",
            "        \"\"\"",
            "        session = get_session()",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(",
            "                self, 405, \"Not Implemented: Use /agents/ interface\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        if \"agents\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            logger.warning('GET returning 400 response. uri not supported: %s', self.request.path)",
            "            return",
            "",
            "        agent_id = rest_params[\"agents\"]",
            "",
            "        if (agent_id is not None) and (agent_id != ''):",
            "            # If the agent ID is not valid (wrong set of characters),",
            "            # just do nothing.",
            "            if not validators.valid_agent_id(agent_id):",
            "                web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                logger.error(\"GET received an invalid agent ID: %s\", agent_id)",
            "                return",
            "",
            "            try:",
            "                agent = session.query(VerfierMain).filter_by(",
            "                    agent_id=agent_id).one_or_none()",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "",
            "            if agent is not None:",
            "                response = cloud_verifier_common.process_get_status(agent)",
            "                web_util.echo_json_response(self, 200, \"Success\", response)",
            "            else:",
            "                web_util.echo_json_response(self, 404, \"agent id not found\")",
            "        else:",
            "            json_response = None",
            "            if \"bulk\" in rest_params:",
            "                agent_list = None",
            "",
            "                if (\"verifier\" in rest_params) and (rest_params[\"verifier\"] != ''):",
            "                    agent_list = session.query(VerfierMain).filter_by(verifier_id=rest_params[\"verifier\"]).all()",
            "                else:",
            "                    agent_list = session.query(VerfierMain).all()",
            "",
            "                json_response = {}",
            "                for agent in agent_list:",
            "                    json_response[agent.agent_id] = cloud_verifier_common.process_get_status(agent)",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\", json_response)",
            "            else:",
            "                if (\"verifier\" in rest_params) and (rest_params[\"verifier\"] != ''):",
            "                    json_response = session.query(VerfierMain.agent_id).filter_by(",
            "                        verifier_id=rest_params[\"verifier\"]).all()",
            "                else:",
            "                    json_response = session.query(VerfierMain.agent_id).all()",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\", {",
            "                    'uuids': json_response})",
            "",
            "            logger.info('GET returning 200 response for agent_id list')",
            "",
            "    def delete(self):",
            "        \"\"\"This method handles the DELETE requests to remove agents from the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for DELETEing, i.e. /agents. All other DELETE uri's will return errors.",
            "        agents requests require a single agent_id parameter which identifies the agent to be deleted.",
            "        \"\"\"",
            "        session = get_session()",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None:",
            "            web_util.echo_json_response(",
            "                self, 405, \"Not Implemented: Use /agents/ interface\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        if \"agents\" not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            return",
            "",
            "        agent_id = rest_params[\"agents\"]",
            "",
            "        if agent_id is None:",
            "            web_util.echo_json_response(self, 400, \"uri not supported\")",
            "            logger.warning('DELETE returning 400 response. uri not supported: %s', self.request.path)",
            "            return",
            "",
            "        # If the agent ID is not valid (wrong set of characters), just",
            "        # do nothing.",
            "        if not validators.valid_agent_id(agent_id):",
            "            web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "            logger.error(\"DELETE received an invalid agent ID: %s\", agent_id)",
            "            return",
            "",
            "        try:",
            "            agent = session.query(VerfierMain).filter_by(",
            "                agent_id=agent_id).first()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        if agent is None:",
            "            web_util.echo_json_response(self, 404, \"agent id not found\")",
            "            logger.info('DELETE returning 404 response. agent id: %s not found.', agent_id)",
            "            return",
            "",
            "        verifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "        if verifier_id != agent.verifier_id:",
            "            web_util.echo_json_response(self, 404, \"agent id associated to this verifier\")",
            "            logger.info('DELETE returning 404 response. agent id: %s not associated to this verifer.', agent_id)",
            "            return",
            "",
            "        op_state = agent.operational_state",
            "        if op_state in (states.SAVED, states.FAILED, states.TERMINATED,",
            "                        states.TENANT_FAILED, states.INVALID_QUOTE):",
            "            try:",
            "                verifier_db_delete_agent(session, agent_id)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 200, \"Success\")",
            "            logger.info('DELETE returning 200 response for agent id: %s', agent_id)",
            "        else:",
            "            try:",
            "                update_agent = session.query(VerfierMain).get(agent_id)",
            "                update_agent.operational_state = states.TERMINATED",
            "                try:",
            "                    session.add(update_agent)",
            "                except SQLAlchemyError as e:",
            "                    logger.error('SQLAlchemy Error: %s', e)",
            "                session.commit()",
            "                web_util.echo_json_response(self, 202, \"Accepted\")",
            "                logger.info('DELETE returning 202 response for agent id: %s', agent_id)",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "",
            "    def post(self):",
            "        \"\"\"This method handles the POST requests to add agents to the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for POSTing, i.e. /agents. All other POST uri's will return errors.",
            "        agents requests require a json block sent in the body",
            "        \"\"\"",
            "        session = get_session()",
            "        try:",
            "            rest_params = web_util.get_restful_params(self.request.uri)",
            "            if rest_params is None:",
            "                web_util.echo_json_response(",
            "                    self, 405, \"Not Implemented: Use /agents/ interface\")",
            "                return",
            "",
            "            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "                return",
            "",
            "            if \"agents\" not in rest_params:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning('POST returning 400 response. uri not supported: %s', self.request.path)",
            "                return",
            "",
            "            agent_id = rest_params[\"agents\"]",
            "",
            "            if agent_id is not None:",
            "                # If the agent ID is not valid (wrong set of",
            "                # characters), just do nothing.",
            "                if not validators.valid_agent_id(agent_id):",
            "                    web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                    logger.error(\"POST received an invalid agent ID: %s\", agent_id)",
            "                    return",
            "",
            "                content_length = len(self.request.body)",
            "                if content_length == 0:",
            "                    web_util.echo_json_response(",
            "                        self, 400, \"Expected non zero content length\")",
            "                    logger.warning('POST returning 400 response. Expected non zero content length.')",
            "                else:",
            "                    json_body = json.loads(self.request.body)",
            "                    agent_data = {}",
            "                    agent_data['v'] = json_body['v']",
            "                    agent_data['ip'] = json_body['cloudagent_ip']",
            "                    agent_data['port'] = int(json_body['cloudagent_port'])",
            "                    agent_data['operational_state'] = states.START",
            "                    agent_data['public_key'] = \"\"",
            "                    agent_data['tpm_policy'] = json_body['tpm_policy']",
            "                    agent_data['meta_data'] = json_body['metadata']",
            "                    agent_data['allowlist'] = json_body['allowlist']",
            "                    agent_data['mb_refstate'] = json_body['mb_refstate']",
            "                    agent_data['ima_sign_verification_keys'] = json_body['ima_sign_verification_keys']",
            "                    agent_data['revocation_key'] = json_body['revocation_key']",
            "                    agent_data['accept_tpm_hash_algs'] = json_body['accept_tpm_hash_algs']",
            "                    agent_data['accept_tpm_encryption_algs'] = json_body['accept_tpm_encryption_algs']",
            "                    agent_data['accept_tpm_signing_algs'] = json_body['accept_tpm_signing_algs']",
            "                    agent_data['supported_version'] = json_body['supported_version']",
            "                    agent_data['ak_tpm'] = json_body['ak_tpm']",
            "                    agent_data['mtls_cert'] = json_body.get('mtls_cert', None)",
            "                    agent_data['hash_alg'] = \"\"",
            "                    agent_data['enc_alg'] = \"\"",
            "                    agent_data['sign_alg'] = \"\"",
            "                    agent_data['agent_id'] = agent_id",
            "                    agent_data['boottime'] = 0",
            "                    agent_data['ima_pcrs'] = []",
            "                    agent_data['pcr10'] = None",
            "                    agent_data['next_ima_ml_entry'] = 0",
            "                    agent_data['learned_ima_keyrings'] = {}",
            "                    agent_data['verifier_id'] = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "                    agent_data['verifier_ip'] = config.get('cloud_verifier', 'cloudverifier_ip')",
            "                    agent_data['verifier_port'] = config.get('cloud_verifier', 'cloudverifier_port')",
            "",
            "                    # TODO: Always error for v1.0 version after initial upgrade",
            "                    if agent_data['mtls_cert'] is None and agent_data['supported_version'] != \"1.0\":",
            "                        web_util.echo_json_response(self, 400, \"mTLS certificate for agent is required!\")",
            "                        return",
            "",
            "                    is_valid, err_msg = cloud_verifier_common.validate_agent_data(agent_data)",
            "                    if not is_valid:",
            "                        web_util.echo_json_response(self, 400, err_msg)",
            "                        logger.warning(err_msg)",
            "                        return",
            "",
            "                    try:",
            "                        new_agent_count = session.query(",
            "                            VerfierMain).filter_by(agent_id=agent_id).count()",
            "                    except SQLAlchemyError as e:",
            "                        logger.error('SQLAlchemy Error: %s', e)",
            "                        raise e",
            "",
            "                    # don't allow overwriting",
            "",
            "                    if new_agent_count > 0:",
            "                        web_util.echo_json_response(",
            "                            self, 409, f\"Agent of uuid {agent_id} already exists\")",
            "                        logger.warning(\"Agent of uuid %s already exists\", agent_id)",
            "                    else:",
            "                        try:",
            "                            # Add the agent and data",
            "                            session.add(VerfierMain(**agent_data))",
            "                            session.commit()",
            "                        except SQLAlchemyError as e:",
            "                            logger.error('SQLAlchemy Error: %s', e)",
            "                            raise e",
            "",
            "                        # add default fields that are ephemeral",
            "                        for key,val in exclude_db.items():",
            "                            agent_data[key] = val",
            "",
            "                        # Prepare SSLContext for mTLS connections",
            "                        agent_mtls_cert_enabled = config.getboolean('cloud_verifier', 'agent_mtls_cert_enabled', fallback=False)",
            "                        mtls_cert = agent_data['mtls_cert']",
            "                        agent_data['ssl_context'] = None",
            "                        if agent_mtls_cert_enabled and mtls_cert:",
            "                            agent_data['ssl_context'] = web_util.generate_agent_mtls_context(mtls_cert, self.mtls_options)",
            "",
            "                        if agent_data['ssl_context'] is None:",
            "                            logger.warning('Connecting to agent without mTLS: %s', agent_id)",
            "",
            "                        asyncio.ensure_future(",
            "                            process_agent(agent_data, states.GET_QUOTE))",
            "                        web_util.echo_json_response(self, 200, \"Success\")",
            "                        logger.info('POST returning 200 response for adding agent id: %s', agent_id)",
            "            else:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"POST returning 400 response. uri not supported\")",
            "        except Exception as e:",
            "            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")",
            "            logger.warning(\"POST returning 400 response. Exception error: %s\", e)",
            "            logger.exception(e)",
            "",
            "    def put(self):",
            "        \"\"\"This method handles the PUT requests to add agents to the Cloud Verifier.",
            "",
            "        Currently, only agents resources are available for PUTing, i.e. /agents. All other PUT uri's will return errors.",
            "        agents requests require a json block sent in the body",
            "        \"\"\"",
            "        session = get_session()",
            "        try:",
            "            rest_params = web_util.get_restful_params(self.request.uri)",
            "            if rest_params is None:",
            "                web_util.echo_json_response(",
            "                    self, 405, \"Not Implemented: Use /agents/ interface\")",
            "                return",
            "",
            "            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "                return",
            "",
            "            if \"agents\" not in rest_params:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning('PUT returning 400 response. uri not supported: %s', self.request.path)",
            "                return",
            "",
            "            agent_id = rest_params[\"agents\"]",
            "",
            "            if agent_id is None:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"PUT returning 400 response. uri not supported\")",
            "",
            "            # If the agent ID is not valid (wrong set of characters),",
            "            # just do nothing.",
            "            if not validators.valid_agent_id(agent_id):",
            "                web_util.echo_json_response(self, 400, \"agent_id not not valid\")",
            "                logger.error(\"PUT received an invalid agent ID: %s\", agent_id)",
            "                return",
            "",
            "            try:",
            "                verifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "                agent = session.query(VerfierMain).filter_by(",
            "                    agent_id=agent_id, verifier_id=verifier_id).one()",
            "            except SQLAlchemyError as e:",
            "                logger.error('SQLAlchemy Error: %s', e)",
            "                raise e",
            "",
            "            if agent is None:",
            "                web_util.echo_json_response(self, 404, \"agent id not found\")",
            "                logger.info('PUT returning 404 response. agent id: %s not found.', agent_id)",
            "                return",
            "",
            "            if \"reactivate\" in rest_params:",
            "                if not isinstance(agent, dict):",
            "                    agent = _from_db_obj(agent)",
            "                if agent[\"mtls_cert\"]:",
            "                    agent['ssl_context'] = web_util.generate_agent_mtls_context(agent[\"mtls_cert\"], self.mtls_options)",
            "                agent[\"operational_state\"] = states.START",
            "                asyncio.ensure_future(",
            "                    process_agent(agent, states.GET_QUOTE))",
            "                web_util.echo_json_response(self, 200, \"Success\")",
            "                logger.info('PUT returning 200 response for agent id: %s', agent_id)",
            "            elif \"stop\" in rest_params:",
            "                # do stuff for terminate",
            "                logger.debug(\"Stopping polling on %s\", agent_id)",
            "                try:",
            "                    session.query(VerfierMain).filter(VerfierMain.agent_id == agent_id).update(",
            "                        {'operational_state': states.TENANT_FAILED})",
            "                    session.commit()",
            "                except SQLAlchemyError as e:",
            "                    logger.error('SQLAlchemy Error: %s', e)",
            "",
            "                web_util.echo_json_response(self, 200, \"Success\")",
            "                logger.info('PUT returning 200 response for agent id: %s', agent_id)",
            "            else:",
            "                web_util.echo_json_response(self, 400, \"uri not supported\")",
            "                logger.warning(\"PUT returning 400 response. uri not supported\")",
            "",
            "        except Exception as e:",
            "            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")",
            "            logger.warning(\"PUT returning 400 response. Exception error: %s\", e)",
            "            logger.exception(e)",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "class AllowlistHandler(BaseHandler):",
            "    def head(self):",
            "        web_util.echo_json_response(",
            "            self, 400, \"Allowlist handler: HEAD Not Implemented\")",
            "",
            "    def get(self):",
            "        \"\"\"Get an allowlist",
            "",
            "        GET /allowlists/{name}",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            logger.warning(",
            "                'GET returning 400 response: %s', self.request.path)",
            "            return",
            "",
            "        session = get_session()",
            "        try:",
            "            allowlist = session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).one()",
            "        except NoResultFound:",
            "            web_util.echo_json_response(self, 404, f\"Allowlist {allowlist_name} not found\")",
            "            return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        response = {}",
            "        for field in ('name', 'tpm_policy', 'ima_policy'):",
            "            response[field] = getattr(allowlist, field, None)",
            "        web_util.echo_json_response(self, 200, 'Success', response)",
            "",
            "    def delete(self):",
            "        \"\"\"Delete an allowlist",
            "",
            "        DELETE /allowlists/{name}",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            logger.warning(",
            "                'DELETE returning 400 response: %s', self.request.path)",
            "            return",
            "",
            "        session = get_session()",
            "        try:",
            "            session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).one()",
            "        except NoResultFound:",
            "            web_util.echo_json_response(self, 404, f\"Allowlist {allowlist_name} not found\")",
            "            return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        try:",
            "            session.query(VerifierAllowlist).filter_by(",
            "                name=allowlist_name).delete()",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            web_util.echo_json_response(self, 500, \"Failed to get allowlist\")",
            "            raise",
            "",
            "        # NOTE(kaifeng) 204 Can not have response body, but current helper",
            "        # doesn't support this case.",
            "        self.set_status(204)",
            "        self.set_header('Content-Type', 'application/json')",
            "        self.finish()",
            "        logger.info(",
            "            'DELETE returning 204 response for allowlist: %s', allowlist_name)",
            "",
            "    def post(self):",
            "        \"\"\"Create an allowlist",
            "",
            "        POST /allowlists/{name}",
            "        body: {\"tpm_policy\": {..} ...",
            "        \"\"\"",
            "",
            "        rest_params = web_util.get_restful_params(self.request.uri)",
            "        if rest_params is None or 'allowlists' not in rest_params:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):",
            "            return",
            "",
            "        allowlist_name = rest_params['allowlists']",
            "        if allowlist_name is None:",
            "            web_util.echo_json_response(self, 400, \"Invalid URL\")",
            "            return",
            "",
            "        content_length = len(self.request.body)",
            "        if content_length == 0:",
            "            web_util.echo_json_response(",
            "                self, 400, \"Expected non zero content length\")",
            "            logger.warning(",
            "                'POST returning 400 response. Expected non zero content length.')",
            "            return",
            "",
            "        allowlist = {}",
            "        json_body = json.loads(self.request.body)",
            "        allowlist['name'] = allowlist_name",
            "        tpm_policy = json_body.get('tpm_policy')",
            "        if tpm_policy:",
            "            allowlist['tpm_policy'] = tpm_policy",
            "        ima_policy = json_body.get('ima_policy')",
            "        if ima_policy:",
            "            allowlist['ima_policy'] = ima_policy",
            "",
            "        session = get_session()",
            "        # don't allow overwritting",
            "        try:",
            "            al_count = session.query(",
            "                VerifierAllowlist).filter_by(name=allowlist_name).count()",
            "            if al_count > 0:",
            "                web_util.echo_json_response(",
            "                    self, 409, f\"Allowlist with name {allowlist_name} already exists\")",
            "                logger.warning(",
            "                    \"Allowlist with name %s already exists\", allowlist_name)",
            "                return",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            raise",
            "",
            "        try:",
            "            # Add the agent and data",
            "            session.add(VerifierAllowlist(**allowlist))",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "            raise",
            "",
            "        web_util.echo_json_response(self, 201)",
            "        logger.info('POST returning 201')",
            "",
            "    def put(self):",
            "        web_util.echo_json_response(",
            "            self, 400, \"Allowlist handler: PUT Not Implemented\")",
            "",
            "    def data_received(self, chunk):",
            "        raise NotImplementedError()",
            "",
            "",
            "async def invoke_get_quote(agent, need_pubkey):",
            "    failure = Failure(Component.INTERNAL, [\"verifier\"])",
            "    if agent is None:",
            "        raise Exception(\"agent deleted while being processed\")",
            "    params = cloud_verifier_common.prepare_get_quote(agent)",
            "",
            "    partial_req = \"1\"",
            "    if need_pubkey:",
            "        partial_req = \"0\"",
            "",
            "    # TODO: remove special handling after initial upgrade",
            "    if agent['ssl_context']:",
            "        res = tornado_requests.request(\"GET\",",
            "                                       f\"https://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/quotes/integrity\"",
            "                                       f\"?nonce={params['nonce']}&mask={params['mask']}\"",
            "                                       f\"&partial={partial_req}&ima_ml_entry={params['ima_ml_entry']}\",",
            "                                       context=agent['ssl_context'])",
            "    else:",
            "        res = tornado_requests.request(\"GET\",",
            "                                       f\"http://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/quotes/integrity\"",
            "                                       f\"?nonce={params['nonce']}&mask={params['mask']}\"",
            "                                       f\"&partial={partial_req}&ima_ml_entry={params['ima_ml_entry']}\")",
            "    response = await res",
            "",
            "    if response.status_code != 200:",
            "        # this is a connection error, retry get quote",
            "        if response.status_code in [500, 599]:",
            "            asyncio.ensure_future(process_agent(",
            "                agent, states.GET_QUOTE_RETRY))",
            "        else:",
            "            # catastrophic error, do not continue",
            "            logger.critical(\"Unexpected Get Quote response error for cloud agent %s, Error: %s\", agent['agent_id'], response.status_code)",
            "            failure.add_event(\"no_quote\", \"Unexpected Get Quote reponse from agent\", False)",
            "            asyncio.ensure_future(process_agent(agent, states.FAILED, failure))",
            "    else:",
            "        try:",
            "            json_response = json.loads(response.body)",
            "",
            "            # validate the cloud agent response",
            "            if 'provide_V' not in agent :",
            "                agent['provide_V'] = True",
            "            agentAttestState = get_AgentAttestStates().get_by_agent_id(agent['agent_id'])",
            "            failure = cloud_verifier_common.process_quote_response(agent, json_response['results'], agentAttestState)",
            "            if not failure:",
            "                if agent['provide_V']:",
            "                    asyncio.ensure_future(process_agent(agent, states.PROVIDE_V))",
            "                else:",
            "                    asyncio.ensure_future(process_agent(agent, states.GET_QUOTE))",
            "            else:",
            "                asyncio.ensure_future(process_agent(agent, states.INVALID_QUOTE, failure))",
            "",
            "            # store the attestation state",
            "            store_attestation_state(agentAttestState)",
            "",
            "        except Exception as e:",
            "            logger.exception(e)",
            "",
            "",
            "async def invoke_provide_v(agent):",
            "    failure = Failure(Component.INTERNAL, [\"verifier\"])",
            "    if agent is None:",
            "        raise Exception(\"Agent deleted while being processed\")",
            "    try:",
            "        if agent['pending_event'] is not None:",
            "            agent['pending_event'] = None",
            "    except KeyError:",
            "        pass",
            "    v_json_message = cloud_verifier_common.prepare_v(agent)",
            "",
            "    # TODO: remove special handling after initial upgrade",
            "    if agent['ssl_context']:",
            "        res = tornado_requests.request(",
            "            \"POST\", f\"https://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/keys/vkey\",",
            "            data=v_json_message, context=agent['ssl_context'])",
            "    else:",
            "        res = tornado_requests.request(",
            "            \"POST\", f\"http://{agent['ip']}:{agent['port']}/v{agent['supported_version']}/keys/vkey\",",
            "            data=v_json_message)",
            "",
            "    response = await res",
            "",
            "    if response.status_code != 200:",
            "        if response.status_code in [500, 599]:",
            "            asyncio.ensure_future(",
            "                process_agent(agent, states.PROVIDE_V_RETRY))",
            "        else:",
            "            # catastrophic error, do not continue",
            "            logger.critical(\"Unexpected Provide V response error for cloud agent %s, Error: %s\", agent['agent_id'], response.status_code)",
            "            failure.add_event(\"no_v\", {\"message\": \"Unexpected provide V response\", \"data\": response.status_code}, False)",
            "            asyncio.ensure_future(process_agent(agent, states.FAILED, failure))",
            "    else:",
            "        asyncio.ensure_future(process_agent(agent, states.GET_QUOTE))",
            "",
            "",
            "async def process_agent(agent, new_operational_state, failure=Failure(Component.INTERNAL, [\"verifier\"])):",
            "    # Convert to dict if the agent arg is a db object",
            "    if not isinstance(agent, dict):",
            "        agent = _from_db_obj(agent)",
            "",
            "    session = get_session()",
            "    try:  # pylint: disable=R1702",
            "        main_agent_operational_state = agent['operational_state']",
            "        try:",
            "            stored_agent = session.query(VerfierMain).filter_by(",
            "                agent_id=str(agent['agent_id'])).first()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        # if the user did terminated this agent",
            "        if stored_agent.operational_state == states.TERMINATED:",
            "            logger.warning(\"Agent %s terminated by user.\", agent['agent_id'])",
            "            if agent['pending_event'] is not None:",
            "                tornado.ioloop.IOLoop.current().remove_timeout(",
            "                    agent['pending_event'])",
            "            verifier_db_delete_agent(session, agent['agent_id'])",
            "            return",
            "",
            "        # if the user tells us to stop polling because the tenant quote check failed",
            "        if stored_agent.operational_state == states.TENANT_FAILED:",
            "            logger.warning(\"Agent %s has failed tenant quote. Stopping polling\",  agent['agent_id'])",
            "            if agent['pending_event'] is not None:",
            "                tornado.ioloop.IOLoop.current().remove_timeout(",
            "                    agent['pending_event'])",
            "            return",
            "",
            "        # If failed during processing, log regardless and drop it on the floor",
            "        # The administration application (tenant) can GET the status and act accordingly (delete/retry/etc).",
            "        if new_operational_state in (states.FAILED, states.INVALID_QUOTE):",
            "            assert failure, \"States FAILED and INVALID QUOTE should only be reached with a failure message\"",
            "",
            "            if agent.get('severity_level') is None or agent['severity_level'] < failure.highest_severity.severity:",
            "                agent['severity_level'] = failure.highest_severity.severity",
            "                agent['last_event_id'] = failure.highest_severity_event.event_id",
            "                agent['operational_state'] = new_operational_state",
            "",
            "                # issue notification for invalid quotes",
            "                if new_operational_state == states.INVALID_QUOTE:",
            "                    cloud_verifier_common.notify_error(agent, event=failure.highest_severity_event)",
            "",
            "                # When the failure is irrecoverable we stop polling the agent",
            "                if not failure.recoverable or failure.highest_severity == MAX_SEVERITY_LABEL:",
            "                    if agent['pending_event'] is not None:",
            "                        tornado.ioloop.IOLoop.current().remove_timeout(",
            "                            agent['pending_event'])",
            "                    for key in exclude_db:",
            "                        if key in agent:",
            "                            del agent[key]",
            "                    session.query(VerfierMain).filter_by(",
            "                        agent_id=agent['agent_id']).update(agent)",
            "                    session.commit()",
            "",
            "        # propagate all state, but remove none DB keys first (using exclude_db)",
            "        try:",
            "            agent_db = dict(agent)",
            "            for key in exclude_db:",
            "                if key in agent_db:",
            "                    del agent_db[key]",
            "",
            "            session.query(VerfierMain).filter_by(",
            "                agent_id=agent_db['agent_id']).update(agent_db)",
            "            session.commit()",
            "        except SQLAlchemyError as e:",
            "            logger.error('SQLAlchemy Error: %s', e)",
            "",
            "        # If agent was in a failed state we check if we either stop polling",
            "        # or just add it again to the event loop",
            "        if new_operational_state in [states.FAILED, states.INVALID_QUOTE]:",
            "            if not failure.recoverable or failure.highest_severity == MAX_SEVERITY_LABEL:",
            "                logger.warning(\"Agent %s failed, stopping polling\", agent['agent_id'])",
            "                return",
            "",
            "            await invoke_get_quote(agent, False)",
            "            return",
            "",
            "        # if new, get a quote",
            "        if (main_agent_operational_state == states.START and",
            "                new_operational_state == states.GET_QUOTE):",
            "            agent['num_retries'] = 0",
            "            agent['operational_state'] = states.GET_QUOTE",
            "            await invoke_get_quote(agent, True)",
            "            return",
            "",
            "        if (main_agent_operational_state == states.GET_QUOTE and",
            "                new_operational_state == states.PROVIDE_V):",
            "            agent['num_retries'] = 0",
            "            agent['operational_state'] = states.PROVIDE_V",
            "            await invoke_provide_v(agent)",
            "            return",
            "",
            "        if (main_agent_operational_state in (states.PROVIDE_V, states.GET_QUOTE) and",
            "                new_operational_state == states.GET_QUOTE):",
            "            agent['num_retries'] = 0",
            "            interval = config.getfloat('cloud_verifier', 'quote_interval')",
            "            agent['operational_state'] = states.GET_QUOTE",
            "            if interval == 0:",
            "                await invoke_get_quote(agent, False)",
            "            else:",
            "                logger.debug(\"Setting up callback to check again in %f seconds\", interval)",
            "                # set up a call back to check again",
            "                cb = functools.partial(invoke_get_quote, agent, False)",
            "                pending = tornado.ioloop.IOLoop.current().call_later(interval, cb)",
            "                agent['pending_event'] = pending",
            "            return",
            "",
            "        maxr = config.getint('cloud_verifier', 'max_retries')",
            "        interval = config.getfloat('cloud_verifier', 'retry_interval')",
            "        exponential_backoff = config.getboolean('cloud_verifier', 'exponential_backoff')",
            "",
            "        if (main_agent_operational_state == states.GET_QUOTE and",
            "                new_operational_state == states.GET_QUOTE_RETRY):",
            "            if agent['num_retries'] >= maxr:",
            "                logger.warning(\"Agent %s was not reachable for quote in %d tries, setting state to FAILED\", agent['agent_id'], maxr)",
            "                failure.add_event(\"not_reachable\", \"agent was not reachable from verifier\", False)",
            "                if agent['first_verified']:  # only notify on previously good agents",
            "                    cloud_verifier_common.notify_error(",
            "                        agent, msgtype='comm_error', event=failure.highest_severity_event)",
            "                else:",
            "                    logger.debug(\"Communication error for new agent. No notification will be sent\")",
            "                await process_agent(agent, states.FAILED, failure)",
            "            else:",
            "                agent['operational_state'] = states.GET_QUOTE",
            "                cb = functools.partial(invoke_get_quote, agent, True)",
            "                agent['num_retries'] += 1",
            "                next_retry = retry.retry_time(exponential_backoff, interval, agent['num_retries'], logger)",
            "                logger.info(\"Connection to %s refused after %d/%d tries, trying again in %f seconds\", agent['ip'], agent['num_retries'], maxr, next_retry)",
            "                tornado.ioloop.IOLoop.current().call_later(next_retry, cb)",
            "            return",
            "",
            "        if (main_agent_operational_state == states.PROVIDE_V and",
            "                new_operational_state == states.PROVIDE_V_RETRY):",
            "            if agent['num_retries'] >= maxr:",
            "                logger.warning(\"Agent %s was not reachable to provide v in %d tries, setting state to FAILED\", agent['agent_id'], maxr)",
            "                failure.add_event(\"not_reachable_v\", \"agent was not reachable to provide V\", False)",
            "                cloud_verifier_common.notify_error(",
            "                    agent, msgtype='comm_error', event=failure.highest_severity_event)",
            "                await process_agent(agent, states.FAILED, failure)",
            "            else:",
            "                agent['operational_state'] = states.PROVIDE_V",
            "                cb = functools.partial(invoke_provide_v, agent)",
            "                agent['num_retries'] += 1",
            "                next_retry = retry.retry_time(exponential_backoff, interval, agent['num_retries'], logger)",
            "                logger.info(\"Connection to %s refused after %d/%d tries, trying again in %f seconds\", agent['ip'], agent['num_retries'], maxr, next_retry)",
            "                tornado.ioloop.IOLoop.current().call_later(next_retry, cb)",
            "            return",
            "        raise Exception(\"nothing should ever fall out of this!\")",
            "",
            "    except Exception as e:",
            "        logger.error(\"Polling thread error: %s\", e)",
            "        logger.exception(e)",
            "",
            "",
            "async def activate_agents(verifier_id, verifier_ip, verifier_port, mtls_options):",
            "    session = get_session()",
            "    aas = get_AgentAttestStates()",
            "    try:",
            "        agents = session.query(VerfierMain).filter_by(",
            "            verifier_id=verifier_id).all()",
            "        for agent in agents:",
            "            agent.verifier_ip = verifier_ip",
            "            agent.verifier_host = verifier_port",
            "            agent_run = _from_db_obj(agent)",
            "            if agent_run[\"mtls_cert\"]:",
            "                agent_run[\"ssl_context\"] = web_util.generate_agent_mtls_context(agent_run[\"mtls_cert\"], mtls_options)",
            "            if agent.operational_state == states.START:",
            "                asyncio.ensure_future(process_agent(agent_run, states.GET_QUOTE))",
            "            if agent.boottime:",
            "                ima_pcrs_dict = {}",
            "                for pcr_num in agent.ima_pcrs:",
            "                    ima_pcrs_dict[pcr_num] = getattr(agent, f'pcr{pcr_num}')",
            "                aas.add(agent.agent_id, agent.boottime, ima_pcrs_dict, agent.next_ima_ml_entry, agent.learned_ima_keyrings)",
            "        session.commit()",
            "    except SQLAlchemyError as e:",
            "        logger.error('SQLAlchemy Error: %s', e)",
            "",
            "",
            "def main():",
            "    \"\"\"Main method of the Cloud Verifier Server.  This method is encapsulated in a function for packaging to allow it to be",
            "    called as a function by an external program.\"\"\"",
            "",
            "    cloudverifier_port = config.get('cloud_verifier', 'cloudverifier_port')",
            "    cloudverifier_host = config.get('cloud_verifier', 'cloudverifier_ip')",
            "    cloudverifier_id = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)",
            "",
            "    # allow tornado's max upload size to be configurable",
            "    max_upload_size = None",
            "    if config.has_option('cloud_verifier', 'max_upload_size'):",
            "        max_upload_size = int(config.get('cloud_verifier', 'max_upload_size'))",
            "",
            "    # set a conservative general umask",
            "    os.umask(0o077)",
            "",
            "    VerfierMain.metadata.create_all(engine, checkfirst=True)",
            "    session = get_session()",
            "    try:",
            "        query_all = session.query(VerfierMain).all()",
            "        for row in query_all:",
            "            if row.operational_state in states.APPROVED_REACTIVATE_STATES:",
            "                row.operational_state = states.START",
            "        session.commit()",
            "    except SQLAlchemyError as e:",
            "        logger.error('SQLAlchemy Error: %s', e)",
            "",
            "    num = session.query(VerfierMain.agent_id).count()",
            "    if num > 0:",
            "        agent_ids = session.query(VerfierMain.agent_id).all()",
            "        logger.info(\"Agent ids in db loaded from file: %s\", agent_ids)",
            "",
            "    logger.info('Starting Cloud Verifier (tornado) on port %s, use <Ctrl-C> to stop', cloudverifier_port)",
            "",
            "    # print out API versions we support",
            "    keylime_api_version.log_api_versions(logger)",
            "",
            "    context, mtls_options = web_util.init_mtls(logger=logger)",
            "",
            "    # Check for user defined CA to connect to agent",
            "    agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)",
            "    agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)",
            "    agent_mtls_private_key_pw = config.get(\"cloud_verifier\", \"agent_mtls_private_key_pw\", fallback=None)",
            "",
            "    # Only set custom options if the cert should not be the same as used by the verifier",
            "    if agent_mtls_cert != \"CV\":",
            "        mtls_options = (agent_mtls_cert, agent_mtls_private_key, agent_mtls_private_key_pw)",
            "",
            "    app = tornado.web.Application([",
            "        (r\"/v?[0-9]+(?:\\.[0-9]+)?/agents/.*\", AgentsHandler, {\"mtls_options\": mtls_options}),",
            "        (r\"/v?[0-9]+(?:\\.[0-9]+)?/allowlists/.*\", AllowlistHandler),",
            "        (r\"/versions?\", VersionHandler),",
            "        (r\".*\", MainHandler),",
            "    ])",
            "",
            "    sockets = tornado.netutil.bind_sockets(",
            "        int(cloudverifier_port), address=cloudverifier_host)",
            "",
            "    def server_process(task_id):",
            "        logger.info(\"Starting server of process %s\", task_id)",
            "        engine.dispose()",
            "        server = tornado.httpserver.HTTPServer(app, ssl_options=context, max_buffer_size=max_upload_size)",
            "        server.add_sockets(sockets)",
            "",
            "        def server_sig_handler(*_):",
            "            logger.info(\"Shutting down server %s..\", task_id)",
            "            # Stop server to not accept new incoming connections",
            "            server.stop()",
            "",
            "            # Wait for all connections to be closed and then stop ioloop",
            "            async def stop():",
            "                await server.close_all_connections()",
            "                tornado.ioloop.IOLoop.current().stop()",
            "            asyncio.ensure_future(stop())",
            "",
            "        # Attach signal handler to ioloop.",
            "        # Do not use signal.signal(..) for that because it does not work!",
            "        loop = asyncio.get_event_loop()",
            "        loop.add_signal_handler(signal.SIGINT, server_sig_handler)",
            "        loop.add_signal_handler(signal.SIGTERM, server_sig_handler)",
            "",
            "        server.start()",
            "        if task_id == 0:",
            "            # Reactivate agents",
            "            asyncio.ensure_future(activate_agents(cloudverifier_id, cloudverifier_host, cloudverifier_port, mtls_options))",
            "        tornado.ioloop.IOLoop.current().start()",
            "        logger.debug(\"Server %s stopped.\", task_id)",
            "        sys.exit(0)",
            "",
            "    processes = []",
            "",
            "    def sig_handler(*_):",
            "        if config.getboolean('cloud_verifier', 'revocation_notifier'):",
            "            revocation_notifier.stop_broker()",
            "        for p in processes:",
            "            p.join()",
            "        sys.exit(0)",
            "",
            "    signal.signal(signal.SIGINT, sig_handler)",
            "    signal.signal(signal.SIGTERM, sig_handler)",
            "    if config.getboolean('cloud_verifier', 'revocation_notifier'):",
            "        logger.info(\"Starting service for revocation notifications on port %s\",",
            "                    config.getint('cloud_verifier', 'revocation_notifier_port'))",
            "        revocation_notifier.start_broker()",
            "",
            "    num_workers = config.getint(",
            "        'cloud_verifier', 'multiprocessing_pool_num_workers')",
            "    if num_workers <= 0:",
            "        num_workers = tornado.process.cpu_count()",
            "    for task_id in range(0, num_workers):",
            "        process = Process(target=server_process, args=(task_id,))",
            "        process.start()",
            "        processes.append(process)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "22": [],
            "460": [
                "AgentsHandler",
                "post"
            ],
            "461": [
                "AgentsHandler",
                "post"
            ],
            "462": [
                "AgentsHandler",
                "post"
            ],
            "463": [
                "AgentsHandler",
                "post"
            ],
            "464": [
                "AgentsHandler",
                "post"
            ],
            "465": [
                "AgentsHandler",
                "post"
            ],
            "466": [
                "AgentsHandler",
                "post"
            ],
            "467": [
                "AgentsHandler",
                "post"
            ],
            "468": [
                "AgentsHandler",
                "post"
            ],
            "469": [
                "AgentsHandler",
                "post"
            ],
            "470": [
                "AgentsHandler",
                "post"
            ],
            "471": [
                "AgentsHandler",
                "post"
            ],
            "472": [
                "AgentsHandler",
                "post"
            ],
            "473": [
                "AgentsHandler",
                "post"
            ],
            "475": [
                "AgentsHandler",
                "post"
            ],
            "513": [
                "AgentsHandler",
                "post"
            ]
        },
        "addLocation": []
    },
    "keylime/tenant.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 631,
                "afterPatchRowNumber": 631,
                "PatchRowcode": "             'accept_tpm_hash_algs': self.accept_tpm_hash_algs,"
            },
            "1": {
                "beforePatchRowNumber": 632,
                "afterPatchRowNumber": 632,
                "PatchRowcode": "             'accept_tpm_encryption_algs': self.accept_tpm_encryption_algs,"
            },
            "2": {
                "beforePatchRowNumber": 633,
                "afterPatchRowNumber": 633,
                "PatchRowcode": "             'accept_tpm_signing_algs': self.accept_tpm_signing_algs,"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 634,
                "PatchRowcode": "+            'ak_tpm': self.registrar_data['aik_tpm'],"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 635,
                "PatchRowcode": "+            'mtls_cert': self.registrar_data.get('mtls_cert', None),"
            },
            "5": {
                "beforePatchRowNumber": 634,
                "afterPatchRowNumber": 636,
                "PatchRowcode": "             'supported_version': self.supported_version,"
            },
            "6": {
                "beforePatchRowNumber": 635,
                "afterPatchRowNumber": 637,
                "PatchRowcode": "         }"
            },
            "7": {
                "beforePatchRowNumber": 636,
                "afterPatchRowNumber": 638,
                "PatchRowcode": "         json_message = json.dumps(data)"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python3",
            "",
            "'''",
            "SPDX-License-Identifier: Apache-2.0",
            "Copyright 2017 Massachusetts Institute of Technology.",
            "'''",
            "",
            "import argparse",
            "import base64",
            "import hashlib",
            "import io",
            "import logging",
            "import os",
            "import subprocess",
            "import sys",
            "import time",
            "import zipfile",
            "import json",
            "import tempfile",
            "import requests",
            "",
            "from cryptography.hazmat.primitives import serialization as crypto_serialization",
            "",
            "from keylime.agentstates import AgentAttestState",
            "from keylime.requests_client import RequestsClient",
            "from keylime.common import states, retry",
            "from keylime import config",
            "from keylime import keylime_logging",
            "from keylime import registrar_client",
            "from keylime.tpm import tpm2_objects",
            "from keylime.tpm.tpm_main import tpm",
            "from keylime.tpm.tpm_abstract import TPM_Utilities",
            "from keylime import crypto",
            "from keylime.cmd import user_data_encrypt",
            "from keylime import ca_util",
            "from keylime.common import algorithms, validators",
            "from keylime.ima import ima, file_signatures",
            "from keylime import measured_boot",
            "from keylime import signing",
            "from keylime import api_version as keylime_api_version",
            "",
            "# setup logging",
            "logger = keylime_logging.init_logging('tenant')",
            "",
            "# special exception that suppresses stack traces when it happens",
            "class UserError(Exception):",
            "    pass",
            "",
            "",
            "class Tenant():",
            "    \"\"\"Simple command processor example.\"\"\"",
            "",
            "    config = None",
            "",
            "    cloudverifier_ip = None",
            "    cloudverifier_port = None",
            "",
            "    cloudagent_ip = None",
            "    cv_cloudagent_ip = None",
            "    cloudagent_port = None",
            "",
            "    registrar_ip = None",
            "    registrar_port = None",
            "    registrar_data = None",
            "",
            "    webapp_ip = None",
            "    webapp_port = None",
            "",
            "    api_version = None",
            "",
            "    uuid_service_generate_locally = None",
            "    agent_uuid = None",
            "",
            "    K = None",
            "    V = None",
            "    U = None",
            "    auth_tag = None",
            "",
            "    tpm_policy = None",
            "    metadata = {}",
            "    allowlist = {}",
            "    ima_sign_verification_keys = []",
            "    revocation_key = \"\"",
            "    accept_tpm_hash_algs = []",
            "    accept_tpm_encryption_algs = []",
            "    accept_tpm_signing_algs = []",
            "    mb_refstate = None",
            "    supported_version = None",
            "",
            "    payload = None",
            "",
            "    tpm_instance = tpm()",
            "",
            "    def __init__(self):",
            "        \"\"\" Set up required values and TLS",
            "        \"\"\"",
            "        self.nonce = None",
            "        self.agent_ip = None",
            "        self.verifier_id = None",
            "        self.agent_port = None",
            "        self.verifier_ip = config.get('tenant', 'cloudverifier_ip')",
            "        self.verifier_port = config.get('tenant', 'cloudverifier_port')",
            "        self.registrar_ip = config.get('tenant', 'registrar_ip')",
            "        self.registrar_port = config.get('tenant', 'registrar_port')",
            "        self.webapp_port = config.getint('webapp', 'webapp_port')",
            "        self.webapp_ip = config.get('webapp', 'webapp_ip')",
            "",
            "        self.api_version = keylime_api_version.current_version()",
            "",
            "        (self.my_cert, self.my_priv_key), (self.my_agent_cert, self.my_agent_priv_key), self.verifier_ca_cert = Tenant.get_tls_context()",
            "        self.cert = (self.my_cert, self.my_priv_key)",
            "        self.agent_cert = (self.my_agent_cert, self.my_agent_priv_key)",
            "        if config.getboolean('general', \"enable_tls\"):",
            "            self.tls_cv_enabled = True",
            "        else:",
            "            self.tls_cv_enabled = False",
            "            self.cert = \"\"",
            "            logger.warning(",
            "                \"Warning: TLS is currently disabled, keys will be sent in the clear! This should only be used for testing.\")",
            "        self.tls_agent_enabled = True",
            "        self.verify_custom = None",
            "",
            "    @property",
            "    def verifier_base_url(self):",
            "        return f'{self.verifier_ip}:{self.verifier_port}'",
            "",
            "    @staticmethod",
            "    def get_tls_context():",
            "        \"\"\"Generate certifcate naming and path",
            "",
            "        Returns:",
            "            string -- my_cert (client_cert), my_priv_key (client private key)",
            "        \"\"\"",
            "        verifier_ca_cert = config.get('tenant', 'ca_cert')",
            "        my_cert = config.get('tenant', 'my_cert')",
            "        my_priv_key = config.get('tenant', 'private_key')",
            "        tls_dir = config.get('tenant', 'tls_dir')",
            "",
            "        if tls_dir == 'default':",
            "            verifier_ca_cert = 'cacert.crt'",
            "            my_cert = 'client-cert.crt'",
            "            my_priv_key = 'client-private.pem'",
            "            tls_dir = 'cv_ca'",
            "",
            "        if tls_dir[0] != '/':",
            "            tls_dir = os.path.abspath(os.path.join(config.WORK_DIR, tls_dir))",
            "",
            "        logger.info(\"Setting up client TLS in %s\", tls_dir)",
            "        verifier_ca_cert = os.path.join(tls_dir, verifier_ca_cert)",
            "        my_cert = os.path.join(tls_dir, my_cert)",
            "        my_priv_key = os.path.join(tls_dir, my_priv_key)",
            "",
            "        tls_context = (my_cert, my_priv_key)",
            "",
            "        agent_mtls_context = (None, None)",
            "        # Check for user defined CA to connect to agent",
            "        agent_mtls_cert_enabled = config.getboolean('tenant', 'agent_mtls_cert_enabled', fallback=False)",
            "",
            "        if agent_mtls_cert_enabled:",
            "            agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)",
            "            agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)",
            "            agent_mtls_context = tls_context",
            "            if agent_mtls_cert != \"CV\":",
            "                agent_mtls_context = (agent_mtls_cert, agent_mtls_private_key)",
            "",
            "        return tls_context, agent_mtls_context, verifier_ca_cert",
            "",
            "    def process_allowlist(self, args):",
            "        # Set up PCR values",
            "        tpm_policy = config.get('tenant', 'tpm_policy')",
            "        if \"tpm_policy\" in args and args[\"tpm_policy\"] is not None:",
            "            tpm_policy = args[\"tpm_policy\"]",
            "        self.tpm_policy = TPM_Utilities.readPolicy(tpm_policy)",
            "        logger.info(\"TPM PCR Mask from policy is %s\", self.tpm_policy['mask'])",
            "",
            "        if len(args.get(\"ima_sign_verification_keys\")) > 0:",
            "            # Auto-enable IMA (or-bit mask)",
            "            self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))",
            "",
            "            # Add all IMA file signing verification keys to a keyring",
            "            tenant_keyring = file_signatures.ImaKeyring()",
            "            for filename in args[\"ima_sign_verification_keys\"]:",
            "                pubkey, keyidv2 = file_signatures.get_pubkey_from_file(filename)",
            "                if not pubkey:",
            "                    raise UserError(f\"File '{filename}' is not a file with a key\")",
            "                tenant_keyring.add_pubkey(pubkey, keyidv2)",
            "            self.ima_sign_verification_keys = tenant_keyring.to_string()",
            "",
            "        # Read command-line path string allowlist",
            "        al_data = None",
            "",
            "        if \"allowlist\" in args and args[\"allowlist\"] is not None:",
            "",
            "            self.enforce_pcrs(list(self.tpm_policy.keys()), [ config.IMA_PCR ], \"IMA\")",
            "",
            "            # Auto-enable IMA (or-bit mask)",
            "            self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))",
            "",
            "            if isinstance(args[\"allowlist\"], str):",
            "                if args[\"allowlist\"] == \"default\":",
            "                    args[\"allowlist\"] = config.get('tenant', 'allowlist')",
            "                try:",
            "                    al_data = ima.read_allowlist(args[\"allowlist\"], args[\"allowlist_checksum\"], args[\"allowlist_sig\"], args[\"allowlist_sig_key\"])",
            "                except Exception as ima_e:",
            "                    raise UserError(str(ima_e)) from ima_e",
            "            elif isinstance(args[\"allowlist\"], list):",
            "                al_data = args[\"allowlist\"]",
            "            else:",
            "                raise UserError(\"Invalid allowlist provided\")",
            "",
            "        # Read command-line path string IMA exclude list",
            "        excl_data = None",
            "        if \"ima_exclude\" in args and args[\"ima_exclude\"] is not None:",
            "            if isinstance(args[\"ima_exclude\"], str):",
            "                if args[\"ima_exclude\"] == \"default\":",
            "                    args[\"ima_exclude\"] = config.get(",
            "                        'tenant', 'ima_excludelist')",
            "                excl_data = ima.read_excllist(args[\"ima_exclude\"])",
            "            elif isinstance(args[\"ima_exclude\"], list):",
            "                excl_data = args[\"ima_exclude\"]",
            "            else:",
            "                raise UserError(\"Invalid exclude list provided\")",
            "",
            "        # Set up IMA",
            "        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.IMA_PCR):",
            "            # Process allowlists",
            "            self.allowlist = ima.process_allowlists(al_data, excl_data)",
            "",
            "        # Read command-line path string TPM event log (measured boot) reference state",
            "        mb_refstate_data = None",
            "        if \"mb_refstate\" in args and args[\"mb_refstate\"] is not None:",
            "",
            "            self.enforce_pcrs(list(self.tpm_policy.keys()), config.MEASUREDBOOT_PCRS, \"measured boot\")",
            "",
            "            # Auto-enable TPM event log mesured boot (or-bit mask)",
            "            for _pcr in config.MEASUREDBOOT_PCRS:",
            "                self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << _pcr))",
            "",
            "            logger.info(\"TPM PCR Mask automatically modified is %s to include IMA/Event log PCRs\", self.tpm_policy['mask'])",
            "",
            "            if isinstance(args[\"mb_refstate\"], str):",
            "                if args[\"mb_refstate\"] == \"default\":",
            "                    args[\"mb_refstate\"] = config.get('tenant', 'mb_refstate')",
            "                mb_refstate_data = measured_boot.read_mb_refstate(args[\"mb_refstate\"])",
            "            else:",
            "                raise UserError(\"Invalid measured boot reference state (intended state) provided\")",
            "",
            "        # Set up measured boot (TPM event log) reference state",
            "        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.MEASUREDBOOT_PCRS[2]) :",
            "            # Process measured boot reference state",
            "            self.mb_refstate = mb_refstate_data",
            "",
            "    def init_add(self, args):",
            "        \"\"\" Set up required values. Command line options can overwrite these config values",
            "",
            "        Arguments:",
            "            args {[string]} -- agent_ip|agent_port|cv_agent_ip",
            "        \"\"\"",
            "        if \"agent_ip\" in args:",
            "            self.agent_ip = args[\"agent_ip\"]",
            "",
            "        if 'agent_port' in args and args['agent_port'] is not None:",
            "            self.agent_port = args['agent_port']",
            "",
            "        registrar_client.init_client_tls(\"tenant\")",
            "        self.registrar_data = registrar_client.getData(self.registrar_ip, self.registrar_port, self.agent_uuid)",
            "",
            "        if self.registrar_data is None:",
            "            raise UserError(f\"Agent ${self.agent_uuid} data not found in the Registrar.\")",
            "",
            "        # try to get the port or ip from the registrar if it is missing",
            "        if (self.agent_ip is None or self.agent_port is None) and self.registrar_data is not None:",
            "            if self.agent_ip is None:",
            "                if self.registrar_data['ip'] is not None:",
            "                    self.agent_ip = self.registrar_data['ip']",
            "                else:",
            "                    raise UserError(\"No Ip was specified or found in the Registrar\")",
            "",
            "            if self.agent_port is None and self.registrar_data['port'] is not None:",
            "                self.agent_port = self.registrar_data[\"port\"]",
            "",
            "        # If no agent port was found try to use the default from the config file",
            "        if self.agent_port is None:",
            "            self.agent_port = config.get('cloud_agent', 'cloudagent_port')",
            "",
            "        # Check if a contact ip and port for the agent was found",
            "        if self.agent_ip is None:",
            "            raise UserError(\"The contact ip address for the agent was not specified.\")",
            "",
            "        if self.agent_port is None:",
            "            raise UserError(\"The contact port for the agent was not specified.\")",
            "",
            "        # Auto-detection for API version",
            "        self.supported_version = args[\"supported_version\"]",
            "        if self.supported_version is None:",
            "            # Default to 1.0 if the agent did not send a mTLS certificate",
            "            if self.registrar_data.get(\"mtls_cert\", None) is None:",
            "                self.supported_version = \"1.0\"",
            "            else:",
            "                # Try to connect to the agent to get supported version",
            "                if self.registrar_data['mtls_cert'] == \"disabled\":",
            "                    self.tls_agent_enabled = False",
            "                    self.verify_custom = False",
            "                    logger.warning(",
            "                        \"Warning: mTLS for agents is disabled: the identity of each node will be based on the properties of the TPM only. \"",
            "                        \"Unless you have strict control of your network, it is strongly advised that remote code execution should be disabled, \"",
            "                        \"by setting \\\"payload_script=\\\" and \\\"extract_payload_zip=False\\\" under \\\"[cloud_agent]\\\"\")",
            "                else:",
            "                    self.verify_custom = self.registrar_data['mtls_cert']",
            "",
            "                with RequestsClient(f\"{self.agent_ip}:{self.agent_port}\", tls_enabled=self.tls_agent_enabled, cert=self.agent_cert,",
            "                                    ignore_hostname=True, verify_custom=self.verify_custom) as get_version:",
            "                    res = get_version.get(\"/version\")",
            "                    if res and res.status_code == 200:",
            "                        try:",
            "                            data = res.json()",
            "                            api_version = data[\"results\"][\"supported_version\"]",
            "                            if keylime_api_version.validate_version(api_version):",
            "                                self.supported_version = api_version",
            "                            else:",
            "                                logger.warning(\"API version provided by the agent is not valid\")",
            "                        except (TypeError, KeyError):",
            "                            pass",
            "",
            "        if self.supported_version is None:",
            "            api_version = keylime_api_version.current_version()",
            "            logger.warning(\"Could not detect supported API version. Defaulting to %s\", api_version)",
            "            self.supported_version = api_version",
            "",
            "        # Now set the cv_agent_ip",
            "        if 'cv_agent_ip' in args and args['cv_agent_ip'] is not None:",
            "            self.cv_cloudagent_ip = args['cv_agent_ip']",
            "        else:",
            "            self.cv_cloudagent_ip = self.agent_ip",
            "",
            "        # Make sure all keys exist in dictionary",
            "        if \"file\" not in args:",
            "            args[\"file\"] = None",
            "        if \"keyfile\" not in args:",
            "            args[\"keyfile\"] = None",
            "        if \"payload\" not in args:",
            "            args[\"payload\"] = None",
            "        if \"ca_dir\" not in args:",
            "            args[\"ca_dir\"] = None",
            "        if \"incl_dir\" not in args:",
            "            args[\"incl_dir\"] = None",
            "        if \"ca_dir_pw\" not in args:",
            "            args[\"ca_dir_pw\"] = None",
            "",
            "        # Set up accepted algorithms",
            "        self.accept_tpm_hash_algs = config.get(",
            "            'tenant', 'accept_tpm_hash_algs').split(',')",
            "        self.accept_tpm_encryption_algs = config.get(",
            "            'tenant', 'accept_tpm_encryption_algs').split(',')",
            "        self.accept_tpm_signing_algs = config.get(",
            "            'tenant', 'accept_tpm_signing_algs').split(',')",
            "",
            "        self.process_allowlist(args)",
            "",
            "        # if none",
            "        if (args[\"file\"] is None and args[\"keyfile\"] is None and args[\"ca_dir\"] is None):",
            "            raise UserError(",
            "                \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "        if args[\"keyfile\"] is not None:",
            "            if args[\"file\"] is not None or args[\"ca_dir\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "            # read the keys in",
            "            if isinstance(args[\"keyfile\"], dict) and \"data\" in args[\"keyfile\"]:",
            "                if isinstance(args[\"keyfile\"][\"data\"], list) and len(args[\"keyfile\"][\"data\"]) == 1:",
            "                    keyfile = args[\"keyfile\"][\"data\"][0]",
            "                    if keyfile is None:",
            "                        raise UserError(\"Invalid key file contents\")",
            "                    f = io.StringIO(keyfile)",
            "                else:",
            "                    raise UserError(\"Invalid key file provided\")",
            "            else:",
            "                f = open(args[\"keyfile\"], encoding=\"utf-8\")  #pylint: disable=consider-using-with",
            "            self.K = base64.b64decode(f.readline())",
            "            self.U = base64.b64decode(f.readline())",
            "            self.V = base64.b64decode(f.readline())",
            "            f.close()",
            "",
            "            # read the payload in (opt.)",
            "            if isinstance(args[\"payload\"], dict) and \"data\" in args[\"payload\"]:",
            "                if isinstance(args[\"payload\"][\"data\"], list) and len(args[\"payload\"][\"data\"]) > 0:",
            "                    self.payload = args[\"payload\"][\"data\"][0]",
            "            else:",
            "                if args[\"payload\"] is not None:",
            "                    with open(args[\"payload\"], 'rb') as f:",
            "                        self.payload = f.read()",
            "",
            "        if args[\"file\"] is not None:",
            "            if args[\"keyfile\"] is not None or args[\"ca_dir\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "            if isinstance(args[\"file\"], dict) and \"data\" in args[\"file\"]:",
            "                if isinstance(args[\"file\"][\"data\"], list) and len(args[\"file\"][\"data\"]) > 0:",
            "                    contents = args[\"file\"][\"data\"][0]",
            "                    if contents is None:",
            "                        raise UserError(\"Invalid file payload contents\")",
            "                else:",
            "                    raise UserError(\"Invalid file payload provided\")",
            "            else:",
            "                with open(args[\"file\"], encoding=\"utf-8\") as f:",
            "                    contents = f.read()",
            "            ret = user_data_encrypt.encrypt(contents)",
            "            self.K = ret['k']",
            "            self.U = ret['u']",
            "            self.V = ret['v']",
            "            self.payload = ret['ciphertext']",
            "",
            "        if args[\"ca_dir\"] is None and args[\"incl_dir\"] is not None:",
            "            raise UserError(",
            "                \"--include option is only valid when used with --cert\")",
            "        if args[\"ca_dir\"] is not None:",
            "            if args[\"file\"] is not None or args[\"keyfile\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "            if args[\"ca_dir\"] == 'default':",
            "                args[\"ca_dir\"] = config.CA_WORK_DIR",
            "",
            "            if \"ca_dir_pw\" in args and args[\"ca_dir_pw\"] is not None:",
            "                ca_util.setpassword(args[\"ca_dir_pw\"])",
            "",
            "            if not os.path.exists(args[\"ca_dir\"]) or not os.path.exists(os.path.join(args[\"ca_dir\"], \"cacert.crt\")):",
            "                logger.warning(\"CA directory does not exist. Creating...\")",
            "                ca_util.cmd_init(args[\"ca_dir\"])",
            "            if not os.path.exists(",
            "                    os.path.join(args[\"ca_dir\"],",
            "                                 f\"{self.agent_uuid}-private.pem\")):",
            "                ca_util.cmd_mkcert(args[\"ca_dir\"], self.agent_uuid)",
            "",
            "            cert_pkg, serial, subject = ca_util.cmd_certpkg(",
            "                args[\"ca_dir\"], self.agent_uuid)",
            "",
            "            # support revocation",
            "            if not os.path.exists(os.path.join(args[\"ca_dir\"], \"RevocationNotifier-private.pem\")):",
            "                ca_util.cmd_mkcert(args[\"ca_dir\"], \"RevocationNotifier\")",
            "            rev_package, _, _ = ca_util.cmd_certpkg(",
            "                args[\"ca_dir\"], \"RevocationNotifier\")",
            "",
            "            # extract public and private keys from package",
            "            sf = io.BytesIO(rev_package)",
            "            with zipfile.ZipFile(sf) as zf:",
            "                privkey = zf.read(\"RevocationNotifier-private.pem\")",
            "                cert = zf.read(\"RevocationNotifier-cert.crt\")",
            "",
            "            # put the cert of the revoker into the cert package",
            "            sf = io.BytesIO(cert_pkg)",
            "            with zipfile.ZipFile(sf, 'a', compression=zipfile.ZIP_STORED) as zf:",
            "                zf.writestr('RevocationNotifier-cert.crt', cert)",
            "",
            "                # add additional files to zip",
            "                if args[\"incl_dir\"] is not None:",
            "                    if isinstance(args[\"incl_dir\"], dict) and \"data\" in args[\"incl_dir\"] and \"name\" in args[\"incl_dir\"]:",
            "                        if isinstance(args[\"incl_dir\"][\"data\"], list) and isinstance(args[\"incl_dir\"][\"name\"], list):",
            "                            if len(args[\"incl_dir\"][\"data\"]) != len(args[\"incl_dir\"][\"name\"]):",
            "                                raise UserError(\"Invalid incl_dir provided\")",
            "                            for i in range(len(args[\"incl_dir\"][\"data\"])):",
            "                                zf.writestr(os.path.basename(",
            "                                    args[\"incl_dir\"][\"name\"][i]), args[\"incl_dir\"][\"data\"][i])",
            "                    else:",
            "                        if os.path.exists(args[\"incl_dir\"]):",
            "                            files = next(os.walk(args[\"incl_dir\"]))[2]",
            "                            for filename in files:",
            "                                with open(os.path.join(args[\"incl_dir\"],",
            "                                                       filename), 'rb') as f:",
            "                                    zf.writestr(",
            "                                        os.path.basename(f.name), f.read())",
            "                        else:",
            "                            logger.warning('Specified include directory %s does not exist. Skipping...', args[\"incl_dir\"])",
            "",
            "            cert_pkg = sf.getvalue()",
            "",
            "            # put the private key into the data to be send to the CV",
            "            self.revocation_key = privkey.decode('utf-8')",
            "",
            "            # encrypt up the cert package",
            "            ret = user_data_encrypt.encrypt(cert_pkg)",
            "            self.K = ret['k']",
            "            self.U = ret['u']",
            "            self.V = ret['v']",
            "            self.metadata = {'cert_serial': serial, 'subject': subject}",
            "            self.payload = ret['ciphertext']",
            "",
            "        if self.payload is not None and len(self.payload) > config.getint('tenant', 'max_payload_size'):",
            "            raise UserError(f\"Payload size {len(self.payload)} exceeds max size {config.getint('tenant', 'max_payload_size')}\")",
            "",
            "    def enforce_pcrs(self, policy_pcrs, protected_pcrs, pcr_use) :",
            "        policy_pcrs = list(self.tpm_policy.keys())",
            "        policy_pcrs.remove('mask')",
            "",
            "        for _pcr in policy_pcrs :",
            "            if int(_pcr) in protected_pcrs :",
            "                logger.error('WARNING: PCR %s is specified in \"tpm_policy\", but will in fact be used by %s. Please remove it from policy', _pcr, pcr_use)",
            "                sys.exit(1)",
            "",
            "    def preloop(self):",
            "        \"\"\" encrypt the agent UUID as a check for delivering the correct key",
            "        \"\"\"",
            "        self.auth_tag = crypto.do_hmac(self.K, self.agent_uuid)",
            "        # be very careful printing K, U, or V as they leak in logs stored on unprotected disks",
            "        if config.INSECURE_DEBUG:",
            "            logger.debug(\"K: %s\", base64.b64encode(self.K))",
            "            logger.debug(\"V: %s\", base64.b64encode(self.V))",
            "            logger.debug(\"U: %s\", base64.b64encode(self.U))",
            "            logger.debug(\"Auth Tag: %s\", self.auth_tag)",
            "",
            "    def check_ek(self, ekcert):",
            "        \"\"\" Check the Entity Key",
            "",
            "        Arguments:",
            "            ekcert {str} -- The endorsement key, either None, \"emulator\", or base64 encoded der cert",
            "",
            "        Returns:",
            "            [type] -- [description]",
            "        \"\"\"",
            "        if config.getboolean('tenant', 'require_ek_cert'):",
            "            if ekcert == 'emulator' and config.DISABLE_EK_CERT_CHECK_EMULATOR:",
            "                logger.info(\"Not checking ekcert of TPM emulator\")",
            "            elif ekcert is None:",
            "                logger.warning(\"No EK cert provided, require_ek_cert option in config set to True\")",
            "                return False",
            "            elif not self.tpm_instance.verify_ek(base64.b64decode(ekcert)):",
            "                logger.warning(\"Invalid EK certificate\")",
            "                return False",
            "",
            "        return True",
            "",
            "    def validate_tpm_quote(self, public_key, quote, hash_alg):",
            "        \"\"\" Validate TPM Quote received from the Agent",
            "",
            "        Arguments:",
            "            public_key {[type]} -- [description]",
            "            quote {[type]} -- [description]",
            "            hash_alg {bool} -- [description]",
            "",
            "        Raises:",
            "            UserError: [description]",
            "",
            "        Returns:",
            "            [type] -- [description]",
            "        \"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        if self.registrar_data is None:",
            "            logger.warning(\"AIK not found in registrar, quote not validated\")",
            "            return False",
            "",
            "        failure = self.tpm_instance.check_quote(AgentAttestState(self.agent_uuid), self.nonce, public_key, quote,",
            "                                                self.registrar_data['aik_tpm'], hash_alg=hash_alg,",
            "                                                compressed=(self.supported_version == \"1.0\"))",
            "        if failure:",
            "            if self.registrar_data['regcount'] > 1:",
            "                logger.error(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured or a malicious host is present. Run 'regdelete' for this agent and restart\")",
            "                sys.exit()",
            "            return False",
            "",
            "        if self.registrar_data['regcount'] > 1:",
            "            logger.warning(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured. Run 'regdelete' for this agent and restart\")",
            "",
            "        if not config.getboolean('tenant', 'require_ek_cert') and config.get('tenant', 'ek_check_script') == \"\":",
            "            logger.warning(",
            "                \"DANGER: EK cert checking is disabled and no additional checks on EKs have been specified with ek_check_script option. Keylime is not secure!!\")",
            "",
            "        # check EK cert and make sure it matches EK",
            "        if not self.check_ek(self.registrar_data['ekcert']):",
            "            return False",
            "        # if agent is virtual, check phyisical EK cert and make sure it matches phyiscal EK",
            "        if 'provider_keys' in self.registrar_data:",
            "            if not self.check_ek(self.registrar_data['provider_keys']['ekcert']):",
            "                return False",
            "",
            "        # check all EKs with optional script:",
            "        script = config.get('tenant', 'ek_check_script')",
            "        if not script:",
            "            return True",
            "",
            "        if script[0] != '/':",
            "            script = os.path.join(config.WORK_DIR, script)",
            "",
            "        logger.info(\"Checking EK with script %s\", script)",
            "        # now we need to exec the script with the ek and ek cert in vars",
            "        env = os.environ.copy()",
            "        env['AGENT_UUID'] = self.agent_uuid",
            "        env['EK'] = tpm2_objects.pubkey_from_tpm2b_public(",
            "            base64.b64decode(self.registrar_data['ek_tpm']),",
            "            ).public_bytes(",
            "                crypto_serialization.Encoding.PEM,",
            "                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,",
            "            )",
            "        env['EK_TPM'] = self.registrar_data['ek_tpm']",
            "        if self.registrar_data['ekcert'] is not None:",
            "            env['EK_CERT'] = self.registrar_data['ekcert']",
            "        else:",
            "            env['EK_CERT'] = \"\"",
            "",
            "        env['PROVKEYS'] = json.dumps(self.registrar_data.get('provider_keys', {}))",
            "        with subprocess.Popen(script, env=env, shell=True,",
            "                              cwd=config.WORK_DIR, stdout=subprocess.PIPE,",
            "                              stderr=subprocess.STDOUT) as proc:",
            "            retval = proc.wait()",
            "            if retval != 0:",
            "                raise UserError(\"External check script failed to validate EK\")",
            "            logger.debug(\"External check script successfully to validated EK\")",
            "            while True:",
            "                line = proc.stdout.readline().decode()",
            "                if line == \"\":",
            "                    break",
            "                logger.debug(\"ek_check output: %s\", line.strip())",
            "        return True",
            "",
            "    def do_cv(self):",
            "        \"\"\" Initiaite v, agent_id and ip and initiate the cloudinit sequence",
            "        \"\"\"",
            "        b64_v = base64.b64encode(self.V).decode('utf-8')",
            "        logger.debug(\"b64_v: %s\", b64_v)",
            "        data = {",
            "            'v': b64_v,",
            "            'cloudagent_ip': self.cv_cloudagent_ip,",
            "            'cloudagent_port': self.agent_port,",
            "            'tpm_policy': json.dumps(self.tpm_policy),",
            "            'allowlist': json.dumps(self.allowlist),",
            "            'mb_refstate': json.dumps(self.mb_refstate),",
            "            'ima_sign_verification_keys': json.dumps(self.ima_sign_verification_keys),",
            "            'metadata': json.dumps(self.metadata),",
            "            'revocation_key': self.revocation_key,",
            "            'accept_tpm_hash_algs': self.accept_tpm_hash_algs,",
            "            'accept_tpm_encryption_algs': self.accept_tpm_encryption_algs,",
            "            'accept_tpm_signing_algs': self.accept_tpm_signing_algs,",
            "            'supported_version': self.supported_version,",
            "        }",
            "        json_message = json.dumps(data)",
            "        do_cv = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cv.post(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            data=json_message,",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        if response.status_code == 409:",
            "            # this is a conflict, need to update or delete it",
            "            logger.error(\"Agent %s already existed at CV. Please use delete or update.\", self.agent_uuid)",
            "            sys.exit()",
            "        elif response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response.json())",
            "            logger.error(\"POST command response: %s Unexpected response from Cloud Verifier: %s\", response.status_code, response.text)",
            "            sys.exit()",
            "",
            "    def do_cvstatus(self):",
            "        \"\"\"Perform operational state look up for agent on the verifier\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            res = response.pop('results')",
            "            response['results'] = {self.agent_uuid: res}",
            "",
            "            operational_state = states.state_to_str(",
            "                response['results'][self.agent_uuid]['operational_state'])",
            "            response['results'][self.agent_uuid]['operational_state'] = operational_state",
            "",
            "            logger.info(\"Agent Info:\\n%s\", json.dumps(response[\"results\"]))",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvlist(self):",
            "        \"\"\"List all agent statuses in cloudverifier\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        verifier_id = \"\"",
            "        if self.verifier_id is not None:",
            "            verifier_id = self.verifier_id",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/?verifier={verifier_id}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            logger.info('From verifier %s port %s retrieved: \"%s\"',",
            "                        self.verifier_ip, self.verifier_port, response)",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvbulkinfo(self):",
            "        \"\"\"Perform operational state look up for agent\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "",
            "        verifier_id = \"\"",
            "        if self.verifier_id is not None:",
            "            verifier_id = self.verifier_id",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/?bulk={True}&verifier={verifier_id}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            for agent in response[\"results\"].keys():",
            "                response[\"results\"][agent][\"operational_state\"] = \\",
            "                    states.state_to_str(response[\"results\"][agent][",
            "                                            \"operational_state\"])",
            "            logger.info(\"Bulk Agent Info:\\n%s\", json.dumps(response[\"results\"]))",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvdelete(self, verifier_check=True):",
            "        \"\"\"Delete agent from Verifier.\"\"\"",
            "        if verifier_check:",
            "            cvresponse = self.do_cvstatus()",
            "",
            "            if not isinstance(cvresponse, dict):",
            "                return cvresponse",
            "",
            "            if cvresponse['code'] != 200:",
            "                logger.error(\"Could not get status of agent %s from \"",
            "                             \"verifier %s.\", self.agent_uuid, self.verifier_ip)",
            "                return cvresponse",
            "",
            "            self.verifier_ip = cvresponse['results'][self.agent_uuid][\"verifier_ip\"]",
            "            self.verifier_port = cvresponse['results'][self.agent_uuid][\"verifier_port\"]",
            "",
            "        do_cvdelete = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvdelete.delete(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        response = response.json()",
            "",
            "        if response['code'] == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response",
            "        if response['code'] == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response",
            "        if response['code'] == 202:",
            "            deleted = False",
            "            for _ in range(12):",
            "                get_cvdelete = RequestsClient(",
            "                    self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "                response = get_cvdelete.get(",
            "                    (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "                    cert=self.cert,",
            "                    verify=self.verifier_ca_cert",
            "                )",
            "",
            "                if response.status_code == 404:",
            "                    deleted = True",
            "                    break",
            "                time.sleep(.4)",
            "            if deleted:",
            "                logger.info(\"CV completed deletion of agent %s\", self.agent_uuid)",
            "                return response.json()",
            "            logger.error(\"Timed out waiting for delete of agent %s to complete at CV\", self.agent_uuid)",
            "            return response.json()",
            "        if response['code'] == 200:",
            "            logger.info(\"Agent %s deleted from the CV\", self.agent_uuid)",
            "            return response",
            "",
            "        keylime_logging.log_http_response(",
            "            logger, logging.ERROR, response)",
            "        return response",
            "",
            "    def do_regstatus(self):",
            "        registrar_client.init_client_tls('tenant')",
            "        agent_info = registrar_client.getData(self.registrar_ip,",
            "                                              self.registrar_port,",
            "                                              self.agent_uuid)",
            "",
            "        if not agent_info:",
            "            logger.info(",
            "                \"Agent %s does not exist on the registrar. Please register the agent with the registrar.\",",
            "                self.agent_uuid)",
            "            response = {'code': 404,",
            "                        'status': f\"Agent {self.agent_uuid} does not exist on \"",
            "                                  f\"registrar {self.registrar_ip} port {self.registrar_port}.\",",
            "                        'results': {}}",
            "            logger.info(json.dumps(response))",
            "            return response",
            "",
            "        response = {'code': 200,",
            "                    'status': f\"Agent {self.agent_uuid} exists on \"",
            "                              f\"registrar {self.registrar_ip} port {self.registrar_port}.\",",
            "                    'results': {}}",
            "        response['results'][self.agent_uuid] = agent_info",
            "        response['results'][self.agent_uuid]['operational_state'] = \\",
            "            states.state_to_str(states.REGISTERED)",
            "",
            "        logger.info(json.dumps(response))",
            "",
            "        return response",
            "",
            "    def do_reglist(self):",
            "        \"\"\"List agents from Registrar\"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        response = registrar_client.doRegistrarList(",
            "            self.registrar_ip, self.registrar_port)",
            "",
            "        logger.info(\"From registrar %s port %s retrieved %s\",",
            "                    self.registrar_ip, self.registrar_port,",
            "                    json.dumps(response))",
            "        return response",
            "",
            "    def do_regdelete(self):",
            "        \"\"\"Delete agent from Registrar\"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        response = registrar_client.doRegistrarDelete(self.registrar_ip,",
            "                                           self.registrar_port,",
            "                                           self.agent_uuid)",
            "",
            "        return response",
            "",
            "    def do_status(self):",
            "        \"\"\"Perform operational state look up for agent\"\"\"",
            "",
            "        regresponse = self.do_regstatus()",
            "",
            "        if regresponse['code'] == 404:",
            "            return regresponse",
            "",
            "        cvresponse = self.do_cvstatus()",
            "",
            "        if not isinstance(cvresponse, dict):",
            "            logger.error(\"Unexpected response from Cloud Verifier %s on \"",
            "                         \"port %s. response %s\", self.verifier_ip,",
            "                         self.verifier_port, str(cvresponse))",
            "            return cvresponse",
            "",
            "        if regresponse['code'] == 200 and cvresponse['code'] == 200:",
            "            return cvresponse",
            "        if regresponse['code'] == 200 and cvresponse['code'] != 200:",
            "            return regresponse",
            "",
            "        logger.error(\"Unknown inconsistent state between registrar %s on \"",
            "                     \"port %s and verifier %s on port %s occured. Got \"",
            "                     \"registrar response %s verifier response %s\",",
            "                     self.verifier_ip, self.verifier_port, self.registrar_ip,",
            "                     self.registrar_port, str(regresponse), str(cvresponse))",
            "",
            "        return {'registrar': regresponse, 'verifier': cvresponse}",
            "",
            "    def do_cvreactivate(self, verifier_check=True):",
            "        \"\"\"Reactive Agent.\"\"\"",
            "        if verifier_check:",
            "            agent_json = self.do_cvstatus()",
            "            self.verifier_ip = agent_json['results'][self.agent_uuid]['verifier_ip']",
            "            self.verifier_port = agent_json['results'][self.agent_uuid]['verifier_port']",
            "",
            "        do_cvreactivate = RequestsClient(",
            "            self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvreactivate.put(",
            "            f'/v{self.api_version}/agents/{self.agent_uuid}/reactivate',",
            "            data=b'',",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            logger.info(\"Agent %s re-activated\", self.agent_uuid)",
            "            return response.json()",
            "",
            "        response_body = response.json()",
            "        keylime_logging.log_http_response(",
            "            logger, logging.ERROR, response_body)",
            "        logger.error(\"Update command response: %s Unexpected response from Cloud Verifier.\", response.status_code)",
            "        return response.json()",
            "",
            "    def do_cvstop(self):",
            "        \"\"\" Stop declared active agent",
            "        \"\"\"",
            "        params = f'/v{self.api_version}/agents/{self.agent_uuid}/stop'",
            "        do_cvstop = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvstop.put(",
            "            params,",
            "            cert=self.cert,",
            "            data=b'',",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        response_body = response.json()",
            "        if response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response_body)",
            "        else:",
            "            logger.info(\"Agent %s stopped\", self.agent_uuid)",
            "",
            "    def do_quote(self):",
            "        \"\"\" Perform TPM quote by GET towards Agent",
            "",
            "        Raises:",
            "            UserError: Connection handler",
            "        \"\"\"",
            "        self.nonce = TPM_Utilities.random_password(20)",
            "",
            "        numtries = 0",
            "        response = None",
            "        # Note: We need a specific retry handler (perhaps in common), no point having localised unless we have too.",
            "        while True:",
            "            try:",
            "                params = f'/v{self.supported_version}/quotes/identity?nonce=%s' % (self.nonce)",
            "                cloudagent_base_url = f'{self.agent_ip}:{self.agent_port}'",
            "",
            "                if self.registrar_data['mtls_cert']:",
            "                    with RequestsClient(cloudagent_base_url, tls_enabled=self.tls_agent_enabled, ignore_hostname=True, cert=self.agent_cert,",
            "                                        verify_custom=self.verify_custom) as do_quote:",
            "                        response = do_quote.get(params)",
            "                else:",
            "                    logger.warning(\"Connecting to agent without using mTLS!\")",
            "                    do_quote = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "                    response = do_quote.get(params)",
            "",
            "                print(response)",
            "                response_body = response.json()",
            "",
            "            except Exception as e:",
            "                if response.status_code in (503, 504):",
            "                    numtries += 1",
            "                    maxr = config.getint('tenant', 'max_retries')",
            "                    if numtries >= maxr:",
            "                        logger.error(\"Tenant cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)",
            "                        sys.exit()",
            "                    interval = config.getfloat('tenant', 'retry_interval')",
            "                    exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                    next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                    logger.info(\"Tenant connection to agent at %s refused %s/%s times, trying again in %s seconds...\",",
            "                        self.agent_ip, numtries, maxr, next_retry)",
            "                    time.sleep(next_retry)",
            "                    continue",
            "",
            "                raise e",
            "            break",
            "",
            "        if response is not None and response.status_code != 200:",
            "            raise UserError(",
            "               f\"Status command response: {response.status_code} Unexpected response from Cloud Agent.\")",
            "",
            "        if \"results\" not in response_body:",
            "            raise UserError(",
            "                f\"Error: unexpected http response body from Cloud Agent: {str(response.status)}\")",
            "",
            "        quote = response_body[\"results\"][\"quote\"]",
            "        logger.debug(\"Agent_quote received quote: %s\", quote)",
            "",
            "        public_key = response_body[\"results\"][\"pubkey\"]",
            "        logger.debug(\"Agent_quote received public key: %s\", public_key)",
            "",
            "        # Ensure hash_alg is in accept_tpm_hash_algs list",
            "        hash_alg = response_body[\"results\"][\"hash_alg\"]",
            "        logger.debug(\"Agent_quote received hash algorithm: %s\", hash_alg)",
            "        if not algorithms.is_accepted(hash_alg, config.get('tenant', 'accept_tpm_hash_algs').split(','))\\",
            "                or not algorithms.Hash.is_recognized(hash_alg):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\")",
            "",
            "        # Ensure enc_alg is in accept_tpm_encryption_algs list",
            "        enc_alg = response_body[\"results\"][\"enc_alg\"]",
            "        logger.debug(\"Agent_quote received encryption algorithm: %s\", enc_alg)",
            "        if not algorithms.is_accepted(enc_alg, config.get('tenant', 'accept_tpm_encryption_algs').split(',')):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\")",
            "",
            "        # Ensure sign_alg is in accept_tpm_encryption_algs list",
            "        sign_alg = response_body[\"results\"][\"sign_alg\"]",
            "        logger.debug(\"Agent_quote received signing algorithm: %s\", sign_alg)",
            "        if not algorithms.is_accepted(sign_alg, config.get('tenant', 'accept_tpm_signing_algs').split(',')):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\")",
            "",
            "        if not self.validate_tpm_quote(public_key, quote, algorithms.Hash(hash_alg)):",
            "            raise UserError(",
            "                f\"TPM Quote from cloud agent is invalid for nonce: {self.nonce}\")",
            "",
            "        logger.info(\"Quote from %s validated\", self.agent_ip)",
            "",
            "        # encrypt U with the public key",
            "        encrypted_U = crypto.rsa_encrypt(",
            "            crypto.rsa_import_pubkey(public_key), self.U)",
            "",
            "        b64_encrypted_u = base64.b64encode(encrypted_U)",
            "        logger.debug(\"b64_encrypted_u: %s\", b64_encrypted_u.decode('utf-8'))",
            "        data = {",
            "            'encrypted_key': b64_encrypted_u.decode('utf-8'),",
            "            'auth_tag': self.auth_tag",
            "        }",
            "",
            "        if self.payload is not None:",
            "            data['payload'] = self.payload.decode('utf-8')",
            "",
            "",
            "        # post encrypted U back to CloudAgent",
            "        params = f'/v{self.supported_version}/keys/ukey'",
            "        cloudagent_base_url = (",
            "            f'{self.agent_ip}:{self.agent_port}'",
            "        )",
            "",
            "        if self.registrar_data['mtls_cert']:",
            "            with RequestsClient(cloudagent_base_url, tls_enabled=self.tls_agent_enabled, ignore_hostname=True, cert=self.agent_cert,",
            "                                verify_custom=self.verify_custom) as post_ukey:",
            "                response = post_ukey.post(params, json=data)",
            "        else:",
            "            logger.warning(\"Connecting to agent without using mTLS!\")",
            "            post_ukey = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "            response = post_ukey.post(params, json=data)",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Agent at %s with Port %s. Connection refused.\", self.agent_ip, self.agent_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        if response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response_body)",
            "            raise UserError(",
            "                f\"Posting of Encrypted U to the Cloud Agent failed with response code {response.status_code} ({response.text})\")",
            "",
            "    def do_verify(self):",
            "        \"\"\" Perform verify using a random generated challenge",
            "        \"\"\"",
            "        challenge = TPM_Utilities.random_password(20)",
            "        numtries = 0",
            "",
            "        while True:",
            "            response = None",
            "            try:",
            "                cloudagent_base_url = (",
            "                    f'{self.agent_ip}:{self.agent_port}'",
            "                )",
            "",
            "                if self.registrar_data['mtls_cert']:",
            "                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True,",
            "                                        cert=self.agent_cert, verify_custom=self.registrar_data['mtls_cert']) as do_verify:",
            "                        response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')",
            "                else:",
            "                    logger.warning(\"Connecting to agent without using mTLS!\")",
            "                    do_verify = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "                    response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')",
            "",
            "                response_body = response.json()",
            "            except Exception as e:",
            "                if response is not None and response.status_code in (503, 504):",
            "                    numtries += 1",
            "                    maxr = config.getint('tenant', 'max_retries')",
            "                    if numtries >= maxr:",
            "                        logger.error(\"Cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)",
            "                        self.do_cvstop()",
            "                        sys.exit()",
            "                    interval = config.getfloat('tenant', 'retry_interval')",
            "                    exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                    next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                    logger.info(\"Verifier connection to agent at %s refused %s/%s times, trying again in %s seconds...\",",
            "                        self.agent_ip, numtries, maxr, next_retry)",
            "                    time.sleep(next_retry)",
            "                    continue",
            "                self.do_cvstop()",
            "                raise e",
            "            if response.status_code == 200:",
            "                if \"results\" not in response_body or 'hmac' not in response_body['results']:",
            "                    logger.critical(\"Error: unexpected http response body from Cloud Agent: %s\", response.status_code)",
            "                    self.do_cvstop()",
            "                    break",
            "                mac = response_body['results']['hmac']",
            "",
            "                ex_mac = crypto.do_hmac(self.K, challenge)",
            "",
            "                if mac == ex_mac:",
            "                    logger.info(\"Key derivation successful\")",
            "                else:",
            "                    logger.error(\"Key derivation failed\")",
            "                    self.do_cvstop()",
            "            else:",
            "                keylime_logging.log_http_response(",
            "                    logger, logging.ERROR, response_body)",
            "                numtries += 1",
            "                maxr = config.getint('tenant', 'max_retries')",
            "                if numtries >= maxr:",
            "                    logger.error(\"Agent on %s with port %s failed key derivation\", self.agent_ip, self.agent_port)",
            "                    self.do_cvstop()",
            "                    sys.exit()",
            "                interval = config.getfloat('tenant', 'retry_interval')",
            "                exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                logger.info(\"Key derivation not yet complete (retry %s/%s), trying again in %s seconds... (Ctrl-C to stop)\",",
            "                    numtries, maxr, next_retry)",
            "                time.sleep(next_retry)",
            "                continue",
            "            break",
            "",
            "    def do_add_allowlist(self, args):",
            "        if 'allowlist_name' not in args or not args['allowlist_name']:",
            "            raise UserError('allowlist_name is required to add an allowlist')",
            "",
            "        allowlist_name = args['allowlist_name']",
            "        self.process_allowlist(args)",
            "        data = {",
            "            'tpm_policy': json.dumps(self.tpm_policy),",
            "            'allowlist': json.dumps(self.allowlist)",
            "        }",
            "        body = json.dumps(data)",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.post(f'/v{self.api_version}/allowlists/{allowlist_name}', data=body,",
            "                                  cert=self.cert, verify=self.verifier_ca_cert)",
            "        Tenant._print_json_response(response)",
            "",
            "    def do_delete_allowlist(self, name):",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.delete(f'/v{self.api_version}/allowlists/{name}',",
            "                                    cert=self.cert, verify=self.verifier_ca_cert)",
            "        Tenant._print_json_response(response)",
            "",
            "    def do_show_allowlist(self, name):",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.get(f'/v{self.api_version}/allowlists/{name}',",
            "                                 cert=self.cert, verify=self.verifier_ca_cert)",
            "        print(f\"Show allowlist command response: {response.status_code}.\")",
            "        Tenant._print_json_response(response)",
            "",
            "    @staticmethod",
            "    def _print_json_response(response):",
            "        try:",
            "            json_response = response.json()",
            "        except ValueError:",
            "            json_response = '{}'",
            "        print(json_response)",
            "",
            "",
            "def write_to_namedtempfile(data, delete_tmp_files):",
            "    temp = tempfile.NamedTemporaryFile(prefix=\"keylime-\", delete=delete_tmp_files)  #pylint: disable=consider-using-with",
            "    temp.write(data)",
            "    temp.flush()",
            "    return temp.name",
            "",
            "def main(argv=sys.argv):  #pylint: disable=dangerous-default-value",
            "    \"\"\"[summary]",
            "",
            "    Keyword Arguments:",
            "        argv {[type]} -- [description] (default: {sys.argv})",
            "",
            "    Raises:",
            "        UserError: [description]",
            "        UserError: [description]",
            "        UserError: [description]",
            "    \"\"\"",
            "    parser = argparse.ArgumentParser(argv[0])",
            "    parser.add_argument('-c', '--command', action='store', dest='command', default='add',",
            "                        help=\"valid commands are add,delete,update,\"",
            "                             \"regstatus,cvstatus,status,reglist,cvlist,reactivate,\"",
            "                             \"regdelete,bulkinfo,addallowlist,showallowlist,deleteallowlist. defaults to add\")",
            "    parser.add_argument('-t', '--targethost', action='store',",
            "                        dest='agent_ip', help=\"the IP address of the host to provision\")",
            "    parser.add_argument('-tp', '--targetport', action='store',",
            "                        dest='agent_port', help=\"the Port of the host to provision\")",
            "    parser.add_argument('-r', '--registrarhost', action='store',",
            "                        dest='registrar_ip', help=\"the IP address of the registrar where to retrieve the agents data from.\")",
            "    parser.add_argument('-rp', '--registrarport', action=\"store\",",
            "                        dest='registrar_port', help=\"the port of the registrar.\")",
            "    parser.add_argument('--cv_targethost', action='store', default=None, dest='cv_agent_ip',",
            "                        help='the IP address of the host to provision that the verifier will use (optional).  Use only if different than argument to option -t/--targethost')",
            "    parser.add_argument('-v', '--cv', action='store', dest='verifier_ip',",
            "                        help=\"the IP address of the cloud verifier\")",
            "    parser.add_argument('-vp', '--cvport', action='store', dest='verifier_port',",
            "                        help=\"the port of the cloud verifier\")",
            "    parser.add_argument('-vi', '--cvid', action='store', dest='verifier_id',",
            "                        help=\"the unique identifier of a cloud verifier\")",
            "    parser.add_argument('-nvc', '--no-verifier-check', action='store_false', dest='verifier_check', default=True,",
            "                        help='Disable the check to confirm if the agent is being processed by the specified verifier. Use only with -c/--command delete or reactivate')",
            "    parser.add_argument('-u', '--uuid', action='store',",
            "                        dest='agent_uuid', help=\"UUID for the agent to provision\")",
            "    parser.add_argument('-f', '--file', action='store', default=None,",
            "                        help='Deliver the specified plaintext to the provisioned agent')",
            "    parser.add_argument('--cert', action='store', dest='ca_dir', default=None,",
            "                        help='Create and deliver a certificate using a CA created by ca-util. Pass in the CA directory or use \"default\" to use the standard dir')",
            "    parser.add_argument('-k', '--key', action='store', dest='keyfile',",
            "                        help='an intermedia key file produced by user_data_encrypt')",
            "    parser.add_argument('-p', '--payload', action='store', default=None,",
            "                        help='Specify the encrypted payload to deliver with encrypted keys specified by -k')",
            "    parser.add_argument('--include', action='store', dest='incl_dir', default=None,",
            "                        help=\"Include additional files in provided directory in certificate zip file.  Must be specified with --cert\")",
            "    parser.add_argument('--allowlist', action='store', dest='allowlist',",
            "                        default=None, help=\"Specify the file path of an allowlist\")",
            "    parser.add_argument('--signature-verification-key', '--sign_verification_key', action='append', dest='ima_sign_verification_keys',",
            "                        default=[], help=\"Specify an IMA file signature verification key\")",
            "    parser.add_argument('--signature-verification-key-sig', action='append', dest='ima_sign_verification_key_sigs',",
            "                        default=[], help=\"Specify the GPG signature file for an IMA file signature verification key; pair this option with --signature-verification-key\")",
            "    parser.add_argument('--signature-verification-key-sig-key', action='append', dest='ima_sign_verification_key_sig_keys',",
            "                        default=[], help=\"Specify the GPG public key file use to validate the --signature-verification-key-sig; pair this option with --signature-verification-key\")",
            "    parser.add_argument('--signature-verification-key-url', action='append', dest='ima_sign_verification_key_urls',",
            "                        default=[], help=\"Specify the URL for a remote IMA file signature verification key\")",
            "    parser.add_argument('--signature-verification-key-sig-url', action='append',",
            "                        dest='ima_sign_verification_key_sig_urls',",
            "                        default=[], help=\"Specify the URL for the remote GPG signature of a remote IMA file signature verification key; pair this option with --signature-verification-key-url\")",
            "    parser.add_argument('--signature-verification-key-sig-url-key', action='append',",
            "                        dest='ima_sign_verification_key_sig_url_keys',",
            "                        default=[], help=\"Specify the GPG public key file used to validate the --signature-verification-key-sig-url; pair this option with --signature-verification-key-url\")",
            "    parser.add_argument('--mb_refstate', action='store', dest='mb_refstate',",
            "                        default=None, help=\"Specify the location of a measure boot reference state (intended state)\")",
            "    parser.add_argument('--allowlist-checksum', action='store', dest='allowlist_checksum',",
            "                        default=None, help=\"Specify the SHA-256 checksum of an allowlist\")",
            "    parser.add_argument('--allowlist-sig', action='store', dest='allowlist_sig',",
            "                        default=None, help=\"Specify the GPG signature file of an allowlist\")",
            "    parser.add_argument('--allowlist-sig-key', action='store', dest='allowlist_sig_key',",
            "                        default=None, help=\"Specify the GPG public key file used to validate the --allowlist-sig or --allowlist-sig-url\")",
            "    parser.add_argument('--allowlist-url', action='store', dest='allowlist_url',",
            "                        default=None, help=\"Specify the URL of a remote allowlist\")",
            "    parser.add_argument('--allowlist-sig-url', action='store', dest='allowlist_sig_url',",
            "                        default=None, help=\"Specify the URL of the remote GPG signature file of an allowlist\")",
            "    parser.add_argument('--exclude', action='store', dest='ima_exclude',",
            "                        default=None, help=\"Specify the location of an IMA exclude list\")",
            "    parser.add_argument('--tpm_policy', action='store', dest='tpm_policy', default=None,",
            "                        help=\"Specify a TPM policy in JSON format. e.g., {\\\"15\\\":\\\"0000000000000000000000000000000000000000\\\"}\")",
            "    parser.add_argument('--verify', action='store_true', default=False,",
            "                        help='Block on cryptographically checked key derivation confirmation from the agent once it has been provisioned')",
            "    parser.add_argument('--allowlist-name', help='The name of allowlist to operate with')",
            "    parser.add_argument('--supported-version', default=None, action=\"store\", dest='supported_version', help='API version that is supported by the agent. Detected automatically by default')",
            "",
            "    args = parser.parse_args(argv[1:])",
            "",
            "    # Make sure argument dependencies are enforced",
            "    if( args.allowlist and args.allowlist_url):",
            "        parser.error(\"--allowlist and --allowlist-url cannot be specified at the same time\")",
            "    if( args.allowlist_url and not (args.allowlist_sig or args.allowlist_sig_url or args.allowlist_checksum)):",
            "        parser.error(\"--allowlist-url must have either --allowlist-sig, --allowlist-sig-url or --allowlist-checksum to verifier integrity\")",
            "    if( args.allowlist_sig and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-sig must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_sig_url and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-sig-url must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_checksum and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-checksum must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_sig and not args.allowlist_sig_key):",
            "        parser.error(\"--allowlist-sig must also have --allowlist-sig-key\")",
            "    if( args.allowlist_sig_url and not args.allowlist_sig_key):",
            "        parser.error(\"--allowlist-sig-url must also have --allowlist-sig-key\")",
            "    if( args.allowlist_sig_key and not (args.allowlist_sig or args.allowlist_sig_url)):",
            "        parser.error(\"--allowlist-sig-key must have either --allowlist-sig or --allowlist-sig-url\")",
            "",
            "    mytenant = Tenant()",
            "",
            "    if args.agent_uuid is not None:",
            "        mytenant.agent_uuid = args.agent_uuid",
            "        # if the uuid is actually a public key, then hash it",
            "        if mytenant.agent_uuid.startswith('-----BEGIN PUBLIC KEY-----'):",
            "            mytenant.agent_uuid = hashlib.sha256(",
            "                mytenant.agent_uuid).hexdigest()",
            "        if not validators.valid_agent_id(mytenant.agent_uuid):",
            "            raise UserError(\"The agent ID set via agent uuid parameter use invalid characters\")",
            "    else:",
            "        logger.warning(\"Using default UUID d432fbb3-d2f1-4a97-9ef7-75bd81c00000\")",
            "        mytenant.agent_uuid = \"d432fbb3-d2f1-4a97-9ef7-75bd81c00000\"",
            "",
            "    if args.verifier_id is not None:",
            "        mytenant.verifier_id = args.verifier_id",
            "    if args.verifier_ip is not None:",
            "        mytenant.verifier_ip = args.verifier_ip",
            "    if args.verifier_port is not None:",
            "        mytenant.verifier_port = args.verifier_port",
            "",
            "    if args.registrar_ip is not None:",
            "        mytenant.registrar_ip = args.registrar_ip",
            "    if args.registrar_port is not None:",
            "        mytenant.registrar_port = args.registrar_port",
            "",
            "    # we only need to fetch remote files if we are adding or updating",
            "    if args.command in ['add', 'update', 'addallowlist']:",
            "        delete_tmp_files = logger.level > logging.DEBUG # delete tmp files unless in DEBUG mode",
            "",
            "        if args.allowlist_url:",
            "            logger.info(\"Downloading Allowlist from %s\", args.allowlist_url)",
            "            response = requests.get(args.allowlist_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                args.allowlist = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Allowlist temporarily saved in %s\", args.allowlist)",
            "            else:",
            "                raise Exception(f\"Downloading allowlist ({args.allowlist_url}) failed with status code {response.status_code}!\")",
            "",
            "        if args.allowlist_sig_url:",
            "            logger.info(\"Downloading Allowlist signature from %s\", args.allowlist_sig_url)",
            "            response = requests.get(args.allowlist_sig_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                args.allowlist_sig = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Allowlist signature temporarily saved in %s\", args.allowlist_sig)",
            "            else:",
            "                raise Exception(f\"Downloading allowlist signature ({args.allowlist_sig_url}) failed with status code {response.status_code}!\")",
            "",
            "        # verify all the local keys for which we have a signature file and a key to verify",
            "        for i, key_file in enumerate(args.ima_sign_verification_keys):",
            "            if len(args.ima_sign_verification_key_sigs) <= i:",
            "                break",
            "            keysig_file = args.ima_sign_verification_key_sigs[i]",
            "            if len(args.ima_sign_verification_key_sig_keys) == 0:",
            "                raise UserError(f\"A gpg key is missing for key signature file '{keysig_file}'\")",
            "",
            "            gpg_key_file = args.ima_sign_verification_key_sig_keys[i]",
            "            signing.verify_signature_from_file(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")",
            "",
            "            logger.info(\"Signature verification on %s was successful\", key_file)",
            "",
            "        # verify all the remote keys for which we have a signature URL and key to to verify",
            "        # Append the downloaded key files to args.ima_sign_verification_keys",
            "        for i, key_url in enumerate(args.ima_sign_verification_key_urls):",
            "",
            "            logger.info(\"Downloading key from %s\", key_url)",
            "            response = requests.get(key_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                key_file = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                args.ima_sign_verification_keys.append(key_file)",
            "                logger.debug(\"Key temporarily saved in %s\", key_file)",
            "            else:",
            "                raise Exception(f\"Downloading key ({key_url}) failed with status code {response.status_code}!\")",
            "",
            "            if len(args.ima_sign_verification_key_sig_urls) <= i:",
            "                continue",
            "",
            "            keysig_url = args.ima_sign_verification_key_sig_urls[i]",
            "",
            "            if len(args.ima_sign_verification_key_sig_url_keys) == 0:",
            "                raise UserError(f\"A gpg key is missing for key signature URL '{keysig_url}'\")",
            "",
            "            logger.info(\"Downloading key signature from %s\", keysig_url)",
            "            response = requests.get(keysig_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                keysig_file = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Key signature temporarily saved in %s\", keysig_file)",
            "            else:",
            "                raise Exception(f\"Downloading key signature ({key_url}) failed with status code {response.status_code}!\")",
            "",
            "            gpg_key_file = args.ima_sign_verification_key_sig_url_keys[i]",
            "            signing.verify_signature_from_file(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")",
            "            logger.info(\"Signature verification on %s was successful\", key_url)",
            "",
            "    if args.command == 'add':",
            "        mytenant.init_add(vars(args))",
            "        mytenant.preloop()",
            "        mytenant.do_quote()",
            "        mytenant.do_cv()",
            "        if args.verify:",
            "            mytenant.do_verify()",
            "    elif args.command == 'update':",
            "        mytenant.init_add(vars(args))",
            "        mytenant.do_cvdelete(args.verifier_check)",
            "        mytenant.preloop()",
            "        mytenant.do_quote()",
            "        mytenant.do_cv()",
            "        if args.verify:",
            "            mytenant.do_verify()",
            "    elif args.command == 'delete':",
            "        mytenant.do_cvdelete(args.verifier_check)",
            "    elif args.command == 'status':",
            "        mytenant.do_status()",
            "    elif args.command == 'cvstatus':",
            "        mytenant.do_cvstatus()",
            "    elif args.command == 'bulkinfo':",
            "        mytenant.do_cvbulkinfo()",
            "    elif args.command == 'cvlist':",
            "        mytenant.do_cvlist()",
            "    elif args.command == 'reactivate':",
            "        mytenant.do_cvreactivate(args.verifier_check)",
            "    elif args.command == 'regstatus':",
            "        mytenant.do_regstatus()",
            "    elif args.command == 'reglist':",
            "        mytenant.do_reglist()",
            "    elif args.command == 'regdelete':",
            "        mytenant.do_regdelete()",
            "    elif args.command == 'addallowlist':",
            "        mytenant.do_add_allowlist(vars(args))",
            "    elif args.command == 'showallowlist':",
            "        mytenant.do_show_allowlist(args.allowlist_name)",
            "    elif args.command == 'deleteallowlist':",
            "        mytenant.do_delete_allowlist(args.allowlist_name)",
            "    else:",
            "        raise UserError(f\"Invalid command specified: {args.command}\")"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python3",
            "",
            "'''",
            "SPDX-License-Identifier: Apache-2.0",
            "Copyright 2017 Massachusetts Institute of Technology.",
            "'''",
            "",
            "import argparse",
            "import base64",
            "import hashlib",
            "import io",
            "import logging",
            "import os",
            "import subprocess",
            "import sys",
            "import time",
            "import zipfile",
            "import json",
            "import tempfile",
            "import requests",
            "",
            "from cryptography.hazmat.primitives import serialization as crypto_serialization",
            "",
            "from keylime.agentstates import AgentAttestState",
            "from keylime.requests_client import RequestsClient",
            "from keylime.common import states, retry",
            "from keylime import config",
            "from keylime import keylime_logging",
            "from keylime import registrar_client",
            "from keylime.tpm import tpm2_objects",
            "from keylime.tpm.tpm_main import tpm",
            "from keylime.tpm.tpm_abstract import TPM_Utilities",
            "from keylime import crypto",
            "from keylime.cmd import user_data_encrypt",
            "from keylime import ca_util",
            "from keylime.common import algorithms, validators",
            "from keylime.ima import ima, file_signatures",
            "from keylime import measured_boot",
            "from keylime import signing",
            "from keylime import api_version as keylime_api_version",
            "",
            "# setup logging",
            "logger = keylime_logging.init_logging('tenant')",
            "",
            "# special exception that suppresses stack traces when it happens",
            "class UserError(Exception):",
            "    pass",
            "",
            "",
            "class Tenant():",
            "    \"\"\"Simple command processor example.\"\"\"",
            "",
            "    config = None",
            "",
            "    cloudverifier_ip = None",
            "    cloudverifier_port = None",
            "",
            "    cloudagent_ip = None",
            "    cv_cloudagent_ip = None",
            "    cloudagent_port = None",
            "",
            "    registrar_ip = None",
            "    registrar_port = None",
            "    registrar_data = None",
            "",
            "    webapp_ip = None",
            "    webapp_port = None",
            "",
            "    api_version = None",
            "",
            "    uuid_service_generate_locally = None",
            "    agent_uuid = None",
            "",
            "    K = None",
            "    V = None",
            "    U = None",
            "    auth_tag = None",
            "",
            "    tpm_policy = None",
            "    metadata = {}",
            "    allowlist = {}",
            "    ima_sign_verification_keys = []",
            "    revocation_key = \"\"",
            "    accept_tpm_hash_algs = []",
            "    accept_tpm_encryption_algs = []",
            "    accept_tpm_signing_algs = []",
            "    mb_refstate = None",
            "    supported_version = None",
            "",
            "    payload = None",
            "",
            "    tpm_instance = tpm()",
            "",
            "    def __init__(self):",
            "        \"\"\" Set up required values and TLS",
            "        \"\"\"",
            "        self.nonce = None",
            "        self.agent_ip = None",
            "        self.verifier_id = None",
            "        self.agent_port = None",
            "        self.verifier_ip = config.get('tenant', 'cloudverifier_ip')",
            "        self.verifier_port = config.get('tenant', 'cloudverifier_port')",
            "        self.registrar_ip = config.get('tenant', 'registrar_ip')",
            "        self.registrar_port = config.get('tenant', 'registrar_port')",
            "        self.webapp_port = config.getint('webapp', 'webapp_port')",
            "        self.webapp_ip = config.get('webapp', 'webapp_ip')",
            "",
            "        self.api_version = keylime_api_version.current_version()",
            "",
            "        (self.my_cert, self.my_priv_key), (self.my_agent_cert, self.my_agent_priv_key), self.verifier_ca_cert = Tenant.get_tls_context()",
            "        self.cert = (self.my_cert, self.my_priv_key)",
            "        self.agent_cert = (self.my_agent_cert, self.my_agent_priv_key)",
            "        if config.getboolean('general', \"enable_tls\"):",
            "            self.tls_cv_enabled = True",
            "        else:",
            "            self.tls_cv_enabled = False",
            "            self.cert = \"\"",
            "            logger.warning(",
            "                \"Warning: TLS is currently disabled, keys will be sent in the clear! This should only be used for testing.\")",
            "        self.tls_agent_enabled = True",
            "        self.verify_custom = None",
            "",
            "    @property",
            "    def verifier_base_url(self):",
            "        return f'{self.verifier_ip}:{self.verifier_port}'",
            "",
            "    @staticmethod",
            "    def get_tls_context():",
            "        \"\"\"Generate certifcate naming and path",
            "",
            "        Returns:",
            "            string -- my_cert (client_cert), my_priv_key (client private key)",
            "        \"\"\"",
            "        verifier_ca_cert = config.get('tenant', 'ca_cert')",
            "        my_cert = config.get('tenant', 'my_cert')",
            "        my_priv_key = config.get('tenant', 'private_key')",
            "        tls_dir = config.get('tenant', 'tls_dir')",
            "",
            "        if tls_dir == 'default':",
            "            verifier_ca_cert = 'cacert.crt'",
            "            my_cert = 'client-cert.crt'",
            "            my_priv_key = 'client-private.pem'",
            "            tls_dir = 'cv_ca'",
            "",
            "        if tls_dir[0] != '/':",
            "            tls_dir = os.path.abspath(os.path.join(config.WORK_DIR, tls_dir))",
            "",
            "        logger.info(\"Setting up client TLS in %s\", tls_dir)",
            "        verifier_ca_cert = os.path.join(tls_dir, verifier_ca_cert)",
            "        my_cert = os.path.join(tls_dir, my_cert)",
            "        my_priv_key = os.path.join(tls_dir, my_priv_key)",
            "",
            "        tls_context = (my_cert, my_priv_key)",
            "",
            "        agent_mtls_context = (None, None)",
            "        # Check for user defined CA to connect to agent",
            "        agent_mtls_cert_enabled = config.getboolean('tenant', 'agent_mtls_cert_enabled', fallback=False)",
            "",
            "        if agent_mtls_cert_enabled:",
            "            agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)",
            "            agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)",
            "            agent_mtls_context = tls_context",
            "            if agent_mtls_cert != \"CV\":",
            "                agent_mtls_context = (agent_mtls_cert, agent_mtls_private_key)",
            "",
            "        return tls_context, agent_mtls_context, verifier_ca_cert",
            "",
            "    def process_allowlist(self, args):",
            "        # Set up PCR values",
            "        tpm_policy = config.get('tenant', 'tpm_policy')",
            "        if \"tpm_policy\" in args and args[\"tpm_policy\"] is not None:",
            "            tpm_policy = args[\"tpm_policy\"]",
            "        self.tpm_policy = TPM_Utilities.readPolicy(tpm_policy)",
            "        logger.info(\"TPM PCR Mask from policy is %s\", self.tpm_policy['mask'])",
            "",
            "        if len(args.get(\"ima_sign_verification_keys\")) > 0:",
            "            # Auto-enable IMA (or-bit mask)",
            "            self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))",
            "",
            "            # Add all IMA file signing verification keys to a keyring",
            "            tenant_keyring = file_signatures.ImaKeyring()",
            "            for filename in args[\"ima_sign_verification_keys\"]:",
            "                pubkey, keyidv2 = file_signatures.get_pubkey_from_file(filename)",
            "                if not pubkey:",
            "                    raise UserError(f\"File '{filename}' is not a file with a key\")",
            "                tenant_keyring.add_pubkey(pubkey, keyidv2)",
            "            self.ima_sign_verification_keys = tenant_keyring.to_string()",
            "",
            "        # Read command-line path string allowlist",
            "        al_data = None",
            "",
            "        if \"allowlist\" in args and args[\"allowlist\"] is not None:",
            "",
            "            self.enforce_pcrs(list(self.tpm_policy.keys()), [ config.IMA_PCR ], \"IMA\")",
            "",
            "            # Auto-enable IMA (or-bit mask)",
            "            self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))",
            "",
            "            if isinstance(args[\"allowlist\"], str):",
            "                if args[\"allowlist\"] == \"default\":",
            "                    args[\"allowlist\"] = config.get('tenant', 'allowlist')",
            "                try:",
            "                    al_data = ima.read_allowlist(args[\"allowlist\"], args[\"allowlist_checksum\"], args[\"allowlist_sig\"], args[\"allowlist_sig_key\"])",
            "                except Exception as ima_e:",
            "                    raise UserError(str(ima_e)) from ima_e",
            "            elif isinstance(args[\"allowlist\"], list):",
            "                al_data = args[\"allowlist\"]",
            "            else:",
            "                raise UserError(\"Invalid allowlist provided\")",
            "",
            "        # Read command-line path string IMA exclude list",
            "        excl_data = None",
            "        if \"ima_exclude\" in args and args[\"ima_exclude\"] is not None:",
            "            if isinstance(args[\"ima_exclude\"], str):",
            "                if args[\"ima_exclude\"] == \"default\":",
            "                    args[\"ima_exclude\"] = config.get(",
            "                        'tenant', 'ima_excludelist')",
            "                excl_data = ima.read_excllist(args[\"ima_exclude\"])",
            "            elif isinstance(args[\"ima_exclude\"], list):",
            "                excl_data = args[\"ima_exclude\"]",
            "            else:",
            "                raise UserError(\"Invalid exclude list provided\")",
            "",
            "        # Set up IMA",
            "        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.IMA_PCR):",
            "            # Process allowlists",
            "            self.allowlist = ima.process_allowlists(al_data, excl_data)",
            "",
            "        # Read command-line path string TPM event log (measured boot) reference state",
            "        mb_refstate_data = None",
            "        if \"mb_refstate\" in args and args[\"mb_refstate\"] is not None:",
            "",
            "            self.enforce_pcrs(list(self.tpm_policy.keys()), config.MEASUREDBOOT_PCRS, \"measured boot\")",
            "",
            "            # Auto-enable TPM event log mesured boot (or-bit mask)",
            "            for _pcr in config.MEASUREDBOOT_PCRS:",
            "                self.tpm_policy['mask'] = hex(int(self.tpm_policy['mask'], 0) | (1 << _pcr))",
            "",
            "            logger.info(\"TPM PCR Mask automatically modified is %s to include IMA/Event log PCRs\", self.tpm_policy['mask'])",
            "",
            "            if isinstance(args[\"mb_refstate\"], str):",
            "                if args[\"mb_refstate\"] == \"default\":",
            "                    args[\"mb_refstate\"] = config.get('tenant', 'mb_refstate')",
            "                mb_refstate_data = measured_boot.read_mb_refstate(args[\"mb_refstate\"])",
            "            else:",
            "                raise UserError(\"Invalid measured boot reference state (intended state) provided\")",
            "",
            "        # Set up measured boot (TPM event log) reference state",
            "        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.MEASUREDBOOT_PCRS[2]) :",
            "            # Process measured boot reference state",
            "            self.mb_refstate = mb_refstate_data",
            "",
            "    def init_add(self, args):",
            "        \"\"\" Set up required values. Command line options can overwrite these config values",
            "",
            "        Arguments:",
            "            args {[string]} -- agent_ip|agent_port|cv_agent_ip",
            "        \"\"\"",
            "        if \"agent_ip\" in args:",
            "            self.agent_ip = args[\"agent_ip\"]",
            "",
            "        if 'agent_port' in args and args['agent_port'] is not None:",
            "            self.agent_port = args['agent_port']",
            "",
            "        registrar_client.init_client_tls(\"tenant\")",
            "        self.registrar_data = registrar_client.getData(self.registrar_ip, self.registrar_port, self.agent_uuid)",
            "",
            "        if self.registrar_data is None:",
            "            raise UserError(f\"Agent ${self.agent_uuid} data not found in the Registrar.\")",
            "",
            "        # try to get the port or ip from the registrar if it is missing",
            "        if (self.agent_ip is None or self.agent_port is None) and self.registrar_data is not None:",
            "            if self.agent_ip is None:",
            "                if self.registrar_data['ip'] is not None:",
            "                    self.agent_ip = self.registrar_data['ip']",
            "                else:",
            "                    raise UserError(\"No Ip was specified or found in the Registrar\")",
            "",
            "            if self.agent_port is None and self.registrar_data['port'] is not None:",
            "                self.agent_port = self.registrar_data[\"port\"]",
            "",
            "        # If no agent port was found try to use the default from the config file",
            "        if self.agent_port is None:",
            "            self.agent_port = config.get('cloud_agent', 'cloudagent_port')",
            "",
            "        # Check if a contact ip and port for the agent was found",
            "        if self.agent_ip is None:",
            "            raise UserError(\"The contact ip address for the agent was not specified.\")",
            "",
            "        if self.agent_port is None:",
            "            raise UserError(\"The contact port for the agent was not specified.\")",
            "",
            "        # Auto-detection for API version",
            "        self.supported_version = args[\"supported_version\"]",
            "        if self.supported_version is None:",
            "            # Default to 1.0 if the agent did not send a mTLS certificate",
            "            if self.registrar_data.get(\"mtls_cert\", None) is None:",
            "                self.supported_version = \"1.0\"",
            "            else:",
            "                # Try to connect to the agent to get supported version",
            "                if self.registrar_data['mtls_cert'] == \"disabled\":",
            "                    self.tls_agent_enabled = False",
            "                    self.verify_custom = False",
            "                    logger.warning(",
            "                        \"Warning: mTLS for agents is disabled: the identity of each node will be based on the properties of the TPM only. \"",
            "                        \"Unless you have strict control of your network, it is strongly advised that remote code execution should be disabled, \"",
            "                        \"by setting \\\"payload_script=\\\" and \\\"extract_payload_zip=False\\\" under \\\"[cloud_agent]\\\"\")",
            "                else:",
            "                    self.verify_custom = self.registrar_data['mtls_cert']",
            "",
            "                with RequestsClient(f\"{self.agent_ip}:{self.agent_port}\", tls_enabled=self.tls_agent_enabled, cert=self.agent_cert,",
            "                                    ignore_hostname=True, verify_custom=self.verify_custom) as get_version:",
            "                    res = get_version.get(\"/version\")",
            "                    if res and res.status_code == 200:",
            "                        try:",
            "                            data = res.json()",
            "                            api_version = data[\"results\"][\"supported_version\"]",
            "                            if keylime_api_version.validate_version(api_version):",
            "                                self.supported_version = api_version",
            "                            else:",
            "                                logger.warning(\"API version provided by the agent is not valid\")",
            "                        except (TypeError, KeyError):",
            "                            pass",
            "",
            "        if self.supported_version is None:",
            "            api_version = keylime_api_version.current_version()",
            "            logger.warning(\"Could not detect supported API version. Defaulting to %s\", api_version)",
            "            self.supported_version = api_version",
            "",
            "        # Now set the cv_agent_ip",
            "        if 'cv_agent_ip' in args and args['cv_agent_ip'] is not None:",
            "            self.cv_cloudagent_ip = args['cv_agent_ip']",
            "        else:",
            "            self.cv_cloudagent_ip = self.agent_ip",
            "",
            "        # Make sure all keys exist in dictionary",
            "        if \"file\" not in args:",
            "            args[\"file\"] = None",
            "        if \"keyfile\" not in args:",
            "            args[\"keyfile\"] = None",
            "        if \"payload\" not in args:",
            "            args[\"payload\"] = None",
            "        if \"ca_dir\" not in args:",
            "            args[\"ca_dir\"] = None",
            "        if \"incl_dir\" not in args:",
            "            args[\"incl_dir\"] = None",
            "        if \"ca_dir_pw\" not in args:",
            "            args[\"ca_dir_pw\"] = None",
            "",
            "        # Set up accepted algorithms",
            "        self.accept_tpm_hash_algs = config.get(",
            "            'tenant', 'accept_tpm_hash_algs').split(',')",
            "        self.accept_tpm_encryption_algs = config.get(",
            "            'tenant', 'accept_tpm_encryption_algs').split(',')",
            "        self.accept_tpm_signing_algs = config.get(",
            "            'tenant', 'accept_tpm_signing_algs').split(',')",
            "",
            "        self.process_allowlist(args)",
            "",
            "        # if none",
            "        if (args[\"file\"] is None and args[\"keyfile\"] is None and args[\"ca_dir\"] is None):",
            "            raise UserError(",
            "                \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "        if args[\"keyfile\"] is not None:",
            "            if args[\"file\"] is not None or args[\"ca_dir\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "            # read the keys in",
            "            if isinstance(args[\"keyfile\"], dict) and \"data\" in args[\"keyfile\"]:",
            "                if isinstance(args[\"keyfile\"][\"data\"], list) and len(args[\"keyfile\"][\"data\"]) == 1:",
            "                    keyfile = args[\"keyfile\"][\"data\"][0]",
            "                    if keyfile is None:",
            "                        raise UserError(\"Invalid key file contents\")",
            "                    f = io.StringIO(keyfile)",
            "                else:",
            "                    raise UserError(\"Invalid key file provided\")",
            "            else:",
            "                f = open(args[\"keyfile\"], encoding=\"utf-8\")  #pylint: disable=consider-using-with",
            "            self.K = base64.b64decode(f.readline())",
            "            self.U = base64.b64decode(f.readline())",
            "            self.V = base64.b64decode(f.readline())",
            "            f.close()",
            "",
            "            # read the payload in (opt.)",
            "            if isinstance(args[\"payload\"], dict) and \"data\" in args[\"payload\"]:",
            "                if isinstance(args[\"payload\"][\"data\"], list) and len(args[\"payload\"][\"data\"]) > 0:",
            "                    self.payload = args[\"payload\"][\"data\"][0]",
            "            else:",
            "                if args[\"payload\"] is not None:",
            "                    with open(args[\"payload\"], 'rb') as f:",
            "                        self.payload = f.read()",
            "",
            "        if args[\"file\"] is not None:",
            "            if args[\"keyfile\"] is not None or args[\"ca_dir\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "",
            "            if isinstance(args[\"file\"], dict) and \"data\" in args[\"file\"]:",
            "                if isinstance(args[\"file\"][\"data\"], list) and len(args[\"file\"][\"data\"]) > 0:",
            "                    contents = args[\"file\"][\"data\"][0]",
            "                    if contents is None:",
            "                        raise UserError(\"Invalid file payload contents\")",
            "                else:",
            "                    raise UserError(\"Invalid file payload provided\")",
            "            else:",
            "                with open(args[\"file\"], encoding=\"utf-8\") as f:",
            "                    contents = f.read()",
            "            ret = user_data_encrypt.encrypt(contents)",
            "            self.K = ret['k']",
            "            self.U = ret['u']",
            "            self.V = ret['v']",
            "            self.payload = ret['ciphertext']",
            "",
            "        if args[\"ca_dir\"] is None and args[\"incl_dir\"] is not None:",
            "            raise UserError(",
            "                \"--include option is only valid when used with --cert\")",
            "        if args[\"ca_dir\"] is not None:",
            "            if args[\"file\"] is not None or args[\"keyfile\"] is not None:",
            "                raise UserError(",
            "                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")",
            "            if args[\"ca_dir\"] == 'default':",
            "                args[\"ca_dir\"] = config.CA_WORK_DIR",
            "",
            "            if \"ca_dir_pw\" in args and args[\"ca_dir_pw\"] is not None:",
            "                ca_util.setpassword(args[\"ca_dir_pw\"])",
            "",
            "            if not os.path.exists(args[\"ca_dir\"]) or not os.path.exists(os.path.join(args[\"ca_dir\"], \"cacert.crt\")):",
            "                logger.warning(\"CA directory does not exist. Creating...\")",
            "                ca_util.cmd_init(args[\"ca_dir\"])",
            "            if not os.path.exists(",
            "                    os.path.join(args[\"ca_dir\"],",
            "                                 f\"{self.agent_uuid}-private.pem\")):",
            "                ca_util.cmd_mkcert(args[\"ca_dir\"], self.agent_uuid)",
            "",
            "            cert_pkg, serial, subject = ca_util.cmd_certpkg(",
            "                args[\"ca_dir\"], self.agent_uuid)",
            "",
            "            # support revocation",
            "            if not os.path.exists(os.path.join(args[\"ca_dir\"], \"RevocationNotifier-private.pem\")):",
            "                ca_util.cmd_mkcert(args[\"ca_dir\"], \"RevocationNotifier\")",
            "            rev_package, _, _ = ca_util.cmd_certpkg(",
            "                args[\"ca_dir\"], \"RevocationNotifier\")",
            "",
            "            # extract public and private keys from package",
            "            sf = io.BytesIO(rev_package)",
            "            with zipfile.ZipFile(sf) as zf:",
            "                privkey = zf.read(\"RevocationNotifier-private.pem\")",
            "                cert = zf.read(\"RevocationNotifier-cert.crt\")",
            "",
            "            # put the cert of the revoker into the cert package",
            "            sf = io.BytesIO(cert_pkg)",
            "            with zipfile.ZipFile(sf, 'a', compression=zipfile.ZIP_STORED) as zf:",
            "                zf.writestr('RevocationNotifier-cert.crt', cert)",
            "",
            "                # add additional files to zip",
            "                if args[\"incl_dir\"] is not None:",
            "                    if isinstance(args[\"incl_dir\"], dict) and \"data\" in args[\"incl_dir\"] and \"name\" in args[\"incl_dir\"]:",
            "                        if isinstance(args[\"incl_dir\"][\"data\"], list) and isinstance(args[\"incl_dir\"][\"name\"], list):",
            "                            if len(args[\"incl_dir\"][\"data\"]) != len(args[\"incl_dir\"][\"name\"]):",
            "                                raise UserError(\"Invalid incl_dir provided\")",
            "                            for i in range(len(args[\"incl_dir\"][\"data\"])):",
            "                                zf.writestr(os.path.basename(",
            "                                    args[\"incl_dir\"][\"name\"][i]), args[\"incl_dir\"][\"data\"][i])",
            "                    else:",
            "                        if os.path.exists(args[\"incl_dir\"]):",
            "                            files = next(os.walk(args[\"incl_dir\"]))[2]",
            "                            for filename in files:",
            "                                with open(os.path.join(args[\"incl_dir\"],",
            "                                                       filename), 'rb') as f:",
            "                                    zf.writestr(",
            "                                        os.path.basename(f.name), f.read())",
            "                        else:",
            "                            logger.warning('Specified include directory %s does not exist. Skipping...', args[\"incl_dir\"])",
            "",
            "            cert_pkg = sf.getvalue()",
            "",
            "            # put the private key into the data to be send to the CV",
            "            self.revocation_key = privkey.decode('utf-8')",
            "",
            "            # encrypt up the cert package",
            "            ret = user_data_encrypt.encrypt(cert_pkg)",
            "            self.K = ret['k']",
            "            self.U = ret['u']",
            "            self.V = ret['v']",
            "            self.metadata = {'cert_serial': serial, 'subject': subject}",
            "            self.payload = ret['ciphertext']",
            "",
            "        if self.payload is not None and len(self.payload) > config.getint('tenant', 'max_payload_size'):",
            "            raise UserError(f\"Payload size {len(self.payload)} exceeds max size {config.getint('tenant', 'max_payload_size')}\")",
            "",
            "    def enforce_pcrs(self, policy_pcrs, protected_pcrs, pcr_use) :",
            "        policy_pcrs = list(self.tpm_policy.keys())",
            "        policy_pcrs.remove('mask')",
            "",
            "        for _pcr in policy_pcrs :",
            "            if int(_pcr) in protected_pcrs :",
            "                logger.error('WARNING: PCR %s is specified in \"tpm_policy\", but will in fact be used by %s. Please remove it from policy', _pcr, pcr_use)",
            "                sys.exit(1)",
            "",
            "    def preloop(self):",
            "        \"\"\" encrypt the agent UUID as a check for delivering the correct key",
            "        \"\"\"",
            "        self.auth_tag = crypto.do_hmac(self.K, self.agent_uuid)",
            "        # be very careful printing K, U, or V as they leak in logs stored on unprotected disks",
            "        if config.INSECURE_DEBUG:",
            "            logger.debug(\"K: %s\", base64.b64encode(self.K))",
            "            logger.debug(\"V: %s\", base64.b64encode(self.V))",
            "            logger.debug(\"U: %s\", base64.b64encode(self.U))",
            "            logger.debug(\"Auth Tag: %s\", self.auth_tag)",
            "",
            "    def check_ek(self, ekcert):",
            "        \"\"\" Check the Entity Key",
            "",
            "        Arguments:",
            "            ekcert {str} -- The endorsement key, either None, \"emulator\", or base64 encoded der cert",
            "",
            "        Returns:",
            "            [type] -- [description]",
            "        \"\"\"",
            "        if config.getboolean('tenant', 'require_ek_cert'):",
            "            if ekcert == 'emulator' and config.DISABLE_EK_CERT_CHECK_EMULATOR:",
            "                logger.info(\"Not checking ekcert of TPM emulator\")",
            "            elif ekcert is None:",
            "                logger.warning(\"No EK cert provided, require_ek_cert option in config set to True\")",
            "                return False",
            "            elif not self.tpm_instance.verify_ek(base64.b64decode(ekcert)):",
            "                logger.warning(\"Invalid EK certificate\")",
            "                return False",
            "",
            "        return True",
            "",
            "    def validate_tpm_quote(self, public_key, quote, hash_alg):",
            "        \"\"\" Validate TPM Quote received from the Agent",
            "",
            "        Arguments:",
            "            public_key {[type]} -- [description]",
            "            quote {[type]} -- [description]",
            "            hash_alg {bool} -- [description]",
            "",
            "        Raises:",
            "            UserError: [description]",
            "",
            "        Returns:",
            "            [type] -- [description]",
            "        \"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        if self.registrar_data is None:",
            "            logger.warning(\"AIK not found in registrar, quote not validated\")",
            "            return False",
            "",
            "        failure = self.tpm_instance.check_quote(AgentAttestState(self.agent_uuid), self.nonce, public_key, quote,",
            "                                                self.registrar_data['aik_tpm'], hash_alg=hash_alg,",
            "                                                compressed=(self.supported_version == \"1.0\"))",
            "        if failure:",
            "            if self.registrar_data['regcount'] > 1:",
            "                logger.error(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured or a malicious host is present. Run 'regdelete' for this agent and restart\")",
            "                sys.exit()",
            "            return False",
            "",
            "        if self.registrar_data['regcount'] > 1:",
            "            logger.warning(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured. Run 'regdelete' for this agent and restart\")",
            "",
            "        if not config.getboolean('tenant', 'require_ek_cert') and config.get('tenant', 'ek_check_script') == \"\":",
            "            logger.warning(",
            "                \"DANGER: EK cert checking is disabled and no additional checks on EKs have been specified with ek_check_script option. Keylime is not secure!!\")",
            "",
            "        # check EK cert and make sure it matches EK",
            "        if not self.check_ek(self.registrar_data['ekcert']):",
            "            return False",
            "        # if agent is virtual, check phyisical EK cert and make sure it matches phyiscal EK",
            "        if 'provider_keys' in self.registrar_data:",
            "            if not self.check_ek(self.registrar_data['provider_keys']['ekcert']):",
            "                return False",
            "",
            "        # check all EKs with optional script:",
            "        script = config.get('tenant', 'ek_check_script')",
            "        if not script:",
            "            return True",
            "",
            "        if script[0] != '/':",
            "            script = os.path.join(config.WORK_DIR, script)",
            "",
            "        logger.info(\"Checking EK with script %s\", script)",
            "        # now we need to exec the script with the ek and ek cert in vars",
            "        env = os.environ.copy()",
            "        env['AGENT_UUID'] = self.agent_uuid",
            "        env['EK'] = tpm2_objects.pubkey_from_tpm2b_public(",
            "            base64.b64decode(self.registrar_data['ek_tpm']),",
            "            ).public_bytes(",
            "                crypto_serialization.Encoding.PEM,",
            "                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,",
            "            )",
            "        env['EK_TPM'] = self.registrar_data['ek_tpm']",
            "        if self.registrar_data['ekcert'] is not None:",
            "            env['EK_CERT'] = self.registrar_data['ekcert']",
            "        else:",
            "            env['EK_CERT'] = \"\"",
            "",
            "        env['PROVKEYS'] = json.dumps(self.registrar_data.get('provider_keys', {}))",
            "        with subprocess.Popen(script, env=env, shell=True,",
            "                              cwd=config.WORK_DIR, stdout=subprocess.PIPE,",
            "                              stderr=subprocess.STDOUT) as proc:",
            "            retval = proc.wait()",
            "            if retval != 0:",
            "                raise UserError(\"External check script failed to validate EK\")",
            "            logger.debug(\"External check script successfully to validated EK\")",
            "            while True:",
            "                line = proc.stdout.readline().decode()",
            "                if line == \"\":",
            "                    break",
            "                logger.debug(\"ek_check output: %s\", line.strip())",
            "        return True",
            "",
            "    def do_cv(self):",
            "        \"\"\" Initiaite v, agent_id and ip and initiate the cloudinit sequence",
            "        \"\"\"",
            "        b64_v = base64.b64encode(self.V).decode('utf-8')",
            "        logger.debug(\"b64_v: %s\", b64_v)",
            "        data = {",
            "            'v': b64_v,",
            "            'cloudagent_ip': self.cv_cloudagent_ip,",
            "            'cloudagent_port': self.agent_port,",
            "            'tpm_policy': json.dumps(self.tpm_policy),",
            "            'allowlist': json.dumps(self.allowlist),",
            "            'mb_refstate': json.dumps(self.mb_refstate),",
            "            'ima_sign_verification_keys': json.dumps(self.ima_sign_verification_keys),",
            "            'metadata': json.dumps(self.metadata),",
            "            'revocation_key': self.revocation_key,",
            "            'accept_tpm_hash_algs': self.accept_tpm_hash_algs,",
            "            'accept_tpm_encryption_algs': self.accept_tpm_encryption_algs,",
            "            'accept_tpm_signing_algs': self.accept_tpm_signing_algs,",
            "            'ak_tpm': self.registrar_data['aik_tpm'],",
            "            'mtls_cert': self.registrar_data.get('mtls_cert', None),",
            "            'supported_version': self.supported_version,",
            "        }",
            "        json_message = json.dumps(data)",
            "        do_cv = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cv.post(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            data=json_message,",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        if response.status_code == 409:",
            "            # this is a conflict, need to update or delete it",
            "            logger.error(\"Agent %s already existed at CV. Please use delete or update.\", self.agent_uuid)",
            "            sys.exit()",
            "        elif response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response.json())",
            "            logger.error(\"POST command response: %s Unexpected response from Cloud Verifier: %s\", response.status_code, response.text)",
            "            sys.exit()",
            "",
            "    def do_cvstatus(self):",
            "        \"\"\"Perform operational state look up for agent on the verifier\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            res = response.pop('results')",
            "            response['results'] = {self.agent_uuid: res}",
            "",
            "            operational_state = states.state_to_str(",
            "                response['results'][self.agent_uuid]['operational_state'])",
            "            response['results'][self.agent_uuid]['operational_state'] = operational_state",
            "",
            "            logger.info(\"Agent Info:\\n%s\", json.dumps(response[\"results\"]))",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvlist(self):",
            "        \"\"\"List all agent statuses in cloudverifier\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        verifier_id = \"\"",
            "        if self.verifier_id is not None:",
            "            verifier_id = self.verifier_id",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/?verifier={verifier_id}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            logger.info('From verifier %s port %s retrieved: \"%s\"',",
            "                        self.verifier_ip, self.verifier_port, response)",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvbulkinfo(self):",
            "        \"\"\"Perform operational state look up for agent\"\"\"",
            "",
            "        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "",
            "        verifier_id = \"\"",
            "        if self.verifier_id is not None:",
            "            verifier_id = self.verifier_id",
            "        response = do_cvstatus.get(",
            "            (f'/v{self.api_version}/agents/?bulk={True}&verifier={verifier_id}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 404:",
            "            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",",
            "                        self.verifier_ip, self.verifier_port, self.agent_uuid)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            response = response.json()",
            "",
            "            for agent in response[\"results\"].keys():",
            "                response[\"results\"][agent][\"operational_state\"] = \\",
            "                    states.state_to_str(response[\"results\"][agent][",
            "                                            \"operational_state\"])",
            "            logger.info(\"Bulk Agent Info:\\n%s\", json.dumps(response[\"results\"]))",
            "",
            "            return response",
            "",
            "        logger.info(\"Status command response: %s. Unexpected response \"",
            "                    \"from Cloud Verifier %s on port %s. %s\",",
            "                    response.status_code,",
            "                    self.verifier_ip, self.verifier_port, str(response))",
            "        return response",
            "",
            "    def do_cvdelete(self, verifier_check=True):",
            "        \"\"\"Delete agent from Verifier.\"\"\"",
            "        if verifier_check:",
            "            cvresponse = self.do_cvstatus()",
            "",
            "            if not isinstance(cvresponse, dict):",
            "                return cvresponse",
            "",
            "            if cvresponse['code'] != 200:",
            "                logger.error(\"Could not get status of agent %s from \"",
            "                             \"verifier %s.\", self.agent_uuid, self.verifier_ip)",
            "                return cvresponse",
            "",
            "            self.verifier_ip = cvresponse['results'][self.agent_uuid][\"verifier_ip\"]",
            "            self.verifier_port = cvresponse['results'][self.agent_uuid][\"verifier_port\"]",
            "",
            "        do_cvdelete = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvdelete.delete(",
            "            (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        response = response.json()",
            "",
            "        if response['code'] == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response",
            "        if response['code'] == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response",
            "        if response['code'] == 202:",
            "            deleted = False",
            "            for _ in range(12):",
            "                get_cvdelete = RequestsClient(",
            "                    self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "                response = get_cvdelete.get(",
            "                    (f'/v{self.api_version}/agents/{self.agent_uuid}'),",
            "                    cert=self.cert,",
            "                    verify=self.verifier_ca_cert",
            "                )",
            "",
            "                if response.status_code == 404:",
            "                    deleted = True",
            "                    break",
            "                time.sleep(.4)",
            "            if deleted:",
            "                logger.info(\"CV completed deletion of agent %s\", self.agent_uuid)",
            "                return response.json()",
            "            logger.error(\"Timed out waiting for delete of agent %s to complete at CV\", self.agent_uuid)",
            "            return response.json()",
            "        if response['code'] == 200:",
            "            logger.info(\"Agent %s deleted from the CV\", self.agent_uuid)",
            "            return response",
            "",
            "        keylime_logging.log_http_response(",
            "            logger, logging.ERROR, response)",
            "        return response",
            "",
            "    def do_regstatus(self):",
            "        registrar_client.init_client_tls('tenant')",
            "        agent_info = registrar_client.getData(self.registrar_ip,",
            "                                              self.registrar_port,",
            "                                              self.agent_uuid)",
            "",
            "        if not agent_info:",
            "            logger.info(",
            "                \"Agent %s does not exist on the registrar. Please register the agent with the registrar.\",",
            "                self.agent_uuid)",
            "            response = {'code': 404,",
            "                        'status': f\"Agent {self.agent_uuid} does not exist on \"",
            "                                  f\"registrar {self.registrar_ip} port {self.registrar_port}.\",",
            "                        'results': {}}",
            "            logger.info(json.dumps(response))",
            "            return response",
            "",
            "        response = {'code': 200,",
            "                    'status': f\"Agent {self.agent_uuid} exists on \"",
            "                              f\"registrar {self.registrar_ip} port {self.registrar_port}.\",",
            "                    'results': {}}",
            "        response['results'][self.agent_uuid] = agent_info",
            "        response['results'][self.agent_uuid]['operational_state'] = \\",
            "            states.state_to_str(states.REGISTERED)",
            "",
            "        logger.info(json.dumps(response))",
            "",
            "        return response",
            "",
            "    def do_reglist(self):",
            "        \"\"\"List agents from Registrar\"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        response = registrar_client.doRegistrarList(",
            "            self.registrar_ip, self.registrar_port)",
            "",
            "        logger.info(\"From registrar %s port %s retrieved %s\",",
            "                    self.registrar_ip, self.registrar_port,",
            "                    json.dumps(response))",
            "        return response",
            "",
            "    def do_regdelete(self):",
            "        \"\"\"Delete agent from Registrar\"\"\"",
            "        registrar_client.init_client_tls('tenant')",
            "        response = registrar_client.doRegistrarDelete(self.registrar_ip,",
            "                                           self.registrar_port,",
            "                                           self.agent_uuid)",
            "",
            "        return response",
            "",
            "    def do_status(self):",
            "        \"\"\"Perform operational state look up for agent\"\"\"",
            "",
            "        regresponse = self.do_regstatus()",
            "",
            "        if regresponse['code'] == 404:",
            "            return regresponse",
            "",
            "        cvresponse = self.do_cvstatus()",
            "",
            "        if not isinstance(cvresponse, dict):",
            "            logger.error(\"Unexpected response from Cloud Verifier %s on \"",
            "                         \"port %s. response %s\", self.verifier_ip,",
            "                         self.verifier_port, str(cvresponse))",
            "            return cvresponse",
            "",
            "        if regresponse['code'] == 200 and cvresponse['code'] == 200:",
            "            return cvresponse",
            "        if regresponse['code'] == 200 and cvresponse['code'] != 200:",
            "            return regresponse",
            "",
            "        logger.error(\"Unknown inconsistent state between registrar %s on \"",
            "                     \"port %s and verifier %s on port %s occured. Got \"",
            "                     \"registrar response %s verifier response %s\",",
            "                     self.verifier_ip, self.verifier_port, self.registrar_ip,",
            "                     self.registrar_port, str(regresponse), str(cvresponse))",
            "",
            "        return {'registrar': regresponse, 'verifier': cvresponse}",
            "",
            "    def do_cvreactivate(self, verifier_check=True):",
            "        \"\"\"Reactive Agent.\"\"\"",
            "        if verifier_check:",
            "            agent_json = self.do_cvstatus()",
            "            self.verifier_ip = agent_json['results'][self.agent_uuid]['verifier_ip']",
            "            self.verifier_port = agent_json['results'][self.agent_uuid]['verifier_port']",
            "",
            "        do_cvreactivate = RequestsClient(",
            "            self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvreactivate.put(",
            "            f'/v{self.api_version}/agents/{self.agent_uuid}/reactivate',",
            "            data=b'',",
            "            cert=self.cert,",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            return response.json()",
            "        if response.status_code == 200:",
            "            logger.info(\"Agent %s re-activated\", self.agent_uuid)",
            "            return response.json()",
            "",
            "        response_body = response.json()",
            "        keylime_logging.log_http_response(",
            "            logger, logging.ERROR, response_body)",
            "        logger.error(\"Update command response: %s Unexpected response from Cloud Verifier.\", response.status_code)",
            "        return response.json()",
            "",
            "    def do_cvstop(self):",
            "        \"\"\" Stop declared active agent",
            "        \"\"\"",
            "        params = f'/v{self.api_version}/agents/{self.agent_uuid}/stop'",
            "        do_cvstop = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = do_cvstop.put(",
            "            params,",
            "            cert=self.cert,",
            "            data=b'',",
            "            verify=self.verifier_ca_cert",
            "        )",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        response_body = response.json()",
            "        if response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response_body)",
            "        else:",
            "            logger.info(\"Agent %s stopped\", self.agent_uuid)",
            "",
            "    def do_quote(self):",
            "        \"\"\" Perform TPM quote by GET towards Agent",
            "",
            "        Raises:",
            "            UserError: Connection handler",
            "        \"\"\"",
            "        self.nonce = TPM_Utilities.random_password(20)",
            "",
            "        numtries = 0",
            "        response = None",
            "        # Note: We need a specific retry handler (perhaps in common), no point having localised unless we have too.",
            "        while True:",
            "            try:",
            "                params = f'/v{self.supported_version}/quotes/identity?nonce=%s' % (self.nonce)",
            "                cloudagent_base_url = f'{self.agent_ip}:{self.agent_port}'",
            "",
            "                if self.registrar_data['mtls_cert']:",
            "                    with RequestsClient(cloudagent_base_url, tls_enabled=self.tls_agent_enabled, ignore_hostname=True, cert=self.agent_cert,",
            "                                        verify_custom=self.verify_custom) as do_quote:",
            "                        response = do_quote.get(params)",
            "                else:",
            "                    logger.warning(\"Connecting to agent without using mTLS!\")",
            "                    do_quote = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "                    response = do_quote.get(params)",
            "",
            "                print(response)",
            "                response_body = response.json()",
            "",
            "            except Exception as e:",
            "                if response.status_code in (503, 504):",
            "                    numtries += 1",
            "                    maxr = config.getint('tenant', 'max_retries')",
            "                    if numtries >= maxr:",
            "                        logger.error(\"Tenant cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)",
            "                        sys.exit()",
            "                    interval = config.getfloat('tenant', 'retry_interval')",
            "                    exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                    next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                    logger.info(\"Tenant connection to agent at %s refused %s/%s times, trying again in %s seconds...\",",
            "                        self.agent_ip, numtries, maxr, next_retry)",
            "                    time.sleep(next_retry)",
            "                    continue",
            "",
            "                raise e",
            "            break",
            "",
            "        if response is not None and response.status_code != 200:",
            "            raise UserError(",
            "               f\"Status command response: {response.status_code} Unexpected response from Cloud Agent.\")",
            "",
            "        if \"results\" not in response_body:",
            "            raise UserError(",
            "                f\"Error: unexpected http response body from Cloud Agent: {str(response.status)}\")",
            "",
            "        quote = response_body[\"results\"][\"quote\"]",
            "        logger.debug(\"Agent_quote received quote: %s\", quote)",
            "",
            "        public_key = response_body[\"results\"][\"pubkey\"]",
            "        logger.debug(\"Agent_quote received public key: %s\", public_key)",
            "",
            "        # Ensure hash_alg is in accept_tpm_hash_algs list",
            "        hash_alg = response_body[\"results\"][\"hash_alg\"]",
            "        logger.debug(\"Agent_quote received hash algorithm: %s\", hash_alg)",
            "        if not algorithms.is_accepted(hash_alg, config.get('tenant', 'accept_tpm_hash_algs').split(','))\\",
            "                or not algorithms.Hash.is_recognized(hash_alg):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\")",
            "",
            "        # Ensure enc_alg is in accept_tpm_encryption_algs list",
            "        enc_alg = response_body[\"results\"][\"enc_alg\"]",
            "        logger.debug(\"Agent_quote received encryption algorithm: %s\", enc_alg)",
            "        if not algorithms.is_accepted(enc_alg, config.get('tenant', 'accept_tpm_encryption_algs').split(',')):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\")",
            "",
            "        # Ensure sign_alg is in accept_tpm_encryption_algs list",
            "        sign_alg = response_body[\"results\"][\"sign_alg\"]",
            "        logger.debug(\"Agent_quote received signing algorithm: %s\", sign_alg)",
            "        if not algorithms.is_accepted(sign_alg, config.get('tenant', 'accept_tpm_signing_algs').split(',')):",
            "            raise UserError(",
            "                f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\")",
            "",
            "        if not self.validate_tpm_quote(public_key, quote, algorithms.Hash(hash_alg)):",
            "            raise UserError(",
            "                f\"TPM Quote from cloud agent is invalid for nonce: {self.nonce}\")",
            "",
            "        logger.info(\"Quote from %s validated\", self.agent_ip)",
            "",
            "        # encrypt U with the public key",
            "        encrypted_U = crypto.rsa_encrypt(",
            "            crypto.rsa_import_pubkey(public_key), self.U)",
            "",
            "        b64_encrypted_u = base64.b64encode(encrypted_U)",
            "        logger.debug(\"b64_encrypted_u: %s\", b64_encrypted_u.decode('utf-8'))",
            "        data = {",
            "            'encrypted_key': b64_encrypted_u.decode('utf-8'),",
            "            'auth_tag': self.auth_tag",
            "        }",
            "",
            "        if self.payload is not None:",
            "            data['payload'] = self.payload.decode('utf-8')",
            "",
            "",
            "        # post encrypted U back to CloudAgent",
            "        params = f'/v{self.supported_version}/keys/ukey'",
            "        cloudagent_base_url = (",
            "            f'{self.agent_ip}:{self.agent_port}'",
            "        )",
            "",
            "        if self.registrar_data['mtls_cert']:",
            "            with RequestsClient(cloudagent_base_url, tls_enabled=self.tls_agent_enabled, ignore_hostname=True, cert=self.agent_cert,",
            "                                verify_custom=self.verify_custom) as post_ukey:",
            "                response = post_ukey.post(params, json=data)",
            "        else:",
            "            logger.warning(\"Connecting to agent without using mTLS!\")",
            "            post_ukey = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "            response = post_ukey.post(params, json=data)",
            "",
            "        if response.status_code == 503:",
            "            logger.error(\"Cannot connect to Agent at %s with Port %s. Connection refused.\", self.agent_ip, self.agent_port)",
            "            sys.exit()",
            "        elif response.status_code == 504:",
            "            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)",
            "            sys.exit()",
            "",
            "        if response.status_code != 200:",
            "            keylime_logging.log_http_response(",
            "                logger, logging.ERROR, response_body)",
            "            raise UserError(",
            "                f\"Posting of Encrypted U to the Cloud Agent failed with response code {response.status_code} ({response.text})\")",
            "",
            "    def do_verify(self):",
            "        \"\"\" Perform verify using a random generated challenge",
            "        \"\"\"",
            "        challenge = TPM_Utilities.random_password(20)",
            "        numtries = 0",
            "",
            "        while True:",
            "            response = None",
            "            try:",
            "                cloudagent_base_url = (",
            "                    f'{self.agent_ip}:{self.agent_port}'",
            "                )",
            "",
            "                if self.registrar_data['mtls_cert']:",
            "                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True,",
            "                                        cert=self.agent_cert, verify_custom=self.registrar_data['mtls_cert']) as do_verify:",
            "                        response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')",
            "                else:",
            "                    logger.warning(\"Connecting to agent without using mTLS!\")",
            "                    do_verify = RequestsClient(cloudagent_base_url, tls_enabled=False)",
            "                    response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')",
            "",
            "                response_body = response.json()",
            "            except Exception as e:",
            "                if response is not None and response.status_code in (503, 504):",
            "                    numtries += 1",
            "                    maxr = config.getint('tenant', 'max_retries')",
            "                    if numtries >= maxr:",
            "                        logger.error(\"Cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)",
            "                        self.do_cvstop()",
            "                        sys.exit()",
            "                    interval = config.getfloat('tenant', 'retry_interval')",
            "                    exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                    next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                    logger.info(\"Verifier connection to agent at %s refused %s/%s times, trying again in %s seconds...\",",
            "                        self.agent_ip, numtries, maxr, next_retry)",
            "                    time.sleep(next_retry)",
            "                    continue",
            "                self.do_cvstop()",
            "                raise e",
            "            if response.status_code == 200:",
            "                if \"results\" not in response_body or 'hmac' not in response_body['results']:",
            "                    logger.critical(\"Error: unexpected http response body from Cloud Agent: %s\", response.status_code)",
            "                    self.do_cvstop()",
            "                    break",
            "                mac = response_body['results']['hmac']",
            "",
            "                ex_mac = crypto.do_hmac(self.K, challenge)",
            "",
            "                if mac == ex_mac:",
            "                    logger.info(\"Key derivation successful\")",
            "                else:",
            "                    logger.error(\"Key derivation failed\")",
            "                    self.do_cvstop()",
            "            else:",
            "                keylime_logging.log_http_response(",
            "                    logger, logging.ERROR, response_body)",
            "                numtries += 1",
            "                maxr = config.getint('tenant', 'max_retries')",
            "                if numtries >= maxr:",
            "                    logger.error(\"Agent on %s with port %s failed key derivation\", self.agent_ip, self.agent_port)",
            "                    self.do_cvstop()",
            "                    sys.exit()",
            "                interval = config.getfloat('tenant', 'retry_interval')",
            "                exponential_backoff = config.getboolean('tenant', 'exponential_backoff')",
            "                next_retry = retry.retry_time(exponential_backoff, interval, numtries, logger)",
            "                logger.info(\"Key derivation not yet complete (retry %s/%s), trying again in %s seconds... (Ctrl-C to stop)\",",
            "                    numtries, maxr, next_retry)",
            "                time.sleep(next_retry)",
            "                continue",
            "            break",
            "",
            "    def do_add_allowlist(self, args):",
            "        if 'allowlist_name' not in args or not args['allowlist_name']:",
            "            raise UserError('allowlist_name is required to add an allowlist')",
            "",
            "        allowlist_name = args['allowlist_name']",
            "        self.process_allowlist(args)",
            "        data = {",
            "            'tpm_policy': json.dumps(self.tpm_policy),",
            "            'allowlist': json.dumps(self.allowlist)",
            "        }",
            "        body = json.dumps(data)",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.post(f'/v{self.api_version}/allowlists/{allowlist_name}', data=body,",
            "                                  cert=self.cert, verify=self.verifier_ca_cert)",
            "        Tenant._print_json_response(response)",
            "",
            "    def do_delete_allowlist(self, name):",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.delete(f'/v{self.api_version}/allowlists/{name}',",
            "                                    cert=self.cert, verify=self.verifier_ca_cert)",
            "        Tenant._print_json_response(response)",
            "",
            "    def do_show_allowlist(self, name):",
            "        cv_client = RequestsClient(self.verifier_base_url, self.tls_cv_enabled, ignore_hostname=True)",
            "        response = cv_client.get(f'/v{self.api_version}/allowlists/{name}',",
            "                                 cert=self.cert, verify=self.verifier_ca_cert)",
            "        print(f\"Show allowlist command response: {response.status_code}.\")",
            "        Tenant._print_json_response(response)",
            "",
            "    @staticmethod",
            "    def _print_json_response(response):",
            "        try:",
            "            json_response = response.json()",
            "        except ValueError:",
            "            json_response = '{}'",
            "        print(json_response)",
            "",
            "",
            "def write_to_namedtempfile(data, delete_tmp_files):",
            "    temp = tempfile.NamedTemporaryFile(prefix=\"keylime-\", delete=delete_tmp_files)  #pylint: disable=consider-using-with",
            "    temp.write(data)",
            "    temp.flush()",
            "    return temp.name",
            "",
            "def main(argv=sys.argv):  #pylint: disable=dangerous-default-value",
            "    \"\"\"[summary]",
            "",
            "    Keyword Arguments:",
            "        argv {[type]} -- [description] (default: {sys.argv})",
            "",
            "    Raises:",
            "        UserError: [description]",
            "        UserError: [description]",
            "        UserError: [description]",
            "    \"\"\"",
            "    parser = argparse.ArgumentParser(argv[0])",
            "    parser.add_argument('-c', '--command', action='store', dest='command', default='add',",
            "                        help=\"valid commands are add,delete,update,\"",
            "                             \"regstatus,cvstatus,status,reglist,cvlist,reactivate,\"",
            "                             \"regdelete,bulkinfo,addallowlist,showallowlist,deleteallowlist. defaults to add\")",
            "    parser.add_argument('-t', '--targethost', action='store',",
            "                        dest='agent_ip', help=\"the IP address of the host to provision\")",
            "    parser.add_argument('-tp', '--targetport', action='store',",
            "                        dest='agent_port', help=\"the Port of the host to provision\")",
            "    parser.add_argument('-r', '--registrarhost', action='store',",
            "                        dest='registrar_ip', help=\"the IP address of the registrar where to retrieve the agents data from.\")",
            "    parser.add_argument('-rp', '--registrarport', action=\"store\",",
            "                        dest='registrar_port', help=\"the port of the registrar.\")",
            "    parser.add_argument('--cv_targethost', action='store', default=None, dest='cv_agent_ip',",
            "                        help='the IP address of the host to provision that the verifier will use (optional).  Use only if different than argument to option -t/--targethost')",
            "    parser.add_argument('-v', '--cv', action='store', dest='verifier_ip',",
            "                        help=\"the IP address of the cloud verifier\")",
            "    parser.add_argument('-vp', '--cvport', action='store', dest='verifier_port',",
            "                        help=\"the port of the cloud verifier\")",
            "    parser.add_argument('-vi', '--cvid', action='store', dest='verifier_id',",
            "                        help=\"the unique identifier of a cloud verifier\")",
            "    parser.add_argument('-nvc', '--no-verifier-check', action='store_false', dest='verifier_check', default=True,",
            "                        help='Disable the check to confirm if the agent is being processed by the specified verifier. Use only with -c/--command delete or reactivate')",
            "    parser.add_argument('-u', '--uuid', action='store',",
            "                        dest='agent_uuid', help=\"UUID for the agent to provision\")",
            "    parser.add_argument('-f', '--file', action='store', default=None,",
            "                        help='Deliver the specified plaintext to the provisioned agent')",
            "    parser.add_argument('--cert', action='store', dest='ca_dir', default=None,",
            "                        help='Create and deliver a certificate using a CA created by ca-util. Pass in the CA directory or use \"default\" to use the standard dir')",
            "    parser.add_argument('-k', '--key', action='store', dest='keyfile',",
            "                        help='an intermedia key file produced by user_data_encrypt')",
            "    parser.add_argument('-p', '--payload', action='store', default=None,",
            "                        help='Specify the encrypted payload to deliver with encrypted keys specified by -k')",
            "    parser.add_argument('--include', action='store', dest='incl_dir', default=None,",
            "                        help=\"Include additional files in provided directory in certificate zip file.  Must be specified with --cert\")",
            "    parser.add_argument('--allowlist', action='store', dest='allowlist',",
            "                        default=None, help=\"Specify the file path of an allowlist\")",
            "    parser.add_argument('--signature-verification-key', '--sign_verification_key', action='append', dest='ima_sign_verification_keys',",
            "                        default=[], help=\"Specify an IMA file signature verification key\")",
            "    parser.add_argument('--signature-verification-key-sig', action='append', dest='ima_sign_verification_key_sigs',",
            "                        default=[], help=\"Specify the GPG signature file for an IMA file signature verification key; pair this option with --signature-verification-key\")",
            "    parser.add_argument('--signature-verification-key-sig-key', action='append', dest='ima_sign_verification_key_sig_keys',",
            "                        default=[], help=\"Specify the GPG public key file use to validate the --signature-verification-key-sig; pair this option with --signature-verification-key\")",
            "    parser.add_argument('--signature-verification-key-url', action='append', dest='ima_sign_verification_key_urls',",
            "                        default=[], help=\"Specify the URL for a remote IMA file signature verification key\")",
            "    parser.add_argument('--signature-verification-key-sig-url', action='append',",
            "                        dest='ima_sign_verification_key_sig_urls',",
            "                        default=[], help=\"Specify the URL for the remote GPG signature of a remote IMA file signature verification key; pair this option with --signature-verification-key-url\")",
            "    parser.add_argument('--signature-verification-key-sig-url-key', action='append',",
            "                        dest='ima_sign_verification_key_sig_url_keys',",
            "                        default=[], help=\"Specify the GPG public key file used to validate the --signature-verification-key-sig-url; pair this option with --signature-verification-key-url\")",
            "    parser.add_argument('--mb_refstate', action='store', dest='mb_refstate',",
            "                        default=None, help=\"Specify the location of a measure boot reference state (intended state)\")",
            "    parser.add_argument('--allowlist-checksum', action='store', dest='allowlist_checksum',",
            "                        default=None, help=\"Specify the SHA-256 checksum of an allowlist\")",
            "    parser.add_argument('--allowlist-sig', action='store', dest='allowlist_sig',",
            "                        default=None, help=\"Specify the GPG signature file of an allowlist\")",
            "    parser.add_argument('--allowlist-sig-key', action='store', dest='allowlist_sig_key',",
            "                        default=None, help=\"Specify the GPG public key file used to validate the --allowlist-sig or --allowlist-sig-url\")",
            "    parser.add_argument('--allowlist-url', action='store', dest='allowlist_url',",
            "                        default=None, help=\"Specify the URL of a remote allowlist\")",
            "    parser.add_argument('--allowlist-sig-url', action='store', dest='allowlist_sig_url',",
            "                        default=None, help=\"Specify the URL of the remote GPG signature file of an allowlist\")",
            "    parser.add_argument('--exclude', action='store', dest='ima_exclude',",
            "                        default=None, help=\"Specify the location of an IMA exclude list\")",
            "    parser.add_argument('--tpm_policy', action='store', dest='tpm_policy', default=None,",
            "                        help=\"Specify a TPM policy in JSON format. e.g., {\\\"15\\\":\\\"0000000000000000000000000000000000000000\\\"}\")",
            "    parser.add_argument('--verify', action='store_true', default=False,",
            "                        help='Block on cryptographically checked key derivation confirmation from the agent once it has been provisioned')",
            "    parser.add_argument('--allowlist-name', help='The name of allowlist to operate with')",
            "    parser.add_argument('--supported-version', default=None, action=\"store\", dest='supported_version', help='API version that is supported by the agent. Detected automatically by default')",
            "",
            "    args = parser.parse_args(argv[1:])",
            "",
            "    # Make sure argument dependencies are enforced",
            "    if( args.allowlist and args.allowlist_url):",
            "        parser.error(\"--allowlist and --allowlist-url cannot be specified at the same time\")",
            "    if( args.allowlist_url and not (args.allowlist_sig or args.allowlist_sig_url or args.allowlist_checksum)):",
            "        parser.error(\"--allowlist-url must have either --allowlist-sig, --allowlist-sig-url or --allowlist-checksum to verifier integrity\")",
            "    if( args.allowlist_sig and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-sig must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_sig_url and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-sig-url must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_checksum and not (args.allowlist_url or args.allowlist)):",
            "        parser.error(\"--allowlist-checksum must have either --allowlist or --allowlist-url\")",
            "    if( args.allowlist_sig and not args.allowlist_sig_key):",
            "        parser.error(\"--allowlist-sig must also have --allowlist-sig-key\")",
            "    if( args.allowlist_sig_url and not args.allowlist_sig_key):",
            "        parser.error(\"--allowlist-sig-url must also have --allowlist-sig-key\")",
            "    if( args.allowlist_sig_key and not (args.allowlist_sig or args.allowlist_sig_url)):",
            "        parser.error(\"--allowlist-sig-key must have either --allowlist-sig or --allowlist-sig-url\")",
            "",
            "    mytenant = Tenant()",
            "",
            "    if args.agent_uuid is not None:",
            "        mytenant.agent_uuid = args.agent_uuid",
            "        # if the uuid is actually a public key, then hash it",
            "        if mytenant.agent_uuid.startswith('-----BEGIN PUBLIC KEY-----'):",
            "            mytenant.agent_uuid = hashlib.sha256(",
            "                mytenant.agent_uuid).hexdigest()",
            "        if not validators.valid_agent_id(mytenant.agent_uuid):",
            "            raise UserError(\"The agent ID set via agent uuid parameter use invalid characters\")",
            "    else:",
            "        logger.warning(\"Using default UUID d432fbb3-d2f1-4a97-9ef7-75bd81c00000\")",
            "        mytenant.agent_uuid = \"d432fbb3-d2f1-4a97-9ef7-75bd81c00000\"",
            "",
            "    if args.verifier_id is not None:",
            "        mytenant.verifier_id = args.verifier_id",
            "    if args.verifier_ip is not None:",
            "        mytenant.verifier_ip = args.verifier_ip",
            "    if args.verifier_port is not None:",
            "        mytenant.verifier_port = args.verifier_port",
            "",
            "    if args.registrar_ip is not None:",
            "        mytenant.registrar_ip = args.registrar_ip",
            "    if args.registrar_port is not None:",
            "        mytenant.registrar_port = args.registrar_port",
            "",
            "    # we only need to fetch remote files if we are adding or updating",
            "    if args.command in ['add', 'update', 'addallowlist']:",
            "        delete_tmp_files = logger.level > logging.DEBUG # delete tmp files unless in DEBUG mode",
            "",
            "        if args.allowlist_url:",
            "            logger.info(\"Downloading Allowlist from %s\", args.allowlist_url)",
            "            response = requests.get(args.allowlist_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                args.allowlist = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Allowlist temporarily saved in %s\", args.allowlist)",
            "            else:",
            "                raise Exception(f\"Downloading allowlist ({args.allowlist_url}) failed with status code {response.status_code}!\")",
            "",
            "        if args.allowlist_sig_url:",
            "            logger.info(\"Downloading Allowlist signature from %s\", args.allowlist_sig_url)",
            "            response = requests.get(args.allowlist_sig_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                args.allowlist_sig = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Allowlist signature temporarily saved in %s\", args.allowlist_sig)",
            "            else:",
            "                raise Exception(f\"Downloading allowlist signature ({args.allowlist_sig_url}) failed with status code {response.status_code}!\")",
            "",
            "        # verify all the local keys for which we have a signature file and a key to verify",
            "        for i, key_file in enumerate(args.ima_sign_verification_keys):",
            "            if len(args.ima_sign_verification_key_sigs) <= i:",
            "                break",
            "            keysig_file = args.ima_sign_verification_key_sigs[i]",
            "            if len(args.ima_sign_verification_key_sig_keys) == 0:",
            "                raise UserError(f\"A gpg key is missing for key signature file '{keysig_file}'\")",
            "",
            "            gpg_key_file = args.ima_sign_verification_key_sig_keys[i]",
            "            signing.verify_signature_from_file(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")",
            "",
            "            logger.info(\"Signature verification on %s was successful\", key_file)",
            "",
            "        # verify all the remote keys for which we have a signature URL and key to to verify",
            "        # Append the downloaded key files to args.ima_sign_verification_keys",
            "        for i, key_url in enumerate(args.ima_sign_verification_key_urls):",
            "",
            "            logger.info(\"Downloading key from %s\", key_url)",
            "            response = requests.get(key_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                key_file = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                args.ima_sign_verification_keys.append(key_file)",
            "                logger.debug(\"Key temporarily saved in %s\", key_file)",
            "            else:",
            "                raise Exception(f\"Downloading key ({key_url}) failed with status code {response.status_code}!\")",
            "",
            "            if len(args.ima_sign_verification_key_sig_urls) <= i:",
            "                continue",
            "",
            "            keysig_url = args.ima_sign_verification_key_sig_urls[i]",
            "",
            "            if len(args.ima_sign_verification_key_sig_url_keys) == 0:",
            "                raise UserError(f\"A gpg key is missing for key signature URL '{keysig_url}'\")",
            "",
            "            logger.info(\"Downloading key signature from %s\", keysig_url)",
            "            response = requests.get(keysig_url, allow_redirects=False)",
            "            if response.status_code == 200:",
            "                keysig_file = write_to_namedtempfile(response.content, delete_tmp_files)",
            "                logger.debug(\"Key signature temporarily saved in %s\", keysig_file)",
            "            else:",
            "                raise Exception(f\"Downloading key signature ({key_url}) failed with status code {response.status_code}!\")",
            "",
            "            gpg_key_file = args.ima_sign_verification_key_sig_url_keys[i]",
            "            signing.verify_signature_from_file(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")",
            "            logger.info(\"Signature verification on %s was successful\", key_url)",
            "",
            "    if args.command == 'add':",
            "        mytenant.init_add(vars(args))",
            "        mytenant.preloop()",
            "        mytenant.do_quote()",
            "        mytenant.do_cv()",
            "        if args.verify:",
            "            mytenant.do_verify()",
            "    elif args.command == 'update':",
            "        mytenant.init_add(vars(args))",
            "        mytenant.do_cvdelete(args.verifier_check)",
            "        mytenant.preloop()",
            "        mytenant.do_quote()",
            "        mytenant.do_cv()",
            "        if args.verify:",
            "            mytenant.do_verify()",
            "    elif args.command == 'delete':",
            "        mytenant.do_cvdelete(args.verifier_check)",
            "    elif args.command == 'status':",
            "        mytenant.do_status()",
            "    elif args.command == 'cvstatus':",
            "        mytenant.do_cvstatus()",
            "    elif args.command == 'bulkinfo':",
            "        mytenant.do_cvbulkinfo()",
            "    elif args.command == 'cvlist':",
            "        mytenant.do_cvlist()",
            "    elif args.command == 'reactivate':",
            "        mytenant.do_cvreactivate(args.verifier_check)",
            "    elif args.command == 'regstatus':",
            "        mytenant.do_regstatus()",
            "    elif args.command == 'reglist':",
            "        mytenant.do_reglist()",
            "    elif args.command == 'regdelete':",
            "        mytenant.do_regdelete()",
            "    elif args.command == 'addallowlist':",
            "        mytenant.do_add_allowlist(vars(args))",
            "    elif args.command == 'showallowlist':",
            "        mytenant.do_show_allowlist(args.allowlist_name)",
            "    elif args.command == 'deleteallowlist':",
            "        mytenant.do_delete_allowlist(args.allowlist_name)",
            "    else:",
            "        raise UserError(f\"Invalid command specified: {args.command}\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "keylime.tenant.Tenant.do_cv.data",
            "zipp",
            "keylime.tenant.main"
        ]
    }
}