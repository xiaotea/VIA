{
    "localstack/dashboard/infra.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import re"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import os"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import json"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import logging"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import socket"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import tempfile"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from six import iteritems"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from localstack.config import DEFAULT_REGION"
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from localstack.utils.aws import aws_stack"
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from localstack.utils.common import (short_uid, parallelize, is_port_open, new_tmp_file,"
            },
            "10": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    to_str, rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, run, md5)"
            },
            "11": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from localstack.utils.bootstrap import is_api_enabled"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from localstack.utils.common import (short_uid, parallelize,"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+    rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, md5)"
            },
            "14": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from localstack.utils.aws.aws_models import (ElasticSearch, S3Notification,"
            },
            "15": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 10,
                "PatchRowcode": "     EventSource, DynamoDB, DynamoDBStream, FirehoseStream, S3Bucket, SqsQueue,"
            },
            "16": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 11,
                "PatchRowcode": "     KinesisShard, KinesisStream, LambdaFunction)"
            },
            "17": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# TODO: CLI commands in this file need to be replaced with SDK calls!"
            },
            "19": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "20": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "21": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " AWS_CACHE_TIMEOUT = 5  # 5 seconds"
            },
            "22": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " AWS_LAMBDA_CODE_CACHE_TIMEOUT = 5 * 60  # 5 minutes"
            },
            "23": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " MOCK_OBJ = False"
            },
            "24": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " LOG = logging.getLogger(__name__)"
            },
            "25": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def run_cached(cmd, cache_duration_secs=None):"
            },
            "28": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if cache_duration_secs is None:"
            },
            "29": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cache_duration_secs = AWS_CACHE_TIMEOUT"
            },
            "30": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    env_vars = os.environ.copy()"
            },
            "31": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    env_vars.update({"
            },
            "32": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'AWS_ACCESS_KEY_ID': os.environ.get('AWS_ACCESS_KEY_ID') or 'test',"
            },
            "33": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'AWS_SECRET_ACCESS_KEY': os.environ.get('AWS_SECRET_ACCESS_KEY') or 'test',"
            },
            "34": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'AWS_DEFAULT_REGION': DEFAULT_REGION or os.environ.get('AWS_DEFAULT_REGION'),"
            },
            "35": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'PYTHONWARNINGS': 'ignore:Unverified HTTPS request'"
            },
            "36": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    })"
            },
            "37": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    tmp_file_path = new_tmp_file()"
            },
            "38": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    error = None"
            },
            "39": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with open(tmp_file_path, 'w') as err_file:"
            },
            "40": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "41": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return run(cmd, cache_duration_secs=cache_duration_secs, env_vars=env_vars, stderr=err_file)"
            },
            "42": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception as e:"
            },
            "43": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            error = e"
            },
            "44": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if error:"
            },
            "45": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        LOG.warning('Error running command: %s %s %s' % (cmd, error, load_file(tmp_file_path)))"
            },
            "46": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        raise error"
            },
            "47": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "48": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "49": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def run_aws_cmd(service, cmd_params, env=None, cache_duration_secs=None):"
            },
            "50": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cmd = '%s %s' % (aws_cmd(service, env), cmd_params)"
            },
            "51": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if not is_api_enabled(service):"
            },
            "52": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return '{}'"
            },
            "53": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_cached(cmd, cache_duration_secs=cache_duration_secs)"
            },
            "54": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "55": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "56": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_s3api(cmd_params, env):"
            },
            "57": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('s3api', cmd_params, env)"
            },
            "58": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "59": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "60": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_es(cmd_params, env):"
            },
            "61": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('es', cmd_params, env)"
            },
            "62": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "63": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "64": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_kinesis(cmd_params, env, cache_duration_secs=None):"
            },
            "65": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('kinesis', cmd_params, env,"
            },
            "66": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cache_duration_secs=cache_duration_secs)"
            },
            "67": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "68": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "69": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_dynamodb(cmd_params, env):"
            },
            "70": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('dynamodb', cmd_params, env)"
            },
            "71": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "72": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "73": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_firehose(cmd_params, env):"
            },
            "74": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('firehose', cmd_params, env)"
            },
            "75": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "76": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "77": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_sqs(cmd_params, env):"
            },
            "78": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('sqs', cmd_params, env)"
            },
            "79": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "80": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "81": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def cmd_lambda(cmd_params, env, cache_duration_secs=None):"
            },
            "82": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return run_aws_cmd('lambda', cmd_params, env,"
            },
            "83": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cache_duration_secs=cache_duration_secs)"
            },
            "84": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "85": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "86": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def aws_cmd(service, env):"
            },
            "87": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # TODO: use boto3 instead of running aws-cli commands here!"
            },
            "88": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "89": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cmd = '{ test `which aws` || . .venv/bin/activate; }; aws'"
            },
            "90": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    endpoint_url = None"
            },
            "91": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    env = aws_stack.get_environment(env)"
            },
            "92": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if aws_stack.is_local_env(env):"
            },
            "93": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        endpoint_url = aws_stack.get_local_service_url(service)"
            },
            "94": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if endpoint_url:"
            },
            "95": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if not is_port_open(endpoint_url):"
            },
            "96": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise socket.error()"
            },
            "97": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if endpoint_url.startswith('https://'):"
            },
            "98": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            cmd += ' --no-verify-ssl'"
            },
            "99": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cmd = '%s --endpoint-url=\"%s\"' % (cmd, endpoint_url)"
            },
            "100": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cmd = '%s %s' % (cmd, service)"
            },
            "101": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return cmd"
            },
            "102": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "103": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "104": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " def get_kinesis_streams(filter='.*', pool={}, env=None):"
            },
            "105": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "     if MOCK_OBJ:"
            },
            "106": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 29,
                "PatchRowcode": "         return []"
            },
            "107": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 30,
                "PatchRowcode": "     result = []"
            },
            "108": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "     try:"
            },
            "109": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_kinesis('list-streams', env)"
            },
            "110": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        kinesis_client = aws_stack.connect_to_service('kinesis')"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+        out = kinesis_client.list_streams()"
            },
            "113": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "         for name in out['StreamNames']:"
            },
            "114": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "             if re.match(filter, name):"
            },
            "115": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = cmd_kinesis('describe-stream --stream-name %s' % name, env=env)"
            },
            "116": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = json.loads(details)"
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+                details = kinesis_client.describe_stream(StreamArn=name)"
            },
            "118": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "                 arn = details['StreamDescription']['StreamARN']"
            },
            "119": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "                 stream = KinesisStream(arn)"
            },
            "120": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "                 pool[arn] = stream"
            },
            "121": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " "
            },
            "122": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " def get_kinesis_shards(stream_name=None, stream_details=None, env=None):"
            },
            "123": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "     if not stream_details:"
            },
            "124": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_kinesis('describe-stream --stream-name %s' % stream_name, env)"
            },
            "125": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        stream_details = json.loads(out)"
            },
            "126": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    shards = stream_details['StreamDescription']['Shards']"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+        kinesis_client = aws_stack.connect_to_service('kinesis')"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+        out = kinesis_client.describe_stream(StreamArn=stream_name)"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+    shards = out['StreamDescription']['Shards']"
            },
            "130": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     result = []"
            },
            "131": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     for s in shards:"
            },
            "132": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "         shard = KinesisShard(s['ShardId'])"
            },
            "133": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " def get_sqs_queues(filter='.*', pool={}, env=None):"
            },
            "134": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "     result = []"
            },
            "135": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "     try:"
            },
            "136": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_sqs('list-queues', env)"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+        sqs_client = aws_stack.connect_to_service('sqs')"
            },
            "138": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+        out = sqs_client.list_queues()"
            },
            "139": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "         if not out.strip():"
            },
            "140": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "             return result"
            },
            "141": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        queues = json.loads(out)['QueueUrls']"
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+        queues = out['QueueUrls']"
            },
            "143": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "         for q in queues:"
            },
            "144": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "             name = q.split('/')[-1]"
            },
            "145": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "             arn = aws_stack.sqs_queue_arn(name)"
            },
            "146": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "     return result"
            },
            "147": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 78,
                "PatchRowcode": " "
            },
            "148": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 79,
                "PatchRowcode": " "
            },
            "149": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# TODO move to util"
            },
            "150": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def resolve_string_or_variable(string, code_map):"
            },
            "151": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if re.match(r'^[\"\\'].*[\"\\']$', string):"
            },
            "152": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return string.replace('\"', '').replace(\"'\", '')"
            },
            "153": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.warning('Variable resolution not implemented')"
            },
            "154": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return None"
            },
            "155": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "156": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "157": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# TODO move to util"
            },
            "158": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def extract_endpoints(code_map, pool={}):"
            },
            "159": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    result = []"
            },
            "160": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    identifiers = []"
            },
            "161": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    for key, code in iteritems(code_map):"
            },
            "162": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Elasticsearch references"
            },
            "163": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pattern = r'[\\'\"](.*\\.es\\.amazonaws\\.com)[\\'\"]'"
            },
            "164": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for es in re.findall(pattern, code):"
            },
            "165": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if es not in identifiers:"
            },
            "166": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                identifiers.append(es)"
            },
            "167": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                es = EventSource.get(es, pool=pool, type=ElasticSearch)"
            },
            "168": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if es:"
            },
            "169": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    result.append(es)"
            },
            "170": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Elasticsearch references"
            },
            "171": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pattern = r'\\.put_record_batch\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "172": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for firehose in re.findall(pattern, code):"
            },
            "173": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if firehose not in identifiers:"
            },
            "174": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                identifiers.append(firehose)"
            },
            "175": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)"
            },
            "176": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if firehose:"
            },
            "177": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    result.append(firehose)"
            },
            "178": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # DynamoDB references"
            },
            "179": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # TODO fix pattern to be generic"
            },
            "180": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pattern = r'\\.(insert|get)_document\\s*\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "181": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for (op, dynamo) in re.findall(pattern, code):"
            },
            "182": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dynamo = resolve_string_or_variable(dynamo, code_map)"
            },
            "183": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if dynamo not in identifiers:"
            },
            "184": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                identifiers.append(dynamo)"
            },
            "185": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)"
            },
            "186": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if dynamo:"
            },
            "187": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    result.append(dynamo)"
            },
            "188": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # S3 references"
            },
            "189": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pattern = r'\\.upload_file\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "190": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for s3 in re.findall(pattern, code):"
            },
            "191": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            s3 = resolve_string_or_variable(s3, code_map)"
            },
            "192": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if s3 not in identifiers:"
            },
            "193": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                identifiers.append(s3)"
            },
            "194": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)"
            },
            "195": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if s3:"
            },
            "196": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    result.append(s3)"
            },
            "197": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return result"
            },
            "198": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "199": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "200": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " def get_lambda_functions(filter='.*', details=False, pool={}, env=None):"
            },
            "201": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "     if MOCK_OBJ:"
            },
            "202": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         return []"
            },
            "203": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "                     LOG.warning(\"Unable to get code for lambda '%s'\" % func_name)"
            },
            "204": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 103,
                "PatchRowcode": " "
            },
            "205": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "     try:"
            },
            "206": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_lambda('list-functions', env)"
            },
            "207": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "208": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+        lambda_client = aws_stack.connect_to_service('lambda')"
            },
            "209": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        out = lambda_client.list_functions()"
            },
            "210": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 107,
                "PatchRowcode": "         parallelize(handle, out['Functions'])"
            },
            "211": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "     except Exception:"
            },
            "212": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "         pass"
            },
            "213": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "     if MOCK_OBJ:"
            },
            "214": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         return {}"
            },
            "215": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": 116,
                "PatchRowcode": " "
            },
            "216": {
                "beforePatchRowNumber": 252,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cmd = 'list-event-source-mappings'"
            },
            "217": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+    lambda_client = aws_stack.connect_to_service('lambda')"
            },
            "218": {
                "beforePatchRowNumber": 253,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "     if func_name:"
            },
            "219": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cmd = '%s --function-name %s' % (cmd, func_name)"
            },
            "220": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    out = cmd_lambda(cmd, env=env)"
            },
            "221": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    out = json.loads(out)"
            },
            "222": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+        out = lambda_client.list_event_source_mappings(FunctionName=func_name)"
            },
            "223": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+    else:"
            },
            "224": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+        out = lambda_client.list_event_source_mappings()"
            },
            "225": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "     result = out['EventSourceMappings']"
            },
            "226": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "     return result"
            },
            "227": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": 124,
                "PatchRowcode": " "
            },
            "228": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "     env = aws_stack.get_environment(env)"
            },
            "229": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "     if cache_time is None and not aws_stack.is_local_env(env):"
            },
            "230": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "         cache_time = AWS_LAMBDA_CODE_CACHE_TIMEOUT"
            },
            "231": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    out = cmd_lambda('get-function --function-name %s' % func_name, env, cache_time)"
            },
            "232": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    out = json.loads(out)"
            },
            "233": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+    lambda_client = aws_stack.connect_to_service('lambda')"
            },
            "234": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+    out = lambda_client.get_function(FunctionName=func_name)"
            },
            "235": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "     loc = out['Code']['Location']"
            },
            "236": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "     hash = md5(loc)"
            },
            "237": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "     folder = TMP_DOWNLOAD_FILE_PATTERN.replace('*', hash)"
            },
            "238": {
                "beforePatchRowNumber": 309,
                "afterPatchRowNumber": 174,
                "PatchRowcode": " def get_elasticsearch_domains(filter='.*', pool={}, env=None):"
            },
            "239": {
                "beforePatchRowNumber": 310,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "     result = []"
            },
            "240": {
                "beforePatchRowNumber": 311,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "     try:"
            },
            "241": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_es('list-domain-names', env)"
            },
            "242": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "243": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+        es_client = aws_stack.connect_to_service('es')"
            },
            "244": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 178,
                "PatchRowcode": "+        out = es_client.list_domain_names()"
            },
            "245": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 179,
                "PatchRowcode": " "
            },
            "246": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "         def handle(domain):"
            },
            "247": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "             domain = domain['DomainName']"
            },
            "248": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "             if re.match(filter, domain):"
            },
            "249": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = cmd_es('describe-elasticsearch-domain --domain-name %s' % domain, env)"
            },
            "250": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = json.loads(details)['DomainStatus']"
            },
            "251": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+                details = es_client.describe_elasticsearch_domain(DomainName=domain)"
            },
            "252": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+                details = details['DomainStatus']"
            },
            "253": {
                "beforePatchRowNumber": 320,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "                 arn = details['ARN']"
            },
            "254": {
                "beforePatchRowNumber": 321,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "                 es = ElasticSearch(arn)"
            },
            "255": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "                 es.endpoint = details.get('Endpoint', 'n/a')"
            },
            "256": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 197,
                "PatchRowcode": " def get_dynamo_dbs(filter='.*', pool={}, env=None):"
            },
            "257": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "     result = []"
            },
            "258": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 199,
                "PatchRowcode": "     try:"
            },
            "259": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_dynamodb('list-tables', env)"
            },
            "260": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "261": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+        dynamodb_client = aws_stack.connect_to_service('dynamodb')"
            },
            "262": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+        out = dynamodb_client.list_tables()"
            },
            "263": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 202,
                "PatchRowcode": " "
            },
            "264": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "         def handle(table):"
            },
            "265": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "             if re.match(filter, table):"
            },
            "266": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = cmd_dynamodb('describe-table --table-name %s' % table, env)"
            },
            "267": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = json.loads(details)['Table']"
            },
            "268": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+                details = dynamodb_client.describe_table(TableName=table)"
            },
            "269": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+                details = details['Table']"
            },
            "270": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 207,
                "PatchRowcode": "                 arn = details['TableArn']"
            },
            "271": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "                 db = DynamoDB(arn)"
            },
            "272": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "                 db.count = details['ItemCount']"
            },
            "273": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "             pool[arn] = bucket"
            },
            "274": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 230,
                "PatchRowcode": "             if details:"
            },
            "275": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 231,
                "PatchRowcode": "                 try:"
            },
            "276": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    out = cmd_s3api('get-bucket-notification-configuration --bucket %s' % bucket_name, env=env)"
            },
            "277": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+                    s3_client = aws_stack.connect_to_service('s3')"
            },
            "278": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+                    out = s3_client.get_bucket_notification(Bucket=bucket_name)"
            },
            "279": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "                     if out:"
            },
            "280": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        out = json.loads(out)"
            },
            "281": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "                         if 'CloudFunctionConfiguration' in out:"
            },
            "282": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "                             func = out['CloudFunctionConfiguration']['CloudFunction']"
            },
            "283": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "                             func = EventSource.get(func, pool=pool)"
            },
            "284": {
                "beforePatchRowNumber": 377,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "                     print('WARNING: Unable to get details for bucket: %s' % e)"
            },
            "285": {
                "beforePatchRowNumber": 378,
                "afterPatchRowNumber": 243,
                "PatchRowcode": " "
            },
            "286": {
                "beforePatchRowNumber": 379,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "     try:"
            },
            "287": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_s3api('list-buckets', env)"
            },
            "288": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "289": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+        s3_client = aws_stack.connect_to_service('s3')"
            },
            "290": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+        out = s3_client.list_buckets()"
            },
            "291": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "         parallelize(handle, out['Buckets'])"
            },
            "292": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 248,
                "PatchRowcode": "     except Exception:"
            },
            "293": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 249,
                "PatchRowcode": "         pass"
            },
            "294": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 253,
                "PatchRowcode": " def get_firehose_streams(filter='.*', pool={}, env=None):"
            },
            "295": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 254,
                "PatchRowcode": "     result = []"
            },
            "296": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "     try:"
            },
            "297": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = cmd_firehose('list-delivery-streams', env)"
            },
            "298": {
                "beforePatchRowNumber": 392,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        out = json.loads(out)"
            },
            "299": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+        firehose_client = aws_stack.connect_to_service('firehose')"
            },
            "300": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+        out = firehose_client.list_delivery_streams()"
            },
            "301": {
                "beforePatchRowNumber": 393,
                "afterPatchRowNumber": 258,
                "PatchRowcode": "         for stream_name in out['DeliveryStreamNames']:"
            },
            "302": {
                "beforePatchRowNumber": 394,
                "afterPatchRowNumber": 259,
                "PatchRowcode": "             if re.match(filter, stream_name):"
            },
            "303": {
                "beforePatchRowNumber": 395,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = cmd_firehose("
            },
            "304": {
                "beforePatchRowNumber": 396,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    'describe-delivery-stream --delivery-stream-name %s' % stream_name, env)"
            },
            "305": {
                "beforePatchRowNumber": 397,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                details = json.loads(details)['DeliveryStreamDescription']"
            },
            "306": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+                details = firehose_client.describe_delivery_stream("
            },
            "307": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+                    DeliveryStreamName=stream_name)"
            },
            "308": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+                details = details['DeliveryStreamDescription']"
            },
            "309": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": 263,
                "PatchRowcode": "                 arn = details['DeliveryStreamARN']"
            },
            "310": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": 264,
                "PatchRowcode": "                 s = FirehoseStream(arn)"
            },
            "311": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "                 for dest in details['Destinations']:"
            },
            "312": {
                "beforePatchRowNumber": 408,
                "afterPatchRowNumber": 273,
                "PatchRowcode": " "
            },
            "313": {
                "beforePatchRowNumber": 409,
                "afterPatchRowNumber": 274,
                "PatchRowcode": " "
            },
            "314": {
                "beforePatchRowNumber": 410,
                "afterPatchRowNumber": 275,
                "PatchRowcode": " def read_kinesis_iterator(shard_iterator, max_results=10, env=None):"
            },
            "315": {
                "beforePatchRowNumber": 411,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    data = cmd_kinesis('get-records --shard-iterator %s --limit %s' %"
            },
            "316": {
                "beforePatchRowNumber": 412,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        (shard_iterator, max_results), env, cache_duration_secs=0)"
            },
            "317": {
                "beforePatchRowNumber": 413,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    data = json.loads(to_str(data))"
            },
            "318": {
                "beforePatchRowNumber": 414,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    result = data"
            },
            "319": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+    kinesis_client = aws_stack.connect_to_service('kinesis')"
            },
            "320": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+    result = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=max_results)"
            },
            "321": {
                "beforePatchRowNumber": 415,
                "afterPatchRowNumber": 278,
                "PatchRowcode": "     return result"
            },
            "322": {
                "beforePatchRowNumber": 416,
                "afterPatchRowNumber": 279,
                "PatchRowcode": " "
            },
            "323": {
                "beforePatchRowNumber": 417,
                "afterPatchRowNumber": 280,
                "PatchRowcode": " "
            },
            "324": {
                "beforePatchRowNumber": 497,
                "afterPatchRowNumber": 360,
                "PatchRowcode": "             result['edges'].append({'source': src_uid, 'target': tgt_uid})"
            },
            "325": {
                "beforePatchRowNumber": 498,
                "afterPatchRowNumber": 361,
                "PatchRowcode": " "
            },
            "326": {
                "beforePatchRowNumber": 499,
                "afterPatchRowNumber": 362,
                "PatchRowcode": "     return result"
            },
            "327": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+"
            },
            "328": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+"
            },
            "329": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+# TODO: Move to utils.common"
            },
            "330": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+def extract_endpoints(code_map, pool={}):"
            },
            "331": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+    result = []"
            },
            "332": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+    identifiers = []"
            },
            "333": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+    for key, code in iteritems(code_map):"
            },
            "334": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        # Elasticsearch references"
            },
            "335": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        pattern = r'[\\'\"](.*\\.es\\.amazonaws\\.com)[\\'\"]'"
            },
            "336": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+        for es in re.findall(pattern, code):"
            },
            "337": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+            if es not in identifiers:"
            },
            "338": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 374,
                "PatchRowcode": "+                identifiers.append(es)"
            },
            "339": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 375,
                "PatchRowcode": "+                es = EventSource.get(es, pool=pool, type=ElasticSearch)"
            },
            "340": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 376,
                "PatchRowcode": "+                if es:"
            },
            "341": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 377,
                "PatchRowcode": "+                    result.append(es)"
            },
            "342": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+        # Elasticsearch references"
            },
            "343": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+        pattern = r'\\.put_record_batch\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "344": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 380,
                "PatchRowcode": "+        for firehose in re.findall(pattern, code):"
            },
            "345": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 381,
                "PatchRowcode": "+            if firehose not in identifiers:"
            },
            "346": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 382,
                "PatchRowcode": "+                identifiers.append(firehose)"
            },
            "347": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)"
            },
            "348": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+                if firehose:"
            },
            "349": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 385,
                "PatchRowcode": "+                    result.append(firehose)"
            },
            "350": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 386,
                "PatchRowcode": "+        # DynamoDB references"
            },
            "351": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+        # TODO fix pattern to be generic"
            },
            "352": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+        pattern = r'\\.(insert|get)_document\\s*\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "353": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 389,
                "PatchRowcode": "+        for (op, dynamo) in re.findall(pattern, code):"
            },
            "354": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 390,
                "PatchRowcode": "+            dynamo = resolve_string_or_variable(dynamo, code_map)"
            },
            "355": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+            if dynamo not in identifiers:"
            },
            "356": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 392,
                "PatchRowcode": "+                identifiers.append(dynamo)"
            },
            "357": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 393,
                "PatchRowcode": "+                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)"
            },
            "358": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 394,
                "PatchRowcode": "+                if dynamo:"
            },
            "359": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 395,
                "PatchRowcode": "+                    result.append(dynamo)"
            },
            "360": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+        # S3 references"
            },
            "361": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+        pattern = r'\\.upload_file\\([^,]+,\\s*([^,\\s]+)\\s*,'"
            },
            "362": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+        for s3 in re.findall(pattern, code):"
            },
            "363": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+            s3 = resolve_string_or_variable(s3, code_map)"
            },
            "364": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+            if s3 not in identifiers:"
            },
            "365": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 401,
                "PatchRowcode": "+                identifiers.append(s3)"
            },
            "366": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 402,
                "PatchRowcode": "+                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)"
            },
            "367": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 403,
                "PatchRowcode": "+                if s3:"
            },
            "368": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 404,
                "PatchRowcode": "+                    result.append(s3)"
            },
            "369": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 405,
                "PatchRowcode": "+    return result"
            },
            "370": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+"
            },
            "371": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 407,
                "PatchRowcode": "+"
            },
            "372": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 408,
                "PatchRowcode": "+# TODO: Move to utils.common"
            },
            "373": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 409,
                "PatchRowcode": "+def resolve_string_or_variable(string, code_map):"
            },
            "374": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 410,
                "PatchRowcode": "+    if re.match(r'^[\"\\'].*[\"\\']$', string):"
            },
            "375": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 411,
                "PatchRowcode": "+        return string.replace('\"', '').replace(\"'\", '')"
            },
            "376": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 412,
                "PatchRowcode": "+    LOG.warning('Variable resolution not implemented')"
            },
            "377": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 413,
                "PatchRowcode": "+    return None"
            }
        },
        "frontPatchFile": [
            "import re",
            "import os",
            "import json",
            "import logging",
            "import socket",
            "import tempfile",
            "from six import iteritems",
            "from localstack.config import DEFAULT_REGION",
            "from localstack.utils.aws import aws_stack",
            "from localstack.utils.common import (short_uid, parallelize, is_port_open, new_tmp_file,",
            "    to_str, rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, run, md5)",
            "from localstack.utils.bootstrap import is_api_enabled",
            "from localstack.utils.aws.aws_models import (ElasticSearch, S3Notification,",
            "    EventSource, DynamoDB, DynamoDBStream, FirehoseStream, S3Bucket, SqsQueue,",
            "    KinesisShard, KinesisStream, LambdaFunction)",
            "",
            "# TODO: CLI commands in this file need to be replaced with SDK calls!",
            "",
            "",
            "AWS_CACHE_TIMEOUT = 5  # 5 seconds",
            "AWS_LAMBDA_CODE_CACHE_TIMEOUT = 5 * 60  # 5 minutes",
            "MOCK_OBJ = False",
            "TMP_DOWNLOAD_FILE_PATTERN = os.path.join(tempfile.gettempdir(), 'tmpfile.*')",
            "TMP_DOWNLOAD_CACHE_MAX_AGE = 30 * 60",
            "last_cache_cleanup_time = {'time': 0}",
            "",
            "# time delta for recent Kinesis events",
            "KINESIS_RECENT_EVENTS_TIME_DIFF_SECS = 60",
            "",
            "# logger",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "def run_cached(cmd, cache_duration_secs=None):",
            "    if cache_duration_secs is None:",
            "        cache_duration_secs = AWS_CACHE_TIMEOUT",
            "    env_vars = os.environ.copy()",
            "    env_vars.update({",
            "        'AWS_ACCESS_KEY_ID': os.environ.get('AWS_ACCESS_KEY_ID') or 'test',",
            "        'AWS_SECRET_ACCESS_KEY': os.environ.get('AWS_SECRET_ACCESS_KEY') or 'test',",
            "        'AWS_DEFAULT_REGION': DEFAULT_REGION or os.environ.get('AWS_DEFAULT_REGION'),",
            "        'PYTHONWARNINGS': 'ignore:Unverified HTTPS request'",
            "    })",
            "    tmp_file_path = new_tmp_file()",
            "    error = None",
            "    with open(tmp_file_path, 'w') as err_file:",
            "        try:",
            "            return run(cmd, cache_duration_secs=cache_duration_secs, env_vars=env_vars, stderr=err_file)",
            "        except Exception as e:",
            "            error = e",
            "    if error:",
            "        LOG.warning('Error running command: %s %s %s' % (cmd, error, load_file(tmp_file_path)))",
            "        raise error",
            "",
            "",
            "def run_aws_cmd(service, cmd_params, env=None, cache_duration_secs=None):",
            "    cmd = '%s %s' % (aws_cmd(service, env), cmd_params)",
            "    if not is_api_enabled(service):",
            "        return '{}'",
            "    return run_cached(cmd, cache_duration_secs=cache_duration_secs)",
            "",
            "",
            "def cmd_s3api(cmd_params, env):",
            "    return run_aws_cmd('s3api', cmd_params, env)",
            "",
            "",
            "def cmd_es(cmd_params, env):",
            "    return run_aws_cmd('es', cmd_params, env)",
            "",
            "",
            "def cmd_kinesis(cmd_params, env, cache_duration_secs=None):",
            "    return run_aws_cmd('kinesis', cmd_params, env,",
            "        cache_duration_secs=cache_duration_secs)",
            "",
            "",
            "def cmd_dynamodb(cmd_params, env):",
            "    return run_aws_cmd('dynamodb', cmd_params, env)",
            "",
            "",
            "def cmd_firehose(cmd_params, env):",
            "    return run_aws_cmd('firehose', cmd_params, env)",
            "",
            "",
            "def cmd_sqs(cmd_params, env):",
            "    return run_aws_cmd('sqs', cmd_params, env)",
            "",
            "",
            "def cmd_lambda(cmd_params, env, cache_duration_secs=None):",
            "    return run_aws_cmd('lambda', cmd_params, env,",
            "        cache_duration_secs=cache_duration_secs)",
            "",
            "",
            "def aws_cmd(service, env):",
            "    # TODO: use boto3 instead of running aws-cli commands here!",
            "",
            "    cmd = '{ test `which aws` || . .venv/bin/activate; }; aws'",
            "    endpoint_url = None",
            "    env = aws_stack.get_environment(env)",
            "    if aws_stack.is_local_env(env):",
            "        endpoint_url = aws_stack.get_local_service_url(service)",
            "    if endpoint_url:",
            "        if not is_port_open(endpoint_url):",
            "            raise socket.error()",
            "        if endpoint_url.startswith('https://'):",
            "            cmd += ' --no-verify-ssl'",
            "        cmd = '%s --endpoint-url=\"%s\"' % (cmd, endpoint_url)",
            "    cmd = '%s %s' % (cmd, service)",
            "    return cmd",
            "",
            "",
            "def get_kinesis_streams(filter='.*', pool={}, env=None):",
            "    if MOCK_OBJ:",
            "        return []",
            "    result = []",
            "    try:",
            "        out = cmd_kinesis('list-streams', env)",
            "        out = json.loads(out)",
            "        for name in out['StreamNames']:",
            "            if re.match(filter, name):",
            "                details = cmd_kinesis('describe-stream --stream-name %s' % name, env=env)",
            "                details = json.loads(details)",
            "                arn = details['StreamDescription']['StreamARN']",
            "                stream = KinesisStream(arn)",
            "                pool[arn] = stream",
            "                stream.shards = get_kinesis_shards(stream_details=details, env=env)",
            "                result.append(stream)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_kinesis_shards(stream_name=None, stream_details=None, env=None):",
            "    if not stream_details:",
            "        out = cmd_kinesis('describe-stream --stream-name %s' % stream_name, env)",
            "        stream_details = json.loads(out)",
            "    shards = stream_details['StreamDescription']['Shards']",
            "    result = []",
            "    for s in shards:",
            "        shard = KinesisShard(s['ShardId'])",
            "        shard.start_key = s['HashKeyRange']['StartingHashKey']",
            "        shard.end_key = s['HashKeyRange']['EndingHashKey']",
            "        result.append(shard)",
            "    return result",
            "",
            "",
            "def get_sqs_queues(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        out = cmd_sqs('list-queues', env)",
            "        if not out.strip():",
            "            return result",
            "        queues = json.loads(out)['QueueUrls']",
            "        for q in queues:",
            "            name = q.split('/')[-1]",
            "            arn = aws_stack.sqs_queue_arn(name)",
            "            if re.match(filter, name):",
            "                queue = SqsQueue(arn)",
            "                result.append(queue)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "# TODO move to util",
            "def resolve_string_or_variable(string, code_map):",
            "    if re.match(r'^[\"\\'].*[\"\\']$', string):",
            "        return string.replace('\"', '').replace(\"'\", '')",
            "    LOG.warning('Variable resolution not implemented')",
            "    return None",
            "",
            "",
            "# TODO move to util",
            "def extract_endpoints(code_map, pool={}):",
            "    result = []",
            "    identifiers = []",
            "    for key, code in iteritems(code_map):",
            "        # Elasticsearch references",
            "        pattern = r'[\\'\"](.*\\.es\\.amazonaws\\.com)[\\'\"]'",
            "        for es in re.findall(pattern, code):",
            "            if es not in identifiers:",
            "                identifiers.append(es)",
            "                es = EventSource.get(es, pool=pool, type=ElasticSearch)",
            "                if es:",
            "                    result.append(es)",
            "        # Elasticsearch references",
            "        pattern = r'\\.put_record_batch\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for firehose in re.findall(pattern, code):",
            "            if firehose not in identifiers:",
            "                identifiers.append(firehose)",
            "                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)",
            "                if firehose:",
            "                    result.append(firehose)",
            "        # DynamoDB references",
            "        # TODO fix pattern to be generic",
            "        pattern = r'\\.(insert|get)_document\\s*\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for (op, dynamo) in re.findall(pattern, code):",
            "            dynamo = resolve_string_or_variable(dynamo, code_map)",
            "            if dynamo not in identifiers:",
            "                identifiers.append(dynamo)",
            "                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)",
            "                if dynamo:",
            "                    result.append(dynamo)",
            "        # S3 references",
            "        pattern = r'\\.upload_file\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for s3 in re.findall(pattern, code):",
            "            s3 = resolve_string_or_variable(s3, code_map)",
            "            if s3 not in identifiers:",
            "                identifiers.append(s3)",
            "                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)",
            "                if s3:",
            "                    result.append(s3)",
            "    return result",
            "",
            "",
            "def get_lambda_functions(filter='.*', details=False, pool={}, env=None):",
            "    if MOCK_OBJ:",
            "        return []",
            "",
            "    result = []",
            "",
            "    def handle(func):",
            "        func_name = func['FunctionName']",
            "        if re.match(filter, func_name):",
            "            arn = func['FunctionArn']",
            "            f = LambdaFunction(arn)",
            "            pool[arn] = f",
            "            result.append(f)",
            "            if details:",
            "                sources = get_lambda_event_sources(f.name(), env=env)",
            "                for src in sources:",
            "                    arn = src['EventSourceArn']",
            "                    f.event_sources.append(EventSource.get(arn, pool=pool))",
            "                try:",
            "                    code_map = get_lambda_code(func_name, env=env)",
            "                    f.targets = extract_endpoints(code_map, pool)",
            "                except Exception:",
            "                    LOG.warning(\"Unable to get code for lambda '%s'\" % func_name)",
            "",
            "    try:",
            "        out = cmd_lambda('list-functions', env)",
            "        out = json.loads(out)",
            "        parallelize(handle, out['Functions'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_lambda_event_sources(func_name=None, env=None):",
            "    if MOCK_OBJ:",
            "        return {}",
            "",
            "    cmd = 'list-event-source-mappings'",
            "    if func_name:",
            "        cmd = '%s --function-name %s' % (cmd, func_name)",
            "    out = cmd_lambda(cmd, env=env)",
            "    out = json.loads(out)",
            "    result = out['EventSourceMappings']",
            "    return result",
            "",
            "",
            "def get_lambda_code(func_name, retries=1, cache_time=None, env=None):",
            "    if MOCK_OBJ:",
            "        return ''",
            "    env = aws_stack.get_environment(env)",
            "    if cache_time is None and not aws_stack.is_local_env(env):",
            "        cache_time = AWS_LAMBDA_CODE_CACHE_TIMEOUT",
            "    out = cmd_lambda('get-function --function-name %s' % func_name, env, cache_time)",
            "    out = json.loads(out)",
            "    loc = out['Code']['Location']",
            "    hash = md5(loc)",
            "    folder = TMP_DOWNLOAD_FILE_PATTERN.replace('*', hash)",
            "    filename = 'archive.zip'",
            "    archive = '%s/%s' % (folder, filename)",
            "    try:",
            "        mkdir(folder)",
            "        if not os.path.isfile(archive):",
            "            download(loc, archive, verify_ssl=False)",
            "        if len(os.listdir(folder)) <= 1:",
            "            zip_path = os.path.join(folder, filename)",
            "            unzip(zip_path, folder)",
            "    except Exception as e:",
            "        print('WARN: %s' % e)",
            "        rm_rf(archive)",
            "        if retries > 0:",
            "            return get_lambda_code(func_name, retries=retries - 1, cache_time=1, env=env)",
            "        else:",
            "            print('WARNING: Unable to retrieve lambda code: %s' % e)",
            "",
            "    # traverse subdirectories and get script sources",
            "    result = {}",
            "    for root, subdirs, files in os.walk(folder):",
            "        for file in files:",
            "            prefix = root.split(folder)[-1]",
            "            key = '%s/%s' % (prefix, file)",
            "            if re.match(r'.+\\.py$', key) or re.match(r'.+\\.js$', key):",
            "                codefile = '%s/%s' % (root, file)",
            "                result[key] = load_file(codefile)",
            "",
            "    # cleanup cache",
            "    clean_cache(file_pattern=TMP_DOWNLOAD_FILE_PATTERN,",
            "        last_clean_time=last_cache_cleanup_time,",
            "        max_age=TMP_DOWNLOAD_CACHE_MAX_AGE)",
            "    # TODO: delete only if cache_time is over",
            "    rm_rf(folder)",
            "",
            "    return result",
            "",
            "",
            "def get_elasticsearch_domains(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        out = cmd_es('list-domain-names', env)",
            "        out = json.loads(out)",
            "",
            "        def handle(domain):",
            "            domain = domain['DomainName']",
            "            if re.match(filter, domain):",
            "                details = cmd_es('describe-elasticsearch-domain --domain-name %s' % domain, env)",
            "                details = json.loads(details)['DomainStatus']",
            "                arn = details['ARN']",
            "                es = ElasticSearch(arn)",
            "                es.endpoint = details.get('Endpoint', 'n/a')",
            "                result.append(es)",
            "                pool[arn] = es",
            "        parallelize(handle, out['DomainNames'])",
            "    except Exception:",
            "        pass",
            "",
            "    return result",
            "",
            "",
            "def get_dynamo_dbs(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        out = cmd_dynamodb('list-tables', env)",
            "        out = json.loads(out)",
            "",
            "        def handle(table):",
            "            if re.match(filter, table):",
            "                details = cmd_dynamodb('describe-table --table-name %s' % table, env)",
            "                details = json.loads(details)['Table']",
            "                arn = details['TableArn']",
            "                db = DynamoDB(arn)",
            "                db.count = details['ItemCount']",
            "                db.bytes = details['TableSizeBytes']",
            "                db.created_at = details['CreationDateTime']",
            "                result.append(db)",
            "                pool[arn] = db",
            "        parallelize(handle, out['TableNames'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_s3_buckets(filter='.*', pool={}, details=False, env=None):",
            "    result = []",
            "",
            "    def handle(bucket):",
            "        bucket_name = bucket['Name']",
            "        if re.match(filter, bucket_name):",
            "            arn = 'arn:aws:s3:::%s' % bucket_name",
            "            bucket = S3Bucket(arn)",
            "            result.append(bucket)",
            "            pool[arn] = bucket",
            "            if details:",
            "                try:",
            "                    out = cmd_s3api('get-bucket-notification-configuration --bucket %s' % bucket_name, env=env)",
            "                    if out:",
            "                        out = json.loads(out)",
            "                        if 'CloudFunctionConfiguration' in out:",
            "                            func = out['CloudFunctionConfiguration']['CloudFunction']",
            "                            func = EventSource.get(func, pool=pool)",
            "                            n = S3Notification(func.id)",
            "                            n.target = func",
            "                            bucket.notifications.append(n)",
            "                except Exception as e:",
            "                    print('WARNING: Unable to get details for bucket: %s' % e)",
            "",
            "    try:",
            "        out = cmd_s3api('list-buckets', env)",
            "        out = json.loads(out)",
            "        parallelize(handle, out['Buckets'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_firehose_streams(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        out = cmd_firehose('list-delivery-streams', env)",
            "        out = json.loads(out)",
            "        for stream_name in out['DeliveryStreamNames']:",
            "            if re.match(filter, stream_name):",
            "                details = cmd_firehose(",
            "                    'describe-delivery-stream --delivery-stream-name %s' % stream_name, env)",
            "                details = json.loads(details)['DeliveryStreamDescription']",
            "                arn = details['DeliveryStreamARN']",
            "                s = FirehoseStream(arn)",
            "                for dest in details['Destinations']:",
            "                    dest_s3 = dest['S3DestinationDescription']['BucketARN']",
            "                    bucket = EventSource.get(dest_s3, pool=pool)",
            "                    s.destinations.append(bucket)",
            "                result.append(s)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def read_kinesis_iterator(shard_iterator, max_results=10, env=None):",
            "    data = cmd_kinesis('get-records --shard-iterator %s --limit %s' %",
            "        (shard_iterator, max_results), env, cache_duration_secs=0)",
            "    data = json.loads(to_str(data))",
            "    result = data",
            "    return result",
            "",
            "",
            "def get_kinesis_events(stream_name, shard_id, max_results=10, env=None):",
            "    records = []",
            "    try:",
            "        env = aws_stack.get_environment(env)",
            "        records = aws_stack.kinesis_get_latest_records(stream_name, shard_id, count=max_results, env=env)",
            "        for r in records:",
            "            r['ApproximateArrivalTimestamp'] = mktime(r['ApproximateArrivalTimestamp'])",
            "    except Exception:",
            "        pass",
            "    result = {'events': records}",
            "    return result",
            "",
            "",
            "def get_graph(name_filter='.*', env=None, **kwargs):",
            "    result = {",
            "        'nodes': [],",
            "        'edges': []",
            "    }",
            "",
            "    pool = {}",
            "    node_ids = {}",
            "",
            "    # Make sure we load components in the right order:",
            "    # (ES,DynamoDB,S3) -> (Kinesis,Lambda)",
            "    domains = get_elasticsearch_domains(name_filter, pool=pool, env=env)",
            "    dbs = get_dynamo_dbs(name_filter, pool=pool, env=env)",
            "    buckets = get_s3_buckets(name_filter, details=True, pool=pool, env=env)",
            "    streams = get_kinesis_streams(name_filter, pool=pool, env=env)",
            "    firehoses = get_firehose_streams(name_filter, pool=pool, env=env)",
            "    lambdas = get_lambda_functions(name_filter, details=True, pool=pool, env=env)",
            "    queues = get_sqs_queues(name_filter, pool=pool, env=env)",
            "",
            "    for es in domains:",
            "        uid = short_uid()",
            "        node_ids[es.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': es.id, 'name': es.name(), 'type': 'es'})",
            "    for b in buckets:",
            "        uid = short_uid()",
            "        node_ids[b.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': b.id, 'name': b.name(), 'type': 's3'})",
            "    for db in dbs:",
            "        uid = short_uid()",
            "        node_ids[db.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': db.id, 'name': db.name(), 'type': 'dynamodb'})",
            "    for s in streams:",
            "        uid = short_uid()",
            "        node_ids[s.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': s.id, 'name': s.name(), 'type': 'kinesis'})",
            "        for shard in s.shards:",
            "            uid1 = short_uid()",
            "            name = re.sub(r'shardId-0*', '', shard.id) or '0'",
            "            result['nodes'].append({'id': uid1, 'arn': shard.id, 'name': name,",
            "                'type': 'kinesis_shard', 'streamName': s.name(), 'parent': uid})",
            "    for f in firehoses:",
            "        uid = short_uid()",
            "        node_ids[f.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': f.id, 'name': f.name(), 'type': 'firehose'})",
            "        for d in f.destinations:",
            "            result['edges'].append({'source': uid, 'target': node_ids[d.id]})",
            "    for q in queues:",
            "        uid = short_uid()",
            "        node_ids[q.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': q.id, 'name': q.name(), 'type': 'sqs'})",
            "    for lda in lambdas:",
            "        uid = short_uid()",
            "        node_ids[lda.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': lda.id, 'name': lda.name(), 'type': 'lambda'})",
            "        for s in lda.event_sources:",
            "            lookup_id = s.id",
            "            if isinstance(s, DynamoDBStream):",
            "                lookup_id = s.table.id",
            "            result['edges'].append({'source': node_ids.get(lookup_id), 'target': uid})",
            "        for t in lda.targets:",
            "            lookup_id = t.id",
            "            result['edges'].append({'source': uid, 'target': node_ids.get(lookup_id)})",
            "    for b in buckets:",
            "        for n in b.notifications:",
            "            src_uid = node_ids[b.id]",
            "            tgt_uid = node_ids[n.target.id]",
            "            result['edges'].append({'source': src_uid, 'target': tgt_uid})",
            "",
            "    return result"
        ],
        "afterPatchFile": [
            "import re",
            "import os",
            "import logging",
            "import tempfile",
            "from six import iteritems",
            "from localstack.utils.aws import aws_stack",
            "from localstack.utils.common import (short_uid, parallelize,",
            "    rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, md5)",
            "from localstack.utils.aws.aws_models import (ElasticSearch, S3Notification,",
            "    EventSource, DynamoDB, DynamoDBStream, FirehoseStream, S3Bucket, SqsQueue,",
            "    KinesisShard, KinesisStream, LambdaFunction)",
            "",
            "AWS_CACHE_TIMEOUT = 5  # 5 seconds",
            "AWS_LAMBDA_CODE_CACHE_TIMEOUT = 5 * 60  # 5 minutes",
            "MOCK_OBJ = False",
            "TMP_DOWNLOAD_FILE_PATTERN = os.path.join(tempfile.gettempdir(), 'tmpfile.*')",
            "TMP_DOWNLOAD_CACHE_MAX_AGE = 30 * 60",
            "last_cache_cleanup_time = {'time': 0}",
            "",
            "# time delta for recent Kinesis events",
            "KINESIS_RECENT_EVENTS_TIME_DIFF_SECS = 60",
            "",
            "# logger",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "def get_kinesis_streams(filter='.*', pool={}, env=None):",
            "    if MOCK_OBJ:",
            "        return []",
            "    result = []",
            "    try:",
            "        kinesis_client = aws_stack.connect_to_service('kinesis')",
            "        out = kinesis_client.list_streams()",
            "        for name in out['StreamNames']:",
            "            if re.match(filter, name):",
            "                details = kinesis_client.describe_stream(StreamArn=name)",
            "                arn = details['StreamDescription']['StreamARN']",
            "                stream = KinesisStream(arn)",
            "                pool[arn] = stream",
            "                stream.shards = get_kinesis_shards(stream_details=details, env=env)",
            "                result.append(stream)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_kinesis_shards(stream_name=None, stream_details=None, env=None):",
            "    if not stream_details:",
            "        kinesis_client = aws_stack.connect_to_service('kinesis')",
            "        out = kinesis_client.describe_stream(StreamArn=stream_name)",
            "    shards = out['StreamDescription']['Shards']",
            "    result = []",
            "    for s in shards:",
            "        shard = KinesisShard(s['ShardId'])",
            "        shard.start_key = s['HashKeyRange']['StartingHashKey']",
            "        shard.end_key = s['HashKeyRange']['EndingHashKey']",
            "        result.append(shard)",
            "    return result",
            "",
            "",
            "def get_sqs_queues(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        sqs_client = aws_stack.connect_to_service('sqs')",
            "        out = sqs_client.list_queues()",
            "        if not out.strip():",
            "            return result",
            "        queues = out['QueueUrls']",
            "        for q in queues:",
            "            name = q.split('/')[-1]",
            "            arn = aws_stack.sqs_queue_arn(name)",
            "            if re.match(filter, name):",
            "                queue = SqsQueue(arn)",
            "                result.append(queue)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_lambda_functions(filter='.*', details=False, pool={}, env=None):",
            "    if MOCK_OBJ:",
            "        return []",
            "",
            "    result = []",
            "",
            "    def handle(func):",
            "        func_name = func['FunctionName']",
            "        if re.match(filter, func_name):",
            "            arn = func['FunctionArn']",
            "            f = LambdaFunction(arn)",
            "            pool[arn] = f",
            "            result.append(f)",
            "            if details:",
            "                sources = get_lambda_event_sources(f.name(), env=env)",
            "                for src in sources:",
            "                    arn = src['EventSourceArn']",
            "                    f.event_sources.append(EventSource.get(arn, pool=pool))",
            "                try:",
            "                    code_map = get_lambda_code(func_name, env=env)",
            "                    f.targets = extract_endpoints(code_map, pool)",
            "                except Exception:",
            "                    LOG.warning(\"Unable to get code for lambda '%s'\" % func_name)",
            "",
            "    try:",
            "        lambda_client = aws_stack.connect_to_service('lambda')",
            "        out = lambda_client.list_functions()",
            "        parallelize(handle, out['Functions'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_lambda_event_sources(func_name=None, env=None):",
            "    if MOCK_OBJ:",
            "        return {}",
            "",
            "    lambda_client = aws_stack.connect_to_service('lambda')",
            "    if func_name:",
            "        out = lambda_client.list_event_source_mappings(FunctionName=func_name)",
            "    else:",
            "        out = lambda_client.list_event_source_mappings()",
            "    result = out['EventSourceMappings']",
            "    return result",
            "",
            "",
            "def get_lambda_code(func_name, retries=1, cache_time=None, env=None):",
            "    if MOCK_OBJ:",
            "        return ''",
            "    env = aws_stack.get_environment(env)",
            "    if cache_time is None and not aws_stack.is_local_env(env):",
            "        cache_time = AWS_LAMBDA_CODE_CACHE_TIMEOUT",
            "    lambda_client = aws_stack.connect_to_service('lambda')",
            "    out = lambda_client.get_function(FunctionName=func_name)",
            "    loc = out['Code']['Location']",
            "    hash = md5(loc)",
            "    folder = TMP_DOWNLOAD_FILE_PATTERN.replace('*', hash)",
            "    filename = 'archive.zip'",
            "    archive = '%s/%s' % (folder, filename)",
            "    try:",
            "        mkdir(folder)",
            "        if not os.path.isfile(archive):",
            "            download(loc, archive, verify_ssl=False)",
            "        if len(os.listdir(folder)) <= 1:",
            "            zip_path = os.path.join(folder, filename)",
            "            unzip(zip_path, folder)",
            "    except Exception as e:",
            "        print('WARN: %s' % e)",
            "        rm_rf(archive)",
            "        if retries > 0:",
            "            return get_lambda_code(func_name, retries=retries - 1, cache_time=1, env=env)",
            "        else:",
            "            print('WARNING: Unable to retrieve lambda code: %s' % e)",
            "",
            "    # traverse subdirectories and get script sources",
            "    result = {}",
            "    for root, subdirs, files in os.walk(folder):",
            "        for file in files:",
            "            prefix = root.split(folder)[-1]",
            "            key = '%s/%s' % (prefix, file)",
            "            if re.match(r'.+\\.py$', key) or re.match(r'.+\\.js$', key):",
            "                codefile = '%s/%s' % (root, file)",
            "                result[key] = load_file(codefile)",
            "",
            "    # cleanup cache",
            "    clean_cache(file_pattern=TMP_DOWNLOAD_FILE_PATTERN,",
            "        last_clean_time=last_cache_cleanup_time,",
            "        max_age=TMP_DOWNLOAD_CACHE_MAX_AGE)",
            "    # TODO: delete only if cache_time is over",
            "    rm_rf(folder)",
            "",
            "    return result",
            "",
            "",
            "def get_elasticsearch_domains(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        es_client = aws_stack.connect_to_service('es')",
            "        out = es_client.list_domain_names()",
            "",
            "        def handle(domain):",
            "            domain = domain['DomainName']",
            "            if re.match(filter, domain):",
            "                details = es_client.describe_elasticsearch_domain(DomainName=domain)",
            "                details = details['DomainStatus']",
            "                arn = details['ARN']",
            "                es = ElasticSearch(arn)",
            "                es.endpoint = details.get('Endpoint', 'n/a')",
            "                result.append(es)",
            "                pool[arn] = es",
            "        parallelize(handle, out['DomainNames'])",
            "    except Exception:",
            "        pass",
            "",
            "    return result",
            "",
            "",
            "def get_dynamo_dbs(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        dynamodb_client = aws_stack.connect_to_service('dynamodb')",
            "        out = dynamodb_client.list_tables()",
            "",
            "        def handle(table):",
            "            if re.match(filter, table):",
            "                details = dynamodb_client.describe_table(TableName=table)",
            "                details = details['Table']",
            "                arn = details['TableArn']",
            "                db = DynamoDB(arn)",
            "                db.count = details['ItemCount']",
            "                db.bytes = details['TableSizeBytes']",
            "                db.created_at = details['CreationDateTime']",
            "                result.append(db)",
            "                pool[arn] = db",
            "        parallelize(handle, out['TableNames'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_s3_buckets(filter='.*', pool={}, details=False, env=None):",
            "    result = []",
            "",
            "    def handle(bucket):",
            "        bucket_name = bucket['Name']",
            "        if re.match(filter, bucket_name):",
            "            arn = 'arn:aws:s3:::%s' % bucket_name",
            "            bucket = S3Bucket(arn)",
            "            result.append(bucket)",
            "            pool[arn] = bucket",
            "            if details:",
            "                try:",
            "                    s3_client = aws_stack.connect_to_service('s3')",
            "                    out = s3_client.get_bucket_notification(Bucket=bucket_name)",
            "                    if out:",
            "                        if 'CloudFunctionConfiguration' in out:",
            "                            func = out['CloudFunctionConfiguration']['CloudFunction']",
            "                            func = EventSource.get(func, pool=pool)",
            "                            n = S3Notification(func.id)",
            "                            n.target = func",
            "                            bucket.notifications.append(n)",
            "                except Exception as e:",
            "                    print('WARNING: Unable to get details for bucket: %s' % e)",
            "",
            "    try:",
            "        s3_client = aws_stack.connect_to_service('s3')",
            "        out = s3_client.list_buckets()",
            "        parallelize(handle, out['Buckets'])",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def get_firehose_streams(filter='.*', pool={}, env=None):",
            "    result = []",
            "    try:",
            "        firehose_client = aws_stack.connect_to_service('firehose')",
            "        out = firehose_client.list_delivery_streams()",
            "        for stream_name in out['DeliveryStreamNames']:",
            "            if re.match(filter, stream_name):",
            "                details = firehose_client.describe_delivery_stream(",
            "                    DeliveryStreamName=stream_name)",
            "                details = details['DeliveryStreamDescription']",
            "                arn = details['DeliveryStreamARN']",
            "                s = FirehoseStream(arn)",
            "                for dest in details['Destinations']:",
            "                    dest_s3 = dest['S3DestinationDescription']['BucketARN']",
            "                    bucket = EventSource.get(dest_s3, pool=pool)",
            "                    s.destinations.append(bucket)",
            "                result.append(s)",
            "    except Exception:",
            "        pass",
            "    return result",
            "",
            "",
            "def read_kinesis_iterator(shard_iterator, max_results=10, env=None):",
            "    kinesis_client = aws_stack.connect_to_service('kinesis')",
            "    result = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=max_results)",
            "    return result",
            "",
            "",
            "def get_kinesis_events(stream_name, shard_id, max_results=10, env=None):",
            "    records = []",
            "    try:",
            "        env = aws_stack.get_environment(env)",
            "        records = aws_stack.kinesis_get_latest_records(stream_name, shard_id, count=max_results, env=env)",
            "        for r in records:",
            "            r['ApproximateArrivalTimestamp'] = mktime(r['ApproximateArrivalTimestamp'])",
            "    except Exception:",
            "        pass",
            "    result = {'events': records}",
            "    return result",
            "",
            "",
            "def get_graph(name_filter='.*', env=None, **kwargs):",
            "    result = {",
            "        'nodes': [],",
            "        'edges': []",
            "    }",
            "",
            "    pool = {}",
            "    node_ids = {}",
            "",
            "    # Make sure we load components in the right order:",
            "    # (ES,DynamoDB,S3) -> (Kinesis,Lambda)",
            "    domains = get_elasticsearch_domains(name_filter, pool=pool, env=env)",
            "    dbs = get_dynamo_dbs(name_filter, pool=pool, env=env)",
            "    buckets = get_s3_buckets(name_filter, details=True, pool=pool, env=env)",
            "    streams = get_kinesis_streams(name_filter, pool=pool, env=env)",
            "    firehoses = get_firehose_streams(name_filter, pool=pool, env=env)",
            "    lambdas = get_lambda_functions(name_filter, details=True, pool=pool, env=env)",
            "    queues = get_sqs_queues(name_filter, pool=pool, env=env)",
            "",
            "    for es in domains:",
            "        uid = short_uid()",
            "        node_ids[es.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': es.id, 'name': es.name(), 'type': 'es'})",
            "    for b in buckets:",
            "        uid = short_uid()",
            "        node_ids[b.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': b.id, 'name': b.name(), 'type': 's3'})",
            "    for db in dbs:",
            "        uid = short_uid()",
            "        node_ids[db.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': db.id, 'name': db.name(), 'type': 'dynamodb'})",
            "    for s in streams:",
            "        uid = short_uid()",
            "        node_ids[s.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': s.id, 'name': s.name(), 'type': 'kinesis'})",
            "        for shard in s.shards:",
            "            uid1 = short_uid()",
            "            name = re.sub(r'shardId-0*', '', shard.id) or '0'",
            "            result['nodes'].append({'id': uid1, 'arn': shard.id, 'name': name,",
            "                'type': 'kinesis_shard', 'streamName': s.name(), 'parent': uid})",
            "    for f in firehoses:",
            "        uid = short_uid()",
            "        node_ids[f.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': f.id, 'name': f.name(), 'type': 'firehose'})",
            "        for d in f.destinations:",
            "            result['edges'].append({'source': uid, 'target': node_ids[d.id]})",
            "    for q in queues:",
            "        uid = short_uid()",
            "        node_ids[q.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': q.id, 'name': q.name(), 'type': 'sqs'})",
            "    for lda in lambdas:",
            "        uid = short_uid()",
            "        node_ids[lda.id] = uid",
            "        result['nodes'].append({'id': uid, 'arn': lda.id, 'name': lda.name(), 'type': 'lambda'})",
            "        for s in lda.event_sources:",
            "            lookup_id = s.id",
            "            if isinstance(s, DynamoDBStream):",
            "                lookup_id = s.table.id",
            "            result['edges'].append({'source': node_ids.get(lookup_id), 'target': uid})",
            "        for t in lda.targets:",
            "            lookup_id = t.id",
            "            result['edges'].append({'source': uid, 'target': node_ids.get(lookup_id)})",
            "    for b in buckets:",
            "        for n in b.notifications:",
            "            src_uid = node_ids[b.id]",
            "            tgt_uid = node_ids[n.target.id]",
            "            result['edges'].append({'source': src_uid, 'target': tgt_uid})",
            "",
            "    return result",
            "",
            "",
            "# TODO: Move to utils.common",
            "def extract_endpoints(code_map, pool={}):",
            "    result = []",
            "    identifiers = []",
            "    for key, code in iteritems(code_map):",
            "        # Elasticsearch references",
            "        pattern = r'[\\'\"](.*\\.es\\.amazonaws\\.com)[\\'\"]'",
            "        for es in re.findall(pattern, code):",
            "            if es not in identifiers:",
            "                identifiers.append(es)",
            "                es = EventSource.get(es, pool=pool, type=ElasticSearch)",
            "                if es:",
            "                    result.append(es)",
            "        # Elasticsearch references",
            "        pattern = r'\\.put_record_batch\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for firehose in re.findall(pattern, code):",
            "            if firehose not in identifiers:",
            "                identifiers.append(firehose)",
            "                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)",
            "                if firehose:",
            "                    result.append(firehose)",
            "        # DynamoDB references",
            "        # TODO fix pattern to be generic",
            "        pattern = r'\\.(insert|get)_document\\s*\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for (op, dynamo) in re.findall(pattern, code):",
            "            dynamo = resolve_string_or_variable(dynamo, code_map)",
            "            if dynamo not in identifiers:",
            "                identifiers.append(dynamo)",
            "                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)",
            "                if dynamo:",
            "                    result.append(dynamo)",
            "        # S3 references",
            "        pattern = r'\\.upload_file\\([^,]+,\\s*([^,\\s]+)\\s*,'",
            "        for s3 in re.findall(pattern, code):",
            "            s3 = resolve_string_or_variable(s3, code_map)",
            "            if s3 not in identifiers:",
            "                identifiers.append(s3)",
            "                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)",
            "                if s3:",
            "                    result.append(s3)",
            "    return result",
            "",
            "",
            "# TODO: Move to utils.common",
            "def resolve_string_or_variable(string, code_map):",
            "    if re.match(r'^[\"\\'].*[\"\\']$', string):",
            "        return string.replace('\"', '').replace(\"'\", '')",
            "    LOG.warning('Variable resolution not implemented')",
            "    return None"
        ],
        "action": [
            "0",
            "0",
            "1",
            "0",
            "1",
            "0",
            "0",
            "1",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "3": [],
            "5": [],
            "8": [],
            "10": [],
            "11": [],
            "12": [],
            "17": [],
            "18": [],
            "19": [],
            "34": [
                "run_cached"
            ],
            "35": [
                "run_cached"
            ],
            "36": [
                "run_cached"
            ],
            "37": [
                "run_cached"
            ],
            "38": [
                "run_cached"
            ],
            "39": [
                "run_cached"
            ],
            "40": [
                "run_cached"
            ],
            "41": [
                "run_cached"
            ],
            "42": [
                "run_cached"
            ],
            "43": [
                "run_cached"
            ],
            "44": [
                "run_cached"
            ],
            "45": [
                "run_cached"
            ],
            "46": [
                "run_cached"
            ],
            "47": [
                "run_cached"
            ],
            "48": [
                "run_cached"
            ],
            "49": [
                "run_cached"
            ],
            "50": [
                "run_cached"
            ],
            "51": [
                "run_cached"
            ],
            "52": [
                "run_cached"
            ],
            "53": [
                "run_cached"
            ],
            "54": [],
            "55": [],
            "56": [
                "run_aws_cmd"
            ],
            "57": [
                "run_aws_cmd"
            ],
            "58": [
                "run_aws_cmd"
            ],
            "59": [
                "run_aws_cmd"
            ],
            "60": [
                "run_aws_cmd"
            ],
            "61": [],
            "62": [],
            "63": [
                "cmd_s3api"
            ],
            "64": [
                "cmd_s3api"
            ],
            "65": [],
            "66": [],
            "67": [
                "cmd_es"
            ],
            "68": [
                "cmd_es"
            ],
            "69": [],
            "70": [],
            "71": [
                "cmd_kinesis"
            ],
            "72": [
                "cmd_kinesis"
            ],
            "73": [
                "cmd_kinesis"
            ],
            "74": [],
            "75": [],
            "76": [
                "cmd_dynamodb"
            ],
            "77": [
                "cmd_dynamodb"
            ],
            "78": [],
            "79": [],
            "80": [
                "cmd_firehose"
            ],
            "81": [
                "cmd_firehose"
            ],
            "82": [],
            "83": [],
            "84": [
                "cmd_sqs"
            ],
            "85": [
                "cmd_sqs"
            ],
            "86": [],
            "87": [],
            "88": [
                "cmd_lambda"
            ],
            "89": [
                "cmd_lambda"
            ],
            "90": [
                "cmd_lambda"
            ],
            "91": [],
            "92": [],
            "93": [
                "aws_cmd"
            ],
            "94": [
                "aws_cmd"
            ],
            "95": [
                "aws_cmd"
            ],
            "96": [
                "aws_cmd"
            ],
            "97": [
                "aws_cmd"
            ],
            "98": [
                "aws_cmd"
            ],
            "99": [
                "aws_cmd"
            ],
            "100": [
                "aws_cmd"
            ],
            "101": [
                "aws_cmd"
            ],
            "102": [
                "aws_cmd"
            ],
            "103": [
                "aws_cmd"
            ],
            "104": [
                "aws_cmd"
            ],
            "105": [
                "aws_cmd"
            ],
            "106": [
                "aws_cmd"
            ],
            "107": [
                "aws_cmd"
            ],
            "108": [
                "aws_cmd"
            ],
            "109": [],
            "110": [],
            "116": [
                "get_kinesis_streams"
            ],
            "117": [
                "get_kinesis_streams"
            ],
            "120": [
                "get_kinesis_streams"
            ],
            "121": [
                "get_kinesis_streams"
            ],
            "134": [
                "get_kinesis_shards"
            ],
            "135": [
                "get_kinesis_shards"
            ],
            "136": [
                "get_kinesis_shards"
            ],
            "149": [
                "get_sqs_queues"
            ],
            "152": [
                "get_sqs_queues"
            ],
            "164": [],
            "165": [
                "resolve_string_or_variable"
            ],
            "166": [
                "resolve_string_or_variable"
            ],
            "167": [
                "resolve_string_or_variable"
            ],
            "168": [
                "resolve_string_or_variable"
            ],
            "169": [
                "resolve_string_or_variable"
            ],
            "170": [],
            "171": [],
            "172": [],
            "173": [
                "extract_endpoints"
            ],
            "174": [
                "extract_endpoints"
            ],
            "175": [
                "extract_endpoints"
            ],
            "176": [
                "extract_endpoints"
            ],
            "177": [
                "extract_endpoints"
            ],
            "178": [
                "extract_endpoints"
            ],
            "179": [
                "extract_endpoints"
            ],
            "180": [
                "extract_endpoints"
            ],
            "181": [
                "extract_endpoints"
            ],
            "182": [
                "extract_endpoints"
            ],
            "183": [
                "extract_endpoints"
            ],
            "184": [
                "extract_endpoints"
            ],
            "185": [
                "extract_endpoints"
            ],
            "186": [
                "extract_endpoints"
            ],
            "187": [
                "extract_endpoints"
            ],
            "188": [
                "extract_endpoints"
            ],
            "189": [
                "extract_endpoints"
            ],
            "190": [
                "extract_endpoints"
            ],
            "191": [
                "extract_endpoints"
            ],
            "192": [
                "extract_endpoints"
            ],
            "193": [
                "extract_endpoints"
            ],
            "194": [
                "extract_endpoints"
            ],
            "195": [
                "extract_endpoints"
            ],
            "196": [
                "extract_endpoints"
            ],
            "197": [
                "extract_endpoints"
            ],
            "198": [
                "extract_endpoints"
            ],
            "199": [
                "extract_endpoints"
            ],
            "200": [
                "extract_endpoints"
            ],
            "201": [
                "extract_endpoints"
            ],
            "202": [
                "extract_endpoints"
            ],
            "203": [
                "extract_endpoints"
            ],
            "204": [
                "extract_endpoints"
            ],
            "205": [
                "extract_endpoints"
            ],
            "206": [
                "extract_endpoints"
            ],
            "207": [
                "extract_endpoints"
            ],
            "208": [
                "extract_endpoints"
            ],
            "209": [
                "extract_endpoints"
            ],
            "210": [
                "extract_endpoints"
            ],
            "211": [
                "extract_endpoints"
            ],
            "212": [
                "extract_endpoints"
            ],
            "213": [],
            "214": [],
            "240": [
                "get_lambda_functions"
            ],
            "241": [
                "get_lambda_functions"
            ],
            "252": [
                "get_lambda_event_sources"
            ],
            "254": [
                "get_lambda_event_sources"
            ],
            "255": [
                "get_lambda_event_sources"
            ],
            "256": [
                "get_lambda_event_sources"
            ],
            "267": [
                "get_lambda_code"
            ],
            "268": [
                "get_lambda_code"
            ],
            "312": [
                "get_elasticsearch_domains"
            ],
            "313": [
                "get_elasticsearch_domains"
            ],
            "318": [
                "get_elasticsearch_domains",
                "handle"
            ],
            "319": [
                "get_elasticsearch_domains",
                "handle"
            ],
            "335": [
                "get_dynamo_dbs"
            ],
            "336": [
                "get_dynamo_dbs"
            ],
            "340": [
                "get_dynamo_dbs",
                "handle"
            ],
            "341": [
                "get_dynamo_dbs",
                "handle"
            ],
            "367": [
                "get_s3_buckets",
                "handle"
            ],
            "369": [
                "get_s3_buckets",
                "handle"
            ],
            "380": [
                "get_s3_buckets"
            ],
            "381": [
                "get_s3_buckets"
            ],
            "391": [
                "get_firehose_streams"
            ],
            "392": [
                "get_firehose_streams"
            ],
            "395": [
                "get_firehose_streams"
            ],
            "396": [
                "get_firehose_streams"
            ],
            "397": [
                "get_firehose_streams"
            ],
            "411": [
                "read_kinesis_iterator"
            ],
            "412": [
                "read_kinesis_iterator"
            ],
            "413": [
                "read_kinesis_iterator"
            ],
            "414": [
                "read_kinesis_iterator"
            ]
        },
        "addLocation": []
    }
}