{
    "vyper/codegen/core.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 186,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "     with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex("
            },
            "2": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "         \"copy_bytes_count\""
            },
            "3": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ) as (b2, length,), dst.cache_when_complex(\"dst\") as (b3, dst):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):"
            },
            "5": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 190,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "         # fast code for common case where num bytes is small"
            },
            "7": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "         # TODO expand this for more cases where num words is less than ~8"
            }
        },
        "frontPatchFile": [
            "from vyper import ast as vy_ast",
            "from vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import (",
            "    DYNAMIC_ARRAY_OVERHEAD,",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    DArrayType,",
            "    MappingType,",
            "    SArrayType,",
            "    StructType,",
            "    TupleLike,",
            "    TupleType,",
            "    ceil32,",
            "    is_bytes_m_type,",
            "    is_decimal_type,",
            "    is_integer_type,",
            ")",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch",
            "from vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD",
            "",
            "",
            "# propagate revert message when calls to external contracts fail",
            "def check_external_call(call_ir):",
            "    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]",
            "    revert = [\"revert\", 0, \"returndatasize\"]",
            "",
            "    propagate_revert_ir = [\"seq\", copy_revertdata, revert]",
            "    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]",
            "",
            "",
            "# cost per byte of the identity precompile",
            "def _identity_gas_bound(num_bytes):",
            "    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)",
            "",
            "",
            "def _calldatacopy_gas_bound(num_bytes):",
            "    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "def _codecopy_gas_bound(num_bytes):",
            "    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "# Copy byte array word-for-word (including layout)",
            "def make_byte_array_copier(dst, src):",
            "    assert isinstance(src.typ, ByteArrayLike)",
            "    assert isinstance(dst.typ, ByteArrayLike)",
            "",
            "    if src.typ.maxlen > dst.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")",
            "    # stricter check for zeroing a byte array.",
            "    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"",
            "        )  # pragma: notest",
            "",
            "    if src.value == \"~empty\":",
            "        # set length word to 0.",
            "        return STORE(dst, 0)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src):",
            "        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):",
            "",
            "            max_bytes = src.typ.maxlen",
            "",
            "            ret = [\"seq\"]",
            "            # store length",
            "            ret.append(STORE(dst, len_))",
            "",
            "            dst = bytes_data_ptr(dst)",
            "            src = bytes_data_ptr(src)",
            "",
            "            ret.append(copy_bytes(dst, src, len_, max_bytes))",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "def bytes_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, ByteArrayLike)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def dynarray_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, DArrayType)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def _dynarray_make_setter(dst, src):",
            "    assert isinstance(src.typ, DArrayType)",
            "    assert isinstance(dst.typ, DArrayType)",
            "",
            "    if src.value == \"~empty\":",
            "        return IRnode.from_list(STORE(dst, 0))",
            "",
            "    if src.value == \"multi\":",
            "        ret = [\"seq\"]",
            "        # handle literals",
            "",
            "        # write the length word",
            "        store_length = STORE(dst, len(src.args))",
            "        ann = None",
            "        if src.annotation is not None:",
            "            ann = f\"len({src.annotation})\"",
            "        store_length = IRnode.from_list(store_length, annotation=ann)",
            "        ret.append(store_length)",
            "",
            "        n_items = len(src.args)",
            "        for i in range(n_items):",
            "            k = IRnode.from_list(i, typ=\"uint256\")",
            "            dst_i = get_element_ptr(dst, k, array_bounds_check=False)",
            "            src_i = get_element_ptr(src, k, array_bounds_check=False)",
            "            ret.append(make_setter(dst_i, src_i))",
            "",
            "        return ret",
            "",
            "    with src.cache_when_complex(\"darray_src\") as (b1, src):",
            "",
            "        # for ABI-encoded dynamic data, we must loop to unpack, since",
            "        # the layout does not match our memory layout",
            "        should_loop = (",
            "            src.encoding in (Encoding.ABI, Encoding.JSON_ABI)",
            "            and src.typ.subtype.abi_type.is_dynamic()",
            "        )",
            "",
            "        # if the subtype is dynamic, there might be a lot of",
            "        # unused space inside of each element. for instance",
            "        # DynArray[DynArray[uint256, 100], 5] where all the child",
            "        # arrays are empty - for this case, we recursively call",
            "        # into make_setter instead of straight bytes copy",
            "        # TODO we can make this heuristic more precise, e.g.",
            "        # loop when subtype.is_dynamic AND location == storage",
            "        # OR array_size <= /bound where loop is cheaper than memcpy/",
            "        should_loop |= src.typ.subtype.abi_type.is_dynamic()",
            "        should_loop |= needs_clamp(src.typ.subtype, src.encoding)",
            "",
            "        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):",
            "            ret = [\"seq\"]",
            "",
            "            ret.append(STORE(dst, count))",
            "",
            "            if should_loop:",
            "                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")",
            "",
            "                loop_body = make_setter(",
            "                    get_element_ptr(dst, i, array_bounds_check=False),",
            "                    get_element_ptr(src, i, array_bounds_check=False),",
            "                )",
            "                loop_body.annotation = f\"{dst}[i] = {src}[i]\"",
            "",
            "                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])",
            "",
            "            else:",
            "                element_size = src.typ.subtype.memory_bytes_required",
            "                # number of elements * size of element in bytes",
            "                n_bytes = _mul(count, element_size)",
            "                max_bytes = src.typ.count * element_size",
            "",
            "                src_ = dynarray_data_ptr(src)",
            "                dst_ = dynarray_data_ptr(dst)",
            "                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))",
            "",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "# Copy bytes",
            "# Accepts 4 arguments:",
            "# (i) an IR node for the start position of the source",
            "# (ii) an IR node for the start position of the destination",
            "# (iii) an IR node for the length (in bytes)",
            "# (iv) a constant for the max length (in bytes)",
            "# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may",
            "# copy an entire (32-byte) word, depending on the copy routine chosen.",
            "# TODO maybe always pad to ceil32, to reduce dirty bytes bugs",
            "def copy_bytes(dst, src, length, length_bound):",
            "    annotation = f\"copy_bytes from {src} to {dst}\"",
            "",
            "    src = IRnode.from_list(src)",
            "    dst = IRnode.from_list(dst)",
            "    length = IRnode.from_list(length)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(",
            "        \"copy_bytes_count\"",
            "    ) as (b2, length,), dst.cache_when_complex(\"dst\") as (b3, dst):",
            "",
            "        # fast code for common case where num bytes is small",
            "        # TODO expand this for more cases where num words is less than ~8",
            "        if length_bound <= 32:",
            "            copy_op = STORE(dst, LOAD(src))",
            "            ret = IRnode.from_list(copy_op, annotation=annotation)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):",
            "            # special cases: batch copy to memory",
            "            # TODO: iloadbytes",
            "            if src.location == MEMORY:",
            "                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]",
            "                gas_bound = _identity_gas_bound(length_bound)",
            "            elif src.location == CALLDATA:",
            "                copy_op = [\"calldatacopy\", dst, src, length]",
            "                gas_bound = _calldatacopy_gas_bound(length_bound)",
            "            elif src.location == DATA:",
            "                copy_op = [\"dloadbytes\", dst, src, length]",
            "                # note: dloadbytes compiles to CODECOPY",
            "                gas_bound = _codecopy_gas_bound(length_bound)",
            "",
            "            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):",
            "            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)",
            "            # compile to identity, CODECOPY respectively.",
            "            pass",
            "",
            "        # general case, copy word-for-word",
            "        # pseudocode for our approach (memory-storage as example):",
            "        # for i in range(len, bound=MAX_LEN):",
            "        #   sstore(_dst + i, mload(src + i * 32))",
            "        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")",
            "",
            "        n = [\"div\", [\"ceil32\", length], 32]",
            "        n_bound = ceil32(length_bound) // 32",
            "",
            "        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))",
            "        src_i = add_ofst(src, _mul(i, src.location.word_scale))",
            "",
            "        copy_one_word = STORE(dst_i, LOAD(src_i))",
            "",
            "        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]",
            "",
            "        return b1.resolve(",
            "            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))",
            "        )",
            "",
            "",
            "# get the number of bytes at runtime",
            "def get_bytearray_length(arg):",
            "    typ = BaseType(\"uint256\")",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "# get the number of elements at runtime",
            "def get_dyn_array_count(arg):",
            "    assert isinstance(arg.typ, DArrayType)",
            "",
            "    typ = BaseType(\"uint256\")",
            "",
            "    if arg.value == \"multi\":",
            "        return IRnode.from_list(len(arg.args), typ=typ)",
            "",
            "    if arg.value == \"~empty\":",
            "        # empty(DynArray[])",
            "        return IRnode.from_list(0, typ=typ)",
            "",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "def append_dyn_array(darray_node, elem_node):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "",
            "    assert darray_node.typ.count > 0, \"jerk boy u r out\"",
            "",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        len_ = get_dyn_array_count(darray_node)",
            "        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):",
            "            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])",
            "            ret.append(STORE(darray_node, [\"add\", len_, 1]))",
            "            # NOTE: typechecks elem_node",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            ret.append(",
            "                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)",
            "            )",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)))",
            "",
            "",
            "def pop_dyn_array(darray_node, return_popped_item):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]",
            "        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")",
            "",
            "        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):",
            "            ret.append(STORE(darray_node, new_len))",
            "",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            if return_popped_item:",
            "                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)",
            "                ret.append(popped_item)",
            "                typ = popped_item.typ",
            "                location = popped_item.location",
            "                encoding = popped_item.encoding",
            "            else:",
            "                typ, location, encoding = None, None, None",
            "            return IRnode.from_list(",
            "                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding",
            "            )",
            "",
            "",
            "def getpos(node):",
            "    return (",
            "        node.lineno,",
            "        node.col_offset,",
            "        getattr(node, \"end_lineno\", None),",
            "        getattr(node, \"end_col_offset\", None),",
            "    )",
            "",
            "",
            "# TODO since this is always(?) used as add_ofst(ptr, n*ptr.location.word_scale)",
            "# maybe the API should be `add_words_to_ofst(ptr, n)` and handle the",
            "# word_scale multiplication inside",
            "def add_ofst(ptr, ofst):",
            "    ofst = IRnode.from_list(ofst)",
            "    if isinstance(ptr.value, int) and isinstance(ofst.value, int):",
            "        # NOTE: duplicate with optimizer rule (but removing this makes a",
            "        # test on --no-optimize mode use too much gas)",
            "        ret = ptr.value + ofst.value",
            "    else:",
            "        ret = [\"add\", ptr, ofst]",
            "    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)",
            "",
            "",
            "# shorthand util",
            "def _mul(x, y):",
            "    x, y = IRnode.from_list(x), IRnode.from_list(y)",
            "    # NOTE: similar deal: duplicate with optimizer rule",
            "    if isinstance(x.value, int) and isinstance(y.value, int):",
            "        ret = x.value * y.value",
            "    else:",
            "        ret = [\"mul\", x, y]",
            "    return IRnode.from_list(ret)",
            "",
            "",
            "# Resolve pointer locations for ABI-encoded data",
            "def _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):",
            "    member_abi_t = member_t.abi_type",
            "",
            "    # ABI encoding has length word and then pretends length is not there",
            "    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>",
            "    # note that inner array ofst is 0x20, not 0x40.",
            "    if has_length_word(parent.typ):",
            "        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "",
            "    ofst_ir = add_ofst(parent, ofst)",
            "",
            "    if member_abi_t.is_dynamic():",
            "        # double dereference, according to ABI spec",
            "        # TODO optimize special case: first dynamic item",
            "        # offset is statically known.",
            "        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))",
            "",
            "    return IRnode.from_list(",
            "        ofst_ir,",
            "        typ=member_t,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=f\"{parent}{ofst}\",",
            "    )",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_tuplelike(parent, key):",
            "    typ = parent.typ",
            "    assert isinstance(typ, TupleLike)",
            "",
            "    if isinstance(typ, StructType):",
            "        assert isinstance(key, str)",
            "        subtype = typ.members[key]",
            "        attrs = list(typ.tuple_keys())",
            "        index = attrs.index(key)",
            "        annotation = key",
            "    else:",
            "        assert isinstance(key, int)",
            "        subtype = typ.members[key]",
            "        attrs = list(range(len(typ.members)))",
            "        index = key",
            "        annotation = None",
            "",
            "    # generated by empty() + make_setter",
            "    if parent.value == \"~empty\":",
            "        return IRnode.from_list(\"~empty\", typ=subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"",
            "        return parent.args[index]",
            "",
            "    ofst = 0  # offset from parent start",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_t = typ.members[attrs[index]]",
            "",
            "        for i in range(index):",
            "            member_abi_t = typ.members[attrs[i]].abi_type",
            "            ofst += member_abi_t.embedded_static_size()",
            "",
            "        return _getelemptr_abi_helper(parent, member_t, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest",
            "",
            "    return IRnode.from_list(",
            "        add_ofst(parent, ofst),",
            "        typ=subtype,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=annotation,",
            "    )",
            "",
            "",
            "def has_length_word(typ):",
            "    return isinstance(typ, (DArrayType, ByteArrayLike))",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_array(parent, key, array_bounds_check):",
            "",
            "    assert isinstance(parent.typ, ArrayLike)",
            "",
            "    if not is_integer_type(key.typ):",
            "        raise TypeCheckFailure(f\"{key.typ} used as array index\")",
            "",
            "    subtype = parent.typ.subtype",
            "",
            "    if parent.value == \"~empty\":",
            "        if array_bounds_check:",
            "            # this case was previously missing a bounds check. codegen",
            "            # is a bit complicated when bounds check is required, so",
            "            # block it. there is no reason to index into a literal empty",
            "            # array anyways!",
            "            raise TypeCheckFailure(\"indexing into zero array not allowed\")",
            "        return IRnode.from_list(\"~empty\", subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert isinstance(key.value, int)",
            "        return parent.args[key.value]",
            "",
            "    ix = unwrap_location(key)",
            "",
            "    if array_bounds_check:",
            "        # clamplt works, even for signed ints. since two's-complement",
            "        # is used, if the index is negative, (unsigned) LT will interpret",
            "        # it as a very large number, larger than any practical value for",
            "        # an array index, and the clamp will throw an error.",
            "        clamp_op = \"uclamplt\"",
            "        is_darray = isinstance(parent.typ, DArrayType)",
            "        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count",
            "        # NOTE: there are optimization rules for this when ix or bound is literal",
            "        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_abi_t = subtype.abi_type",
            "",
            "        ofst = _mul(ix, member_abi_t.embedded_static_size())",
            "",
            "        return _getelemptr_abi_helper(parent, subtype, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        element_size = subtype.storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        element_size = subtype.memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "",
            "    ofst = _mul(ix, element_size)",
            "",
            "    if has_length_word(parent.typ):",
            "        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "    else:",
            "        data_ptr = parent",
            "",
            "    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)",
            "",
            "",
            "def _get_element_ptr_mapping(parent, key):",
            "    assert isinstance(parent.typ, MappingType)",
            "    subtype = parent.typ.valuetype",
            "    key = unwrap_location(key)",
            "",
            "    # TODO when is key None?",
            "    if key is None or parent.location != STORAGE:",
            "        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")",
            "",
            "    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)",
            "",
            "",
            "# Take a value representing a memory or storage location, and descend down to",
            "# an element or member variable",
            "# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.",
            "def get_element_ptr(parent, key, array_bounds_check=True):",
            "    with parent.cache_when_complex(\"val\") as (b, parent):",
            "        typ = parent.typ",
            "",
            "        if isinstance(typ, TupleLike):",
            "            ret = _get_element_ptr_tuplelike(parent, key)",
            "",
            "        elif isinstance(typ, MappingType):",
            "            ret = _get_element_ptr_mapping(parent, key)",
            "",
            "        elif isinstance(typ, ArrayLike):",
            "            ret = _get_element_ptr_array(parent, key, array_bounds_check)",
            "",
            "        else:",
            "            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest",
            "",
            "        return b.resolve(ret)",
            "",
            "",
            "def LOAD(ptr: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.load_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr])",
            "",
            "",
            "def STORE(ptr: IRnode, val: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.store_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr, val])",
            "",
            "",
            "# Unwrap location",
            "def unwrap_location(orig):",
            "    if orig.location is not None:",
            "        return IRnode.from_list(LOAD(orig), typ=orig.typ)",
            "    else:",
            "        # CMC 2022-03-24 TODO refactor so this branch can be removed",
            "        if orig.value == \"~empty\":",
            "            return IRnode.from_list(0, typ=orig.typ)",
            "        return orig",
            "",
            "",
            "# utility function, constructs an IR tuple out of a list of IR nodes",
            "def ir_tuple_from_args(args):",
            "    typ = TupleType([x.typ for x in args])",
            "    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)",
            "",
            "",
            "def _needs_external_call_wrap(ir_typ):",
            "    # for calls to ABI conforming contracts.",
            "    # according to the ABI spec, return types are ALWAYS tuples even",
            "    # if only one element is being returned.",
            "    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding",
            "    # \"and the return values v_1, ..., v_k of f are encoded as",
            "    #",
            "    #    enc((v_1, ..., v_k))",
            "    #    i.e. the values are combined into a tuple and encoded.",
            "    # \"",
            "    # therefore, wrap it in a tuple if it's not already a tuple.",
            "    # for example, `bytes` is returned as abi-encoded (bytes,)",
            "    # and `(bytes,)` is returned as abi-encoded ((bytes,),)",
            "    # In general `-> X` gets returned as (X,)",
            "    # including structs. MyStruct is returned as abi-encoded (MyStruct,).",
            "    # (Sorry this is so confusing. I didn't make these rules.)",
            "",
            "    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)",
            "",
            "",
            "def calculate_type_for_external_return(ir_typ):",
            "    if _needs_external_call_wrap(ir_typ):",
            "        return TupleType([ir_typ])",
            "    return ir_typ",
            "",
            "",
            "def wrap_value_for_external_return(ir_val):",
            "    # used for LHS promotion",
            "    if _needs_external_call_wrap(ir_val.typ):",
            "        return ir_tuple_from_args([ir_val])",
            "    else:",
            "        return ir_val",
            "",
            "",
            "def set_type_for_external_return(ir_val):",
            "    # used for RHS promotion",
            "    ir_val.typ = calculate_type_for_external_return(ir_val.typ)",
            "",
            "",
            "# return a dummy IRnode with the given type",
            "def dummy_node_for_type(typ):",
            "    return IRnode(\"fake_node\", typ=typ)",
            "",
            "",
            "def _check_assign_bytes(left, right):",
            "    if right.typ.maxlen > left.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest",
            "    # stricter check for zeroing a byte array.",
            "    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "        )  # pragma: notest",
            "",
            "",
            "def _check_assign_list(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if left.value == \"multi\":",
            "        # Cannot do something like [a, b, c] = [1, 2, 3]",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left, SArrayType):",
            "        if not isinstance(right, SArrayType):",
            "            FAIL()  # pragma: notest",
            "        if left.typ.count != right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "    if isinstance(left, DArrayType):",
            "        if not isinstance(right, DArrayType):",
            "            FAIL()  # pragma: notest",
            "",
            "        if left.typ.count < right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # stricter check for zeroing",
            "        if right.value == \"~empty\" and right.typ.count != left.typ.count:",
            "            raise TypeCheckFailure(",
            "                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "            )  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "",
            "def _check_assign_tuple(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if not isinstance(right.typ, left.typ.__class__):",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left.typ, StructType):",
            "        for k in left.typ.members:",
            "            if k not in right.typ.members:",
            "                FAIL()  # pragma: notest",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(",
            "                dummy_node_for_type(left.typ.members[k]),",
            "                dummy_node_for_type(right.typ.members[k]),",
            "            )",
            "",
            "        for k in right.typ.members:",
            "            if k not in left.typ.members:",
            "                FAIL()  # pragma: notest",
            "",
            "        if left.typ.name != right.typ.name:",
            "            FAIL()  # pragma: notest",
            "",
            "    else:",
            "        if len(left.typ.members) != len(right.typ.members):",
            "            FAIL()  # pragma: notest",
            "        for (l, r) in zip(left.typ.members, right.typ.members):",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))",
            "",
            "",
            "# sanity check an assignment",
            "# typechecking source code is done at an earlier phase",
            "# this function is more of a sanity check for typechecking internally",
            "# generated assignments",
            "def check_assign(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")",
            "",
            "    if isinstance(left.typ, ByteArrayLike):",
            "        _check_assign_bytes(left, right)",
            "    elif isinstance(left.typ, ArrayLike):",
            "        _check_assign_list(left, right)",
            "    elif isinstance(left.typ, TupleLike):",
            "        _check_assign_tuple(left, right)",
            "",
            "    elif isinstance(left.typ, BaseType):",
            "        # TODO once we propagate types from typechecker, introduce this check:",
            "        # if left.typ != right.typ:",
            "        #    FAIL()  # pragma: notest",
            "        pass",
            "",
            "    else:  # pragma: nocover",
            "        FAIL()",
            "",
            "",
            "_label = 0",
            "",
            "",
            "# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol",
            "def _freshname(name):",
            "    global _label",
            "    _label += 1",
            "    return f\"{name}{_label}\"",
            "",
            "",
            "# returns True if t is ABI encoded and is a type that needs any kind of",
            "# validation",
            "def needs_clamp(t, encoding):",
            "    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):",
            "        return False",
            "    if isinstance(t, (ByteArrayLike, DArrayType)):",
            "        if encoding == Encoding.JSON_ABI:",
            "            # don't have bytestring size bound from json, don't clamp",
            "            return False",
            "        return True",
            "    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):",
            "        return True",
            "    if isinstance(t, SArrayType):",
            "        return needs_clamp(t.subtype, encoding)",
            "    if isinstance(t, TupleLike):",
            "        return any(needs_clamp(m, encoding) for m in t.tuple_members())",
            "    return False",
            "",
            "",
            "# Create an x=y statement, where the types may be compound",
            "def make_setter(left, right):",
            "    check_assign(left, right)",
            "",
            "    # Basic types",
            "    if isinstance(left.typ, BaseType):",
            "        enc = right.encoding  # unwrap_location butchers encoding",
            "        right = unwrap_location(right)",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, enc):",
            "            right = clamp_basetype(right)",
            "",
            "        return STORE(left, right)",
            "",
            "    # Byte arrays",
            "    elif isinstance(left.typ, ByteArrayLike):",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"bs_ptr\") as (b, right):",
            "                copier = make_byte_array_copier(left, right)",
            "                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])",
            "        else:",
            "            ret = make_byte_array_copier(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    elif isinstance(left.typ, DArrayType):",
            "        # TODO should we enable this?",
            "        # implicit conversion from sarray to darray",
            "        # if isinstance(right.typ, SArrayType):",
            "        #    return _complex_make_setter(left, right)",
            "",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"arr_ptr\") as (b, right):",
            "                copier = _dynarray_make_setter(left, right)",
            "                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])",
            "        else:",
            "            ret = _dynarray_make_setter(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    # Arrays",
            "    elif isinstance(left.typ, (SArrayType, TupleLike)):",
            "        return _complex_make_setter(left, right)",
            "",
            "",
            "def _complex_make_setter(left, right):",
            "    if right.value == \"~empty\" and left.location == MEMORY:",
            "        # optimized memzero",
            "        return mzero(left, left.typ.memory_bytes_required)",
            "",
            "    ret = [\"seq\"]",
            "",
            "    if isinstance(left.typ, SArrayType):",
            "        n_items = right.typ.count",
            "        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]",
            "",
            "    if isinstance(left.typ, TupleLike):",
            "        keys = left.typ.tuple_keys()",
            "",
            "    # if len(keyz) == 0:",
            "    #    return IRnode.from_list([\"pass\"])",
            "",
            "    # general case",
            "    # TODO use copy_bytes when the generated code is above a certain size",
            "    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):",
            "",
            "        for k in keys:",
            "            l_i = get_element_ptr(left, k, array_bounds_check=False)",
            "            r_i = get_element_ptr(right, k, array_bounds_check=False)",
            "            ret.append(make_setter(l_i, r_i))",
            "",
            "        return b1.resolve(b2.resolve(IRnode.from_list(ret)))",
            "",
            "",
            "def ensure_in_memory(ir_var, context):",
            "    \"\"\"Ensure a variable is in memory. This is useful for functions",
            "    which expect to operate on memory variables.",
            "    \"\"\"",
            "    if ir_var.location == MEMORY:",
            "        return ir_var",
            "",
            "    typ = ir_var.typ",
            "    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)",
            "    do_copy = make_setter(buf, ir_var)",
            "",
            "    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)",
            "",
            "",
            "def eval_seq(ir_node):",
            "    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so",
            "    that the value can be known without possibly evaluating side effects",
            "    \"\"\"",
            "    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:",
            "        return eval_seq(ir_node.args[-1])",
            "    if isinstance(ir_node.value, int):",
            "        return IRnode.from_list(ir_node)",
            "    return None",
            "",
            "",
            "# TODO move return checks to vyper/semantics/validation",
            "def is_return_from_function(node):",
            "    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":",
            "        return True",
            "    if isinstance(node, vy_ast.Return):",
            "        return True",
            "    elif isinstance(node, vy_ast.Raise):",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def check_single_exit(fn_node):",
            "    _check_return_body(fn_node, fn_node.body)",
            "    for node in fn_node.get_descendants(vy_ast.If):",
            "        _check_return_body(node, node.body)",
            "        if node.orelse:",
            "            _check_return_body(node, node.orelse)",
            "",
            "",
            "def _check_return_body(node, node_list):",
            "    return_count = len([n for n in node_list if is_return_from_function(n)])",
            "    if return_count > 1:",
            "        raise StructureException(",
            "            \"Too too many exit statements (return, raise or selfdestruct).\", node",
            "        )",
            "    # Check for invalid code after returns.",
            "    last_node_pos = len(node_list) - 1",
            "    for idx, n in enumerate(node_list):",
            "        if is_return_from_function(n) and idx < last_node_pos:",
            "            # is not last statement in body.",
            "            raise StructureException(",
            "                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]",
            "            )",
            "",
            "",
            "def mzero(dst, nbytes):",
            "    # calldatacopy from past-the-end gives zero bytes.",
            "    # cf. YP H.2 (ops section) with CALLDATACOPY spec.",
            "    return IRnode.from_list(",
            "        # calldatacopy mempos calldatapos len",
            "        [\"calldatacopy\", dst, \"calldatasize\", nbytes],",
            "        annotation=\"mzero\",",
            "    )",
            "",
            "",
            "# zero pad a bytearray according to the ABI spec. The last word",
            "# of the byte array needs to be right-padded with zeroes.",
            "def zero_pad(bytez_placeholder):",
            "    len_ = [\"mload\", bytez_placeholder]",
            "    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]",
            "    # the runtime length of the data rounded up to nearest 32",
            "    # from spec:",
            "    #   the actual value of X as a byte sequence,",
            "    #   followed by the *minimum* number of zero-bytes",
            "    #   such that len(enc(X)) is a multiple of 32.",
            "    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]",
            "    return IRnode.from_list(",
            "        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],",
            "        annotation=\"Zero pad\",",
            "    )",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shr(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shr\", bits, x]",
            "    return [\"div\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shl(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shl\", bits, x]",
            "    return [\"mul\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "def sar(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"sar\", bits, x]",
            "",
            "    # emulate for older arches. keep in mind note from EIP 145:",
            "    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds",
            "    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"",
            "    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]",
            "",
            "",
            "def clamp_bytestring(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, ByteArrayLike):",
            "        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest",
            "    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]",
            "",
            "",
            "def clamp_dyn_array(ir_node):",
            "    t = ir_node.typ",
            "    assert isinstance(t, DArrayType)",
            "    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]",
            "",
            "",
            "# clampers for basetype",
            "def clamp_basetype(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, BaseType):",
            "        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "    # copy of the input",
            "    ir_node = unwrap_location(ir_node)",
            "",
            "    if is_integer_type(t) or is_decimal_type(t):",
            "        if t._num_info.bits == 256:",
            "            return ir_node",
            "        else:",
            "            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)",
            "",
            "    if is_bytes_m_type(t):",
            "        if t._bytes_info.m == 32:",
            "            return ir_node  # special case, no clamp.",
            "        else:",
            "            return bytes_clamp(ir_node, t._bytes_info.m)",
            "",
            "    if t.typ in (\"address\",):",
            "        return int_clamp(ir_node, 160)",
            "    if t.typ in (\"bool\",):",
            "        return int_clamp(ir_node, 1)",
            "",
            "    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "",
            "def int_clamp(ir_node, bits, signed=False):",
            "    \"\"\"Generalized clamper for integer types. Takes the number of bits,",
            "    whether it's signed, and returns an IR node which checks it is",
            "    in bounds. (Consumers should use clamp_basetype instead which uses",
            "    type-based dispatch and is a little safer.)",
            "    \"\"\"",
            "    if bits >= 256:",
            "        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        if signed:",
            "            # example for bits==128:",
            "            # promote_signed_int(val, bits) is the \"canonical\" version of val",
            "            # if val is in bounds, the bits above bit 128 should be equal.",
            "            # (this works for both val >= 0 and val < 0. in the first case,",
            "            # all upper bits should be 0 if val is a valid int128,",
            "            # in the latter case, all upper bits should be 1.)",
            "            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]",
            "        else:",
            "            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]",
            "",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "",
            "    # TODO fix this annotation",
            "    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")",
            "",
            "",
            "def bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:",
            "    if not (0 < n_bytes <= 32):",
            "        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")",
            "",
            "",
            "# e.g. for int8, promote 255 to -1",
            "def promote_signed_int(x, bits):",
            "    assert bits % 8 == 0",
            "    ret = [\"signextend\", bits // 8 - 1, x]",
            "    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")"
        ],
        "afterPatchFile": [
            "from vyper import ast as vy_ast",
            "from vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import (",
            "    DYNAMIC_ARRAY_OVERHEAD,",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    DArrayType,",
            "    MappingType,",
            "    SArrayType,",
            "    StructType,",
            "    TupleLike,",
            "    TupleType,",
            "    ceil32,",
            "    is_bytes_m_type,",
            "    is_decimal_type,",
            "    is_integer_type,",
            ")",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch",
            "from vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD",
            "",
            "",
            "# propagate revert message when calls to external contracts fail",
            "def check_external_call(call_ir):",
            "    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]",
            "    revert = [\"revert\", 0, \"returndatasize\"]",
            "",
            "    propagate_revert_ir = [\"seq\", copy_revertdata, revert]",
            "    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]",
            "",
            "",
            "# cost per byte of the identity precompile",
            "def _identity_gas_bound(num_bytes):",
            "    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)",
            "",
            "",
            "def _calldatacopy_gas_bound(num_bytes):",
            "    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "def _codecopy_gas_bound(num_bytes):",
            "    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "# Copy byte array word-for-word (including layout)",
            "def make_byte_array_copier(dst, src):",
            "    assert isinstance(src.typ, ByteArrayLike)",
            "    assert isinstance(dst.typ, ByteArrayLike)",
            "",
            "    if src.typ.maxlen > dst.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")",
            "    # stricter check for zeroing a byte array.",
            "    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"",
            "        )  # pragma: notest",
            "",
            "    if src.value == \"~empty\":",
            "        # set length word to 0.",
            "        return STORE(dst, 0)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src):",
            "        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):",
            "",
            "            max_bytes = src.typ.maxlen",
            "",
            "            ret = [\"seq\"]",
            "            # store length",
            "            ret.append(STORE(dst, len_))",
            "",
            "            dst = bytes_data_ptr(dst)",
            "            src = bytes_data_ptr(src)",
            "",
            "            ret.append(copy_bytes(dst, src, len_, max_bytes))",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "def bytes_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, ByteArrayLike)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def dynarray_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, DArrayType)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def _dynarray_make_setter(dst, src):",
            "    assert isinstance(src.typ, DArrayType)",
            "    assert isinstance(dst.typ, DArrayType)",
            "",
            "    if src.value == \"~empty\":",
            "        return IRnode.from_list(STORE(dst, 0))",
            "",
            "    if src.value == \"multi\":",
            "        ret = [\"seq\"]",
            "        # handle literals",
            "",
            "        # write the length word",
            "        store_length = STORE(dst, len(src.args))",
            "        ann = None",
            "        if src.annotation is not None:",
            "            ann = f\"len({src.annotation})\"",
            "        store_length = IRnode.from_list(store_length, annotation=ann)",
            "        ret.append(store_length)",
            "",
            "        n_items = len(src.args)",
            "        for i in range(n_items):",
            "            k = IRnode.from_list(i, typ=\"uint256\")",
            "            dst_i = get_element_ptr(dst, k, array_bounds_check=False)",
            "            src_i = get_element_ptr(src, k, array_bounds_check=False)",
            "            ret.append(make_setter(dst_i, src_i))",
            "",
            "        return ret",
            "",
            "    with src.cache_when_complex(\"darray_src\") as (b1, src):",
            "",
            "        # for ABI-encoded dynamic data, we must loop to unpack, since",
            "        # the layout does not match our memory layout",
            "        should_loop = (",
            "            src.encoding in (Encoding.ABI, Encoding.JSON_ABI)",
            "            and src.typ.subtype.abi_type.is_dynamic()",
            "        )",
            "",
            "        # if the subtype is dynamic, there might be a lot of",
            "        # unused space inside of each element. for instance",
            "        # DynArray[DynArray[uint256, 100], 5] where all the child",
            "        # arrays are empty - for this case, we recursively call",
            "        # into make_setter instead of straight bytes copy",
            "        # TODO we can make this heuristic more precise, e.g.",
            "        # loop when subtype.is_dynamic AND location == storage",
            "        # OR array_size <= /bound where loop is cheaper than memcpy/",
            "        should_loop |= src.typ.subtype.abi_type.is_dynamic()",
            "        should_loop |= needs_clamp(src.typ.subtype, src.encoding)",
            "",
            "        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):",
            "            ret = [\"seq\"]",
            "",
            "            ret.append(STORE(dst, count))",
            "",
            "            if should_loop:",
            "                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")",
            "",
            "                loop_body = make_setter(",
            "                    get_element_ptr(dst, i, array_bounds_check=False),",
            "                    get_element_ptr(src, i, array_bounds_check=False),",
            "                )",
            "                loop_body.annotation = f\"{dst}[i] = {src}[i]\"",
            "",
            "                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])",
            "",
            "            else:",
            "                element_size = src.typ.subtype.memory_bytes_required",
            "                # number of elements * size of element in bytes",
            "                n_bytes = _mul(count, element_size)",
            "                max_bytes = src.typ.count * element_size",
            "",
            "                src_ = dynarray_data_ptr(src)",
            "                dst_ = dynarray_data_ptr(dst)",
            "                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))",
            "",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "# Copy bytes",
            "# Accepts 4 arguments:",
            "# (i) an IR node for the start position of the source",
            "# (ii) an IR node for the start position of the destination",
            "# (iii) an IR node for the length (in bytes)",
            "# (iv) a constant for the max length (in bytes)",
            "# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may",
            "# copy an entire (32-byte) word, depending on the copy routine chosen.",
            "# TODO maybe always pad to ceil32, to reduce dirty bytes bugs",
            "def copy_bytes(dst, src, length, length_bound):",
            "    annotation = f\"copy_bytes from {src} to {dst}\"",
            "",
            "    src = IRnode.from_list(src)",
            "    dst = IRnode.from_list(dst)",
            "    length = IRnode.from_list(length)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(",
            "        \"copy_bytes_count\"",
            "    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):",
            "",
            "        # fast code for common case where num bytes is small",
            "        # TODO expand this for more cases where num words is less than ~8",
            "        if length_bound <= 32:",
            "            copy_op = STORE(dst, LOAD(src))",
            "            ret = IRnode.from_list(copy_op, annotation=annotation)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):",
            "            # special cases: batch copy to memory",
            "            # TODO: iloadbytes",
            "            if src.location == MEMORY:",
            "                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]",
            "                gas_bound = _identity_gas_bound(length_bound)",
            "            elif src.location == CALLDATA:",
            "                copy_op = [\"calldatacopy\", dst, src, length]",
            "                gas_bound = _calldatacopy_gas_bound(length_bound)",
            "            elif src.location == DATA:",
            "                copy_op = [\"dloadbytes\", dst, src, length]",
            "                # note: dloadbytes compiles to CODECOPY",
            "                gas_bound = _codecopy_gas_bound(length_bound)",
            "",
            "            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):",
            "            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)",
            "            # compile to identity, CODECOPY respectively.",
            "            pass",
            "",
            "        # general case, copy word-for-word",
            "        # pseudocode for our approach (memory-storage as example):",
            "        # for i in range(len, bound=MAX_LEN):",
            "        #   sstore(_dst + i, mload(src + i * 32))",
            "        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")",
            "",
            "        n = [\"div\", [\"ceil32\", length], 32]",
            "        n_bound = ceil32(length_bound) // 32",
            "",
            "        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))",
            "        src_i = add_ofst(src, _mul(i, src.location.word_scale))",
            "",
            "        copy_one_word = STORE(dst_i, LOAD(src_i))",
            "",
            "        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]",
            "",
            "        return b1.resolve(",
            "            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))",
            "        )",
            "",
            "",
            "# get the number of bytes at runtime",
            "def get_bytearray_length(arg):",
            "    typ = BaseType(\"uint256\")",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "# get the number of elements at runtime",
            "def get_dyn_array_count(arg):",
            "    assert isinstance(arg.typ, DArrayType)",
            "",
            "    typ = BaseType(\"uint256\")",
            "",
            "    if arg.value == \"multi\":",
            "        return IRnode.from_list(len(arg.args), typ=typ)",
            "",
            "    if arg.value == \"~empty\":",
            "        # empty(DynArray[])",
            "        return IRnode.from_list(0, typ=typ)",
            "",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "def append_dyn_array(darray_node, elem_node):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "",
            "    assert darray_node.typ.count > 0, \"jerk boy u r out\"",
            "",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        len_ = get_dyn_array_count(darray_node)",
            "        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):",
            "            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])",
            "            ret.append(STORE(darray_node, [\"add\", len_, 1]))",
            "            # NOTE: typechecks elem_node",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            ret.append(",
            "                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)",
            "            )",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)))",
            "",
            "",
            "def pop_dyn_array(darray_node, return_popped_item):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]",
            "        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")",
            "",
            "        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):",
            "            ret.append(STORE(darray_node, new_len))",
            "",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            if return_popped_item:",
            "                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)",
            "                ret.append(popped_item)",
            "                typ = popped_item.typ",
            "                location = popped_item.location",
            "                encoding = popped_item.encoding",
            "            else:",
            "                typ, location, encoding = None, None, None",
            "            return IRnode.from_list(",
            "                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding",
            "            )",
            "",
            "",
            "def getpos(node):",
            "    return (",
            "        node.lineno,",
            "        node.col_offset,",
            "        getattr(node, \"end_lineno\", None),",
            "        getattr(node, \"end_col_offset\", None),",
            "    )",
            "",
            "",
            "# TODO since this is always(?) used as add_ofst(ptr, n*ptr.location.word_scale)",
            "# maybe the API should be `add_words_to_ofst(ptr, n)` and handle the",
            "# word_scale multiplication inside",
            "def add_ofst(ptr, ofst):",
            "    ofst = IRnode.from_list(ofst)",
            "    if isinstance(ptr.value, int) and isinstance(ofst.value, int):",
            "        # NOTE: duplicate with optimizer rule (but removing this makes a",
            "        # test on --no-optimize mode use too much gas)",
            "        ret = ptr.value + ofst.value",
            "    else:",
            "        ret = [\"add\", ptr, ofst]",
            "    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)",
            "",
            "",
            "# shorthand util",
            "def _mul(x, y):",
            "    x, y = IRnode.from_list(x), IRnode.from_list(y)",
            "    # NOTE: similar deal: duplicate with optimizer rule",
            "    if isinstance(x.value, int) and isinstance(y.value, int):",
            "        ret = x.value * y.value",
            "    else:",
            "        ret = [\"mul\", x, y]",
            "    return IRnode.from_list(ret)",
            "",
            "",
            "# Resolve pointer locations for ABI-encoded data",
            "def _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):",
            "    member_abi_t = member_t.abi_type",
            "",
            "    # ABI encoding has length word and then pretends length is not there",
            "    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>",
            "    # note that inner array ofst is 0x20, not 0x40.",
            "    if has_length_word(parent.typ):",
            "        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "",
            "    ofst_ir = add_ofst(parent, ofst)",
            "",
            "    if member_abi_t.is_dynamic():",
            "        # double dereference, according to ABI spec",
            "        # TODO optimize special case: first dynamic item",
            "        # offset is statically known.",
            "        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))",
            "",
            "    return IRnode.from_list(",
            "        ofst_ir,",
            "        typ=member_t,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=f\"{parent}{ofst}\",",
            "    )",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_tuplelike(parent, key):",
            "    typ = parent.typ",
            "    assert isinstance(typ, TupleLike)",
            "",
            "    if isinstance(typ, StructType):",
            "        assert isinstance(key, str)",
            "        subtype = typ.members[key]",
            "        attrs = list(typ.tuple_keys())",
            "        index = attrs.index(key)",
            "        annotation = key",
            "    else:",
            "        assert isinstance(key, int)",
            "        subtype = typ.members[key]",
            "        attrs = list(range(len(typ.members)))",
            "        index = key",
            "        annotation = None",
            "",
            "    # generated by empty() + make_setter",
            "    if parent.value == \"~empty\":",
            "        return IRnode.from_list(\"~empty\", typ=subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"",
            "        return parent.args[index]",
            "",
            "    ofst = 0  # offset from parent start",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_t = typ.members[attrs[index]]",
            "",
            "        for i in range(index):",
            "            member_abi_t = typ.members[attrs[i]].abi_type",
            "            ofst += member_abi_t.embedded_static_size()",
            "",
            "        return _getelemptr_abi_helper(parent, member_t, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest",
            "",
            "    return IRnode.from_list(",
            "        add_ofst(parent, ofst),",
            "        typ=subtype,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=annotation,",
            "    )",
            "",
            "",
            "def has_length_word(typ):",
            "    return isinstance(typ, (DArrayType, ByteArrayLike))",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_array(parent, key, array_bounds_check):",
            "",
            "    assert isinstance(parent.typ, ArrayLike)",
            "",
            "    if not is_integer_type(key.typ):",
            "        raise TypeCheckFailure(f\"{key.typ} used as array index\")",
            "",
            "    subtype = parent.typ.subtype",
            "",
            "    if parent.value == \"~empty\":",
            "        if array_bounds_check:",
            "            # this case was previously missing a bounds check. codegen",
            "            # is a bit complicated when bounds check is required, so",
            "            # block it. there is no reason to index into a literal empty",
            "            # array anyways!",
            "            raise TypeCheckFailure(\"indexing into zero array not allowed\")",
            "        return IRnode.from_list(\"~empty\", subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert isinstance(key.value, int)",
            "        return parent.args[key.value]",
            "",
            "    ix = unwrap_location(key)",
            "",
            "    if array_bounds_check:",
            "        # clamplt works, even for signed ints. since two's-complement",
            "        # is used, if the index is negative, (unsigned) LT will interpret",
            "        # it as a very large number, larger than any practical value for",
            "        # an array index, and the clamp will throw an error.",
            "        clamp_op = \"uclamplt\"",
            "        is_darray = isinstance(parent.typ, DArrayType)",
            "        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count",
            "        # NOTE: there are optimization rules for this when ix or bound is literal",
            "        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_abi_t = subtype.abi_type",
            "",
            "        ofst = _mul(ix, member_abi_t.embedded_static_size())",
            "",
            "        return _getelemptr_abi_helper(parent, subtype, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        element_size = subtype.storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        element_size = subtype.memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "",
            "    ofst = _mul(ix, element_size)",
            "",
            "    if has_length_word(parent.typ):",
            "        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "    else:",
            "        data_ptr = parent",
            "",
            "    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)",
            "",
            "",
            "def _get_element_ptr_mapping(parent, key):",
            "    assert isinstance(parent.typ, MappingType)",
            "    subtype = parent.typ.valuetype",
            "    key = unwrap_location(key)",
            "",
            "    # TODO when is key None?",
            "    if key is None or parent.location != STORAGE:",
            "        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")",
            "",
            "    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)",
            "",
            "",
            "# Take a value representing a memory or storage location, and descend down to",
            "# an element or member variable",
            "# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.",
            "def get_element_ptr(parent, key, array_bounds_check=True):",
            "    with parent.cache_when_complex(\"val\") as (b, parent):",
            "        typ = parent.typ",
            "",
            "        if isinstance(typ, TupleLike):",
            "            ret = _get_element_ptr_tuplelike(parent, key)",
            "",
            "        elif isinstance(typ, MappingType):",
            "            ret = _get_element_ptr_mapping(parent, key)",
            "",
            "        elif isinstance(typ, ArrayLike):",
            "            ret = _get_element_ptr_array(parent, key, array_bounds_check)",
            "",
            "        else:",
            "            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest",
            "",
            "        return b.resolve(ret)",
            "",
            "",
            "def LOAD(ptr: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.load_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr])",
            "",
            "",
            "def STORE(ptr: IRnode, val: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.store_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr, val])",
            "",
            "",
            "# Unwrap location",
            "def unwrap_location(orig):",
            "    if orig.location is not None:",
            "        return IRnode.from_list(LOAD(orig), typ=orig.typ)",
            "    else:",
            "        # CMC 2022-03-24 TODO refactor so this branch can be removed",
            "        if orig.value == \"~empty\":",
            "            return IRnode.from_list(0, typ=orig.typ)",
            "        return orig",
            "",
            "",
            "# utility function, constructs an IR tuple out of a list of IR nodes",
            "def ir_tuple_from_args(args):",
            "    typ = TupleType([x.typ for x in args])",
            "    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)",
            "",
            "",
            "def _needs_external_call_wrap(ir_typ):",
            "    # for calls to ABI conforming contracts.",
            "    # according to the ABI spec, return types are ALWAYS tuples even",
            "    # if only one element is being returned.",
            "    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding",
            "    # \"and the return values v_1, ..., v_k of f are encoded as",
            "    #",
            "    #    enc((v_1, ..., v_k))",
            "    #    i.e. the values are combined into a tuple and encoded.",
            "    # \"",
            "    # therefore, wrap it in a tuple if it's not already a tuple.",
            "    # for example, `bytes` is returned as abi-encoded (bytes,)",
            "    # and `(bytes,)` is returned as abi-encoded ((bytes,),)",
            "    # In general `-> X` gets returned as (X,)",
            "    # including structs. MyStruct is returned as abi-encoded (MyStruct,).",
            "    # (Sorry this is so confusing. I didn't make these rules.)",
            "",
            "    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)",
            "",
            "",
            "def calculate_type_for_external_return(ir_typ):",
            "    if _needs_external_call_wrap(ir_typ):",
            "        return TupleType([ir_typ])",
            "    return ir_typ",
            "",
            "",
            "def wrap_value_for_external_return(ir_val):",
            "    # used for LHS promotion",
            "    if _needs_external_call_wrap(ir_val.typ):",
            "        return ir_tuple_from_args([ir_val])",
            "    else:",
            "        return ir_val",
            "",
            "",
            "def set_type_for_external_return(ir_val):",
            "    # used for RHS promotion",
            "    ir_val.typ = calculate_type_for_external_return(ir_val.typ)",
            "",
            "",
            "# return a dummy IRnode with the given type",
            "def dummy_node_for_type(typ):",
            "    return IRnode(\"fake_node\", typ=typ)",
            "",
            "",
            "def _check_assign_bytes(left, right):",
            "    if right.typ.maxlen > left.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest",
            "    # stricter check for zeroing a byte array.",
            "    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "        )  # pragma: notest",
            "",
            "",
            "def _check_assign_list(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if left.value == \"multi\":",
            "        # Cannot do something like [a, b, c] = [1, 2, 3]",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left, SArrayType):",
            "        if not isinstance(right, SArrayType):",
            "            FAIL()  # pragma: notest",
            "        if left.typ.count != right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "    if isinstance(left, DArrayType):",
            "        if not isinstance(right, DArrayType):",
            "            FAIL()  # pragma: notest",
            "",
            "        if left.typ.count < right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # stricter check for zeroing",
            "        if right.value == \"~empty\" and right.typ.count != left.typ.count:",
            "            raise TypeCheckFailure(",
            "                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "            )  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "",
            "def _check_assign_tuple(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if not isinstance(right.typ, left.typ.__class__):",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left.typ, StructType):",
            "        for k in left.typ.members:",
            "            if k not in right.typ.members:",
            "                FAIL()  # pragma: notest",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(",
            "                dummy_node_for_type(left.typ.members[k]),",
            "                dummy_node_for_type(right.typ.members[k]),",
            "            )",
            "",
            "        for k in right.typ.members:",
            "            if k not in left.typ.members:",
            "                FAIL()  # pragma: notest",
            "",
            "        if left.typ.name != right.typ.name:",
            "            FAIL()  # pragma: notest",
            "",
            "    else:",
            "        if len(left.typ.members) != len(right.typ.members):",
            "            FAIL()  # pragma: notest",
            "        for (l, r) in zip(left.typ.members, right.typ.members):",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))",
            "",
            "",
            "# sanity check an assignment",
            "# typechecking source code is done at an earlier phase",
            "# this function is more of a sanity check for typechecking internally",
            "# generated assignments",
            "def check_assign(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")",
            "",
            "    if isinstance(left.typ, ByteArrayLike):",
            "        _check_assign_bytes(left, right)",
            "    elif isinstance(left.typ, ArrayLike):",
            "        _check_assign_list(left, right)",
            "    elif isinstance(left.typ, TupleLike):",
            "        _check_assign_tuple(left, right)",
            "",
            "    elif isinstance(left.typ, BaseType):",
            "        # TODO once we propagate types from typechecker, introduce this check:",
            "        # if left.typ != right.typ:",
            "        #    FAIL()  # pragma: notest",
            "        pass",
            "",
            "    else:  # pragma: nocover",
            "        FAIL()",
            "",
            "",
            "_label = 0",
            "",
            "",
            "# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol",
            "def _freshname(name):",
            "    global _label",
            "    _label += 1",
            "    return f\"{name}{_label}\"",
            "",
            "",
            "# returns True if t is ABI encoded and is a type that needs any kind of",
            "# validation",
            "def needs_clamp(t, encoding):",
            "    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):",
            "        return False",
            "    if isinstance(t, (ByteArrayLike, DArrayType)):",
            "        if encoding == Encoding.JSON_ABI:",
            "            # don't have bytestring size bound from json, don't clamp",
            "            return False",
            "        return True",
            "    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):",
            "        return True",
            "    if isinstance(t, SArrayType):",
            "        return needs_clamp(t.subtype, encoding)",
            "    if isinstance(t, TupleLike):",
            "        return any(needs_clamp(m, encoding) for m in t.tuple_members())",
            "    return False",
            "",
            "",
            "# Create an x=y statement, where the types may be compound",
            "def make_setter(left, right):",
            "    check_assign(left, right)",
            "",
            "    # Basic types",
            "    if isinstance(left.typ, BaseType):",
            "        enc = right.encoding  # unwrap_location butchers encoding",
            "        right = unwrap_location(right)",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, enc):",
            "            right = clamp_basetype(right)",
            "",
            "        return STORE(left, right)",
            "",
            "    # Byte arrays",
            "    elif isinstance(left.typ, ByteArrayLike):",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"bs_ptr\") as (b, right):",
            "                copier = make_byte_array_copier(left, right)",
            "                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])",
            "        else:",
            "            ret = make_byte_array_copier(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    elif isinstance(left.typ, DArrayType):",
            "        # TODO should we enable this?",
            "        # implicit conversion from sarray to darray",
            "        # if isinstance(right.typ, SArrayType):",
            "        #    return _complex_make_setter(left, right)",
            "",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"arr_ptr\") as (b, right):",
            "                copier = _dynarray_make_setter(left, right)",
            "                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])",
            "        else:",
            "            ret = _dynarray_make_setter(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    # Arrays",
            "    elif isinstance(left.typ, (SArrayType, TupleLike)):",
            "        return _complex_make_setter(left, right)",
            "",
            "",
            "def _complex_make_setter(left, right):",
            "    if right.value == \"~empty\" and left.location == MEMORY:",
            "        # optimized memzero",
            "        return mzero(left, left.typ.memory_bytes_required)",
            "",
            "    ret = [\"seq\"]",
            "",
            "    if isinstance(left.typ, SArrayType):",
            "        n_items = right.typ.count",
            "        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]",
            "",
            "    if isinstance(left.typ, TupleLike):",
            "        keys = left.typ.tuple_keys()",
            "",
            "    # if len(keyz) == 0:",
            "    #    return IRnode.from_list([\"pass\"])",
            "",
            "    # general case",
            "    # TODO use copy_bytes when the generated code is above a certain size",
            "    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):",
            "",
            "        for k in keys:",
            "            l_i = get_element_ptr(left, k, array_bounds_check=False)",
            "            r_i = get_element_ptr(right, k, array_bounds_check=False)",
            "            ret.append(make_setter(l_i, r_i))",
            "",
            "        return b1.resolve(b2.resolve(IRnode.from_list(ret)))",
            "",
            "",
            "def ensure_in_memory(ir_var, context):",
            "    \"\"\"Ensure a variable is in memory. This is useful for functions",
            "    which expect to operate on memory variables.",
            "    \"\"\"",
            "    if ir_var.location == MEMORY:",
            "        return ir_var",
            "",
            "    typ = ir_var.typ",
            "    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)",
            "    do_copy = make_setter(buf, ir_var)",
            "",
            "    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)",
            "",
            "",
            "def eval_seq(ir_node):",
            "    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so",
            "    that the value can be known without possibly evaluating side effects",
            "    \"\"\"",
            "    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:",
            "        return eval_seq(ir_node.args[-1])",
            "    if isinstance(ir_node.value, int):",
            "        return IRnode.from_list(ir_node)",
            "    return None",
            "",
            "",
            "# TODO move return checks to vyper/semantics/validation",
            "def is_return_from_function(node):",
            "    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":",
            "        return True",
            "    if isinstance(node, vy_ast.Return):",
            "        return True",
            "    elif isinstance(node, vy_ast.Raise):",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def check_single_exit(fn_node):",
            "    _check_return_body(fn_node, fn_node.body)",
            "    for node in fn_node.get_descendants(vy_ast.If):",
            "        _check_return_body(node, node.body)",
            "        if node.orelse:",
            "            _check_return_body(node, node.orelse)",
            "",
            "",
            "def _check_return_body(node, node_list):",
            "    return_count = len([n for n in node_list if is_return_from_function(n)])",
            "    if return_count > 1:",
            "        raise StructureException(",
            "            \"Too too many exit statements (return, raise or selfdestruct).\", node",
            "        )",
            "    # Check for invalid code after returns.",
            "    last_node_pos = len(node_list) - 1",
            "    for idx, n in enumerate(node_list):",
            "        if is_return_from_function(n) and idx < last_node_pos:",
            "            # is not last statement in body.",
            "            raise StructureException(",
            "                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]",
            "            )",
            "",
            "",
            "def mzero(dst, nbytes):",
            "    # calldatacopy from past-the-end gives zero bytes.",
            "    # cf. YP H.2 (ops section) with CALLDATACOPY spec.",
            "    return IRnode.from_list(",
            "        # calldatacopy mempos calldatapos len",
            "        [\"calldatacopy\", dst, \"calldatasize\", nbytes],",
            "        annotation=\"mzero\",",
            "    )",
            "",
            "",
            "# zero pad a bytearray according to the ABI spec. The last word",
            "# of the byte array needs to be right-padded with zeroes.",
            "def zero_pad(bytez_placeholder):",
            "    len_ = [\"mload\", bytez_placeholder]",
            "    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]",
            "    # the runtime length of the data rounded up to nearest 32",
            "    # from spec:",
            "    #   the actual value of X as a byte sequence,",
            "    #   followed by the *minimum* number of zero-bytes",
            "    #   such that len(enc(X)) is a multiple of 32.",
            "    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]",
            "    return IRnode.from_list(",
            "        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],",
            "        annotation=\"Zero pad\",",
            "    )",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shr(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shr\", bits, x]",
            "    return [\"div\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shl(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shl\", bits, x]",
            "    return [\"mul\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "def sar(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"sar\", bits, x]",
            "",
            "    # emulate for older arches. keep in mind note from EIP 145:",
            "    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds",
            "    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"",
            "    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]",
            "",
            "",
            "def clamp_bytestring(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, ByteArrayLike):",
            "        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest",
            "    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]",
            "",
            "",
            "def clamp_dyn_array(ir_node):",
            "    t = ir_node.typ",
            "    assert isinstance(t, DArrayType)",
            "    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]",
            "",
            "",
            "# clampers for basetype",
            "def clamp_basetype(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, BaseType):",
            "        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "    # copy of the input",
            "    ir_node = unwrap_location(ir_node)",
            "",
            "    if is_integer_type(t) or is_decimal_type(t):",
            "        if t._num_info.bits == 256:",
            "            return ir_node",
            "        else:",
            "            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)",
            "",
            "    if is_bytes_m_type(t):",
            "        if t._bytes_info.m == 32:",
            "            return ir_node  # special case, no clamp.",
            "        else:",
            "            return bytes_clamp(ir_node, t._bytes_info.m)",
            "",
            "    if t.typ in (\"address\",):",
            "        return int_clamp(ir_node, 160)",
            "    if t.typ in (\"bool\",):",
            "        return int_clamp(ir_node, 1)",
            "",
            "    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "",
            "def int_clamp(ir_node, bits, signed=False):",
            "    \"\"\"Generalized clamper for integer types. Takes the number of bits,",
            "    whether it's signed, and returns an IR node which checks it is",
            "    in bounds. (Consumers should use clamp_basetype instead which uses",
            "    type-based dispatch and is a little safer.)",
            "    \"\"\"",
            "    if bits >= 256:",
            "        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        if signed:",
            "            # example for bits==128:",
            "            # promote_signed_int(val, bits) is the \"canonical\" version of val",
            "            # if val is in bounds, the bits above bit 128 should be equal.",
            "            # (this works for both val >= 0 and val < 0. in the first case,",
            "            # all upper bits should be 0 if val is a valid int128,",
            "            # in the latter case, all upper bits should be 1.)",
            "            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]",
            "        else:",
            "            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]",
            "",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "",
            "    # TODO fix this annotation",
            "    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")",
            "",
            "",
            "def bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:",
            "    if not (0 < n_bytes <= 32):",
            "        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")",
            "",
            "",
            "# e.g. for int8, promote 255 to -1",
            "def promote_signed_int(x, bits):",
            "    assert bits % 8 == 0",
            "    ret = [\"signextend\", bits // 8 - 1, x]",
            "    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "189": [
                "copy_bytes"
            ]
        },
        "addLocation": []
    },
    "vyper/codegen/expr.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from vyper.address_space import DATA, IMMUTABLES, MEMORY, STORAGE"
            },
            "1": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from vyper.codegen import external_call, self_call"
            },
            "2": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from vyper.codegen.core import ("
            },
            "3": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOAD,"
            },
            "4": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    bytes_data_ptr,"
            },
            "5": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     clamp_basetype,"
            },
            "6": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 9,
                "PatchRowcode": "     ensure_in_memory,"
            },
            "7": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 10,
                "PatchRowcode": "     get_dyn_array_count,"
            },
            "8": {
                "beforePatchRowNumber": 801,
                "afterPatchRowNumber": 799,
                "PatchRowcode": "             left = Expr(self.expr.left, self.context).ir_node"
            },
            "9": {
                "beforePatchRowNumber": 802,
                "afterPatchRowNumber": 800,
                "PatchRowcode": "             right = Expr(self.expr.right, self.context).ir_node"
            },
            "10": {
                "beforePatchRowNumber": 803,
                "afterPatchRowNumber": 801,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 804,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            length_mismatch = left.typ.maxlen != right.typ.maxlen"
            },
            "12": {
                "beforePatchRowNumber": 805,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            left_over_32 = left.typ.maxlen > 32"
            },
            "13": {
                "beforePatchRowNumber": 806,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            right_over_32 = right.typ.maxlen > 32"
            },
            "14": {
                "beforePatchRowNumber": 807,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "15": {
                "beforePatchRowNumber": 808,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if length_mismatch or left_over_32 or right_over_32:"
            },
            "16": {
                "beforePatchRowNumber": 809,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                left_keccak = keccak256_helper(self.expr, left, self.context)"
            },
            "17": {
                "beforePatchRowNumber": 810,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                right_keccak = keccak256_helper(self.expr, right, self.context)"
            },
            "18": {
                "beforePatchRowNumber": 811,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "19": {
                "beforePatchRowNumber": 812,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if op == \"eq\" or op == \"ne\":"
            },
            "20": {
                "beforePatchRowNumber": 813,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")"
            },
            "21": {
                "beforePatchRowNumber": 814,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "22": {
                "beforePatchRowNumber": 815,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                else:"
            },
            "23": {
                "beforePatchRowNumber": 816,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 802,
                "PatchRowcode": "+            left_keccak = keccak256_helper(self.expr, left, self.context)"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 803,
                "PatchRowcode": "+            right_keccak = keccak256_helper(self.expr, right, self.context)"
            },
            "26": {
                "beforePatchRowNumber": 817,
                "afterPatchRowNumber": 804,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 805,
                "PatchRowcode": "+            if op not in (\"eq\", \"ne\"):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 806,
                "PatchRowcode": "+                return  # raises"
            },
            "29": {
                "beforePatchRowNumber": 818,
                "afterPatchRowNumber": 807,
                "PatchRowcode": "             else:"
            },
            "30": {
                "beforePatchRowNumber": 819,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "31": {
                "beforePatchRowNumber": 820,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                def load_bytearray(side):"
            },
            "32": {
                "beforePatchRowNumber": 821,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return LOAD(bytes_data_ptr(side))"
            },
            "33": {
                "beforePatchRowNumber": 822,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "34": {
                "beforePatchRowNumber": 823,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return IRnode.from_list("
            },
            "35": {
                "beforePatchRowNumber": 824,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # CMC 2022-03-24 TODO investigate this."
            },
            "36": {
                "beforePatchRowNumber": 825,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    [op, load_bytearray(left), load_bytearray(right)],"
            },
            "37": {
                "beforePatchRowNumber": 826,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    typ=\"bool\","
            },
            "38": {
                "beforePatchRowNumber": 827,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 808,
                "PatchRowcode": "+                # use hash even for Bytes[N<=32], because there could be dirty"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 809,
                "PatchRowcode": "+                # bytes past the bytes data."
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 810,
                "PatchRowcode": "+                return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")"
            },
            "42": {
                "beforePatchRowNumber": 828,
                "afterPatchRowNumber": 811,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 829,
                "afterPatchRowNumber": 812,
                "PatchRowcode": "         # Compare other types."
            },
            "44": {
                "beforePatchRowNumber": 830,
                "afterPatchRowNumber": 813,
                "PatchRowcode": "         elif is_numeric_type(left.typ) and is_numeric_type(right.typ):"
            }
        },
        "frontPatchFile": [
            "import decimal",
            "import math",
            "",
            "from vyper import ast as vy_ast",
            "from vyper.address_space import DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen import external_call, self_call",
            "from vyper.codegen.core import (",
            "    LOAD,",
            "    bytes_data_ptr,",
            "    clamp_basetype,",
            "    ensure_in_memory,",
            "    get_dyn_array_count,",
            "    get_element_ptr,",
            "    getpos,",
            "    make_setter,",
            "    pop_dyn_array,",
            "    unwrap_location,",
            ")",
            "from vyper.codegen.ir_node import IRnode",
            "from vyper.codegen.keccak256_helper import keccak256_helper",
            "from vyper.codegen.types import (",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    ByteArrayType,",
            "    DArrayType,",
            "    InterfaceType,",
            "    MappingType,",
            "    SArrayType,",
            "    StringType,",
            "    StructType,",
            "    TupleType,",
            "    is_base_type,",
            "    is_numeric_type,",
            ")",
            "from vyper.codegen.types.convert import new_type_to_old_type",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import (",
            "    CompilerPanic,",
            "    EvmVersionException,",
            "    StructureException,",
            "    TypeCheckFailure,",
            "    TypeMismatch,",
            ")",
            "from vyper.utils import DECIMAL_DIVISOR, SizeLimits, bytes_to_int, checksum_encode, string_to_bytes",
            "",
            "ENVIRONMENT_VARIABLES = {",
            "    \"block\",",
            "    \"msg\",",
            "    \"tx\",",
            "    \"chain\",",
            "}",
            "",
            "",
            "def calculate_largest_power(a: int, num_bits: int, is_signed: bool) -> int:",
            "    \"\"\"",
            "    For a given base `a`, compute the maximum power `b` that will not",
            "    produce an overflow in the equation `a ** b`",
            "",
            "    Arguments",
            "    ---------",
            "    a : int",
            "        Base value for the equation `a ** b`",
            "    num_bits : int",
            "        The maximum number of bits that the resulting value must fit in",
            "    is_signed : bool",
            "        Is the operation being performed on signed integers?",
            "",
            "    Returns",
            "    -------",
            "    int",
            "        Largest possible value for `b` where the result does not overflow",
            "        `num_bits`",
            "    \"\"\"",
            "    if num_bits % 8:",
            "        raise CompilerPanic(\"Type is not a modulo of 8\")",
            "",
            "    value_bits = num_bits - (1 if is_signed else 0)",
            "    if a >= 2 ** value_bits:",
            "        raise TypeCheckFailure(\"Value is too large and will always throw\")",
            "    elif a < -(2 ** value_bits):",
            "        raise TypeCheckFailure(\"Value is too small and will always throw\")",
            "",
            "    a_is_negative = a < 0",
            "    a = abs(a)  # No longer need to know if it's signed or not",
            "    if a in (0, 1):",
            "        raise CompilerPanic(\"Exponential operation is useless!\")",
            "",
            "    # NOTE: There is an edge case if `a` were left signed where the following",
            "    #       operation would not work (`ln(a)` is undefined if `a <= 0`)",
            "    b = int(decimal.Decimal(value_bits) / (decimal.Decimal(a).ln() / decimal.Decimal(2).ln()))",
            "    if b <= 1:",
            "        return 1  # Value is assumed to be in range, therefore power of 1 is max",
            "",
            "    # Do a bit of iteration to ensure we have the exact number",
            "    num_iterations = 0",
            "    while a ** (b + 1) < 2 ** value_bits:",
            "        b += 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "    while a ** b >= 2 ** value_bits:",
            "        b -= 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "",
            "    # Edge case: If a is negative and the values of a and b are such that:",
            "    #               (a) ** (b + 1) == -(2 ** value_bits)",
            "    #            we can actually squeak one more out of it because it's on the edge",
            "    if a_is_negative and (-a) ** (b + 1) == -(2 ** value_bits):  # NOTE: a = abs(a)",
            "        return b + 1",
            "    else:",
            "        return b  # Exact",
            "",
            "",
            "def calculate_largest_base(b: int, num_bits: int, is_signed: bool) -> int:",
            "    \"\"\"",
            "    For a given power `b`, compute the maximum base `a` that will not produce an",
            "    overflow in the equation `a ** b`",
            "",
            "    Arguments",
            "    ---------",
            "    b : int",
            "        Power value for the equation `a ** b`",
            "    num_bits : int",
            "        The maximum number of bits that the resulting value must fit in",
            "    is_signed : bool",
            "        Is the operation being performed on signed integers?",
            "",
            "    Returns",
            "    -------",
            "    int",
            "        Largest possible value for `a` where the result does not overflow",
            "        `num_bits`",
            "    \"\"\"",
            "    if num_bits % 8:",
            "        raise CompilerPanic(\"Type is not a modulo of 8\")",
            "    if b < 0:",
            "        raise TypeCheckFailure(\"Cannot calculate negative exponents\")",
            "",
            "    value_bits = num_bits - (1 if is_signed else 0)",
            "    if b > value_bits:",
            "        raise TypeCheckFailure(\"Value is too large and will always throw\")",
            "    elif b < 2:",
            "        return 2 ** value_bits - 1  # Maximum value for type",
            "",
            "    # Estimate (up to ~39 digits precision required)",
            "    a = math.ceil(2 ** (decimal.Decimal(value_bits) / decimal.Decimal(b)))",
            "    # Do a bit of iteration to ensure we have the exact number",
            "    num_iterations = 0",
            "    while (a + 1) ** b < 2 ** value_bits:",
            "        a += 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "    while a ** b >= 2 ** value_bits:",
            "        a -= 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "",
            "    return a",
            "",
            "",
            "class Expr:",
            "    # TODO: Once other refactors are made reevaluate all inline imports",
            "",
            "    def __init__(self, node, context):",
            "        self.expr = node",
            "        self.context = context",
            "",
            "        if isinstance(node, IRnode):",
            "            # TODO this seems bad",
            "            self.ir_node = node",
            "            return",
            "",
            "        fn = getattr(self, f\"parse_{type(node).__name__}\", None)",
            "        if fn is None:",
            "            raise TypeCheckFailure(f\"Invalid statement node: {type(node).__name__}\")",
            "",
            "        self.ir_node = fn()",
            "        if self.ir_node is None:",
            "            raise TypeCheckFailure(f\"{type(node).__name__} node did not produce IR. {self.expr}\")",
            "",
            "        self.ir_node.annotation = self.expr.get(\"node_source_code\")",
            "        self.ir_node.source_pos = getpos(self.expr)",
            "",
            "    def parse_Int(self):",
            "        # Literal (mostly likely) becomes int256",
            "        if self.expr.n < 0:",
            "            return IRnode.from_list(self.expr.n, typ=BaseType(\"int256\", is_literal=True))",
            "        # Literal is large enough (mostly likely) becomes uint256.",
            "        else:",
            "            return IRnode.from_list(self.expr.n, typ=BaseType(\"uint256\", is_literal=True))",
            "",
            "    def parse_Decimal(self):",
            "        val = self.expr.value * DECIMAL_DIVISOR",
            "",
            "        # sanity check that type checker did its job",
            "        assert isinstance(val, decimal.Decimal)",
            "        assert SizeLimits.in_bounds(\"decimal\", val)",
            "        assert math.ceil(val) == math.floor(val)",
            "",
            "        val = int(val)",
            "",
            "        return IRnode.from_list(val, typ=BaseType(\"decimal\", is_literal=True))",
            "",
            "    def parse_Hex(self):",
            "        hexstr = self.expr.value",
            "",
            "        if len(hexstr) == 42:",
            "            # sanity check typechecker did its job",
            "            assert checksum_encode(hexstr) == hexstr",
            "            typ = BaseType(\"address\")",
            "            # TODO allow non-checksum encoded bytes20",
            "            return IRnode.from_list(int(self.expr.value, 16), typ=typ)",
            "",
            "        else:",
            "            n_bytes = (len(hexstr) - 2) // 2  # e.g. \"0x1234\" is 2 bytes",
            "            # TODO: typ = new_type_to_old_type(self.expr._metadata[\"type\"])",
            "            #       assert n_bytes == typ._bytes_info.m",
            "",
            "            # bytes_m types are left padded with zeros",
            "            val = int(hexstr, 16) << 8 * (32 - n_bytes)",
            "",
            "            typ = BaseType(f\"bytes{n_bytes}\", is_literal=True)",
            "            typ.is_literal = True",
            "            return IRnode.from_list(val, typ=typ)",
            "",
            "    # String literals",
            "    def parse_Str(self):",
            "        bytez, bytez_length = string_to_bytes(self.expr.value)",
            "        typ = StringType(bytez_length, is_literal=True)",
            "        return self._make_bytelike(typ, bytez, bytez_length)",
            "",
            "    # Byte literals",
            "    def parse_Bytes(self):",
            "        bytez = self.expr.s",
            "        bytez_length = len(self.expr.s)",
            "        typ = ByteArrayType(bytez_length, is_literal=True)",
            "        return self._make_bytelike(typ, bytez, bytez_length)",
            "",
            "    def _make_bytelike(self, btype, bytez, bytez_length):",
            "        placeholder = self.context.new_internal_variable(btype)",
            "        seq = []",
            "        seq.append([\"mstore\", placeholder, bytez_length])",
            "        for i in range(0, len(bytez), 32):",
            "            seq.append(",
            "                [",
            "                    \"mstore\",",
            "                    [\"add\", placeholder, i + 32],",
            "                    bytes_to_int((bytez + b\"\\x00\" * 31)[i : i + 32]),",
            "                ]",
            "            )",
            "        return IRnode.from_list(",
            "            [\"seq\"] + seq + [placeholder],",
            "            typ=btype,",
            "            location=MEMORY,",
            "            annotation=f\"Create {btype}: {bytez}\",",
            "        )",
            "",
            "    # True, False, None constants",
            "    def parse_NameConstant(self):",
            "        if self.expr.value is True:",
            "            return IRnode.from_list(1, typ=BaseType(\"bool\", is_literal=True))",
            "        elif self.expr.value is False:",
            "            return IRnode.from_list(0, typ=BaseType(\"bool\", is_literal=True))",
            "",
            "    # Variable names",
            "    def parse_Name(self):",
            "",
            "        if self.expr.id == \"self\":",
            "            return IRnode.from_list([\"address\"], typ=\"address\")",
            "        elif self.expr.id in self.context.vars:",
            "            var = self.context.vars[self.expr.id]",
            "            return IRnode.from_list(",
            "                var.pos,",
            "                typ=var.typ,",
            "                location=var.location,  # either 'memory' or 'calldata' storage is handled above.",
            "                encoding=var.encoding,",
            "                annotation=self.expr.id,",
            "                mutable=var.mutable,",
            "            )",
            "",
            "        elif self.expr._metadata[\"type\"].is_immutable:",
            "            var = self.context.globals[self.expr.id]",
            "            ofst = self.expr._metadata[\"type\"].position.offset",
            "",
            "            if self.context.sig.is_init_func:",
            "                mutable = True",
            "                location = IMMUTABLES",
            "            else:",
            "                mutable = False",
            "                location = DATA",
            "",
            "            return IRnode.from_list(",
            "                ofst,",
            "                typ=var.typ,",
            "                location=location,",
            "                annotation=self.expr.id,",
            "                mutable=mutable,",
            "            )",
            "",
            "    # x.y or x[5]",
            "    def parse_Attribute(self):",
            "        # x.balance: balance of address x",
            "        if self.expr.attr == \"balance\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                if (",
            "                    isinstance(self.expr.value, vy_ast.Name)",
            "                    and self.expr.value.id == \"self\"",
            "                    and version_check(begin=\"istanbul\")",
            "                ):",
            "                    seq = [\"selfbalance\"]",
            "                else:",
            "                    seq = [\"balance\", addr]",
            "                return IRnode.from_list(seq, typ=BaseType(\"uint256\"))",
            "        # x.codesize: codesize of address x",
            "        elif self.expr.attr == \"codesize\" or self.expr.attr == \"is_contract\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                if self.expr.attr == \"codesize\":",
            "                    if self.expr.value.id == \"self\":",
            "                        eval_code = [\"codesize\"]",
            "                    else:",
            "                        eval_code = [\"extcodesize\", addr]",
            "                    output_type = \"uint256\"",
            "                else:",
            "                    eval_code = [\"gt\", [\"extcodesize\", addr], 0]",
            "                    output_type = \"bool\"",
            "                return IRnode.from_list(eval_code, typ=BaseType(output_type))",
            "        # x.codehash: keccak of address x",
            "        elif self.expr.attr == \"codehash\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if not version_check(begin=\"constantinople\"):",
            "                raise EvmVersionException(",
            "                    \"address.codehash is unavailable prior to constantinople ruleset\", self.expr",
            "                )",
            "            if is_base_type(addr.typ, \"address\"):",
            "                return IRnode.from_list([\"extcodehash\", addr], typ=BaseType(\"bytes32\"))",
            "        # x.code: codecopy/extcodecopy of address x",
            "        elif self.expr.attr == \"code\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                # These adhoc nodes will be replaced with a valid node in `Slice.build_IR`",
            "                if addr.value == \"address\":  # for `self.code`",
            "                    return IRnode.from_list([\"~selfcode\"], typ=ByteArrayType(0))",
            "                return IRnode.from_list([\"~extcode\", addr], typ=ByteArrayType(0))",
            "        # self.x: global attribute",
            "        elif isinstance(self.expr.value, vy_ast.Name) and self.expr.value.id == \"self\":",
            "            type_ = self.expr._metadata[\"type\"]",
            "            var = self.context.globals[self.expr.attr]",
            "            return IRnode.from_list(",
            "                type_.position.position,",
            "                typ=var.typ,",
            "                location=STORAGE,",
            "                annotation=\"self.\" + self.expr.attr,",
            "            )",
            "        # Reserved keywords",
            "        elif (",
            "            isinstance(self.expr.value, vy_ast.Name) and self.expr.value.id in ENVIRONMENT_VARIABLES",
            "        ):",
            "            key = f\"{self.expr.value.id}.{self.expr.attr}\"",
            "            if key == \"msg.sender\":",
            "                return IRnode.from_list([\"caller\"], typ=\"address\")",
            "            elif key == \"msg.data\":",
            "                # This adhoc node will be replaced with a valid node in `Slice/Len.build_IR`",
            "                return IRnode.from_list([\"~calldata\"], typ=ByteArrayType(0))",
            "            elif key == \"msg.value\" and self.context.is_payable:",
            "                return IRnode.from_list([\"callvalue\"], typ=BaseType(\"uint256\"))",
            "            elif key == \"msg.gas\":",
            "                return IRnode.from_list([\"gas\"], typ=\"uint256\")",
            "            elif key == \"block.difficulty\":",
            "                return IRnode.from_list([\"difficulty\"], typ=\"uint256\")",
            "            elif key == \"block.timestamp\":",
            "                return IRnode.from_list([\"timestamp\"], typ=BaseType(\"uint256\"))",
            "            elif key == \"block.coinbase\":",
            "                return IRnode.from_list([\"coinbase\"], typ=\"address\")",
            "            elif key == \"block.number\":",
            "                return IRnode.from_list([\"number\"], typ=\"uint256\")",
            "            elif key == \"block.gaslimit\":",
            "                return IRnode.from_list([\"gaslimit\"], typ=\"uint256\")",
            "            elif key == \"block.basefee\":",
            "                return IRnode.from_list([\"basefee\"], typ=\"uint256\")",
            "            elif key == \"block.prevhash\":",
            "                return IRnode.from_list([\"blockhash\", [\"sub\", \"number\", 1]], typ=\"bytes32\")",
            "            elif key == \"tx.origin\":",
            "                return IRnode.from_list([\"origin\"], typ=\"address\")",
            "            elif key == \"tx.gasprice\":",
            "                return IRnode.from_list([\"gasprice\"], typ=\"uint256\")",
            "            elif key == \"chain.id\":",
            "                if not version_check(begin=\"istanbul\"):",
            "                    raise EvmVersionException(",
            "                        \"chain.id is unavailable prior to istanbul ruleset\", self.expr",
            "                    )",
            "                return IRnode.from_list([\"chainid\"], typ=\"uint256\")",
            "        # Other variables",
            "        else:",
            "            sub = Expr(self.expr.value, self.context).ir_node",
            "            # contract type",
            "            if isinstance(sub.typ, InterfaceType):",
            "                return sub",
            "            if isinstance(sub.typ, StructType) and self.expr.attr in sub.typ.members:",
            "                return get_element_ptr(sub, self.expr.attr)",
            "",
            "    def parse_Subscript(self):",
            "        sub = Expr(self.expr.value, self.context).ir_node",
            "        if sub.value == \"multi\":",
            "            # force literal to memory, e.g.",
            "            # MY_LIST: constant(decimal[6])",
            "            # ...",
            "            # return MY_LIST[ix]",
            "            sub = ensure_in_memory(sub, self.context)",
            "",
            "        if isinstance(sub.typ, MappingType):",
            "            # TODO sanity check we are in a self.my_map[i] situation",
            "            index = Expr.parse_value_expr(self.expr.slice.value, self.context)",
            "            if isinstance(index.typ, ByteArrayLike):",
            "                # we have to hash the key to get a storage location",
            "                assert len(index.args) == 1",
            "                index = keccak256_helper(self.expr.slice.value, index.args[0], self.context)",
            "",
            "        elif isinstance(sub.typ, ArrayLike):",
            "            index = Expr.parse_value_expr(self.expr.slice.value, self.context)",
            "",
            "        elif isinstance(sub.typ, TupleType):",
            "            index = self.expr.slice.value.n",
            "            # note: this check should also happen in get_element_ptr",
            "            if not 0 <= index < len(sub.typ.members):",
            "                return",
            "        else:",
            "            return",
            "",
            "        ir_node = get_element_ptr(sub, index)",
            "        ir_node.mutable = sub.mutable",
            "        return ir_node",
            "",
            "    def parse_BinOp(self):",
            "        left = Expr.parse_value_expr(self.expr.left, self.context)",
            "        right = Expr.parse_value_expr(self.expr.right, self.context)",
            "",
            "        if not is_numeric_type(left.typ) or not is_numeric_type(right.typ):",
            "            return",
            "",
            "        types = {left.typ.typ, right.typ.typ}",
            "        literals = {left.typ.is_literal, right.typ.is_literal}",
            "",
            "        # If one value of the operation is a literal, we recast it to match the non-literal type.",
            "        # We know this is OK because types were already verified in the actual typechecking pass.",
            "        # This is a temporary solution to not break codegen while we work toward removing types",
            "        # altogether at this stage of complition. @iamdefinitelyahuman",
            "        if literals == {True, False} and len(types) > 1 and \"decimal\" not in types:",
            "            if left.typ.is_literal and SizeLimits.in_bounds(right.typ.typ, left.value):",
            "                left = IRnode.from_list(left.value, typ=BaseType(right.typ.typ, is_literal=True))",
            "            elif right.typ.is_literal and SizeLimits.in_bounds(left.typ.typ, right.value):",
            "                right = IRnode.from_list(right.value, typ=BaseType(left.typ.typ, is_literal=True))",
            "",
            "        ltyp, rtyp = left.typ.typ, right.typ.typ",
            "",
            "        # Sanity check - ensure that we aren't dealing with different types",
            "        # This should be unreachable due to the type check pass",
            "        assert ltyp == rtyp, \"unreachable\"",
            "",
            "        arith = None",
            "        if isinstance(self.expr.op, (vy_ast.Add, vy_ast.Sub)):",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if ltyp == \"uint256\":",
            "                if isinstance(self.expr.op, vy_ast.Add):",
            "                    # safeadd",
            "                    arith = [\"seq\", [\"assert\", [\"ge\", [\"add\", \"l\", \"r\"], \"l\"]], [\"add\", \"l\", \"r\"]]",
            "",
            "                elif isinstance(self.expr.op, vy_ast.Sub):",
            "                    # safesub",
            "                    arith = [\"seq\", [\"assert\", [\"ge\", \"l\", \"r\"]], [\"sub\", \"l\", \"r\"]]",
            "",
            "            elif ltyp == \"int256\":",
            "                if isinstance(self.expr.op, vy_ast.Add):",
            "                    op, comp1, comp2 = \"add\", \"sge\", \"slt\"",
            "                else:",
            "                    op, comp1, comp2 = \"sub\", \"sle\", \"sgt\"",
            "",
            "                if right.typ.is_literal:",
            "                    if right.value >= 0:",
            "                        arith = [\"seq\", [\"assert\", [comp1, [op, \"l\", \"r\"], \"l\"]], [op, \"l\", \"r\"]]",
            "                    else:",
            "                        arith = [\"seq\", [\"assert\", [comp2, [op, \"l\", \"r\"], \"l\"]], [op, \"l\", \"r\"]]",
            "                else:",
            "                    arith = [",
            "                        \"with\",",
            "                        \"ans\",",
            "                        [op, \"l\", \"r\"],",
            "                        [",
            "                            \"seq\",",
            "                            [",
            "                                \"assert\",",
            "                                [",
            "                                    \"or\",",
            "                                    [\"and\", [\"sge\", \"r\", 0], [comp1, \"ans\", \"l\"]],",
            "                                    [\"and\", [\"slt\", \"r\", 0], [comp2, \"ans\", \"l\"]],",
            "                                ],",
            "                            ],",
            "                            \"ans\",",
            "                        ],",
            "                    ]",
            "",
            "            elif ltyp in (\"decimal\", \"int128\", \"uint8\"):",
            "                op = \"add\" if isinstance(self.expr.op, vy_ast.Add) else \"sub\"",
            "                arith = [op, \"l\", \"r\"]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Mult):",
            "            new_typ = BaseType(ltyp)",
            "            if ltyp == \"uint256\":",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        [\"assert\", [\"or\", [\"eq\", [\"div\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        \"ans\",",
            "                    ],",
            "                ]",
            "",
            "            elif ltyp == \"int256\":",
            "                if version_check(begin=\"constantinople\"):",
            "                    upper_bound = [\"shl\", 255, 1]",
            "                else:",
            "                    upper_bound = -(2 ** 255)",
            "                if not left.typ.is_literal and not right.typ.is_literal:",
            "                    bounds_check = [",
            "                        \"assert\",",
            "                        [\"or\", [\"ne\", \"l\", [\"not\", 0]], [\"ne\", \"r\", upper_bound]],",
            "                    ]",
            "                elif left.typ.is_literal and left.value == -1:",
            "                    bounds_check = [\"assert\", [\"ne\", \"r\", upper_bound]]",
            "                elif right.typ.is_literal and right.value == -(2 ** 255):",
            "                    bounds_check = [\"assert\", [\"ne\", \"l\", [\"not\", 0]]]",
            "                else:",
            "                    bounds_check = \"pass\"",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        bounds_check,",
            "                        [\"assert\", [\"or\", [\"eq\", [\"sdiv\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        \"ans\",",
            "                    ],",
            "                ]",
            "",
            "            elif ltyp in (\"int128\", \"uint8\"):",
            "                arith = [\"mul\", \"l\", \"r\"]",
            "",
            "            elif ltyp == \"decimal\":",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        [\"assert\", [\"or\", [\"eq\", [\"sdiv\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        [\"sdiv\", \"ans\", DECIMAL_DIVISOR],",
            "                    ],",
            "                ]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Div):",
            "            if right.typ.is_literal and right.value == 0:",
            "                return",
            "",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if right.typ.is_literal:",
            "                divisor = \"r\"",
            "            else:",
            "                # only apply the non-zero clamp when r is not a constant",
            "                divisor = [\"clamp_nonzero\", \"r\"]",
            "",
            "            if ltyp in (\"uint8\", \"uint256\"):",
            "                arith = [\"div\", \"l\", divisor]",
            "",
            "            elif ltyp == \"int256\":",
            "                if version_check(begin=\"constantinople\"):",
            "                    upper_bound = [\"shl\", 255, 1]",
            "                else:",
            "                    upper_bound = -(2 ** 255)",
            "                if not left.typ.is_literal and not right.typ.is_literal:",
            "                    bounds_check = [",
            "                        \"assert\",",
            "                        [\"or\", [\"ne\", \"r\", [\"not\", 0]], [\"ne\", \"l\", upper_bound]],",
            "                    ]",
            "                elif left.typ.is_literal and left.value == -(2 ** 255):",
            "                    bounds_check = [\"assert\", [\"ne\", \"r\", [\"not\", 0]]]",
            "                elif right.typ.is_literal and right.value == -1:",
            "                    bounds_check = [\"assert\", [\"ne\", \"l\", upper_bound]]",
            "                else:",
            "                    bounds_check = \"pass\"",
            "                arith = [\"seq\", bounds_check, [\"sdiv\", \"l\", divisor]]",
            "",
            "            elif ltyp == \"int128\":",
            "                arith = [\"sdiv\", \"l\", divisor]",
            "",
            "            elif ltyp == \"decimal\":",
            "                arith = [",
            "                    \"sdiv\",",
            "                    [\"mul\", \"l\", DECIMAL_DIVISOR],",
            "                    divisor,",
            "                ]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Mod):",
            "            if right.typ.is_literal and right.value == 0:",
            "                return",
            "",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if right.typ.is_literal:",
            "                divisor = \"r\"",
            "            else:",
            "                # only apply the non-zero clamp when r is not a constant",
            "                divisor = [\"clamp_nonzero\", \"r\"]",
            "",
            "            if ltyp in (\"uint8\", \"uint256\"):",
            "                arith = [\"mod\", \"l\", divisor]",
            "            else:",
            "                arith = [\"smod\", \"l\", divisor]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Pow):",
            "            new_typ = BaseType(ltyp)",
            "",
            "            # TODO optimizer rule for special cases",
            "            if self.expr.left.get(\"value\") == 1:",
            "                return IRnode.from_list([1], typ=new_typ)",
            "            if self.expr.left.get(\"value\") == 0:",
            "                return IRnode.from_list([\"iszero\", right], typ=new_typ)",
            "",
            "            if ltyp == \"int128\":",
            "                is_signed = True",
            "                num_bits = 128",
            "            elif ltyp == \"int256\":",
            "                is_signed = True",
            "                num_bits = 256",
            "            elif ltyp == \"uint8\":",
            "                is_signed = False",
            "                num_bits = 8",
            "            else:",
            "                is_signed = False",
            "                num_bits = 256",
            "",
            "            if isinstance(self.expr.left, vy_ast.Int):",
            "                value = self.expr.left.value",
            "                upper_bound = calculate_largest_power(value, num_bits, is_signed) + 1",
            "                # for signed integers, this also prevents negative values",
            "                clamp = [\"lt\", right, upper_bound]",
            "                return IRnode.from_list(",
            "                    [\"seq\", [\"assert\", clamp], [\"exp\", left, right]],",
            "                    typ=new_typ,",
            "                )",
            "            elif isinstance(self.expr.right, vy_ast.Int):",
            "                value = self.expr.right.value",
            "                upper_bound = calculate_largest_base(value, num_bits, is_signed) + 1",
            "                if is_signed:",
            "                    clamp = [\"and\", [\"slt\", left, upper_bound], [\"sgt\", left, -upper_bound]]",
            "                else:",
            "                    clamp = [\"lt\", left, upper_bound]",
            "                return IRnode.from_list(",
            "                    [\"seq\", [\"assert\", clamp], [\"exp\", left, right]], typ=new_typ",
            "                )",
            "            else:",
            "                # `a ** b` where neither `a` or `b` are known",
            "                # TODO this is currently unreachable, once we implement a way to do it safely",
            "                # remove the check in `vyper/context/types/value/numeric.py`",
            "                return",
            "",
            "        if arith is None:",
            "            return",
            "",
            "        arith = IRnode.from_list(arith, typ=new_typ)",
            "",
            "        p = [",
            "            \"with\",",
            "            \"l\",",
            "            left,",
            "            [",
            "                \"with\",",
            "                \"r\",",
            "                right,",
            "                # note clamp_basetype is a noop on [u]int256",
            "                # note: clamp_basetype throws on unclampable input",
            "                clamp_basetype(arith),",
            "            ],",
            "        ]",
            "        return IRnode.from_list(p, typ=new_typ)",
            "",
            "    def build_in_comparator(self):",
            "        left = Expr(self.expr.left, self.context).ir_node",
            "        right = Expr(self.expr.right, self.context).ir_node",
            "",
            "        # temporary kludge to block #2637 bug",
            "        # TODO actually fix the bug",
            "        if not isinstance(left.typ, BaseType):",
            "            raise TypeMismatch(",
            "                \"`in` not allowed for arrays of non-base types, tracked in issue #2637\", self.expr",
            "            )",
            "",
            "        if isinstance(self.expr.op, vy_ast.In):",
            "            found, not_found = 1, 0",
            "        elif isinstance(self.expr.op, vy_ast.NotIn):",
            "            found, not_found = 0, 1",
            "        else:",
            "            return  # pragma: notest",
            "",
            "        i = IRnode.from_list(self.context.fresh_varname(\"in_ix\"), typ=\"uint256\")",
            "",
            "        found_ptr = self.context.new_internal_variable(BaseType(\"bool\"))",
            "",
            "        ret = [\"seq\"]",
            "",
            "        left = unwrap_location(left)",
            "        with left.cache_when_complex(\"needle\") as (b1, left), right.cache_when_complex(",
            "            \"haystack\"",
            "        ) as (b2, right):",
            "            if right.value == \"multi\":",
            "                # Copy literal to memory to be compared.",
            "                tmp_list = IRnode.from_list(",
            "                    self.context.new_internal_variable(right.typ), typ=right.typ, location=MEMORY",
            "                )",
            "                ret.append(make_setter(tmp_list, right))",
            "",
            "                right = tmp_list",
            "",
            "            # location of i'th item from list",
            "            ith_element_ptr = get_element_ptr(right, i, array_bounds_check=False)",
            "            ith_element = unwrap_location(ith_element_ptr)",
            "",
            "            if isinstance(right.typ, SArrayType):",
            "                len_ = right.typ.count",
            "            else:",
            "                len_ = get_dyn_array_count(right)",
            "",
            "            # Condition repeat loop has to break on.",
            "            # TODO maybe put result on the stack",
            "            loop_body = [",
            "                \"if\",",
            "                [\"eq\", left, ith_element],",
            "                [\"seq\", [\"mstore\", found_ptr, found], \"break\"],  # store true.",
            "            ]",
            "            loop = [\"repeat\", i, 0, len_, right.typ.count, loop_body]",
            "",
            "            ret.append(",
            "                [",
            "                    \"seq\",",
            "                    [\"mstore\", found_ptr, not_found],",
            "                    loop,",
            "                    [\"mload\", found_ptr],",
            "                ]",
            "            )",
            "",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)), typ=\"bool\")",
            "",
            "    @staticmethod",
            "    def _signed_to_unsigned_comparision_op(op):",
            "        translation_map = {",
            "            \"sgt\": \"gt\",",
            "            \"sge\": \"ge\",",
            "            \"sle\": \"le\",",
            "            \"slt\": \"lt\",",
            "        }",
            "        if op in translation_map:",
            "            return translation_map[op]",
            "        else:",
            "            return op",
            "",
            "    def parse_Compare(self):",
            "        left = Expr.parse_value_expr(self.expr.left, self.context)",
            "        right = Expr.parse_value_expr(self.expr.right, self.context)",
            "",
            "        if right.value is None:",
            "            return",
            "",
            "        if isinstance(self.expr.op, (vy_ast.In, vy_ast.NotIn)):",
            "            if isinstance(right.typ, ArrayLike):",
            "                return self.build_in_comparator()",
            "            return  # pragma: notest",
            "",
            "        if isinstance(self.expr.op, vy_ast.Gt):",
            "            op = \"sgt\"",
            "        elif isinstance(self.expr.op, vy_ast.GtE):",
            "            op = \"sge\"",
            "        elif isinstance(self.expr.op, vy_ast.LtE):",
            "            op = \"sle\"",
            "        elif isinstance(self.expr.op, vy_ast.Lt):",
            "            op = \"slt\"",
            "        elif isinstance(self.expr.op, vy_ast.Eq):",
            "            op = \"eq\"",
            "        elif isinstance(self.expr.op, vy_ast.NotEq):",
            "            op = \"ne\"",
            "        else:",
            "            return  # pragma: notest",
            "",
            "        # Compare (limited to 32) byte arrays.",
            "        if isinstance(left.typ, ByteArrayLike) and isinstance(right.typ, ByteArrayLike):",
            "            left = Expr(self.expr.left, self.context).ir_node",
            "            right = Expr(self.expr.right, self.context).ir_node",
            "",
            "            length_mismatch = left.typ.maxlen != right.typ.maxlen",
            "            left_over_32 = left.typ.maxlen > 32",
            "            right_over_32 = right.typ.maxlen > 32",
            "",
            "            if length_mismatch or left_over_32 or right_over_32:",
            "                left_keccak = keccak256_helper(self.expr, left, self.context)",
            "                right_keccak = keccak256_helper(self.expr, right, self.context)",
            "",
            "                if op == \"eq\" or op == \"ne\":",
            "                    return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")",
            "",
            "                else:",
            "                    return",
            "",
            "            else:",
            "",
            "                def load_bytearray(side):",
            "                    return LOAD(bytes_data_ptr(side))",
            "",
            "                return IRnode.from_list(",
            "                    # CMC 2022-03-24 TODO investigate this.",
            "                    [op, load_bytearray(left), load_bytearray(right)],",
            "                    typ=\"bool\",",
            "                )",
            "",
            "        # Compare other types.",
            "        elif is_numeric_type(left.typ) and is_numeric_type(right.typ):",
            "            if left.typ.typ == right.typ.typ == \"uint256\":",
            "                # this works because we only have one unsigned integer type",
            "                # in the future if others are added, this logic must be expanded",
            "                op = self._signed_to_unsigned_comparision_op(op)",
            "",
            "        elif isinstance(left.typ, BaseType) and isinstance(right.typ, BaseType):",
            "            if op not in (\"eq\", \"ne\"):",
            "                return",
            "        else:",
            "            # kludge to block behavior in #2638",
            "            # TODO actually implement equality for complex types",
            "            raise TypeMismatch(",
            "                f\"operation not yet supported for {left.typ}, {right.typ}, see issue #2638\",",
            "                self.expr.op,",
            "            )",
            "",
            "        return IRnode.from_list([op, left, right], typ=\"bool\")",
            "",
            "    def parse_BoolOp(self):",
            "        for value in self.expr.values:",
            "            # Check for boolean operations with non-boolean inputs",
            "            _expr = Expr.parse_value_expr(value, self.context)",
            "            if not is_base_type(_expr.typ, \"bool\"):",
            "                return",
            "",
            "        def _build_if_ir(condition, true, false):",
            "            # generate a basic if statement in IR",
            "            o = [\"if\", condition, true, false]",
            "            return o",
            "",
            "        if isinstance(self.expr.op, vy_ast.And):",
            "            # create the initial `x and y` from the final two values",
            "            ir_node = _build_if_ir(",
            "                Expr.parse_value_expr(self.expr.values[-2], self.context),",
            "                Expr.parse_value_expr(self.expr.values[-1], self.context),",
            "                [0],",
            "            )",
            "            # iterate backward through the remaining values",
            "            for node in self.expr.values[-3::-1]:",
            "                ir_node = _build_if_ir(Expr.parse_value_expr(node, self.context), ir_node, [0])",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Or):",
            "            # create the initial `x or y` from the final two values",
            "            ir_node = _build_if_ir(",
            "                Expr.parse_value_expr(self.expr.values[-2], self.context),",
            "                [1],",
            "                Expr.parse_value_expr(self.expr.values[-1], self.context),",
            "            )",
            "",
            "            # iterate backward through the remaining values",
            "            for node in self.expr.values[-3::-1]:",
            "                ir_node = _build_if_ir(Expr.parse_value_expr(node, self.context), 1, ir_node)",
            "        else:",
            "            raise TypeCheckFailure(f\"Unexpected boolean operator: {type(self.expr.op).__name__}\")",
            "",
            "        return IRnode.from_list(ir_node, typ=\"bool\")",
            "",
            "    # Unary operations (only \"not\" supported)",
            "    def parse_UnaryOp(self):",
            "        operand = Expr.parse_value_expr(self.expr.operand, self.context)",
            "        if isinstance(self.expr.op, vy_ast.Not):",
            "            if isinstance(operand.typ, BaseType) and operand.typ.typ == \"bool\":",
            "                return IRnode.from_list([\"iszero\", operand], typ=\"bool\")",
            "        elif isinstance(self.expr.op, vy_ast.USub) and is_numeric_type(operand.typ):",
            "            assert operand.typ._num_info.is_signed",
            "            # Clamp on minimum integer value as we cannot negate that value",
            "            # (all other integer values are fine)",
            "            min_int_val, _ = operand.typ._num_info.bounds",
            "            return IRnode.from_list(",
            "                [\"sub\", 0, [\"clampgt\", operand, min_int_val]],",
            "                typ=operand.typ,",
            "            )",
            "",
            "    def _is_valid_interface_assign(self):",
            "        if self.expr.args and len(self.expr.args) == 1:",
            "            arg_ir = Expr(self.expr.args[0], self.context).ir_node",
            "            if arg_ir.typ == BaseType(\"address\"):",
            "                return True, arg_ir",
            "        return False, None",
            "",
            "    # Function calls",
            "    def parse_Call(self):",
            "        # TODO check out this inline import",
            "        from vyper.builtin_functions import DISPATCH_TABLE",
            "",
            "        if isinstance(self.expr.func, vy_ast.Name):",
            "            function_name = self.expr.func.id",
            "",
            "            if function_name in DISPATCH_TABLE:",
            "                return DISPATCH_TABLE[function_name].build_IR(self.expr, self.context)",
            "",
            "            # Struct constructors do not need `self` prefix.",
            "            elif function_name in self.context.structs:",
            "                args = self.expr.args",
            "                if len(args) == 1 and isinstance(args[0], vy_ast.Dict):",
            "                    return Expr.struct_literals(args[0], function_name, self.context)",
            "",
            "            # Interface assignment. Bar(<address>).",
            "            elif function_name in self.context.sigs:",
            "                ret, arg_ir = self._is_valid_interface_assign()",
            "                if ret is True:",
            "                    arg_ir.typ = InterfaceType(function_name)  # Cast to Correct interface type.",
            "                    return arg_ir",
            "",
            "        elif isinstance(self.expr.func, vy_ast.Attribute) and self.expr.func.attr == \"pop\":",
            "            darray = Expr(self.expr.func.value, self.context).ir_node",
            "            assert len(self.expr.args) == 0",
            "            assert isinstance(darray.typ, DArrayType)",
            "            return pop_dyn_array(",
            "                darray,",
            "                return_popped_item=True,",
            "            )",
            "",
            "        elif (",
            "            isinstance(self.expr.func, vy_ast.Attribute)",
            "            and isinstance(self.expr.func.value, vy_ast.Name)",
            "            and self.expr.func.value.id == \"self\"",
            "        ):  # noqa: E501",
            "            return self_call.ir_for_self_call(self.expr, self.context)",
            "        else:",
            "            return external_call.ir_for_external_call(self.expr, self.context)",
            "",
            "    def parse_List(self):",
            "        typ = new_type_to_old_type(self.expr._metadata[\"type\"])",
            "        if len(self.expr.elements) == 0:",
            "            return IRnode.from_list(\"~empty\", typ=typ)",
            "",
            "        multi_ir = [Expr(x, self.context).ir_node for x in self.expr.elements]",
            "",
            "        return IRnode.from_list([\"multi\"] + multi_ir, typ=typ)",
            "",
            "    def parse_Tuple(self):",
            "        tuple_elements = [Expr(x, self.context).ir_node for x in self.expr.elements]",
            "        typ = TupleType([x.typ for x in tuple_elements], is_literal=True)",
            "        multi_ir = IRnode.from_list([\"multi\"] + tuple_elements, typ=typ)",
            "        return multi_ir",
            "",
            "    @staticmethod",
            "    def struct_literals(expr, name, context):",
            "        member_subs = {}",
            "        member_typs = {}",
            "        for key, value in zip(expr.keys, expr.values):",
            "            if not isinstance(key, vy_ast.Name):",
            "                return",
            "            if key.id in member_subs:",
            "                return",
            "            sub = Expr(value, context).ir_node",
            "            member_subs[key.id] = sub",
            "            member_typs[key.id] = sub.typ",
            "        return IRnode.from_list(",
            "            [\"multi\"] + [member_subs[key] for key in member_subs.keys()],",
            "            typ=StructType(member_typs, name, is_literal=True),",
            "        )",
            "",
            "    # Parse an expression that results in a value",
            "    @classmethod",
            "    def parse_value_expr(cls, expr, context):",
            "        return unwrap_location(cls(expr, context).ir_node)",
            "",
            "    # Parse an expression that represents a pointer to memory/calldata or storage.",
            "    @classmethod",
            "    def parse_pointer_expr(cls, expr, context):",
            "        o = cls(expr, context).ir_node",
            "        if not o.location:",
            "            raise StructureException(\"Looking for a variable location, instead got a value\", expr)",
            "        return o"
        ],
        "afterPatchFile": [
            "import decimal",
            "import math",
            "",
            "from vyper import ast as vy_ast",
            "from vyper.address_space import DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen import external_call, self_call",
            "from vyper.codegen.core import (",
            "    clamp_basetype,",
            "    ensure_in_memory,",
            "    get_dyn_array_count,",
            "    get_element_ptr,",
            "    getpos,",
            "    make_setter,",
            "    pop_dyn_array,",
            "    unwrap_location,",
            ")",
            "from vyper.codegen.ir_node import IRnode",
            "from vyper.codegen.keccak256_helper import keccak256_helper",
            "from vyper.codegen.types import (",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    ByteArrayType,",
            "    DArrayType,",
            "    InterfaceType,",
            "    MappingType,",
            "    SArrayType,",
            "    StringType,",
            "    StructType,",
            "    TupleType,",
            "    is_base_type,",
            "    is_numeric_type,",
            ")",
            "from vyper.codegen.types.convert import new_type_to_old_type",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import (",
            "    CompilerPanic,",
            "    EvmVersionException,",
            "    StructureException,",
            "    TypeCheckFailure,",
            "    TypeMismatch,",
            ")",
            "from vyper.utils import DECIMAL_DIVISOR, SizeLimits, bytes_to_int, checksum_encode, string_to_bytes",
            "",
            "ENVIRONMENT_VARIABLES = {",
            "    \"block\",",
            "    \"msg\",",
            "    \"tx\",",
            "    \"chain\",",
            "}",
            "",
            "",
            "def calculate_largest_power(a: int, num_bits: int, is_signed: bool) -> int:",
            "    \"\"\"",
            "    For a given base `a`, compute the maximum power `b` that will not",
            "    produce an overflow in the equation `a ** b`",
            "",
            "    Arguments",
            "    ---------",
            "    a : int",
            "        Base value for the equation `a ** b`",
            "    num_bits : int",
            "        The maximum number of bits that the resulting value must fit in",
            "    is_signed : bool",
            "        Is the operation being performed on signed integers?",
            "",
            "    Returns",
            "    -------",
            "    int",
            "        Largest possible value for `b` where the result does not overflow",
            "        `num_bits`",
            "    \"\"\"",
            "    if num_bits % 8:",
            "        raise CompilerPanic(\"Type is not a modulo of 8\")",
            "",
            "    value_bits = num_bits - (1 if is_signed else 0)",
            "    if a >= 2 ** value_bits:",
            "        raise TypeCheckFailure(\"Value is too large and will always throw\")",
            "    elif a < -(2 ** value_bits):",
            "        raise TypeCheckFailure(\"Value is too small and will always throw\")",
            "",
            "    a_is_negative = a < 0",
            "    a = abs(a)  # No longer need to know if it's signed or not",
            "    if a in (0, 1):",
            "        raise CompilerPanic(\"Exponential operation is useless!\")",
            "",
            "    # NOTE: There is an edge case if `a` were left signed where the following",
            "    #       operation would not work (`ln(a)` is undefined if `a <= 0`)",
            "    b = int(decimal.Decimal(value_bits) / (decimal.Decimal(a).ln() / decimal.Decimal(2).ln()))",
            "    if b <= 1:",
            "        return 1  # Value is assumed to be in range, therefore power of 1 is max",
            "",
            "    # Do a bit of iteration to ensure we have the exact number",
            "    num_iterations = 0",
            "    while a ** (b + 1) < 2 ** value_bits:",
            "        b += 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "    while a ** b >= 2 ** value_bits:",
            "        b -= 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "",
            "    # Edge case: If a is negative and the values of a and b are such that:",
            "    #               (a) ** (b + 1) == -(2 ** value_bits)",
            "    #            we can actually squeak one more out of it because it's on the edge",
            "    if a_is_negative and (-a) ** (b + 1) == -(2 ** value_bits):  # NOTE: a = abs(a)",
            "        return b + 1",
            "    else:",
            "        return b  # Exact",
            "",
            "",
            "def calculate_largest_base(b: int, num_bits: int, is_signed: bool) -> int:",
            "    \"\"\"",
            "    For a given power `b`, compute the maximum base `a` that will not produce an",
            "    overflow in the equation `a ** b`",
            "",
            "    Arguments",
            "    ---------",
            "    b : int",
            "        Power value for the equation `a ** b`",
            "    num_bits : int",
            "        The maximum number of bits that the resulting value must fit in",
            "    is_signed : bool",
            "        Is the operation being performed on signed integers?",
            "",
            "    Returns",
            "    -------",
            "    int",
            "        Largest possible value for `a` where the result does not overflow",
            "        `num_bits`",
            "    \"\"\"",
            "    if num_bits % 8:",
            "        raise CompilerPanic(\"Type is not a modulo of 8\")",
            "    if b < 0:",
            "        raise TypeCheckFailure(\"Cannot calculate negative exponents\")",
            "",
            "    value_bits = num_bits - (1 if is_signed else 0)",
            "    if b > value_bits:",
            "        raise TypeCheckFailure(\"Value is too large and will always throw\")",
            "    elif b < 2:",
            "        return 2 ** value_bits - 1  # Maximum value for type",
            "",
            "    # Estimate (up to ~39 digits precision required)",
            "    a = math.ceil(2 ** (decimal.Decimal(value_bits) / decimal.Decimal(b)))",
            "    # Do a bit of iteration to ensure we have the exact number",
            "    num_iterations = 0",
            "    while (a + 1) ** b < 2 ** value_bits:",
            "        a += 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "    while a ** b >= 2 ** value_bits:",
            "        a -= 1",
            "        num_iterations += 1",
            "        assert num_iterations < 10000",
            "",
            "    return a",
            "",
            "",
            "class Expr:",
            "    # TODO: Once other refactors are made reevaluate all inline imports",
            "",
            "    def __init__(self, node, context):",
            "        self.expr = node",
            "        self.context = context",
            "",
            "        if isinstance(node, IRnode):",
            "            # TODO this seems bad",
            "            self.ir_node = node",
            "            return",
            "",
            "        fn = getattr(self, f\"parse_{type(node).__name__}\", None)",
            "        if fn is None:",
            "            raise TypeCheckFailure(f\"Invalid statement node: {type(node).__name__}\")",
            "",
            "        self.ir_node = fn()",
            "        if self.ir_node is None:",
            "            raise TypeCheckFailure(f\"{type(node).__name__} node did not produce IR. {self.expr}\")",
            "",
            "        self.ir_node.annotation = self.expr.get(\"node_source_code\")",
            "        self.ir_node.source_pos = getpos(self.expr)",
            "",
            "    def parse_Int(self):",
            "        # Literal (mostly likely) becomes int256",
            "        if self.expr.n < 0:",
            "            return IRnode.from_list(self.expr.n, typ=BaseType(\"int256\", is_literal=True))",
            "        # Literal is large enough (mostly likely) becomes uint256.",
            "        else:",
            "            return IRnode.from_list(self.expr.n, typ=BaseType(\"uint256\", is_literal=True))",
            "",
            "    def parse_Decimal(self):",
            "        val = self.expr.value * DECIMAL_DIVISOR",
            "",
            "        # sanity check that type checker did its job",
            "        assert isinstance(val, decimal.Decimal)",
            "        assert SizeLimits.in_bounds(\"decimal\", val)",
            "        assert math.ceil(val) == math.floor(val)",
            "",
            "        val = int(val)",
            "",
            "        return IRnode.from_list(val, typ=BaseType(\"decimal\", is_literal=True))",
            "",
            "    def parse_Hex(self):",
            "        hexstr = self.expr.value",
            "",
            "        if len(hexstr) == 42:",
            "            # sanity check typechecker did its job",
            "            assert checksum_encode(hexstr) == hexstr",
            "            typ = BaseType(\"address\")",
            "            # TODO allow non-checksum encoded bytes20",
            "            return IRnode.from_list(int(self.expr.value, 16), typ=typ)",
            "",
            "        else:",
            "            n_bytes = (len(hexstr) - 2) // 2  # e.g. \"0x1234\" is 2 bytes",
            "            # TODO: typ = new_type_to_old_type(self.expr._metadata[\"type\"])",
            "            #       assert n_bytes == typ._bytes_info.m",
            "",
            "            # bytes_m types are left padded with zeros",
            "            val = int(hexstr, 16) << 8 * (32 - n_bytes)",
            "",
            "            typ = BaseType(f\"bytes{n_bytes}\", is_literal=True)",
            "            typ.is_literal = True",
            "            return IRnode.from_list(val, typ=typ)",
            "",
            "    # String literals",
            "    def parse_Str(self):",
            "        bytez, bytez_length = string_to_bytes(self.expr.value)",
            "        typ = StringType(bytez_length, is_literal=True)",
            "        return self._make_bytelike(typ, bytez, bytez_length)",
            "",
            "    # Byte literals",
            "    def parse_Bytes(self):",
            "        bytez = self.expr.s",
            "        bytez_length = len(self.expr.s)",
            "        typ = ByteArrayType(bytez_length, is_literal=True)",
            "        return self._make_bytelike(typ, bytez, bytez_length)",
            "",
            "    def _make_bytelike(self, btype, bytez, bytez_length):",
            "        placeholder = self.context.new_internal_variable(btype)",
            "        seq = []",
            "        seq.append([\"mstore\", placeholder, bytez_length])",
            "        for i in range(0, len(bytez), 32):",
            "            seq.append(",
            "                [",
            "                    \"mstore\",",
            "                    [\"add\", placeholder, i + 32],",
            "                    bytes_to_int((bytez + b\"\\x00\" * 31)[i : i + 32]),",
            "                ]",
            "            )",
            "        return IRnode.from_list(",
            "            [\"seq\"] + seq + [placeholder],",
            "            typ=btype,",
            "            location=MEMORY,",
            "            annotation=f\"Create {btype}: {bytez}\",",
            "        )",
            "",
            "    # True, False, None constants",
            "    def parse_NameConstant(self):",
            "        if self.expr.value is True:",
            "            return IRnode.from_list(1, typ=BaseType(\"bool\", is_literal=True))",
            "        elif self.expr.value is False:",
            "            return IRnode.from_list(0, typ=BaseType(\"bool\", is_literal=True))",
            "",
            "    # Variable names",
            "    def parse_Name(self):",
            "",
            "        if self.expr.id == \"self\":",
            "            return IRnode.from_list([\"address\"], typ=\"address\")",
            "        elif self.expr.id in self.context.vars:",
            "            var = self.context.vars[self.expr.id]",
            "            return IRnode.from_list(",
            "                var.pos,",
            "                typ=var.typ,",
            "                location=var.location,  # either 'memory' or 'calldata' storage is handled above.",
            "                encoding=var.encoding,",
            "                annotation=self.expr.id,",
            "                mutable=var.mutable,",
            "            )",
            "",
            "        elif self.expr._metadata[\"type\"].is_immutable:",
            "            var = self.context.globals[self.expr.id]",
            "            ofst = self.expr._metadata[\"type\"].position.offset",
            "",
            "            if self.context.sig.is_init_func:",
            "                mutable = True",
            "                location = IMMUTABLES",
            "            else:",
            "                mutable = False",
            "                location = DATA",
            "",
            "            return IRnode.from_list(",
            "                ofst,",
            "                typ=var.typ,",
            "                location=location,",
            "                annotation=self.expr.id,",
            "                mutable=mutable,",
            "            )",
            "",
            "    # x.y or x[5]",
            "    def parse_Attribute(self):",
            "        # x.balance: balance of address x",
            "        if self.expr.attr == \"balance\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                if (",
            "                    isinstance(self.expr.value, vy_ast.Name)",
            "                    and self.expr.value.id == \"self\"",
            "                    and version_check(begin=\"istanbul\")",
            "                ):",
            "                    seq = [\"selfbalance\"]",
            "                else:",
            "                    seq = [\"balance\", addr]",
            "                return IRnode.from_list(seq, typ=BaseType(\"uint256\"))",
            "        # x.codesize: codesize of address x",
            "        elif self.expr.attr == \"codesize\" or self.expr.attr == \"is_contract\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                if self.expr.attr == \"codesize\":",
            "                    if self.expr.value.id == \"self\":",
            "                        eval_code = [\"codesize\"]",
            "                    else:",
            "                        eval_code = [\"extcodesize\", addr]",
            "                    output_type = \"uint256\"",
            "                else:",
            "                    eval_code = [\"gt\", [\"extcodesize\", addr], 0]",
            "                    output_type = \"bool\"",
            "                return IRnode.from_list(eval_code, typ=BaseType(output_type))",
            "        # x.codehash: keccak of address x",
            "        elif self.expr.attr == \"codehash\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if not version_check(begin=\"constantinople\"):",
            "                raise EvmVersionException(",
            "                    \"address.codehash is unavailable prior to constantinople ruleset\", self.expr",
            "                )",
            "            if is_base_type(addr.typ, \"address\"):",
            "                return IRnode.from_list([\"extcodehash\", addr], typ=BaseType(\"bytes32\"))",
            "        # x.code: codecopy/extcodecopy of address x",
            "        elif self.expr.attr == \"code\":",
            "            addr = Expr.parse_value_expr(self.expr.value, self.context)",
            "            if is_base_type(addr.typ, \"address\"):",
            "                # These adhoc nodes will be replaced with a valid node in `Slice.build_IR`",
            "                if addr.value == \"address\":  # for `self.code`",
            "                    return IRnode.from_list([\"~selfcode\"], typ=ByteArrayType(0))",
            "                return IRnode.from_list([\"~extcode\", addr], typ=ByteArrayType(0))",
            "        # self.x: global attribute",
            "        elif isinstance(self.expr.value, vy_ast.Name) and self.expr.value.id == \"self\":",
            "            type_ = self.expr._metadata[\"type\"]",
            "            var = self.context.globals[self.expr.attr]",
            "            return IRnode.from_list(",
            "                type_.position.position,",
            "                typ=var.typ,",
            "                location=STORAGE,",
            "                annotation=\"self.\" + self.expr.attr,",
            "            )",
            "        # Reserved keywords",
            "        elif (",
            "            isinstance(self.expr.value, vy_ast.Name) and self.expr.value.id in ENVIRONMENT_VARIABLES",
            "        ):",
            "            key = f\"{self.expr.value.id}.{self.expr.attr}\"",
            "            if key == \"msg.sender\":",
            "                return IRnode.from_list([\"caller\"], typ=\"address\")",
            "            elif key == \"msg.data\":",
            "                # This adhoc node will be replaced with a valid node in `Slice/Len.build_IR`",
            "                return IRnode.from_list([\"~calldata\"], typ=ByteArrayType(0))",
            "            elif key == \"msg.value\" and self.context.is_payable:",
            "                return IRnode.from_list([\"callvalue\"], typ=BaseType(\"uint256\"))",
            "            elif key == \"msg.gas\":",
            "                return IRnode.from_list([\"gas\"], typ=\"uint256\")",
            "            elif key == \"block.difficulty\":",
            "                return IRnode.from_list([\"difficulty\"], typ=\"uint256\")",
            "            elif key == \"block.timestamp\":",
            "                return IRnode.from_list([\"timestamp\"], typ=BaseType(\"uint256\"))",
            "            elif key == \"block.coinbase\":",
            "                return IRnode.from_list([\"coinbase\"], typ=\"address\")",
            "            elif key == \"block.number\":",
            "                return IRnode.from_list([\"number\"], typ=\"uint256\")",
            "            elif key == \"block.gaslimit\":",
            "                return IRnode.from_list([\"gaslimit\"], typ=\"uint256\")",
            "            elif key == \"block.basefee\":",
            "                return IRnode.from_list([\"basefee\"], typ=\"uint256\")",
            "            elif key == \"block.prevhash\":",
            "                return IRnode.from_list([\"blockhash\", [\"sub\", \"number\", 1]], typ=\"bytes32\")",
            "            elif key == \"tx.origin\":",
            "                return IRnode.from_list([\"origin\"], typ=\"address\")",
            "            elif key == \"tx.gasprice\":",
            "                return IRnode.from_list([\"gasprice\"], typ=\"uint256\")",
            "            elif key == \"chain.id\":",
            "                if not version_check(begin=\"istanbul\"):",
            "                    raise EvmVersionException(",
            "                        \"chain.id is unavailable prior to istanbul ruleset\", self.expr",
            "                    )",
            "                return IRnode.from_list([\"chainid\"], typ=\"uint256\")",
            "        # Other variables",
            "        else:",
            "            sub = Expr(self.expr.value, self.context).ir_node",
            "            # contract type",
            "            if isinstance(sub.typ, InterfaceType):",
            "                return sub",
            "            if isinstance(sub.typ, StructType) and self.expr.attr in sub.typ.members:",
            "                return get_element_ptr(sub, self.expr.attr)",
            "",
            "    def parse_Subscript(self):",
            "        sub = Expr(self.expr.value, self.context).ir_node",
            "        if sub.value == \"multi\":",
            "            # force literal to memory, e.g.",
            "            # MY_LIST: constant(decimal[6])",
            "            # ...",
            "            # return MY_LIST[ix]",
            "            sub = ensure_in_memory(sub, self.context)",
            "",
            "        if isinstance(sub.typ, MappingType):",
            "            # TODO sanity check we are in a self.my_map[i] situation",
            "            index = Expr.parse_value_expr(self.expr.slice.value, self.context)",
            "            if isinstance(index.typ, ByteArrayLike):",
            "                # we have to hash the key to get a storage location",
            "                assert len(index.args) == 1",
            "                index = keccak256_helper(self.expr.slice.value, index.args[0], self.context)",
            "",
            "        elif isinstance(sub.typ, ArrayLike):",
            "            index = Expr.parse_value_expr(self.expr.slice.value, self.context)",
            "",
            "        elif isinstance(sub.typ, TupleType):",
            "            index = self.expr.slice.value.n",
            "            # note: this check should also happen in get_element_ptr",
            "            if not 0 <= index < len(sub.typ.members):",
            "                return",
            "        else:",
            "            return",
            "",
            "        ir_node = get_element_ptr(sub, index)",
            "        ir_node.mutable = sub.mutable",
            "        return ir_node",
            "",
            "    def parse_BinOp(self):",
            "        left = Expr.parse_value_expr(self.expr.left, self.context)",
            "        right = Expr.parse_value_expr(self.expr.right, self.context)",
            "",
            "        if not is_numeric_type(left.typ) or not is_numeric_type(right.typ):",
            "            return",
            "",
            "        types = {left.typ.typ, right.typ.typ}",
            "        literals = {left.typ.is_literal, right.typ.is_literal}",
            "",
            "        # If one value of the operation is a literal, we recast it to match the non-literal type.",
            "        # We know this is OK because types were already verified in the actual typechecking pass.",
            "        # This is a temporary solution to not break codegen while we work toward removing types",
            "        # altogether at this stage of complition. @iamdefinitelyahuman",
            "        if literals == {True, False} and len(types) > 1 and \"decimal\" not in types:",
            "            if left.typ.is_literal and SizeLimits.in_bounds(right.typ.typ, left.value):",
            "                left = IRnode.from_list(left.value, typ=BaseType(right.typ.typ, is_literal=True))",
            "            elif right.typ.is_literal and SizeLimits.in_bounds(left.typ.typ, right.value):",
            "                right = IRnode.from_list(right.value, typ=BaseType(left.typ.typ, is_literal=True))",
            "",
            "        ltyp, rtyp = left.typ.typ, right.typ.typ",
            "",
            "        # Sanity check - ensure that we aren't dealing with different types",
            "        # This should be unreachable due to the type check pass",
            "        assert ltyp == rtyp, \"unreachable\"",
            "",
            "        arith = None",
            "        if isinstance(self.expr.op, (vy_ast.Add, vy_ast.Sub)):",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if ltyp == \"uint256\":",
            "                if isinstance(self.expr.op, vy_ast.Add):",
            "                    # safeadd",
            "                    arith = [\"seq\", [\"assert\", [\"ge\", [\"add\", \"l\", \"r\"], \"l\"]], [\"add\", \"l\", \"r\"]]",
            "",
            "                elif isinstance(self.expr.op, vy_ast.Sub):",
            "                    # safesub",
            "                    arith = [\"seq\", [\"assert\", [\"ge\", \"l\", \"r\"]], [\"sub\", \"l\", \"r\"]]",
            "",
            "            elif ltyp == \"int256\":",
            "                if isinstance(self.expr.op, vy_ast.Add):",
            "                    op, comp1, comp2 = \"add\", \"sge\", \"slt\"",
            "                else:",
            "                    op, comp1, comp2 = \"sub\", \"sle\", \"sgt\"",
            "",
            "                if right.typ.is_literal:",
            "                    if right.value >= 0:",
            "                        arith = [\"seq\", [\"assert\", [comp1, [op, \"l\", \"r\"], \"l\"]], [op, \"l\", \"r\"]]",
            "                    else:",
            "                        arith = [\"seq\", [\"assert\", [comp2, [op, \"l\", \"r\"], \"l\"]], [op, \"l\", \"r\"]]",
            "                else:",
            "                    arith = [",
            "                        \"with\",",
            "                        \"ans\",",
            "                        [op, \"l\", \"r\"],",
            "                        [",
            "                            \"seq\",",
            "                            [",
            "                                \"assert\",",
            "                                [",
            "                                    \"or\",",
            "                                    [\"and\", [\"sge\", \"r\", 0], [comp1, \"ans\", \"l\"]],",
            "                                    [\"and\", [\"slt\", \"r\", 0], [comp2, \"ans\", \"l\"]],",
            "                                ],",
            "                            ],",
            "                            \"ans\",",
            "                        ],",
            "                    ]",
            "",
            "            elif ltyp in (\"decimal\", \"int128\", \"uint8\"):",
            "                op = \"add\" if isinstance(self.expr.op, vy_ast.Add) else \"sub\"",
            "                arith = [op, \"l\", \"r\"]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Mult):",
            "            new_typ = BaseType(ltyp)",
            "            if ltyp == \"uint256\":",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        [\"assert\", [\"or\", [\"eq\", [\"div\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        \"ans\",",
            "                    ],",
            "                ]",
            "",
            "            elif ltyp == \"int256\":",
            "                if version_check(begin=\"constantinople\"):",
            "                    upper_bound = [\"shl\", 255, 1]",
            "                else:",
            "                    upper_bound = -(2 ** 255)",
            "                if not left.typ.is_literal and not right.typ.is_literal:",
            "                    bounds_check = [",
            "                        \"assert\",",
            "                        [\"or\", [\"ne\", \"l\", [\"not\", 0]], [\"ne\", \"r\", upper_bound]],",
            "                    ]",
            "                elif left.typ.is_literal and left.value == -1:",
            "                    bounds_check = [\"assert\", [\"ne\", \"r\", upper_bound]]",
            "                elif right.typ.is_literal and right.value == -(2 ** 255):",
            "                    bounds_check = [\"assert\", [\"ne\", \"l\", [\"not\", 0]]]",
            "                else:",
            "                    bounds_check = \"pass\"",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        bounds_check,",
            "                        [\"assert\", [\"or\", [\"eq\", [\"sdiv\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        \"ans\",",
            "                    ],",
            "                ]",
            "",
            "            elif ltyp in (\"int128\", \"uint8\"):",
            "                arith = [\"mul\", \"l\", \"r\"]",
            "",
            "            elif ltyp == \"decimal\":",
            "                arith = [",
            "                    \"with\",",
            "                    \"ans\",",
            "                    [\"mul\", \"l\", \"r\"],",
            "                    [",
            "                        \"seq\",",
            "                        [\"assert\", [\"or\", [\"eq\", [\"sdiv\", \"ans\", \"l\"], \"r\"], [\"iszero\", \"l\"]]],",
            "                        [\"sdiv\", \"ans\", DECIMAL_DIVISOR],",
            "                    ],",
            "                ]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Div):",
            "            if right.typ.is_literal and right.value == 0:",
            "                return",
            "",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if right.typ.is_literal:",
            "                divisor = \"r\"",
            "            else:",
            "                # only apply the non-zero clamp when r is not a constant",
            "                divisor = [\"clamp_nonzero\", \"r\"]",
            "",
            "            if ltyp in (\"uint8\", \"uint256\"):",
            "                arith = [\"div\", \"l\", divisor]",
            "",
            "            elif ltyp == \"int256\":",
            "                if version_check(begin=\"constantinople\"):",
            "                    upper_bound = [\"shl\", 255, 1]",
            "                else:",
            "                    upper_bound = -(2 ** 255)",
            "                if not left.typ.is_literal and not right.typ.is_literal:",
            "                    bounds_check = [",
            "                        \"assert\",",
            "                        [\"or\", [\"ne\", \"r\", [\"not\", 0]], [\"ne\", \"l\", upper_bound]],",
            "                    ]",
            "                elif left.typ.is_literal and left.value == -(2 ** 255):",
            "                    bounds_check = [\"assert\", [\"ne\", \"r\", [\"not\", 0]]]",
            "                elif right.typ.is_literal and right.value == -1:",
            "                    bounds_check = [\"assert\", [\"ne\", \"l\", upper_bound]]",
            "                else:",
            "                    bounds_check = \"pass\"",
            "                arith = [\"seq\", bounds_check, [\"sdiv\", \"l\", divisor]]",
            "",
            "            elif ltyp == \"int128\":",
            "                arith = [\"sdiv\", \"l\", divisor]",
            "",
            "            elif ltyp == \"decimal\":",
            "                arith = [",
            "                    \"sdiv\",",
            "                    [\"mul\", \"l\", DECIMAL_DIVISOR],",
            "                    divisor,",
            "                ]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Mod):",
            "            if right.typ.is_literal and right.value == 0:",
            "                return",
            "",
            "            new_typ = BaseType(ltyp)",
            "",
            "            if right.typ.is_literal:",
            "                divisor = \"r\"",
            "            else:",
            "                # only apply the non-zero clamp when r is not a constant",
            "                divisor = [\"clamp_nonzero\", \"r\"]",
            "",
            "            if ltyp in (\"uint8\", \"uint256\"):",
            "                arith = [\"mod\", \"l\", divisor]",
            "            else:",
            "                arith = [\"smod\", \"l\", divisor]",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Pow):",
            "            new_typ = BaseType(ltyp)",
            "",
            "            # TODO optimizer rule for special cases",
            "            if self.expr.left.get(\"value\") == 1:",
            "                return IRnode.from_list([1], typ=new_typ)",
            "            if self.expr.left.get(\"value\") == 0:",
            "                return IRnode.from_list([\"iszero\", right], typ=new_typ)",
            "",
            "            if ltyp == \"int128\":",
            "                is_signed = True",
            "                num_bits = 128",
            "            elif ltyp == \"int256\":",
            "                is_signed = True",
            "                num_bits = 256",
            "            elif ltyp == \"uint8\":",
            "                is_signed = False",
            "                num_bits = 8",
            "            else:",
            "                is_signed = False",
            "                num_bits = 256",
            "",
            "            if isinstance(self.expr.left, vy_ast.Int):",
            "                value = self.expr.left.value",
            "                upper_bound = calculate_largest_power(value, num_bits, is_signed) + 1",
            "                # for signed integers, this also prevents negative values",
            "                clamp = [\"lt\", right, upper_bound]",
            "                return IRnode.from_list(",
            "                    [\"seq\", [\"assert\", clamp], [\"exp\", left, right]],",
            "                    typ=new_typ,",
            "                )",
            "            elif isinstance(self.expr.right, vy_ast.Int):",
            "                value = self.expr.right.value",
            "                upper_bound = calculate_largest_base(value, num_bits, is_signed) + 1",
            "                if is_signed:",
            "                    clamp = [\"and\", [\"slt\", left, upper_bound], [\"sgt\", left, -upper_bound]]",
            "                else:",
            "                    clamp = [\"lt\", left, upper_bound]",
            "                return IRnode.from_list(",
            "                    [\"seq\", [\"assert\", clamp], [\"exp\", left, right]], typ=new_typ",
            "                )",
            "            else:",
            "                # `a ** b` where neither `a` or `b` are known",
            "                # TODO this is currently unreachable, once we implement a way to do it safely",
            "                # remove the check in `vyper/context/types/value/numeric.py`",
            "                return",
            "",
            "        if arith is None:",
            "            return",
            "",
            "        arith = IRnode.from_list(arith, typ=new_typ)",
            "",
            "        p = [",
            "            \"with\",",
            "            \"l\",",
            "            left,",
            "            [",
            "                \"with\",",
            "                \"r\",",
            "                right,",
            "                # note clamp_basetype is a noop on [u]int256",
            "                # note: clamp_basetype throws on unclampable input",
            "                clamp_basetype(arith),",
            "            ],",
            "        ]",
            "        return IRnode.from_list(p, typ=new_typ)",
            "",
            "    def build_in_comparator(self):",
            "        left = Expr(self.expr.left, self.context).ir_node",
            "        right = Expr(self.expr.right, self.context).ir_node",
            "",
            "        # temporary kludge to block #2637 bug",
            "        # TODO actually fix the bug",
            "        if not isinstance(left.typ, BaseType):",
            "            raise TypeMismatch(",
            "                \"`in` not allowed for arrays of non-base types, tracked in issue #2637\", self.expr",
            "            )",
            "",
            "        if isinstance(self.expr.op, vy_ast.In):",
            "            found, not_found = 1, 0",
            "        elif isinstance(self.expr.op, vy_ast.NotIn):",
            "            found, not_found = 0, 1",
            "        else:",
            "            return  # pragma: notest",
            "",
            "        i = IRnode.from_list(self.context.fresh_varname(\"in_ix\"), typ=\"uint256\")",
            "",
            "        found_ptr = self.context.new_internal_variable(BaseType(\"bool\"))",
            "",
            "        ret = [\"seq\"]",
            "",
            "        left = unwrap_location(left)",
            "        with left.cache_when_complex(\"needle\") as (b1, left), right.cache_when_complex(",
            "            \"haystack\"",
            "        ) as (b2, right):",
            "            if right.value == \"multi\":",
            "                # Copy literal to memory to be compared.",
            "                tmp_list = IRnode.from_list(",
            "                    self.context.new_internal_variable(right.typ), typ=right.typ, location=MEMORY",
            "                )",
            "                ret.append(make_setter(tmp_list, right))",
            "",
            "                right = tmp_list",
            "",
            "            # location of i'th item from list",
            "            ith_element_ptr = get_element_ptr(right, i, array_bounds_check=False)",
            "            ith_element = unwrap_location(ith_element_ptr)",
            "",
            "            if isinstance(right.typ, SArrayType):",
            "                len_ = right.typ.count",
            "            else:",
            "                len_ = get_dyn_array_count(right)",
            "",
            "            # Condition repeat loop has to break on.",
            "            # TODO maybe put result on the stack",
            "            loop_body = [",
            "                \"if\",",
            "                [\"eq\", left, ith_element],",
            "                [\"seq\", [\"mstore\", found_ptr, found], \"break\"],  # store true.",
            "            ]",
            "            loop = [\"repeat\", i, 0, len_, right.typ.count, loop_body]",
            "",
            "            ret.append(",
            "                [",
            "                    \"seq\",",
            "                    [\"mstore\", found_ptr, not_found],",
            "                    loop,",
            "                    [\"mload\", found_ptr],",
            "                ]",
            "            )",
            "",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)), typ=\"bool\")",
            "",
            "    @staticmethod",
            "    def _signed_to_unsigned_comparision_op(op):",
            "        translation_map = {",
            "            \"sgt\": \"gt\",",
            "            \"sge\": \"ge\",",
            "            \"sle\": \"le\",",
            "            \"slt\": \"lt\",",
            "        }",
            "        if op in translation_map:",
            "            return translation_map[op]",
            "        else:",
            "            return op",
            "",
            "    def parse_Compare(self):",
            "        left = Expr.parse_value_expr(self.expr.left, self.context)",
            "        right = Expr.parse_value_expr(self.expr.right, self.context)",
            "",
            "        if right.value is None:",
            "            return",
            "",
            "        if isinstance(self.expr.op, (vy_ast.In, vy_ast.NotIn)):",
            "            if isinstance(right.typ, ArrayLike):",
            "                return self.build_in_comparator()",
            "            return  # pragma: notest",
            "",
            "        if isinstance(self.expr.op, vy_ast.Gt):",
            "            op = \"sgt\"",
            "        elif isinstance(self.expr.op, vy_ast.GtE):",
            "            op = \"sge\"",
            "        elif isinstance(self.expr.op, vy_ast.LtE):",
            "            op = \"sle\"",
            "        elif isinstance(self.expr.op, vy_ast.Lt):",
            "            op = \"slt\"",
            "        elif isinstance(self.expr.op, vy_ast.Eq):",
            "            op = \"eq\"",
            "        elif isinstance(self.expr.op, vy_ast.NotEq):",
            "            op = \"ne\"",
            "        else:",
            "            return  # pragma: notest",
            "",
            "        # Compare (limited to 32) byte arrays.",
            "        if isinstance(left.typ, ByteArrayLike) and isinstance(right.typ, ByteArrayLike):",
            "            left = Expr(self.expr.left, self.context).ir_node",
            "            right = Expr(self.expr.right, self.context).ir_node",
            "",
            "            left_keccak = keccak256_helper(self.expr, left, self.context)",
            "            right_keccak = keccak256_helper(self.expr, right, self.context)",
            "",
            "            if op not in (\"eq\", \"ne\"):",
            "                return  # raises",
            "            else:",
            "                # use hash even for Bytes[N<=32], because there could be dirty",
            "                # bytes past the bytes data.",
            "                return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")",
            "",
            "        # Compare other types.",
            "        elif is_numeric_type(left.typ) and is_numeric_type(right.typ):",
            "            if left.typ.typ == right.typ.typ == \"uint256\":",
            "                # this works because we only have one unsigned integer type",
            "                # in the future if others are added, this logic must be expanded",
            "                op = self._signed_to_unsigned_comparision_op(op)",
            "",
            "        elif isinstance(left.typ, BaseType) and isinstance(right.typ, BaseType):",
            "            if op not in (\"eq\", \"ne\"):",
            "                return",
            "        else:",
            "            # kludge to block behavior in #2638",
            "            # TODO actually implement equality for complex types",
            "            raise TypeMismatch(",
            "                f\"operation not yet supported for {left.typ}, {right.typ}, see issue #2638\",",
            "                self.expr.op,",
            "            )",
            "",
            "        return IRnode.from_list([op, left, right], typ=\"bool\")",
            "",
            "    def parse_BoolOp(self):",
            "        for value in self.expr.values:",
            "            # Check for boolean operations with non-boolean inputs",
            "            _expr = Expr.parse_value_expr(value, self.context)",
            "            if not is_base_type(_expr.typ, \"bool\"):",
            "                return",
            "",
            "        def _build_if_ir(condition, true, false):",
            "            # generate a basic if statement in IR",
            "            o = [\"if\", condition, true, false]",
            "            return o",
            "",
            "        if isinstance(self.expr.op, vy_ast.And):",
            "            # create the initial `x and y` from the final two values",
            "            ir_node = _build_if_ir(",
            "                Expr.parse_value_expr(self.expr.values[-2], self.context),",
            "                Expr.parse_value_expr(self.expr.values[-1], self.context),",
            "                [0],",
            "            )",
            "            # iterate backward through the remaining values",
            "            for node in self.expr.values[-3::-1]:",
            "                ir_node = _build_if_ir(Expr.parse_value_expr(node, self.context), ir_node, [0])",
            "",
            "        elif isinstance(self.expr.op, vy_ast.Or):",
            "            # create the initial `x or y` from the final two values",
            "            ir_node = _build_if_ir(",
            "                Expr.parse_value_expr(self.expr.values[-2], self.context),",
            "                [1],",
            "                Expr.parse_value_expr(self.expr.values[-1], self.context),",
            "            )",
            "",
            "            # iterate backward through the remaining values",
            "            for node in self.expr.values[-3::-1]:",
            "                ir_node = _build_if_ir(Expr.parse_value_expr(node, self.context), 1, ir_node)",
            "        else:",
            "            raise TypeCheckFailure(f\"Unexpected boolean operator: {type(self.expr.op).__name__}\")",
            "",
            "        return IRnode.from_list(ir_node, typ=\"bool\")",
            "",
            "    # Unary operations (only \"not\" supported)",
            "    def parse_UnaryOp(self):",
            "        operand = Expr.parse_value_expr(self.expr.operand, self.context)",
            "        if isinstance(self.expr.op, vy_ast.Not):",
            "            if isinstance(operand.typ, BaseType) and operand.typ.typ == \"bool\":",
            "                return IRnode.from_list([\"iszero\", operand], typ=\"bool\")",
            "        elif isinstance(self.expr.op, vy_ast.USub) and is_numeric_type(operand.typ):",
            "            assert operand.typ._num_info.is_signed",
            "            # Clamp on minimum integer value as we cannot negate that value",
            "            # (all other integer values are fine)",
            "            min_int_val, _ = operand.typ._num_info.bounds",
            "            return IRnode.from_list(",
            "                [\"sub\", 0, [\"clampgt\", operand, min_int_val]],",
            "                typ=operand.typ,",
            "            )",
            "",
            "    def _is_valid_interface_assign(self):",
            "        if self.expr.args and len(self.expr.args) == 1:",
            "            arg_ir = Expr(self.expr.args[0], self.context).ir_node",
            "            if arg_ir.typ == BaseType(\"address\"):",
            "                return True, arg_ir",
            "        return False, None",
            "",
            "    # Function calls",
            "    def parse_Call(self):",
            "        # TODO check out this inline import",
            "        from vyper.builtin_functions import DISPATCH_TABLE",
            "",
            "        if isinstance(self.expr.func, vy_ast.Name):",
            "            function_name = self.expr.func.id",
            "",
            "            if function_name in DISPATCH_TABLE:",
            "                return DISPATCH_TABLE[function_name].build_IR(self.expr, self.context)",
            "",
            "            # Struct constructors do not need `self` prefix.",
            "            elif function_name in self.context.structs:",
            "                args = self.expr.args",
            "                if len(args) == 1 and isinstance(args[0], vy_ast.Dict):",
            "                    return Expr.struct_literals(args[0], function_name, self.context)",
            "",
            "            # Interface assignment. Bar(<address>).",
            "            elif function_name in self.context.sigs:",
            "                ret, arg_ir = self._is_valid_interface_assign()",
            "                if ret is True:",
            "                    arg_ir.typ = InterfaceType(function_name)  # Cast to Correct interface type.",
            "                    return arg_ir",
            "",
            "        elif isinstance(self.expr.func, vy_ast.Attribute) and self.expr.func.attr == \"pop\":",
            "            darray = Expr(self.expr.func.value, self.context).ir_node",
            "            assert len(self.expr.args) == 0",
            "            assert isinstance(darray.typ, DArrayType)",
            "            return pop_dyn_array(",
            "                darray,",
            "                return_popped_item=True,",
            "            )",
            "",
            "        elif (",
            "            isinstance(self.expr.func, vy_ast.Attribute)",
            "            and isinstance(self.expr.func.value, vy_ast.Name)",
            "            and self.expr.func.value.id == \"self\"",
            "        ):  # noqa: E501",
            "            return self_call.ir_for_self_call(self.expr, self.context)",
            "        else:",
            "            return external_call.ir_for_external_call(self.expr, self.context)",
            "",
            "    def parse_List(self):",
            "        typ = new_type_to_old_type(self.expr._metadata[\"type\"])",
            "        if len(self.expr.elements) == 0:",
            "            return IRnode.from_list(\"~empty\", typ=typ)",
            "",
            "        multi_ir = [Expr(x, self.context).ir_node for x in self.expr.elements]",
            "",
            "        return IRnode.from_list([\"multi\"] + multi_ir, typ=typ)",
            "",
            "    def parse_Tuple(self):",
            "        tuple_elements = [Expr(x, self.context).ir_node for x in self.expr.elements]",
            "        typ = TupleType([x.typ for x in tuple_elements], is_literal=True)",
            "        multi_ir = IRnode.from_list([\"multi\"] + tuple_elements, typ=typ)",
            "        return multi_ir",
            "",
            "    @staticmethod",
            "    def struct_literals(expr, name, context):",
            "        member_subs = {}",
            "        member_typs = {}",
            "        for key, value in zip(expr.keys, expr.values):",
            "            if not isinstance(key, vy_ast.Name):",
            "                return",
            "            if key.id in member_subs:",
            "                return",
            "            sub = Expr(value, context).ir_node",
            "            member_subs[key.id] = sub",
            "            member_typs[key.id] = sub.typ",
            "        return IRnode.from_list(",
            "            [\"multi\"] + [member_subs[key] for key in member_subs.keys()],",
            "            typ=StructType(member_typs, name, is_literal=True),",
            "        )",
            "",
            "    # Parse an expression that results in a value",
            "    @classmethod",
            "    def parse_value_expr(cls, expr, context):",
            "        return unwrap_location(cls(expr, context).ir_node)",
            "",
            "    # Parse an expression that represents a pointer to memory/calldata or storage.",
            "    @classmethod",
            "    def parse_pointer_expr(cls, expr, context):",
            "        o = cls(expr, context).ir_node",
            "        if not o.location:",
            "            raise StructureException(\"Looking for a variable location, instead got a value\", expr)",
            "        return o"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "8": [],
            "9": [],
            "804": [
                "Expr",
                "parse_Compare"
            ],
            "805": [
                "Expr",
                "parse_Compare"
            ],
            "806": [
                "Expr",
                "parse_Compare"
            ],
            "807": [
                "Expr",
                "parse_Compare"
            ],
            "808": [
                "Expr",
                "parse_Compare"
            ],
            "809": [
                "Expr",
                "parse_Compare"
            ],
            "810": [
                "Expr",
                "parse_Compare"
            ],
            "811": [
                "Expr",
                "parse_Compare"
            ],
            "812": [
                "Expr",
                "parse_Compare"
            ],
            "813": [
                "Expr",
                "parse_Compare"
            ],
            "814": [
                "Expr",
                "parse_Compare"
            ],
            "815": [
                "Expr",
                "parse_Compare"
            ],
            "816": [
                "Expr",
                "parse_Compare"
            ],
            "819": [
                "Expr",
                "parse_Compare"
            ],
            "820": [
                "Expr",
                "parse_Compare"
            ],
            "821": [
                "Expr",
                "parse_Compare"
            ],
            "822": [
                "Expr",
                "parse_Compare"
            ],
            "823": [
                "Expr",
                "parse_Compare"
            ],
            "824": [
                "Expr",
                "parse_Compare"
            ],
            "825": [
                "Expr",
                "parse_Compare"
            ],
            "826": [
                "Expr",
                "parse_Compare"
            ],
            "827": [
                "Expr",
                "parse_Compare"
            ]
        },
        "addLocation": []
    },
    "vyper/codegen/keccak256_helper.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from math import ceil"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from vyper.codegen.core import ensure_in_memory"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3,
                "PatchRowcode": "+from vyper.codegen.core import bytes_data_ptr, ensure_in_memory, get_bytearray_length"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from vyper.codegen.ir_node import IRnode"
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from vyper.codegen.types import BaseType, ByteArrayLike, is_base_type"
            },
            "6": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from vyper.exceptions import CompilerPanic"
            },
            "7": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     return SHA3_BASE + num_words * SHA3_PER_WORD"
            },
            "8": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def keccak256_helper(expr, ir_arg, context):"
            },
            "11": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    sub = ir_arg  # TODO get rid of useless variable"
            },
            "12": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    _check_byteslike(sub.typ, expr)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+def keccak256_helper(expr, to_hash, context):"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+    _check_byteslike(to_hash.typ, expr)"
            },
            "15": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 27,
                "PatchRowcode": "     # Can hash literals"
            },
            "17": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "     # TODO this is dead code."
            },
            "18": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if isinstance(sub, bytes):"
            },
            "19": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return IRnode.from_list(bytes_to_int(keccak256(sub)), typ=BaseType(\"bytes32\"))"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+    if isinstance(to_hash, bytes):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+        return IRnode.from_list(bytes_to_int(keccak256(to_hash)), typ=BaseType(\"bytes32\"))"
            },
            "22": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "     # Can hash bytes32 objects"
            },
            "24": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if is_base_type(sub.typ, \"bytes32\"):"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+    if is_base_type(to_hash.typ, \"bytes32\"):"
            },
            "26": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "         return IRnode.from_list("
            },
            "27": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "             ["
            },
            "28": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "                 \"seq\","
            },
            "29": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+                [\"mstore\", MemoryPositions.FREE_VAR_SPACE, to_hash],"
            },
            "31": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "                 [\"sha3\", MemoryPositions.FREE_VAR_SPACE, 32],"
            },
            "32": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "             ],"
            },
            "33": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "             typ=BaseType(\"bytes32\"),"
            },
            "34": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "             add_gas_estimate=_gas_bound(1),"
            },
            "35": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "         )"
            },
            "36": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    sub = ensure_in_memory(sub, context)"
            },
            "38": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "39": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return IRnode.from_list("
            },
            "40": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ["
            },
            "41": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"with\","
            },
            "42": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"_buf\","
            },
            "43": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            sub,"
            },
            "44": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            [\"sha3\", [\"add\", \"_buf\", 32], [\"mload\", \"_buf\"]],"
            },
            "45": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ],"
            },
            "46": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        typ=BaseType(\"bytes32\"),"
            },
            "47": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        annotation=\"keccak256\","
            },
            "48": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        add_gas_estimate=_gas_bound(ceil(sub.typ.maxlen / 32)),"
            },
            "49": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    )"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+    to_hash = ensure_in_memory(to_hash, context)"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+    with to_hash.cache_when_complex(\"buf\") as (b1, to_hash):"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+        data = bytes_data_ptr(to_hash)"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+        len_ = get_bytearray_length(to_hash)"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+        return b1.resolve("
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+            IRnode.from_list("
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+                [\"sha3\", data, len_],"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+                typ=\"bytes32\","
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+                annotation=\"keccak256\","
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+                add_gas_estimate=_gas_bound(ceil(to_hash.typ.maxlen / 32)),"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+            )"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+        )"
            }
        },
        "frontPatchFile": [
            "from math import ceil",
            "",
            "from vyper.codegen.core import ensure_in_memory",
            "from vyper.codegen.ir_node import IRnode",
            "from vyper.codegen.types import BaseType, ByteArrayLike, is_base_type",
            "from vyper.exceptions import CompilerPanic",
            "from vyper.utils import MemoryPositions, bytes_to_int, keccak256",
            "",
            "",
            "def _check_byteslike(typ, _expr):",
            "    if not isinstance(typ, ByteArrayLike) and not is_base_type(typ, \"bytes32\"):",
            "        # NOTE this may be checked at a higher level, but just be safe",
            "        raise CompilerPanic(",
            "            \"keccak256 only accepts bytes-like objects\",",
            "        )",
            "",
            "",
            "def _gas_bound(num_words):",
            "    SHA3_BASE = 30",
            "    SHA3_PER_WORD = 6",
            "    return SHA3_BASE + num_words * SHA3_PER_WORD",
            "",
            "",
            "def keccak256_helper(expr, ir_arg, context):",
            "    sub = ir_arg  # TODO get rid of useless variable",
            "    _check_byteslike(sub.typ, expr)",
            "",
            "    # Can hash literals",
            "    # TODO this is dead code.",
            "    if isinstance(sub, bytes):",
            "        return IRnode.from_list(bytes_to_int(keccak256(sub)), typ=BaseType(\"bytes32\"))",
            "",
            "    # Can hash bytes32 objects",
            "    if is_base_type(sub.typ, \"bytes32\"):",
            "        return IRnode.from_list(",
            "            [",
            "                \"seq\",",
            "                [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],",
            "                [\"sha3\", MemoryPositions.FREE_VAR_SPACE, 32],",
            "            ],",
            "            typ=BaseType(\"bytes32\"),",
            "            add_gas_estimate=_gas_bound(1),",
            "        )",
            "",
            "    sub = ensure_in_memory(sub, context)",
            "",
            "    return IRnode.from_list(",
            "        [",
            "            \"with\",",
            "            \"_buf\",",
            "            sub,",
            "            [\"sha3\", [\"add\", \"_buf\", 32], [\"mload\", \"_buf\"]],",
            "        ],",
            "        typ=BaseType(\"bytes32\"),",
            "        annotation=\"keccak256\",",
            "        add_gas_estimate=_gas_bound(ceil(sub.typ.maxlen / 32)),",
            "    )"
        ],
        "afterPatchFile": [
            "from math import ceil",
            "",
            "from vyper.codegen.core import bytes_data_ptr, ensure_in_memory, get_bytearray_length",
            "from vyper.codegen.ir_node import IRnode",
            "from vyper.codegen.types import BaseType, ByteArrayLike, is_base_type",
            "from vyper.exceptions import CompilerPanic",
            "from vyper.utils import MemoryPositions, bytes_to_int, keccak256",
            "",
            "",
            "def _check_byteslike(typ, _expr):",
            "    if not isinstance(typ, ByteArrayLike) and not is_base_type(typ, \"bytes32\"):",
            "        # NOTE this may be checked at a higher level, but just be safe",
            "        raise CompilerPanic(",
            "            \"keccak256 only accepts bytes-like objects\",",
            "        )",
            "",
            "",
            "def _gas_bound(num_words):",
            "    SHA3_BASE = 30",
            "    SHA3_PER_WORD = 6",
            "    return SHA3_BASE + num_words * SHA3_PER_WORD",
            "",
            "",
            "def keccak256_helper(expr, to_hash, context):",
            "    _check_byteslike(to_hash.typ, expr)",
            "",
            "    # Can hash literals",
            "    # TODO this is dead code.",
            "    if isinstance(to_hash, bytes):",
            "        return IRnode.from_list(bytes_to_int(keccak256(to_hash)), typ=BaseType(\"bytes32\"))",
            "",
            "    # Can hash bytes32 objects",
            "    if is_base_type(to_hash.typ, \"bytes32\"):",
            "        return IRnode.from_list(",
            "            [",
            "                \"seq\",",
            "                [\"mstore\", MemoryPositions.FREE_VAR_SPACE, to_hash],",
            "                [\"sha3\", MemoryPositions.FREE_VAR_SPACE, 32],",
            "            ],",
            "            typ=BaseType(\"bytes32\"),",
            "            add_gas_estimate=_gas_bound(1),",
            "        )",
            "",
            "    to_hash = ensure_in_memory(to_hash, context)",
            "",
            "    with to_hash.cache_when_complex(\"buf\") as (b1, to_hash):",
            "        data = bytes_data_ptr(to_hash)",
            "        len_ = get_bytearray_length(to_hash)",
            "        return b1.resolve(",
            "            IRnode.from_list(",
            "                [\"sha3\", data, len_],",
            "                typ=\"bytes32\",",
            "                annotation=\"keccak256\",",
            "                add_gas_estimate=_gas_bound(ceil(to_hash.typ.maxlen / 32)),",
            "            )",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "3": [],
            "24": [
                "keccak256_helper"
            ],
            "25": [
                "keccak256_helper"
            ],
            "26": [
                "keccak256_helper"
            ],
            "30": [
                "keccak256_helper"
            ],
            "31": [
                "keccak256_helper"
            ],
            "34": [
                "keccak256_helper"
            ],
            "38": [
                "keccak256_helper"
            ],
            "45": [
                "keccak256_helper"
            ],
            "46": [
                "keccak256_helper"
            ],
            "47": [
                "keccak256_helper"
            ],
            "48": [
                "keccak256_helper"
            ],
            "49": [
                "keccak256_helper"
            ],
            "50": [
                "keccak256_helper"
            ],
            "51": [
                "keccak256_helper"
            ],
            "52": [
                "keccak256_helper"
            ],
            "53": [
                "keccak256_helper"
            ],
            "54": [
                "keccak256_helper"
            ],
            "55": [
                "keccak256_helper"
            ],
            "56": [
                "keccak256_helper"
            ],
            "57": [
                "keccak256_helper"
            ]
        },
        "addLocation": []
    }
}