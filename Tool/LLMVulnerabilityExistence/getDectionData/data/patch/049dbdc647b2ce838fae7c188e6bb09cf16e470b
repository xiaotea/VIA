{
    "vyper/codegen/core.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 123,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "         # for ABI-encoded dynamic data, we must loop to unpack, since"
            },
            "2": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "         # the layout does not match our memory layout"
            },
            "3": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        should_loop = ("
            },
            "4": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            src.encoding in (Encoding.ABI, Encoding.JSON_ABI)"
            },
            "5": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            and src.typ.subtype.abi_type.is_dynamic()"
            },
            "6": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+        should_loop = src.encoding == Encoding.ABI and src.typ.subtype.abi_type.is_dynamic()"
            },
            "8": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 127,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         # if the subtype is dynamic, there might be a lot of"
            },
            "10": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "         # unused space inside of each element. for instance"
            },
            "11": {
                "beforePatchRowNumber": 379,
                "afterPatchRowNumber": 376,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 377,
                "PatchRowcode": "     ofst = 0  # offset from parent start"
            },
            "13": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 378,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+    if parent.encoding == Encoding.ABI:"
            },
            "16": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 380,
                "PatchRowcode": "         if parent.location == STORAGE:"
            },
            "17": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest"
            },
            "18": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 382,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 446,
                "PatchRowcode": "         # NOTE: there are optimization rules for this when ix or bound is literal"
            },
            "20": {
                "beforePatchRowNumber": 450,
                "afterPatchRowNumber": 447,
                "PatchRowcode": "         ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)"
            },
            "21": {
                "beforePatchRowNumber": 451,
                "afterPatchRowNumber": 448,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 452,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 449,
                "PatchRowcode": "+    if parent.encoding == Encoding.ABI:"
            },
            "24": {
                "beforePatchRowNumber": 453,
                "afterPatchRowNumber": 450,
                "PatchRowcode": "         if parent.location == STORAGE:"
            },
            "25": {
                "beforePatchRowNumber": 454,
                "afterPatchRowNumber": 451,
                "PatchRowcode": "             raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest"
            },
            "26": {
                "beforePatchRowNumber": 455,
                "afterPatchRowNumber": 452,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 703,
                "afterPatchRowNumber": 700,
                "PatchRowcode": " # returns True if t is ABI encoded and is a type that needs any kind of"
            },
            "28": {
                "beforePatchRowNumber": 704,
                "afterPatchRowNumber": 701,
                "PatchRowcode": " # validation"
            },
            "29": {
                "beforePatchRowNumber": 705,
                "afterPatchRowNumber": 702,
                "PatchRowcode": " def needs_clamp(t, encoding):"
            },
            "30": {
                "beforePatchRowNumber": 706,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 703,
                "PatchRowcode": "+    if encoding == Encoding.VYPER:"
            },
            "32": {
                "beforePatchRowNumber": 707,
                "afterPatchRowNumber": 704,
                "PatchRowcode": "         return False"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 705,
                "PatchRowcode": "+    if encoding != Encoding.ABI:"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 706,
                "PatchRowcode": "+        raise CompilerPanic(\"unreachable\")  # pragma: notest"
            },
            "35": {
                "beforePatchRowNumber": 708,
                "afterPatchRowNumber": 707,
                "PatchRowcode": "     if isinstance(t, (ByteArrayLike, DArrayType)):"
            },
            "36": {
                "beforePatchRowNumber": 709,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if encoding == Encoding.JSON_ABI:"
            },
            "37": {
                "beforePatchRowNumber": 710,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # don't have bytestring size bound from json, don't clamp"
            },
            "38": {
                "beforePatchRowNumber": 711,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return False"
            },
            "39": {
                "beforePatchRowNumber": 712,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return True"
            },
            "40": {
                "beforePatchRowNumber": 713,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):"
            },
            "41": {
                "beforePatchRowNumber": 714,
                "afterPatchRowNumber": 708,
                "PatchRowcode": "         return True"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 709,
                "PatchRowcode": "+    if isinstance(t, BaseType):"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 710,
                "PatchRowcode": "+        return t.typ not in (\"int256\", \"uint256\", \"bytes32\")"
            },
            "44": {
                "beforePatchRowNumber": 715,
                "afterPatchRowNumber": 711,
                "PatchRowcode": "     if isinstance(t, SArrayType):"
            },
            "45": {
                "beforePatchRowNumber": 716,
                "afterPatchRowNumber": 712,
                "PatchRowcode": "         return needs_clamp(t.subtype, encoding)"
            },
            "46": {
                "beforePatchRowNumber": 717,
                "afterPatchRowNumber": 713,
                "PatchRowcode": "     if isinstance(t, TupleLike):"
            },
            "47": {
                "beforePatchRowNumber": 718,
                "afterPatchRowNumber": 714,
                "PatchRowcode": "         return any(needs_clamp(m, encoding) for m in t.tuple_members())"
            },
            "48": {
                "beforePatchRowNumber": 719,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return False"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 715,
                "PatchRowcode": "+"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 716,
                "PatchRowcode": "+    raise CompilerPanic(\"unreachable\")  # pragma: notest"
            },
            "51": {
                "beforePatchRowNumber": 720,
                "afterPatchRowNumber": 717,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 721,
                "afterPatchRowNumber": 718,
                "PatchRowcode": " "
            },
            "53": {
                "beforePatchRowNumber": 722,
                "afterPatchRowNumber": 719,
                "PatchRowcode": " # Create an x=y statement, where the types may be compound"
            }
        },
        "frontPatchFile": [
            "from vyper import ast as vy_ast",
            "from vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import (",
            "    DYNAMIC_ARRAY_OVERHEAD,",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    DArrayType,",
            "    MappingType,",
            "    SArrayType,",
            "    StructType,",
            "    TupleLike,",
            "    TupleType,",
            "    ceil32,",
            "    is_bytes_m_type,",
            "    is_decimal_type,",
            "    is_integer_type,",
            ")",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch",
            "from vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD",
            "",
            "",
            "# propagate revert message when calls to external contracts fail",
            "def check_external_call(call_ir):",
            "    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]",
            "    revert = [\"revert\", 0, \"returndatasize\"]",
            "",
            "    propagate_revert_ir = [\"seq\", copy_revertdata, revert]",
            "    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]",
            "",
            "",
            "# cost per byte of the identity precompile",
            "def _identity_gas_bound(num_bytes):",
            "    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)",
            "",
            "",
            "def _calldatacopy_gas_bound(num_bytes):",
            "    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "def _codecopy_gas_bound(num_bytes):",
            "    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "# Copy byte array word-for-word (including layout)",
            "def make_byte_array_copier(dst, src):",
            "    assert isinstance(src.typ, ByteArrayLike)",
            "    assert isinstance(dst.typ, ByteArrayLike)",
            "",
            "    if src.typ.maxlen > dst.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")",
            "    # stricter check for zeroing a byte array.",
            "    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"",
            "        )  # pragma: notest",
            "",
            "    if src.value == \"~empty\":",
            "        # set length word to 0.",
            "        return STORE(dst, 0)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src):",
            "        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):",
            "",
            "            max_bytes = src.typ.maxlen",
            "",
            "            ret = [\"seq\"]",
            "            # store length",
            "            ret.append(STORE(dst, len_))",
            "",
            "            dst = bytes_data_ptr(dst)",
            "            src = bytes_data_ptr(src)",
            "",
            "            ret.append(copy_bytes(dst, src, len_, max_bytes))",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "def bytes_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, ByteArrayLike)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def dynarray_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, DArrayType)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def _dynarray_make_setter(dst, src):",
            "    assert isinstance(src.typ, DArrayType)",
            "    assert isinstance(dst.typ, DArrayType)",
            "",
            "    if src.value == \"~empty\":",
            "        return IRnode.from_list(STORE(dst, 0))",
            "",
            "    if src.value == \"multi\":",
            "        ret = [\"seq\"]",
            "        # handle literals",
            "",
            "        # write the length word",
            "        store_length = STORE(dst, len(src.args))",
            "        ann = None",
            "        if src.annotation is not None:",
            "            ann = f\"len({src.annotation})\"",
            "        store_length = IRnode.from_list(store_length, annotation=ann)",
            "        ret.append(store_length)",
            "",
            "        n_items = len(src.args)",
            "        for i in range(n_items):",
            "            k = IRnode.from_list(i, typ=\"uint256\")",
            "            dst_i = get_element_ptr(dst, k, array_bounds_check=False)",
            "            src_i = get_element_ptr(src, k, array_bounds_check=False)",
            "            ret.append(make_setter(dst_i, src_i))",
            "",
            "        return ret",
            "",
            "    with src.cache_when_complex(\"darray_src\") as (b1, src):",
            "",
            "        # for ABI-encoded dynamic data, we must loop to unpack, since",
            "        # the layout does not match our memory layout",
            "        should_loop = (",
            "            src.encoding in (Encoding.ABI, Encoding.JSON_ABI)",
            "            and src.typ.subtype.abi_type.is_dynamic()",
            "        )",
            "",
            "        # if the subtype is dynamic, there might be a lot of",
            "        # unused space inside of each element. for instance",
            "        # DynArray[DynArray[uint256, 100], 5] where all the child",
            "        # arrays are empty - for this case, we recursively call",
            "        # into make_setter instead of straight bytes copy",
            "        # TODO we can make this heuristic more precise, e.g.",
            "        # loop when subtype.is_dynamic AND location == storage",
            "        # OR array_size <= /bound where loop is cheaper than memcpy/",
            "        should_loop |= src.typ.subtype.abi_type.is_dynamic()",
            "        should_loop |= needs_clamp(src.typ.subtype, src.encoding)",
            "",
            "        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):",
            "            ret = [\"seq\"]",
            "",
            "            ret.append(STORE(dst, count))",
            "",
            "            if should_loop:",
            "                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")",
            "",
            "                loop_body = make_setter(",
            "                    get_element_ptr(dst, i, array_bounds_check=False),",
            "                    get_element_ptr(src, i, array_bounds_check=False),",
            "                )",
            "                loop_body.annotation = f\"{dst}[i] = {src}[i]\"",
            "",
            "                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])",
            "",
            "            else:",
            "                element_size = src.typ.subtype.memory_bytes_required",
            "                # number of elements * size of element in bytes",
            "                n_bytes = _mul(count, element_size)",
            "                max_bytes = src.typ.count * element_size",
            "",
            "                src_ = dynarray_data_ptr(src)",
            "                dst_ = dynarray_data_ptr(dst)",
            "                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))",
            "",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "# Copy bytes",
            "# Accepts 4 arguments:",
            "# (i) an IR node for the start position of the source",
            "# (ii) an IR node for the start position of the destination",
            "# (iii) an IR node for the length (in bytes)",
            "# (iv) a constant for the max length (in bytes)",
            "# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may",
            "# copy an entire (32-byte) word, depending on the copy routine chosen.",
            "# TODO maybe always pad to ceil32, to reduce dirty bytes bugs",
            "def copy_bytes(dst, src, length, length_bound):",
            "    annotation = f\"copy_bytes from {src} to {dst}\"",
            "",
            "    src = IRnode.from_list(src)",
            "    dst = IRnode.from_list(dst)",
            "    length = IRnode.from_list(length)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(",
            "        \"copy_bytes_count\"",
            "    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):",
            "",
            "        # fast code for common case where num bytes is small",
            "        # TODO expand this for more cases where num words is less than ~8",
            "        if length_bound <= 32:",
            "            copy_op = STORE(dst, LOAD(src))",
            "            ret = IRnode.from_list(copy_op, annotation=annotation)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):",
            "            # special cases: batch copy to memory",
            "            # TODO: iloadbytes",
            "            if src.location == MEMORY:",
            "                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]",
            "                gas_bound = _identity_gas_bound(length_bound)",
            "            elif src.location == CALLDATA:",
            "                copy_op = [\"calldatacopy\", dst, src, length]",
            "                gas_bound = _calldatacopy_gas_bound(length_bound)",
            "            elif src.location == DATA:",
            "                copy_op = [\"dloadbytes\", dst, src, length]",
            "                # note: dloadbytes compiles to CODECOPY",
            "                gas_bound = _codecopy_gas_bound(length_bound)",
            "",
            "            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):",
            "            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)",
            "            # compile to identity, CODECOPY respectively.",
            "            pass",
            "",
            "        # general case, copy word-for-word",
            "        # pseudocode for our approach (memory-storage as example):",
            "        # for i in range(len, bound=MAX_LEN):",
            "        #   sstore(_dst + i, mload(src + i * 32))",
            "        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")",
            "",
            "        n = [\"div\", [\"ceil32\", length], 32]",
            "        n_bound = ceil32(length_bound) // 32",
            "",
            "        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))",
            "        src_i = add_ofst(src, _mul(i, src.location.word_scale))",
            "",
            "        copy_one_word = STORE(dst_i, LOAD(src_i))",
            "",
            "        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]",
            "",
            "        return b1.resolve(",
            "            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))",
            "        )",
            "",
            "",
            "# get the number of bytes at runtime",
            "def get_bytearray_length(arg):",
            "    typ = BaseType(\"uint256\")",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "# get the number of elements at runtime",
            "def get_dyn_array_count(arg):",
            "    assert isinstance(arg.typ, DArrayType)",
            "",
            "    typ = BaseType(\"uint256\")",
            "",
            "    if arg.value == \"multi\":",
            "        return IRnode.from_list(len(arg.args), typ=typ)",
            "",
            "    if arg.value == \"~empty\":",
            "        # empty(DynArray[])",
            "        return IRnode.from_list(0, typ=typ)",
            "",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "def append_dyn_array(darray_node, elem_node):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "",
            "    assert darray_node.typ.count > 0, \"jerk boy u r out\"",
            "",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        len_ = get_dyn_array_count(darray_node)",
            "        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):",
            "            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])",
            "            ret.append(STORE(darray_node, [\"add\", len_, 1]))",
            "            # NOTE: typechecks elem_node",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            ret.append(",
            "                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)",
            "            )",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)))",
            "",
            "",
            "def pop_dyn_array(darray_node, return_popped_item):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]",
            "        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")",
            "",
            "        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):",
            "            ret.append(STORE(darray_node, new_len))",
            "",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            if return_popped_item:",
            "                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)",
            "                ret.append(popped_item)",
            "                typ = popped_item.typ",
            "                location = popped_item.location",
            "                encoding = popped_item.encoding",
            "            else:",
            "                typ, location, encoding = None, None, None",
            "            return IRnode.from_list(",
            "                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding",
            "            )",
            "",
            "",
            "def getpos(node):",
            "    return (",
            "        node.lineno,",
            "        node.col_offset,",
            "        getattr(node, \"end_lineno\", None),",
            "        getattr(node, \"end_col_offset\", None),",
            "    )",
            "",
            "",
            "# add an offset to a pointer, keeping location and encoding info",
            "def add_ofst(ptr, ofst):",
            "    ret = [\"add\", ptr, ofst]",
            "    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)",
            "",
            "",
            "# shorthand util",
            "def _mul(x, y):",
            "    ret = [\"mul\", x, y]",
            "    return IRnode.from_list(ret)",
            "",
            "",
            "# Resolve pointer locations for ABI-encoded data",
            "def _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):",
            "    member_abi_t = member_t.abi_type",
            "",
            "    # ABI encoding has length word and then pretends length is not there",
            "    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>",
            "    # note that inner array ofst is 0x20, not 0x40.",
            "    if has_length_word(parent.typ):",
            "        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "",
            "    ofst_ir = add_ofst(parent, ofst)",
            "",
            "    if member_abi_t.is_dynamic():",
            "        # double dereference, according to ABI spec",
            "        # TODO optimize special case: first dynamic item",
            "        # offset is statically known.",
            "        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))",
            "",
            "    return IRnode.from_list(",
            "        ofst_ir,",
            "        typ=member_t,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=f\"{parent}{ofst}\",",
            "    )",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_tuplelike(parent, key):",
            "    typ = parent.typ",
            "    assert isinstance(typ, TupleLike)",
            "",
            "    if isinstance(typ, StructType):",
            "        assert isinstance(key, str)",
            "        subtype = typ.members[key]",
            "        attrs = list(typ.tuple_keys())",
            "        index = attrs.index(key)",
            "        annotation = key",
            "    else:",
            "        assert isinstance(key, int)",
            "        subtype = typ.members[key]",
            "        attrs = list(range(len(typ.members)))",
            "        index = key",
            "        annotation = None",
            "",
            "    # generated by empty() + make_setter",
            "    if parent.value == \"~empty\":",
            "        return IRnode.from_list(\"~empty\", typ=subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"",
            "        return parent.args[index]",
            "",
            "    ofst = 0  # offset from parent start",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_t = typ.members[attrs[index]]",
            "",
            "        for i in range(index):",
            "            member_abi_t = typ.members[attrs[i]].abi_type",
            "            ofst += member_abi_t.embedded_static_size()",
            "",
            "        return _getelemptr_abi_helper(parent, member_t, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest",
            "",
            "    return IRnode.from_list(",
            "        add_ofst(parent, ofst),",
            "        typ=subtype,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=annotation,",
            "    )",
            "",
            "",
            "def has_length_word(typ):",
            "    return isinstance(typ, (DArrayType, ByteArrayLike))",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_array(parent, key, array_bounds_check):",
            "",
            "    assert isinstance(parent.typ, ArrayLike)",
            "",
            "    if not is_integer_type(key.typ):",
            "        raise TypeCheckFailure(f\"{key.typ} used as array index\")",
            "",
            "    subtype = parent.typ.subtype",
            "",
            "    if parent.value == \"~empty\":",
            "        if array_bounds_check:",
            "            # this case was previously missing a bounds check. codegen",
            "            # is a bit complicated when bounds check is required, so",
            "            # block it. there is no reason to index into a literal empty",
            "            # array anyways!",
            "            raise TypeCheckFailure(\"indexing into zero array not allowed\")",
            "        return IRnode.from_list(\"~empty\", subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert isinstance(key.value, int)",
            "        return parent.args[key.value]",
            "",
            "    ix = unwrap_location(key)",
            "",
            "    if array_bounds_check:",
            "        # clamplt works, even for signed ints. since two's-complement",
            "        # is used, if the index is negative, (unsigned) LT will interpret",
            "        # it as a very large number, larger than any practical value for",
            "        # an array index, and the clamp will throw an error.",
            "        clamp_op = \"uclamplt\"",
            "        is_darray = isinstance(parent.typ, DArrayType)",
            "        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count",
            "        # NOTE: there are optimization rules for this when ix or bound is literal",
            "        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)",
            "",
            "    if parent.encoding in (Encoding.ABI, Encoding.JSON_ABI):",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_abi_t = subtype.abi_type",
            "",
            "        ofst = _mul(ix, member_abi_t.embedded_static_size())",
            "",
            "        return _getelemptr_abi_helper(parent, subtype, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        element_size = subtype.storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        element_size = subtype.memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "",
            "    ofst = _mul(ix, element_size)",
            "",
            "    if has_length_word(parent.typ):",
            "        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "    else:",
            "        data_ptr = parent",
            "",
            "    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)",
            "",
            "",
            "def _get_element_ptr_mapping(parent, key):",
            "    assert isinstance(parent.typ, MappingType)",
            "    subtype = parent.typ.valuetype",
            "    key = unwrap_location(key)",
            "",
            "    # TODO when is key None?",
            "    if key is None or parent.location != STORAGE:",
            "        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")",
            "",
            "    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)",
            "",
            "",
            "# Take a value representing a memory or storage location, and descend down to",
            "# an element or member variable",
            "# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.",
            "def get_element_ptr(parent, key, array_bounds_check=True):",
            "    with parent.cache_when_complex(\"val\") as (b, parent):",
            "        typ = parent.typ",
            "",
            "        if isinstance(typ, TupleLike):",
            "            ret = _get_element_ptr_tuplelike(parent, key)",
            "",
            "        elif isinstance(typ, MappingType):",
            "            ret = _get_element_ptr_mapping(parent, key)",
            "",
            "        elif isinstance(typ, ArrayLike):",
            "            ret = _get_element_ptr_array(parent, key, array_bounds_check)",
            "",
            "        else:",
            "            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest",
            "",
            "        return b.resolve(ret)",
            "",
            "",
            "def LOAD(ptr: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.load_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr])",
            "",
            "",
            "def STORE(ptr: IRnode, val: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.store_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr, val])",
            "",
            "",
            "# Unwrap location",
            "def unwrap_location(orig):",
            "    if orig.location is not None:",
            "        return IRnode.from_list(LOAD(orig), typ=orig.typ)",
            "    else:",
            "        # CMC 2022-03-24 TODO refactor so this branch can be removed",
            "        if orig.value == \"~empty\":",
            "            return IRnode.from_list(0, typ=orig.typ)",
            "        return orig",
            "",
            "",
            "# utility function, constructs an IR tuple out of a list of IR nodes",
            "def ir_tuple_from_args(args):",
            "    typ = TupleType([x.typ for x in args])",
            "    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)",
            "",
            "",
            "def _needs_external_call_wrap(ir_typ):",
            "    # for calls to ABI conforming contracts.",
            "    # according to the ABI spec, return types are ALWAYS tuples even",
            "    # if only one element is being returned.",
            "    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding",
            "    # \"and the return values v_1, ..., v_k of f are encoded as",
            "    #",
            "    #    enc((v_1, ..., v_k))",
            "    #    i.e. the values are combined into a tuple and encoded.",
            "    # \"",
            "    # therefore, wrap it in a tuple if it's not already a tuple.",
            "    # for example, `bytes` is returned as abi-encoded (bytes,)",
            "    # and `(bytes,)` is returned as abi-encoded ((bytes,),)",
            "    # In general `-> X` gets returned as (X,)",
            "    # including structs. MyStruct is returned as abi-encoded (MyStruct,).",
            "    # (Sorry this is so confusing. I didn't make these rules.)",
            "",
            "    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)",
            "",
            "",
            "def calculate_type_for_external_return(ir_typ):",
            "    if _needs_external_call_wrap(ir_typ):",
            "        return TupleType([ir_typ])",
            "    return ir_typ",
            "",
            "",
            "def wrap_value_for_external_return(ir_val):",
            "    # used for LHS promotion",
            "    if _needs_external_call_wrap(ir_val.typ):",
            "        return ir_tuple_from_args([ir_val])",
            "    else:",
            "        return ir_val",
            "",
            "",
            "def set_type_for_external_return(ir_val):",
            "    # used for RHS promotion",
            "    ir_val.typ = calculate_type_for_external_return(ir_val.typ)",
            "",
            "",
            "# return a dummy IRnode with the given type",
            "def dummy_node_for_type(typ):",
            "    return IRnode(\"fake_node\", typ=typ)",
            "",
            "",
            "def _check_assign_bytes(left, right):",
            "    if right.typ.maxlen > left.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest",
            "    # stricter check for zeroing a byte array.",
            "    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "        )  # pragma: notest",
            "",
            "",
            "def _check_assign_list(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if left.value == \"multi\":",
            "        # Cannot do something like [a, b, c] = [1, 2, 3]",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left, SArrayType):",
            "        if not isinstance(right, SArrayType):",
            "            FAIL()  # pragma: notest",
            "        if left.typ.count != right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "    if isinstance(left, DArrayType):",
            "        if not isinstance(right, DArrayType):",
            "            FAIL()  # pragma: notest",
            "",
            "        if left.typ.count < right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # stricter check for zeroing",
            "        if right.value == \"~empty\" and right.typ.count != left.typ.count:",
            "            raise TypeCheckFailure(",
            "                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "            )  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "",
            "def _check_assign_tuple(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if not isinstance(right.typ, left.typ.__class__):",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left.typ, StructType):",
            "        for k in left.typ.members:",
            "            if k not in right.typ.members:",
            "                FAIL()  # pragma: notest",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(",
            "                dummy_node_for_type(left.typ.members[k]),",
            "                dummy_node_for_type(right.typ.members[k]),",
            "            )",
            "",
            "        for k in right.typ.members:",
            "            if k not in left.typ.members:",
            "                FAIL()  # pragma: notest",
            "",
            "        if left.typ.name != right.typ.name:",
            "            FAIL()  # pragma: notest",
            "",
            "    else:",
            "        if len(left.typ.members) != len(right.typ.members):",
            "            FAIL()  # pragma: notest",
            "        for (l, r) in zip(left.typ.members, right.typ.members):",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))",
            "",
            "",
            "# sanity check an assignment",
            "# typechecking source code is done at an earlier phase",
            "# this function is more of a sanity check for typechecking internally",
            "# generated assignments",
            "def check_assign(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")",
            "",
            "    if isinstance(left.typ, ByteArrayLike):",
            "        _check_assign_bytes(left, right)",
            "    elif isinstance(left.typ, ArrayLike):",
            "        _check_assign_list(left, right)",
            "    elif isinstance(left.typ, TupleLike):",
            "        _check_assign_tuple(left, right)",
            "",
            "    elif isinstance(left.typ, BaseType):",
            "        # TODO once we propagate types from typechecker, introduce this check:",
            "        # if left.typ != right.typ:",
            "        #    FAIL()  # pragma: notest",
            "        pass",
            "",
            "    else:  # pragma: nocover",
            "        FAIL()",
            "",
            "",
            "_label = 0",
            "",
            "",
            "# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol",
            "def _freshname(name):",
            "    global _label",
            "    _label += 1",
            "    return f\"{name}{_label}\"",
            "",
            "",
            "# returns True if t is ABI encoded and is a type that needs any kind of",
            "# validation",
            "def needs_clamp(t, encoding):",
            "    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):",
            "        return False",
            "    if isinstance(t, (ByteArrayLike, DArrayType)):",
            "        if encoding == Encoding.JSON_ABI:",
            "            # don't have bytestring size bound from json, don't clamp",
            "            return False",
            "        return True",
            "    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):",
            "        return True",
            "    if isinstance(t, SArrayType):",
            "        return needs_clamp(t.subtype, encoding)",
            "    if isinstance(t, TupleLike):",
            "        return any(needs_clamp(m, encoding) for m in t.tuple_members())",
            "    return False",
            "",
            "",
            "# Create an x=y statement, where the types may be compound",
            "def make_setter(left, right):",
            "    check_assign(left, right)",
            "",
            "    # Basic types",
            "    if isinstance(left.typ, BaseType):",
            "        enc = right.encoding  # unwrap_location butchers encoding",
            "        right = unwrap_location(right)",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, enc):",
            "            right = clamp_basetype(right)",
            "",
            "        return STORE(left, right)",
            "",
            "    # Byte arrays",
            "    elif isinstance(left.typ, ByteArrayLike):",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"bs_ptr\") as (b, right):",
            "                copier = make_byte_array_copier(left, right)",
            "                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])",
            "        else:",
            "            ret = make_byte_array_copier(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    elif isinstance(left.typ, DArrayType):",
            "        # TODO should we enable this?",
            "        # implicit conversion from sarray to darray",
            "        # if isinstance(right.typ, SArrayType):",
            "        #    return _complex_make_setter(left, right)",
            "",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"arr_ptr\") as (b, right):",
            "                copier = _dynarray_make_setter(left, right)",
            "                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])",
            "        else:",
            "            ret = _dynarray_make_setter(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    # Arrays",
            "    elif isinstance(left.typ, (SArrayType, TupleLike)):",
            "        return _complex_make_setter(left, right)",
            "",
            "",
            "def _complex_make_setter(left, right):",
            "    if right.value == \"~empty\" and left.location == MEMORY:",
            "        # optimized memzero",
            "        return mzero(left, left.typ.memory_bytes_required)",
            "",
            "    ret = [\"seq\"]",
            "",
            "    if isinstance(left.typ, SArrayType):",
            "        n_items = right.typ.count",
            "        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]",
            "",
            "    if isinstance(left.typ, TupleLike):",
            "        keys = left.typ.tuple_keys()",
            "",
            "    # if len(keyz) == 0:",
            "    #    return IRnode.from_list([\"pass\"])",
            "",
            "    # general case",
            "    # TODO use copy_bytes when the generated code is above a certain size",
            "    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):",
            "",
            "        for k in keys:",
            "            l_i = get_element_ptr(left, k, array_bounds_check=False)",
            "            r_i = get_element_ptr(right, k, array_bounds_check=False)",
            "            ret.append(make_setter(l_i, r_i))",
            "",
            "        return b1.resolve(b2.resolve(IRnode.from_list(ret)))",
            "",
            "",
            "def ensure_in_memory(ir_var, context):",
            "    \"\"\"Ensure a variable is in memory. This is useful for functions",
            "    which expect to operate on memory variables.",
            "    \"\"\"",
            "    if ir_var.location == MEMORY:",
            "        return ir_var",
            "",
            "    typ = ir_var.typ",
            "    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)",
            "    do_copy = make_setter(buf, ir_var)",
            "",
            "    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)",
            "",
            "",
            "def eval_seq(ir_node):",
            "    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so",
            "    that the value can be known without possibly evaluating side effects",
            "    \"\"\"",
            "    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:",
            "        return eval_seq(ir_node.args[-1])",
            "    if isinstance(ir_node.value, int):",
            "        return IRnode.from_list(ir_node)",
            "    return None",
            "",
            "",
            "# TODO move return checks to vyper/semantics/validation",
            "def is_return_from_function(node):",
            "    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":",
            "        return True",
            "    if isinstance(node, vy_ast.Return):",
            "        return True",
            "    elif isinstance(node, vy_ast.Raise):",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def check_single_exit(fn_node):",
            "    _check_return_body(fn_node, fn_node.body)",
            "    for node in fn_node.get_descendants(vy_ast.If):",
            "        _check_return_body(node, node.body)",
            "        if node.orelse:",
            "            _check_return_body(node, node.orelse)",
            "",
            "",
            "def _check_return_body(node, node_list):",
            "    return_count = len([n for n in node_list if is_return_from_function(n)])",
            "    if return_count > 1:",
            "        raise StructureException(",
            "            \"Too too many exit statements (return, raise or selfdestruct).\", node",
            "        )",
            "    # Check for invalid code after returns.",
            "    last_node_pos = len(node_list) - 1",
            "    for idx, n in enumerate(node_list):",
            "        if is_return_from_function(n) and idx < last_node_pos:",
            "            # is not last statement in body.",
            "            raise StructureException(",
            "                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]",
            "            )",
            "",
            "",
            "def mzero(dst, nbytes):",
            "    # calldatacopy from past-the-end gives zero bytes.",
            "    # cf. YP H.2 (ops section) with CALLDATACOPY spec.",
            "    return IRnode.from_list(",
            "        # calldatacopy mempos calldatapos len",
            "        [\"calldatacopy\", dst, \"calldatasize\", nbytes],",
            "        annotation=\"mzero\",",
            "    )",
            "",
            "",
            "# zero pad a bytearray according to the ABI spec. The last word",
            "# of the byte array needs to be right-padded with zeroes.",
            "def zero_pad(bytez_placeholder):",
            "    len_ = [\"mload\", bytez_placeholder]",
            "    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]",
            "    # the runtime length of the data rounded up to nearest 32",
            "    # from spec:",
            "    #   the actual value of X as a byte sequence,",
            "    #   followed by the *minimum* number of zero-bytes",
            "    #   such that len(enc(X)) is a multiple of 32.",
            "    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]",
            "    return IRnode.from_list(",
            "        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],",
            "        annotation=\"Zero pad\",",
            "    )",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shr(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shr\", bits, x]",
            "    return [\"div\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shl(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shl\", bits, x]",
            "    return [\"mul\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "def sar(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"sar\", bits, x]",
            "",
            "    # emulate for older arches. keep in mind note from EIP 145:",
            "    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds",
            "    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"",
            "    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]",
            "",
            "",
            "def clamp_bytestring(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, ByteArrayLike):",
            "        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest",
            "    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]",
            "",
            "",
            "def clamp_dyn_array(ir_node):",
            "    t = ir_node.typ",
            "    assert isinstance(t, DArrayType)",
            "    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]",
            "",
            "",
            "# clampers for basetype",
            "def clamp_basetype(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, BaseType):",
            "        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "    # copy of the input",
            "    ir_node = unwrap_location(ir_node)",
            "",
            "    if is_integer_type(t) or is_decimal_type(t):",
            "        if t._num_info.bits == 256:",
            "            return ir_node",
            "        else:",
            "            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)",
            "",
            "    if is_bytes_m_type(t):",
            "        if t._bytes_info.m == 32:",
            "            return ir_node  # special case, no clamp.",
            "        else:",
            "            return bytes_clamp(ir_node, t._bytes_info.m)",
            "",
            "    if t.typ in (\"address\",):",
            "        return int_clamp(ir_node, 160)",
            "    if t.typ in (\"bool\",):",
            "        return int_clamp(ir_node, 1)",
            "",
            "    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "",
            "def int_clamp(ir_node, bits, signed=False):",
            "    \"\"\"Generalized clamper for integer types. Takes the number of bits,",
            "    whether it's signed, and returns an IR node which checks it is",
            "    in bounds. (Consumers should use clamp_basetype instead which uses",
            "    type-based dispatch and is a little safer.)",
            "    \"\"\"",
            "    if bits >= 256:",
            "        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        if signed:",
            "            # example for bits==128:",
            "            # promote_signed_int(val, bits) is the \"canonical\" version of val",
            "            # if val is in bounds, the bits above bit 128 should be equal.",
            "            # (this works for both val >= 0 and val < 0. in the first case,",
            "            # all upper bits should be 0 if val is a valid int128,",
            "            # in the latter case, all upper bits should be 1.)",
            "            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]",
            "        else:",
            "            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]",
            "",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "",
            "    # TODO fix this annotation",
            "    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")",
            "",
            "",
            "def bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:",
            "    if not (0 < n_bytes <= 32):",
            "        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")",
            "",
            "",
            "# e.g. for int8, promote 255 to -1",
            "def promote_signed_int(x, bits):",
            "    assert bits % 8 == 0",
            "    ret = [\"signextend\", bits // 8 - 1, x]",
            "    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")"
        ],
        "afterPatchFile": [
            "from vyper import ast as vy_ast",
            "from vyper.address_space import CALLDATA, DATA, IMMUTABLES, MEMORY, STORAGE",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import (",
            "    DYNAMIC_ARRAY_OVERHEAD,",
            "    ArrayLike,",
            "    BaseType,",
            "    ByteArrayLike,",
            "    DArrayType,",
            "    MappingType,",
            "    SArrayType,",
            "    StructType,",
            "    TupleLike,",
            "    TupleType,",
            "    ceil32,",
            "    is_bytes_m_type,",
            "    is_decimal_type,",
            "    is_integer_type,",
            ")",
            "from vyper.evm.opcodes import version_check",
            "from vyper.exceptions import CompilerPanic, StructureException, TypeCheckFailure, TypeMismatch",
            "from vyper.utils import GAS_CALLDATACOPY_WORD, GAS_CODECOPY_WORD, GAS_IDENTITY, GAS_IDENTITYWORD",
            "",
            "",
            "# propagate revert message when calls to external contracts fail",
            "def check_external_call(call_ir):",
            "    copy_revertdata = [\"returndatacopy\", 0, 0, \"returndatasize\"]",
            "    revert = [\"revert\", 0, \"returndatasize\"]",
            "",
            "    propagate_revert_ir = [\"seq\", copy_revertdata, revert]",
            "    return [\"if\", [\"iszero\", call_ir], propagate_revert_ir]",
            "",
            "",
            "# cost per byte of the identity precompile",
            "def _identity_gas_bound(num_bytes):",
            "    return GAS_IDENTITY + GAS_IDENTITYWORD * (ceil32(num_bytes) // 32)",
            "",
            "",
            "def _calldatacopy_gas_bound(num_bytes):",
            "    return GAS_CALLDATACOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "def _codecopy_gas_bound(num_bytes):",
            "    return GAS_CODECOPY_WORD * ceil32(num_bytes) // 32",
            "",
            "",
            "# Copy byte array word-for-word (including layout)",
            "def make_byte_array_copier(dst, src):",
            "    assert isinstance(src.typ, ByteArrayLike)",
            "    assert isinstance(dst.typ, ByteArrayLike)",
            "",
            "    if src.typ.maxlen > dst.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {src.typ} to {dst.typ}\")",
            "    # stricter check for zeroing a byte array.",
            "    if src.value == \"~empty\" and src.typ.maxlen != dst.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {dst.typ} but got {src.typ}\"",
            "        )  # pragma: notest",
            "",
            "    if src.value == \"~empty\":",
            "        # set length word to 0.",
            "        return STORE(dst, 0)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src):",
            "        with get_bytearray_length(src).cache_when_complex(\"len\") as (b2, len_):",
            "",
            "            max_bytes = src.typ.maxlen",
            "",
            "            ret = [\"seq\"]",
            "            # store length",
            "            ret.append(STORE(dst, len_))",
            "",
            "            dst = bytes_data_ptr(dst)",
            "            src = bytes_data_ptr(src)",
            "",
            "            ret.append(copy_bytes(dst, src, len_, max_bytes))",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "def bytes_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, ByteArrayLike)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def dynarray_data_ptr(ptr):",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"tried to modify non-pointer type\")",
            "    assert isinstance(ptr.typ, DArrayType)",
            "    return add_ofst(ptr, ptr.location.word_scale)",
            "",
            "",
            "def _dynarray_make_setter(dst, src):",
            "    assert isinstance(src.typ, DArrayType)",
            "    assert isinstance(dst.typ, DArrayType)",
            "",
            "    if src.value == \"~empty\":",
            "        return IRnode.from_list(STORE(dst, 0))",
            "",
            "    if src.value == \"multi\":",
            "        ret = [\"seq\"]",
            "        # handle literals",
            "",
            "        # write the length word",
            "        store_length = STORE(dst, len(src.args))",
            "        ann = None",
            "        if src.annotation is not None:",
            "            ann = f\"len({src.annotation})\"",
            "        store_length = IRnode.from_list(store_length, annotation=ann)",
            "        ret.append(store_length)",
            "",
            "        n_items = len(src.args)",
            "        for i in range(n_items):",
            "            k = IRnode.from_list(i, typ=\"uint256\")",
            "            dst_i = get_element_ptr(dst, k, array_bounds_check=False)",
            "            src_i = get_element_ptr(src, k, array_bounds_check=False)",
            "            ret.append(make_setter(dst_i, src_i))",
            "",
            "        return ret",
            "",
            "    with src.cache_when_complex(\"darray_src\") as (b1, src):",
            "",
            "        # for ABI-encoded dynamic data, we must loop to unpack, since",
            "        # the layout does not match our memory layout",
            "        should_loop = src.encoding == Encoding.ABI and src.typ.subtype.abi_type.is_dynamic()",
            "",
            "        # if the subtype is dynamic, there might be a lot of",
            "        # unused space inside of each element. for instance",
            "        # DynArray[DynArray[uint256, 100], 5] where all the child",
            "        # arrays are empty - for this case, we recursively call",
            "        # into make_setter instead of straight bytes copy",
            "        # TODO we can make this heuristic more precise, e.g.",
            "        # loop when subtype.is_dynamic AND location == storage",
            "        # OR array_size <= /bound where loop is cheaper than memcpy/",
            "        should_loop |= src.typ.subtype.abi_type.is_dynamic()",
            "        should_loop |= needs_clamp(src.typ.subtype, src.encoding)",
            "",
            "        with get_dyn_array_count(src).cache_when_complex(\"darray_count\") as (b2, count):",
            "            ret = [\"seq\"]",
            "",
            "            ret.append(STORE(dst, count))",
            "",
            "            if should_loop:",
            "                i = IRnode.from_list(_freshname(\"copy_darray_ix\"), typ=\"uint256\")",
            "",
            "                loop_body = make_setter(",
            "                    get_element_ptr(dst, i, array_bounds_check=False),",
            "                    get_element_ptr(src, i, array_bounds_check=False),",
            "                )",
            "                loop_body.annotation = f\"{dst}[i] = {src}[i]\"",
            "",
            "                ret.append([\"repeat\", i, 0, count, src.typ.count, loop_body])",
            "",
            "            else:",
            "                element_size = src.typ.subtype.memory_bytes_required",
            "                # number of elements * size of element in bytes",
            "                n_bytes = _mul(count, element_size)",
            "                max_bytes = src.typ.count * element_size",
            "",
            "                src_ = dynarray_data_ptr(src)",
            "                dst_ = dynarray_data_ptr(dst)",
            "                ret.append(copy_bytes(dst_, src_, n_bytes, max_bytes))",
            "",
            "            return b1.resolve(b2.resolve(ret))",
            "",
            "",
            "# Copy bytes",
            "# Accepts 4 arguments:",
            "# (i) an IR node for the start position of the source",
            "# (ii) an IR node for the start position of the destination",
            "# (iii) an IR node for the length (in bytes)",
            "# (iv) a constant for the max length (in bytes)",
            "# NOTE: may pad to ceil32 of `length`! If you ask to copy 1 byte, it may",
            "# copy an entire (32-byte) word, depending on the copy routine chosen.",
            "# TODO maybe always pad to ceil32, to reduce dirty bytes bugs",
            "def copy_bytes(dst, src, length, length_bound):",
            "    annotation = f\"copy_bytes from {src} to {dst}\"",
            "",
            "    src = IRnode.from_list(src)",
            "    dst = IRnode.from_list(dst)",
            "    length = IRnode.from_list(length)",
            "",
            "    with src.cache_when_complex(\"src\") as (b1, src), length.cache_when_complex(",
            "        \"copy_bytes_count\"",
            "    ) as (b2, length), dst.cache_when_complex(\"dst\") as (b3, dst):",
            "",
            "        # fast code for common case where num bytes is small",
            "        # TODO expand this for more cases where num words is less than ~8",
            "        if length_bound <= 32:",
            "            copy_op = STORE(dst, LOAD(src))",
            "            ret = IRnode.from_list(copy_op, annotation=annotation)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == MEMORY and src.location in (MEMORY, CALLDATA, DATA):",
            "            # special cases: batch copy to memory",
            "            # TODO: iloadbytes",
            "            if src.location == MEMORY:",
            "                copy_op = [\"staticcall\", \"gas\", 4, src, length, dst, length]",
            "                gas_bound = _identity_gas_bound(length_bound)",
            "            elif src.location == CALLDATA:",
            "                copy_op = [\"calldatacopy\", dst, src, length]",
            "                gas_bound = _calldatacopy_gas_bound(length_bound)",
            "            elif src.location == DATA:",
            "                copy_op = [\"dloadbytes\", dst, src, length]",
            "                # note: dloadbytes compiles to CODECOPY",
            "                gas_bound = _codecopy_gas_bound(length_bound)",
            "",
            "            ret = IRnode.from_list(copy_op, annotation=annotation, add_gas_estimate=gas_bound)",
            "            return b1.resolve(b2.resolve(b3.resolve(ret)))",
            "",
            "        if dst.location == IMMUTABLES and src.location in (MEMORY, DATA):",
            "            # TODO istorebytes-from-mem, istorebytes-from-calldata(?)",
            "            # compile to identity, CODECOPY respectively.",
            "            pass",
            "",
            "        # general case, copy word-for-word",
            "        # pseudocode for our approach (memory-storage as example):",
            "        # for i in range(len, bound=MAX_LEN):",
            "        #   sstore(_dst + i, mload(src + i * 32))",
            "        i = IRnode.from_list(_freshname(\"copy_bytes_ix\"), typ=\"uint256\")",
            "",
            "        n = [\"div\", [\"ceil32\", length], 32]",
            "        n_bound = ceil32(length_bound) // 32",
            "",
            "        dst_i = add_ofst(dst, _mul(i, dst.location.word_scale))",
            "        src_i = add_ofst(src, _mul(i, src.location.word_scale))",
            "",
            "        copy_one_word = STORE(dst_i, LOAD(src_i))",
            "",
            "        main_loop = [\"repeat\", i, 0, n, n_bound, copy_one_word]",
            "",
            "        return b1.resolve(",
            "            b2.resolve(b3.resolve(IRnode.from_list(main_loop, annotation=annotation)))",
            "        )",
            "",
            "",
            "# get the number of bytes at runtime",
            "def get_bytearray_length(arg):",
            "    typ = BaseType(\"uint256\")",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "# get the number of elements at runtime",
            "def get_dyn_array_count(arg):",
            "    assert isinstance(arg.typ, DArrayType)",
            "",
            "    typ = BaseType(\"uint256\")",
            "",
            "    if arg.value == \"multi\":",
            "        return IRnode.from_list(len(arg.args), typ=typ)",
            "",
            "    if arg.value == \"~empty\":",
            "        # empty(DynArray[])",
            "        return IRnode.from_list(0, typ=typ)",
            "",
            "    return IRnode.from_list(LOAD(arg), typ=typ)",
            "",
            "",
            "def append_dyn_array(darray_node, elem_node):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "",
            "    assert darray_node.typ.count > 0, \"jerk boy u r out\"",
            "",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        len_ = get_dyn_array_count(darray_node)",
            "        with len_.cache_when_complex(\"old_darray_len\") as (b2, len_):",
            "            ret.append([\"assert\", [\"le\", len_, darray_node.typ.count - 1]])",
            "            ret.append(STORE(darray_node, [\"add\", len_, 1]))",
            "            # NOTE: typechecks elem_node",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            ret.append(",
            "                make_setter(get_element_ptr(darray_node, len_, array_bounds_check=False), elem_node)",
            "            )",
            "            return IRnode.from_list(b1.resolve(b2.resolve(ret)))",
            "",
            "",
            "def pop_dyn_array(darray_node, return_popped_item):",
            "    assert isinstance(darray_node.typ, DArrayType)",
            "    ret = [\"seq\"]",
            "    with darray_node.cache_when_complex(\"darray\") as (b1, darray_node):",
            "        old_len = [\"clamp_nonzero\", get_dyn_array_count(darray_node)]",
            "        new_len = IRnode.from_list([\"sub\", old_len, 1], typ=\"uint256\")",
            "",
            "        with new_len.cache_when_complex(\"new_len\") as (b2, new_len):",
            "            ret.append(STORE(darray_node, new_len))",
            "",
            "            # NOTE skip array bounds check bc we already asserted len two lines up",
            "            if return_popped_item:",
            "                popped_item = get_element_ptr(darray_node, new_len, array_bounds_check=False)",
            "                ret.append(popped_item)",
            "                typ = popped_item.typ",
            "                location = popped_item.location",
            "                encoding = popped_item.encoding",
            "            else:",
            "                typ, location, encoding = None, None, None",
            "            return IRnode.from_list(",
            "                b1.resolve(b2.resolve(ret)), typ=typ, location=location, encoding=encoding",
            "            )",
            "",
            "",
            "def getpos(node):",
            "    return (",
            "        node.lineno,",
            "        node.col_offset,",
            "        getattr(node, \"end_lineno\", None),",
            "        getattr(node, \"end_col_offset\", None),",
            "    )",
            "",
            "",
            "# add an offset to a pointer, keeping location and encoding info",
            "def add_ofst(ptr, ofst):",
            "    ret = [\"add\", ptr, ofst]",
            "    return IRnode.from_list(ret, location=ptr.location, encoding=ptr.encoding)",
            "",
            "",
            "# shorthand util",
            "def _mul(x, y):",
            "    ret = [\"mul\", x, y]",
            "    return IRnode.from_list(ret)",
            "",
            "",
            "# Resolve pointer locations for ABI-encoded data",
            "def _getelemptr_abi_helper(parent, member_t, ofst, clamp=True):",
            "    member_abi_t = member_t.abi_type",
            "",
            "    # ABI encoding has length word and then pretends length is not there",
            "    # e.g. [[1,2]] is encoded as 0x01 <len> 0x20 <inner array ofst> <encode(inner array)>",
            "    # note that inner array ofst is 0x20, not 0x40.",
            "    if has_length_word(parent.typ):",
            "        parent = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "",
            "    ofst_ir = add_ofst(parent, ofst)",
            "",
            "    if member_abi_t.is_dynamic():",
            "        # double dereference, according to ABI spec",
            "        # TODO optimize special case: first dynamic item",
            "        # offset is statically known.",
            "        ofst_ir = add_ofst(parent, unwrap_location(ofst_ir))",
            "",
            "    return IRnode.from_list(",
            "        ofst_ir,",
            "        typ=member_t,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=f\"{parent}{ofst}\",",
            "    )",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_tuplelike(parent, key):",
            "    typ = parent.typ",
            "    assert isinstance(typ, TupleLike)",
            "",
            "    if isinstance(typ, StructType):",
            "        assert isinstance(key, str)",
            "        subtype = typ.members[key]",
            "        attrs = list(typ.tuple_keys())",
            "        index = attrs.index(key)",
            "        annotation = key",
            "    else:",
            "        assert isinstance(key, int)",
            "        subtype = typ.members[key]",
            "        attrs = list(range(len(typ.members)))",
            "        index = key",
            "        annotation = None",
            "",
            "    # generated by empty() + make_setter",
            "    if parent.value == \"~empty\":",
            "        return IRnode.from_list(\"~empty\", typ=subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert parent.encoding != Encoding.ABI, \"no abi-encoded literals\"",
            "        return parent.args[index]",
            "",
            "    ofst = 0  # offset from parent start",
            "",
            "    if parent.encoding == Encoding.ABI:",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_t = typ.members[attrs[index]]",
            "",
            "        for i in range(index):",
            "            member_abi_t = typ.members[attrs[i]].abi_type",
            "            ofst += member_abi_t.embedded_static_size()",
            "",
            "        return _getelemptr_abi_helper(parent, member_t, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        for i in range(index):",
            "            ofst += typ.members[attrs[i]].memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(f\"bad location {parent.location}\")  # pragma: notest",
            "",
            "    return IRnode.from_list(",
            "        add_ofst(parent, ofst),",
            "        typ=subtype,",
            "        location=parent.location,",
            "        encoding=parent.encoding,",
            "        annotation=annotation,",
            "    )",
            "",
            "",
            "def has_length_word(typ):",
            "    return isinstance(typ, (DArrayType, ByteArrayLike))",
            "",
            "",
            "# TODO simplify this code, especially the ABI decoding",
            "def _get_element_ptr_array(parent, key, array_bounds_check):",
            "",
            "    assert isinstance(parent.typ, ArrayLike)",
            "",
            "    if not is_integer_type(key.typ):",
            "        raise TypeCheckFailure(f\"{key.typ} used as array index\")",
            "",
            "    subtype = parent.typ.subtype",
            "",
            "    if parent.value == \"~empty\":",
            "        if array_bounds_check:",
            "            # this case was previously missing a bounds check. codegen",
            "            # is a bit complicated when bounds check is required, so",
            "            # block it. there is no reason to index into a literal empty",
            "            # array anyways!",
            "            raise TypeCheckFailure(\"indexing into zero array not allowed\")",
            "        return IRnode.from_list(\"~empty\", subtype)",
            "",
            "    if parent.value == \"multi\":",
            "        assert isinstance(key.value, int)",
            "        return parent.args[key.value]",
            "",
            "    ix = unwrap_location(key)",
            "",
            "    if array_bounds_check:",
            "        # clamplt works, even for signed ints. since two's-complement",
            "        # is used, if the index is negative, (unsigned) LT will interpret",
            "        # it as a very large number, larger than any practical value for",
            "        # an array index, and the clamp will throw an error.",
            "        clamp_op = \"uclamplt\"",
            "        is_darray = isinstance(parent.typ, DArrayType)",
            "        bound = get_dyn_array_count(parent) if is_darray else parent.typ.count",
            "        # NOTE: there are optimization rules for this when ix or bound is literal",
            "        ix = IRnode.from_list([clamp_op, ix, bound], typ=ix.typ)",
            "",
            "    if parent.encoding == Encoding.ABI:",
            "        if parent.location == STORAGE:",
            "            raise CompilerPanic(\"storage variables should not be abi encoded\")  # pragma: notest",
            "",
            "        member_abi_t = subtype.abi_type",
            "",
            "        ofst = _mul(ix, member_abi_t.embedded_static_size())",
            "",
            "        return _getelemptr_abi_helper(parent, subtype, ofst)",
            "",
            "    if parent.location.word_addressable:",
            "        element_size = subtype.storage_size_in_words",
            "    elif parent.location.byte_addressable:",
            "        element_size = subtype.memory_bytes_required",
            "    else:",
            "        raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "",
            "    ofst = _mul(ix, element_size)",
            "",
            "    if has_length_word(parent.typ):",
            "        data_ptr = add_ofst(parent, parent.location.word_scale * DYNAMIC_ARRAY_OVERHEAD)",
            "    else:",
            "        data_ptr = parent",
            "",
            "    return IRnode.from_list(add_ofst(data_ptr, ofst), typ=subtype, location=parent.location)",
            "",
            "",
            "def _get_element_ptr_mapping(parent, key):",
            "    assert isinstance(parent.typ, MappingType)",
            "    subtype = parent.typ.valuetype",
            "    key = unwrap_location(key)",
            "",
            "    # TODO when is key None?",
            "    if key is None or parent.location != STORAGE:",
            "        raise TypeCheckFailure(\"bad dereference on mapping {parent}[{sub}]\")",
            "",
            "    return IRnode.from_list([\"sha3_64\", parent, key], typ=subtype, location=STORAGE)",
            "",
            "",
            "# Take a value representing a memory or storage location, and descend down to",
            "# an element or member variable",
            "# This is analogous (but not necessarily equivalent to) getelementptr in LLVM.",
            "def get_element_ptr(parent, key, array_bounds_check=True):",
            "    with parent.cache_when_complex(\"val\") as (b, parent):",
            "        typ = parent.typ",
            "",
            "        if isinstance(typ, TupleLike):",
            "            ret = _get_element_ptr_tuplelike(parent, key)",
            "",
            "        elif isinstance(typ, MappingType):",
            "            ret = _get_element_ptr_mapping(parent, key)",
            "",
            "        elif isinstance(typ, ArrayLike):",
            "            ret = _get_element_ptr_array(parent, key, array_bounds_check)",
            "",
            "        else:",
            "            raise CompilerPanic(f\"get_element_ptr cannot be called on {typ}\")  # pragma: notest",
            "",
            "        return b.resolve(ret)",
            "",
            "",
            "def LOAD(ptr: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.load_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr])",
            "",
            "",
            "def STORE(ptr: IRnode, val: IRnode) -> IRnode:",
            "    if ptr.location is None:",
            "        raise CompilerPanic(\"cannot dereference non-pointer type\")",
            "    op = ptr.location.store_op",
            "    if op is None:",
            "        raise CompilerPanic(f\"unreachable {ptr.location}\")  # pragma: notest",
            "    return IRnode.from_list([op, ptr, val])",
            "",
            "",
            "# Unwrap location",
            "def unwrap_location(orig):",
            "    if orig.location is not None:",
            "        return IRnode.from_list(LOAD(orig), typ=orig.typ)",
            "    else:",
            "        # CMC 2022-03-24 TODO refactor so this branch can be removed",
            "        if orig.value == \"~empty\":",
            "            return IRnode.from_list(0, typ=orig.typ)",
            "        return orig",
            "",
            "",
            "# utility function, constructs an IR tuple out of a list of IR nodes",
            "def ir_tuple_from_args(args):",
            "    typ = TupleType([x.typ for x in args])",
            "    return IRnode.from_list([\"multi\"] + [x for x in args], typ=typ)",
            "",
            "",
            "def _needs_external_call_wrap(ir_typ):",
            "    # for calls to ABI conforming contracts.",
            "    # according to the ABI spec, return types are ALWAYS tuples even",
            "    # if only one element is being returned.",
            "    # https://solidity.readthedocs.io/en/latest/abi-spec.html#function-selector-and-argument-encoding",
            "    # \"and the return values v_1, ..., v_k of f are encoded as",
            "    #",
            "    #    enc((v_1, ..., v_k))",
            "    #    i.e. the values are combined into a tuple and encoded.",
            "    # \"",
            "    # therefore, wrap it in a tuple if it's not already a tuple.",
            "    # for example, `bytes` is returned as abi-encoded (bytes,)",
            "    # and `(bytes,)` is returned as abi-encoded ((bytes,),)",
            "    # In general `-> X` gets returned as (X,)",
            "    # including structs. MyStruct is returned as abi-encoded (MyStruct,).",
            "    # (Sorry this is so confusing. I didn't make these rules.)",
            "",
            "    return not (isinstance(ir_typ, TupleType) and len(ir_typ.members) > 1)",
            "",
            "",
            "def calculate_type_for_external_return(ir_typ):",
            "    if _needs_external_call_wrap(ir_typ):",
            "        return TupleType([ir_typ])",
            "    return ir_typ",
            "",
            "",
            "def wrap_value_for_external_return(ir_val):",
            "    # used for LHS promotion",
            "    if _needs_external_call_wrap(ir_val.typ):",
            "        return ir_tuple_from_args([ir_val])",
            "    else:",
            "        return ir_val",
            "",
            "",
            "def set_type_for_external_return(ir_val):",
            "    # used for RHS promotion",
            "    ir_val.typ = calculate_type_for_external_return(ir_val.typ)",
            "",
            "",
            "# return a dummy IRnode with the given type",
            "def dummy_node_for_type(typ):",
            "    return IRnode(\"fake_node\", typ=typ)",
            "",
            "",
            "def _check_assign_bytes(left, right):",
            "    if right.typ.maxlen > left.typ.maxlen:",
            "        raise TypeMismatch(f\"Cannot cast from {right.typ} to {left.typ}\")  # pragma: notest",
            "    # stricter check for zeroing a byte array.",
            "    if right.value == \"~empty\" and right.typ.maxlen != left.typ.maxlen:",
            "        raise TypeMismatch(",
            "            f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "        )  # pragma: notest",
            "",
            "",
            "def _check_assign_list(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if left.value == \"multi\":",
            "        # Cannot do something like [a, b, c] = [1, 2, 3]",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left, SArrayType):",
            "        if not isinstance(right, SArrayType):",
            "            FAIL()  # pragma: notest",
            "        if left.typ.count != right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "    if isinstance(left, DArrayType):",
            "        if not isinstance(right, DArrayType):",
            "            FAIL()  # pragma: notest",
            "",
            "        if left.typ.count < right.typ.count:",
            "            FAIL()  # pragma: notest",
            "",
            "        # stricter check for zeroing",
            "        if right.value == \"~empty\" and right.typ.count != left.typ.count:",
            "            raise TypeCheckFailure(",
            "                f\"Bad type for clearing bytes: expected {left.typ} but got {right.typ}\"",
            "            )  # pragma: notest",
            "",
            "        # TODO recurse into left, right if literals?",
            "        check_assign(dummy_node_for_type(left.typ.subtyp), dummy_node_for_type(right.typ.subtyp))",
            "",
            "",
            "def _check_assign_tuple(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ}\")",
            "",
            "    if not isinstance(right.typ, left.typ.__class__):",
            "        FAIL()  # pragma: notest",
            "",
            "    if isinstance(left.typ, StructType):",
            "        for k in left.typ.members:",
            "            if k not in right.typ.members:",
            "                FAIL()  # pragma: notest",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(",
            "                dummy_node_for_type(left.typ.members[k]),",
            "                dummy_node_for_type(right.typ.members[k]),",
            "            )",
            "",
            "        for k in right.typ.members:",
            "            if k not in left.typ.members:",
            "                FAIL()  # pragma: notest",
            "",
            "        if left.typ.name != right.typ.name:",
            "            FAIL()  # pragma: notest",
            "",
            "    else:",
            "        if len(left.typ.members) != len(right.typ.members):",
            "            FAIL()  # pragma: notest",
            "        for (l, r) in zip(left.typ.members, right.typ.members):",
            "            # TODO recurse into left, right if literals?",
            "            check_assign(dummy_node_for_type(l), dummy_node_for_type(r))",
            "",
            "",
            "# sanity check an assignment",
            "# typechecking source code is done at an earlier phase",
            "# this function is more of a sanity check for typechecking internally",
            "# generated assignments",
            "def check_assign(left, right):",
            "    def FAIL():  # pragma: nocover",
            "        raise TypeCheckFailure(f\"assigning {right.typ} to {left.typ} {left} {right}\")",
            "",
            "    if isinstance(left.typ, ByteArrayLike):",
            "        _check_assign_bytes(left, right)",
            "    elif isinstance(left.typ, ArrayLike):",
            "        _check_assign_list(left, right)",
            "    elif isinstance(left.typ, TupleLike):",
            "        _check_assign_tuple(left, right)",
            "",
            "    elif isinstance(left.typ, BaseType):",
            "        # TODO once we propagate types from typechecker, introduce this check:",
            "        # if left.typ != right.typ:",
            "        #    FAIL()  # pragma: notest",
            "        pass",
            "",
            "    else:  # pragma: nocover",
            "        FAIL()",
            "",
            "",
            "_label = 0",
            "",
            "",
            "# TODO might want to coalesce with Context.fresh_varname and compile_ir.mksymbol",
            "def _freshname(name):",
            "    global _label",
            "    _label += 1",
            "    return f\"{name}{_label}\"",
            "",
            "",
            "# returns True if t is ABI encoded and is a type that needs any kind of",
            "# validation",
            "def needs_clamp(t, encoding):",
            "    if encoding == Encoding.VYPER:",
            "        return False",
            "    if encoding != Encoding.ABI:",
            "        raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "    if isinstance(t, (ByteArrayLike, DArrayType)):",
            "        return True",
            "    if isinstance(t, BaseType):",
            "        return t.typ not in (\"int256\", \"uint256\", \"bytes32\")",
            "    if isinstance(t, SArrayType):",
            "        return needs_clamp(t.subtype, encoding)",
            "    if isinstance(t, TupleLike):",
            "        return any(needs_clamp(m, encoding) for m in t.tuple_members())",
            "",
            "    raise CompilerPanic(\"unreachable\")  # pragma: notest",
            "",
            "",
            "# Create an x=y statement, where the types may be compound",
            "def make_setter(left, right):",
            "    check_assign(left, right)",
            "",
            "    # Basic types",
            "    if isinstance(left.typ, BaseType):",
            "        enc = right.encoding  # unwrap_location butchers encoding",
            "        right = unwrap_location(right)",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, enc):",
            "            right = clamp_basetype(right)",
            "",
            "        return STORE(left, right)",
            "",
            "    # Byte arrays",
            "    elif isinstance(left.typ, ByteArrayLike):",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"bs_ptr\") as (b, right):",
            "                copier = make_byte_array_copier(left, right)",
            "                ret = b.resolve([\"seq\", clamp_bytestring(right), copier])",
            "        else:",
            "            ret = make_byte_array_copier(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    elif isinstance(left.typ, DArrayType):",
            "        # TODO should we enable this?",
            "        # implicit conversion from sarray to darray",
            "        # if isinstance(right.typ, SArrayType):",
            "        #    return _complex_make_setter(left, right)",
            "",
            "        # TODO rethink/streamline the clamp_basetype logic",
            "        if needs_clamp(right.typ, right.encoding):",
            "            with right.cache_when_complex(\"arr_ptr\") as (b, right):",
            "                copier = _dynarray_make_setter(left, right)",
            "                ret = b.resolve([\"seq\", clamp_dyn_array(right), copier])",
            "        else:",
            "            ret = _dynarray_make_setter(left, right)",
            "",
            "        return IRnode.from_list(ret)",
            "",
            "    # Arrays",
            "    elif isinstance(left.typ, (SArrayType, TupleLike)):",
            "        return _complex_make_setter(left, right)",
            "",
            "",
            "def _complex_make_setter(left, right):",
            "    if right.value == \"~empty\" and left.location == MEMORY:",
            "        # optimized memzero",
            "        return mzero(left, left.typ.memory_bytes_required)",
            "",
            "    ret = [\"seq\"]",
            "",
            "    if isinstance(left.typ, SArrayType):",
            "        n_items = right.typ.count",
            "        keys = [IRnode.from_list(i, typ=\"uint256\") for i in range(n_items)]",
            "",
            "    if isinstance(left.typ, TupleLike):",
            "        keys = left.typ.tuple_keys()",
            "",
            "    # if len(keyz) == 0:",
            "    #    return IRnode.from_list([\"pass\"])",
            "",
            "    # general case",
            "    # TODO use copy_bytes when the generated code is above a certain size",
            "    with left.cache_when_complex(\"_L\") as (b1, left), right.cache_when_complex(\"_R\") as (b2, right):",
            "",
            "        for k in keys:",
            "            l_i = get_element_ptr(left, k, array_bounds_check=False)",
            "            r_i = get_element_ptr(right, k, array_bounds_check=False)",
            "            ret.append(make_setter(l_i, r_i))",
            "",
            "        return b1.resolve(b2.resolve(IRnode.from_list(ret)))",
            "",
            "",
            "def ensure_in_memory(ir_var, context):",
            "    \"\"\"Ensure a variable is in memory. This is useful for functions",
            "    which expect to operate on memory variables.",
            "    \"\"\"",
            "    if ir_var.location == MEMORY:",
            "        return ir_var",
            "",
            "    typ = ir_var.typ",
            "    buf = IRnode.from_list(context.new_internal_variable(typ), typ=typ, location=MEMORY)",
            "    do_copy = make_setter(buf, ir_var)",
            "",
            "    return IRnode.from_list([\"seq\", do_copy, buf], typ=typ, location=MEMORY)",
            "",
            "",
            "def eval_seq(ir_node):",
            "    \"\"\"Tries to find the \"return\" value of a `seq` statement, in order so",
            "    that the value can be known without possibly evaluating side effects",
            "    \"\"\"",
            "    if ir_node.value in (\"seq\", \"with\") and len(ir_node.args) > 0:",
            "        return eval_seq(ir_node.args[-1])",
            "    if isinstance(ir_node.value, int):",
            "        return IRnode.from_list(ir_node)",
            "    return None",
            "",
            "",
            "# TODO move return checks to vyper/semantics/validation",
            "def is_return_from_function(node):",
            "    if isinstance(node, vy_ast.Expr) and node.get(\"value.func.id\") == \"selfdestruct\":",
            "        return True",
            "    if isinstance(node, vy_ast.Return):",
            "        return True",
            "    elif isinstance(node, vy_ast.Raise):",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def check_single_exit(fn_node):",
            "    _check_return_body(fn_node, fn_node.body)",
            "    for node in fn_node.get_descendants(vy_ast.If):",
            "        _check_return_body(node, node.body)",
            "        if node.orelse:",
            "            _check_return_body(node, node.orelse)",
            "",
            "",
            "def _check_return_body(node, node_list):",
            "    return_count = len([n for n in node_list if is_return_from_function(n)])",
            "    if return_count > 1:",
            "        raise StructureException(",
            "            \"Too too many exit statements (return, raise or selfdestruct).\", node",
            "        )",
            "    # Check for invalid code after returns.",
            "    last_node_pos = len(node_list) - 1",
            "    for idx, n in enumerate(node_list):",
            "        if is_return_from_function(n) and idx < last_node_pos:",
            "            # is not last statement in body.",
            "            raise StructureException(",
            "                \"Exit statement with succeeding code (that will not execute).\", node_list[idx + 1]",
            "            )",
            "",
            "",
            "def mzero(dst, nbytes):",
            "    # calldatacopy from past-the-end gives zero bytes.",
            "    # cf. YP H.2 (ops section) with CALLDATACOPY spec.",
            "    return IRnode.from_list(",
            "        # calldatacopy mempos calldatapos len",
            "        [\"calldatacopy\", dst, \"calldatasize\", nbytes],",
            "        annotation=\"mzero\",",
            "    )",
            "",
            "",
            "# zero pad a bytearray according to the ABI spec. The last word",
            "# of the byte array needs to be right-padded with zeroes.",
            "def zero_pad(bytez_placeholder):",
            "    len_ = [\"mload\", bytez_placeholder]",
            "    dst = [\"add\", [\"add\", bytez_placeholder, 32], \"len\"]",
            "    # the runtime length of the data rounded up to nearest 32",
            "    # from spec:",
            "    #   the actual value of X as a byte sequence,",
            "    #   followed by the *minimum* number of zero-bytes",
            "    #   such that len(enc(X)) is a multiple of 32.",
            "    num_zero_bytes = [\"sub\", [\"ceil32\", \"len\"], \"len\"]",
            "    return IRnode.from_list(",
            "        [\"with\", \"len\", len_, [\"with\", \"dst\", dst, mzero(\"dst\", num_zero_bytes)]],",
            "        annotation=\"Zero pad\",",
            "    )",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shr(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shr\", bits, x]",
            "    return [\"div\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "# convenience rewrites for shr/sar/shl",
            "def shl(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"shl\", bits, x]",
            "    return [\"mul\", x, [\"exp\", 2, bits]]",
            "",
            "",
            "def sar(bits, x):",
            "    if version_check(begin=\"constantinople\"):",
            "        return [\"sar\", bits, x]",
            "",
            "    # emulate for older arches. keep in mind note from EIP 145:",
            "    # \"This is not equivalent to PUSH1 2 EXP SDIV, since it rounds",
            "    # differently. See SDIV(-1, 2) == 0, while SAR(-1, 1) == -1.\"",
            "    return [\"sdiv\", [\"add\", [\"slt\", x, 0], x], [\"exp\", 2, bits]]",
            "",
            "",
            "def clamp_bytestring(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, ByteArrayLike):",
            "        raise CompilerPanic(f\"{t} passed to clamp_bytestring\")  # pragma: notest",
            "    return [\"assert\", [\"le\", get_bytearray_length(ir_node), t.maxlen]]",
            "",
            "",
            "def clamp_dyn_array(ir_node):",
            "    t = ir_node.typ",
            "    assert isinstance(t, DArrayType)",
            "    return [\"assert\", [\"le\", get_dyn_array_count(ir_node), t.count]]",
            "",
            "",
            "# clampers for basetype",
            "def clamp_basetype(ir_node):",
            "    t = ir_node.typ",
            "    if not isinstance(t, BaseType):",
            "        raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "    # copy of the input",
            "    ir_node = unwrap_location(ir_node)",
            "",
            "    if is_integer_type(t) or is_decimal_type(t):",
            "        if t._num_info.bits == 256:",
            "            return ir_node",
            "        else:",
            "            return int_clamp(ir_node, t._num_info.bits, signed=t._num_info.is_signed)",
            "",
            "    if is_bytes_m_type(t):",
            "        if t._bytes_info.m == 32:",
            "            return ir_node  # special case, no clamp.",
            "        else:",
            "            return bytes_clamp(ir_node, t._bytes_info.m)",
            "",
            "    if t.typ in (\"address\",):",
            "        return int_clamp(ir_node, 160)",
            "    if t.typ in (\"bool\",):",
            "        return int_clamp(ir_node, 1)",
            "",
            "    raise CompilerPanic(f\"{t} passed to clamp_basetype\")  # pragma: notest",
            "",
            "",
            "def int_clamp(ir_node, bits, signed=False):",
            "    \"\"\"Generalized clamper for integer types. Takes the number of bits,",
            "    whether it's signed, and returns an IR node which checks it is",
            "    in bounds. (Consumers should use clamp_basetype instead which uses",
            "    type-based dispatch and is a little safer.)",
            "    \"\"\"",
            "    if bits >= 256:",
            "        raise CompilerPanic(f\"invalid clamp: {bits}>=256 ({ir_node})\")  # pragma: notest",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        if signed:",
            "            # example for bits==128:",
            "            # promote_signed_int(val, bits) is the \"canonical\" version of val",
            "            # if val is in bounds, the bits above bit 128 should be equal.",
            "            # (this works for both val >= 0 and val < 0. in the first case,",
            "            # all upper bits should be 0 if val is a valid int128,",
            "            # in the latter case, all upper bits should be 1.)",
            "            assertion = [\"assert\", [\"eq\", val, promote_signed_int(val, bits)]]",
            "        else:",
            "            assertion = [\"assert\", [\"iszero\", shr(bits, val)]]",
            "",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "",
            "    # TODO fix this annotation",
            "    return IRnode.from_list(ret, annotation=f\"int_clamp {ir_node.typ}\")",
            "",
            "",
            "def bytes_clamp(ir_node: IRnode, n_bytes: int) -> IRnode:",
            "    if not (0 < n_bytes <= 32):",
            "        raise CompilerPanic(f\"bad type: bytes{n_bytes}\")",
            "    with ir_node.cache_when_complex(\"val\") as (b, val):",
            "        assertion = [\"assert\", [\"iszero\", shl(n_bytes * 8, val)]]",
            "        ret = b.resolve([\"seq\", assertion, val])",
            "    return IRnode.from_list(ret, annotation=f\"bytes{n_bytes}_clamp\")",
            "",
            "",
            "# e.g. for int8, promote 255 to -1",
            "def promote_signed_int(x, bits):",
            "    assert bits % 8 == 0",
            "    ret = [\"signextend\", bits // 8 - 1, x]",
            "    return IRnode.from_list(ret, annotation=f\"promote int{bits}\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "126": [
                "_dynarray_make_setter"
            ],
            "127": [
                "_dynarray_make_setter"
            ],
            "128": [
                "_dynarray_make_setter"
            ],
            "129": [
                "_dynarray_make_setter"
            ],
            "382": [
                "_get_element_ptr_tuplelike"
            ],
            "452": [
                "_get_element_ptr_array"
            ],
            "706": [
                "needs_clamp"
            ],
            "709": [
                "needs_clamp"
            ],
            "710": [
                "needs_clamp"
            ],
            "711": [
                "needs_clamp"
            ],
            "712": [
                "needs_clamp"
            ],
            "713": [
                "needs_clamp"
            ],
            "719": [
                "needs_clamp"
            ]
        },
        "addLocation": []
    },
    "vyper/codegen/external_call.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": "     check_assign,"
            },
            "1": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": "     check_external_call,"
            },
            "2": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     dummy_node_for_type,"
            },
            "3": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    get_element_ptr,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+    make_setter,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+    needs_clamp,"
            },
            "6": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " )"
            },
            "7": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from vyper.codegen.ir_node import Encoding, IRnode"
            },
            "8": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from vyper.codegen.types import InterfaceType, TupleType, get_type_for_exact_size"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+from vyper.codegen.types.convert import new_type_to_old_type"
            },
            "10": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from vyper.exceptions import StateAccessViolation, TypeCheckFailure"
            },
            "11": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "     return buf, mstore_method_id + [encode_args], args_ofst, args_len"
            },
            "14": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 62,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _returndata_encoding(contract_sig):"
            },
            "17": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if contract_sig.is_from_json:"
            },
            "18": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return Encoding.JSON_ABI"
            },
            "19": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return Encoding.ABI"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+def _unpack_returndata(buf, contract_sig, skip_contract_check, context, expr):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+    # expr.func._metadata[\"type\"].return_type is more accurate"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+    # than contract_sig.return_type in the case of JSON interfaces."
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+    ast_return_t = expr.func._metadata[\"type\"].return_type"
            },
            "24": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "26": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _unpack_returndata(buf, contract_sig, skip_contract_check, context):"
            },
            "27": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return_t = contract_sig.return_type"
            },
            "28": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if return_t is None:"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+    if ast_return_t is None:"
            },
            "30": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "         return [\"pass\"], 0, 0"
            },
            "31": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 71,
                "PatchRowcode": " "
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    # sanity check"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+    return_t = new_type_to_old_type(ast_return_t)"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+    check_assign(dummy_node_for_type(return_t), dummy_node_for_type(contract_sig.return_type))"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "     return_t = calculate_type_for_external_return(return_t)"
            },
            "37": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # if the abi signature has a different type than"
            },
            "38": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # the vyper type, we need to wrap and unwrap the type"
            },
            "39": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # so that the ABI decoding works correctly"
            },
            "40": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    should_unwrap_abi_tuple = return_t != contract_sig.return_type"
            },
            "41": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 77,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 78,
                "PatchRowcode": "     abi_return_t = return_t.abi_type"
            },
            "43": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 79,
                "PatchRowcode": " "
            },
            "44": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "     # revert when returndatasize is not in bounds"
            },
            "45": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "     ret = []"
            },
            "46": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "     # runtime: min_return_size <= returndatasize"
            },
            "47": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # TODO move the -1 optimization to IR optimizer"
            },
            "48": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "     if not skip_contract_check:"
            },
            "49": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ret += [[\"assert\", [\"gt\", \"returndatasize\", min_return_size - 1]]]"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+        ret += [[\"assert\", [\"ge\", \"returndatasize\", min_return_size]]]"
            },
            "51": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 92,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # add as the last IRnode a pointer to the return data structure"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+    encoding = Encoding.ABI"
            },
            "54": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 94,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # the return type has been wrapped by the calling contract;"
            },
            "56": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # unwrap it so downstream code isn't confused."
            },
            "57": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # basically this expands to buf+32 if the return type has been wrapped"
            },
            "58": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # in a tuple AND its ABI type is dynamic."
            },
            "59": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # in most cases, this simply will evaluate to ret."
            },
            "60": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # in the special case where the return type has been wrapped"
            },
            "61": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # in a tuple AND its ABI type is dynamic, it expands to buf+32."
            },
            "62": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    buf = IRnode(buf, typ=return_t, encoding=_returndata_encoding(contract_sig), location=MEMORY)"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+    buf = IRnode.from_list("
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+        buf,"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+        typ=return_t,"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+        location=MEMORY,"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+        encoding=encoding,"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+        annotation=f\"{expr.node_source_code} returndata buffer\","
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+    )"
            },
            "70": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 102,
                "PatchRowcode": " "
            },
            "71": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if should_unwrap_abi_tuple:"
            },
            "72": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        buf = get_element_ptr(buf, 0, array_bounds_check=False)"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    assert isinstance(return_t, TupleType)"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+    # unpack strictly"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+    if needs_clamp(return_t, encoding):"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        buf2 = IRnode.from_list("
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+            context.new_internal_variable(return_t), typ=return_t, location=MEMORY"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+        )"
            },
            "79": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 109,
                "PatchRowcode": " "
            },
            "80": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ret += [buf]"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+        ret.append(make_setter(buf2, buf))"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        ret.append(buf2)"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+    else:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+        ret.append(buf)"
            },
            "85": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 114,
                "PatchRowcode": " "
            },
            "86": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     return ret, ret_ofst, ret_len"
            },
            "87": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 116,
                "PatchRowcode": " "
            },
            "88": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "     buf, arg_packer, args_ofst, args_len = _pack_arguments(contract_sig, args_ir, context)"
            },
            "89": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "90": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "     ret_unpacker, ret_ofst, ret_len = _unpack_returndata("
            },
            "91": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        buf, contract_sig, skip_contract_check, context"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+        buf, contract_sig, skip_contract_check, context, expr"
            },
            "93": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "     )"
            },
            "94": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "95": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "     sub += arg_packer"
            },
            "96": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "     if contract_sig.return_type is not None:"
            },
            "97": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "         sub += ret_unpacker"
            },
            "98": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 175,
                "PatchRowcode": " "
            },
            "99": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ret = IRnode.from_list("
            },
            "100": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sub,"
            },
            "101": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        typ=contract_sig.return_type,"
            },
            "102": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        location=MEMORY,"
            },
            "103": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # set the encoding to ABI here, downstream code will decode and add clampers."
            },
            "104": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        encoding=_returndata_encoding(contract_sig),"
            },
            "105": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    )"
            },
            "106": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "107": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return ret"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+    return IRnode.from_list(sub, typ=contract_sig.return_type, location=MEMORY)"
            },
            "109": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 177,
                "PatchRowcode": " "
            },
            "110": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 178,
                "PatchRowcode": " "
            },
            "111": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 179,
                "PatchRowcode": " def _get_special_kwargs(stmt_expr, context):"
            }
        },
        "frontPatchFile": [
            "import vyper.utils as util",
            "from vyper.address_space import MEMORY",
            "from vyper.codegen.abi_encoder import abi_encode",
            "from vyper.codegen.core import (",
            "    calculate_type_for_external_return,",
            "    check_assign,",
            "    check_external_call,",
            "    dummy_node_for_type,",
            "    get_element_ptr,",
            ")",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import InterfaceType, TupleType, get_type_for_exact_size",
            "from vyper.exceptions import StateAccessViolation, TypeCheckFailure",
            "",
            "",
            "def _pack_arguments(contract_sig, args, context):",
            "    # abi encoding just treats all args as a big tuple",
            "    args_tuple_t = TupleType([x.typ for x in args])",
            "    args_as_tuple = IRnode.from_list([\"multi\"] + [x for x in args], typ=args_tuple_t)",
            "    args_abi_t = args_tuple_t.abi_type",
            "",
            "    # sanity typecheck - make sure the arguments can be assigned",
            "    dst_tuple_t = TupleType([arg.typ for arg in contract_sig.args][: len(args)])",
            "    check_assign(dummy_node_for_type(dst_tuple_t), args_as_tuple)",
            "",
            "    if contract_sig.return_type is not None:",
            "        return_abi_t = calculate_type_for_external_return(contract_sig.return_type).abi_type",
            "",
            "        # we use the same buffer for args and returndata,",
            "        # so allocate enough space here for the returndata too.",
            "        buflen = max(args_abi_t.size_bound(), return_abi_t.size_bound())",
            "    else:",
            "        buflen = args_abi_t.size_bound()",
            "",
            "    buflen += 32  # padding for the method id",
            "",
            "    buf_t = get_type_for_exact_size(buflen)",
            "    buf = context.new_internal_variable(buf_t)",
            "",
            "    args_ofst = buf + 28",
            "    args_len = args_abi_t.size_bound() + 4",
            "",
            "    abi_signature = contract_sig.name + dst_tuple_t.abi_type.selector_name()",
            "",
            "    # layout:",
            "    # 32 bytes                 | args",
            "    # 0x..00<method_id_4bytes> | args",
            "    # the reason for the left padding is just so the alignment is easier.",
            "    # if we were only targeting constantinople, we could align",
            "    # to buf (and also keep code size small) by using",
            "    # (mstore buf (shl signature.method_id 224))",
            "    mstore_method_id = [[\"mstore\", buf, util.abi_method_id(abi_signature)]]",
            "",
            "    if len(args) == 0:",
            "        encode_args = [\"pass\"]",
            "    else:",
            "        encode_args = abi_encode(buf + 32, args_as_tuple, context, bufsz=buflen)",
            "",
            "    return buf, mstore_method_id + [encode_args], args_ofst, args_len",
            "",
            "",
            "def _returndata_encoding(contract_sig):",
            "    if contract_sig.is_from_json:",
            "        return Encoding.JSON_ABI",
            "    return Encoding.ABI",
            "",
            "",
            "def _unpack_returndata(buf, contract_sig, skip_contract_check, context):",
            "    return_t = contract_sig.return_type",
            "    if return_t is None:",
            "        return [\"pass\"], 0, 0",
            "",
            "    return_t = calculate_type_for_external_return(return_t)",
            "    # if the abi signature has a different type than",
            "    # the vyper type, we need to wrap and unwrap the type",
            "    # so that the ABI decoding works correctly",
            "    should_unwrap_abi_tuple = return_t != contract_sig.return_type",
            "",
            "    abi_return_t = return_t.abi_type",
            "",
            "    min_return_size = abi_return_t.min_size()",
            "    max_return_size = abi_return_t.size_bound()",
            "    assert 0 < min_return_size <= max_return_size",
            "",
            "    ret_ofst = buf",
            "    ret_len = max_return_size",
            "",
            "    # revert when returndatasize is not in bounds",
            "    ret = []",
            "    # runtime: min_return_size <= returndatasize",
            "    # TODO move the -1 optimization to IR optimizer",
            "    if not skip_contract_check:",
            "        ret += [[\"assert\", [\"gt\", \"returndatasize\", min_return_size - 1]]]",
            "",
            "    # add as the last IRnode a pointer to the return data structure",
            "",
            "    # the return type has been wrapped by the calling contract;",
            "    # unwrap it so downstream code isn't confused.",
            "    # basically this expands to buf+32 if the return type has been wrapped",
            "    # in a tuple AND its ABI type is dynamic.",
            "    # in most cases, this simply will evaluate to ret.",
            "    # in the special case where the return type has been wrapped",
            "    # in a tuple AND its ABI type is dynamic, it expands to buf+32.",
            "    buf = IRnode(buf, typ=return_t, encoding=_returndata_encoding(contract_sig), location=MEMORY)",
            "",
            "    if should_unwrap_abi_tuple:",
            "        buf = get_element_ptr(buf, 0, array_bounds_check=False)",
            "",
            "    ret += [buf]",
            "",
            "    return ret, ret_ofst, ret_len",
            "",
            "",
            "def _external_call_helper(",
            "    contract_address,",
            "    contract_sig,",
            "    args_ir,",
            "    context,",
            "    value=None,",
            "    gas=None,",
            "    skip_contract_check=None,",
            "    expr=None,",
            "):",
            "",
            "    if value is None:",
            "        value = 0",
            "    if gas is None:",
            "        gas = \"gas\"",
            "    if skip_contract_check is None:",
            "        skip_contract_check = False",
            "",
            "    # sanity check",
            "    assert len(contract_sig.base_args) <= len(args_ir) <= len(contract_sig.args)",
            "",
            "    if context.is_constant() and contract_sig.mutability not in (\"view\", \"pure\"):",
            "        # TODO is this already done in type checker?",
            "        raise StateAccessViolation(",
            "            f\"May not call state modifying function '{contract_sig.name}' \"",
            "            f\"within {context.pp_constancy()}.\",",
            "            expr,",
            "        )",
            "",
            "    sub = [\"seq\"]",
            "",
            "    buf, arg_packer, args_ofst, args_len = _pack_arguments(contract_sig, args_ir, context)",
            "",
            "    ret_unpacker, ret_ofst, ret_len = _unpack_returndata(",
            "        buf, contract_sig, skip_contract_check, context",
            "    )",
            "",
            "    sub += arg_packer",
            "",
            "    if contract_sig.return_type is None and not skip_contract_check:",
            "        # if we do not expect return data, check that a contract exists at the",
            "        # target address. we must perform this check BEFORE the call because",
            "        # the contract might selfdestruct. on the other hand we can omit this",
            "        # when we _do_ expect return data because we later check",
            "        # `returndatasize` (that check works even if the contract",
            "        # selfdestructs).",
            "        sub.append([\"assert\", [\"extcodesize\", contract_address]])",
            "",
            "    if context.is_constant() or contract_sig.mutability in (\"view\", \"pure\"):",
            "        call_op = [\"staticcall\", gas, contract_address, args_ofst, args_len, ret_ofst, ret_len]",
            "    else:",
            "        call_op = [\"call\", gas, contract_address, value, args_ofst, args_len, ret_ofst, ret_len]",
            "",
            "    sub.append(check_external_call(call_op))",
            "",
            "    if contract_sig.return_type is not None:",
            "        sub += ret_unpacker",
            "",
            "    ret = IRnode.from_list(",
            "        sub,",
            "        typ=contract_sig.return_type,",
            "        location=MEMORY,",
            "        # set the encoding to ABI here, downstream code will decode and add clampers.",
            "        encoding=_returndata_encoding(contract_sig),",
            "    )",
            "",
            "    return ret",
            "",
            "",
            "def _get_special_kwargs(stmt_expr, context):",
            "    from vyper.codegen.expr import Expr  # TODO rethink this circular import",
            "",
            "    value, gas, skip_contract_check = None, None, None",
            "    for kw in stmt_expr.keywords:",
            "        if kw.arg == \"gas\":",
            "            gas = Expr.parse_value_expr(kw.value, context)",
            "        elif kw.arg == \"value\":",
            "            value = Expr.parse_value_expr(kw.value, context)",
            "        elif kw.arg == \"skip_contract_check\":",
            "            skip_contract_check = kw.value.value",
            "            assert isinstance(skip_contract_check, bool), \"type checker missed this\"",
            "        else:",
            "            raise TypeCheckFailure(\"Unexpected keyword argument\")",
            "",
            "    # TODO maybe return a small dataclass to reduce verbosity",
            "    return value, gas, skip_contract_check",
            "",
            "",
            "def ir_for_external_call(stmt_expr, context):",
            "    from vyper.codegen.expr import Expr  # TODO rethink this circular import",
            "",
            "    contract_address = Expr.parse_value_expr(stmt_expr.func.value, context)",
            "    value, gas, skip_contract_check = _get_special_kwargs(stmt_expr, context)",
            "    args_ir = [Expr(x, context).ir_node for x in stmt_expr.args]",
            "",
            "    assert isinstance(contract_address.typ, InterfaceType)",
            "    contract_name = contract_address.typ.name",
            "    method_name = stmt_expr.func.attr",
            "    contract_sig = context.sigs[contract_name][method_name]",
            "",
            "    ret = _external_call_helper(",
            "        contract_address,",
            "        contract_sig,",
            "        args_ir,",
            "        context,",
            "        value=value,",
            "        gas=gas,",
            "        skip_contract_check=skip_contract_check,",
            "        expr=stmt_expr,",
            "    )",
            "    ret.annotation = stmt_expr.get(\"node_source_code\")",
            "",
            "    return ret"
        ],
        "afterPatchFile": [
            "import vyper.utils as util",
            "from vyper.address_space import MEMORY",
            "from vyper.codegen.abi_encoder import abi_encode",
            "from vyper.codegen.core import (",
            "    calculate_type_for_external_return,",
            "    check_assign,",
            "    check_external_call,",
            "    dummy_node_for_type,",
            "    make_setter,",
            "    needs_clamp,",
            ")",
            "from vyper.codegen.ir_node import Encoding, IRnode",
            "from vyper.codegen.types import InterfaceType, TupleType, get_type_for_exact_size",
            "from vyper.codegen.types.convert import new_type_to_old_type",
            "from vyper.exceptions import StateAccessViolation, TypeCheckFailure",
            "",
            "",
            "def _pack_arguments(contract_sig, args, context):",
            "    # abi encoding just treats all args as a big tuple",
            "    args_tuple_t = TupleType([x.typ for x in args])",
            "    args_as_tuple = IRnode.from_list([\"multi\"] + [x for x in args], typ=args_tuple_t)",
            "    args_abi_t = args_tuple_t.abi_type",
            "",
            "    # sanity typecheck - make sure the arguments can be assigned",
            "    dst_tuple_t = TupleType([arg.typ for arg in contract_sig.args][: len(args)])",
            "    check_assign(dummy_node_for_type(dst_tuple_t), args_as_tuple)",
            "",
            "    if contract_sig.return_type is not None:",
            "        return_abi_t = calculate_type_for_external_return(contract_sig.return_type).abi_type",
            "",
            "        # we use the same buffer for args and returndata,",
            "        # so allocate enough space here for the returndata too.",
            "        buflen = max(args_abi_t.size_bound(), return_abi_t.size_bound())",
            "    else:",
            "        buflen = args_abi_t.size_bound()",
            "",
            "    buflen += 32  # padding for the method id",
            "",
            "    buf_t = get_type_for_exact_size(buflen)",
            "    buf = context.new_internal_variable(buf_t)",
            "",
            "    args_ofst = buf + 28",
            "    args_len = args_abi_t.size_bound() + 4",
            "",
            "    abi_signature = contract_sig.name + dst_tuple_t.abi_type.selector_name()",
            "",
            "    # layout:",
            "    # 32 bytes                 | args",
            "    # 0x..00<method_id_4bytes> | args",
            "    # the reason for the left padding is just so the alignment is easier.",
            "    # if we were only targeting constantinople, we could align",
            "    # to buf (and also keep code size small) by using",
            "    # (mstore buf (shl signature.method_id 224))",
            "    mstore_method_id = [[\"mstore\", buf, util.abi_method_id(abi_signature)]]",
            "",
            "    if len(args) == 0:",
            "        encode_args = [\"pass\"]",
            "    else:",
            "        encode_args = abi_encode(buf + 32, args_as_tuple, context, bufsz=buflen)",
            "",
            "    return buf, mstore_method_id + [encode_args], args_ofst, args_len",
            "",
            "",
            "def _unpack_returndata(buf, contract_sig, skip_contract_check, context, expr):",
            "    # expr.func._metadata[\"type\"].return_type is more accurate",
            "    # than contract_sig.return_type in the case of JSON interfaces.",
            "    ast_return_t = expr.func._metadata[\"type\"].return_type",
            "",
            "    if ast_return_t is None:",
            "        return [\"pass\"], 0, 0",
            "",
            "    # sanity check",
            "    return_t = new_type_to_old_type(ast_return_t)",
            "    check_assign(dummy_node_for_type(return_t), dummy_node_for_type(contract_sig.return_type))",
            "",
            "    return_t = calculate_type_for_external_return(return_t)",
            "",
            "    abi_return_t = return_t.abi_type",
            "",
            "    min_return_size = abi_return_t.min_size()",
            "    max_return_size = abi_return_t.size_bound()",
            "    assert 0 < min_return_size <= max_return_size",
            "",
            "    ret_ofst = buf",
            "    ret_len = max_return_size",
            "",
            "    # revert when returndatasize is not in bounds",
            "    ret = []",
            "    # runtime: min_return_size <= returndatasize",
            "    if not skip_contract_check:",
            "        ret += [[\"assert\", [\"ge\", \"returndatasize\", min_return_size]]]",
            "",
            "    encoding = Encoding.ABI",
            "",
            "    buf = IRnode.from_list(",
            "        buf,",
            "        typ=return_t,",
            "        location=MEMORY,",
            "        encoding=encoding,",
            "        annotation=f\"{expr.node_source_code} returndata buffer\",",
            "    )",
            "",
            "    assert isinstance(return_t, TupleType)",
            "    # unpack strictly",
            "    if needs_clamp(return_t, encoding):",
            "        buf2 = IRnode.from_list(",
            "            context.new_internal_variable(return_t), typ=return_t, location=MEMORY",
            "        )",
            "",
            "        ret.append(make_setter(buf2, buf))",
            "        ret.append(buf2)",
            "    else:",
            "        ret.append(buf)",
            "",
            "    return ret, ret_ofst, ret_len",
            "",
            "",
            "def _external_call_helper(",
            "    contract_address,",
            "    contract_sig,",
            "    args_ir,",
            "    context,",
            "    value=None,",
            "    gas=None,",
            "    skip_contract_check=None,",
            "    expr=None,",
            "):",
            "",
            "    if value is None:",
            "        value = 0",
            "    if gas is None:",
            "        gas = \"gas\"",
            "    if skip_contract_check is None:",
            "        skip_contract_check = False",
            "",
            "    # sanity check",
            "    assert len(contract_sig.base_args) <= len(args_ir) <= len(contract_sig.args)",
            "",
            "    if context.is_constant() and contract_sig.mutability not in (\"view\", \"pure\"):",
            "        # TODO is this already done in type checker?",
            "        raise StateAccessViolation(",
            "            f\"May not call state modifying function '{contract_sig.name}' \"",
            "            f\"within {context.pp_constancy()}.\",",
            "            expr,",
            "        )",
            "",
            "    sub = [\"seq\"]",
            "",
            "    buf, arg_packer, args_ofst, args_len = _pack_arguments(contract_sig, args_ir, context)",
            "",
            "    ret_unpacker, ret_ofst, ret_len = _unpack_returndata(",
            "        buf, contract_sig, skip_contract_check, context, expr",
            "    )",
            "",
            "    sub += arg_packer",
            "",
            "    if contract_sig.return_type is None and not skip_contract_check:",
            "        # if we do not expect return data, check that a contract exists at the",
            "        # target address. we must perform this check BEFORE the call because",
            "        # the contract might selfdestruct. on the other hand we can omit this",
            "        # when we _do_ expect return data because we later check",
            "        # `returndatasize` (that check works even if the contract",
            "        # selfdestructs).",
            "        sub.append([\"assert\", [\"extcodesize\", contract_address]])",
            "",
            "    if context.is_constant() or contract_sig.mutability in (\"view\", \"pure\"):",
            "        call_op = [\"staticcall\", gas, contract_address, args_ofst, args_len, ret_ofst, ret_len]",
            "    else:",
            "        call_op = [\"call\", gas, contract_address, value, args_ofst, args_len, ret_ofst, ret_len]",
            "",
            "    sub.append(check_external_call(call_op))",
            "",
            "    if contract_sig.return_type is not None:",
            "        sub += ret_unpacker",
            "",
            "    return IRnode.from_list(sub, typ=contract_sig.return_type, location=MEMORY)",
            "",
            "",
            "def _get_special_kwargs(stmt_expr, context):",
            "    from vyper.codegen.expr import Expr  # TODO rethink this circular import",
            "",
            "    value, gas, skip_contract_check = None, None, None",
            "    for kw in stmt_expr.keywords:",
            "        if kw.arg == \"gas\":",
            "            gas = Expr.parse_value_expr(kw.value, context)",
            "        elif kw.arg == \"value\":",
            "            value = Expr.parse_value_expr(kw.value, context)",
            "        elif kw.arg == \"skip_contract_check\":",
            "            skip_contract_check = kw.value.value",
            "            assert isinstance(skip_contract_check, bool), \"type checker missed this\"",
            "        else:",
            "            raise TypeCheckFailure(\"Unexpected keyword argument\")",
            "",
            "    # TODO maybe return a small dataclass to reduce verbosity",
            "    return value, gas, skip_contract_check",
            "",
            "",
            "def ir_for_external_call(stmt_expr, context):",
            "    from vyper.codegen.expr import Expr  # TODO rethink this circular import",
            "",
            "    contract_address = Expr.parse_value_expr(stmt_expr.func.value, context)",
            "    value, gas, skip_contract_check = _get_special_kwargs(stmt_expr, context)",
            "    args_ir = [Expr(x, context).ir_node for x in stmt_expr.args]",
            "",
            "    assert isinstance(contract_address.typ, InterfaceType)",
            "    contract_name = contract_address.typ.name",
            "    method_name = stmt_expr.func.attr",
            "    contract_sig = context.sigs[contract_name][method_name]",
            "",
            "    ret = _external_call_helper(",
            "        contract_address,",
            "        contract_sig,",
            "        args_ir,",
            "        context,",
            "        value=value,",
            "        gas=gas,",
            "        skip_contract_check=skip_contract_check,",
            "        expr=stmt_expr,",
            "    )",
            "    ret.annotation = stmt_expr.get(\"node_source_code\")",
            "",
            "    return ret"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "9": [],
            "62": [
                "_returndata_encoding"
            ],
            "63": [
                "_returndata_encoding"
            ],
            "64": [
                "_returndata_encoding"
            ],
            "65": [
                "_returndata_encoding"
            ],
            "67": [],
            "68": [
                "_unpack_returndata"
            ],
            "69": [
                "_unpack_returndata"
            ],
            "70": [
                "_unpack_returndata"
            ],
            "74": [
                "_unpack_returndata"
            ],
            "75": [
                "_unpack_returndata"
            ],
            "76": [
                "_unpack_returndata"
            ],
            "77": [
                "_unpack_returndata"
            ],
            "91": [
                "_unpack_returndata"
            ],
            "93": [
                "_unpack_returndata"
            ],
            "95": [
                "_unpack_returndata"
            ],
            "97": [
                "_unpack_returndata"
            ],
            "98": [
                "_unpack_returndata"
            ],
            "99": [
                "_unpack_returndata"
            ],
            "100": [
                "_unpack_returndata"
            ],
            "101": [
                "_unpack_returndata"
            ],
            "102": [
                "_unpack_returndata"
            ],
            "103": [
                "_unpack_returndata"
            ],
            "104": [
                "_unpack_returndata"
            ],
            "106": [
                "_unpack_returndata"
            ],
            "107": [
                "_unpack_returndata"
            ],
            "109": [
                "_unpack_returndata"
            ],
            "148": [
                "_external_call_helper"
            ],
            "172": [
                "_external_call_helper"
            ],
            "173": [
                "_external_call_helper"
            ],
            "174": [
                "_external_call_helper"
            ],
            "175": [
                "_external_call_helper"
            ],
            "176": [
                "_external_call_helper"
            ],
            "177": [
                "_external_call_helper"
            ],
            "178": [
                "_external_call_helper"
            ],
            "179": [
                "_external_call_helper"
            ],
            "180": [
                "_external_call_helper"
            ]
        },
        "addLocation": []
    }
}