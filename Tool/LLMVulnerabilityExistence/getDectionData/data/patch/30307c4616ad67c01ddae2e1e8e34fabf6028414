{
    "lib/sqlalchemy/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 122,
                "PatchRowcode": " from .engine import engine_from_config  # noqa nosort"
            },
            "1": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 123,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-__version__ = '1.3.0b3'"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+__version__ = \"1.3.0b3\""
            },
            "5": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 126,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 127,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " def __go(lcls):"
            }
        },
        "frontPatchFile": [
            "# sqlalchemy/__init__.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "from . import util as _util  # noqa",
            "from .inspection import inspect  # noqa",
            "from .schema import BLANK_SCHEMA  # noqa",
            "from .schema import CheckConstraint  # noqa",
            "from .schema import Column  # noqa",
            "from .schema import ColumnDefault  # noqa",
            "from .schema import Constraint  # noqa",
            "from .schema import DDL  # noqa",
            "from .schema import DefaultClause  # noqa",
            "from .schema import FetchedValue  # noqa",
            "from .schema import ForeignKey  # noqa",
            "from .schema import ForeignKeyConstraint  # noqa",
            "from .schema import Index  # noqa",
            "from .schema import MetaData  # noqa",
            "from .schema import PassiveDefault  # noqa",
            "from .schema import PrimaryKeyConstraint  # noqa",
            "from .schema import Sequence  # noqa",
            "from .schema import Table  # noqa",
            "from .schema import ThreadLocalMetaData  # noqa",
            "from .schema import UniqueConstraint  # noqa",
            "from .sql import alias  # noqa",
            "from .sql import all_  # noqa",
            "from .sql import and_  # noqa",
            "from .sql import any_  # noqa",
            "from .sql import asc  # noqa",
            "from .sql import between  # noqa",
            "from .sql import bindparam  # noqa",
            "from .sql import case  # noqa",
            "from .sql import cast  # noqa",
            "from .sql import collate  # noqa",
            "from .sql import column  # noqa",
            "from .sql import delete  # noqa",
            "from .sql import desc  # noqa",
            "from .sql import distinct  # noqa",
            "from .sql import except_  # noqa",
            "from .sql import except_all  # noqa",
            "from .sql import exists  # noqa",
            "from .sql import extract  # noqa",
            "from .sql import false  # noqa",
            "from .sql import func  # noqa",
            "from .sql import funcfilter  # noqa",
            "from .sql import insert  # noqa",
            "from .sql import intersect  # noqa",
            "from .sql import intersect_all  # noqa",
            "from .sql import join  # noqa",
            "from .sql import lateral  # noqa",
            "from .sql import literal  # noqa",
            "from .sql import literal_column  # noqa",
            "from .sql import modifier  # noqa",
            "from .sql import not_  # noqa",
            "from .sql import null  # noqa",
            "from .sql import nullsfirst  # noqa",
            "from .sql import nullslast  # noqa",
            "from .sql import or_  # noqa",
            "from .sql import outerjoin  # noqa",
            "from .sql import outparam  # noqa",
            "from .sql import over  # noqa",
            "from .sql import select  # noqa",
            "from .sql import subquery  # noqa",
            "from .sql import table  # noqa",
            "from .sql import tablesample  # noqa",
            "from .sql import text  # noqa",
            "from .sql import true  # noqa",
            "from .sql import tuple_  # noqa",
            "from .sql import type_coerce  # noqa",
            "from .sql import union  # noqa",
            "from .sql import union_all  # noqa",
            "from .sql import update  # noqa",
            "from .sql import within_group  # noqa",
            "from .types import ARRAY  # noqa",
            "from .types import BIGINT  # noqa",
            "from .types import BigInteger  # noqa",
            "from .types import BINARY  # noqa",
            "from .types import Binary  # noqa",
            "from .types import BLOB  # noqa",
            "from .types import BOOLEAN  # noqa",
            "from .types import Boolean  # noqa",
            "from .types import CHAR  # noqa",
            "from .types import CLOB  # noqa",
            "from .types import DATE  # noqa",
            "from .types import Date  # noqa",
            "from .types import DATETIME  # noqa",
            "from .types import DateTime  # noqa",
            "from .types import DECIMAL  # noqa",
            "from .types import Enum  # noqa",
            "from .types import FLOAT  # noqa",
            "from .types import Float  # noqa",
            "from .types import INT  # noqa",
            "from .types import INTEGER  # noqa",
            "from .types import Integer  # noqa",
            "from .types import Interval  # noqa",
            "from .types import JSON  # noqa",
            "from .types import LargeBinary  # noqa",
            "from .types import NCHAR  # noqa",
            "from .types import NUMERIC  # noqa",
            "from .types import Numeric  # noqa",
            "from .types import NVARCHAR  # noqa",
            "from .types import PickleType  # noqa",
            "from .types import REAL  # noqa",
            "from .types import SMALLINT  # noqa",
            "from .types import SmallInteger  # noqa",
            "from .types import String  # noqa",
            "from .types import TEXT  # noqa",
            "from .types import Text  # noqa",
            "from .types import TIME  # noqa",
            "from .types import Time  # noqa",
            "from .types import TIMESTAMP  # noqa",
            "from .types import TypeDecorator  # noqa",
            "from .types import Unicode  # noqa",
            "from .types import UnicodeText  # noqa",
            "from .types import VARBINARY  # noqa",
            "from .types import VARCHAR  # noqa",
            "",
            "from .engine import create_engine  # noqa nosort",
            "from .engine import engine_from_config  # noqa nosort",
            "",
            "",
            "__version__ = '1.3.0b3'",
            "",
            "",
            "def __go(lcls):",
            "    global __all__",
            "",
            "    from . import events  # noqa",
            "    from . import util as _sa_util",
            "",
            "    import inspect as _inspect",
            "",
            "    __all__ = sorted(",
            "        name",
            "        for name, obj in lcls.items()",
            "        if not (name.startswith(\"_\") or _inspect.ismodule(obj))",
            "    )",
            "",
            "    _sa_util.dependencies.resolve_all(\"sqlalchemy\")",
            "",
            "",
            "__go(locals())"
        ],
        "afterPatchFile": [
            "# sqlalchemy/__init__.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "from . import util as _util  # noqa",
            "from .inspection import inspect  # noqa",
            "from .schema import BLANK_SCHEMA  # noqa",
            "from .schema import CheckConstraint  # noqa",
            "from .schema import Column  # noqa",
            "from .schema import ColumnDefault  # noqa",
            "from .schema import Constraint  # noqa",
            "from .schema import DDL  # noqa",
            "from .schema import DefaultClause  # noqa",
            "from .schema import FetchedValue  # noqa",
            "from .schema import ForeignKey  # noqa",
            "from .schema import ForeignKeyConstraint  # noqa",
            "from .schema import Index  # noqa",
            "from .schema import MetaData  # noqa",
            "from .schema import PassiveDefault  # noqa",
            "from .schema import PrimaryKeyConstraint  # noqa",
            "from .schema import Sequence  # noqa",
            "from .schema import Table  # noqa",
            "from .schema import ThreadLocalMetaData  # noqa",
            "from .schema import UniqueConstraint  # noqa",
            "from .sql import alias  # noqa",
            "from .sql import all_  # noqa",
            "from .sql import and_  # noqa",
            "from .sql import any_  # noqa",
            "from .sql import asc  # noqa",
            "from .sql import between  # noqa",
            "from .sql import bindparam  # noqa",
            "from .sql import case  # noqa",
            "from .sql import cast  # noqa",
            "from .sql import collate  # noqa",
            "from .sql import column  # noqa",
            "from .sql import delete  # noqa",
            "from .sql import desc  # noqa",
            "from .sql import distinct  # noqa",
            "from .sql import except_  # noqa",
            "from .sql import except_all  # noqa",
            "from .sql import exists  # noqa",
            "from .sql import extract  # noqa",
            "from .sql import false  # noqa",
            "from .sql import func  # noqa",
            "from .sql import funcfilter  # noqa",
            "from .sql import insert  # noqa",
            "from .sql import intersect  # noqa",
            "from .sql import intersect_all  # noqa",
            "from .sql import join  # noqa",
            "from .sql import lateral  # noqa",
            "from .sql import literal  # noqa",
            "from .sql import literal_column  # noqa",
            "from .sql import modifier  # noqa",
            "from .sql import not_  # noqa",
            "from .sql import null  # noqa",
            "from .sql import nullsfirst  # noqa",
            "from .sql import nullslast  # noqa",
            "from .sql import or_  # noqa",
            "from .sql import outerjoin  # noqa",
            "from .sql import outparam  # noqa",
            "from .sql import over  # noqa",
            "from .sql import select  # noqa",
            "from .sql import subquery  # noqa",
            "from .sql import table  # noqa",
            "from .sql import tablesample  # noqa",
            "from .sql import text  # noqa",
            "from .sql import true  # noqa",
            "from .sql import tuple_  # noqa",
            "from .sql import type_coerce  # noqa",
            "from .sql import union  # noqa",
            "from .sql import union_all  # noqa",
            "from .sql import update  # noqa",
            "from .sql import within_group  # noqa",
            "from .types import ARRAY  # noqa",
            "from .types import BIGINT  # noqa",
            "from .types import BigInteger  # noqa",
            "from .types import BINARY  # noqa",
            "from .types import Binary  # noqa",
            "from .types import BLOB  # noqa",
            "from .types import BOOLEAN  # noqa",
            "from .types import Boolean  # noqa",
            "from .types import CHAR  # noqa",
            "from .types import CLOB  # noqa",
            "from .types import DATE  # noqa",
            "from .types import Date  # noqa",
            "from .types import DATETIME  # noqa",
            "from .types import DateTime  # noqa",
            "from .types import DECIMAL  # noqa",
            "from .types import Enum  # noqa",
            "from .types import FLOAT  # noqa",
            "from .types import Float  # noqa",
            "from .types import INT  # noqa",
            "from .types import INTEGER  # noqa",
            "from .types import Integer  # noqa",
            "from .types import Interval  # noqa",
            "from .types import JSON  # noqa",
            "from .types import LargeBinary  # noqa",
            "from .types import NCHAR  # noqa",
            "from .types import NUMERIC  # noqa",
            "from .types import Numeric  # noqa",
            "from .types import NVARCHAR  # noqa",
            "from .types import PickleType  # noqa",
            "from .types import REAL  # noqa",
            "from .types import SMALLINT  # noqa",
            "from .types import SmallInteger  # noqa",
            "from .types import String  # noqa",
            "from .types import TEXT  # noqa",
            "from .types import Text  # noqa",
            "from .types import TIME  # noqa",
            "from .types import Time  # noqa",
            "from .types import TIMESTAMP  # noqa",
            "from .types import TypeDecorator  # noqa",
            "from .types import Unicode  # noqa",
            "from .types import UnicodeText  # noqa",
            "from .types import VARBINARY  # noqa",
            "from .types import VARCHAR  # noqa",
            "",
            "from .engine import create_engine  # noqa nosort",
            "from .engine import engine_from_config  # noqa nosort",
            "",
            "",
            "__version__ = \"1.3.0b3\"",
            "",
            "",
            "def __go(lcls):",
            "    global __all__",
            "",
            "    from . import events  # noqa",
            "    from . import util as _sa_util",
            "",
            "    import inspect as _inspect",
            "",
            "    __all__ = sorted(",
            "        name",
            "        for name, obj in lcls.items()",
            "        if not (name.startswith(\"_\") or _inspect.ismodule(obj))",
            "    )",
            "",
            "    _sa_util.dependencies.resolve_all(\"sqlalchemy\")",
            "",
            "",
            "__go(locals())"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "125": [
                "__version__"
            ]
        },
        "addLocation": []
    },
    "lib/sqlalchemy/dialects/postgresql/base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 948,
                "afterPatchRowNumber": 948,
                "PatchRowcode": "     _python_UUID = None"
            },
            "1": {
                "beforePatchRowNumber": 949,
                "afterPatchRowNumber": 949,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 950,
                "afterPatchRowNumber": 950,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 951,
                "PatchRowcode": "+IDX_USING = re.compile(r\"^(?:btree|hash|gist|gin|[\\w_]+)$\", re.I)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 952,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": 951,
                "afterPatchRowNumber": 953,
                "PatchRowcode": " AUTOCOMMIT_REGEXP = re.compile("
            },
            "6": {
                "beforePatchRowNumber": 952,
                "afterPatchRowNumber": 954,
                "PatchRowcode": "     r\"\\s*(?:UPDATE|INSERT|CREATE|DELETE|DROP|ALTER|GRANT|REVOKE|\""
            },
            "7": {
                "beforePatchRowNumber": 953,
                "afterPatchRowNumber": 955,
                "PatchRowcode": "     \"IMPORT FOREIGN SCHEMA|REFRESH MATERIALIZED VIEW|TRUNCATE)\","
            },
            "8": {
                "beforePatchRowNumber": 1908,
                "afterPatchRowNumber": 1910,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 1909,
                "afterPatchRowNumber": 1911,
                "PatchRowcode": "         using = index.dialect_options[\"postgresql\"][\"using\"]"
            },
            "10": {
                "beforePatchRowNumber": 1910,
                "afterPatchRowNumber": 1912,
                "PatchRowcode": "         if using:"
            },
            "11": {
                "beforePatchRowNumber": 1911,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            text += \"USING %s \" % preparer.quote(using)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1913,
                "PatchRowcode": "+            text += ("
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1914,
                "PatchRowcode": "+                \"USING %s \""
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1915,
                "PatchRowcode": "+                % self.preparer.validate_sql_phrase(using, IDX_USING).lower()"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1916,
                "PatchRowcode": "+            )"
            },
            "16": {
                "beforePatchRowNumber": 1912,
                "afterPatchRowNumber": 1917,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 1913,
                "afterPatchRowNumber": 1918,
                "PatchRowcode": "         ops = index.dialect_options[\"postgresql\"][\"ops\"]"
            },
            "18": {
                "beforePatchRowNumber": 1914,
                "afterPatchRowNumber": 1919,
                "PatchRowcode": "         text += \"(%s)\" % ("
            },
            "19": {
                "beforePatchRowNumber": 1983,
                "afterPatchRowNumber": 1988,
                "PatchRowcode": "                 \"%s WITH %s\" % (self.sql_compiler.process(expr, **kw), op)"
            },
            "20": {
                "beforePatchRowNumber": 1984,
                "afterPatchRowNumber": 1989,
                "PatchRowcode": "             )"
            },
            "21": {
                "beforePatchRowNumber": 1985,
                "afterPatchRowNumber": 1990,
                "PatchRowcode": "         text += \"EXCLUDE USING %s (%s)\" % ("
            },
            "22": {
                "beforePatchRowNumber": 1986,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            constraint.using,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1991,
                "PatchRowcode": "+            self.preparer.validate_sql_phrase("
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1992,
                "PatchRowcode": "+                constraint.using, IDX_USING"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1993,
                "PatchRowcode": "+            ).lower(),"
            },
            "26": {
                "beforePatchRowNumber": 1987,
                "afterPatchRowNumber": 1994,
                "PatchRowcode": "             \", \".join(elements),"
            },
            "27": {
                "beforePatchRowNumber": 1988,
                "afterPatchRowNumber": 1995,
                "PatchRowcode": "         )"
            },
            "28": {
                "beforePatchRowNumber": 1989,
                "afterPatchRowNumber": 1996,
                "PatchRowcode": "         if constraint.where is not None:"
            }
        },
        "frontPatchFile": [
            "# postgresql/base.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "r\"\"\"",
            ".. dialect:: postgresql",
            "    :name: PostgreSQL",
            "",
            ".. _postgresql_sequences:",
            "",
            "Sequences/SERIAL/IDENTITY",
            "-------------------------",
            "",
            "PostgreSQL supports sequences, and SQLAlchemy uses these as the default means",
            "of creating new primary key values for integer-based primary key columns. When",
            "creating tables, SQLAlchemy will issue the ``SERIAL`` datatype for",
            "integer-based primary key columns, which generates a sequence and server side",
            "default corresponding to the column.",
            "",
            "To specify a specific named sequence to be used for primary key generation,",
            "use the :func:`~sqlalchemy.schema.Sequence` construct::",
            "",
            "    Table('sometable', metadata,",
            "            Column('id', Integer, Sequence('some_id_seq'), primary_key=True)",
            "        )",
            "",
            "When SQLAlchemy issues a single INSERT statement, to fulfill the contract of",
            "having the \"last insert identifier\" available, a RETURNING clause is added to",
            "the INSERT statement which specifies the primary key columns should be",
            "returned after the statement completes. The RETURNING functionality only takes",
            "place if PostgreSQL 8.2 or later is in use. As a fallback approach, the",
            "sequence, whether specified explicitly or implicitly via ``SERIAL``, is",
            "executed independently beforehand, the returned value to be used in the",
            "subsequent insert. Note that when an",
            ":func:`~sqlalchemy.sql.expression.insert()` construct is executed using",
            "\"executemany\" semantics, the \"last inserted identifier\" functionality does not",
            "apply; no RETURNING clause is emitted nor is the sequence pre-executed in this",
            "case.",
            "",
            "To force the usage of RETURNING by default off, specify the flag",
            "``implicit_returning=False`` to :func:`.create_engine`.",
            "",
            "PostgreSQL 10 IDENTITY columns",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL 10 has a new IDENTITY feature that supersedes the use of SERIAL.",
            "Built-in support for rendering of IDENTITY is not available yet, however the",
            "following compilation hook may be used to replace occurrences of SERIAL with",
            "IDENTITY::",
            "",
            "    from sqlalchemy.schema import CreateColumn",
            "    from sqlalchemy.ext.compiler import compiles",
            "",
            "",
            "    @compiles(CreateColumn, 'postgresql')",
            "    def use_identity(element, compiler, **kw):",
            "        text = compiler.visit_create_column(element, **kw)",
            "        text = text.replace(\"SERIAL\", \"INT GENERATED BY DEFAULT AS IDENTITY\")",
            "        return text",
            "",
            "Using the above, a table such as::",
            "",
            "    t = Table(",
            "        't', m,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', String)",
            "    )",
            "",
            "Will generate on the backing database as::",
            "",
            "    CREATE TABLE t (",
            "        id INT GENERATED BY DEFAULT AS IDENTITY NOT NULL,",
            "        data VARCHAR,",
            "        PRIMARY KEY (id)",
            "    )",
            "",
            ".. _postgresql_isolation_level:",
            "",
            "Transaction Isolation Level",
            "---------------------------",
            "",
            "All PostgreSQL dialects support setting of transaction isolation level",
            "both via a dialect-specific parameter",
            ":paramref:`.create_engine.isolation_level` accepted by :func:`.create_engine`,",
            "as well as the :paramref:`.Connection.execution_options.isolation_level`",
            "argument as passed to :meth:`.Connection.execution_options`.",
            "When using a non-psycopg2 dialect, this feature works by issuing the command",
            "``SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL <level>`` for",
            "each new connection.  For the special AUTOCOMMIT isolation level,",
            "DBAPI-specific techniques are used.",
            "",
            "To set isolation level using :func:`.create_engine`::",
            "",
            "    engine = create_engine(",
            "        \"postgresql+pg8000://scott:tiger@localhost/test\",",
            "        isolation_level=\"READ UNCOMMITTED\"",
            "    )",
            "",
            "To set using per-connection execution options::",
            "",
            "    connection = engine.connect()",
            "    connection = connection.execution_options(",
            "        isolation_level=\"READ COMMITTED\"",
            "    )",
            "",
            "Valid values for ``isolation_level`` include:",
            "",
            "* ``READ COMMITTED``",
            "* ``READ UNCOMMITTED``",
            "* ``REPEATABLE READ``",
            "* ``SERIALIZABLE``",
            "* ``AUTOCOMMIT`` - on psycopg2 / pg8000 only",
            "",
            ".. seealso::",
            "",
            "    :ref:`psycopg2_isolation_level`",
            "",
            "    :ref:`pg8000_isolation_level`",
            "",
            ".. _postgresql_schema_reflection:",
            "",
            "Remote-Schema Table Introspection and PostgreSQL search_path",
            "------------------------------------------------------------",
            "",
            "**TL;DR;**: keep the ``search_path`` variable set to its default of ``public``,",
            "name schemas **other** than ``public`` explicitly within ``Table`` definitions.",
            "",
            "The PostgreSQL dialect can reflect tables from any schema.  The",
            ":paramref:`.Table.schema` argument, or alternatively the",
            ":paramref:`.MetaData.reflect.schema` argument determines which schema will",
            "be searched for the table or tables.   The reflected :class:`.Table` objects",
            "will in all cases retain this ``.schema`` attribute as was specified.",
            "However, with regards to tables which these :class:`.Table` objects refer to",
            "via foreign key constraint, a decision must be made as to how the ``.schema``",
            "is represented in those remote tables, in the case where that remote",
            "schema name is also a member of the current",
            "`PostgreSQL search path",
            "<http://www.postgresql.org/docs/current/static/ddl-schemas.html#DDL-SCHEMAS-PATH>`_.",
            "",
            "By default, the PostgreSQL dialect mimics the behavior encouraged by",
            "PostgreSQL's own ``pg_get_constraintdef()`` builtin procedure.  This function",
            "returns a sample definition for a particular foreign key constraint,",
            "omitting the referenced schema name from that definition when the name is",
            "also in the PostgreSQL schema search path.  The interaction below",
            "illustrates this behavior::",
            "",
            "    test=> CREATE TABLE test_schema.referred(id INTEGER PRIMARY KEY);",
            "    CREATE TABLE",
            "    test=> CREATE TABLE referring(",
            "    test(>         id INTEGER PRIMARY KEY,",
            "    test(>         referred_id INTEGER REFERENCES test_schema.referred(id));",
            "    CREATE TABLE",
            "    test=> SET search_path TO public, test_schema;",
            "    test=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM",
            "    test-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n",
            "    test-> ON n.oid = c.relnamespace",
            "    test-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid",
            "    test-> WHERE c.relname='referring' AND r.contype = 'f'",
            "    test-> ;",
            "                   pg_get_constraintdef",
            "    ---------------------------------------------------",
            "     FOREIGN KEY (referred_id) REFERENCES referred(id)",
            "    (1 row)",
            "",
            "Above, we created a table ``referred`` as a member of the remote schema",
            "``test_schema``, however when we added ``test_schema`` to the",
            "PG ``search_path`` and then asked ``pg_get_constraintdef()`` for the",
            "``FOREIGN KEY`` syntax, ``test_schema`` was not included in the output of",
            "the function.",
            "",
            "On the other hand, if we set the search path back to the typical default",
            "of ``public``::",
            "",
            "    test=> SET search_path TO public;",
            "    SET",
            "",
            "The same query against ``pg_get_constraintdef()`` now returns the fully",
            "schema-qualified name for us::",
            "",
            "    test=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM",
            "    test-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n",
            "    test-> ON n.oid = c.relnamespace",
            "    test-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid",
            "    test-> WHERE c.relname='referring' AND r.contype = 'f';",
            "                         pg_get_constraintdef",
            "    ---------------------------------------------------------------",
            "     FOREIGN KEY (referred_id) REFERENCES test_schema.referred(id)",
            "    (1 row)",
            "",
            "SQLAlchemy will by default use the return value of ``pg_get_constraintdef()``",
            "in order to determine the remote schema name.  That is, if our ``search_path``",
            "were set to include ``test_schema``, and we invoked a table",
            "reflection process as follows::",
            "",
            "    >>> from sqlalchemy import Table, MetaData, create_engine",
            "    >>> engine = create_engine(\"postgresql://scott:tiger@localhost/test\")",
            "    >>> with engine.connect() as conn:",
            "    ...     conn.execute(\"SET search_path TO test_schema, public\")",
            "    ...     meta = MetaData()",
            "    ...     referring = Table('referring', meta,",
            "    ...                       autoload=True, autoload_with=conn)",
            "    ...",
            "    <sqlalchemy.engine.result.ResultProxy object at 0x101612ed0>",
            "",
            "The above process would deliver to the :attr:`.MetaData.tables` collection",
            "``referred`` table named **without** the schema::",
            "",
            "    >>> meta.tables['referred'].schema is None",
            "    True",
            "",
            "To alter the behavior of reflection such that the referred schema is",
            "maintained regardless of the ``search_path`` setting, use the",
            "``postgresql_ignore_search_path`` option, which can be specified as a",
            "dialect-specific argument to both :class:`.Table` as well as",
            ":meth:`.MetaData.reflect`::",
            "",
            "    >>> with engine.connect() as conn:",
            "    ...     conn.execute(\"SET search_path TO test_schema, public\")",
            "    ...     meta = MetaData()",
            "    ...     referring = Table('referring', meta, autoload=True,",
            "    ...                       autoload_with=conn,",
            "    ...                       postgresql_ignore_search_path=True)",
            "    ...",
            "    <sqlalchemy.engine.result.ResultProxy object at 0x1016126d0>",
            "",
            "We will now have ``test_schema.referred`` stored as schema-qualified::",
            "",
            "    >>> meta.tables['test_schema.referred'].schema",
            "    'test_schema'",
            "",
            ".. sidebar:: Best Practices for PostgreSQL Schema reflection",
            "",
            "    The description of PostgreSQL schema reflection behavior is complex, and",
            "    is the product of many years of dealing with widely varied use cases and",
            "    user preferences. But in fact, there's no need to understand any of it if",
            "    you just stick to the simplest use pattern: leave the ``search_path`` set",
            "    to its default of ``public`` only, never refer to the name ``public`` as",
            "    an explicit schema name otherwise, and refer to all other schema names",
            "    explicitly when building up a :class:`.Table` object.  The options",
            "    described here are only for those users who can't, or prefer not to, stay",
            "    within these guidelines.",
            "",
            "Note that **in all cases**, the \"default\" schema is always reflected as",
            "``None``. The \"default\" schema on PostgreSQL is that which is returned by the",
            "PostgreSQL ``current_schema()`` function.  On a typical PostgreSQL",
            "installation, this is the name ``public``.  So a table that refers to another",
            "which is in the ``public`` (i.e. default) schema will always have the",
            "``.schema`` attribute set to ``None``.",
            "",
            ".. versionadded:: 0.9.2 Added the ``postgresql_ignore_search_path``",
            "   dialect-level option accepted by :class:`.Table` and",
            "   :meth:`.MetaData.reflect`.",
            "",
            "",
            ".. seealso::",
            "",
            "    `The Schema Search Path",
            "    <http://www.postgresql.org/docs/9.0/static/ddl-schemas.html#DDL-SCHEMAS-PATH>`_",
            "    - on the PostgreSQL website.",
            "",
            "INSERT/UPDATE...RETURNING",
            "-------------------------",
            "",
            "The dialect supports PG 8.2's ``INSERT..RETURNING``, ``UPDATE..RETURNING`` and",
            "``DELETE..RETURNING`` syntaxes.   ``INSERT..RETURNING`` is used by default",
            "for single-row INSERT statements in order to fetch newly generated",
            "primary key identifiers.   To specify an explicit ``RETURNING`` clause,",
            "use the :meth:`._UpdateBase.returning` method on a per-statement basis::",
            "",
            "    # INSERT..RETURNING",
            "    result = table.insert().returning(table.c.col1, table.c.col2).\\",
            "        values(name='foo')",
            "    print result.fetchall()",
            "",
            "    # UPDATE..RETURNING",
            "    result = table.update().returning(table.c.col1, table.c.col2).\\",
            "        where(table.c.name=='foo').values(name='bar')",
            "    print result.fetchall()",
            "",
            "    # DELETE..RETURNING",
            "    result = table.delete().returning(table.c.col1, table.c.col2).\\",
            "        where(table.c.name=='foo')",
            "    print result.fetchall()",
            "",
            ".. _postgresql_insert_on_conflict:",
            "",
            "INSERT...ON CONFLICT (Upsert)",
            "------------------------------",
            "",
            "Starting with version 9.5, PostgreSQL allows \"upserts\" (update or insert) of",
            "rows into a table via the ``ON CONFLICT`` clause of the ``INSERT`` statement. A",
            "candidate row will only be inserted if that row does not violate any unique",
            "constraints.  In the case of a unique constraint violation, a secondary action",
            "can occur which can be either \"DO UPDATE\", indicating that the data in the",
            "target row should be updated, or \"DO NOTHING\", which indicates to silently skip",
            "this row.",
            "",
            "Conflicts are determined using existing unique constraints and indexes.  These",
            "constraints may be identified either using their name as stated in DDL,",
            "or they may be *inferred* by stating the columns and conditions that comprise",
            "the indexes.",
            "",
            "SQLAlchemy provides ``ON CONFLICT`` support via the PostgreSQL-specific",
            ":func:`.postgresql.dml.insert()` function, which provides",
            "the generative methods :meth:`~.postgresql.dml.Insert.on_conflict_do_update`",
            "and :meth:`~.postgresql.dml.Insert.on_conflict_do_nothing`::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    insert_stmt = insert(my_table).values(",
            "        id='some_existing_id',",
            "        data='inserted value')",
            "",
            "    do_nothing_stmt = insert_stmt.on_conflict_do_nothing(",
            "        index_elements=['id']",
            "    )",
            "",
            "    conn.execute(do_nothing_stmt)",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='pk_my_table',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    conn.execute(do_update_stmt)",
            "",
            "Both methods supply the \"target\" of the conflict using either the",
            "named constraint or by column inference:",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.index_elements` argument",
            "  specifies a sequence containing string column names, :class:`.Column`",
            "  objects, and/or SQL expression elements, which would identify a unique",
            "  index::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        index_elements=[my_table.c.id],",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "* When using :paramref:`.Insert.on_conflict_do_update.index_elements` to",
            "  infer an index, a partial index can be inferred by also specifying the",
            "  use the :paramref:`.Insert.on_conflict_do_update.index_where` parameter::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(user_email='a@b.com', data='inserted data')",
            "    stmt = stmt.on_conflict_do_update(",
            "        index_elements=[my_table.c.user_email],",
            "        index_where=my_table.c.user_email.like('%@gmail.com'),",
            "        set_=dict(data=stmt.excluded.data)",
            "        )",
            "    conn.execute(stmt)",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.constraint` argument is",
            "  used to specify an index directly rather than inferring it.  This can be",
            "  the name of a UNIQUE constraint, a PRIMARY KEY constraint, or an INDEX::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='my_table_idx_1',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='my_table_pk',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.constraint` argument may",
            "  also refer to a SQLAlchemy construct representing a constraint,",
            "  e.g. :class:`.UniqueConstraint`, :class:`.PrimaryKeyConstraint`,",
            "  :class:`.Index`, or :class:`.ExcludeConstraint`.   In this use,",
            "  if the constraint has a name, it is used directly.  Otherwise, if the",
            "  constraint is unnamed, then inference will be used, where the expressions",
            "  and optional WHERE clause of the constraint will be spelled out in the",
            "  construct.  This use is especially convenient",
            "  to refer to the named or unnamed primary key of a :class:`.Table` using the",
            "  :attr:`.Table.primary_key` attribute::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint=my_table.primary_key,",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "``ON CONFLICT...DO UPDATE`` is used to perform an update of the already",
            "existing row, using any combination of new values as well as values",
            "from the proposed insertion.   These values are specified using the",
            ":paramref:`.Insert.on_conflict_do_update.set_` parameter.  This",
            "parameter accepts a dictionary which consists of direct values",
            "for UPDATE::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    do_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value')",
            "        )",
            "    conn.execute(do_update_stmt)",
            "",
            ".. warning::",
            "",
            "    The :meth:`.Insert.on_conflict_do_update` method does **not** take into",
            "    account Python-side default UPDATE values or generation functions, e.g.",
            "    e.g. those specified using :paramref:`.Column.onupdate`.",
            "    These values will not be exercised for an ON CONFLICT style of UPDATE,",
            "    unless they are manually specified in the",
            "    :paramref:`.Insert.on_conflict_do_update.set_` dictionary.",
            "",
            "In order to refer to the proposed insertion row, the special alias",
            ":attr:`~.postgresql.dml.Insert.excluded` is available as an attribute on",
            "the :class:`.postgresql.dml.Insert` object; this object is a",
            ":class:`.ColumnCollection` which alias contains all columns of the target",
            "table::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(",
            "        id='some_id',",
            "        data='inserted value',",
            "        author='jlh')",
            "    do_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value', author=stmt.excluded.author)",
            "        )",
            "    conn.execute(do_update_stmt)",
            "",
            "The :meth:`.Insert.on_conflict_do_update` method also accepts",
            "a WHERE clause using the :paramref:`.Insert.on_conflict_do_update.where`",
            "parameter, which will limit those rows which receive an UPDATE::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(",
            "        id='some_id',",
            "        data='inserted value',",
            "        author='jlh')",
            "    on_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value', author=stmt.excluded.author)",
            "        where=(my_table.c.status == 2)",
            "        )",
            "    conn.execute(on_update_stmt)",
            "",
            "``ON CONFLICT`` may also be used to skip inserting a row entirely",
            "if any conflict with a unique or exclusion constraint occurs; below",
            "this is illustrated using the",
            ":meth:`~.postgresql.dml.Insert.on_conflict_do_nothing` method::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    stmt = stmt.on_conflict_do_nothing(index_elements=['id'])",
            "    conn.execute(stmt)",
            "",
            "If ``DO NOTHING`` is used without specifying any columns or constraint,",
            "it has the effect of skipping the INSERT for any unique or exclusion",
            "constraint violation which occurs::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    stmt = stmt.on_conflict_do_nothing()",
            "    conn.execute(stmt)",
            "",
            ".. versionadded:: 1.1 Added support for PostgreSQL ON CONFLICT clauses",
            "",
            ".. seealso::",
            "",
            "    `INSERT .. ON CONFLICT",
            "    <http://www.postgresql.org/docs/current/static/sql-insert.html#SQL-ON-CONFLICT>`_",
            "    - in the PostgreSQL documentation.",
            "",
            ".. _postgresql_match:",
            "",
            "Full Text Search",
            "----------------",
            "",
            "SQLAlchemy makes available the PostgreSQL ``@@`` operator via the",
            ":meth:`.ColumnElement.match` method on any textual column expression.",
            "On a PostgreSQL dialect, an expression like the following::",
            "",
            "    select([sometable.c.text.match(\"search string\")])",
            "",
            "will emit to the database::",
            "",
            "    SELECT text @@ to_tsquery('search string') FROM table",
            "",
            "The PostgreSQL text search functions such as ``to_tsquery()``",
            "and ``to_tsvector()`` are available",
            "explicitly using the standard :data:`.func` construct.  For example::",
            "",
            "    select([",
            "        func.to_tsvector('fat cats ate rats').match('cat & rat')",
            "    ])",
            "",
            "Emits the equivalent of::",
            "",
            "    SELECT to_tsvector('fat cats ate rats') @@ to_tsquery('cat & rat')",
            "",
            "The :class:`.postgresql.TSVECTOR` type can provide for explicit CAST::",
            "",
            "    from sqlalchemy.dialects.postgresql import TSVECTOR",
            "    from sqlalchemy import select, cast",
            "    select([cast(\"some text\", TSVECTOR)])",
            "",
            "produces a statement equivalent to::",
            "",
            "    SELECT CAST('some text' AS TSVECTOR) AS anon_1",
            "",
            "Full Text Searches in PostgreSQL are influenced by a combination of: the",
            "PostgreSQL setting of ``default_text_search_config``, the ``regconfig`` used",
            "to build the GIN/GiST indexes, and the ``regconfig`` optionally passed in",
            "during a query.",
            "",
            "When performing a Full Text Search against a column that has a GIN or",
            "GiST index that is already pre-computed (which is common on full text",
            "searches) one may need to explicitly pass in a particular PostgreSQL",
            "``regconfig`` value to ensure the query-planner utilizes the index and does",
            "not re-compute the column on demand.",
            "",
            "In order to provide for this explicit query planning, or to use different",
            "search strategies, the ``match`` method accepts a ``postgresql_regconfig``",
            "keyword argument::",
            "",
            "    select([mytable.c.id]).where(",
            "        mytable.c.title.match('somestring', postgresql_regconfig='english')",
            "    )",
            "",
            "Emits the equivalent of::",
            "",
            "    SELECT mytable.id FROM mytable",
            "    WHERE mytable.title @@ to_tsquery('english', 'somestring')",
            "",
            "One can also specifically pass in a `'regconfig'` value to the",
            "``to_tsvector()`` command as the initial argument::",
            "",
            "    select([mytable.c.id]).where(",
            "            func.to_tsvector('english', mytable.c.title )\\",
            "            .match('somestring', postgresql_regconfig='english')",
            "        )",
            "",
            "produces a statement equivalent to::",
            "",
            "    SELECT mytable.id FROM mytable",
            "    WHERE to_tsvector('english', mytable.title) @@",
            "        to_tsquery('english', 'somestring')",
            "",
            "It is recommended that you use the ``EXPLAIN ANALYZE...`` tool from",
            "PostgreSQL to ensure that you are generating queries with SQLAlchemy that",
            "take full advantage of any indexes you may have created for full text search.",
            "",
            "FROM ONLY ...",
            "------------------------",
            "",
            "The dialect supports PostgreSQL's ONLY keyword for targeting only a particular",
            "table in an inheritance hierarchy. This can be used to produce the",
            "``SELECT ... FROM ONLY``, ``UPDATE ONLY ...``, and ``DELETE FROM ONLY ...``",
            "syntaxes. It uses SQLAlchemy's hints mechanism::",
            "",
            "    # SELECT ... FROM ONLY ...",
            "    result = table.select().with_hint(table, 'ONLY', 'postgresql')",
            "    print result.fetchall()",
            "",
            "    # UPDATE ONLY ...",
            "    table.update(values=dict(foo='bar')).with_hint('ONLY',",
            "                                                   dialect_name='postgresql')",
            "",
            "    # DELETE FROM ONLY ...",
            "    table.delete().with_hint('ONLY', dialect_name='postgresql')",
            "",
            "",
            ".. _postgresql_indexes:",
            "",
            "PostgreSQL-Specific Index Options",
            "---------------------------------",
            "",
            "Several extensions to the :class:`.Index` construct are available, specific",
            "to the PostgreSQL dialect.",
            "",
            ".. _postgresql_partial_indexes:",
            "",
            "Partial Indexes",
            "^^^^^^^^^^^^^^^",
            "",
            "Partial indexes add criterion to the index definition so that the index is",
            "applied to a subset of rows.   These can be specified on :class:`.Index`",
            "using the ``postgresql_where`` keyword argument::",
            "",
            "  Index('my_index', my_table.c.id, postgresql_where=my_table.c.value > 10)",
            "",
            "Operator Classes",
            "^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL allows the specification of an *operator class* for each column of",
            "an index (see",
            "http://www.postgresql.org/docs/8.3/interactive/indexes-opclass.html).",
            "The :class:`.Index` construct allows these to be specified via the",
            "``postgresql_ops`` keyword argument::",
            "",
            "    Index(",
            "        'my_index', my_table.c.id, my_table.c.data,",
            "        postgresql_ops={",
            "            'data': 'text_pattern_ops',",
            "            'id': 'int4_ops'",
            "        })",
            "",
            "Note that the keys in the ``postgresql_ops`` dictionary are the \"key\" name of",
            "the :class:`.Column`, i.e. the name used to access it from the ``.c``",
            "collection of :class:`.Table`, which can be configured to be different than",
            "the actual name of the column as expressed in the database.",
            "",
            "If ``postgresql_ops`` is to be used against a complex SQL expression such",
            "as a function call, then to apply to the column it must be given a label",
            "that is identified in the dictionary by name, e.g.::",
            "",
            "    Index(",
            "        'my_index', my_table.c.id,",
            "        func.lower(my_table.c.data).label('data_lower'),",
            "        postgresql_ops={",
            "            'data_lower': 'text_pattern_ops',",
            "            'id': 'int4_ops'",
            "        })",
            "",
            "",
            "Index Types",
            "^^^^^^^^^^^",
            "",
            "PostgreSQL provides several index types: B-Tree, Hash, GiST, and GIN, as well",
            "as the ability for users to create their own (see",
            "http://www.postgresql.org/docs/8.3/static/indexes-types.html). These can be",
            "specified on :class:`.Index` using the ``postgresql_using`` keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_using='gin')",
            "",
            "The value passed to the keyword argument will be simply passed through to the",
            "underlying CREATE INDEX command, so it *must* be a valid index type for your",
            "version of PostgreSQL.",
            "",
            ".. _postgresql_index_storage:",
            "",
            "Index Storage Parameters",
            "^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL allows storage parameters to be set on indexes. The storage",
            "parameters available depend on the index method used by the index. Storage",
            "parameters can be specified on :class:`.Index` using the ``postgresql_with``",
            "keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_with={\"fillfactor\": 50})",
            "",
            ".. versionadded:: 1.0.6",
            "",
            "PostgreSQL allows to define the tablespace in which to create the index.",
            "The tablespace can be specified on :class:`.Index` using the",
            "``postgresql_tablespace`` keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_tablespace='my_tablespace')",
            "",
            ".. versionadded:: 1.1",
            "",
            "Note that the same option is available on :class:`.Table` as well.",
            "",
            ".. _postgresql_index_concurrently:",
            "",
            "Indexes with CONCURRENTLY",
            "^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "The PostgreSQL index option CONCURRENTLY is supported by passing the",
            "flag ``postgresql_concurrently`` to the :class:`.Index` construct::",
            "",
            "    tbl = Table('testtbl', m, Column('data', Integer))",
            "",
            "    idx1 = Index('test_idx1', tbl.c.data, postgresql_concurrently=True)",
            "",
            "The above index construct will render DDL for CREATE INDEX, assuming",
            "PostgreSQL 8.2 or higher is detected or for a connection-less dialect, as::",
            "",
            "    CREATE INDEX CONCURRENTLY test_idx1 ON testtbl (data)",
            "",
            "For DROP INDEX, assuming PostgreSQL 9.2 or higher is detected or for",
            "a connection-less dialect, it will emit::",
            "",
            "    DROP INDEX CONCURRENTLY test_idx1",
            "",
            ".. versionadded:: 1.1 support for CONCURRENTLY on DROP INDEX.  The",
            "   CONCURRENTLY keyword is now only emitted if a high enough version",
            "   of PostgreSQL is detected on the connection (or for a connection-less",
            "   dialect).",
            "",
            "When using CONCURRENTLY, the PostgreSQL database requires that the statement",
            "be invoked outside of a transaction block.   The Python DBAPI enforces that",
            "even for a single statement, a transaction is present, so to use this",
            "construct, the DBAPI's \"autocommit\" mode must be used::",
            "",
            "    metadata = MetaData()",
            "    table = Table(",
            "        \"foo\", metadata,",
            "        Column(\"id\", String))",
            "    index = Index(",
            "        \"foo_idx\", table.c.id, postgresql_concurrently=True)",
            "",
            "    with engine.connect() as conn:",
            "        with conn.execution_options(isolation_level='AUTOCOMMIT'):",
            "            table.create(conn)",
            "",
            ".. seealso::",
            "",
            "    :ref:`postgresql_isolation_level`",
            "",
            ".. _postgresql_index_reflection:",
            "",
            "PostgreSQL Index Reflection",
            "---------------------------",
            "",
            "The PostgreSQL database creates a UNIQUE INDEX implicitly whenever the",
            "UNIQUE CONSTRAINT construct is used.   When inspecting a table using",
            ":class:`.Inspector`, the :meth:`.Inspector.get_indexes`",
            "and the :meth:`.Inspector.get_unique_constraints` will report on these",
            "two constructs distinctly; in the case of the index, the key",
            "``duplicates_constraint`` will be present in the index entry if it is",
            "detected as mirroring a constraint.   When performing reflection using",
            "``Table(..., autoload=True)``, the UNIQUE INDEX is **not** returned",
            "in :attr:`.Table.indexes` when it is detected as mirroring a",
            ":class:`.UniqueConstraint` in the :attr:`.Table.constraints` collection.",
            "",
            ".. versionchanged:: 1.0.0 - :class:`.Table` reflection now includes",
            "   :class:`.UniqueConstraint` objects present in the :attr:`.Table.constraints`",
            "   collection; the PostgreSQL backend will no longer include a \"mirrored\"",
            "   :class:`.Index` construct in :attr:`.Table.indexes` if it is detected",
            "   as corresponding to a unique constraint.",
            "",
            "Special Reflection Options",
            "--------------------------",
            "",
            "The :class:`.Inspector` used for the PostgreSQL backend is an instance",
            "of :class:`.PGInspector`, which offers additional methods::",
            "",
            "    from sqlalchemy import create_engine, inspect",
            "",
            "    engine = create_engine(\"postgresql+psycopg2://localhost/test\")",
            "    insp = inspect(engine)  # will be a PGInspector",
            "",
            "    print(insp.get_enums())",
            "",
            ".. autoclass:: PGInspector",
            "    :members:",
            "",
            ".. _postgresql_table_options:",
            "",
            "PostgreSQL Table Options",
            "------------------------",
            "",
            "Several options for CREATE TABLE are supported directly by the PostgreSQL",
            "dialect in conjunction with the :class:`.Table` construct:",
            "",
            "* ``TABLESPACE``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_tablespace='some_tablespace')",
            "",
            "  The above option is also available on the :class:`.Index` construct.",
            "",
            "* ``ON COMMIT``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_on_commit='PRESERVE ROWS')",
            "",
            "* ``WITH OIDS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_with_oids=True)",
            "",
            "* ``WITHOUT OIDS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_with_oids=False)",
            "",
            "* ``INHERITS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_inherits=\"some_supertable\")",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_inherits=(\"t1\", \"t2\", ...))",
            "",
            "    .. versionadded:: 1.0.0",
            "",
            "* ``PARTITION BY``::",
            "",
            "    Table(\"some_table\", metadata, ...,",
            "          postgresql_partition_by='LIST (part_column)')",
            "",
            "    .. versionadded:: 1.2.6",
            "",
            ".. seealso::",
            "",
            "    `PostgreSQL CREATE TABLE options",
            "    <http://www.postgresql.org/docs/current/static/sql-createtable.html>`_",
            "",
            "ARRAY Types",
            "-----------",
            "",
            "The PostgreSQL dialect supports arrays, both as multidimensional column types",
            "as well as array literals:",
            "",
            "* :class:`.postgresql.ARRAY` - ARRAY datatype",
            "",
            "* :class:`.postgresql.array` - array literal",
            "",
            "* :func:`.postgresql.array_agg` - ARRAY_AGG SQL function",
            "",
            "* :class:`.postgresql.aggregate_order_by` - helper for PG's ORDER BY aggregate",
            "  function syntax.",
            "",
            "JSON Types",
            "----------",
            "",
            "The PostgreSQL dialect supports both JSON and JSONB datatypes, including",
            "psycopg2's native support and support for all of PostgreSQL's special",
            "operators:",
            "",
            "* :class:`.postgresql.JSON`",
            "",
            "* :class:`.postgresql.JSONB`",
            "",
            "HSTORE Type",
            "-----------",
            "",
            "The PostgreSQL HSTORE type as well as hstore literals are supported:",
            "",
            "* :class:`.postgresql.HSTORE` - HSTORE datatype",
            "",
            "* :class:`.postgresql.hstore` - hstore literal",
            "",
            "ENUM Types",
            "----------",
            "",
            "PostgreSQL has an independently creatable TYPE structure which is used",
            "to implement an enumerated type.   This approach introduces significant",
            "complexity on the SQLAlchemy side in terms of when this type should be",
            "CREATED and DROPPED.   The type object is also an independently reflectable",
            "entity.   The following sections should be consulted:",
            "",
            "* :class:`.postgresql.ENUM` - DDL and typing support for ENUM.",
            "",
            "* :meth:`.PGInspector.get_enums` - retrieve a listing of current ENUM types",
            "",
            "* :meth:`.postgresql.ENUM.create` , :meth:`.postgresql.ENUM.drop` - individual",
            "  CREATE and DROP commands for ENUM.",
            "",
            ".. _postgresql_array_of_enum:",
            "",
            "Using ENUM with ARRAY",
            "^^^^^^^^^^^^^^^^^^^^^",
            "",
            "The combination of ENUM and ARRAY is not directly supported by backend",
            "DBAPIs at this time.   In order to send and receive an ARRAY of ENUM,",
            "use the following workaround type::",
            "",
            "    class ArrayOfEnum(ARRAY):",
            "",
            "        def bind_expression(self, bindvalue):",
            "            return sa.cast(bindvalue, self)",
            "",
            "        def result_processor(self, dialect, coltype):",
            "            super_rp = super(ArrayOfEnum, self).result_processor(",
            "                dialect, coltype)",
            "",
            "            def handle_raw_string(value):",
            "                inner = re.match(r\"^{(.*)}$\", value).group(1)",
            "                return inner.split(\",\") if inner else []",
            "",
            "            def process(value):",
            "                if value is None:",
            "                    return None",
            "                return super_rp(handle_raw_string(value))",
            "            return process",
            "",
            "E.g.::",
            "",
            "    Table(",
            "        'mydata', metadata,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', ArrayOfEnum(ENUM('a', 'b, 'c', name='myenum')))",
            "",
            "    )",
            "",
            "This type is not included as a built-in type as it would be incompatible",
            "with a DBAPI that suddenly decides to support ARRAY of ENUM directly in",
            "a new version.",
            "",
            ".. _postgresql_array_of_json:",
            "",
            "Using JSON/JSONB with ARRAY",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "Similar to using ENUM, for an ARRAY of JSON/JSONB we need to render the",
            "appropriate CAST, however current psycopg2 drivers seem to handle the result",
            "for ARRAY of JSON automatically, so the type is simpler::",
            "",
            "",
            "    class CastingArray(ARRAY):",
            "        def bind_expression(self, bindvalue):",
            "            return sa.cast(bindvalue, self)",
            "",
            "E.g.::",
            "",
            "    Table(",
            "        'mydata', metadata,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', CastingArray(JSONB))",
            "    )",
            "",
            "",
            "\"\"\"",
            "from collections import defaultdict",
            "import datetime as dt",
            "import re",
            "",
            "from ... import exc",
            "from ... import schema",
            "from ... import sql",
            "from ... import util",
            "from ...engine import default",
            "from ...engine import reflection",
            "from ...sql import compiler",
            "from ...sql import elements",
            "from ...sql import expression",
            "from ...sql import sqltypes",
            "from ...types import BIGINT",
            "from ...types import BOOLEAN",
            "from ...types import CHAR",
            "from ...types import DATE",
            "from ...types import FLOAT",
            "from ...types import INTEGER",
            "from ...types import NUMERIC",
            "from ...types import REAL",
            "from ...types import SMALLINT",
            "from ...types import TEXT",
            "from ...types import VARCHAR",
            "",
            "",
            "try:",
            "    from uuid import UUID as _python_UUID  # noqa",
            "except ImportError:",
            "    _python_UUID = None",
            "",
            "",
            "AUTOCOMMIT_REGEXP = re.compile(",
            "    r\"\\s*(?:UPDATE|INSERT|CREATE|DELETE|DROP|ALTER|GRANT|REVOKE|\"",
            "    \"IMPORT FOREIGN SCHEMA|REFRESH MATERIALIZED VIEW|TRUNCATE)\",",
            "    re.I | re.UNICODE,",
            ")",
            "",
            "RESERVED_WORDS = set(",
            "    [",
            "        \"all\",",
            "        \"analyse\",",
            "        \"analyze\",",
            "        \"and\",",
            "        \"any\",",
            "        \"array\",",
            "        \"as\",",
            "        \"asc\",",
            "        \"asymmetric\",",
            "        \"both\",",
            "        \"case\",",
            "        \"cast\",",
            "        \"check\",",
            "        \"collate\",",
            "        \"column\",",
            "        \"constraint\",",
            "        \"create\",",
            "        \"current_catalog\",",
            "        \"current_date\",",
            "        \"current_role\",",
            "        \"current_time\",",
            "        \"current_timestamp\",",
            "        \"current_user\",",
            "        \"default\",",
            "        \"deferrable\",",
            "        \"desc\",",
            "        \"distinct\",",
            "        \"do\",",
            "        \"else\",",
            "        \"end\",",
            "        \"except\",",
            "        \"false\",",
            "        \"fetch\",",
            "        \"for\",",
            "        \"foreign\",",
            "        \"from\",",
            "        \"grant\",",
            "        \"group\",",
            "        \"having\",",
            "        \"in\",",
            "        \"initially\",",
            "        \"intersect\",",
            "        \"into\",",
            "        \"leading\",",
            "        \"limit\",",
            "        \"localtime\",",
            "        \"localtimestamp\",",
            "        \"new\",",
            "        \"not\",",
            "        \"null\",",
            "        \"of\",",
            "        \"off\",",
            "        \"offset\",",
            "        \"old\",",
            "        \"on\",",
            "        \"only\",",
            "        \"or\",",
            "        \"order\",",
            "        \"placing\",",
            "        \"primary\",",
            "        \"references\",",
            "        \"returning\",",
            "        \"select\",",
            "        \"session_user\",",
            "        \"some\",",
            "        \"symmetric\",",
            "        \"table\",",
            "        \"then\",",
            "        \"to\",",
            "        \"trailing\",",
            "        \"true\",",
            "        \"union\",",
            "        \"unique\",",
            "        \"user\",",
            "        \"using\",",
            "        \"variadic\",",
            "        \"when\",",
            "        \"where\",",
            "        \"window\",",
            "        \"with\",",
            "        \"authorization\",",
            "        \"between\",",
            "        \"binary\",",
            "        \"cross\",",
            "        \"current_schema\",",
            "        \"freeze\",",
            "        \"full\",",
            "        \"ilike\",",
            "        \"inner\",",
            "        \"is\",",
            "        \"isnull\",",
            "        \"join\",",
            "        \"left\",",
            "        \"like\",",
            "        \"natural\",",
            "        \"notnull\",",
            "        \"outer\",",
            "        \"over\",",
            "        \"overlaps\",",
            "        \"right\",",
            "        \"similar\",",
            "        \"verbose\",",
            "    ]",
            ")",
            "",
            "_DECIMAL_TYPES = (1231, 1700)",
            "_FLOAT_TYPES = (700, 701, 1021, 1022)",
            "_INT_TYPES = (20, 21, 23, 26, 1005, 1007, 1016)",
            "",
            "",
            "class BYTEA(sqltypes.LargeBinary):",
            "    __visit_name__ = \"BYTEA\"",
            "",
            "",
            "class DOUBLE_PRECISION(sqltypes.Float):",
            "    __visit_name__ = \"DOUBLE_PRECISION\"",
            "",
            "",
            "class INET(sqltypes.TypeEngine):",
            "    __visit_name__ = \"INET\"",
            "",
            "",
            "PGInet = INET",
            "",
            "",
            "class CIDR(sqltypes.TypeEngine):",
            "    __visit_name__ = \"CIDR\"",
            "",
            "",
            "PGCidr = CIDR",
            "",
            "",
            "class MACADDR(sqltypes.TypeEngine):",
            "    __visit_name__ = \"MACADDR\"",
            "",
            "",
            "PGMacAddr = MACADDR",
            "",
            "",
            "class MONEY(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL MONEY type.",
            "",
            "    .. versionadded:: 1.2",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"MONEY\"",
            "",
            "",
            "class OID(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL OID type.",
            "",
            "    .. versionadded:: 0.9.5",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"OID\"",
            "",
            "",
            "class REGCLASS(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL REGCLASS type.",
            "",
            "    .. versionadded:: 1.2.7",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"REGCLASS\"",
            "",
            "",
            "class TIMESTAMP(sqltypes.TIMESTAMP):",
            "    def __init__(self, timezone=False, precision=None):",
            "        super(TIMESTAMP, self).__init__(timezone=timezone)",
            "        self.precision = precision",
            "",
            "",
            "class TIME(sqltypes.TIME):",
            "    def __init__(self, timezone=False, precision=None):",
            "        super(TIME, self).__init__(timezone=timezone)",
            "        self.precision = precision",
            "",
            "",
            "class INTERVAL(sqltypes.NativeForEmulated, sqltypes._AbstractInterval):",
            "",
            "    \"\"\"PostgreSQL INTERVAL type.",
            "",
            "    The INTERVAL type may not be supported on all DBAPIs.",
            "    It is known to work on psycopg2 and not pg8000 or zxjdbc.",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"INTERVAL\"",
            "    native = True",
            "",
            "    def __init__(self, precision=None, fields=None):",
            "        \"\"\"Construct an INTERVAL.",
            "",
            "        :param precision: optional integer precision value",
            "        :param fields: string fields specifier.  allows storage of fields",
            "         to be limited, such as ``\"YEAR\"``, ``\"MONTH\"``, ``\"DAY TO HOUR\"``,",
            "         etc.",
            "",
            "         .. versionadded:: 1.2",
            "",
            "        \"\"\"",
            "        self.precision = precision",
            "        self.fields = fields",
            "",
            "    @classmethod",
            "    def adapt_emulated_to_native(cls, interval, **kw):",
            "        return INTERVAL(precision=interval.second_precision)",
            "",
            "    @property",
            "    def _type_affinity(self):",
            "        return sqltypes.Interval",
            "",
            "    @property",
            "    def python_type(self):",
            "        return dt.timedelta",
            "",
            "",
            "PGInterval = INTERVAL",
            "",
            "",
            "class BIT(sqltypes.TypeEngine):",
            "    __visit_name__ = \"BIT\"",
            "",
            "    def __init__(self, length=None, varying=False):",
            "        if not varying:",
            "            # BIT without VARYING defaults to length 1",
            "            self.length = length or 1",
            "        else:",
            "            # but BIT VARYING can be unlimited-length, so no default",
            "            self.length = length",
            "        self.varying = varying",
            "",
            "",
            "PGBit = BIT",
            "",
            "",
            "class UUID(sqltypes.TypeEngine):",
            "",
            "    \"\"\"PostgreSQL UUID type.",
            "",
            "    Represents the UUID column type, interpreting",
            "    data either as natively returned by the DBAPI",
            "    or as Python uuid objects.",
            "",
            "    The UUID type may not be supported on all DBAPIs.",
            "    It is known to work on psycopg2 and not pg8000.",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"UUID\"",
            "",
            "    def __init__(self, as_uuid=False):",
            "        \"\"\"Construct a UUID type.",
            "",
            "",
            "        :param as_uuid=False: if True, values will be interpreted",
            "         as Python uuid objects, converting to/from string via the",
            "         DBAPI.",
            "",
            "         \"\"\"",
            "        if as_uuid and _python_UUID is None:",
            "            raise NotImplementedError(",
            "                \"This version of Python does not support \"",
            "                \"the native UUID type.\"",
            "            )",
            "        self.as_uuid = as_uuid",
            "",
            "    def bind_processor(self, dialect):",
            "        if self.as_uuid:",
            "",
            "            def process(value):",
            "                if value is not None:",
            "                    value = util.text_type(value)",
            "                return value",
            "",
            "            return process",
            "        else:",
            "            return None",
            "",
            "    def result_processor(self, dialect, coltype):",
            "        if self.as_uuid:",
            "",
            "            def process(value):",
            "                if value is not None:",
            "                    value = _python_UUID(value)",
            "                return value",
            "",
            "            return process",
            "        else:",
            "            return None",
            "",
            "",
            "PGUuid = UUID",
            "",
            "",
            "class TSVECTOR(sqltypes.TypeEngine):",
            "",
            "    \"\"\"The :class:`.postgresql.TSVECTOR` type implements the PostgreSQL",
            "    text search type TSVECTOR.",
            "",
            "    It can be used to do full text queries on natural language",
            "    documents.",
            "",
            "    .. versionadded:: 0.9.0",
            "",
            "    .. seealso::",
            "",
            "        :ref:`postgresql_match`",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"TSVECTOR\"",
            "",
            "",
            "class ENUM(sqltypes.NativeForEmulated, sqltypes.Enum):",
            "",
            "    \"\"\"PostgreSQL ENUM type.",
            "",
            "    This is a subclass of :class:`.types.Enum` which includes",
            "    support for PG's ``CREATE TYPE`` and ``DROP TYPE``.",
            "",
            "    When the builtin type :class:`.types.Enum` is used and the",
            "    :paramref:`.Enum.native_enum` flag is left at its default of",
            "    True, the PostgreSQL backend will use a :class:`.postgresql.ENUM`",
            "    type as the implementation, so the special create/drop rules",
            "    will be used.",
            "",
            "    The create/drop behavior of ENUM is necessarily intricate, due to the",
            "    awkward relationship the ENUM type has in relationship to the",
            "    parent table, in that it may be \"owned\" by just a single table, or",
            "    may be shared among many tables.",
            "",
            "    When using :class:`.types.Enum` or :class:`.postgresql.ENUM`",
            "    in an \"inline\" fashion, the ``CREATE TYPE`` and ``DROP TYPE`` is emitted",
            "    corresponding to when the :meth:`.Table.create` and :meth:`.Table.drop`",
            "    methods are called::",
            "",
            "        table = Table('sometable', metadata,",
            "            Column('some_enum', ENUM('a', 'b', 'c', name='myenum'))",
            "        )",
            "",
            "        table.create(engine)  # will emit CREATE ENUM and CREATE TABLE",
            "        table.drop(engine)  # will emit DROP TABLE and DROP ENUM",
            "",
            "    To use a common enumerated type between multiple tables, the best",
            "    practice is to declare the :class:`.types.Enum` or",
            "    :class:`.postgresql.ENUM` independently, and associate it with the",
            "    :class:`.MetaData` object itself::",
            "",
            "        my_enum = ENUM('a', 'b', 'c', name='myenum', metadata=metadata)",
            "",
            "        t1 = Table('sometable_one', metadata,",
            "            Column('some_enum', myenum)",
            "        )",
            "",
            "        t2 = Table('sometable_two', metadata,",
            "            Column('some_enum', myenum)",
            "        )",
            "",
            "    When this pattern is used, care must still be taken at the level",
            "    of individual table creates.  Emitting CREATE TABLE without also",
            "    specifying ``checkfirst=True`` will still cause issues::",
            "",
            "        t1.create(engine) # will fail: no such type 'myenum'",
            "",
            "    If we specify ``checkfirst=True``, the individual table-level create",
            "    operation will check for the ``ENUM`` and create if not exists::",
            "",
            "        # will check if enum exists, and emit CREATE TYPE if not",
            "        t1.create(engine, checkfirst=True)",
            "",
            "    When using a metadata-level ENUM type, the type will always be created",
            "    and dropped if either the metadata-wide create/drop is called::",
            "",
            "        metadata.create_all(engine)  # will emit CREATE TYPE",
            "        metadata.drop_all(engine)  # will emit DROP TYPE",
            "",
            "    The type can also be created and dropped directly::",
            "",
            "        my_enum.create(engine)",
            "        my_enum.drop(engine)",
            "",
            "    .. versionchanged:: 1.0.0 The PostgreSQL :class:`.postgresql.ENUM` type",
            "       now behaves more strictly with regards to CREATE/DROP.  A metadata-level",
            "       ENUM type will only be created and dropped at the metadata level,",
            "       not the table level, with the exception of",
            "       ``table.create(checkfirst=True)``.",
            "       The ``table.drop()`` call will now emit a DROP TYPE for a table-level",
            "       enumerated type.",
            "",
            "    \"\"\"",
            "",
            "    native_enum = True",
            "",
            "    def __init__(self, *enums, **kw):",
            "        \"\"\"Construct an :class:`~.postgresql.ENUM`.",
            "",
            "        Arguments are the same as that of",
            "        :class:`.types.Enum`, but also including",
            "        the following parameters.",
            "",
            "        :param create_type: Defaults to True.",
            "         Indicates that ``CREATE TYPE`` should be",
            "         emitted, after optionally checking for the",
            "         presence of the type, when the parent",
            "         table is being created; and additionally",
            "         that ``DROP TYPE`` is called when the table",
            "         is dropped.    When ``False``, no check",
            "         will be performed and no ``CREATE TYPE``",
            "         or ``DROP TYPE`` is emitted, unless",
            "         :meth:`~.postgresql.ENUM.create`",
            "         or :meth:`~.postgresql.ENUM.drop`",
            "         are called directly.",
            "         Setting to ``False`` is helpful",
            "         when invoking a creation scheme to a SQL file",
            "         without access to the actual database -",
            "         the :meth:`~.postgresql.ENUM.create` and",
            "         :meth:`~.postgresql.ENUM.drop` methods can",
            "         be used to emit SQL to a target bind.",
            "",
            "        \"\"\"",
            "        self.create_type = kw.pop(\"create_type\", True)",
            "        super(ENUM, self).__init__(*enums, **kw)",
            "",
            "    @classmethod",
            "    def adapt_emulated_to_native(cls, impl, **kw):",
            "        \"\"\"Produce a PostgreSQL native :class:`.postgresql.ENUM` from plain",
            "        :class:`.Enum`.",
            "",
            "        \"\"\"",
            "        kw.setdefault(\"validate_strings\", impl.validate_strings)",
            "        kw.setdefault(\"name\", impl.name)",
            "        kw.setdefault(\"schema\", impl.schema)",
            "        kw.setdefault(\"inherit_schema\", impl.inherit_schema)",
            "        kw.setdefault(\"metadata\", impl.metadata)",
            "        kw.setdefault(\"_create_events\", False)",
            "        kw.setdefault(\"values_callable\", impl.values_callable)",
            "        return cls(**kw)",
            "",
            "    def create(self, bind=None, checkfirst=True):",
            "        \"\"\"Emit ``CREATE TYPE`` for this",
            "        :class:`~.postgresql.ENUM`.",
            "",
            "        If the underlying dialect does not support",
            "        PostgreSQL CREATE TYPE, no action is taken.",
            "",
            "        :param bind: a connectable :class:`.Engine`,",
            "         :class:`.Connection`, or similar object to emit",
            "         SQL.",
            "        :param checkfirst: if ``True``, a query against",
            "         the PG catalog will be first performed to see",
            "         if the type does not exist already before",
            "         creating.",
            "",
            "        \"\"\"",
            "        if not bind.dialect.supports_native_enum:",
            "            return",
            "",
            "        if not checkfirst or not bind.dialect.has_type(",
            "            bind, self.name, schema=self.schema",
            "        ):",
            "            bind.execute(CreateEnumType(self))",
            "",
            "    def drop(self, bind=None, checkfirst=True):",
            "        \"\"\"Emit ``DROP TYPE`` for this",
            "        :class:`~.postgresql.ENUM`.",
            "",
            "        If the underlying dialect does not support",
            "        PostgreSQL DROP TYPE, no action is taken.",
            "",
            "        :param bind: a connectable :class:`.Engine`,",
            "         :class:`.Connection`, or similar object to emit",
            "         SQL.",
            "        :param checkfirst: if ``True``, a query against",
            "         the PG catalog will be first performed to see",
            "         if the type actually exists before dropping.",
            "",
            "        \"\"\"",
            "        if not bind.dialect.supports_native_enum:",
            "            return",
            "",
            "        if not checkfirst or bind.dialect.has_type(",
            "            bind, self.name, schema=self.schema",
            "        ):",
            "            bind.execute(DropEnumType(self))",
            "",
            "    def _check_for_name_in_memos(self, checkfirst, kw):",
            "        \"\"\"Look in the 'ddl runner' for 'memos', then",
            "        note our name in that collection.",
            "",
            "        This to ensure a particular named enum is operated",
            "        upon only once within any kind of create/drop",
            "        sequence without relying upon \"checkfirst\".",
            "",
            "        \"\"\"",
            "        if not self.create_type:",
            "            return True",
            "        if \"_ddl_runner\" in kw:",
            "            ddl_runner = kw[\"_ddl_runner\"]",
            "            if \"_pg_enums\" in ddl_runner.memo:",
            "                pg_enums = ddl_runner.memo[\"_pg_enums\"]",
            "            else:",
            "                pg_enums = ddl_runner.memo[\"_pg_enums\"] = set()",
            "            present = (self.schema, self.name) in pg_enums",
            "            pg_enums.add((self.schema, self.name))",
            "            return present",
            "        else:",
            "            return False",
            "",
            "    def _on_table_create(self, target, bind, checkfirst=False, **kw):",
            "        if (",
            "            checkfirst",
            "            or (",
            "                not self.metadata",
            "                and not kw.get(\"_is_metadata_operation\", False)",
            "            )",
            "            and not self._check_for_name_in_memos(checkfirst, kw)",
            "        ):",
            "            self.create(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_table_drop(self, target, bind, checkfirst=False, **kw):",
            "        if (",
            "            not self.metadata",
            "            and not kw.get(\"_is_metadata_operation\", False)",
            "            and not self._check_for_name_in_memos(checkfirst, kw)",
            "        ):",
            "            self.drop(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_metadata_create(self, target, bind, checkfirst=False, **kw):",
            "        if not self._check_for_name_in_memos(checkfirst, kw):",
            "            self.create(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_metadata_drop(self, target, bind, checkfirst=False, **kw):",
            "        if not self._check_for_name_in_memos(checkfirst, kw):",
            "            self.drop(bind=bind, checkfirst=checkfirst)",
            "",
            "",
            "colspecs = {sqltypes.Interval: INTERVAL, sqltypes.Enum: ENUM}",
            "",
            "ischema_names = {",
            "    \"integer\": INTEGER,",
            "    \"bigint\": BIGINT,",
            "    \"smallint\": SMALLINT,",
            "    \"character varying\": VARCHAR,",
            "    \"character\": CHAR,",
            "    '\"char\"': sqltypes.String,",
            "    \"name\": sqltypes.String,",
            "    \"text\": TEXT,",
            "    \"numeric\": NUMERIC,",
            "    \"float\": FLOAT,",
            "    \"real\": REAL,",
            "    \"inet\": INET,",
            "    \"cidr\": CIDR,",
            "    \"uuid\": UUID,",
            "    \"bit\": BIT,",
            "    \"bit varying\": BIT,",
            "    \"macaddr\": MACADDR,",
            "    \"money\": MONEY,",
            "    \"oid\": OID,",
            "    \"regclass\": REGCLASS,",
            "    \"double precision\": DOUBLE_PRECISION,",
            "    \"timestamp\": TIMESTAMP,",
            "    \"timestamp with time zone\": TIMESTAMP,",
            "    \"timestamp without time zone\": TIMESTAMP,",
            "    \"time with time zone\": TIME,",
            "    \"time without time zone\": TIME,",
            "    \"date\": DATE,",
            "    \"time\": TIME,",
            "    \"bytea\": BYTEA,",
            "    \"boolean\": BOOLEAN,",
            "    \"interval\": INTERVAL,",
            "    \"tsvector\": TSVECTOR,",
            "}",
            "",
            "",
            "class PGCompiler(compiler.SQLCompiler):",
            "    def visit_array(self, element, **kw):",
            "        return \"ARRAY[%s]\" % self.visit_clauselist(element, **kw)",
            "",
            "    def visit_slice(self, element, **kw):",
            "        return \"%s:%s\" % (",
            "            self.process(element.start, **kw),",
            "            self.process(element.stop, **kw),",
            "        )",
            "",
            "    def visit_json_getitem_op_binary(self, binary, operator, **kw):",
            "        kw[\"eager_grouping\"] = True",
            "        return self._generate_generic_binary(binary, \" -> \", **kw)",
            "",
            "    def visit_json_path_getitem_op_binary(self, binary, operator, **kw):",
            "        kw[\"eager_grouping\"] = True",
            "        return self._generate_generic_binary(binary, \" #> \", **kw)",
            "",
            "    def visit_getitem_binary(self, binary, operator, **kw):",
            "        return \"%s[%s]\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_aggregate_order_by(self, element, **kw):",
            "        return \"%s ORDER BY %s\" % (",
            "            self.process(element.target, **kw),",
            "            self.process(element.order_by, **kw),",
            "        )",
            "",
            "    def visit_match_op_binary(self, binary, operator, **kw):",
            "        if \"postgresql_regconfig\" in binary.modifiers:",
            "            regconfig = self.render_literal_value(",
            "                binary.modifiers[\"postgresql_regconfig\"], sqltypes.STRINGTYPE",
            "            )",
            "            if regconfig:",
            "                return \"%s @@ to_tsquery(%s, %s)\" % (",
            "                    self.process(binary.left, **kw),",
            "                    regconfig,",
            "                    self.process(binary.right, **kw),",
            "                )",
            "        return \"%s @@ to_tsquery(%s)\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_ilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "",
            "        return \"%s ILIKE %s\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"%s NOT ILIKE %s\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_empty_set_expr(self, element_types):",
            "        # cast the empty set to the type we are comparing against.  if",
            "        # we are comparing against the null type, pick an arbitrary",
            "        # datatype for the empty set",
            "        return \"SELECT %s WHERE 1!=1\" % (",
            "            \", \".join(",
            "                \"CAST(NULL AS %s)\"",
            "                % self.dialect.type_compiler.process(",
            "                    INTEGER() if type_._isnull else type_",
            "                )",
            "                for type_ in element_types or [INTEGER()]",
            "            ),",
            "        )",
            "",
            "    def render_literal_value(self, value, type_):",
            "        value = super(PGCompiler, self).render_literal_value(value, type_)",
            "",
            "        if self.dialect._backslash_escapes:",
            "            value = value.replace(\"\\\\\", \"\\\\\\\\\")",
            "        return value",
            "",
            "    def visit_sequence(self, seq, **kw):",
            "        return \"nextval('%s')\" % self.preparer.format_sequence(seq)",
            "",
            "    def limit_clause(self, select, **kw):",
            "        text = \"\"",
            "        if select._limit_clause is not None:",
            "            text += \" \\n LIMIT \" + self.process(select._limit_clause, **kw)",
            "        if select._offset_clause is not None:",
            "            if select._limit_clause is None:",
            "                text += \" \\n LIMIT ALL\"",
            "            text += \" OFFSET \" + self.process(select._offset_clause, **kw)",
            "        return text",
            "",
            "    def format_from_hint_text(self, sqltext, table, hint, iscrud):",
            "        if hint.upper() != \"ONLY\":",
            "            raise exc.CompileError(\"Unrecognized hint: %r\" % hint)",
            "        return \"ONLY \" + sqltext",
            "",
            "    def get_select_precolumns(self, select, **kw):",
            "        if select._distinct is not False:",
            "            if select._distinct is True:",
            "                return \"DISTINCT \"",
            "            elif isinstance(select._distinct, (list, tuple)):",
            "                return (",
            "                    \"DISTINCT ON (\"",
            "                    + \", \".join(",
            "                        [self.process(col, **kw) for col in select._distinct]",
            "                    )",
            "                    + \") \"",
            "                )",
            "            else:",
            "                return (",
            "                    \"DISTINCT ON (\"",
            "                    + self.process(select._distinct, **kw)",
            "                    + \") \"",
            "                )",
            "        else:",
            "            return \"\"",
            "",
            "    def for_update_clause(self, select, **kw):",
            "",
            "        if select._for_update_arg.read:",
            "            if select._for_update_arg.key_share:",
            "                tmp = \" FOR KEY SHARE\"",
            "            else:",
            "                tmp = \" FOR SHARE\"",
            "        elif select._for_update_arg.key_share:",
            "            tmp = \" FOR NO KEY UPDATE\"",
            "        else:",
            "            tmp = \" FOR UPDATE\"",
            "",
            "        if select._for_update_arg.of:",
            "            tables = util.OrderedSet(",
            "                c.table if isinstance(c, expression.ColumnClause) else c",
            "                for c in select._for_update_arg.of",
            "            )",
            "            tmp += \" OF \" + \", \".join(",
            "                self.process(table, ashint=True, use_schema=False, **kw)",
            "                for table in tables",
            "            )",
            "",
            "        if select._for_update_arg.nowait:",
            "            tmp += \" NOWAIT\"",
            "        if select._for_update_arg.skip_locked:",
            "            tmp += \" SKIP LOCKED\"",
            "",
            "        return tmp",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "",
            "        columns = [",
            "            self._label_select_column(None, c, True, False, {})",
            "            for c in expression._select_iterables(returning_cols)",
            "        ]",
            "",
            "        return \"RETURNING \" + \", \".join(columns)",
            "",
            "    def visit_substring_func(self, func, **kw):",
            "        s = self.process(func.clauses.clauses[0], **kw)",
            "        start = self.process(func.clauses.clauses[1], **kw)",
            "        if len(func.clauses.clauses) > 2:",
            "            length = self.process(func.clauses.clauses[2], **kw)",
            "            return \"SUBSTRING(%s FROM %s FOR %s)\" % (s, start, length)",
            "        else:",
            "            return \"SUBSTRING(%s FROM %s)\" % (s, start)",
            "",
            "    def _on_conflict_target(self, clause, **kw):",
            "",
            "        if clause.constraint_target is not None:",
            "            target_text = \"ON CONSTRAINT %s\" % clause.constraint_target",
            "        elif clause.inferred_target_elements is not None:",
            "            target_text = \"(%s)\" % \", \".join(",
            "                (",
            "                    self.preparer.quote(c)",
            "                    if isinstance(c, util.string_types)",
            "                    else self.process(c, include_table=False, use_schema=False)",
            "                )",
            "                for c in clause.inferred_target_elements",
            "            )",
            "            if clause.inferred_target_whereclause is not None:",
            "                target_text += \" WHERE %s\" % self.process(",
            "                    clause.inferred_target_whereclause,",
            "                    include_table=False,",
            "                    use_schema=False,",
            "                )",
            "        else:",
            "            target_text = \"\"",
            "",
            "        return target_text",
            "",
            "    def visit_on_conflict_do_nothing(self, on_conflict, **kw):",
            "",
            "        target_text = self._on_conflict_target(on_conflict, **kw)",
            "",
            "        if target_text:",
            "            return \"ON CONFLICT %s DO NOTHING\" % target_text",
            "        else:",
            "            return \"ON CONFLICT DO NOTHING\"",
            "",
            "    def visit_on_conflict_do_update(self, on_conflict, **kw):",
            "",
            "        clause = on_conflict",
            "",
            "        target_text = self._on_conflict_target(on_conflict, **kw)",
            "",
            "        action_set_ops = []",
            "",
            "        set_parameters = dict(clause.update_values_to_set)",
            "        # create a list of column assignment clauses as tuples",
            "",
            "        insert_statement = self.stack[-1][\"selectable\"]",
            "        cols = insert_statement.table.c",
            "        for c in cols:",
            "            col_key = c.key",
            "            if col_key in set_parameters:",
            "                value = set_parameters.pop(col_key)",
            "                if elements._is_literal(value):",
            "                    value = elements.BindParameter(None, value, type_=c.type)",
            "",
            "                else:",
            "                    if (",
            "                        isinstance(value, elements.BindParameter)",
            "                        and value.type._isnull",
            "                    ):",
            "                        value = value._clone()",
            "                        value.type = c.type",
            "                value_text = self.process(value.self_group(), use_schema=False)",
            "",
            "                key_text = self.preparer.quote(col_key)",
            "                action_set_ops.append(\"%s = %s\" % (key_text, value_text))",
            "",
            "        # check for names that don't match columns",
            "        if set_parameters:",
            "            util.warn(",
            "                \"Additional column names not matching \"",
            "                \"any column keys in table '%s': %s\"",
            "                % (",
            "                    self.statement.table.name,",
            "                    (\", \".join(\"'%s'\" % c for c in set_parameters)),",
            "                )",
            "            )",
            "            for k, v in set_parameters.items():",
            "                key_text = (",
            "                    self.preparer.quote(k)",
            "                    if isinstance(k, util.string_types)",
            "                    else self.process(k, use_schema=False)",
            "                )",
            "                value_text = self.process(",
            "                    elements._literal_as_binds(v), use_schema=False",
            "                )",
            "                action_set_ops.append(\"%s = %s\" % (key_text, value_text))",
            "",
            "        action_text = \", \".join(action_set_ops)",
            "        if clause.update_whereclause is not None:",
            "            action_text += \" WHERE %s\" % self.process(",
            "                clause.update_whereclause, include_table=True, use_schema=False",
            "            )",
            "",
            "        return \"ON CONFLICT %s DO UPDATE SET %s\" % (target_text, action_text)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \"FROM \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "    def delete_extra_from_clause(",
            "        self, delete_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Render the DELETE .. USING clause specific to PostgreSQL.\"\"\"",
            "        return \"USING \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "",
            "class PGDDLCompiler(compiler.DDLCompiler):",
            "    def get_column_specification(self, column, **kwargs):",
            "",
            "        colspec = self.preparer.format_column(column)",
            "        impl_type = column.type.dialect_impl(self.dialect)",
            "        if isinstance(impl_type, sqltypes.TypeDecorator):",
            "            impl_type = impl_type.impl",
            "",
            "        if (",
            "            column.primary_key",
            "            and column is column.table._autoincrement_column",
            "            and (",
            "                self.dialect.supports_smallserial",
            "                or not isinstance(impl_type, sqltypes.SmallInteger)",
            "            )",
            "            and (",
            "                column.default is None",
            "                or (",
            "                    isinstance(column.default, schema.Sequence)",
            "                    and column.default.optional",
            "                )",
            "            )",
            "        ):",
            "            if isinstance(impl_type, sqltypes.BigInteger):",
            "                colspec += \" BIGSERIAL\"",
            "            elif isinstance(impl_type, sqltypes.SmallInteger):",
            "                colspec += \" SMALLSERIAL\"",
            "            else:",
            "                colspec += \" SERIAL\"",
            "        else:",
            "            colspec += \" \" + self.dialect.type_compiler.process(",
            "                column.type, type_expression=column",
            "            )",
            "            default = self.get_column_default_string(column)",
            "            if default is not None:",
            "                colspec += \" DEFAULT \" + default",
            "",
            "        if not column.nullable:",
            "            colspec += \" NOT NULL\"",
            "        return colspec",
            "",
            "    def visit_drop_table_comment(self, drop):",
            "        return \"COMMENT ON TABLE %s IS NULL\" % self.preparer.format_table(",
            "            drop.element",
            "        )",
            "",
            "    def visit_create_enum_type(self, create):",
            "        type_ = create.element",
            "",
            "        return \"CREATE TYPE %s AS ENUM (%s)\" % (",
            "            self.preparer.format_type(type_),",
            "            \", \".join(",
            "                self.sql_compiler.process(sql.literal(e), literal_binds=True)",
            "                for e in type_.enums",
            "            ),",
            "        )",
            "",
            "    def visit_drop_enum_type(self, drop):",
            "        type_ = drop.element",
            "",
            "        return \"DROP TYPE %s\" % (self.preparer.format_type(type_))",
            "",
            "    def visit_create_index(self, create):",
            "        preparer = self.preparer",
            "        index = create.element",
            "        self._verify_index_table(index)",
            "        text = \"CREATE \"",
            "        if index.unique:",
            "            text += \"UNIQUE \"",
            "        text += \"INDEX \"",
            "",
            "        if self.dialect._supports_create_index_concurrently:",
            "            concurrently = index.dialect_options[\"postgresql\"][\"concurrently\"]",
            "            if concurrently:",
            "                text += \"CONCURRENTLY \"",
            "",
            "        text += \"%s ON %s \" % (",
            "            self._prepared_index_name(index, include_schema=False),",
            "            preparer.format_table(index.table),",
            "        )",
            "",
            "        using = index.dialect_options[\"postgresql\"][\"using\"]",
            "        if using:",
            "            text += \"USING %s \" % preparer.quote(using)",
            "",
            "        ops = index.dialect_options[\"postgresql\"][\"ops\"]",
            "        text += \"(%s)\" % (",
            "            \", \".join(",
            "                [",
            "                    self.sql_compiler.process(",
            "                        expr.self_group()",
            "                        if not isinstance(expr, expression.ColumnClause)",
            "                        else expr,",
            "                        include_table=False,",
            "                        literal_binds=True,",
            "                    )",
            "                    + (",
            "                        (\" \" + ops[expr.key])",
            "                        if hasattr(expr, \"key\") and expr.key in ops",
            "                        else \"\"",
            "                    )",
            "                    for expr in index.expressions",
            "                ]",
            "            )",
            "        )",
            "",
            "        withclause = index.dialect_options[\"postgresql\"][\"with\"]",
            "",
            "        if withclause:",
            "            text += \" WITH (%s)\" % (",
            "                \", \".join(",
            "                    [",
            "                        \"%s = %s\" % storage_parameter",
            "                        for storage_parameter in withclause.items()",
            "                    ]",
            "                )",
            "            )",
            "",
            "        tablespace_name = index.dialect_options[\"postgresql\"][\"tablespace\"]",
            "",
            "        if tablespace_name:",
            "            text += \" TABLESPACE %s\" % preparer.quote(tablespace_name)",
            "",
            "        whereclause = index.dialect_options[\"postgresql\"][\"where\"]",
            "",
            "        if whereclause is not None:",
            "            where_compiled = self.sql_compiler.process(",
            "                whereclause, include_table=False, literal_binds=True",
            "            )",
            "            text += \" WHERE \" + where_compiled",
            "        return text",
            "",
            "    def visit_drop_index(self, drop):",
            "        index = drop.element",
            "",
            "        text = \"\\nDROP INDEX \"",
            "",
            "        if self.dialect._supports_drop_index_concurrently:",
            "            concurrently = index.dialect_options[\"postgresql\"][\"concurrently\"]",
            "            if concurrently:",
            "                text += \"CONCURRENTLY \"",
            "",
            "        text += self._prepared_index_name(index, include_schema=True)",
            "        return text",
            "",
            "    def visit_exclude_constraint(self, constraint, **kw):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            text += \"CONSTRAINT %s \" % self.preparer.format_constraint(",
            "                constraint",
            "            )",
            "        elements = []",
            "        for expr, name, op in constraint._render_exprs:",
            "            kw[\"include_table\"] = False",
            "            elements.append(",
            "                \"%s WITH %s\" % (self.sql_compiler.process(expr, **kw), op)",
            "            )",
            "        text += \"EXCLUDE USING %s (%s)\" % (",
            "            constraint.using,",
            "            \", \".join(elements),",
            "        )",
            "        if constraint.where is not None:",
            "            text += \" WHERE (%s)\" % self.sql_compiler.process(",
            "                constraint.where, literal_binds=True",
            "            )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def post_create_table(self, table):",
            "        table_opts = []",
            "        pg_opts = table.dialect_options[\"postgresql\"]",
            "",
            "        inherits = pg_opts.get(\"inherits\")",
            "        if inherits is not None:",
            "            if not isinstance(inherits, (list, tuple)):",
            "                inherits = (inherits,)",
            "            table_opts.append(",
            "                \"\\n INHERITS ( \"",
            "                + \", \".join(self.preparer.quote(name) for name in inherits)",
            "                + \" )\"",
            "            )",
            "",
            "        if pg_opts[\"partition_by\"]:",
            "            table_opts.append(\"\\n PARTITION BY %s\" % pg_opts[\"partition_by\"])",
            "",
            "        if pg_opts[\"with_oids\"] is True:",
            "            table_opts.append(\"\\n WITH OIDS\")",
            "        elif pg_opts[\"with_oids\"] is False:",
            "            table_opts.append(\"\\n WITHOUT OIDS\")",
            "",
            "        if pg_opts[\"on_commit\"]:",
            "            on_commit_options = pg_opts[\"on_commit\"].replace(\"_\", \" \").upper()",
            "            table_opts.append(\"\\n ON COMMIT %s\" % on_commit_options)",
            "",
            "        if pg_opts[\"tablespace\"]:",
            "            tablespace_name = pg_opts[\"tablespace\"]",
            "            table_opts.append(",
            "                \"\\n TABLESPACE %s\" % self.preparer.quote(tablespace_name)",
            "            )",
            "",
            "        return \"\".join(table_opts)",
            "",
            "",
            "class PGTypeCompiler(compiler.GenericTypeCompiler):",
            "    def visit_TSVECTOR(self, type_, **kw):",
            "        return \"TSVECTOR\"",
            "",
            "    def visit_INET(self, type_, **kw):",
            "        return \"INET\"",
            "",
            "    def visit_CIDR(self, type_, **kw):",
            "        return \"CIDR\"",
            "",
            "    def visit_MACADDR(self, type_, **kw):",
            "        return \"MACADDR\"",
            "",
            "    def visit_MONEY(self, type_, **kw):",
            "        return \"MONEY\"",
            "",
            "    def visit_OID(self, type_, **kw):",
            "        return \"OID\"",
            "",
            "    def visit_REGCLASS(self, type_, **kw):",
            "        return \"REGCLASS\"",
            "",
            "    def visit_FLOAT(self, type_, **kw):",
            "        if not type_.precision:",
            "            return \"FLOAT\"",
            "        else:",
            "            return \"FLOAT(%(precision)s)\" % {\"precision\": type_.precision}",
            "",
            "    def visit_DOUBLE_PRECISION(self, type_, **kw):",
            "        return \"DOUBLE PRECISION\"",
            "",
            "    def visit_BIGINT(self, type_, **kw):",
            "        return \"BIGINT\"",
            "",
            "    def visit_HSTORE(self, type_, **kw):",
            "        return \"HSTORE\"",
            "",
            "    def visit_JSON(self, type_, **kw):",
            "        return \"JSON\"",
            "",
            "    def visit_JSONB(self, type_, **kw):",
            "        return \"JSONB\"",
            "",
            "    def visit_INT4RANGE(self, type_, **kw):",
            "        return \"INT4RANGE\"",
            "",
            "    def visit_INT8RANGE(self, type_, **kw):",
            "        return \"INT8RANGE\"",
            "",
            "    def visit_NUMRANGE(self, type_, **kw):",
            "        return \"NUMRANGE\"",
            "",
            "    def visit_DATERANGE(self, type_, **kw):",
            "        return \"DATERANGE\"",
            "",
            "    def visit_TSRANGE(self, type_, **kw):",
            "        return \"TSRANGE\"",
            "",
            "    def visit_TSTZRANGE(self, type_, **kw):",
            "        return \"TSTZRANGE\"",
            "",
            "    def visit_datetime(self, type_, **kw):",
            "        return self.visit_TIMESTAMP(type_, **kw)",
            "",
            "    def visit_enum(self, type_, **kw):",
            "        if not type_.native_enum or not self.dialect.supports_native_enum:",
            "            return super(PGTypeCompiler, self).visit_enum(type_, **kw)",
            "        else:",
            "            return self.visit_ENUM(type_, **kw)",
            "",
            "    def visit_ENUM(self, type_, **kw):",
            "        return self.dialect.identifier_preparer.format_type(type_)",
            "",
            "    def visit_TIMESTAMP(self, type_, **kw):",
            "        return \"TIMESTAMP%s %s\" % (",
            "            \"(%d)\" % type_.precision",
            "            if getattr(type_, \"precision\", None) is not None",
            "            else \"\",",
            "            (type_.timezone and \"WITH\" or \"WITHOUT\") + \" TIME ZONE\",",
            "        )",
            "",
            "    def visit_TIME(self, type_, **kw):",
            "        return \"TIME%s %s\" % (",
            "            \"(%d)\" % type_.precision",
            "            if getattr(type_, \"precision\", None) is not None",
            "            else \"\",",
            "            (type_.timezone and \"WITH\" or \"WITHOUT\") + \" TIME ZONE\",",
            "        )",
            "",
            "    def visit_INTERVAL(self, type_, **kw):",
            "        text = \"INTERVAL\"",
            "        if type_.fields is not None:",
            "            text += \" \" + type_.fields",
            "        if type_.precision is not None:",
            "            text += \" (%d)\" % type_.precision",
            "        return text",
            "",
            "    def visit_BIT(self, type_, **kw):",
            "        if type_.varying:",
            "            compiled = \"BIT VARYING\"",
            "            if type_.length is not None:",
            "                compiled += \"(%d)\" % type_.length",
            "        else:",
            "            compiled = \"BIT(%d)\" % type_.length",
            "        return compiled",
            "",
            "    def visit_UUID(self, type_, **kw):",
            "        return \"UUID\"",
            "",
            "    def visit_large_binary(self, type_, **kw):",
            "        return self.visit_BYTEA(type_, **kw)",
            "",
            "    def visit_BYTEA(self, type_, **kw):",
            "        return \"BYTEA\"",
            "",
            "    def visit_ARRAY(self, type_, **kw):",
            "",
            "        # TODO: pass **kw?",
            "        inner = self.process(type_.item_type)",
            "        return re.sub(",
            "            r\"((?: COLLATE.*)?)$\",",
            "            (",
            "                r\"%s\\1\"",
            "                % (",
            "                    \"[]\"",
            "                    * (type_.dimensions if type_.dimensions is not None else 1)",
            "                )",
            "            ),",
            "            inner,",
            "            count=1,",
            "        )",
            "",
            "",
            "class PGIdentifierPreparer(compiler.IdentifierPreparer):",
            "",
            "    reserved_words = RESERVED_WORDS",
            "",
            "    def _unquote_identifier(self, value):",
            "        if value[0] == self.initial_quote:",
            "            value = value[1:-1].replace(",
            "                self.escape_to_quote, self.escape_quote",
            "            )",
            "        return value",
            "",
            "    def format_type(self, type_, use_schema=True):",
            "        if not type_.name:",
            "            raise exc.CompileError(\"PostgreSQL ENUM type requires a name.\")",
            "",
            "        name = self.quote(type_.name)",
            "        effective_schema = self.schema_for_object(type_)",
            "",
            "        if (",
            "            not self.omit_schema",
            "            and use_schema",
            "            and effective_schema is not None",
            "        ):",
            "            name = self.quote_schema(effective_schema) + \".\" + name",
            "        return name",
            "",
            "",
            "class PGInspector(reflection.Inspector):",
            "    def __init__(self, conn):",
            "        reflection.Inspector.__init__(self, conn)",
            "",
            "    def get_table_oid(self, table_name, schema=None):",
            "        \"\"\"Return the OID for the given table name.\"\"\"",
            "",
            "        return self.dialect.get_table_oid(",
            "            self.bind, table_name, schema, info_cache=self.info_cache",
            "        )",
            "",
            "    def get_enums(self, schema=None):",
            "        \"\"\"Return a list of ENUM objects.",
            "",
            "        Each member is a dictionary containing these fields:",
            "",
            "            * name - name of the enum",
            "            * schema - the schema name for the enum.",
            "            * visible - boolean, whether or not this enum is visible",
            "              in the default search path.",
            "            * labels - a list of string labels that apply to the enum.",
            "",
            "        :param schema: schema name.  If None, the default schema",
            "         (typically 'public') is used.  May also be set to '*' to",
            "         indicate load enums for all schemas.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        \"\"\"",
            "        schema = schema or self.default_schema_name",
            "        return self.dialect._load_enums(self.bind, schema)",
            "",
            "    def get_foreign_table_names(self, schema=None):",
            "        \"\"\"Return a list of FOREIGN TABLE names.",
            "",
            "        Behavior is similar to that of :meth:`.Inspector.get_table_names`,",
            "        except that the list is limited to those tables that report a",
            "        ``relkind`` value of ``f``.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        \"\"\"",
            "        schema = schema or self.default_schema_name",
            "        return self.dialect._get_foreign_table_names(self.bind, schema)",
            "",
            "    def get_view_names(self, schema=None, include=(\"plain\", \"materialized\")):",
            "        \"\"\"Return all view names in `schema`.",
            "",
            "        :param schema: Optional, retrieve names from a non-default schema.",
            "         For special quoting, use :class:`.quoted_name`.",
            "",
            "        :param include: specify which types of views to return.  Passed",
            "         as a string value (for a single type) or a tuple (for any number",
            "         of types).  Defaults to ``('plain', 'materialized')``.",
            "",
            "         .. versionadded:: 1.1",
            "",
            "        \"\"\"",
            "",
            "        return self.dialect.get_view_names(",
            "            self.bind, schema, info_cache=self.info_cache, include=include",
            "        )",
            "",
            "",
            "class CreateEnumType(schema._CreateDropBase):",
            "    __visit_name__ = \"create_enum_type\"",
            "",
            "",
            "class DropEnumType(schema._CreateDropBase):",
            "    __visit_name__ = \"drop_enum_type\"",
            "",
            "",
            "class PGExecutionContext(default.DefaultExecutionContext):",
            "    def fire_sequence(self, seq, type_):",
            "        return self._execute_scalar(",
            "            (",
            "                \"select nextval('%s')\"",
            "                % self.dialect.identifier_preparer.format_sequence(seq)",
            "            ),",
            "            type_,",
            "        )",
            "",
            "    def get_insert_default(self, column):",
            "        if column.primary_key and column is column.table._autoincrement_column:",
            "            if column.server_default and column.server_default.has_argument:",
            "",
            "                # pre-execute passive defaults on primary key columns",
            "                return self._execute_scalar(",
            "                    \"select %s\" % column.server_default.arg, column.type",
            "                )",
            "",
            "            elif column.default is None or (",
            "                column.default.is_sequence and column.default.optional",
            "            ):",
            "",
            "                # execute the sequence associated with a SERIAL primary",
            "                # key column. for non-primary-key SERIAL, the ID just",
            "                # generates server side.",
            "",
            "                try:",
            "                    seq_name = column._postgresql_seq_name",
            "                except AttributeError:",
            "                    tab = column.table.name",
            "                    col = column.name",
            "                    tab = tab[0 : 29 + max(0, (29 - len(col)))]",
            "                    col = col[0 : 29 + max(0, (29 - len(tab)))]",
            "                    name = \"%s_%s_seq\" % (tab, col)",
            "                    column._postgresql_seq_name = seq_name = name",
            "",
            "                if column.table is not None:",
            "                    effective_schema = self.connection.schema_for_object(",
            "                        column.table",
            "                    )",
            "                else:",
            "                    effective_schema = None",
            "",
            "                if effective_schema is not None:",
            "                    exc = 'select nextval(\\'\"%s\".\"%s\"\\')' % (",
            "                        effective_schema,",
            "                        seq_name,",
            "                    )",
            "                else:",
            "                    exc = \"select nextval('\\\"%s\\\"')\" % (seq_name,)",
            "",
            "                return self._execute_scalar(exc, column.type)",
            "",
            "        return super(PGExecutionContext, self).get_insert_default(column)",
            "",
            "    def should_autocommit_text(self, statement):",
            "        return AUTOCOMMIT_REGEXP.match(statement)",
            "",
            "",
            "class PGDialect(default.DefaultDialect):",
            "    name = \"postgresql\"",
            "    supports_alter = True",
            "    max_identifier_length = 63",
            "    supports_sane_rowcount = True",
            "",
            "    supports_native_enum = True",
            "    supports_native_boolean = True",
            "    supports_smallserial = True",
            "",
            "    supports_sequences = True",
            "    sequences_optional = True",
            "    preexecute_autoincrement_sequences = True",
            "    postfetch_lastrowid = False",
            "",
            "    supports_comments = True",
            "    supports_default_values = True",
            "    supports_empty_insert = False",
            "    supports_multivalues_insert = True",
            "    default_paramstyle = \"pyformat\"",
            "    ischema_names = ischema_names",
            "    colspecs = colspecs",
            "",
            "    statement_compiler = PGCompiler",
            "    ddl_compiler = PGDDLCompiler",
            "    type_compiler = PGTypeCompiler",
            "    preparer = PGIdentifierPreparer",
            "    execution_ctx_cls = PGExecutionContext",
            "    inspector = PGInspector",
            "    isolation_level = None",
            "",
            "    construct_arguments = [",
            "        (",
            "            schema.Index,",
            "            {",
            "                \"using\": False,",
            "                \"where\": None,",
            "                \"ops\": {},",
            "                \"concurrently\": False,",
            "                \"with\": {},",
            "                \"tablespace\": None,",
            "            },",
            "        ),",
            "        (",
            "            schema.Table,",
            "            {",
            "                \"ignore_search_path\": False,",
            "                \"tablespace\": None,",
            "                \"partition_by\": None,",
            "                \"with_oids\": None,",
            "                \"on_commit\": None,",
            "                \"inherits\": None,",
            "            },",
            "        ),",
            "    ]",
            "",
            "    reflection_options = (\"postgresql_ignore_search_path\",)",
            "",
            "    _backslash_escapes = True",
            "    _supports_create_index_concurrently = True",
            "    _supports_drop_index_concurrently = True",
            "",
            "    def __init__(",
            "        self,",
            "        isolation_level=None,",
            "        json_serializer=None,",
            "        json_deserializer=None,",
            "        **kwargs",
            "    ):",
            "        default.DefaultDialect.__init__(self, **kwargs)",
            "        self.isolation_level = isolation_level",
            "        self._json_deserializer = json_deserializer",
            "        self._json_serializer = json_serializer",
            "",
            "    def initialize(self, connection):",
            "        super(PGDialect, self).initialize(connection)",
            "        self.implicit_returning = self.server_version_info > (",
            "            8,",
            "            2,",
            "        ) and self.__dict__.get(\"implicit_returning\", True)",
            "        self.supports_native_enum = self.server_version_info >= (8, 3)",
            "        if not self.supports_native_enum:",
            "            self.colspecs = self.colspecs.copy()",
            "            # pop base Enum type",
            "            self.colspecs.pop(sqltypes.Enum, None)",
            "            # psycopg2, others may have placed ENUM here as well",
            "            self.colspecs.pop(ENUM, None)",
            "",
            "        # http://www.postgresql.org/docs/9.3/static/release-9-2.html#AEN116689",
            "        self.supports_smallserial = self.server_version_info >= (9, 2)",
            "",
            "        self._backslash_escapes = (",
            "            self.server_version_info < (8, 2)",
            "            or connection.scalar(\"show standard_conforming_strings\") == \"off\"",
            "        )",
            "",
            "        self._supports_create_index_concurrently = (",
            "            self.server_version_info >= (8, 2)",
            "        )",
            "        self._supports_drop_index_concurrently = self.server_version_info >= (",
            "            9,",
            "            2,",
            "        )",
            "",
            "    def on_connect(self):",
            "        if self.isolation_level is not None:",
            "",
            "            def connect(conn):",
            "                self.set_isolation_level(conn, self.isolation_level)",
            "",
            "            return connect",
            "        else:",
            "            return None",
            "",
            "    _isolation_lookup = set(",
            "        [",
            "            \"SERIALIZABLE\",",
            "            \"READ UNCOMMITTED\",",
            "            \"READ COMMITTED\",",
            "            \"REPEATABLE READ\",",
            "        ]",
            "    )",
            "",
            "    def set_isolation_level(self, connection, level):",
            "        level = level.replace(\"_\", \" \")",
            "        if level not in self._isolation_lookup:",
            "            raise exc.ArgumentError(",
            "                \"Invalid value '%s' for isolation_level. \"",
            "                \"Valid isolation levels for %s are %s\"",
            "                % (level, self.name, \", \".join(self._isolation_lookup))",
            "            )",
            "        cursor = connection.cursor()",
            "        cursor.execute(",
            "            \"SET SESSION CHARACTERISTICS AS TRANSACTION \"",
            "            \"ISOLATION LEVEL %s\" % level",
            "        )",
            "        cursor.execute(\"COMMIT\")",
            "        cursor.close()",
            "",
            "    def get_isolation_level(self, connection):",
            "        cursor = connection.cursor()",
            "        cursor.execute(\"show transaction isolation level\")",
            "        val = cursor.fetchone()[0]",
            "        cursor.close()",
            "        return val.upper()",
            "",
            "    def do_begin_twophase(self, connection, xid):",
            "        self.do_begin(connection.connection)",
            "",
            "    def do_prepare_twophase(self, connection, xid):",
            "        connection.execute(\"PREPARE TRANSACTION '%s'\" % xid)",
            "",
            "    def do_rollback_twophase(",
            "        self, connection, xid, is_prepared=True, recover=False",
            "    ):",
            "        if is_prepared:",
            "            if recover:",
            "                # FIXME: ugly hack to get out of transaction",
            "                # context when committing recoverable transactions",
            "                # Must find out a way how to make the dbapi not",
            "                # open a transaction.",
            "                connection.execute(\"ROLLBACK\")",
            "            connection.execute(\"ROLLBACK PREPARED '%s'\" % xid)",
            "            connection.execute(\"BEGIN\")",
            "            self.do_rollback(connection.connection)",
            "        else:",
            "            self.do_rollback(connection.connection)",
            "",
            "    def do_commit_twophase(",
            "        self, connection, xid, is_prepared=True, recover=False",
            "    ):",
            "        if is_prepared:",
            "            if recover:",
            "                connection.execute(\"ROLLBACK\")",
            "            connection.execute(\"COMMIT PREPARED '%s'\" % xid)",
            "            connection.execute(\"BEGIN\")",
            "            self.do_rollback(connection.connection)",
            "        else:",
            "            self.do_commit(connection.connection)",
            "",
            "    def do_recover_twophase(self, connection):",
            "        resultset = connection.execute(",
            "            sql.text(\"SELECT gid FROM pg_prepared_xacts\")",
            "        )",
            "        return [row[0] for row in resultset]",
            "",
            "    def _get_default_schema_name(self, connection):",
            "        return connection.scalar(\"select current_schema()\")",
            "",
            "    def has_schema(self, connection, schema):",
            "        query = (",
            "            \"select nspname from pg_namespace \" \"where lower(nspname)=:schema\"",
            "        )",
            "        cursor = connection.execute(",
            "            sql.text(query).bindparams(",
            "                sql.bindparam(",
            "                    \"schema\",",
            "                    util.text_type(schema.lower()),",
            "                    type_=sqltypes.Unicode,",
            "                )",
            "            )",
            "        )",
            "",
            "        return bool(cursor.first())",
            "",
            "    def has_table(self, connection, table_name, schema=None):",
            "        # seems like case gets folded in pg_class...",
            "        if schema is None:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"select relname from pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where \"",
            "                    \"pg_catalog.pg_table_is_visible(c.oid) \"",
            "                    \"and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(table_name),",
            "                        type_=sqltypes.Unicode,",
            "                    )",
            "                )",
            "            )",
            "        else:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"select relname from pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where n.nspname=:schema and \"",
            "                    \"relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(table_name),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                    sql.bindparam(",
            "                        \"schema\",",
            "                        util.text_type(schema),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                )",
            "            )",
            "        return bool(cursor.first())",
            "",
            "    def has_sequence(self, connection, sequence_name, schema=None):",
            "        if schema is None:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"SELECT relname FROM pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where relkind='S' and \"",
            "                    \"n.nspname=current_schema() \"",
            "                    \"and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(sequence_name),",
            "                        type_=sqltypes.Unicode,",
            "                    )",
            "                )",
            "            )",
            "        else:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"SELECT relname FROM pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where relkind='S' and \"",
            "                    \"n.nspname=:schema and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(sequence_name),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                    sql.bindparam(",
            "                        \"schema\",",
            "                        util.text_type(schema),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                )",
            "            )",
            "",
            "        return bool(cursor.first())",
            "",
            "    def has_type(self, connection, type_name, schema=None):",
            "        if schema is not None:",
            "            query = \"\"\"",
            "            SELECT EXISTS (",
            "                SELECT * FROM pg_catalog.pg_type t, pg_catalog.pg_namespace n",
            "                WHERE t.typnamespace = n.oid",
            "                AND t.typname = :typname",
            "                AND n.nspname = :nspname",
            "                )",
            "                \"\"\"",
            "            query = sql.text(query)",
            "        else:",
            "            query = \"\"\"",
            "            SELECT EXISTS (",
            "                SELECT * FROM pg_catalog.pg_type t",
            "                WHERE t.typname = :typname",
            "                AND pg_type_is_visible(t.oid)",
            "                )",
            "                \"\"\"",
            "            query = sql.text(query)",
            "        query = query.bindparams(",
            "            sql.bindparam(",
            "                \"typname\", util.text_type(type_name), type_=sqltypes.Unicode",
            "            )",
            "        )",
            "        if schema is not None:",
            "            query = query.bindparams(",
            "                sql.bindparam(",
            "                    \"nspname\", util.text_type(schema), type_=sqltypes.Unicode",
            "                )",
            "            )",
            "        cursor = connection.execute(query)",
            "        return bool(cursor.scalar())",
            "",
            "    def _get_server_version_info(self, connection):",
            "        v = connection.execute(\"select version()\").scalar()",
            "        m = re.match(",
            "            r\".*(?:PostgreSQL|EnterpriseDB) \"",
            "            r\"(\\d+)\\.?(\\d+)?(?:\\.(\\d+))?(?:\\.\\d+)?(?:devel|beta)?\",",
            "            v,",
            "        )",
            "        if not m:",
            "            raise AssertionError(",
            "                \"Could not determine version from string '%s'\" % v",
            "            )",
            "        return tuple([int(x) for x in m.group(1, 2, 3) if x is not None])",
            "",
            "    @reflection.cache",
            "    def get_table_oid(self, connection, table_name, schema=None, **kw):",
            "        \"\"\"Fetch the oid for schema.table_name.",
            "",
            "        Several reflection methods require the table oid.  The idea for using",
            "        this method is that it can be fetched one time and cached for",
            "        subsequent calls.",
            "",
            "        \"\"\"",
            "        table_oid = None",
            "        if schema is not None:",
            "            schema_where_clause = \"n.nspname = :schema\"",
            "        else:",
            "            schema_where_clause = \"pg_catalog.pg_table_is_visible(c.oid)\"",
            "        query = (",
            "            \"\"\"",
            "            SELECT c.oid",
            "            FROM pg_catalog.pg_class c",
            "            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace",
            "            WHERE (%s)",
            "            AND c.relname = :table_name AND c.relkind in",
            "            ('r', 'v', 'm', 'f', 'p')",
            "        \"\"\"",
            "            % schema_where_clause",
            "        )",
            "        # Since we're binding to unicode, table_name and schema_name must be",
            "        # unicode.",
            "        table_name = util.text_type(table_name)",
            "        if schema is not None:",
            "            schema = util.text_type(schema)",
            "        s = sql.text(query).bindparams(table_name=sqltypes.Unicode)",
            "        s = s.columns(oid=sqltypes.Integer)",
            "        if schema:",
            "            s = s.bindparams(sql.bindparam(\"schema\", type_=sqltypes.Unicode))",
            "        c = connection.execute(s, table_name=table_name, schema=schema)",
            "        table_oid = c.scalar()",
            "        if table_oid is None:",
            "            raise exc.NoSuchTableError(table_name)",
            "        return table_oid",
            "",
            "    @reflection.cache",
            "    def get_schema_names(self, connection, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT nspname FROM pg_namespace \"",
            "                \"WHERE nspname NOT LIKE 'pg_%' \"",
            "                \"ORDER BY nspname\"",
            "            ).columns(nspname=sqltypes.Unicode)",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_table_names(self, connection, schema=None, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind in ('r', 'p')\"",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def _get_foreign_table_names(self, connection, schema=None, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind = 'f'\"",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_view_names(",
            "        self, connection, schema=None, include=(\"plain\", \"materialized\"), **kw",
            "    ):",
            "",
            "        include_kind = {\"plain\": \"v\", \"materialized\": \"m\"}",
            "        try:",
            "            kinds = [include_kind[i] for i in util.to_list(include)]",
            "        except KeyError:",
            "            raise ValueError(",
            "                \"include %r unknown, needs to be a sequence containing \"",
            "                \"one or both of 'plain' and 'materialized'\" % (include,)",
            "            )",
            "        if not kinds:",
            "            raise ValueError(",
            "                \"empty include, needs to be a sequence containing \"",
            "                \"one or both of 'plain' and 'materialized'\"",
            "            )",
            "",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind IN (%s)\"",
            "                % (\", \".join(\"'%s'\" % elem for elem in kinds))",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_view_definition(self, connection, view_name, schema=None, **kw):",
            "        view_def = connection.scalar(",
            "            sql.text(",
            "                \"SELECT pg_get_viewdef(c.oid) view_def FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relname = :view_name \"",
            "                \"AND c.relkind IN ('v', 'm')\"",
            "            ).columns(view_def=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "            view_name=view_name,",
            "        )",
            "        return view_def",
            "",
            "    @reflection.cache",
            "    def get_columns(self, connection, table_name, schema=None, **kw):",
            "",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "        SQL_COLS = \"\"\"",
            "            SELECT a.attname,",
            "              pg_catalog.format_type(a.atttypid, a.atttypmod),",
            "              (SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)",
            "                FROM pg_catalog.pg_attrdef d",
            "               WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum",
            "               AND a.atthasdef)",
            "              AS DEFAULT,",
            "              a.attnotnull, a.attnum, a.attrelid as table_oid,",
            "              pgd.description as comment",
            "            FROM pg_catalog.pg_attribute a",
            "            LEFT JOIN pg_catalog.pg_description pgd ON (",
            "                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)",
            "            WHERE a.attrelid = :table_oid",
            "            AND a.attnum > 0 AND NOT a.attisdropped",
            "            ORDER BY a.attnum",
            "        \"\"\"",
            "        s = (",
            "            sql.text(SQL_COLS)",
            "            .bindparams(sql.bindparam(\"table_oid\", type_=sqltypes.Integer))",
            "            .columns(attname=sqltypes.Unicode, default=sqltypes.Unicode)",
            "        )",
            "        c = connection.execute(s, table_oid=table_oid)",
            "        rows = c.fetchall()",
            "",
            "        # dictionary with (name, ) if default search path or (schema, name)",
            "        # as keys",
            "        domains = self._load_domains(connection)",
            "",
            "        # dictionary with (name, ) if default search path or (schema, name)",
            "        # as keys",
            "        enums = dict(",
            "            ((rec[\"name\"],), rec)",
            "            if rec[\"visible\"]",
            "            else ((rec[\"schema\"], rec[\"name\"]), rec)",
            "            for rec in self._load_enums(connection, schema=\"*\")",
            "        )",
            "",
            "        # format columns",
            "        columns = []",
            "",
            "        for (",
            "            name,",
            "            format_type,",
            "            default_,",
            "            notnull,",
            "            attnum,",
            "            table_oid,",
            "            comment,",
            "        ) in rows:",
            "            column_info = self._get_column_info(",
            "                name,",
            "                format_type,",
            "                default_,",
            "                notnull,",
            "                domains,",
            "                enums,",
            "                schema,",
            "                comment,",
            "            )",
            "            columns.append(column_info)",
            "        return columns",
            "",
            "    def _get_column_info(",
            "        self,",
            "        name,",
            "        format_type,",
            "        default,",
            "        notnull,",
            "        domains,",
            "        enums,",
            "        schema,",
            "        comment,",
            "    ):",
            "        def _handle_array_type(attype):",
            "            return (",
            "                # strip '[]' from integer[], etc.",
            "                re.sub(r\"\\[\\]$\", \"\", attype),",
            "                attype.endswith(\"[]\"),",
            "            )",
            "",
            "        # strip (*) from character varying(5), timestamp(5)",
            "        # with time zone, geometry(POLYGON), etc.",
            "        attype = re.sub(r\"\\(.*\\)\", \"\", format_type)",
            "",
            "        # strip '[]' from integer[], etc. and check if an array",
            "        attype, is_array = _handle_array_type(attype)",
            "",
            "        # strip quotes from case sensitive enum or domain names",
            "        enum_or_domain_key = tuple(util.quoted_token_parser(attype))",
            "",
            "        nullable = not notnull",
            "",
            "        charlen = re.search(r\"\\(([\\d,]+)\\)\", format_type)",
            "        if charlen:",
            "            charlen = charlen.group(1)",
            "        args = re.search(r\"\\((.*)\\)\", format_type)",
            "        if args and args.group(1):",
            "            args = tuple(re.split(r\"\\s*,\\s*\", args.group(1)))",
            "        else:",
            "            args = ()",
            "        kwargs = {}",
            "",
            "        if attype == \"numeric\":",
            "            if charlen:",
            "                prec, scale = charlen.split(\",\")",
            "                args = (int(prec), int(scale))",
            "            else:",
            "                args = ()",
            "        elif attype == \"double precision\":",
            "            args = (53,)",
            "        elif attype == \"integer\":",
            "            args = ()",
            "        elif attype in (\"timestamp with time zone\", \"time with time zone\"):",
            "            kwargs[\"timezone\"] = True",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            args = ()",
            "        elif attype in (",
            "            \"timestamp without time zone\",",
            "            \"time without time zone\",",
            "            \"time\",",
            "        ):",
            "            kwargs[\"timezone\"] = False",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            args = ()",
            "        elif attype == \"bit varying\":",
            "            kwargs[\"varying\"] = True",
            "            if charlen:",
            "                args = (int(charlen),)",
            "            else:",
            "                args = ()",
            "        elif attype.startswith(\"interval\"):",
            "            field_match = re.match(r\"interval (.+)\", attype, re.I)",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            if field_match:",
            "                kwargs[\"fields\"] = field_match.group(1)",
            "            attype = \"interval\"",
            "            args = ()",
            "        elif charlen:",
            "            args = (int(charlen),)",
            "",
            "        while True:",
            "            # looping here to suit nested domains",
            "            if attype in self.ischema_names:",
            "                coltype = self.ischema_names[attype]",
            "                break",
            "            elif enum_or_domain_key in enums:",
            "                enum = enums[enum_or_domain_key]",
            "                coltype = ENUM",
            "                kwargs[\"name\"] = enum[\"name\"]",
            "                if not enum[\"visible\"]:",
            "                    kwargs[\"schema\"] = enum[\"schema\"]",
            "                args = tuple(enum[\"labels\"])",
            "                break",
            "            elif enum_or_domain_key in domains:",
            "                domain = domains[enum_or_domain_key]",
            "                attype = domain[\"attype\"]",
            "                attype, is_array = _handle_array_type(attype)",
            "                # strip quotes from case sensitive enum or domain names",
            "                enum_or_domain_key = tuple(util.quoted_token_parser(attype))",
            "                # A table can't override whether the domain is nullable.",
            "                nullable = domain[\"nullable\"]",
            "                if domain[\"default\"] and not default:",
            "                    # It can, however, override the default",
            "                    # value, but can't set it to null.",
            "                    default = domain[\"default\"]",
            "                continue",
            "            else:",
            "                coltype = None",
            "                break",
            "",
            "        if coltype:",
            "            coltype = coltype(*args, **kwargs)",
            "            if is_array:",
            "                coltype = self.ischema_names[\"_array\"](coltype)",
            "        else:",
            "            util.warn(",
            "                \"Did not recognize type '%s' of column '%s'\" % (attype, name)",
            "            )",
            "            coltype = sqltypes.NULLTYPE",
            "        # adjust the default value",
            "        autoincrement = False",
            "        if default is not None:",
            "            match = re.search(r\"\"\"(nextval\\(')([^']+)('.*$)\"\"\", default)",
            "            if match is not None:",
            "                if issubclass(coltype._type_affinity, sqltypes.Integer):",
            "                    autoincrement = True",
            "                # the default is related to a Sequence",
            "                sch = schema",
            "                if \".\" not in match.group(2) and sch is not None:",
            "                    # unconditionally quote the schema name.  this could",
            "                    # later be enhanced to obey quoting rules /",
            "                    # \"quote schema\"",
            "                    default = (",
            "                        match.group(1)",
            "                        + ('\"%s\"' % sch)",
            "                        + \".\"",
            "                        + match.group(2)",
            "                        + match.group(3)",
            "                    )",
            "",
            "        column_info = dict(",
            "            name=name,",
            "            type=coltype,",
            "            nullable=nullable,",
            "            default=default,",
            "            autoincrement=autoincrement,",
            "            comment=comment,",
            "        )",
            "        return column_info",
            "",
            "    @reflection.cache",
            "    def get_pk_constraint(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        if self.server_version_info < (8, 4):",
            "            PK_SQL = \"\"\"",
            "                SELECT a.attname",
            "                FROM",
            "                    pg_class t",
            "                    join pg_index ix on t.oid = ix.indrelid",
            "                    join pg_attribute a",
            "                        on t.oid=a.attrelid AND %s",
            "                 WHERE",
            "                  t.oid = :table_oid and ix.indisprimary = 't'",
            "                ORDER BY a.attnum",
            "            \"\"\" % self._pg_index_any(",
            "                \"a.attnum\", \"ix.indkey\"",
            "            )",
            "",
            "        else:",
            "            # unnest() and generate_subscripts() both introduced in",
            "            # version 8.4",
            "            PK_SQL = \"\"\"",
            "                SELECT a.attname",
            "                FROM pg_attribute a JOIN (",
            "                    SELECT unnest(ix.indkey) attnum,",
            "                           generate_subscripts(ix.indkey, 1) ord",
            "                    FROM pg_index ix",
            "                    WHERE ix.indrelid = :table_oid AND ix.indisprimary",
            "                    ) k ON a.attnum=k.attnum",
            "                WHERE a.attrelid = :table_oid",
            "                ORDER BY k.ord",
            "            \"\"\"",
            "        t = sql.text(PK_SQL).columns(attname=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "        cols = [r[0] for r in c.fetchall()]",
            "",
            "        PK_CONS_SQL = \"\"\"",
            "        SELECT conname",
            "           FROM  pg_catalog.pg_constraint r",
            "           WHERE r.conrelid = :table_oid AND r.contype = 'p'",
            "           ORDER BY 1",
            "        \"\"\"",
            "        t = sql.text(PK_CONS_SQL).columns(conname=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "        name = c.scalar()",
            "",
            "        return {\"constrained_columns\": cols, \"name\": name}",
            "",
            "    @reflection.cache",
            "    def get_foreign_keys(",
            "        self,",
            "        connection,",
            "        table_name,",
            "        schema=None,",
            "        postgresql_ignore_search_path=False,",
            "        **kw",
            "    ):",
            "        preparer = self.identifier_preparer",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        FK_SQL = \"\"\"",
            "          SELECT r.conname,",
            "                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,",
            "                n.nspname as conschema",
            "          FROM  pg_catalog.pg_constraint r,",
            "                pg_namespace n,",
            "                pg_class c",
            "",
            "          WHERE r.conrelid = :table AND",
            "                r.contype = 'f' AND",
            "                c.oid = confrelid AND",
            "                n.oid = c.relnamespace",
            "          ORDER BY 1",
            "        \"\"\"",
            "        # http://www.postgresql.org/docs/9.0/static/sql-createtable.html",
            "        FK_REGEX = re.compile(",
            "            r\"FOREIGN KEY \\((.*?)\\) REFERENCES (?:(.*?)\\.)?(.*?)\\((.*?)\\)\"",
            "            r\"[\\s]?(MATCH (FULL|PARTIAL|SIMPLE)+)?\"",
            "            r\"[\\s]?(ON UPDATE \"",
            "            r\"(CASCADE|RESTRICT|NO ACTION|SET NULL|SET DEFAULT)+)?\"",
            "            r\"[\\s]?(ON DELETE \"",
            "            r\"(CASCADE|RESTRICT|NO ACTION|SET NULL|SET DEFAULT)+)?\"",
            "            r\"[\\s]?(DEFERRABLE|NOT DEFERRABLE)?\"",
            "            r\"[\\s]?(INITIALLY (DEFERRED|IMMEDIATE)+)?\"",
            "        )",
            "",
            "        t = sql.text(FK_SQL).columns(",
            "            conname=sqltypes.Unicode, condef=sqltypes.Unicode",
            "        )",
            "        c = connection.execute(t, table=table_oid)",
            "        fkeys = []",
            "        for conname, condef, conschema in c.fetchall():",
            "            m = re.search(FK_REGEX, condef).groups()",
            "",
            "            (",
            "                constrained_columns,",
            "                referred_schema,",
            "                referred_table,",
            "                referred_columns,",
            "                _,",
            "                match,",
            "                _,",
            "                onupdate,",
            "                _,",
            "                ondelete,",
            "                deferrable,",
            "                _,",
            "                initially,",
            "            ) = m",
            "",
            "            if deferrable is not None:",
            "                deferrable = True if deferrable == \"DEFERRABLE\" else False",
            "            constrained_columns = [",
            "                preparer._unquote_identifier(x)",
            "                for x in re.split(r\"\\s*,\\s*\", constrained_columns)",
            "            ]",
            "",
            "            if postgresql_ignore_search_path:",
            "                # when ignoring search path, we use the actual schema",
            "                # provided it isn't the \"default\" schema",
            "                if conschema != self.default_schema_name:",
            "                    referred_schema = conschema",
            "                else:",
            "                    referred_schema = schema",
            "            elif referred_schema:",
            "                # referred_schema is the schema that we regexp'ed from",
            "                # pg_get_constraintdef().  If the schema is in the search",
            "                # path, pg_get_constraintdef() will give us None.",
            "                referred_schema = preparer._unquote_identifier(referred_schema)",
            "            elif schema is not None and schema == conschema:",
            "                # If the actual schema matches the schema of the table",
            "                # we're reflecting, then we will use that.",
            "                referred_schema = schema",
            "",
            "            referred_table = preparer._unquote_identifier(referred_table)",
            "            referred_columns = [",
            "                preparer._unquote_identifier(x)",
            "                for x in re.split(r\"\\s*,\\s\", referred_columns)",
            "            ]",
            "            fkey_d = {",
            "                \"name\": conname,",
            "                \"constrained_columns\": constrained_columns,",
            "                \"referred_schema\": referred_schema,",
            "                \"referred_table\": referred_table,",
            "                \"referred_columns\": referred_columns,",
            "                \"options\": {",
            "                    \"onupdate\": onupdate,",
            "                    \"ondelete\": ondelete,",
            "                    \"deferrable\": deferrable,",
            "                    \"initially\": initially,",
            "                    \"match\": match,",
            "                },",
            "            }",
            "            fkeys.append(fkey_d)",
            "        return fkeys",
            "",
            "    def _pg_index_any(self, col, compare_to):",
            "        if self.server_version_info < (8, 1):",
            "            # http://www.postgresql.org/message-id/10279.1124395722@sss.pgh.pa.us",
            "            # \"In CVS tip you could replace this with \"attnum = ANY (indkey)\".",
            "            # Unfortunately, most array support doesn't work on int2vector in",
            "            # pre-8.1 releases, so I think you're kinda stuck with the above",
            "            # for now.",
            "            # regards, tom lane\"",
            "            return \"(%s)\" % \" OR \".join(",
            "                \"%s[%d] = %s\" % (compare_to, ind, col) for ind in range(0, 10)",
            "            )",
            "        else:",
            "            return \"%s = ANY(%s)\" % (col, compare_to)",
            "",
            "    @reflection.cache",
            "    def get_indexes(self, connection, table_name, schema, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        # cast indkey as varchar since it's an int2vector,",
            "        # returned as a list by some drivers such as pypostgresql",
            "",
            "        if self.server_version_info < (8, 5):",
            "            IDX_SQL = \"\"\"",
            "              SELECT",
            "                  i.relname as relname,",
            "                  ix.indisunique, ix.indexprs, ix.indpred,",
            "                  a.attname, a.attnum, NULL, ix.indkey%s,",
            "                  %s, am.amname",
            "              FROM",
            "                  pg_class t",
            "                        join pg_index ix on t.oid = ix.indrelid",
            "                        join pg_class i on i.oid = ix.indexrelid",
            "                        left outer join",
            "                            pg_attribute a",
            "                            on t.oid = a.attrelid and %s",
            "                        left outer join",
            "                            pg_am am",
            "                            on i.relam = am.oid",
            "              WHERE",
            "                  t.relkind IN ('r', 'v', 'f', 'm')",
            "                  and t.oid = :table_oid",
            "                  and ix.indisprimary = 'f'",
            "              ORDER BY",
            "                  t.relname,",
            "                  i.relname",
            "            \"\"\" % (",
            "                # version 8.3 here was based on observing the",
            "                # cast does not work in PG 8.2.4, does work in 8.3.0.",
            "                # nothing in PG changelogs regarding this.",
            "                \"::varchar\" if self.server_version_info >= (8, 3) else \"\",",
            "                \"i.reloptions\"",
            "                if self.server_version_info >= (8, 2)",
            "                else \"NULL\",",
            "                self._pg_index_any(\"a.attnum\", \"ix.indkey\"),",
            "            )",
            "        else:",
            "            IDX_SQL = \"\"\"",
            "              SELECT",
            "                  i.relname as relname,",
            "                  ix.indisunique, ix.indexprs, ix.indpred,",
            "                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,",
            "                  i.reloptions, am.amname",
            "              FROM",
            "                  pg_class t",
            "                        join pg_index ix on t.oid = ix.indrelid",
            "                        join pg_class i on i.oid = ix.indexrelid",
            "                        left outer join",
            "                            pg_attribute a",
            "                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)",
            "                        left outer join",
            "                            pg_constraint c",
            "                            on (ix.indrelid = c.conrelid and",
            "                                ix.indexrelid = c.conindid and",
            "                                c.contype in ('p', 'u', 'x'))",
            "                        left outer join",
            "                            pg_am am",
            "                            on i.relam = am.oid",
            "              WHERE",
            "                  t.relkind IN ('r', 'v', 'f', 'm')",
            "                  and t.oid = :table_oid",
            "                  and ix.indisprimary = 'f'",
            "              ORDER BY",
            "                  t.relname,",
            "                  i.relname",
            "            \"\"\"",
            "",
            "        t = sql.text(IDX_SQL).columns(",
            "            relname=sqltypes.Unicode, attname=sqltypes.Unicode",
            "        )",
            "        c = connection.execute(t, table_oid=table_oid)",
            "",
            "        indexes = defaultdict(lambda: defaultdict(dict))",
            "",
            "        sv_idx_name = None",
            "        for row in c.fetchall():",
            "            (",
            "                idx_name,",
            "                unique,",
            "                expr,",
            "                prd,",
            "                col,",
            "                col_num,",
            "                conrelid,",
            "                idx_key,",
            "                options,",
            "                amname,",
            "            ) = row",
            "",
            "            if expr:",
            "                if idx_name != sv_idx_name:",
            "                    util.warn(",
            "                        \"Skipped unsupported reflection of \"",
            "                        \"expression-based index %s\" % idx_name",
            "                    )",
            "                sv_idx_name = idx_name",
            "                continue",
            "",
            "            if prd and not idx_name == sv_idx_name:",
            "                util.warn(",
            "                    \"Predicate of partial index %s ignored during reflection\"",
            "                    % idx_name",
            "                )",
            "                sv_idx_name = idx_name",
            "",
            "            has_idx = idx_name in indexes",
            "            index = indexes[idx_name]",
            "            if col is not None:",
            "                index[\"cols\"][col_num] = col",
            "            if not has_idx:",
            "                index[\"key\"] = [int(k.strip()) for k in idx_key.split()]",
            "                index[\"unique\"] = unique",
            "                if conrelid is not None:",
            "                    index[\"duplicates_constraint\"] = idx_name",
            "                if options:",
            "                    index[\"options\"] = dict(",
            "                        [option.split(\"=\") for option in options]",
            "                    )",
            "",
            "                # it *might* be nice to include that this is 'btree' in the",
            "                # reflection info.  But we don't want an Index object",
            "                # to have a ``postgresql_using`` in it that is just the",
            "                # default, so for the moment leaving this out.",
            "                if amname and amname != \"btree\":",
            "                    index[\"amname\"] = amname",
            "",
            "        result = []",
            "        for name, idx in indexes.items():",
            "            entry = {",
            "                \"name\": name,",
            "                \"unique\": idx[\"unique\"],",
            "                \"column_names\": [idx[\"cols\"][i] for i in idx[\"key\"]],",
            "            }",
            "            if \"duplicates_constraint\" in idx:",
            "                entry[\"duplicates_constraint\"] = idx[\"duplicates_constraint\"]",
            "            if \"options\" in idx:",
            "                entry.setdefault(\"dialect_options\", {})[",
            "                    \"postgresql_with\"",
            "                ] = idx[\"options\"]",
            "            if \"amname\" in idx:",
            "                entry.setdefault(\"dialect_options\", {})[",
            "                    \"postgresql_using\"",
            "                ] = idx[\"amname\"]",
            "            result.append(entry)",
            "        return result",
            "",
            "    @reflection.cache",
            "    def get_unique_constraints(",
            "        self, connection, table_name, schema=None, **kw",
            "    ):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        UNIQUE_SQL = \"\"\"",
            "            SELECT",
            "                cons.conname as name,",
            "                cons.conkey as key,",
            "                a.attnum as col_num,",
            "                a.attname as col_name",
            "            FROM",
            "                pg_catalog.pg_constraint cons",
            "                join pg_attribute a",
            "                  on cons.conrelid = a.attrelid AND",
            "                    a.attnum = ANY(cons.conkey)",
            "            WHERE",
            "                cons.conrelid = :table_oid AND",
            "                cons.contype = 'u'",
            "        \"\"\"",
            "",
            "        t = sql.text(UNIQUE_SQL).columns(col_name=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "",
            "        uniques = defaultdict(lambda: defaultdict(dict))",
            "        for row in c.fetchall():",
            "            uc = uniques[row.name]",
            "            uc[\"key\"] = row.key",
            "            uc[\"cols\"][row.col_num] = row.col_name",
            "",
            "        return [",
            "            {\"name\": name, \"column_names\": [uc[\"cols\"][i] for i in uc[\"key\"]]}",
            "            for name, uc in uniques.items()",
            "        ]",
            "",
            "    @reflection.cache",
            "    def get_table_comment(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        COMMENT_SQL = \"\"\"",
            "            SELECT",
            "                pgd.description as table_comment",
            "            FROM",
            "                pg_catalog.pg_description pgd",
            "            WHERE",
            "                pgd.objsubid = 0 AND",
            "                pgd.objoid = :table_oid",
            "        \"\"\"",
            "",
            "        c = connection.execute(sql.text(COMMENT_SQL), table_oid=table_oid)",
            "        return {\"text\": c.scalar()}",
            "",
            "    @reflection.cache",
            "    def get_check_constraints(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        CHECK_SQL = \"\"\"",
            "            SELECT",
            "                cons.conname as name,",
            "                pg_get_constraintdef(cons.oid) as src",
            "            FROM",
            "                pg_catalog.pg_constraint cons",
            "            WHERE",
            "                cons.conrelid = :table_oid AND",
            "                cons.contype = 'c'",
            "        \"\"\"",
            "",
            "        c = connection.execute(sql.text(CHECK_SQL), table_oid=table_oid)",
            "",
            "        # samples:",
            "        # \"CHECK (((a > 1) AND (a < 5)))\"",
            "        # \"CHECK (((a = 1) OR ((a > 2) AND (a < 5))))\"",
            "        def match_cons(src):",
            "            m = re.match(r\"^CHECK *\\(\\((.+)\\)\\)$\", src)",
            "            if not m:",
            "                util.warn(\"Could not parse CHECK constraint text: %r\" % src)",
            "                return \"\"",
            "            return m.group(1)",
            "",
            "        return [",
            "            {\"name\": name, \"sqltext\": match_cons(src)}",
            "            for name, src in c.fetchall()",
            "        ]",
            "",
            "    def _load_enums(self, connection, schema=None):",
            "        schema = schema or self.default_schema_name",
            "        if not self.supports_native_enum:",
            "            return {}",
            "",
            "        # Load data types for enums:",
            "        SQL_ENUMS = \"\"\"",
            "            SELECT t.typname as \"name\",",
            "               -- no enum defaults in 8.4 at least",
            "               -- t.typdefault as \"default\",",
            "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",",
            "               n.nspname as \"schema\",",
            "               e.enumlabel as \"label\"",
            "            FROM pg_catalog.pg_type t",
            "                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace",
            "                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid",
            "            WHERE t.typtype = 'e'",
            "        \"\"\"",
            "",
            "        if schema != \"*\":",
            "            SQL_ENUMS += \"AND n.nspname = :schema \"",
            "",
            "        # e.oid gives us label order within an enum",
            "        SQL_ENUMS += 'ORDER BY \"schema\", \"name\", e.oid'",
            "",
            "        s = sql.text(SQL_ENUMS).columns(",
            "            attname=sqltypes.Unicode, label=sqltypes.Unicode",
            "        )",
            "",
            "        if schema != \"*\":",
            "            s = s.bindparams(schema=schema)",
            "",
            "        c = connection.execute(s)",
            "",
            "        enums = []",
            "        enum_by_name = {}",
            "        for enum in c.fetchall():",
            "            key = (enum[\"schema\"], enum[\"name\"])",
            "            if key in enum_by_name:",
            "                enum_by_name[key][\"labels\"].append(enum[\"label\"])",
            "            else:",
            "                enum_by_name[key] = enum_rec = {",
            "                    \"name\": enum[\"name\"],",
            "                    \"schema\": enum[\"schema\"],",
            "                    \"visible\": enum[\"visible\"],",
            "                    \"labels\": [enum[\"label\"]],",
            "                }",
            "                enums.append(enum_rec)",
            "        return enums",
            "",
            "    def _load_domains(self, connection):",
            "        # Load data types for domains:",
            "        SQL_DOMAINS = \"\"\"",
            "            SELECT t.typname as \"name\",",
            "               pg_catalog.format_type(t.typbasetype, t.typtypmod) as \"attype\",",
            "               not t.typnotnull as \"nullable\",",
            "               t.typdefault as \"default\",",
            "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",",
            "               n.nspname as \"schema\"",
            "            FROM pg_catalog.pg_type t",
            "               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace",
            "            WHERE t.typtype = 'd'",
            "        \"\"\"",
            "",
            "        s = sql.text(SQL_DOMAINS).columns(attname=sqltypes.Unicode)",
            "        c = connection.execute(s)",
            "",
            "        domains = {}",
            "        for domain in c.fetchall():",
            "            # strip (30) from character varying(30)",
            "            attype = re.search(r\"([^\\(]+)\", domain[\"attype\"]).group(1)",
            "            # 'visible' just means whether or not the domain is in a",
            "            # schema that's on the search path -- or not overridden by",
            "            # a schema with higher precedence. If it's not visible,",
            "            # it will be prefixed with the schema-name when it's used.",
            "            if domain[\"visible\"]:",
            "                key = (domain[\"name\"],)",
            "            else:",
            "                key = (domain[\"schema\"], domain[\"name\"])",
            "",
            "            domains[key] = {",
            "                \"attype\": attype,",
            "                \"nullable\": domain[\"nullable\"],",
            "                \"default\": domain[\"default\"],",
            "            }",
            "",
            "        return domains"
        ],
        "afterPatchFile": [
            "# postgresql/base.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "r\"\"\"",
            ".. dialect:: postgresql",
            "    :name: PostgreSQL",
            "",
            ".. _postgresql_sequences:",
            "",
            "Sequences/SERIAL/IDENTITY",
            "-------------------------",
            "",
            "PostgreSQL supports sequences, and SQLAlchemy uses these as the default means",
            "of creating new primary key values for integer-based primary key columns. When",
            "creating tables, SQLAlchemy will issue the ``SERIAL`` datatype for",
            "integer-based primary key columns, which generates a sequence and server side",
            "default corresponding to the column.",
            "",
            "To specify a specific named sequence to be used for primary key generation,",
            "use the :func:`~sqlalchemy.schema.Sequence` construct::",
            "",
            "    Table('sometable', metadata,",
            "            Column('id', Integer, Sequence('some_id_seq'), primary_key=True)",
            "        )",
            "",
            "When SQLAlchemy issues a single INSERT statement, to fulfill the contract of",
            "having the \"last insert identifier\" available, a RETURNING clause is added to",
            "the INSERT statement which specifies the primary key columns should be",
            "returned after the statement completes. The RETURNING functionality only takes",
            "place if PostgreSQL 8.2 or later is in use. As a fallback approach, the",
            "sequence, whether specified explicitly or implicitly via ``SERIAL``, is",
            "executed independently beforehand, the returned value to be used in the",
            "subsequent insert. Note that when an",
            ":func:`~sqlalchemy.sql.expression.insert()` construct is executed using",
            "\"executemany\" semantics, the \"last inserted identifier\" functionality does not",
            "apply; no RETURNING clause is emitted nor is the sequence pre-executed in this",
            "case.",
            "",
            "To force the usage of RETURNING by default off, specify the flag",
            "``implicit_returning=False`` to :func:`.create_engine`.",
            "",
            "PostgreSQL 10 IDENTITY columns",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL 10 has a new IDENTITY feature that supersedes the use of SERIAL.",
            "Built-in support for rendering of IDENTITY is not available yet, however the",
            "following compilation hook may be used to replace occurrences of SERIAL with",
            "IDENTITY::",
            "",
            "    from sqlalchemy.schema import CreateColumn",
            "    from sqlalchemy.ext.compiler import compiles",
            "",
            "",
            "    @compiles(CreateColumn, 'postgresql')",
            "    def use_identity(element, compiler, **kw):",
            "        text = compiler.visit_create_column(element, **kw)",
            "        text = text.replace(\"SERIAL\", \"INT GENERATED BY DEFAULT AS IDENTITY\")",
            "        return text",
            "",
            "Using the above, a table such as::",
            "",
            "    t = Table(",
            "        't', m,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', String)",
            "    )",
            "",
            "Will generate on the backing database as::",
            "",
            "    CREATE TABLE t (",
            "        id INT GENERATED BY DEFAULT AS IDENTITY NOT NULL,",
            "        data VARCHAR,",
            "        PRIMARY KEY (id)",
            "    )",
            "",
            ".. _postgresql_isolation_level:",
            "",
            "Transaction Isolation Level",
            "---------------------------",
            "",
            "All PostgreSQL dialects support setting of transaction isolation level",
            "both via a dialect-specific parameter",
            ":paramref:`.create_engine.isolation_level` accepted by :func:`.create_engine`,",
            "as well as the :paramref:`.Connection.execution_options.isolation_level`",
            "argument as passed to :meth:`.Connection.execution_options`.",
            "When using a non-psycopg2 dialect, this feature works by issuing the command",
            "``SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL <level>`` for",
            "each new connection.  For the special AUTOCOMMIT isolation level,",
            "DBAPI-specific techniques are used.",
            "",
            "To set isolation level using :func:`.create_engine`::",
            "",
            "    engine = create_engine(",
            "        \"postgresql+pg8000://scott:tiger@localhost/test\",",
            "        isolation_level=\"READ UNCOMMITTED\"",
            "    )",
            "",
            "To set using per-connection execution options::",
            "",
            "    connection = engine.connect()",
            "    connection = connection.execution_options(",
            "        isolation_level=\"READ COMMITTED\"",
            "    )",
            "",
            "Valid values for ``isolation_level`` include:",
            "",
            "* ``READ COMMITTED``",
            "* ``READ UNCOMMITTED``",
            "* ``REPEATABLE READ``",
            "* ``SERIALIZABLE``",
            "* ``AUTOCOMMIT`` - on psycopg2 / pg8000 only",
            "",
            ".. seealso::",
            "",
            "    :ref:`psycopg2_isolation_level`",
            "",
            "    :ref:`pg8000_isolation_level`",
            "",
            ".. _postgresql_schema_reflection:",
            "",
            "Remote-Schema Table Introspection and PostgreSQL search_path",
            "------------------------------------------------------------",
            "",
            "**TL;DR;**: keep the ``search_path`` variable set to its default of ``public``,",
            "name schemas **other** than ``public`` explicitly within ``Table`` definitions.",
            "",
            "The PostgreSQL dialect can reflect tables from any schema.  The",
            ":paramref:`.Table.schema` argument, or alternatively the",
            ":paramref:`.MetaData.reflect.schema` argument determines which schema will",
            "be searched for the table or tables.   The reflected :class:`.Table` objects",
            "will in all cases retain this ``.schema`` attribute as was specified.",
            "However, with regards to tables which these :class:`.Table` objects refer to",
            "via foreign key constraint, a decision must be made as to how the ``.schema``",
            "is represented in those remote tables, in the case where that remote",
            "schema name is also a member of the current",
            "`PostgreSQL search path",
            "<http://www.postgresql.org/docs/current/static/ddl-schemas.html#DDL-SCHEMAS-PATH>`_.",
            "",
            "By default, the PostgreSQL dialect mimics the behavior encouraged by",
            "PostgreSQL's own ``pg_get_constraintdef()`` builtin procedure.  This function",
            "returns a sample definition for a particular foreign key constraint,",
            "omitting the referenced schema name from that definition when the name is",
            "also in the PostgreSQL schema search path.  The interaction below",
            "illustrates this behavior::",
            "",
            "    test=> CREATE TABLE test_schema.referred(id INTEGER PRIMARY KEY);",
            "    CREATE TABLE",
            "    test=> CREATE TABLE referring(",
            "    test(>         id INTEGER PRIMARY KEY,",
            "    test(>         referred_id INTEGER REFERENCES test_schema.referred(id));",
            "    CREATE TABLE",
            "    test=> SET search_path TO public, test_schema;",
            "    test=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM",
            "    test-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n",
            "    test-> ON n.oid = c.relnamespace",
            "    test-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid",
            "    test-> WHERE c.relname='referring' AND r.contype = 'f'",
            "    test-> ;",
            "                   pg_get_constraintdef",
            "    ---------------------------------------------------",
            "     FOREIGN KEY (referred_id) REFERENCES referred(id)",
            "    (1 row)",
            "",
            "Above, we created a table ``referred`` as a member of the remote schema",
            "``test_schema``, however when we added ``test_schema`` to the",
            "PG ``search_path`` and then asked ``pg_get_constraintdef()`` for the",
            "``FOREIGN KEY`` syntax, ``test_schema`` was not included in the output of",
            "the function.",
            "",
            "On the other hand, if we set the search path back to the typical default",
            "of ``public``::",
            "",
            "    test=> SET search_path TO public;",
            "    SET",
            "",
            "The same query against ``pg_get_constraintdef()`` now returns the fully",
            "schema-qualified name for us::",
            "",
            "    test=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM",
            "    test-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n",
            "    test-> ON n.oid = c.relnamespace",
            "    test-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid",
            "    test-> WHERE c.relname='referring' AND r.contype = 'f';",
            "                         pg_get_constraintdef",
            "    ---------------------------------------------------------------",
            "     FOREIGN KEY (referred_id) REFERENCES test_schema.referred(id)",
            "    (1 row)",
            "",
            "SQLAlchemy will by default use the return value of ``pg_get_constraintdef()``",
            "in order to determine the remote schema name.  That is, if our ``search_path``",
            "were set to include ``test_schema``, and we invoked a table",
            "reflection process as follows::",
            "",
            "    >>> from sqlalchemy import Table, MetaData, create_engine",
            "    >>> engine = create_engine(\"postgresql://scott:tiger@localhost/test\")",
            "    >>> with engine.connect() as conn:",
            "    ...     conn.execute(\"SET search_path TO test_schema, public\")",
            "    ...     meta = MetaData()",
            "    ...     referring = Table('referring', meta,",
            "    ...                       autoload=True, autoload_with=conn)",
            "    ...",
            "    <sqlalchemy.engine.result.ResultProxy object at 0x101612ed0>",
            "",
            "The above process would deliver to the :attr:`.MetaData.tables` collection",
            "``referred`` table named **without** the schema::",
            "",
            "    >>> meta.tables['referred'].schema is None",
            "    True",
            "",
            "To alter the behavior of reflection such that the referred schema is",
            "maintained regardless of the ``search_path`` setting, use the",
            "``postgresql_ignore_search_path`` option, which can be specified as a",
            "dialect-specific argument to both :class:`.Table` as well as",
            ":meth:`.MetaData.reflect`::",
            "",
            "    >>> with engine.connect() as conn:",
            "    ...     conn.execute(\"SET search_path TO test_schema, public\")",
            "    ...     meta = MetaData()",
            "    ...     referring = Table('referring', meta, autoload=True,",
            "    ...                       autoload_with=conn,",
            "    ...                       postgresql_ignore_search_path=True)",
            "    ...",
            "    <sqlalchemy.engine.result.ResultProxy object at 0x1016126d0>",
            "",
            "We will now have ``test_schema.referred`` stored as schema-qualified::",
            "",
            "    >>> meta.tables['test_schema.referred'].schema",
            "    'test_schema'",
            "",
            ".. sidebar:: Best Practices for PostgreSQL Schema reflection",
            "",
            "    The description of PostgreSQL schema reflection behavior is complex, and",
            "    is the product of many years of dealing with widely varied use cases and",
            "    user preferences. But in fact, there's no need to understand any of it if",
            "    you just stick to the simplest use pattern: leave the ``search_path`` set",
            "    to its default of ``public`` only, never refer to the name ``public`` as",
            "    an explicit schema name otherwise, and refer to all other schema names",
            "    explicitly when building up a :class:`.Table` object.  The options",
            "    described here are only for those users who can't, or prefer not to, stay",
            "    within these guidelines.",
            "",
            "Note that **in all cases**, the \"default\" schema is always reflected as",
            "``None``. The \"default\" schema on PostgreSQL is that which is returned by the",
            "PostgreSQL ``current_schema()`` function.  On a typical PostgreSQL",
            "installation, this is the name ``public``.  So a table that refers to another",
            "which is in the ``public`` (i.e. default) schema will always have the",
            "``.schema`` attribute set to ``None``.",
            "",
            ".. versionadded:: 0.9.2 Added the ``postgresql_ignore_search_path``",
            "   dialect-level option accepted by :class:`.Table` and",
            "   :meth:`.MetaData.reflect`.",
            "",
            "",
            ".. seealso::",
            "",
            "    `The Schema Search Path",
            "    <http://www.postgresql.org/docs/9.0/static/ddl-schemas.html#DDL-SCHEMAS-PATH>`_",
            "    - on the PostgreSQL website.",
            "",
            "INSERT/UPDATE...RETURNING",
            "-------------------------",
            "",
            "The dialect supports PG 8.2's ``INSERT..RETURNING``, ``UPDATE..RETURNING`` and",
            "``DELETE..RETURNING`` syntaxes.   ``INSERT..RETURNING`` is used by default",
            "for single-row INSERT statements in order to fetch newly generated",
            "primary key identifiers.   To specify an explicit ``RETURNING`` clause,",
            "use the :meth:`._UpdateBase.returning` method on a per-statement basis::",
            "",
            "    # INSERT..RETURNING",
            "    result = table.insert().returning(table.c.col1, table.c.col2).\\",
            "        values(name='foo')",
            "    print result.fetchall()",
            "",
            "    # UPDATE..RETURNING",
            "    result = table.update().returning(table.c.col1, table.c.col2).\\",
            "        where(table.c.name=='foo').values(name='bar')",
            "    print result.fetchall()",
            "",
            "    # DELETE..RETURNING",
            "    result = table.delete().returning(table.c.col1, table.c.col2).\\",
            "        where(table.c.name=='foo')",
            "    print result.fetchall()",
            "",
            ".. _postgresql_insert_on_conflict:",
            "",
            "INSERT...ON CONFLICT (Upsert)",
            "------------------------------",
            "",
            "Starting with version 9.5, PostgreSQL allows \"upserts\" (update or insert) of",
            "rows into a table via the ``ON CONFLICT`` clause of the ``INSERT`` statement. A",
            "candidate row will only be inserted if that row does not violate any unique",
            "constraints.  In the case of a unique constraint violation, a secondary action",
            "can occur which can be either \"DO UPDATE\", indicating that the data in the",
            "target row should be updated, or \"DO NOTHING\", which indicates to silently skip",
            "this row.",
            "",
            "Conflicts are determined using existing unique constraints and indexes.  These",
            "constraints may be identified either using their name as stated in DDL,",
            "or they may be *inferred* by stating the columns and conditions that comprise",
            "the indexes.",
            "",
            "SQLAlchemy provides ``ON CONFLICT`` support via the PostgreSQL-specific",
            ":func:`.postgresql.dml.insert()` function, which provides",
            "the generative methods :meth:`~.postgresql.dml.Insert.on_conflict_do_update`",
            "and :meth:`~.postgresql.dml.Insert.on_conflict_do_nothing`::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    insert_stmt = insert(my_table).values(",
            "        id='some_existing_id',",
            "        data='inserted value')",
            "",
            "    do_nothing_stmt = insert_stmt.on_conflict_do_nothing(",
            "        index_elements=['id']",
            "    )",
            "",
            "    conn.execute(do_nothing_stmt)",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='pk_my_table',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    conn.execute(do_update_stmt)",
            "",
            "Both methods supply the \"target\" of the conflict using either the",
            "named constraint or by column inference:",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.index_elements` argument",
            "  specifies a sequence containing string column names, :class:`.Column`",
            "  objects, and/or SQL expression elements, which would identify a unique",
            "  index::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        index_elements=[my_table.c.id],",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "* When using :paramref:`.Insert.on_conflict_do_update.index_elements` to",
            "  infer an index, a partial index can be inferred by also specifying the",
            "  use the :paramref:`.Insert.on_conflict_do_update.index_where` parameter::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(user_email='a@b.com', data='inserted data')",
            "    stmt = stmt.on_conflict_do_update(",
            "        index_elements=[my_table.c.user_email],",
            "        index_where=my_table.c.user_email.like('%@gmail.com'),",
            "        set_=dict(data=stmt.excluded.data)",
            "        )",
            "    conn.execute(stmt)",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.constraint` argument is",
            "  used to specify an index directly rather than inferring it.  This can be",
            "  the name of a UNIQUE constraint, a PRIMARY KEY constraint, or an INDEX::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='my_table_idx_1',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint='my_table_pk',",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "* The :paramref:`.Insert.on_conflict_do_update.constraint` argument may",
            "  also refer to a SQLAlchemy construct representing a constraint,",
            "  e.g. :class:`.UniqueConstraint`, :class:`.PrimaryKeyConstraint`,",
            "  :class:`.Index`, or :class:`.ExcludeConstraint`.   In this use,",
            "  if the constraint has a name, it is used directly.  Otherwise, if the",
            "  constraint is unnamed, then inference will be used, where the expressions",
            "  and optional WHERE clause of the constraint will be spelled out in the",
            "  construct.  This use is especially convenient",
            "  to refer to the named or unnamed primary key of a :class:`.Table` using the",
            "  :attr:`.Table.primary_key` attribute::",
            "",
            "    do_update_stmt = insert_stmt.on_conflict_do_update(",
            "        constraint=my_table.primary_key,",
            "        set_=dict(data='updated value')",
            "    )",
            "",
            "``ON CONFLICT...DO UPDATE`` is used to perform an update of the already",
            "existing row, using any combination of new values as well as values",
            "from the proposed insertion.   These values are specified using the",
            ":paramref:`.Insert.on_conflict_do_update.set_` parameter.  This",
            "parameter accepts a dictionary which consists of direct values",
            "for UPDATE::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    do_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value')",
            "        )",
            "    conn.execute(do_update_stmt)",
            "",
            ".. warning::",
            "",
            "    The :meth:`.Insert.on_conflict_do_update` method does **not** take into",
            "    account Python-side default UPDATE values or generation functions, e.g.",
            "    e.g. those specified using :paramref:`.Column.onupdate`.",
            "    These values will not be exercised for an ON CONFLICT style of UPDATE,",
            "    unless they are manually specified in the",
            "    :paramref:`.Insert.on_conflict_do_update.set_` dictionary.",
            "",
            "In order to refer to the proposed insertion row, the special alias",
            ":attr:`~.postgresql.dml.Insert.excluded` is available as an attribute on",
            "the :class:`.postgresql.dml.Insert` object; this object is a",
            ":class:`.ColumnCollection` which alias contains all columns of the target",
            "table::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(",
            "        id='some_id',",
            "        data='inserted value',",
            "        author='jlh')",
            "    do_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value', author=stmt.excluded.author)",
            "        )",
            "    conn.execute(do_update_stmt)",
            "",
            "The :meth:`.Insert.on_conflict_do_update` method also accepts",
            "a WHERE clause using the :paramref:`.Insert.on_conflict_do_update.where`",
            "parameter, which will limit those rows which receive an UPDATE::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(",
            "        id='some_id',",
            "        data='inserted value',",
            "        author='jlh')",
            "    on_update_stmt = stmt.on_conflict_do_update(",
            "        index_elements=['id'],",
            "        set_=dict(data='updated value', author=stmt.excluded.author)",
            "        where=(my_table.c.status == 2)",
            "        )",
            "    conn.execute(on_update_stmt)",
            "",
            "``ON CONFLICT`` may also be used to skip inserting a row entirely",
            "if any conflict with a unique or exclusion constraint occurs; below",
            "this is illustrated using the",
            ":meth:`~.postgresql.dml.Insert.on_conflict_do_nothing` method::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    stmt = stmt.on_conflict_do_nothing(index_elements=['id'])",
            "    conn.execute(stmt)",
            "",
            "If ``DO NOTHING`` is used without specifying any columns or constraint,",
            "it has the effect of skipping the INSERT for any unique or exclusion",
            "constraint violation which occurs::",
            "",
            "    from sqlalchemy.dialects.postgresql import insert",
            "",
            "    stmt = insert(my_table).values(id='some_id', data='inserted value')",
            "    stmt = stmt.on_conflict_do_nothing()",
            "    conn.execute(stmt)",
            "",
            ".. versionadded:: 1.1 Added support for PostgreSQL ON CONFLICT clauses",
            "",
            ".. seealso::",
            "",
            "    `INSERT .. ON CONFLICT",
            "    <http://www.postgresql.org/docs/current/static/sql-insert.html#SQL-ON-CONFLICT>`_",
            "    - in the PostgreSQL documentation.",
            "",
            ".. _postgresql_match:",
            "",
            "Full Text Search",
            "----------------",
            "",
            "SQLAlchemy makes available the PostgreSQL ``@@`` operator via the",
            ":meth:`.ColumnElement.match` method on any textual column expression.",
            "On a PostgreSQL dialect, an expression like the following::",
            "",
            "    select([sometable.c.text.match(\"search string\")])",
            "",
            "will emit to the database::",
            "",
            "    SELECT text @@ to_tsquery('search string') FROM table",
            "",
            "The PostgreSQL text search functions such as ``to_tsquery()``",
            "and ``to_tsvector()`` are available",
            "explicitly using the standard :data:`.func` construct.  For example::",
            "",
            "    select([",
            "        func.to_tsvector('fat cats ate rats').match('cat & rat')",
            "    ])",
            "",
            "Emits the equivalent of::",
            "",
            "    SELECT to_tsvector('fat cats ate rats') @@ to_tsquery('cat & rat')",
            "",
            "The :class:`.postgresql.TSVECTOR` type can provide for explicit CAST::",
            "",
            "    from sqlalchemy.dialects.postgresql import TSVECTOR",
            "    from sqlalchemy import select, cast",
            "    select([cast(\"some text\", TSVECTOR)])",
            "",
            "produces a statement equivalent to::",
            "",
            "    SELECT CAST('some text' AS TSVECTOR) AS anon_1",
            "",
            "Full Text Searches in PostgreSQL are influenced by a combination of: the",
            "PostgreSQL setting of ``default_text_search_config``, the ``regconfig`` used",
            "to build the GIN/GiST indexes, and the ``regconfig`` optionally passed in",
            "during a query.",
            "",
            "When performing a Full Text Search against a column that has a GIN or",
            "GiST index that is already pre-computed (which is common on full text",
            "searches) one may need to explicitly pass in a particular PostgreSQL",
            "``regconfig`` value to ensure the query-planner utilizes the index and does",
            "not re-compute the column on demand.",
            "",
            "In order to provide for this explicit query planning, or to use different",
            "search strategies, the ``match`` method accepts a ``postgresql_regconfig``",
            "keyword argument::",
            "",
            "    select([mytable.c.id]).where(",
            "        mytable.c.title.match('somestring', postgresql_regconfig='english')",
            "    )",
            "",
            "Emits the equivalent of::",
            "",
            "    SELECT mytable.id FROM mytable",
            "    WHERE mytable.title @@ to_tsquery('english', 'somestring')",
            "",
            "One can also specifically pass in a `'regconfig'` value to the",
            "``to_tsvector()`` command as the initial argument::",
            "",
            "    select([mytable.c.id]).where(",
            "            func.to_tsvector('english', mytable.c.title )\\",
            "            .match('somestring', postgresql_regconfig='english')",
            "        )",
            "",
            "produces a statement equivalent to::",
            "",
            "    SELECT mytable.id FROM mytable",
            "    WHERE to_tsvector('english', mytable.title) @@",
            "        to_tsquery('english', 'somestring')",
            "",
            "It is recommended that you use the ``EXPLAIN ANALYZE...`` tool from",
            "PostgreSQL to ensure that you are generating queries with SQLAlchemy that",
            "take full advantage of any indexes you may have created for full text search.",
            "",
            "FROM ONLY ...",
            "------------------------",
            "",
            "The dialect supports PostgreSQL's ONLY keyword for targeting only a particular",
            "table in an inheritance hierarchy. This can be used to produce the",
            "``SELECT ... FROM ONLY``, ``UPDATE ONLY ...``, and ``DELETE FROM ONLY ...``",
            "syntaxes. It uses SQLAlchemy's hints mechanism::",
            "",
            "    # SELECT ... FROM ONLY ...",
            "    result = table.select().with_hint(table, 'ONLY', 'postgresql')",
            "    print result.fetchall()",
            "",
            "    # UPDATE ONLY ...",
            "    table.update(values=dict(foo='bar')).with_hint('ONLY',",
            "                                                   dialect_name='postgresql')",
            "",
            "    # DELETE FROM ONLY ...",
            "    table.delete().with_hint('ONLY', dialect_name='postgresql')",
            "",
            "",
            ".. _postgresql_indexes:",
            "",
            "PostgreSQL-Specific Index Options",
            "---------------------------------",
            "",
            "Several extensions to the :class:`.Index` construct are available, specific",
            "to the PostgreSQL dialect.",
            "",
            ".. _postgresql_partial_indexes:",
            "",
            "Partial Indexes",
            "^^^^^^^^^^^^^^^",
            "",
            "Partial indexes add criterion to the index definition so that the index is",
            "applied to a subset of rows.   These can be specified on :class:`.Index`",
            "using the ``postgresql_where`` keyword argument::",
            "",
            "  Index('my_index', my_table.c.id, postgresql_where=my_table.c.value > 10)",
            "",
            "Operator Classes",
            "^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL allows the specification of an *operator class* for each column of",
            "an index (see",
            "http://www.postgresql.org/docs/8.3/interactive/indexes-opclass.html).",
            "The :class:`.Index` construct allows these to be specified via the",
            "``postgresql_ops`` keyword argument::",
            "",
            "    Index(",
            "        'my_index', my_table.c.id, my_table.c.data,",
            "        postgresql_ops={",
            "            'data': 'text_pattern_ops',",
            "            'id': 'int4_ops'",
            "        })",
            "",
            "Note that the keys in the ``postgresql_ops`` dictionary are the \"key\" name of",
            "the :class:`.Column`, i.e. the name used to access it from the ``.c``",
            "collection of :class:`.Table`, which can be configured to be different than",
            "the actual name of the column as expressed in the database.",
            "",
            "If ``postgresql_ops`` is to be used against a complex SQL expression such",
            "as a function call, then to apply to the column it must be given a label",
            "that is identified in the dictionary by name, e.g.::",
            "",
            "    Index(",
            "        'my_index', my_table.c.id,",
            "        func.lower(my_table.c.data).label('data_lower'),",
            "        postgresql_ops={",
            "            'data_lower': 'text_pattern_ops',",
            "            'id': 'int4_ops'",
            "        })",
            "",
            "",
            "Index Types",
            "^^^^^^^^^^^",
            "",
            "PostgreSQL provides several index types: B-Tree, Hash, GiST, and GIN, as well",
            "as the ability for users to create their own (see",
            "http://www.postgresql.org/docs/8.3/static/indexes-types.html). These can be",
            "specified on :class:`.Index` using the ``postgresql_using`` keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_using='gin')",
            "",
            "The value passed to the keyword argument will be simply passed through to the",
            "underlying CREATE INDEX command, so it *must* be a valid index type for your",
            "version of PostgreSQL.",
            "",
            ".. _postgresql_index_storage:",
            "",
            "Index Storage Parameters",
            "^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "PostgreSQL allows storage parameters to be set on indexes. The storage",
            "parameters available depend on the index method used by the index. Storage",
            "parameters can be specified on :class:`.Index` using the ``postgresql_with``",
            "keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_with={\"fillfactor\": 50})",
            "",
            ".. versionadded:: 1.0.6",
            "",
            "PostgreSQL allows to define the tablespace in which to create the index.",
            "The tablespace can be specified on :class:`.Index` using the",
            "``postgresql_tablespace`` keyword argument::",
            "",
            "    Index('my_index', my_table.c.data, postgresql_tablespace='my_tablespace')",
            "",
            ".. versionadded:: 1.1",
            "",
            "Note that the same option is available on :class:`.Table` as well.",
            "",
            ".. _postgresql_index_concurrently:",
            "",
            "Indexes with CONCURRENTLY",
            "^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "The PostgreSQL index option CONCURRENTLY is supported by passing the",
            "flag ``postgresql_concurrently`` to the :class:`.Index` construct::",
            "",
            "    tbl = Table('testtbl', m, Column('data', Integer))",
            "",
            "    idx1 = Index('test_idx1', tbl.c.data, postgresql_concurrently=True)",
            "",
            "The above index construct will render DDL for CREATE INDEX, assuming",
            "PostgreSQL 8.2 or higher is detected or for a connection-less dialect, as::",
            "",
            "    CREATE INDEX CONCURRENTLY test_idx1 ON testtbl (data)",
            "",
            "For DROP INDEX, assuming PostgreSQL 9.2 or higher is detected or for",
            "a connection-less dialect, it will emit::",
            "",
            "    DROP INDEX CONCURRENTLY test_idx1",
            "",
            ".. versionadded:: 1.1 support for CONCURRENTLY on DROP INDEX.  The",
            "   CONCURRENTLY keyword is now only emitted if a high enough version",
            "   of PostgreSQL is detected on the connection (or for a connection-less",
            "   dialect).",
            "",
            "When using CONCURRENTLY, the PostgreSQL database requires that the statement",
            "be invoked outside of a transaction block.   The Python DBAPI enforces that",
            "even for a single statement, a transaction is present, so to use this",
            "construct, the DBAPI's \"autocommit\" mode must be used::",
            "",
            "    metadata = MetaData()",
            "    table = Table(",
            "        \"foo\", metadata,",
            "        Column(\"id\", String))",
            "    index = Index(",
            "        \"foo_idx\", table.c.id, postgresql_concurrently=True)",
            "",
            "    with engine.connect() as conn:",
            "        with conn.execution_options(isolation_level='AUTOCOMMIT'):",
            "            table.create(conn)",
            "",
            ".. seealso::",
            "",
            "    :ref:`postgresql_isolation_level`",
            "",
            ".. _postgresql_index_reflection:",
            "",
            "PostgreSQL Index Reflection",
            "---------------------------",
            "",
            "The PostgreSQL database creates a UNIQUE INDEX implicitly whenever the",
            "UNIQUE CONSTRAINT construct is used.   When inspecting a table using",
            ":class:`.Inspector`, the :meth:`.Inspector.get_indexes`",
            "and the :meth:`.Inspector.get_unique_constraints` will report on these",
            "two constructs distinctly; in the case of the index, the key",
            "``duplicates_constraint`` will be present in the index entry if it is",
            "detected as mirroring a constraint.   When performing reflection using",
            "``Table(..., autoload=True)``, the UNIQUE INDEX is **not** returned",
            "in :attr:`.Table.indexes` when it is detected as mirroring a",
            ":class:`.UniqueConstraint` in the :attr:`.Table.constraints` collection.",
            "",
            ".. versionchanged:: 1.0.0 - :class:`.Table` reflection now includes",
            "   :class:`.UniqueConstraint` objects present in the :attr:`.Table.constraints`",
            "   collection; the PostgreSQL backend will no longer include a \"mirrored\"",
            "   :class:`.Index` construct in :attr:`.Table.indexes` if it is detected",
            "   as corresponding to a unique constraint.",
            "",
            "Special Reflection Options",
            "--------------------------",
            "",
            "The :class:`.Inspector` used for the PostgreSQL backend is an instance",
            "of :class:`.PGInspector`, which offers additional methods::",
            "",
            "    from sqlalchemy import create_engine, inspect",
            "",
            "    engine = create_engine(\"postgresql+psycopg2://localhost/test\")",
            "    insp = inspect(engine)  # will be a PGInspector",
            "",
            "    print(insp.get_enums())",
            "",
            ".. autoclass:: PGInspector",
            "    :members:",
            "",
            ".. _postgresql_table_options:",
            "",
            "PostgreSQL Table Options",
            "------------------------",
            "",
            "Several options for CREATE TABLE are supported directly by the PostgreSQL",
            "dialect in conjunction with the :class:`.Table` construct:",
            "",
            "* ``TABLESPACE``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_tablespace='some_tablespace')",
            "",
            "  The above option is also available on the :class:`.Index` construct.",
            "",
            "* ``ON COMMIT``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_on_commit='PRESERVE ROWS')",
            "",
            "* ``WITH OIDS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_with_oids=True)",
            "",
            "* ``WITHOUT OIDS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_with_oids=False)",
            "",
            "* ``INHERITS``::",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_inherits=\"some_supertable\")",
            "",
            "    Table(\"some_table\", metadata, ..., postgresql_inherits=(\"t1\", \"t2\", ...))",
            "",
            "    .. versionadded:: 1.0.0",
            "",
            "* ``PARTITION BY``::",
            "",
            "    Table(\"some_table\", metadata, ...,",
            "          postgresql_partition_by='LIST (part_column)')",
            "",
            "    .. versionadded:: 1.2.6",
            "",
            ".. seealso::",
            "",
            "    `PostgreSQL CREATE TABLE options",
            "    <http://www.postgresql.org/docs/current/static/sql-createtable.html>`_",
            "",
            "ARRAY Types",
            "-----------",
            "",
            "The PostgreSQL dialect supports arrays, both as multidimensional column types",
            "as well as array literals:",
            "",
            "* :class:`.postgresql.ARRAY` - ARRAY datatype",
            "",
            "* :class:`.postgresql.array` - array literal",
            "",
            "* :func:`.postgresql.array_agg` - ARRAY_AGG SQL function",
            "",
            "* :class:`.postgresql.aggregate_order_by` - helper for PG's ORDER BY aggregate",
            "  function syntax.",
            "",
            "JSON Types",
            "----------",
            "",
            "The PostgreSQL dialect supports both JSON and JSONB datatypes, including",
            "psycopg2's native support and support for all of PostgreSQL's special",
            "operators:",
            "",
            "* :class:`.postgresql.JSON`",
            "",
            "* :class:`.postgresql.JSONB`",
            "",
            "HSTORE Type",
            "-----------",
            "",
            "The PostgreSQL HSTORE type as well as hstore literals are supported:",
            "",
            "* :class:`.postgresql.HSTORE` - HSTORE datatype",
            "",
            "* :class:`.postgresql.hstore` - hstore literal",
            "",
            "ENUM Types",
            "----------",
            "",
            "PostgreSQL has an independently creatable TYPE structure which is used",
            "to implement an enumerated type.   This approach introduces significant",
            "complexity on the SQLAlchemy side in terms of when this type should be",
            "CREATED and DROPPED.   The type object is also an independently reflectable",
            "entity.   The following sections should be consulted:",
            "",
            "* :class:`.postgresql.ENUM` - DDL and typing support for ENUM.",
            "",
            "* :meth:`.PGInspector.get_enums` - retrieve a listing of current ENUM types",
            "",
            "* :meth:`.postgresql.ENUM.create` , :meth:`.postgresql.ENUM.drop` - individual",
            "  CREATE and DROP commands for ENUM.",
            "",
            ".. _postgresql_array_of_enum:",
            "",
            "Using ENUM with ARRAY",
            "^^^^^^^^^^^^^^^^^^^^^",
            "",
            "The combination of ENUM and ARRAY is not directly supported by backend",
            "DBAPIs at this time.   In order to send and receive an ARRAY of ENUM,",
            "use the following workaround type::",
            "",
            "    class ArrayOfEnum(ARRAY):",
            "",
            "        def bind_expression(self, bindvalue):",
            "            return sa.cast(bindvalue, self)",
            "",
            "        def result_processor(self, dialect, coltype):",
            "            super_rp = super(ArrayOfEnum, self).result_processor(",
            "                dialect, coltype)",
            "",
            "            def handle_raw_string(value):",
            "                inner = re.match(r\"^{(.*)}$\", value).group(1)",
            "                return inner.split(\",\") if inner else []",
            "",
            "            def process(value):",
            "                if value is None:",
            "                    return None",
            "                return super_rp(handle_raw_string(value))",
            "            return process",
            "",
            "E.g.::",
            "",
            "    Table(",
            "        'mydata', metadata,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', ArrayOfEnum(ENUM('a', 'b, 'c', name='myenum')))",
            "",
            "    )",
            "",
            "This type is not included as a built-in type as it would be incompatible",
            "with a DBAPI that suddenly decides to support ARRAY of ENUM directly in",
            "a new version.",
            "",
            ".. _postgresql_array_of_json:",
            "",
            "Using JSON/JSONB with ARRAY",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^",
            "",
            "Similar to using ENUM, for an ARRAY of JSON/JSONB we need to render the",
            "appropriate CAST, however current psycopg2 drivers seem to handle the result",
            "for ARRAY of JSON automatically, so the type is simpler::",
            "",
            "",
            "    class CastingArray(ARRAY):",
            "        def bind_expression(self, bindvalue):",
            "            return sa.cast(bindvalue, self)",
            "",
            "E.g.::",
            "",
            "    Table(",
            "        'mydata', metadata,",
            "        Column('id', Integer, primary_key=True),",
            "        Column('data', CastingArray(JSONB))",
            "    )",
            "",
            "",
            "\"\"\"",
            "from collections import defaultdict",
            "import datetime as dt",
            "import re",
            "",
            "from ... import exc",
            "from ... import schema",
            "from ... import sql",
            "from ... import util",
            "from ...engine import default",
            "from ...engine import reflection",
            "from ...sql import compiler",
            "from ...sql import elements",
            "from ...sql import expression",
            "from ...sql import sqltypes",
            "from ...types import BIGINT",
            "from ...types import BOOLEAN",
            "from ...types import CHAR",
            "from ...types import DATE",
            "from ...types import FLOAT",
            "from ...types import INTEGER",
            "from ...types import NUMERIC",
            "from ...types import REAL",
            "from ...types import SMALLINT",
            "from ...types import TEXT",
            "from ...types import VARCHAR",
            "",
            "",
            "try:",
            "    from uuid import UUID as _python_UUID  # noqa",
            "except ImportError:",
            "    _python_UUID = None",
            "",
            "",
            "IDX_USING = re.compile(r\"^(?:btree|hash|gist|gin|[\\w_]+)$\", re.I)",
            "",
            "AUTOCOMMIT_REGEXP = re.compile(",
            "    r\"\\s*(?:UPDATE|INSERT|CREATE|DELETE|DROP|ALTER|GRANT|REVOKE|\"",
            "    \"IMPORT FOREIGN SCHEMA|REFRESH MATERIALIZED VIEW|TRUNCATE)\",",
            "    re.I | re.UNICODE,",
            ")",
            "",
            "RESERVED_WORDS = set(",
            "    [",
            "        \"all\",",
            "        \"analyse\",",
            "        \"analyze\",",
            "        \"and\",",
            "        \"any\",",
            "        \"array\",",
            "        \"as\",",
            "        \"asc\",",
            "        \"asymmetric\",",
            "        \"both\",",
            "        \"case\",",
            "        \"cast\",",
            "        \"check\",",
            "        \"collate\",",
            "        \"column\",",
            "        \"constraint\",",
            "        \"create\",",
            "        \"current_catalog\",",
            "        \"current_date\",",
            "        \"current_role\",",
            "        \"current_time\",",
            "        \"current_timestamp\",",
            "        \"current_user\",",
            "        \"default\",",
            "        \"deferrable\",",
            "        \"desc\",",
            "        \"distinct\",",
            "        \"do\",",
            "        \"else\",",
            "        \"end\",",
            "        \"except\",",
            "        \"false\",",
            "        \"fetch\",",
            "        \"for\",",
            "        \"foreign\",",
            "        \"from\",",
            "        \"grant\",",
            "        \"group\",",
            "        \"having\",",
            "        \"in\",",
            "        \"initially\",",
            "        \"intersect\",",
            "        \"into\",",
            "        \"leading\",",
            "        \"limit\",",
            "        \"localtime\",",
            "        \"localtimestamp\",",
            "        \"new\",",
            "        \"not\",",
            "        \"null\",",
            "        \"of\",",
            "        \"off\",",
            "        \"offset\",",
            "        \"old\",",
            "        \"on\",",
            "        \"only\",",
            "        \"or\",",
            "        \"order\",",
            "        \"placing\",",
            "        \"primary\",",
            "        \"references\",",
            "        \"returning\",",
            "        \"select\",",
            "        \"session_user\",",
            "        \"some\",",
            "        \"symmetric\",",
            "        \"table\",",
            "        \"then\",",
            "        \"to\",",
            "        \"trailing\",",
            "        \"true\",",
            "        \"union\",",
            "        \"unique\",",
            "        \"user\",",
            "        \"using\",",
            "        \"variadic\",",
            "        \"when\",",
            "        \"where\",",
            "        \"window\",",
            "        \"with\",",
            "        \"authorization\",",
            "        \"between\",",
            "        \"binary\",",
            "        \"cross\",",
            "        \"current_schema\",",
            "        \"freeze\",",
            "        \"full\",",
            "        \"ilike\",",
            "        \"inner\",",
            "        \"is\",",
            "        \"isnull\",",
            "        \"join\",",
            "        \"left\",",
            "        \"like\",",
            "        \"natural\",",
            "        \"notnull\",",
            "        \"outer\",",
            "        \"over\",",
            "        \"overlaps\",",
            "        \"right\",",
            "        \"similar\",",
            "        \"verbose\",",
            "    ]",
            ")",
            "",
            "_DECIMAL_TYPES = (1231, 1700)",
            "_FLOAT_TYPES = (700, 701, 1021, 1022)",
            "_INT_TYPES = (20, 21, 23, 26, 1005, 1007, 1016)",
            "",
            "",
            "class BYTEA(sqltypes.LargeBinary):",
            "    __visit_name__ = \"BYTEA\"",
            "",
            "",
            "class DOUBLE_PRECISION(sqltypes.Float):",
            "    __visit_name__ = \"DOUBLE_PRECISION\"",
            "",
            "",
            "class INET(sqltypes.TypeEngine):",
            "    __visit_name__ = \"INET\"",
            "",
            "",
            "PGInet = INET",
            "",
            "",
            "class CIDR(sqltypes.TypeEngine):",
            "    __visit_name__ = \"CIDR\"",
            "",
            "",
            "PGCidr = CIDR",
            "",
            "",
            "class MACADDR(sqltypes.TypeEngine):",
            "    __visit_name__ = \"MACADDR\"",
            "",
            "",
            "PGMacAddr = MACADDR",
            "",
            "",
            "class MONEY(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL MONEY type.",
            "",
            "    .. versionadded:: 1.2",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"MONEY\"",
            "",
            "",
            "class OID(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL OID type.",
            "",
            "    .. versionadded:: 0.9.5",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"OID\"",
            "",
            "",
            "class REGCLASS(sqltypes.TypeEngine):",
            "",
            "    \"\"\"Provide the PostgreSQL REGCLASS type.",
            "",
            "    .. versionadded:: 1.2.7",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"REGCLASS\"",
            "",
            "",
            "class TIMESTAMP(sqltypes.TIMESTAMP):",
            "    def __init__(self, timezone=False, precision=None):",
            "        super(TIMESTAMP, self).__init__(timezone=timezone)",
            "        self.precision = precision",
            "",
            "",
            "class TIME(sqltypes.TIME):",
            "    def __init__(self, timezone=False, precision=None):",
            "        super(TIME, self).__init__(timezone=timezone)",
            "        self.precision = precision",
            "",
            "",
            "class INTERVAL(sqltypes.NativeForEmulated, sqltypes._AbstractInterval):",
            "",
            "    \"\"\"PostgreSQL INTERVAL type.",
            "",
            "    The INTERVAL type may not be supported on all DBAPIs.",
            "    It is known to work on psycopg2 and not pg8000 or zxjdbc.",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"INTERVAL\"",
            "    native = True",
            "",
            "    def __init__(self, precision=None, fields=None):",
            "        \"\"\"Construct an INTERVAL.",
            "",
            "        :param precision: optional integer precision value",
            "        :param fields: string fields specifier.  allows storage of fields",
            "         to be limited, such as ``\"YEAR\"``, ``\"MONTH\"``, ``\"DAY TO HOUR\"``,",
            "         etc.",
            "",
            "         .. versionadded:: 1.2",
            "",
            "        \"\"\"",
            "        self.precision = precision",
            "        self.fields = fields",
            "",
            "    @classmethod",
            "    def adapt_emulated_to_native(cls, interval, **kw):",
            "        return INTERVAL(precision=interval.second_precision)",
            "",
            "    @property",
            "    def _type_affinity(self):",
            "        return sqltypes.Interval",
            "",
            "    @property",
            "    def python_type(self):",
            "        return dt.timedelta",
            "",
            "",
            "PGInterval = INTERVAL",
            "",
            "",
            "class BIT(sqltypes.TypeEngine):",
            "    __visit_name__ = \"BIT\"",
            "",
            "    def __init__(self, length=None, varying=False):",
            "        if not varying:",
            "            # BIT without VARYING defaults to length 1",
            "            self.length = length or 1",
            "        else:",
            "            # but BIT VARYING can be unlimited-length, so no default",
            "            self.length = length",
            "        self.varying = varying",
            "",
            "",
            "PGBit = BIT",
            "",
            "",
            "class UUID(sqltypes.TypeEngine):",
            "",
            "    \"\"\"PostgreSQL UUID type.",
            "",
            "    Represents the UUID column type, interpreting",
            "    data either as natively returned by the DBAPI",
            "    or as Python uuid objects.",
            "",
            "    The UUID type may not be supported on all DBAPIs.",
            "    It is known to work on psycopg2 and not pg8000.",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"UUID\"",
            "",
            "    def __init__(self, as_uuid=False):",
            "        \"\"\"Construct a UUID type.",
            "",
            "",
            "        :param as_uuid=False: if True, values will be interpreted",
            "         as Python uuid objects, converting to/from string via the",
            "         DBAPI.",
            "",
            "         \"\"\"",
            "        if as_uuid and _python_UUID is None:",
            "            raise NotImplementedError(",
            "                \"This version of Python does not support \"",
            "                \"the native UUID type.\"",
            "            )",
            "        self.as_uuid = as_uuid",
            "",
            "    def bind_processor(self, dialect):",
            "        if self.as_uuid:",
            "",
            "            def process(value):",
            "                if value is not None:",
            "                    value = util.text_type(value)",
            "                return value",
            "",
            "            return process",
            "        else:",
            "            return None",
            "",
            "    def result_processor(self, dialect, coltype):",
            "        if self.as_uuid:",
            "",
            "            def process(value):",
            "                if value is not None:",
            "                    value = _python_UUID(value)",
            "                return value",
            "",
            "            return process",
            "        else:",
            "            return None",
            "",
            "",
            "PGUuid = UUID",
            "",
            "",
            "class TSVECTOR(sqltypes.TypeEngine):",
            "",
            "    \"\"\"The :class:`.postgresql.TSVECTOR` type implements the PostgreSQL",
            "    text search type TSVECTOR.",
            "",
            "    It can be used to do full text queries on natural language",
            "    documents.",
            "",
            "    .. versionadded:: 0.9.0",
            "",
            "    .. seealso::",
            "",
            "        :ref:`postgresql_match`",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"TSVECTOR\"",
            "",
            "",
            "class ENUM(sqltypes.NativeForEmulated, sqltypes.Enum):",
            "",
            "    \"\"\"PostgreSQL ENUM type.",
            "",
            "    This is a subclass of :class:`.types.Enum` which includes",
            "    support for PG's ``CREATE TYPE`` and ``DROP TYPE``.",
            "",
            "    When the builtin type :class:`.types.Enum` is used and the",
            "    :paramref:`.Enum.native_enum` flag is left at its default of",
            "    True, the PostgreSQL backend will use a :class:`.postgresql.ENUM`",
            "    type as the implementation, so the special create/drop rules",
            "    will be used.",
            "",
            "    The create/drop behavior of ENUM is necessarily intricate, due to the",
            "    awkward relationship the ENUM type has in relationship to the",
            "    parent table, in that it may be \"owned\" by just a single table, or",
            "    may be shared among many tables.",
            "",
            "    When using :class:`.types.Enum` or :class:`.postgresql.ENUM`",
            "    in an \"inline\" fashion, the ``CREATE TYPE`` and ``DROP TYPE`` is emitted",
            "    corresponding to when the :meth:`.Table.create` and :meth:`.Table.drop`",
            "    methods are called::",
            "",
            "        table = Table('sometable', metadata,",
            "            Column('some_enum', ENUM('a', 'b', 'c', name='myenum'))",
            "        )",
            "",
            "        table.create(engine)  # will emit CREATE ENUM and CREATE TABLE",
            "        table.drop(engine)  # will emit DROP TABLE and DROP ENUM",
            "",
            "    To use a common enumerated type between multiple tables, the best",
            "    practice is to declare the :class:`.types.Enum` or",
            "    :class:`.postgresql.ENUM` independently, and associate it with the",
            "    :class:`.MetaData` object itself::",
            "",
            "        my_enum = ENUM('a', 'b', 'c', name='myenum', metadata=metadata)",
            "",
            "        t1 = Table('sometable_one', metadata,",
            "            Column('some_enum', myenum)",
            "        )",
            "",
            "        t2 = Table('sometable_two', metadata,",
            "            Column('some_enum', myenum)",
            "        )",
            "",
            "    When this pattern is used, care must still be taken at the level",
            "    of individual table creates.  Emitting CREATE TABLE without also",
            "    specifying ``checkfirst=True`` will still cause issues::",
            "",
            "        t1.create(engine) # will fail: no such type 'myenum'",
            "",
            "    If we specify ``checkfirst=True``, the individual table-level create",
            "    operation will check for the ``ENUM`` and create if not exists::",
            "",
            "        # will check if enum exists, and emit CREATE TYPE if not",
            "        t1.create(engine, checkfirst=True)",
            "",
            "    When using a metadata-level ENUM type, the type will always be created",
            "    and dropped if either the metadata-wide create/drop is called::",
            "",
            "        metadata.create_all(engine)  # will emit CREATE TYPE",
            "        metadata.drop_all(engine)  # will emit DROP TYPE",
            "",
            "    The type can also be created and dropped directly::",
            "",
            "        my_enum.create(engine)",
            "        my_enum.drop(engine)",
            "",
            "    .. versionchanged:: 1.0.0 The PostgreSQL :class:`.postgresql.ENUM` type",
            "       now behaves more strictly with regards to CREATE/DROP.  A metadata-level",
            "       ENUM type will only be created and dropped at the metadata level,",
            "       not the table level, with the exception of",
            "       ``table.create(checkfirst=True)``.",
            "       The ``table.drop()`` call will now emit a DROP TYPE for a table-level",
            "       enumerated type.",
            "",
            "    \"\"\"",
            "",
            "    native_enum = True",
            "",
            "    def __init__(self, *enums, **kw):",
            "        \"\"\"Construct an :class:`~.postgresql.ENUM`.",
            "",
            "        Arguments are the same as that of",
            "        :class:`.types.Enum`, but also including",
            "        the following parameters.",
            "",
            "        :param create_type: Defaults to True.",
            "         Indicates that ``CREATE TYPE`` should be",
            "         emitted, after optionally checking for the",
            "         presence of the type, when the parent",
            "         table is being created; and additionally",
            "         that ``DROP TYPE`` is called when the table",
            "         is dropped.    When ``False``, no check",
            "         will be performed and no ``CREATE TYPE``",
            "         or ``DROP TYPE`` is emitted, unless",
            "         :meth:`~.postgresql.ENUM.create`",
            "         or :meth:`~.postgresql.ENUM.drop`",
            "         are called directly.",
            "         Setting to ``False`` is helpful",
            "         when invoking a creation scheme to a SQL file",
            "         without access to the actual database -",
            "         the :meth:`~.postgresql.ENUM.create` and",
            "         :meth:`~.postgresql.ENUM.drop` methods can",
            "         be used to emit SQL to a target bind.",
            "",
            "        \"\"\"",
            "        self.create_type = kw.pop(\"create_type\", True)",
            "        super(ENUM, self).__init__(*enums, **kw)",
            "",
            "    @classmethod",
            "    def adapt_emulated_to_native(cls, impl, **kw):",
            "        \"\"\"Produce a PostgreSQL native :class:`.postgresql.ENUM` from plain",
            "        :class:`.Enum`.",
            "",
            "        \"\"\"",
            "        kw.setdefault(\"validate_strings\", impl.validate_strings)",
            "        kw.setdefault(\"name\", impl.name)",
            "        kw.setdefault(\"schema\", impl.schema)",
            "        kw.setdefault(\"inherit_schema\", impl.inherit_schema)",
            "        kw.setdefault(\"metadata\", impl.metadata)",
            "        kw.setdefault(\"_create_events\", False)",
            "        kw.setdefault(\"values_callable\", impl.values_callable)",
            "        return cls(**kw)",
            "",
            "    def create(self, bind=None, checkfirst=True):",
            "        \"\"\"Emit ``CREATE TYPE`` for this",
            "        :class:`~.postgresql.ENUM`.",
            "",
            "        If the underlying dialect does not support",
            "        PostgreSQL CREATE TYPE, no action is taken.",
            "",
            "        :param bind: a connectable :class:`.Engine`,",
            "         :class:`.Connection`, or similar object to emit",
            "         SQL.",
            "        :param checkfirst: if ``True``, a query against",
            "         the PG catalog will be first performed to see",
            "         if the type does not exist already before",
            "         creating.",
            "",
            "        \"\"\"",
            "        if not bind.dialect.supports_native_enum:",
            "            return",
            "",
            "        if not checkfirst or not bind.dialect.has_type(",
            "            bind, self.name, schema=self.schema",
            "        ):",
            "            bind.execute(CreateEnumType(self))",
            "",
            "    def drop(self, bind=None, checkfirst=True):",
            "        \"\"\"Emit ``DROP TYPE`` for this",
            "        :class:`~.postgresql.ENUM`.",
            "",
            "        If the underlying dialect does not support",
            "        PostgreSQL DROP TYPE, no action is taken.",
            "",
            "        :param bind: a connectable :class:`.Engine`,",
            "         :class:`.Connection`, or similar object to emit",
            "         SQL.",
            "        :param checkfirst: if ``True``, a query against",
            "         the PG catalog will be first performed to see",
            "         if the type actually exists before dropping.",
            "",
            "        \"\"\"",
            "        if not bind.dialect.supports_native_enum:",
            "            return",
            "",
            "        if not checkfirst or bind.dialect.has_type(",
            "            bind, self.name, schema=self.schema",
            "        ):",
            "            bind.execute(DropEnumType(self))",
            "",
            "    def _check_for_name_in_memos(self, checkfirst, kw):",
            "        \"\"\"Look in the 'ddl runner' for 'memos', then",
            "        note our name in that collection.",
            "",
            "        This to ensure a particular named enum is operated",
            "        upon only once within any kind of create/drop",
            "        sequence without relying upon \"checkfirst\".",
            "",
            "        \"\"\"",
            "        if not self.create_type:",
            "            return True",
            "        if \"_ddl_runner\" in kw:",
            "            ddl_runner = kw[\"_ddl_runner\"]",
            "            if \"_pg_enums\" in ddl_runner.memo:",
            "                pg_enums = ddl_runner.memo[\"_pg_enums\"]",
            "            else:",
            "                pg_enums = ddl_runner.memo[\"_pg_enums\"] = set()",
            "            present = (self.schema, self.name) in pg_enums",
            "            pg_enums.add((self.schema, self.name))",
            "            return present",
            "        else:",
            "            return False",
            "",
            "    def _on_table_create(self, target, bind, checkfirst=False, **kw):",
            "        if (",
            "            checkfirst",
            "            or (",
            "                not self.metadata",
            "                and not kw.get(\"_is_metadata_operation\", False)",
            "            )",
            "            and not self._check_for_name_in_memos(checkfirst, kw)",
            "        ):",
            "            self.create(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_table_drop(self, target, bind, checkfirst=False, **kw):",
            "        if (",
            "            not self.metadata",
            "            and not kw.get(\"_is_metadata_operation\", False)",
            "            and not self._check_for_name_in_memos(checkfirst, kw)",
            "        ):",
            "            self.drop(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_metadata_create(self, target, bind, checkfirst=False, **kw):",
            "        if not self._check_for_name_in_memos(checkfirst, kw):",
            "            self.create(bind=bind, checkfirst=checkfirst)",
            "",
            "    def _on_metadata_drop(self, target, bind, checkfirst=False, **kw):",
            "        if not self._check_for_name_in_memos(checkfirst, kw):",
            "            self.drop(bind=bind, checkfirst=checkfirst)",
            "",
            "",
            "colspecs = {sqltypes.Interval: INTERVAL, sqltypes.Enum: ENUM}",
            "",
            "ischema_names = {",
            "    \"integer\": INTEGER,",
            "    \"bigint\": BIGINT,",
            "    \"smallint\": SMALLINT,",
            "    \"character varying\": VARCHAR,",
            "    \"character\": CHAR,",
            "    '\"char\"': sqltypes.String,",
            "    \"name\": sqltypes.String,",
            "    \"text\": TEXT,",
            "    \"numeric\": NUMERIC,",
            "    \"float\": FLOAT,",
            "    \"real\": REAL,",
            "    \"inet\": INET,",
            "    \"cidr\": CIDR,",
            "    \"uuid\": UUID,",
            "    \"bit\": BIT,",
            "    \"bit varying\": BIT,",
            "    \"macaddr\": MACADDR,",
            "    \"money\": MONEY,",
            "    \"oid\": OID,",
            "    \"regclass\": REGCLASS,",
            "    \"double precision\": DOUBLE_PRECISION,",
            "    \"timestamp\": TIMESTAMP,",
            "    \"timestamp with time zone\": TIMESTAMP,",
            "    \"timestamp without time zone\": TIMESTAMP,",
            "    \"time with time zone\": TIME,",
            "    \"time without time zone\": TIME,",
            "    \"date\": DATE,",
            "    \"time\": TIME,",
            "    \"bytea\": BYTEA,",
            "    \"boolean\": BOOLEAN,",
            "    \"interval\": INTERVAL,",
            "    \"tsvector\": TSVECTOR,",
            "}",
            "",
            "",
            "class PGCompiler(compiler.SQLCompiler):",
            "    def visit_array(self, element, **kw):",
            "        return \"ARRAY[%s]\" % self.visit_clauselist(element, **kw)",
            "",
            "    def visit_slice(self, element, **kw):",
            "        return \"%s:%s\" % (",
            "            self.process(element.start, **kw),",
            "            self.process(element.stop, **kw),",
            "        )",
            "",
            "    def visit_json_getitem_op_binary(self, binary, operator, **kw):",
            "        kw[\"eager_grouping\"] = True",
            "        return self._generate_generic_binary(binary, \" -> \", **kw)",
            "",
            "    def visit_json_path_getitem_op_binary(self, binary, operator, **kw):",
            "        kw[\"eager_grouping\"] = True",
            "        return self._generate_generic_binary(binary, \" #> \", **kw)",
            "",
            "    def visit_getitem_binary(self, binary, operator, **kw):",
            "        return \"%s[%s]\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_aggregate_order_by(self, element, **kw):",
            "        return \"%s ORDER BY %s\" % (",
            "            self.process(element.target, **kw),",
            "            self.process(element.order_by, **kw),",
            "        )",
            "",
            "    def visit_match_op_binary(self, binary, operator, **kw):",
            "        if \"postgresql_regconfig\" in binary.modifiers:",
            "            regconfig = self.render_literal_value(",
            "                binary.modifiers[\"postgresql_regconfig\"], sqltypes.STRINGTYPE",
            "            )",
            "            if regconfig:",
            "                return \"%s @@ to_tsquery(%s, %s)\" % (",
            "                    self.process(binary.left, **kw),",
            "                    regconfig,",
            "                    self.process(binary.right, **kw),",
            "                )",
            "        return \"%s @@ to_tsquery(%s)\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_ilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "",
            "        return \"%s ILIKE %s\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"%s NOT ILIKE %s\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_empty_set_expr(self, element_types):",
            "        # cast the empty set to the type we are comparing against.  if",
            "        # we are comparing against the null type, pick an arbitrary",
            "        # datatype for the empty set",
            "        return \"SELECT %s WHERE 1!=1\" % (",
            "            \", \".join(",
            "                \"CAST(NULL AS %s)\"",
            "                % self.dialect.type_compiler.process(",
            "                    INTEGER() if type_._isnull else type_",
            "                )",
            "                for type_ in element_types or [INTEGER()]",
            "            ),",
            "        )",
            "",
            "    def render_literal_value(self, value, type_):",
            "        value = super(PGCompiler, self).render_literal_value(value, type_)",
            "",
            "        if self.dialect._backslash_escapes:",
            "            value = value.replace(\"\\\\\", \"\\\\\\\\\")",
            "        return value",
            "",
            "    def visit_sequence(self, seq, **kw):",
            "        return \"nextval('%s')\" % self.preparer.format_sequence(seq)",
            "",
            "    def limit_clause(self, select, **kw):",
            "        text = \"\"",
            "        if select._limit_clause is not None:",
            "            text += \" \\n LIMIT \" + self.process(select._limit_clause, **kw)",
            "        if select._offset_clause is not None:",
            "            if select._limit_clause is None:",
            "                text += \" \\n LIMIT ALL\"",
            "            text += \" OFFSET \" + self.process(select._offset_clause, **kw)",
            "        return text",
            "",
            "    def format_from_hint_text(self, sqltext, table, hint, iscrud):",
            "        if hint.upper() != \"ONLY\":",
            "            raise exc.CompileError(\"Unrecognized hint: %r\" % hint)",
            "        return \"ONLY \" + sqltext",
            "",
            "    def get_select_precolumns(self, select, **kw):",
            "        if select._distinct is not False:",
            "            if select._distinct is True:",
            "                return \"DISTINCT \"",
            "            elif isinstance(select._distinct, (list, tuple)):",
            "                return (",
            "                    \"DISTINCT ON (\"",
            "                    + \", \".join(",
            "                        [self.process(col, **kw) for col in select._distinct]",
            "                    )",
            "                    + \") \"",
            "                )",
            "            else:",
            "                return (",
            "                    \"DISTINCT ON (\"",
            "                    + self.process(select._distinct, **kw)",
            "                    + \") \"",
            "                )",
            "        else:",
            "            return \"\"",
            "",
            "    def for_update_clause(self, select, **kw):",
            "",
            "        if select._for_update_arg.read:",
            "            if select._for_update_arg.key_share:",
            "                tmp = \" FOR KEY SHARE\"",
            "            else:",
            "                tmp = \" FOR SHARE\"",
            "        elif select._for_update_arg.key_share:",
            "            tmp = \" FOR NO KEY UPDATE\"",
            "        else:",
            "            tmp = \" FOR UPDATE\"",
            "",
            "        if select._for_update_arg.of:",
            "            tables = util.OrderedSet(",
            "                c.table if isinstance(c, expression.ColumnClause) else c",
            "                for c in select._for_update_arg.of",
            "            )",
            "            tmp += \" OF \" + \", \".join(",
            "                self.process(table, ashint=True, use_schema=False, **kw)",
            "                for table in tables",
            "            )",
            "",
            "        if select._for_update_arg.nowait:",
            "            tmp += \" NOWAIT\"",
            "        if select._for_update_arg.skip_locked:",
            "            tmp += \" SKIP LOCKED\"",
            "",
            "        return tmp",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "",
            "        columns = [",
            "            self._label_select_column(None, c, True, False, {})",
            "            for c in expression._select_iterables(returning_cols)",
            "        ]",
            "",
            "        return \"RETURNING \" + \", \".join(columns)",
            "",
            "    def visit_substring_func(self, func, **kw):",
            "        s = self.process(func.clauses.clauses[0], **kw)",
            "        start = self.process(func.clauses.clauses[1], **kw)",
            "        if len(func.clauses.clauses) > 2:",
            "            length = self.process(func.clauses.clauses[2], **kw)",
            "            return \"SUBSTRING(%s FROM %s FOR %s)\" % (s, start, length)",
            "        else:",
            "            return \"SUBSTRING(%s FROM %s)\" % (s, start)",
            "",
            "    def _on_conflict_target(self, clause, **kw):",
            "",
            "        if clause.constraint_target is not None:",
            "            target_text = \"ON CONSTRAINT %s\" % clause.constraint_target",
            "        elif clause.inferred_target_elements is not None:",
            "            target_text = \"(%s)\" % \", \".join(",
            "                (",
            "                    self.preparer.quote(c)",
            "                    if isinstance(c, util.string_types)",
            "                    else self.process(c, include_table=False, use_schema=False)",
            "                )",
            "                for c in clause.inferred_target_elements",
            "            )",
            "            if clause.inferred_target_whereclause is not None:",
            "                target_text += \" WHERE %s\" % self.process(",
            "                    clause.inferred_target_whereclause,",
            "                    include_table=False,",
            "                    use_schema=False,",
            "                )",
            "        else:",
            "            target_text = \"\"",
            "",
            "        return target_text",
            "",
            "    def visit_on_conflict_do_nothing(self, on_conflict, **kw):",
            "",
            "        target_text = self._on_conflict_target(on_conflict, **kw)",
            "",
            "        if target_text:",
            "            return \"ON CONFLICT %s DO NOTHING\" % target_text",
            "        else:",
            "            return \"ON CONFLICT DO NOTHING\"",
            "",
            "    def visit_on_conflict_do_update(self, on_conflict, **kw):",
            "",
            "        clause = on_conflict",
            "",
            "        target_text = self._on_conflict_target(on_conflict, **kw)",
            "",
            "        action_set_ops = []",
            "",
            "        set_parameters = dict(clause.update_values_to_set)",
            "        # create a list of column assignment clauses as tuples",
            "",
            "        insert_statement = self.stack[-1][\"selectable\"]",
            "        cols = insert_statement.table.c",
            "        for c in cols:",
            "            col_key = c.key",
            "            if col_key in set_parameters:",
            "                value = set_parameters.pop(col_key)",
            "                if elements._is_literal(value):",
            "                    value = elements.BindParameter(None, value, type_=c.type)",
            "",
            "                else:",
            "                    if (",
            "                        isinstance(value, elements.BindParameter)",
            "                        and value.type._isnull",
            "                    ):",
            "                        value = value._clone()",
            "                        value.type = c.type",
            "                value_text = self.process(value.self_group(), use_schema=False)",
            "",
            "                key_text = self.preparer.quote(col_key)",
            "                action_set_ops.append(\"%s = %s\" % (key_text, value_text))",
            "",
            "        # check for names that don't match columns",
            "        if set_parameters:",
            "            util.warn(",
            "                \"Additional column names not matching \"",
            "                \"any column keys in table '%s': %s\"",
            "                % (",
            "                    self.statement.table.name,",
            "                    (\", \".join(\"'%s'\" % c for c in set_parameters)),",
            "                )",
            "            )",
            "            for k, v in set_parameters.items():",
            "                key_text = (",
            "                    self.preparer.quote(k)",
            "                    if isinstance(k, util.string_types)",
            "                    else self.process(k, use_schema=False)",
            "                )",
            "                value_text = self.process(",
            "                    elements._literal_as_binds(v), use_schema=False",
            "                )",
            "                action_set_ops.append(\"%s = %s\" % (key_text, value_text))",
            "",
            "        action_text = \", \".join(action_set_ops)",
            "        if clause.update_whereclause is not None:",
            "            action_text += \" WHERE %s\" % self.process(",
            "                clause.update_whereclause, include_table=True, use_schema=False",
            "            )",
            "",
            "        return \"ON CONFLICT %s DO UPDATE SET %s\" % (target_text, action_text)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \"FROM \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "    def delete_extra_from_clause(",
            "        self, delete_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Render the DELETE .. USING clause specific to PostgreSQL.\"\"\"",
            "        return \"USING \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "",
            "class PGDDLCompiler(compiler.DDLCompiler):",
            "    def get_column_specification(self, column, **kwargs):",
            "",
            "        colspec = self.preparer.format_column(column)",
            "        impl_type = column.type.dialect_impl(self.dialect)",
            "        if isinstance(impl_type, sqltypes.TypeDecorator):",
            "            impl_type = impl_type.impl",
            "",
            "        if (",
            "            column.primary_key",
            "            and column is column.table._autoincrement_column",
            "            and (",
            "                self.dialect.supports_smallserial",
            "                or not isinstance(impl_type, sqltypes.SmallInteger)",
            "            )",
            "            and (",
            "                column.default is None",
            "                or (",
            "                    isinstance(column.default, schema.Sequence)",
            "                    and column.default.optional",
            "                )",
            "            )",
            "        ):",
            "            if isinstance(impl_type, sqltypes.BigInteger):",
            "                colspec += \" BIGSERIAL\"",
            "            elif isinstance(impl_type, sqltypes.SmallInteger):",
            "                colspec += \" SMALLSERIAL\"",
            "            else:",
            "                colspec += \" SERIAL\"",
            "        else:",
            "            colspec += \" \" + self.dialect.type_compiler.process(",
            "                column.type, type_expression=column",
            "            )",
            "            default = self.get_column_default_string(column)",
            "            if default is not None:",
            "                colspec += \" DEFAULT \" + default",
            "",
            "        if not column.nullable:",
            "            colspec += \" NOT NULL\"",
            "        return colspec",
            "",
            "    def visit_drop_table_comment(self, drop):",
            "        return \"COMMENT ON TABLE %s IS NULL\" % self.preparer.format_table(",
            "            drop.element",
            "        )",
            "",
            "    def visit_create_enum_type(self, create):",
            "        type_ = create.element",
            "",
            "        return \"CREATE TYPE %s AS ENUM (%s)\" % (",
            "            self.preparer.format_type(type_),",
            "            \", \".join(",
            "                self.sql_compiler.process(sql.literal(e), literal_binds=True)",
            "                for e in type_.enums",
            "            ),",
            "        )",
            "",
            "    def visit_drop_enum_type(self, drop):",
            "        type_ = drop.element",
            "",
            "        return \"DROP TYPE %s\" % (self.preparer.format_type(type_))",
            "",
            "    def visit_create_index(self, create):",
            "        preparer = self.preparer",
            "        index = create.element",
            "        self._verify_index_table(index)",
            "        text = \"CREATE \"",
            "        if index.unique:",
            "            text += \"UNIQUE \"",
            "        text += \"INDEX \"",
            "",
            "        if self.dialect._supports_create_index_concurrently:",
            "            concurrently = index.dialect_options[\"postgresql\"][\"concurrently\"]",
            "            if concurrently:",
            "                text += \"CONCURRENTLY \"",
            "",
            "        text += \"%s ON %s \" % (",
            "            self._prepared_index_name(index, include_schema=False),",
            "            preparer.format_table(index.table),",
            "        )",
            "",
            "        using = index.dialect_options[\"postgresql\"][\"using\"]",
            "        if using:",
            "            text += (",
            "                \"USING %s \"",
            "                % self.preparer.validate_sql_phrase(using, IDX_USING).lower()",
            "            )",
            "",
            "        ops = index.dialect_options[\"postgresql\"][\"ops\"]",
            "        text += \"(%s)\" % (",
            "            \", \".join(",
            "                [",
            "                    self.sql_compiler.process(",
            "                        expr.self_group()",
            "                        if not isinstance(expr, expression.ColumnClause)",
            "                        else expr,",
            "                        include_table=False,",
            "                        literal_binds=True,",
            "                    )",
            "                    + (",
            "                        (\" \" + ops[expr.key])",
            "                        if hasattr(expr, \"key\") and expr.key in ops",
            "                        else \"\"",
            "                    )",
            "                    for expr in index.expressions",
            "                ]",
            "            )",
            "        )",
            "",
            "        withclause = index.dialect_options[\"postgresql\"][\"with\"]",
            "",
            "        if withclause:",
            "            text += \" WITH (%s)\" % (",
            "                \", \".join(",
            "                    [",
            "                        \"%s = %s\" % storage_parameter",
            "                        for storage_parameter in withclause.items()",
            "                    ]",
            "                )",
            "            )",
            "",
            "        tablespace_name = index.dialect_options[\"postgresql\"][\"tablespace\"]",
            "",
            "        if tablespace_name:",
            "            text += \" TABLESPACE %s\" % preparer.quote(tablespace_name)",
            "",
            "        whereclause = index.dialect_options[\"postgresql\"][\"where\"]",
            "",
            "        if whereclause is not None:",
            "            where_compiled = self.sql_compiler.process(",
            "                whereclause, include_table=False, literal_binds=True",
            "            )",
            "            text += \" WHERE \" + where_compiled",
            "        return text",
            "",
            "    def visit_drop_index(self, drop):",
            "        index = drop.element",
            "",
            "        text = \"\\nDROP INDEX \"",
            "",
            "        if self.dialect._supports_drop_index_concurrently:",
            "            concurrently = index.dialect_options[\"postgresql\"][\"concurrently\"]",
            "            if concurrently:",
            "                text += \"CONCURRENTLY \"",
            "",
            "        text += self._prepared_index_name(index, include_schema=True)",
            "        return text",
            "",
            "    def visit_exclude_constraint(self, constraint, **kw):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            text += \"CONSTRAINT %s \" % self.preparer.format_constraint(",
            "                constraint",
            "            )",
            "        elements = []",
            "        for expr, name, op in constraint._render_exprs:",
            "            kw[\"include_table\"] = False",
            "            elements.append(",
            "                \"%s WITH %s\" % (self.sql_compiler.process(expr, **kw), op)",
            "            )",
            "        text += \"EXCLUDE USING %s (%s)\" % (",
            "            self.preparer.validate_sql_phrase(",
            "                constraint.using, IDX_USING",
            "            ).lower(),",
            "            \", \".join(elements),",
            "        )",
            "        if constraint.where is not None:",
            "            text += \" WHERE (%s)\" % self.sql_compiler.process(",
            "                constraint.where, literal_binds=True",
            "            )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def post_create_table(self, table):",
            "        table_opts = []",
            "        pg_opts = table.dialect_options[\"postgresql\"]",
            "",
            "        inherits = pg_opts.get(\"inherits\")",
            "        if inherits is not None:",
            "            if not isinstance(inherits, (list, tuple)):",
            "                inherits = (inherits,)",
            "            table_opts.append(",
            "                \"\\n INHERITS ( \"",
            "                + \", \".join(self.preparer.quote(name) for name in inherits)",
            "                + \" )\"",
            "            )",
            "",
            "        if pg_opts[\"partition_by\"]:",
            "            table_opts.append(\"\\n PARTITION BY %s\" % pg_opts[\"partition_by\"])",
            "",
            "        if pg_opts[\"with_oids\"] is True:",
            "            table_opts.append(\"\\n WITH OIDS\")",
            "        elif pg_opts[\"with_oids\"] is False:",
            "            table_opts.append(\"\\n WITHOUT OIDS\")",
            "",
            "        if pg_opts[\"on_commit\"]:",
            "            on_commit_options = pg_opts[\"on_commit\"].replace(\"_\", \" \").upper()",
            "            table_opts.append(\"\\n ON COMMIT %s\" % on_commit_options)",
            "",
            "        if pg_opts[\"tablespace\"]:",
            "            tablespace_name = pg_opts[\"tablespace\"]",
            "            table_opts.append(",
            "                \"\\n TABLESPACE %s\" % self.preparer.quote(tablespace_name)",
            "            )",
            "",
            "        return \"\".join(table_opts)",
            "",
            "",
            "class PGTypeCompiler(compiler.GenericTypeCompiler):",
            "    def visit_TSVECTOR(self, type_, **kw):",
            "        return \"TSVECTOR\"",
            "",
            "    def visit_INET(self, type_, **kw):",
            "        return \"INET\"",
            "",
            "    def visit_CIDR(self, type_, **kw):",
            "        return \"CIDR\"",
            "",
            "    def visit_MACADDR(self, type_, **kw):",
            "        return \"MACADDR\"",
            "",
            "    def visit_MONEY(self, type_, **kw):",
            "        return \"MONEY\"",
            "",
            "    def visit_OID(self, type_, **kw):",
            "        return \"OID\"",
            "",
            "    def visit_REGCLASS(self, type_, **kw):",
            "        return \"REGCLASS\"",
            "",
            "    def visit_FLOAT(self, type_, **kw):",
            "        if not type_.precision:",
            "            return \"FLOAT\"",
            "        else:",
            "            return \"FLOAT(%(precision)s)\" % {\"precision\": type_.precision}",
            "",
            "    def visit_DOUBLE_PRECISION(self, type_, **kw):",
            "        return \"DOUBLE PRECISION\"",
            "",
            "    def visit_BIGINT(self, type_, **kw):",
            "        return \"BIGINT\"",
            "",
            "    def visit_HSTORE(self, type_, **kw):",
            "        return \"HSTORE\"",
            "",
            "    def visit_JSON(self, type_, **kw):",
            "        return \"JSON\"",
            "",
            "    def visit_JSONB(self, type_, **kw):",
            "        return \"JSONB\"",
            "",
            "    def visit_INT4RANGE(self, type_, **kw):",
            "        return \"INT4RANGE\"",
            "",
            "    def visit_INT8RANGE(self, type_, **kw):",
            "        return \"INT8RANGE\"",
            "",
            "    def visit_NUMRANGE(self, type_, **kw):",
            "        return \"NUMRANGE\"",
            "",
            "    def visit_DATERANGE(self, type_, **kw):",
            "        return \"DATERANGE\"",
            "",
            "    def visit_TSRANGE(self, type_, **kw):",
            "        return \"TSRANGE\"",
            "",
            "    def visit_TSTZRANGE(self, type_, **kw):",
            "        return \"TSTZRANGE\"",
            "",
            "    def visit_datetime(self, type_, **kw):",
            "        return self.visit_TIMESTAMP(type_, **kw)",
            "",
            "    def visit_enum(self, type_, **kw):",
            "        if not type_.native_enum or not self.dialect.supports_native_enum:",
            "            return super(PGTypeCompiler, self).visit_enum(type_, **kw)",
            "        else:",
            "            return self.visit_ENUM(type_, **kw)",
            "",
            "    def visit_ENUM(self, type_, **kw):",
            "        return self.dialect.identifier_preparer.format_type(type_)",
            "",
            "    def visit_TIMESTAMP(self, type_, **kw):",
            "        return \"TIMESTAMP%s %s\" % (",
            "            \"(%d)\" % type_.precision",
            "            if getattr(type_, \"precision\", None) is not None",
            "            else \"\",",
            "            (type_.timezone and \"WITH\" or \"WITHOUT\") + \" TIME ZONE\",",
            "        )",
            "",
            "    def visit_TIME(self, type_, **kw):",
            "        return \"TIME%s %s\" % (",
            "            \"(%d)\" % type_.precision",
            "            if getattr(type_, \"precision\", None) is not None",
            "            else \"\",",
            "            (type_.timezone and \"WITH\" or \"WITHOUT\") + \" TIME ZONE\",",
            "        )",
            "",
            "    def visit_INTERVAL(self, type_, **kw):",
            "        text = \"INTERVAL\"",
            "        if type_.fields is not None:",
            "            text += \" \" + type_.fields",
            "        if type_.precision is not None:",
            "            text += \" (%d)\" % type_.precision",
            "        return text",
            "",
            "    def visit_BIT(self, type_, **kw):",
            "        if type_.varying:",
            "            compiled = \"BIT VARYING\"",
            "            if type_.length is not None:",
            "                compiled += \"(%d)\" % type_.length",
            "        else:",
            "            compiled = \"BIT(%d)\" % type_.length",
            "        return compiled",
            "",
            "    def visit_UUID(self, type_, **kw):",
            "        return \"UUID\"",
            "",
            "    def visit_large_binary(self, type_, **kw):",
            "        return self.visit_BYTEA(type_, **kw)",
            "",
            "    def visit_BYTEA(self, type_, **kw):",
            "        return \"BYTEA\"",
            "",
            "    def visit_ARRAY(self, type_, **kw):",
            "",
            "        # TODO: pass **kw?",
            "        inner = self.process(type_.item_type)",
            "        return re.sub(",
            "            r\"((?: COLLATE.*)?)$\",",
            "            (",
            "                r\"%s\\1\"",
            "                % (",
            "                    \"[]\"",
            "                    * (type_.dimensions if type_.dimensions is not None else 1)",
            "                )",
            "            ),",
            "            inner,",
            "            count=1,",
            "        )",
            "",
            "",
            "class PGIdentifierPreparer(compiler.IdentifierPreparer):",
            "",
            "    reserved_words = RESERVED_WORDS",
            "",
            "    def _unquote_identifier(self, value):",
            "        if value[0] == self.initial_quote:",
            "            value = value[1:-1].replace(",
            "                self.escape_to_quote, self.escape_quote",
            "            )",
            "        return value",
            "",
            "    def format_type(self, type_, use_schema=True):",
            "        if not type_.name:",
            "            raise exc.CompileError(\"PostgreSQL ENUM type requires a name.\")",
            "",
            "        name = self.quote(type_.name)",
            "        effective_schema = self.schema_for_object(type_)",
            "",
            "        if (",
            "            not self.omit_schema",
            "            and use_schema",
            "            and effective_schema is not None",
            "        ):",
            "            name = self.quote_schema(effective_schema) + \".\" + name",
            "        return name",
            "",
            "",
            "class PGInspector(reflection.Inspector):",
            "    def __init__(self, conn):",
            "        reflection.Inspector.__init__(self, conn)",
            "",
            "    def get_table_oid(self, table_name, schema=None):",
            "        \"\"\"Return the OID for the given table name.\"\"\"",
            "",
            "        return self.dialect.get_table_oid(",
            "            self.bind, table_name, schema, info_cache=self.info_cache",
            "        )",
            "",
            "    def get_enums(self, schema=None):",
            "        \"\"\"Return a list of ENUM objects.",
            "",
            "        Each member is a dictionary containing these fields:",
            "",
            "            * name - name of the enum",
            "            * schema - the schema name for the enum.",
            "            * visible - boolean, whether or not this enum is visible",
            "              in the default search path.",
            "            * labels - a list of string labels that apply to the enum.",
            "",
            "        :param schema: schema name.  If None, the default schema",
            "         (typically 'public') is used.  May also be set to '*' to",
            "         indicate load enums for all schemas.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        \"\"\"",
            "        schema = schema or self.default_schema_name",
            "        return self.dialect._load_enums(self.bind, schema)",
            "",
            "    def get_foreign_table_names(self, schema=None):",
            "        \"\"\"Return a list of FOREIGN TABLE names.",
            "",
            "        Behavior is similar to that of :meth:`.Inspector.get_table_names`,",
            "        except that the list is limited to those tables that report a",
            "        ``relkind`` value of ``f``.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        \"\"\"",
            "        schema = schema or self.default_schema_name",
            "        return self.dialect._get_foreign_table_names(self.bind, schema)",
            "",
            "    def get_view_names(self, schema=None, include=(\"plain\", \"materialized\")):",
            "        \"\"\"Return all view names in `schema`.",
            "",
            "        :param schema: Optional, retrieve names from a non-default schema.",
            "         For special quoting, use :class:`.quoted_name`.",
            "",
            "        :param include: specify which types of views to return.  Passed",
            "         as a string value (for a single type) or a tuple (for any number",
            "         of types).  Defaults to ``('plain', 'materialized')``.",
            "",
            "         .. versionadded:: 1.1",
            "",
            "        \"\"\"",
            "",
            "        return self.dialect.get_view_names(",
            "            self.bind, schema, info_cache=self.info_cache, include=include",
            "        )",
            "",
            "",
            "class CreateEnumType(schema._CreateDropBase):",
            "    __visit_name__ = \"create_enum_type\"",
            "",
            "",
            "class DropEnumType(schema._CreateDropBase):",
            "    __visit_name__ = \"drop_enum_type\"",
            "",
            "",
            "class PGExecutionContext(default.DefaultExecutionContext):",
            "    def fire_sequence(self, seq, type_):",
            "        return self._execute_scalar(",
            "            (",
            "                \"select nextval('%s')\"",
            "                % self.dialect.identifier_preparer.format_sequence(seq)",
            "            ),",
            "            type_,",
            "        )",
            "",
            "    def get_insert_default(self, column):",
            "        if column.primary_key and column is column.table._autoincrement_column:",
            "            if column.server_default and column.server_default.has_argument:",
            "",
            "                # pre-execute passive defaults on primary key columns",
            "                return self._execute_scalar(",
            "                    \"select %s\" % column.server_default.arg, column.type",
            "                )",
            "",
            "            elif column.default is None or (",
            "                column.default.is_sequence and column.default.optional",
            "            ):",
            "",
            "                # execute the sequence associated with a SERIAL primary",
            "                # key column. for non-primary-key SERIAL, the ID just",
            "                # generates server side.",
            "",
            "                try:",
            "                    seq_name = column._postgresql_seq_name",
            "                except AttributeError:",
            "                    tab = column.table.name",
            "                    col = column.name",
            "                    tab = tab[0 : 29 + max(0, (29 - len(col)))]",
            "                    col = col[0 : 29 + max(0, (29 - len(tab)))]",
            "                    name = \"%s_%s_seq\" % (tab, col)",
            "                    column._postgresql_seq_name = seq_name = name",
            "",
            "                if column.table is not None:",
            "                    effective_schema = self.connection.schema_for_object(",
            "                        column.table",
            "                    )",
            "                else:",
            "                    effective_schema = None",
            "",
            "                if effective_schema is not None:",
            "                    exc = 'select nextval(\\'\"%s\".\"%s\"\\')' % (",
            "                        effective_schema,",
            "                        seq_name,",
            "                    )",
            "                else:",
            "                    exc = \"select nextval('\\\"%s\\\"')\" % (seq_name,)",
            "",
            "                return self._execute_scalar(exc, column.type)",
            "",
            "        return super(PGExecutionContext, self).get_insert_default(column)",
            "",
            "    def should_autocommit_text(self, statement):",
            "        return AUTOCOMMIT_REGEXP.match(statement)",
            "",
            "",
            "class PGDialect(default.DefaultDialect):",
            "    name = \"postgresql\"",
            "    supports_alter = True",
            "    max_identifier_length = 63",
            "    supports_sane_rowcount = True",
            "",
            "    supports_native_enum = True",
            "    supports_native_boolean = True",
            "    supports_smallserial = True",
            "",
            "    supports_sequences = True",
            "    sequences_optional = True",
            "    preexecute_autoincrement_sequences = True",
            "    postfetch_lastrowid = False",
            "",
            "    supports_comments = True",
            "    supports_default_values = True",
            "    supports_empty_insert = False",
            "    supports_multivalues_insert = True",
            "    default_paramstyle = \"pyformat\"",
            "    ischema_names = ischema_names",
            "    colspecs = colspecs",
            "",
            "    statement_compiler = PGCompiler",
            "    ddl_compiler = PGDDLCompiler",
            "    type_compiler = PGTypeCompiler",
            "    preparer = PGIdentifierPreparer",
            "    execution_ctx_cls = PGExecutionContext",
            "    inspector = PGInspector",
            "    isolation_level = None",
            "",
            "    construct_arguments = [",
            "        (",
            "            schema.Index,",
            "            {",
            "                \"using\": False,",
            "                \"where\": None,",
            "                \"ops\": {},",
            "                \"concurrently\": False,",
            "                \"with\": {},",
            "                \"tablespace\": None,",
            "            },",
            "        ),",
            "        (",
            "            schema.Table,",
            "            {",
            "                \"ignore_search_path\": False,",
            "                \"tablespace\": None,",
            "                \"partition_by\": None,",
            "                \"with_oids\": None,",
            "                \"on_commit\": None,",
            "                \"inherits\": None,",
            "            },",
            "        ),",
            "    ]",
            "",
            "    reflection_options = (\"postgresql_ignore_search_path\",)",
            "",
            "    _backslash_escapes = True",
            "    _supports_create_index_concurrently = True",
            "    _supports_drop_index_concurrently = True",
            "",
            "    def __init__(",
            "        self,",
            "        isolation_level=None,",
            "        json_serializer=None,",
            "        json_deserializer=None,",
            "        **kwargs",
            "    ):",
            "        default.DefaultDialect.__init__(self, **kwargs)",
            "        self.isolation_level = isolation_level",
            "        self._json_deserializer = json_deserializer",
            "        self._json_serializer = json_serializer",
            "",
            "    def initialize(self, connection):",
            "        super(PGDialect, self).initialize(connection)",
            "        self.implicit_returning = self.server_version_info > (",
            "            8,",
            "            2,",
            "        ) and self.__dict__.get(\"implicit_returning\", True)",
            "        self.supports_native_enum = self.server_version_info >= (8, 3)",
            "        if not self.supports_native_enum:",
            "            self.colspecs = self.colspecs.copy()",
            "            # pop base Enum type",
            "            self.colspecs.pop(sqltypes.Enum, None)",
            "            # psycopg2, others may have placed ENUM here as well",
            "            self.colspecs.pop(ENUM, None)",
            "",
            "        # http://www.postgresql.org/docs/9.3/static/release-9-2.html#AEN116689",
            "        self.supports_smallserial = self.server_version_info >= (9, 2)",
            "",
            "        self._backslash_escapes = (",
            "            self.server_version_info < (8, 2)",
            "            or connection.scalar(\"show standard_conforming_strings\") == \"off\"",
            "        )",
            "",
            "        self._supports_create_index_concurrently = (",
            "            self.server_version_info >= (8, 2)",
            "        )",
            "        self._supports_drop_index_concurrently = self.server_version_info >= (",
            "            9,",
            "            2,",
            "        )",
            "",
            "    def on_connect(self):",
            "        if self.isolation_level is not None:",
            "",
            "            def connect(conn):",
            "                self.set_isolation_level(conn, self.isolation_level)",
            "",
            "            return connect",
            "        else:",
            "            return None",
            "",
            "    _isolation_lookup = set(",
            "        [",
            "            \"SERIALIZABLE\",",
            "            \"READ UNCOMMITTED\",",
            "            \"READ COMMITTED\",",
            "            \"REPEATABLE READ\",",
            "        ]",
            "    )",
            "",
            "    def set_isolation_level(self, connection, level):",
            "        level = level.replace(\"_\", \" \")",
            "        if level not in self._isolation_lookup:",
            "            raise exc.ArgumentError(",
            "                \"Invalid value '%s' for isolation_level. \"",
            "                \"Valid isolation levels for %s are %s\"",
            "                % (level, self.name, \", \".join(self._isolation_lookup))",
            "            )",
            "        cursor = connection.cursor()",
            "        cursor.execute(",
            "            \"SET SESSION CHARACTERISTICS AS TRANSACTION \"",
            "            \"ISOLATION LEVEL %s\" % level",
            "        )",
            "        cursor.execute(\"COMMIT\")",
            "        cursor.close()",
            "",
            "    def get_isolation_level(self, connection):",
            "        cursor = connection.cursor()",
            "        cursor.execute(\"show transaction isolation level\")",
            "        val = cursor.fetchone()[0]",
            "        cursor.close()",
            "        return val.upper()",
            "",
            "    def do_begin_twophase(self, connection, xid):",
            "        self.do_begin(connection.connection)",
            "",
            "    def do_prepare_twophase(self, connection, xid):",
            "        connection.execute(\"PREPARE TRANSACTION '%s'\" % xid)",
            "",
            "    def do_rollback_twophase(",
            "        self, connection, xid, is_prepared=True, recover=False",
            "    ):",
            "        if is_prepared:",
            "            if recover:",
            "                # FIXME: ugly hack to get out of transaction",
            "                # context when committing recoverable transactions",
            "                # Must find out a way how to make the dbapi not",
            "                # open a transaction.",
            "                connection.execute(\"ROLLBACK\")",
            "            connection.execute(\"ROLLBACK PREPARED '%s'\" % xid)",
            "            connection.execute(\"BEGIN\")",
            "            self.do_rollback(connection.connection)",
            "        else:",
            "            self.do_rollback(connection.connection)",
            "",
            "    def do_commit_twophase(",
            "        self, connection, xid, is_prepared=True, recover=False",
            "    ):",
            "        if is_prepared:",
            "            if recover:",
            "                connection.execute(\"ROLLBACK\")",
            "            connection.execute(\"COMMIT PREPARED '%s'\" % xid)",
            "            connection.execute(\"BEGIN\")",
            "            self.do_rollback(connection.connection)",
            "        else:",
            "            self.do_commit(connection.connection)",
            "",
            "    def do_recover_twophase(self, connection):",
            "        resultset = connection.execute(",
            "            sql.text(\"SELECT gid FROM pg_prepared_xacts\")",
            "        )",
            "        return [row[0] for row in resultset]",
            "",
            "    def _get_default_schema_name(self, connection):",
            "        return connection.scalar(\"select current_schema()\")",
            "",
            "    def has_schema(self, connection, schema):",
            "        query = (",
            "            \"select nspname from pg_namespace \" \"where lower(nspname)=:schema\"",
            "        )",
            "        cursor = connection.execute(",
            "            sql.text(query).bindparams(",
            "                sql.bindparam(",
            "                    \"schema\",",
            "                    util.text_type(schema.lower()),",
            "                    type_=sqltypes.Unicode,",
            "                )",
            "            )",
            "        )",
            "",
            "        return bool(cursor.first())",
            "",
            "    def has_table(self, connection, table_name, schema=None):",
            "        # seems like case gets folded in pg_class...",
            "        if schema is None:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"select relname from pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where \"",
            "                    \"pg_catalog.pg_table_is_visible(c.oid) \"",
            "                    \"and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(table_name),",
            "                        type_=sqltypes.Unicode,",
            "                    )",
            "                )",
            "            )",
            "        else:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"select relname from pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where n.nspname=:schema and \"",
            "                    \"relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(table_name),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                    sql.bindparam(",
            "                        \"schema\",",
            "                        util.text_type(schema),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                )",
            "            )",
            "        return bool(cursor.first())",
            "",
            "    def has_sequence(self, connection, sequence_name, schema=None):",
            "        if schema is None:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"SELECT relname FROM pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where relkind='S' and \"",
            "                    \"n.nspname=current_schema() \"",
            "                    \"and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(sequence_name),",
            "                        type_=sqltypes.Unicode,",
            "                    )",
            "                )",
            "            )",
            "        else:",
            "            cursor = connection.execute(",
            "                sql.text(",
            "                    \"SELECT relname FROM pg_class c join pg_namespace n on \"",
            "                    \"n.oid=c.relnamespace where relkind='S' and \"",
            "                    \"n.nspname=:schema and relname=:name\"",
            "                ).bindparams(",
            "                    sql.bindparam(",
            "                        \"name\",",
            "                        util.text_type(sequence_name),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                    sql.bindparam(",
            "                        \"schema\",",
            "                        util.text_type(schema),",
            "                        type_=sqltypes.Unicode,",
            "                    ),",
            "                )",
            "            )",
            "",
            "        return bool(cursor.first())",
            "",
            "    def has_type(self, connection, type_name, schema=None):",
            "        if schema is not None:",
            "            query = \"\"\"",
            "            SELECT EXISTS (",
            "                SELECT * FROM pg_catalog.pg_type t, pg_catalog.pg_namespace n",
            "                WHERE t.typnamespace = n.oid",
            "                AND t.typname = :typname",
            "                AND n.nspname = :nspname",
            "                )",
            "                \"\"\"",
            "            query = sql.text(query)",
            "        else:",
            "            query = \"\"\"",
            "            SELECT EXISTS (",
            "                SELECT * FROM pg_catalog.pg_type t",
            "                WHERE t.typname = :typname",
            "                AND pg_type_is_visible(t.oid)",
            "                )",
            "                \"\"\"",
            "            query = sql.text(query)",
            "        query = query.bindparams(",
            "            sql.bindparam(",
            "                \"typname\", util.text_type(type_name), type_=sqltypes.Unicode",
            "            )",
            "        )",
            "        if schema is not None:",
            "            query = query.bindparams(",
            "                sql.bindparam(",
            "                    \"nspname\", util.text_type(schema), type_=sqltypes.Unicode",
            "                )",
            "            )",
            "        cursor = connection.execute(query)",
            "        return bool(cursor.scalar())",
            "",
            "    def _get_server_version_info(self, connection):",
            "        v = connection.execute(\"select version()\").scalar()",
            "        m = re.match(",
            "            r\".*(?:PostgreSQL|EnterpriseDB) \"",
            "            r\"(\\d+)\\.?(\\d+)?(?:\\.(\\d+))?(?:\\.\\d+)?(?:devel|beta)?\",",
            "            v,",
            "        )",
            "        if not m:",
            "            raise AssertionError(",
            "                \"Could not determine version from string '%s'\" % v",
            "            )",
            "        return tuple([int(x) for x in m.group(1, 2, 3) if x is not None])",
            "",
            "    @reflection.cache",
            "    def get_table_oid(self, connection, table_name, schema=None, **kw):",
            "        \"\"\"Fetch the oid for schema.table_name.",
            "",
            "        Several reflection methods require the table oid.  The idea for using",
            "        this method is that it can be fetched one time and cached for",
            "        subsequent calls.",
            "",
            "        \"\"\"",
            "        table_oid = None",
            "        if schema is not None:",
            "            schema_where_clause = \"n.nspname = :schema\"",
            "        else:",
            "            schema_where_clause = \"pg_catalog.pg_table_is_visible(c.oid)\"",
            "        query = (",
            "            \"\"\"",
            "            SELECT c.oid",
            "            FROM pg_catalog.pg_class c",
            "            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace",
            "            WHERE (%s)",
            "            AND c.relname = :table_name AND c.relkind in",
            "            ('r', 'v', 'm', 'f', 'p')",
            "        \"\"\"",
            "            % schema_where_clause",
            "        )",
            "        # Since we're binding to unicode, table_name and schema_name must be",
            "        # unicode.",
            "        table_name = util.text_type(table_name)",
            "        if schema is not None:",
            "            schema = util.text_type(schema)",
            "        s = sql.text(query).bindparams(table_name=sqltypes.Unicode)",
            "        s = s.columns(oid=sqltypes.Integer)",
            "        if schema:",
            "            s = s.bindparams(sql.bindparam(\"schema\", type_=sqltypes.Unicode))",
            "        c = connection.execute(s, table_name=table_name, schema=schema)",
            "        table_oid = c.scalar()",
            "        if table_oid is None:",
            "            raise exc.NoSuchTableError(table_name)",
            "        return table_oid",
            "",
            "    @reflection.cache",
            "    def get_schema_names(self, connection, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT nspname FROM pg_namespace \"",
            "                \"WHERE nspname NOT LIKE 'pg_%' \"",
            "                \"ORDER BY nspname\"",
            "            ).columns(nspname=sqltypes.Unicode)",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_table_names(self, connection, schema=None, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind in ('r', 'p')\"",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def _get_foreign_table_names(self, connection, schema=None, **kw):",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind = 'f'\"",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_view_names(",
            "        self, connection, schema=None, include=(\"plain\", \"materialized\"), **kw",
            "    ):",
            "",
            "        include_kind = {\"plain\": \"v\", \"materialized\": \"m\"}",
            "        try:",
            "            kinds = [include_kind[i] for i in util.to_list(include)]",
            "        except KeyError:",
            "            raise ValueError(",
            "                \"include %r unknown, needs to be a sequence containing \"",
            "                \"one or both of 'plain' and 'materialized'\" % (include,)",
            "            )",
            "        if not kinds:",
            "            raise ValueError(",
            "                \"empty include, needs to be a sequence containing \"",
            "                \"one or both of 'plain' and 'materialized'\"",
            "            )",
            "",
            "        result = connection.execute(",
            "            sql.text(",
            "                \"SELECT c.relname FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relkind IN (%s)\"",
            "                % (\", \".join(\"'%s'\" % elem for elem in kinds))",
            "            ).columns(relname=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "        )",
            "        return [name for name, in result]",
            "",
            "    @reflection.cache",
            "    def get_view_definition(self, connection, view_name, schema=None, **kw):",
            "        view_def = connection.scalar(",
            "            sql.text(",
            "                \"SELECT pg_get_viewdef(c.oid) view_def FROM pg_class c \"",
            "                \"JOIN pg_namespace n ON n.oid = c.relnamespace \"",
            "                \"WHERE n.nspname = :schema AND c.relname = :view_name \"",
            "                \"AND c.relkind IN ('v', 'm')\"",
            "            ).columns(view_def=sqltypes.Unicode),",
            "            schema=schema if schema is not None else self.default_schema_name,",
            "            view_name=view_name,",
            "        )",
            "        return view_def",
            "",
            "    @reflection.cache",
            "    def get_columns(self, connection, table_name, schema=None, **kw):",
            "",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "        SQL_COLS = \"\"\"",
            "            SELECT a.attname,",
            "              pg_catalog.format_type(a.atttypid, a.atttypmod),",
            "              (SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)",
            "                FROM pg_catalog.pg_attrdef d",
            "               WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum",
            "               AND a.atthasdef)",
            "              AS DEFAULT,",
            "              a.attnotnull, a.attnum, a.attrelid as table_oid,",
            "              pgd.description as comment",
            "            FROM pg_catalog.pg_attribute a",
            "            LEFT JOIN pg_catalog.pg_description pgd ON (",
            "                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)",
            "            WHERE a.attrelid = :table_oid",
            "            AND a.attnum > 0 AND NOT a.attisdropped",
            "            ORDER BY a.attnum",
            "        \"\"\"",
            "        s = (",
            "            sql.text(SQL_COLS)",
            "            .bindparams(sql.bindparam(\"table_oid\", type_=sqltypes.Integer))",
            "            .columns(attname=sqltypes.Unicode, default=sqltypes.Unicode)",
            "        )",
            "        c = connection.execute(s, table_oid=table_oid)",
            "        rows = c.fetchall()",
            "",
            "        # dictionary with (name, ) if default search path or (schema, name)",
            "        # as keys",
            "        domains = self._load_domains(connection)",
            "",
            "        # dictionary with (name, ) if default search path or (schema, name)",
            "        # as keys",
            "        enums = dict(",
            "            ((rec[\"name\"],), rec)",
            "            if rec[\"visible\"]",
            "            else ((rec[\"schema\"], rec[\"name\"]), rec)",
            "            for rec in self._load_enums(connection, schema=\"*\")",
            "        )",
            "",
            "        # format columns",
            "        columns = []",
            "",
            "        for (",
            "            name,",
            "            format_type,",
            "            default_,",
            "            notnull,",
            "            attnum,",
            "            table_oid,",
            "            comment,",
            "        ) in rows:",
            "            column_info = self._get_column_info(",
            "                name,",
            "                format_type,",
            "                default_,",
            "                notnull,",
            "                domains,",
            "                enums,",
            "                schema,",
            "                comment,",
            "            )",
            "            columns.append(column_info)",
            "        return columns",
            "",
            "    def _get_column_info(",
            "        self,",
            "        name,",
            "        format_type,",
            "        default,",
            "        notnull,",
            "        domains,",
            "        enums,",
            "        schema,",
            "        comment,",
            "    ):",
            "        def _handle_array_type(attype):",
            "            return (",
            "                # strip '[]' from integer[], etc.",
            "                re.sub(r\"\\[\\]$\", \"\", attype),",
            "                attype.endswith(\"[]\"),",
            "            )",
            "",
            "        # strip (*) from character varying(5), timestamp(5)",
            "        # with time zone, geometry(POLYGON), etc.",
            "        attype = re.sub(r\"\\(.*\\)\", \"\", format_type)",
            "",
            "        # strip '[]' from integer[], etc. and check if an array",
            "        attype, is_array = _handle_array_type(attype)",
            "",
            "        # strip quotes from case sensitive enum or domain names",
            "        enum_or_domain_key = tuple(util.quoted_token_parser(attype))",
            "",
            "        nullable = not notnull",
            "",
            "        charlen = re.search(r\"\\(([\\d,]+)\\)\", format_type)",
            "        if charlen:",
            "            charlen = charlen.group(1)",
            "        args = re.search(r\"\\((.*)\\)\", format_type)",
            "        if args and args.group(1):",
            "            args = tuple(re.split(r\"\\s*,\\s*\", args.group(1)))",
            "        else:",
            "            args = ()",
            "        kwargs = {}",
            "",
            "        if attype == \"numeric\":",
            "            if charlen:",
            "                prec, scale = charlen.split(\",\")",
            "                args = (int(prec), int(scale))",
            "            else:",
            "                args = ()",
            "        elif attype == \"double precision\":",
            "            args = (53,)",
            "        elif attype == \"integer\":",
            "            args = ()",
            "        elif attype in (\"timestamp with time zone\", \"time with time zone\"):",
            "            kwargs[\"timezone\"] = True",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            args = ()",
            "        elif attype in (",
            "            \"timestamp without time zone\",",
            "            \"time without time zone\",",
            "            \"time\",",
            "        ):",
            "            kwargs[\"timezone\"] = False",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            args = ()",
            "        elif attype == \"bit varying\":",
            "            kwargs[\"varying\"] = True",
            "            if charlen:",
            "                args = (int(charlen),)",
            "            else:",
            "                args = ()",
            "        elif attype.startswith(\"interval\"):",
            "            field_match = re.match(r\"interval (.+)\", attype, re.I)",
            "            if charlen:",
            "                kwargs[\"precision\"] = int(charlen)",
            "            if field_match:",
            "                kwargs[\"fields\"] = field_match.group(1)",
            "            attype = \"interval\"",
            "            args = ()",
            "        elif charlen:",
            "            args = (int(charlen),)",
            "",
            "        while True:",
            "            # looping here to suit nested domains",
            "            if attype in self.ischema_names:",
            "                coltype = self.ischema_names[attype]",
            "                break",
            "            elif enum_or_domain_key in enums:",
            "                enum = enums[enum_or_domain_key]",
            "                coltype = ENUM",
            "                kwargs[\"name\"] = enum[\"name\"]",
            "                if not enum[\"visible\"]:",
            "                    kwargs[\"schema\"] = enum[\"schema\"]",
            "                args = tuple(enum[\"labels\"])",
            "                break",
            "            elif enum_or_domain_key in domains:",
            "                domain = domains[enum_or_domain_key]",
            "                attype = domain[\"attype\"]",
            "                attype, is_array = _handle_array_type(attype)",
            "                # strip quotes from case sensitive enum or domain names",
            "                enum_or_domain_key = tuple(util.quoted_token_parser(attype))",
            "                # A table can't override whether the domain is nullable.",
            "                nullable = domain[\"nullable\"]",
            "                if domain[\"default\"] and not default:",
            "                    # It can, however, override the default",
            "                    # value, but can't set it to null.",
            "                    default = domain[\"default\"]",
            "                continue",
            "            else:",
            "                coltype = None",
            "                break",
            "",
            "        if coltype:",
            "            coltype = coltype(*args, **kwargs)",
            "            if is_array:",
            "                coltype = self.ischema_names[\"_array\"](coltype)",
            "        else:",
            "            util.warn(",
            "                \"Did not recognize type '%s' of column '%s'\" % (attype, name)",
            "            )",
            "            coltype = sqltypes.NULLTYPE",
            "        # adjust the default value",
            "        autoincrement = False",
            "        if default is not None:",
            "            match = re.search(r\"\"\"(nextval\\(')([^']+)('.*$)\"\"\", default)",
            "            if match is not None:",
            "                if issubclass(coltype._type_affinity, sqltypes.Integer):",
            "                    autoincrement = True",
            "                # the default is related to a Sequence",
            "                sch = schema",
            "                if \".\" not in match.group(2) and sch is not None:",
            "                    # unconditionally quote the schema name.  this could",
            "                    # later be enhanced to obey quoting rules /",
            "                    # \"quote schema\"",
            "                    default = (",
            "                        match.group(1)",
            "                        + ('\"%s\"' % sch)",
            "                        + \".\"",
            "                        + match.group(2)",
            "                        + match.group(3)",
            "                    )",
            "",
            "        column_info = dict(",
            "            name=name,",
            "            type=coltype,",
            "            nullable=nullable,",
            "            default=default,",
            "            autoincrement=autoincrement,",
            "            comment=comment,",
            "        )",
            "        return column_info",
            "",
            "    @reflection.cache",
            "    def get_pk_constraint(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        if self.server_version_info < (8, 4):",
            "            PK_SQL = \"\"\"",
            "                SELECT a.attname",
            "                FROM",
            "                    pg_class t",
            "                    join pg_index ix on t.oid = ix.indrelid",
            "                    join pg_attribute a",
            "                        on t.oid=a.attrelid AND %s",
            "                 WHERE",
            "                  t.oid = :table_oid and ix.indisprimary = 't'",
            "                ORDER BY a.attnum",
            "            \"\"\" % self._pg_index_any(",
            "                \"a.attnum\", \"ix.indkey\"",
            "            )",
            "",
            "        else:",
            "            # unnest() and generate_subscripts() both introduced in",
            "            # version 8.4",
            "            PK_SQL = \"\"\"",
            "                SELECT a.attname",
            "                FROM pg_attribute a JOIN (",
            "                    SELECT unnest(ix.indkey) attnum,",
            "                           generate_subscripts(ix.indkey, 1) ord",
            "                    FROM pg_index ix",
            "                    WHERE ix.indrelid = :table_oid AND ix.indisprimary",
            "                    ) k ON a.attnum=k.attnum",
            "                WHERE a.attrelid = :table_oid",
            "                ORDER BY k.ord",
            "            \"\"\"",
            "        t = sql.text(PK_SQL).columns(attname=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "        cols = [r[0] for r in c.fetchall()]",
            "",
            "        PK_CONS_SQL = \"\"\"",
            "        SELECT conname",
            "           FROM  pg_catalog.pg_constraint r",
            "           WHERE r.conrelid = :table_oid AND r.contype = 'p'",
            "           ORDER BY 1",
            "        \"\"\"",
            "        t = sql.text(PK_CONS_SQL).columns(conname=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "        name = c.scalar()",
            "",
            "        return {\"constrained_columns\": cols, \"name\": name}",
            "",
            "    @reflection.cache",
            "    def get_foreign_keys(",
            "        self,",
            "        connection,",
            "        table_name,",
            "        schema=None,",
            "        postgresql_ignore_search_path=False,",
            "        **kw",
            "    ):",
            "        preparer = self.identifier_preparer",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        FK_SQL = \"\"\"",
            "          SELECT r.conname,",
            "                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,",
            "                n.nspname as conschema",
            "          FROM  pg_catalog.pg_constraint r,",
            "                pg_namespace n,",
            "                pg_class c",
            "",
            "          WHERE r.conrelid = :table AND",
            "                r.contype = 'f' AND",
            "                c.oid = confrelid AND",
            "                n.oid = c.relnamespace",
            "          ORDER BY 1",
            "        \"\"\"",
            "        # http://www.postgresql.org/docs/9.0/static/sql-createtable.html",
            "        FK_REGEX = re.compile(",
            "            r\"FOREIGN KEY \\((.*?)\\) REFERENCES (?:(.*?)\\.)?(.*?)\\((.*?)\\)\"",
            "            r\"[\\s]?(MATCH (FULL|PARTIAL|SIMPLE)+)?\"",
            "            r\"[\\s]?(ON UPDATE \"",
            "            r\"(CASCADE|RESTRICT|NO ACTION|SET NULL|SET DEFAULT)+)?\"",
            "            r\"[\\s]?(ON DELETE \"",
            "            r\"(CASCADE|RESTRICT|NO ACTION|SET NULL|SET DEFAULT)+)?\"",
            "            r\"[\\s]?(DEFERRABLE|NOT DEFERRABLE)?\"",
            "            r\"[\\s]?(INITIALLY (DEFERRED|IMMEDIATE)+)?\"",
            "        )",
            "",
            "        t = sql.text(FK_SQL).columns(",
            "            conname=sqltypes.Unicode, condef=sqltypes.Unicode",
            "        )",
            "        c = connection.execute(t, table=table_oid)",
            "        fkeys = []",
            "        for conname, condef, conschema in c.fetchall():",
            "            m = re.search(FK_REGEX, condef).groups()",
            "",
            "            (",
            "                constrained_columns,",
            "                referred_schema,",
            "                referred_table,",
            "                referred_columns,",
            "                _,",
            "                match,",
            "                _,",
            "                onupdate,",
            "                _,",
            "                ondelete,",
            "                deferrable,",
            "                _,",
            "                initially,",
            "            ) = m",
            "",
            "            if deferrable is not None:",
            "                deferrable = True if deferrable == \"DEFERRABLE\" else False",
            "            constrained_columns = [",
            "                preparer._unquote_identifier(x)",
            "                for x in re.split(r\"\\s*,\\s*\", constrained_columns)",
            "            ]",
            "",
            "            if postgresql_ignore_search_path:",
            "                # when ignoring search path, we use the actual schema",
            "                # provided it isn't the \"default\" schema",
            "                if conschema != self.default_schema_name:",
            "                    referred_schema = conschema",
            "                else:",
            "                    referred_schema = schema",
            "            elif referred_schema:",
            "                # referred_schema is the schema that we regexp'ed from",
            "                # pg_get_constraintdef().  If the schema is in the search",
            "                # path, pg_get_constraintdef() will give us None.",
            "                referred_schema = preparer._unquote_identifier(referred_schema)",
            "            elif schema is not None and schema == conschema:",
            "                # If the actual schema matches the schema of the table",
            "                # we're reflecting, then we will use that.",
            "                referred_schema = schema",
            "",
            "            referred_table = preparer._unquote_identifier(referred_table)",
            "            referred_columns = [",
            "                preparer._unquote_identifier(x)",
            "                for x in re.split(r\"\\s*,\\s\", referred_columns)",
            "            ]",
            "            fkey_d = {",
            "                \"name\": conname,",
            "                \"constrained_columns\": constrained_columns,",
            "                \"referred_schema\": referred_schema,",
            "                \"referred_table\": referred_table,",
            "                \"referred_columns\": referred_columns,",
            "                \"options\": {",
            "                    \"onupdate\": onupdate,",
            "                    \"ondelete\": ondelete,",
            "                    \"deferrable\": deferrable,",
            "                    \"initially\": initially,",
            "                    \"match\": match,",
            "                },",
            "            }",
            "            fkeys.append(fkey_d)",
            "        return fkeys",
            "",
            "    def _pg_index_any(self, col, compare_to):",
            "        if self.server_version_info < (8, 1):",
            "            # http://www.postgresql.org/message-id/10279.1124395722@sss.pgh.pa.us",
            "            # \"In CVS tip you could replace this with \"attnum = ANY (indkey)\".",
            "            # Unfortunately, most array support doesn't work on int2vector in",
            "            # pre-8.1 releases, so I think you're kinda stuck with the above",
            "            # for now.",
            "            # regards, tom lane\"",
            "            return \"(%s)\" % \" OR \".join(",
            "                \"%s[%d] = %s\" % (compare_to, ind, col) for ind in range(0, 10)",
            "            )",
            "        else:",
            "            return \"%s = ANY(%s)\" % (col, compare_to)",
            "",
            "    @reflection.cache",
            "    def get_indexes(self, connection, table_name, schema, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        # cast indkey as varchar since it's an int2vector,",
            "        # returned as a list by some drivers such as pypostgresql",
            "",
            "        if self.server_version_info < (8, 5):",
            "            IDX_SQL = \"\"\"",
            "              SELECT",
            "                  i.relname as relname,",
            "                  ix.indisunique, ix.indexprs, ix.indpred,",
            "                  a.attname, a.attnum, NULL, ix.indkey%s,",
            "                  %s, am.amname",
            "              FROM",
            "                  pg_class t",
            "                        join pg_index ix on t.oid = ix.indrelid",
            "                        join pg_class i on i.oid = ix.indexrelid",
            "                        left outer join",
            "                            pg_attribute a",
            "                            on t.oid = a.attrelid and %s",
            "                        left outer join",
            "                            pg_am am",
            "                            on i.relam = am.oid",
            "              WHERE",
            "                  t.relkind IN ('r', 'v', 'f', 'm')",
            "                  and t.oid = :table_oid",
            "                  and ix.indisprimary = 'f'",
            "              ORDER BY",
            "                  t.relname,",
            "                  i.relname",
            "            \"\"\" % (",
            "                # version 8.3 here was based on observing the",
            "                # cast does not work in PG 8.2.4, does work in 8.3.0.",
            "                # nothing in PG changelogs regarding this.",
            "                \"::varchar\" if self.server_version_info >= (8, 3) else \"\",",
            "                \"i.reloptions\"",
            "                if self.server_version_info >= (8, 2)",
            "                else \"NULL\",",
            "                self._pg_index_any(\"a.attnum\", \"ix.indkey\"),",
            "            )",
            "        else:",
            "            IDX_SQL = \"\"\"",
            "              SELECT",
            "                  i.relname as relname,",
            "                  ix.indisunique, ix.indexprs, ix.indpred,",
            "                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,",
            "                  i.reloptions, am.amname",
            "              FROM",
            "                  pg_class t",
            "                        join pg_index ix on t.oid = ix.indrelid",
            "                        join pg_class i on i.oid = ix.indexrelid",
            "                        left outer join",
            "                            pg_attribute a",
            "                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)",
            "                        left outer join",
            "                            pg_constraint c",
            "                            on (ix.indrelid = c.conrelid and",
            "                                ix.indexrelid = c.conindid and",
            "                                c.contype in ('p', 'u', 'x'))",
            "                        left outer join",
            "                            pg_am am",
            "                            on i.relam = am.oid",
            "              WHERE",
            "                  t.relkind IN ('r', 'v', 'f', 'm')",
            "                  and t.oid = :table_oid",
            "                  and ix.indisprimary = 'f'",
            "              ORDER BY",
            "                  t.relname,",
            "                  i.relname",
            "            \"\"\"",
            "",
            "        t = sql.text(IDX_SQL).columns(",
            "            relname=sqltypes.Unicode, attname=sqltypes.Unicode",
            "        )",
            "        c = connection.execute(t, table_oid=table_oid)",
            "",
            "        indexes = defaultdict(lambda: defaultdict(dict))",
            "",
            "        sv_idx_name = None",
            "        for row in c.fetchall():",
            "            (",
            "                idx_name,",
            "                unique,",
            "                expr,",
            "                prd,",
            "                col,",
            "                col_num,",
            "                conrelid,",
            "                idx_key,",
            "                options,",
            "                amname,",
            "            ) = row",
            "",
            "            if expr:",
            "                if idx_name != sv_idx_name:",
            "                    util.warn(",
            "                        \"Skipped unsupported reflection of \"",
            "                        \"expression-based index %s\" % idx_name",
            "                    )",
            "                sv_idx_name = idx_name",
            "                continue",
            "",
            "            if prd and not idx_name == sv_idx_name:",
            "                util.warn(",
            "                    \"Predicate of partial index %s ignored during reflection\"",
            "                    % idx_name",
            "                )",
            "                sv_idx_name = idx_name",
            "",
            "            has_idx = idx_name in indexes",
            "            index = indexes[idx_name]",
            "            if col is not None:",
            "                index[\"cols\"][col_num] = col",
            "            if not has_idx:",
            "                index[\"key\"] = [int(k.strip()) for k in idx_key.split()]",
            "                index[\"unique\"] = unique",
            "                if conrelid is not None:",
            "                    index[\"duplicates_constraint\"] = idx_name",
            "                if options:",
            "                    index[\"options\"] = dict(",
            "                        [option.split(\"=\") for option in options]",
            "                    )",
            "",
            "                # it *might* be nice to include that this is 'btree' in the",
            "                # reflection info.  But we don't want an Index object",
            "                # to have a ``postgresql_using`` in it that is just the",
            "                # default, so for the moment leaving this out.",
            "                if amname and amname != \"btree\":",
            "                    index[\"amname\"] = amname",
            "",
            "        result = []",
            "        for name, idx in indexes.items():",
            "            entry = {",
            "                \"name\": name,",
            "                \"unique\": idx[\"unique\"],",
            "                \"column_names\": [idx[\"cols\"][i] for i in idx[\"key\"]],",
            "            }",
            "            if \"duplicates_constraint\" in idx:",
            "                entry[\"duplicates_constraint\"] = idx[\"duplicates_constraint\"]",
            "            if \"options\" in idx:",
            "                entry.setdefault(\"dialect_options\", {})[",
            "                    \"postgresql_with\"",
            "                ] = idx[\"options\"]",
            "            if \"amname\" in idx:",
            "                entry.setdefault(\"dialect_options\", {})[",
            "                    \"postgresql_using\"",
            "                ] = idx[\"amname\"]",
            "            result.append(entry)",
            "        return result",
            "",
            "    @reflection.cache",
            "    def get_unique_constraints(",
            "        self, connection, table_name, schema=None, **kw",
            "    ):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        UNIQUE_SQL = \"\"\"",
            "            SELECT",
            "                cons.conname as name,",
            "                cons.conkey as key,",
            "                a.attnum as col_num,",
            "                a.attname as col_name",
            "            FROM",
            "                pg_catalog.pg_constraint cons",
            "                join pg_attribute a",
            "                  on cons.conrelid = a.attrelid AND",
            "                    a.attnum = ANY(cons.conkey)",
            "            WHERE",
            "                cons.conrelid = :table_oid AND",
            "                cons.contype = 'u'",
            "        \"\"\"",
            "",
            "        t = sql.text(UNIQUE_SQL).columns(col_name=sqltypes.Unicode)",
            "        c = connection.execute(t, table_oid=table_oid)",
            "",
            "        uniques = defaultdict(lambda: defaultdict(dict))",
            "        for row in c.fetchall():",
            "            uc = uniques[row.name]",
            "            uc[\"key\"] = row.key",
            "            uc[\"cols\"][row.col_num] = row.col_name",
            "",
            "        return [",
            "            {\"name\": name, \"column_names\": [uc[\"cols\"][i] for i in uc[\"key\"]]}",
            "            for name, uc in uniques.items()",
            "        ]",
            "",
            "    @reflection.cache",
            "    def get_table_comment(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        COMMENT_SQL = \"\"\"",
            "            SELECT",
            "                pgd.description as table_comment",
            "            FROM",
            "                pg_catalog.pg_description pgd",
            "            WHERE",
            "                pgd.objsubid = 0 AND",
            "                pgd.objoid = :table_oid",
            "        \"\"\"",
            "",
            "        c = connection.execute(sql.text(COMMENT_SQL), table_oid=table_oid)",
            "        return {\"text\": c.scalar()}",
            "",
            "    @reflection.cache",
            "    def get_check_constraints(self, connection, table_name, schema=None, **kw):",
            "        table_oid = self.get_table_oid(",
            "            connection, table_name, schema, info_cache=kw.get(\"info_cache\")",
            "        )",
            "",
            "        CHECK_SQL = \"\"\"",
            "            SELECT",
            "                cons.conname as name,",
            "                pg_get_constraintdef(cons.oid) as src",
            "            FROM",
            "                pg_catalog.pg_constraint cons",
            "            WHERE",
            "                cons.conrelid = :table_oid AND",
            "                cons.contype = 'c'",
            "        \"\"\"",
            "",
            "        c = connection.execute(sql.text(CHECK_SQL), table_oid=table_oid)",
            "",
            "        # samples:",
            "        # \"CHECK (((a > 1) AND (a < 5)))\"",
            "        # \"CHECK (((a = 1) OR ((a > 2) AND (a < 5))))\"",
            "        def match_cons(src):",
            "            m = re.match(r\"^CHECK *\\(\\((.+)\\)\\)$\", src)",
            "            if not m:",
            "                util.warn(\"Could not parse CHECK constraint text: %r\" % src)",
            "                return \"\"",
            "            return m.group(1)",
            "",
            "        return [",
            "            {\"name\": name, \"sqltext\": match_cons(src)}",
            "            for name, src in c.fetchall()",
            "        ]",
            "",
            "    def _load_enums(self, connection, schema=None):",
            "        schema = schema or self.default_schema_name",
            "        if not self.supports_native_enum:",
            "            return {}",
            "",
            "        # Load data types for enums:",
            "        SQL_ENUMS = \"\"\"",
            "            SELECT t.typname as \"name\",",
            "               -- no enum defaults in 8.4 at least",
            "               -- t.typdefault as \"default\",",
            "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",",
            "               n.nspname as \"schema\",",
            "               e.enumlabel as \"label\"",
            "            FROM pg_catalog.pg_type t",
            "                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace",
            "                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid",
            "            WHERE t.typtype = 'e'",
            "        \"\"\"",
            "",
            "        if schema != \"*\":",
            "            SQL_ENUMS += \"AND n.nspname = :schema \"",
            "",
            "        # e.oid gives us label order within an enum",
            "        SQL_ENUMS += 'ORDER BY \"schema\", \"name\", e.oid'",
            "",
            "        s = sql.text(SQL_ENUMS).columns(",
            "            attname=sqltypes.Unicode, label=sqltypes.Unicode",
            "        )",
            "",
            "        if schema != \"*\":",
            "            s = s.bindparams(schema=schema)",
            "",
            "        c = connection.execute(s)",
            "",
            "        enums = []",
            "        enum_by_name = {}",
            "        for enum in c.fetchall():",
            "            key = (enum[\"schema\"], enum[\"name\"])",
            "            if key in enum_by_name:",
            "                enum_by_name[key][\"labels\"].append(enum[\"label\"])",
            "            else:",
            "                enum_by_name[key] = enum_rec = {",
            "                    \"name\": enum[\"name\"],",
            "                    \"schema\": enum[\"schema\"],",
            "                    \"visible\": enum[\"visible\"],",
            "                    \"labels\": [enum[\"label\"]],",
            "                }",
            "                enums.append(enum_rec)",
            "        return enums",
            "",
            "    def _load_domains(self, connection):",
            "        # Load data types for domains:",
            "        SQL_DOMAINS = \"\"\"",
            "            SELECT t.typname as \"name\",",
            "               pg_catalog.format_type(t.typbasetype, t.typtypmod) as \"attype\",",
            "               not t.typnotnull as \"nullable\",",
            "               t.typdefault as \"default\",",
            "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",",
            "               n.nspname as \"schema\"",
            "            FROM pg_catalog.pg_type t",
            "               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace",
            "            WHERE t.typtype = 'd'",
            "        \"\"\"",
            "",
            "        s = sql.text(SQL_DOMAINS).columns(attname=sqltypes.Unicode)",
            "        c = connection.execute(s)",
            "",
            "        domains = {}",
            "        for domain in c.fetchall():",
            "            # strip (30) from character varying(30)",
            "            attype = re.search(r\"([^\\(]+)\", domain[\"attype\"]).group(1)",
            "            # 'visible' just means whether or not the domain is in a",
            "            # schema that's on the search path -- or not overridden by",
            "            # a schema with higher precedence. If it's not visible,",
            "            # it will be prefixed with the schema-name when it's used.",
            "            if domain[\"visible\"]:",
            "                key = (domain[\"name\"],)",
            "            else:",
            "                key = (domain[\"schema\"], domain[\"name\"])",
            "",
            "            domains[key] = {",
            "                \"attype\": attype,",
            "                \"nullable\": domain[\"nullable\"],",
            "                \"default\": domain[\"default\"],",
            "            }",
            "",
            "        return domains"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1911": [
                "PGDDLCompiler",
                "visit_create_index"
            ],
            "1986": [
                "PGDDLCompiler",
                "visit_exclude_constraint"
            ]
        },
        "addLocation": []
    },
    "lib/sqlalchemy/dialects/postgresql/ext.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 91,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "     where = None"
            },
            "2": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 93,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+    @elements._document_text_coercion("
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+        \"where\","
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+        \":class:`.ExcludeConstraint`\","
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+        \":paramref:`.ExcludeConstraint.where`\","
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+    )"
            },
            "8": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 99,
                "PatchRowcode": "     def __init__(self, *elements, **kw):"
            },
            "9": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "         r\"\"\""
            },
            "10": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "         Create an :class:`.ExcludeConstraint` object."
            },
            "11": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "             )"
            },
            "12": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 129,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "         :param \\*elements:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "           A sequence of two tuples of the form ``(column, operator)`` where"
            },
            "16": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "           \"column\" is a SQL expression element or a raw SQL string, most"
            },
            "17": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-          typically a :class:`.Column` object,"
            },
            "18": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-          and \"operator\" is a string containing the operator to use."
            },
            "19": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "20": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-          .. note::"
            },
            "21": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "22": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                A plain string passed for the value of \"column\" is interpreted"
            },
            "23": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                as an arbitrary SQL  expression; when passing a plain string,"
            },
            "24": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                any necessary quoting and escaping syntaxes must be applied"
            },
            "25": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                manually. In order to specify a column name when a"
            },
            "26": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                :class:`.Column` object is not available, while ensuring that"
            },
            "27": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                any necessary quoting rules take effect, an ad-hoc"
            },
            "28": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                :class:`.Column` or :func:`.sql.expression.column` object may"
            },
            "29": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                be used."
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+          typically a :class:`.Column` object, and \"operator\" is a string"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+          containing the operator to use.   In order to specify a column name"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+          when a  :class:`.Column` object is not available, while ensuring"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+          that any necessary quoting rules take effect, an ad-hoc"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+          :class:`.Column` or :func:`.sql.expression.column` object should be"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+          used."
            },
            "36": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 140,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         :param name:"
            },
            "38": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "           Optional, the in-database name of this constraint."
            },
            "39": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "           If set, emit WHERE <predicate> when issuing DDL"
            },
            "40": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "           for this constraint."
            },
            "41": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 160,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-          .. note::"
            },
            "43": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "44": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                A plain string passed here is interpreted as an arbitrary SQL"
            },
            "45": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                expression; when passing a plain string, any necessary quoting"
            },
            "46": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                and escaping syntaxes must be applied manually."
            },
            "47": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "48": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 161,
                "PatchRowcode": "         \"\"\""
            },
            "49": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "         columns = []"
            },
            "50": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "         render_exprs = []"
            },
            "51": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "                 # backwards compat"
            },
            "52": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "                 self.operators[name] = operator"
            },
            "53": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 179,
                "PatchRowcode": " "
            },
            "54": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            expr = expression._literal_as_text(expr)"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+            expr = expression._literal_as_column(expr)"
            },
            "56": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 181,
                "PatchRowcode": " "
            },
            "57": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "             render_exprs.append((expr, name, operator))"
            },
            "58": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 183,
                "PatchRowcode": " "
            },
            "59": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         self._render_exprs = render_exprs"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+"
            },
            "61": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "         ColumnCollectionConstraint.__init__("
            },
            "62": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "             self,"
            },
            "63": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "             *columns,"
            },
            "64": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "         self.using = kw.get(\"using\", \"gist\")"
            },
            "65": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 194,
                "PatchRowcode": "         where = kw.get(\"where\")"
            },
            "66": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "         if where is not None:"
            },
            "67": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.where = expression._literal_as_text(where)"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+            self.where = expression._literal_as_text("
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+                where, allow_coercion_to_text=True"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+            )"
            },
            "71": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": 199,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "     def copy(self, **kw):"
            },
            "73": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "         elements = [(col, self.operators[col]) for col in self.columns.keys()]"
            }
        },
        "frontPatchFile": [
            "# postgresql/ext.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "from .array import ARRAY",
            "from ...sql import elements",
            "from ...sql import expression",
            "from ...sql import functions",
            "from ...sql.schema import ColumnCollectionConstraint",
            "",
            "",
            "class aggregate_order_by(expression.ColumnElement):",
            "    \"\"\"Represent a PostgreSQL aggregate order by expression.",
            "",
            "    E.g.::",
            "",
            "        from sqlalchemy.dialects.postgresql import aggregate_order_by",
            "        expr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))",
            "        stmt = select([expr])",
            "",
            "    would represent the expression::",
            "",
            "        SELECT array_agg(a ORDER BY b DESC) FROM table;",
            "",
            "    Similarly::",
            "",
            "        expr = func.string_agg(",
            "            table.c.a,",
            "            aggregate_order_by(literal_column(\"','\"), table.c.a)",
            "        )",
            "        stmt = select([expr])",
            "",
            "    Would represent::",
            "",
            "        SELECT string_agg(a, ',' ORDER BY a) FROM table;",
            "",
            "    .. versionadded:: 1.1",
            "",
            "    .. versionchanged:: 1.2.13 - the ORDER BY argument may be multiple terms",
            "",
            "    .. seealso::",
            "",
            "        :class:`.array_agg`",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"aggregate_order_by\"",
            "",
            "    def __init__(self, target, *order_by):",
            "        self.target = elements._literal_as_binds(target)",
            "",
            "        _lob = len(order_by)",
            "        if _lob == 0:",
            "            raise TypeError(\"at least one ORDER BY element is required\")",
            "        elif _lob == 1:",
            "            self.order_by = elements._literal_as_binds(order_by[0])",
            "        else:",
            "            self.order_by = elements.ClauseList(",
            "                *order_by, _literal_as_text=elements._literal_as_binds",
            "            )",
            "",
            "    def self_group(self, against=None):",
            "        return self",
            "",
            "    def get_children(self, **kwargs):",
            "        return self.target, self.order_by",
            "",
            "    def _copy_internals(self, clone=elements._clone, **kw):",
            "        self.target = clone(self.target, **kw)",
            "        self.order_by = clone(self.order_by, **kw)",
            "",
            "    @property",
            "    def _from_objects(self):",
            "        return self.target._from_objects + self.order_by._from_objects",
            "",
            "",
            "class ExcludeConstraint(ColumnCollectionConstraint):",
            "    \"\"\"A table-level EXCLUDE constraint.",
            "",
            "    Defines an EXCLUDE constraint as described in the `postgres",
            "    documentation`__.",
            "",
            "    __ http://www.postgresql.org/docs/9.0/static/sql-createtable.html#SQL-CREATETABLE-EXCLUDE",
            "",
            "    \"\"\"  # noqa",
            "",
            "    __visit_name__ = \"exclude_constraint\"",
            "",
            "    where = None",
            "",
            "    def __init__(self, *elements, **kw):",
            "        r\"\"\"",
            "        Create an :class:`.ExcludeConstraint` object.",
            "",
            "        E.g.::",
            "",
            "            const = ExcludeConstraint(",
            "                (Column('period'), '&&'),",
            "                (Column('group'), '='),",
            "                where=(Column('group') != 'some group')",
            "            )",
            "",
            "        The constraint is normally embedded into the :class:`.Table` construct",
            "        directly, or added later using :meth:`.append_constraint`::",
            "",
            "            some_table = Table(",
            "                'some_table', metadata,",
            "                Column('id', Integer, primary_key=True),",
            "                Column('period', TSRANGE()),",
            "                Column('group', String)",
            "            )",
            "",
            "            some_table.append_constraint(",
            "                ExcludeConstraint(",
            "                    (some_table.c.period, '&&'),",
            "                    (some_table.c.group, '='),",
            "                    where=some_table.c.group != 'some group',",
            "                    name='some_table_excl_const'",
            "                )",
            "            )",
            "",
            "        :param \\*elements:",
            "          A sequence of two tuples of the form ``(column, operator)`` where",
            "          \"column\" is a SQL expression element or a raw SQL string, most",
            "          typically a :class:`.Column` object,",
            "          and \"operator\" is a string containing the operator to use.",
            "",
            "          .. note::",
            "",
            "                A plain string passed for the value of \"column\" is interpreted",
            "                as an arbitrary SQL  expression; when passing a plain string,",
            "                any necessary quoting and escaping syntaxes must be applied",
            "                manually. In order to specify a column name when a",
            "                :class:`.Column` object is not available, while ensuring that",
            "                any necessary quoting rules take effect, an ad-hoc",
            "                :class:`.Column` or :func:`.sql.expression.column` object may",
            "                be used.",
            "",
            "        :param name:",
            "          Optional, the in-database name of this constraint.",
            "",
            "        :param deferrable:",
            "          Optional bool.  If set, emit DEFERRABLE or NOT DEFERRABLE when",
            "          issuing DDL for this constraint.",
            "",
            "        :param initially:",
            "          Optional string.  If set, emit INITIALLY <value> when issuing DDL",
            "          for this constraint.",
            "",
            "        :param using:",
            "          Optional string.  If set, emit USING <index_method> when issuing DDL",
            "          for this constraint. Defaults to 'gist'.",
            "",
            "        :param where:",
            "          Optional SQL expression construct or literal SQL string.",
            "          If set, emit WHERE <predicate> when issuing DDL",
            "          for this constraint.",
            "",
            "          .. note::",
            "",
            "                A plain string passed here is interpreted as an arbitrary SQL",
            "                expression; when passing a plain string, any necessary quoting",
            "                and escaping syntaxes must be applied manually.",
            "",
            "        \"\"\"",
            "        columns = []",
            "        render_exprs = []",
            "        self.operators = {}",
            "",
            "        expressions, operators = zip(*elements)",
            "",
            "        for (expr, column, strname, add_element), operator in zip(",
            "            self._extract_col_expression_collection(expressions), operators",
            "        ):",
            "            if add_element is not None:",
            "                columns.append(add_element)",
            "",
            "            name = column.name if column is not None else strname",
            "",
            "            if name is not None:",
            "                # backwards compat",
            "                self.operators[name] = operator",
            "",
            "            expr = expression._literal_as_text(expr)",
            "",
            "            render_exprs.append((expr, name, operator))",
            "",
            "        self._render_exprs = render_exprs",
            "        ColumnCollectionConstraint.__init__(",
            "            self,",
            "            *columns,",
            "            name=kw.get(\"name\"),",
            "            deferrable=kw.get(\"deferrable\"),",
            "            initially=kw.get(\"initially\")",
            "        )",
            "        self.using = kw.get(\"using\", \"gist\")",
            "        where = kw.get(\"where\")",
            "        if where is not None:",
            "            self.where = expression._literal_as_text(where)",
            "",
            "    def copy(self, **kw):",
            "        elements = [(col, self.operators[col]) for col in self.columns.keys()]",
            "        c = self.__class__(",
            "            *elements,",
            "            name=self.name,",
            "            deferrable=self.deferrable,",
            "            initially=self.initially,",
            "            where=self.where,",
            "            using=self.using",
            "        )",
            "        c.dispatch._update(self.dispatch)",
            "        return c",
            "",
            "",
            "def array_agg(*arg, **kw):",
            "    \"\"\"PostgreSQL-specific form of :class:`.array_agg`, ensures",
            "    return type is :class:`.postgresql.ARRAY` and not",
            "    the plain :class:`.types.ARRAY`, unless an explicit ``type_``",
            "    is passed.",
            "",
            "    .. versionadded:: 1.1",
            "",
            "    \"\"\"",
            "    kw[\"_default_array_type\"] = ARRAY",
            "    return functions.func.array_agg(*arg, **kw)"
        ],
        "afterPatchFile": [
            "# postgresql/ext.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "from .array import ARRAY",
            "from ...sql import elements",
            "from ...sql import expression",
            "from ...sql import functions",
            "from ...sql.schema import ColumnCollectionConstraint",
            "",
            "",
            "class aggregate_order_by(expression.ColumnElement):",
            "    \"\"\"Represent a PostgreSQL aggregate order by expression.",
            "",
            "    E.g.::",
            "",
            "        from sqlalchemy.dialects.postgresql import aggregate_order_by",
            "        expr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))",
            "        stmt = select([expr])",
            "",
            "    would represent the expression::",
            "",
            "        SELECT array_agg(a ORDER BY b DESC) FROM table;",
            "",
            "    Similarly::",
            "",
            "        expr = func.string_agg(",
            "            table.c.a,",
            "            aggregate_order_by(literal_column(\"','\"), table.c.a)",
            "        )",
            "        stmt = select([expr])",
            "",
            "    Would represent::",
            "",
            "        SELECT string_agg(a, ',' ORDER BY a) FROM table;",
            "",
            "    .. versionadded:: 1.1",
            "",
            "    .. versionchanged:: 1.2.13 - the ORDER BY argument may be multiple terms",
            "",
            "    .. seealso::",
            "",
            "        :class:`.array_agg`",
            "",
            "    \"\"\"",
            "",
            "    __visit_name__ = \"aggregate_order_by\"",
            "",
            "    def __init__(self, target, *order_by):",
            "        self.target = elements._literal_as_binds(target)",
            "",
            "        _lob = len(order_by)",
            "        if _lob == 0:",
            "            raise TypeError(\"at least one ORDER BY element is required\")",
            "        elif _lob == 1:",
            "            self.order_by = elements._literal_as_binds(order_by[0])",
            "        else:",
            "            self.order_by = elements.ClauseList(",
            "                *order_by, _literal_as_text=elements._literal_as_binds",
            "            )",
            "",
            "    def self_group(self, against=None):",
            "        return self",
            "",
            "    def get_children(self, **kwargs):",
            "        return self.target, self.order_by",
            "",
            "    def _copy_internals(self, clone=elements._clone, **kw):",
            "        self.target = clone(self.target, **kw)",
            "        self.order_by = clone(self.order_by, **kw)",
            "",
            "    @property",
            "    def _from_objects(self):",
            "        return self.target._from_objects + self.order_by._from_objects",
            "",
            "",
            "class ExcludeConstraint(ColumnCollectionConstraint):",
            "    \"\"\"A table-level EXCLUDE constraint.",
            "",
            "    Defines an EXCLUDE constraint as described in the `postgres",
            "    documentation`__.",
            "",
            "    __ http://www.postgresql.org/docs/9.0/static/sql-createtable.html#SQL-CREATETABLE-EXCLUDE",
            "",
            "    \"\"\"  # noqa",
            "",
            "    __visit_name__ = \"exclude_constraint\"",
            "",
            "    where = None",
            "",
            "    @elements._document_text_coercion(",
            "        \"where\",",
            "        \":class:`.ExcludeConstraint`\",",
            "        \":paramref:`.ExcludeConstraint.where`\",",
            "    )",
            "    def __init__(self, *elements, **kw):",
            "        r\"\"\"",
            "        Create an :class:`.ExcludeConstraint` object.",
            "",
            "        E.g.::",
            "",
            "            const = ExcludeConstraint(",
            "                (Column('period'), '&&'),",
            "                (Column('group'), '='),",
            "                where=(Column('group') != 'some group')",
            "            )",
            "",
            "        The constraint is normally embedded into the :class:`.Table` construct",
            "        directly, or added later using :meth:`.append_constraint`::",
            "",
            "            some_table = Table(",
            "                'some_table', metadata,",
            "                Column('id', Integer, primary_key=True),",
            "                Column('period', TSRANGE()),",
            "                Column('group', String)",
            "            )",
            "",
            "            some_table.append_constraint(",
            "                ExcludeConstraint(",
            "                    (some_table.c.period, '&&'),",
            "                    (some_table.c.group, '='),",
            "                    where=some_table.c.group != 'some group',",
            "                    name='some_table_excl_const'",
            "                )",
            "            )",
            "",
            "        :param \\*elements:",
            "",
            "          A sequence of two tuples of the form ``(column, operator)`` where",
            "          \"column\" is a SQL expression element or a raw SQL string, most",
            "          typically a :class:`.Column` object, and \"operator\" is a string",
            "          containing the operator to use.   In order to specify a column name",
            "          when a  :class:`.Column` object is not available, while ensuring",
            "          that any necessary quoting rules take effect, an ad-hoc",
            "          :class:`.Column` or :func:`.sql.expression.column` object should be",
            "          used.",
            "",
            "        :param name:",
            "          Optional, the in-database name of this constraint.",
            "",
            "        :param deferrable:",
            "          Optional bool.  If set, emit DEFERRABLE or NOT DEFERRABLE when",
            "          issuing DDL for this constraint.",
            "",
            "        :param initially:",
            "          Optional string.  If set, emit INITIALLY <value> when issuing DDL",
            "          for this constraint.",
            "",
            "        :param using:",
            "          Optional string.  If set, emit USING <index_method> when issuing DDL",
            "          for this constraint. Defaults to 'gist'.",
            "",
            "        :param where:",
            "          Optional SQL expression construct or literal SQL string.",
            "          If set, emit WHERE <predicate> when issuing DDL",
            "          for this constraint.",
            "",
            "        \"\"\"",
            "        columns = []",
            "        render_exprs = []",
            "        self.operators = {}",
            "",
            "        expressions, operators = zip(*elements)",
            "",
            "        for (expr, column, strname, add_element), operator in zip(",
            "            self._extract_col_expression_collection(expressions), operators",
            "        ):",
            "            if add_element is not None:",
            "                columns.append(add_element)",
            "",
            "            name = column.name if column is not None else strname",
            "",
            "            if name is not None:",
            "                # backwards compat",
            "                self.operators[name] = operator",
            "",
            "            expr = expression._literal_as_column(expr)",
            "",
            "            render_exprs.append((expr, name, operator))",
            "",
            "        self._render_exprs = render_exprs",
            "",
            "        ColumnCollectionConstraint.__init__(",
            "            self,",
            "            *columns,",
            "            name=kw.get(\"name\"),",
            "            deferrable=kw.get(\"deferrable\"),",
            "            initially=kw.get(\"initially\")",
            "        )",
            "        self.using = kw.get(\"using\", \"gist\")",
            "        where = kw.get(\"where\")",
            "        if where is not None:",
            "            self.where = expression._literal_as_text(",
            "                where, allow_coercion_to_text=True",
            "            )",
            "",
            "    def copy(self, **kw):",
            "        elements = [(col, self.operators[col]) for col in self.columns.keys()]",
            "        c = self.__class__(",
            "            *elements,",
            "            name=self.name,",
            "            deferrable=self.deferrable,",
            "            initially=self.initially,",
            "            where=self.where,",
            "            using=self.using",
            "        )",
            "        c.dispatch._update(self.dispatch)",
            "        return c",
            "",
            "",
            "def array_agg(*arg, **kw):",
            "    \"\"\"PostgreSQL-specific form of :class:`.array_agg`, ensures",
            "    return type is :class:`.postgresql.ARRAY` and not",
            "    the plain :class:`.types.ARRAY`, unless an explicit ``type_``",
            "    is passed.",
            "",
            "    .. versionadded:: 1.1",
            "",
            "    \"\"\"",
            "    kw[\"_default_array_type\"] = ARRAY",
            "    return functions.func.array_agg(*arg, **kw)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "128": [
                "ExcludeConstraint",
                "__init__"
            ],
            "129": [
                "ExcludeConstraint",
                "__init__"
            ],
            "130": [
                "ExcludeConstraint",
                "__init__"
            ],
            "131": [
                "ExcludeConstraint",
                "__init__"
            ],
            "132": [
                "ExcludeConstraint",
                "__init__"
            ],
            "133": [
                "ExcludeConstraint",
                "__init__"
            ],
            "134": [
                "ExcludeConstraint",
                "__init__"
            ],
            "135": [
                "ExcludeConstraint",
                "__init__"
            ],
            "136": [
                "ExcludeConstraint",
                "__init__"
            ],
            "137": [
                "ExcludeConstraint",
                "__init__"
            ],
            "138": [
                "ExcludeConstraint",
                "__init__"
            ],
            "139": [
                "ExcludeConstraint",
                "__init__"
            ],
            "140": [
                "ExcludeConstraint",
                "__init__"
            ],
            "162": [
                "ExcludeConstraint",
                "__init__"
            ],
            "163": [
                "ExcludeConstraint",
                "__init__"
            ],
            "164": [
                "ExcludeConstraint",
                "__init__"
            ],
            "165": [
                "ExcludeConstraint",
                "__init__"
            ],
            "166": [
                "ExcludeConstraint",
                "__init__"
            ],
            "167": [
                "ExcludeConstraint",
                "__init__"
            ],
            "187": [
                "ExcludeConstraint",
                "__init__"
            ],
            "202": [
                "ExcludeConstraint",
                "__init__"
            ]
        },
        "addLocation": [
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint.__init__.render_exprs",
            "airflow.www.views.LogModelView",
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint._render_exprs",
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint.operators",
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint.self",
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint",
            "lib.sqlalchemy.dialects.postgresql.ext.ExcludeConstraint.__init__.columns"
        ]
    },
    "lib/sqlalchemy/orm/session.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1257,
                "afterPatchRowNumber": 1257,
                "PatchRowcode": "             in order to execute the statement."
            },
            "1": {
                "beforePatchRowNumber": 1258,
                "afterPatchRowNumber": 1258,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 1259,
                "afterPatchRowNumber": 1259,
                "PatchRowcode": "         \"\"\""
            },
            "3": {
                "beforePatchRowNumber": 1260,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        clause = expression._literal_as_text(clause)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1260,
                "PatchRowcode": "+        clause = expression._literal_as_text("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1261,
                "PatchRowcode": "+            clause, allow_coercion_to_text=True"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1262,
                "PatchRowcode": "+        )"
            },
            "7": {
                "beforePatchRowNumber": 1261,
                "afterPatchRowNumber": 1263,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 1262,
                "afterPatchRowNumber": 1264,
                "PatchRowcode": "         if bind is None:"
            },
            "9": {
                "beforePatchRowNumber": 1263,
                "afterPatchRowNumber": 1265,
                "PatchRowcode": "             bind = self.get_bind(mapper, clause=clause, **kw)"
            }
        },
        "frontPatchFile": [
            "# orm/session.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "\"\"\"Provides the Session class and related utilities.\"\"\"",
            "",
            "",
            "import itertools",
            "import sys",
            "import weakref",
            "",
            "from . import attributes",
            "from . import exc",
            "from . import identity",
            "from . import loading",
            "from . import persistence",
            "from . import query",
            "from . import state as statelib",
            "from .base import _class_to_mapper",
            "from .base import _none_set",
            "from .base import _state_mapper",
            "from .base import instance_str",
            "from .base import object_mapper",
            "from .base import object_state",
            "from .base import state_str",
            "from .deprecated_interfaces import SessionExtension",
            "from .unitofwork import UOWTransaction",
            "from .. import engine",
            "from .. import exc as sa_exc",
            "from .. import sql",
            "from .. import util",
            "from ..inspection import inspect",
            "from ..sql import expression",
            "from ..sql import util as sql_util",
            "",
            "",
            "__all__ = [\"Session\", \"SessionTransaction\", \"SessionExtension\", \"sessionmaker\"]",
            "",
            "_sessions = weakref.WeakValueDictionary()",
            "\"\"\"Weak-referencing dictionary of :class:`.Session` objects.",
            "\"\"\"",
            "",
            "",
            "def _state_session(state):",
            "    \"\"\"Given an :class:`.InstanceState`, return the :class:`.Session`",
            "        associated, if any.",
            "    \"\"\"",
            "    if state.session_id:",
            "        try:",
            "            return _sessions[state.session_id]",
            "        except KeyError:",
            "            pass",
            "    return None",
            "",
            "",
            "class _SessionClassMethods(object):",
            "    \"\"\"Class-level methods for :class:`.Session`, :class:`.sessionmaker`.\"\"\"",
            "",
            "    @classmethod",
            "    @util.deprecated(",
            "        \"1.3\",",
            "        \"The :meth:`.Session.close_all` method is deprecated and will be \"",
            "        \"removed in a future release.  Please refer to \"",
            "        \":func:`.session.close_all_sessions`.\",",
            "    )",
            "    def close_all(cls):",
            "        \"\"\"Close *all* sessions in memory.\"\"\"",
            "",
            "        close_all_sessions()",
            "",
            "    @classmethod",
            "    @util.dependencies(\"sqlalchemy.orm.util\")",
            "    def identity_key(cls, orm_util, *args, **kwargs):",
            "        \"\"\"Return an identity key.",
            "",
            "        This is an alias of :func:`.util.identity_key`.",
            "",
            "        \"\"\"",
            "        return orm_util.identity_key(*args, **kwargs)",
            "",
            "    @classmethod",
            "    def object_session(cls, instance):",
            "        \"\"\"Return the :class:`.Session` to which an object belongs.",
            "",
            "        This is an alias of :func:`.object_session`.",
            "",
            "        \"\"\"",
            "",
            "        return object_session(instance)",
            "",
            "",
            "ACTIVE = util.symbol(\"ACTIVE\")",
            "PREPARED = util.symbol(\"PREPARED\")",
            "COMMITTED = util.symbol(\"COMMITTED\")",
            "DEACTIVE = util.symbol(\"DEACTIVE\")",
            "CLOSED = util.symbol(\"CLOSED\")",
            "",
            "",
            "class SessionTransaction(object):",
            "    \"\"\"A :class:`.Session`-level transaction.",
            "",
            "    :class:`.SessionTransaction` is a mostly behind-the-scenes object",
            "    not normally referenced directly by application code.   It coordinates",
            "    among multiple :class:`.Connection` objects, maintaining a database",
            "    transaction for each one individually, committing or rolling them",
            "    back all at once.   It also provides optional two-phase commit behavior",
            "    which can augment this coordination operation.",
            "",
            "    The :attr:`.Session.transaction` attribute of :class:`.Session`",
            "    refers to the current :class:`.SessionTransaction` object in use, if any.",
            "    The :attr:`.SessionTransaction.parent` attribute refers to the parent",
            "    :class:`.SessionTransaction` in the stack of :class:`.SessionTransaction`",
            "    objects.  If this attribute is ``None``, then this is the top of the stack.",
            "    If non-``None``, then this :class:`.SessionTransaction` refers either",
            "    to a so-called \"subtransaction\" or a \"nested\" transaction.  A",
            "    \"subtransaction\" is a scoping concept that demarcates an inner portion",
            "    of the outermost \"real\" transaction.  A nested transaction, which",
            "    is indicated when the :attr:`.SessionTransaction.nested`",
            "    attribute is also True, indicates that this :class:`.SessionTransaction`",
            "    corresponds to a SAVEPOINT.",
            "",
            "    **Life Cycle**",
            "",
            "    A :class:`.SessionTransaction` is associated with a :class:`.Session`",
            "    in its default mode of ``autocommit=False`` immediately, associated",
            "    with no database connections.  As the :class:`.Session` is called upon",
            "    to emit SQL on behalf of various :class:`.Engine` or :class:`.Connection`",
            "    objects, a corresponding :class:`.Connection` and associated",
            "    :class:`.Transaction` is added to a collection within the",
            "    :class:`.SessionTransaction` object, becoming one of the",
            "    connection/transaction pairs maintained by the",
            "    :class:`.SessionTransaction`.  The start of a :class:`.SessionTransaction`",
            "    can be tracked using the :meth:`.SessionEvents.after_transaction_create`",
            "    event.",
            "",
            "    The lifespan of the :class:`.SessionTransaction` ends when the",
            "    :meth:`.Session.commit`, :meth:`.Session.rollback` or",
            "    :meth:`.Session.close` methods are called.  At this point, the",
            "    :class:`.SessionTransaction` removes its association with its parent",
            "    :class:`.Session`.   A :class:`.Session` that is in ``autocommit=False``",
            "    mode will create a new :class:`.SessionTransaction` to replace it",
            "    immediately, whereas a :class:`.Session` that's in ``autocommit=True``",
            "    mode will remain without a :class:`.SessionTransaction` until the",
            "    :meth:`.Session.begin` method is called.  The end of a",
            "    :class:`.SessionTransaction` can be tracked using the",
            "    :meth:`.SessionEvents.after_transaction_end` event.",
            "",
            "    **Nesting and Subtransactions**",
            "",
            "    Another detail of :class:`.SessionTransaction` behavior is that it is",
            "    capable of \"nesting\".  This means that the :meth:`.Session.begin` method",
            "    can be called while an existing :class:`.SessionTransaction` is already",
            "    present, producing a new :class:`.SessionTransaction` that temporarily",
            "    replaces the parent :class:`.SessionTransaction`.   When a",
            "    :class:`.SessionTransaction` is produced as nested, it assigns itself to",
            "    the :attr:`.Session.transaction` attribute, and it additionally will assign",
            "    the previous :class:`.SessionTransaction` to its :attr:`.Session.parent`",
            "    attribute.  The behavior is effectively a",
            "    stack, where :attr:`.Session.transaction` refers to the current head of",
            "    the stack, and the :attr:`.SessionTransaction.parent` attribute allows",
            "    traversal up the stack until :attr:`.SessionTransaction.parent` is",
            "    ``None``, indicating the top of the stack.",
            "",
            "    When the scope of :class:`.SessionTransaction` is ended via",
            "    :meth:`.Session.commit` or :meth:`.Session.rollback`, it restores its",
            "    parent :class:`.SessionTransaction` back onto the",
            "    :attr:`.Session.transaction` attribute.",
            "",
            "    The purpose of this stack is to allow nesting of",
            "    :meth:`.Session.rollback` or :meth:`.Session.commit` calls in context",
            "    with various flavors of :meth:`.Session.begin`. This nesting behavior",
            "    applies to when :meth:`.Session.begin_nested` is used to emit a",
            "    SAVEPOINT transaction, and is also used to produce a so-called",
            "    \"subtransaction\" which allows a block of code to use a",
            "    begin/rollback/commit sequence regardless of whether or not its enclosing",
            "    code block has begun a transaction.  The :meth:`.flush` method, whether",
            "    called explicitly or via autoflush, is the primary consumer of the",
            "    \"subtransaction\" feature, in that it wishes to guarantee that it works",
            "    within in a transaction block regardless of whether or not the",
            "    :class:`.Session` is in transactional mode when the method is called.",
            "",
            "    Note that the flush process that occurs within the \"autoflush\" feature",
            "    as well as when the :meth:`.Session.flush` method is used **always**",
            "    creates a :class:`.SessionTransaction` object.   This object is normally",
            "    a subtransaction, unless the :class:`.Session` is in autocommit mode",
            "    and no transaction exists at all, in which case it's the outermost",
            "    transaction.   Any event-handling logic or other inspection logic",
            "    needs to take into account whether a :class:`.SessionTransaction`",
            "    is the outermost transaction, a subtransaction, or a \"nested\" / SAVEPOINT",
            "    transaction.",
            "",
            "    .. seealso::",
            "",
            "        :meth:`.Session.rollback`",
            "",
            "        :meth:`.Session.commit`",
            "",
            "        :meth:`.Session.begin`",
            "",
            "        :meth:`.Session.begin_nested`",
            "",
            "        :attr:`.Session.is_active`",
            "",
            "        :meth:`.SessionEvents.after_transaction_create`",
            "",
            "        :meth:`.SessionEvents.after_transaction_end`",
            "",
            "        :meth:`.SessionEvents.after_commit`",
            "",
            "        :meth:`.SessionEvents.after_rollback`",
            "",
            "        :meth:`.SessionEvents.after_soft_rollback`",
            "",
            "    \"\"\"",
            "",
            "    _rollback_exception = None",
            "",
            "    def __init__(self, session, parent=None, nested=False):",
            "        self.session = session",
            "        self._connections = {}",
            "        self._parent = parent",
            "        self.nested = nested",
            "        self._state = ACTIVE",
            "        if not parent and nested:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Can't start a SAVEPOINT transaction when no existing \"",
            "                \"transaction is in progress\"",
            "            )",
            "",
            "        if self.session._enable_transaction_accounting:",
            "            self._take_snapshot()",
            "",
            "        self.session.dispatch.after_transaction_create(self.session, self)",
            "",
            "    @property",
            "    def parent(self):",
            "        \"\"\"The parent :class:`.SessionTransaction` of this",
            "        :class:`.SessionTransaction`.",
            "",
            "        If this attribute is ``None``, indicates this",
            "        :class:`.SessionTransaction` is at the top of the stack, and",
            "        corresponds to a real \"COMMIT\"/\"ROLLBACK\"",
            "        block.  If non-``None``, then this is either a \"subtransaction\"",
            "        or a \"nested\" / SAVEPOINT transaction.  If the",
            "        :attr:`.SessionTransaction.nested` attribute is ``True``, then",
            "        this is a SAVEPOINT, and if ``False``, indicates this a subtransaction.",
            "",
            "        .. versionadded:: 1.0.16 - use ._parent for previous versions",
            "",
            "        \"\"\"",
            "        return self._parent",
            "",
            "    nested = False",
            "    \"\"\"Indicates if this is a nested, or SAVEPOINT, transaction.",
            "",
            "    When :attr:`.SessionTransaction.nested` is True, it is expected",
            "    that :attr:`.SessionTransaction.parent` will be True as well.",
            "",
            "    \"\"\"",
            "",
            "    @property",
            "    def is_active(self):",
            "        return self.session is not None and self._state is ACTIVE",
            "",
            "    def _assert_active(",
            "        self,",
            "        prepared_ok=False,",
            "        rollback_ok=False,",
            "        deactive_ok=False,",
            "        closed_msg=\"This transaction is closed\",",
            "    ):",
            "        if self._state is COMMITTED:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"This session is in 'committed' state; no further \"",
            "                \"SQL can be emitted within this transaction.\"",
            "            )",
            "        elif self._state is PREPARED:",
            "            if not prepared_ok:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"This session is in 'prepared' state; no further \"",
            "                    \"SQL can be emitted within this transaction.\"",
            "                )",
            "        elif self._state is DEACTIVE:",
            "            if not deactive_ok and not rollback_ok:",
            "                if self._rollback_exception:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"This Session's transaction has been rolled back \"",
            "                        \"due to a previous exception during flush.\"",
            "                        \" To begin a new transaction with this Session, \"",
            "                        \"first issue Session.rollback().\"",
            "                        \" Original exception was: %s\"",
            "                        % self._rollback_exception",
            "                    )",
            "                elif not deactive_ok:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"This session is in 'inactive' state, due to the \"",
            "                        \"SQL transaction being rolled back; no further \"",
            "                        \"SQL can be emitted within this transaction.\"",
            "                    )",
            "        elif self._state is CLOSED:",
            "            raise sa_exc.ResourceClosedError(closed_msg)",
            "",
            "    @property",
            "    def _is_transaction_boundary(self):",
            "        return self.nested or not self._parent",
            "",
            "    def connection(self, bindkey, execution_options=None, **kwargs):",
            "        self._assert_active()",
            "        bind = self.session.get_bind(bindkey, **kwargs)",
            "        return self._connection_for_bind(bind, execution_options)",
            "",
            "    def _begin(self, nested=False):",
            "        self._assert_active()",
            "        return SessionTransaction(self.session, self, nested=nested)",
            "",
            "    def _iterate_self_and_parents(self, upto=None):",
            "",
            "        current = self",
            "        result = ()",
            "        while current:",
            "            result += (current,)",
            "            if current._parent is upto:",
            "                break",
            "            elif current._parent is None:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Transaction %s is not on the active transaction list\"",
            "                    % (upto)",
            "                )",
            "            else:",
            "                current = current._parent",
            "",
            "        return result",
            "",
            "    def _take_snapshot(self):",
            "        if not self._is_transaction_boundary:",
            "            self._new = self._parent._new",
            "            self._deleted = self._parent._deleted",
            "            self._dirty = self._parent._dirty",
            "            self._key_switches = self._parent._key_switches",
            "            return",
            "",
            "        if not self.session._flushing:",
            "            self.session.flush()",
            "",
            "        self._new = weakref.WeakKeyDictionary()",
            "        self._deleted = weakref.WeakKeyDictionary()",
            "        self._dirty = weakref.WeakKeyDictionary()",
            "        self._key_switches = weakref.WeakKeyDictionary()",
            "",
            "    def _restore_snapshot(self, dirty_only=False):",
            "        \"\"\"Restore the restoration state taken before a transaction began.",
            "",
            "        Corresponds to a rollback.",
            "",
            "        \"\"\"",
            "        assert self._is_transaction_boundary",
            "",
            "        to_expunge = set(self._new).union(self.session._new)",
            "        self.session._expunge_states(to_expunge, to_transient=True)",
            "",
            "        for s, (oldkey, newkey) in self._key_switches.items():",
            "            # we probably can do this conditionally based on",
            "            # if we expunged or not, but safe_discard does that anyway",
            "            self.session.identity_map.safe_discard(s)",
            "",
            "            # restore the old key",
            "            s.key = oldkey",
            "",
            "            # now restore the object, but only if we didn't expunge",
            "            if s not in to_expunge:",
            "                self.session.identity_map.replace(s)",
            "",
            "        for s in set(self._deleted).union(self.session._deleted):",
            "            self.session._update_impl(s, revert_deletion=True)",
            "",
            "        assert not self.session._deleted",
            "",
            "        for s in self.session.identity_map.all_states():",
            "            if not dirty_only or s.modified or s in self._dirty:",
            "                s._expire(s.dict, self.session.identity_map._modified)",
            "",
            "    def _remove_snapshot(self):",
            "        \"\"\"Remove the restoration state taken before a transaction began.",
            "",
            "        Corresponds to a commit.",
            "",
            "        \"\"\"",
            "        assert self._is_transaction_boundary",
            "",
            "        if not self.nested and self.session.expire_on_commit:",
            "            for s in self.session.identity_map.all_states():",
            "                s._expire(s.dict, self.session.identity_map._modified)",
            "",
            "            statelib.InstanceState._detach_states(",
            "                list(self._deleted), self.session",
            "            )",
            "            self._deleted.clear()",
            "        elif self.nested:",
            "            self._parent._new.update(self._new)",
            "            self._parent._dirty.update(self._dirty)",
            "            self._parent._deleted.update(self._deleted)",
            "            self._parent._key_switches.update(self._key_switches)",
            "",
            "    def _connection_for_bind(self, bind, execution_options):",
            "        self._assert_active()",
            "",
            "        if bind in self._connections:",
            "            if execution_options:",
            "                util.warn(",
            "                    \"Connection is already established for the \"",
            "                    \"given bind; execution_options ignored\"",
            "                )",
            "            return self._connections[bind][0]",
            "",
            "        if self._parent:",
            "            conn = self._parent._connection_for_bind(bind, execution_options)",
            "            if not self.nested:",
            "                return conn",
            "        else:",
            "            if isinstance(bind, engine.Connection):",
            "                conn = bind",
            "                if conn.engine in self._connections:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"Session already has a Connection associated for the \"",
            "                        \"given Connection's Engine\"",
            "                    )",
            "            else:",
            "                conn = bind._contextual_connect()",
            "",
            "        if execution_options:",
            "            conn = conn.execution_options(**execution_options)",
            "",
            "        if self.session.twophase and self._parent is None:",
            "            transaction = conn.begin_twophase()",
            "        elif self.nested:",
            "            transaction = conn.begin_nested()",
            "        else:",
            "            transaction = conn.begin()",
            "",
            "        self._connections[conn] = self._connections[conn.engine] = (",
            "            conn,",
            "            transaction,",
            "            conn is not bind,",
            "        )",
            "        self.session.dispatch.after_begin(self.session, self, conn)",
            "        return conn",
            "",
            "    def prepare(self):",
            "        if self._parent is not None or not self.session.twophase:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"'twophase' mode not enabled, or not root transaction; \"",
            "                \"can't prepare.\"",
            "            )",
            "        self._prepare_impl()",
            "",
            "    def _prepare_impl(self):",
            "        self._assert_active()",
            "        if self._parent is None or self.nested:",
            "            self.session.dispatch.before_commit(self.session)",
            "",
            "        stx = self.session.transaction",
            "        if stx is not self:",
            "            for subtransaction in stx._iterate_self_and_parents(upto=self):",
            "                subtransaction.commit()",
            "",
            "        if not self.session._flushing:",
            "            for _flush_guard in range(100):",
            "                if self.session._is_clean():",
            "                    break",
            "                self.session.flush()",
            "            else:",
            "                raise exc.FlushError(",
            "                    \"Over 100 subsequent flushes have occurred within \"",
            "                    \"session.commit() - is an after_flush() hook \"",
            "                    \"creating new objects?\"",
            "                )",
            "",
            "        if self._parent is None and self.session.twophase:",
            "            try:",
            "                for t in set(self._connections.values()):",
            "                    t[1].prepare()",
            "            except:",
            "                with util.safe_reraise():",
            "                    self.rollback()",
            "",
            "        self._state = PREPARED",
            "",
            "    def commit(self):",
            "        self._assert_active(prepared_ok=True)",
            "        if self._state is not PREPARED:",
            "            self._prepare_impl()",
            "",
            "        if self._parent is None or self.nested:",
            "            for t in set(self._connections.values()):",
            "                t[1].commit()",
            "",
            "            self._state = COMMITTED",
            "            self.session.dispatch.after_commit(self.session)",
            "",
            "            if self.session._enable_transaction_accounting:",
            "                self._remove_snapshot()",
            "",
            "        self.close()",
            "        return self._parent",
            "",
            "    def rollback(self, _capture_exception=False):",
            "        self._assert_active(prepared_ok=True, rollback_ok=True)",
            "",
            "        stx = self.session.transaction",
            "        if stx is not self:",
            "            for subtransaction in stx._iterate_self_and_parents(upto=self):",
            "                subtransaction.close()",
            "",
            "        boundary = self",
            "        rollback_err = None",
            "        if self._state in (ACTIVE, PREPARED):",
            "            for transaction in self._iterate_self_and_parents():",
            "                if transaction._parent is None or transaction.nested:",
            "                    try:",
            "                        for t in set(transaction._connections.values()):",
            "                            t[1].rollback()",
            "",
            "                        transaction._state = DEACTIVE",
            "                        self.session.dispatch.after_rollback(self.session)",
            "                    except:",
            "                        rollback_err = sys.exc_info()",
            "                    finally:",
            "                        transaction._state = DEACTIVE",
            "                        if self.session._enable_transaction_accounting:",
            "                            transaction._restore_snapshot(",
            "                                dirty_only=transaction.nested",
            "                            )",
            "                    boundary = transaction",
            "                    break",
            "                else:",
            "                    transaction._state = DEACTIVE",
            "",
            "        sess = self.session",
            "",
            "        if (",
            "            not rollback_err",
            "            and sess._enable_transaction_accounting",
            "            and not sess._is_clean()",
            "        ):",
            "",
            "            # if items were added, deleted, or mutated",
            "            # here, we need to re-restore the snapshot",
            "            util.warn(",
            "                \"Session's state has been changed on \"",
            "                \"a non-active transaction - this state \"",
            "                \"will be discarded.\"",
            "            )",
            "            boundary._restore_snapshot(dirty_only=boundary.nested)",
            "",
            "        self.close()",
            "",
            "        if self._parent and _capture_exception:",
            "            self._parent._rollback_exception = sys.exc_info()[1]",
            "",
            "        if rollback_err:",
            "            util.reraise(*rollback_err)",
            "",
            "        sess.dispatch.after_soft_rollback(sess, self)",
            "",
            "        return self._parent",
            "",
            "    def close(self, invalidate=False):",
            "        self.session.transaction = self._parent",
            "        if self._parent is None:",
            "            for connection, transaction, autoclose in set(",
            "                self._connections.values()",
            "            ):",
            "                if invalidate:",
            "                    connection.invalidate()",
            "                if autoclose:",
            "                    connection.close()",
            "                else:",
            "                    transaction.close()",
            "",
            "        self._state = CLOSED",
            "        self.session.dispatch.after_transaction_end(self.session, self)",
            "",
            "        if self._parent is None:",
            "            if not self.session.autocommit:",
            "                self.session.begin()",
            "        self.session = None",
            "        self._connections = None",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, type_, value, traceback):",
            "        self._assert_active(deactive_ok=True, prepared_ok=True)",
            "        if self.session.transaction is None:",
            "            return",
            "        if type_ is None:",
            "            try:",
            "                self.commit()",
            "            except:",
            "                with util.safe_reraise():",
            "                    self.rollback()",
            "        else:",
            "            self.rollback()",
            "",
            "",
            "class Session(_SessionClassMethods):",
            "    \"\"\"Manages persistence operations for ORM-mapped objects.",
            "",
            "    The Session's usage paradigm is described at :doc:`/orm/session`.",
            "",
            "",
            "    \"\"\"",
            "",
            "    public_methods = (",
            "        \"__contains__\",",
            "        \"__iter__\",",
            "        \"add\",",
            "        \"add_all\",",
            "        \"begin\",",
            "        \"begin_nested\",",
            "        \"close\",",
            "        \"commit\",",
            "        \"connection\",",
            "        \"delete\",",
            "        \"execute\",",
            "        \"expire\",",
            "        \"expire_all\",",
            "        \"expunge\",",
            "        \"expunge_all\",",
            "        \"flush\",",
            "        \"get_bind\",",
            "        \"is_modified\",",
            "        \"bulk_save_objects\",",
            "        \"bulk_insert_mappings\",",
            "        \"bulk_update_mappings\",",
            "        \"merge\",",
            "        \"query\",",
            "        \"refresh\",",
            "        \"rollback\",",
            "        \"scalar\",",
            "    )",
            "",
            "    @util.deprecated_params(",
            "        weak_identity_map=(",
            "            \"1.0\",",
            "            \"The :paramref:`.Session.weak_identity_map` parameter as well as \"",
            "            \"the strong-referencing identity map are deprecated, and will be \"",
            "            \"removed in a future release.  For the use case where objects \"",
            "            \"present in a :class:`.Session` need to be automatically strong \"",
            "            \"referenced, see the recipe at \"",
            "            \":ref:`session_referencing_behavior` for an event-based approach \"",
            "            \"to maintaining strong identity references. \",",
            "        ),",
            "        _enable_transaction_accounting=(",
            "            \"0.7\",",
            "            \"The :paramref:`.Session._enable_transaction_accounting` \"",
            "            \"parameter is deprecated and will be removed in a future release.\",",
            "        ),",
            "        extension=(",
            "            \"0.7\",",
            "            \":class:`.SessionExtension` is deprecated in favor of the \"",
            "            \":class:`.SessionEvents` listener interface.  The \"",
            "            \":paramref:`.Session.extension` parameter will be \"",
            "            \"removed in a future release.\",",
            "        ),",
            "    )",
            "    def __init__(",
            "        self,",
            "        bind=None,",
            "        autoflush=True,",
            "        expire_on_commit=True,",
            "        _enable_transaction_accounting=True,",
            "        autocommit=False,",
            "        twophase=False,",
            "        weak_identity_map=None,",
            "        binds=None,",
            "        extension=None,",
            "        enable_baked_queries=True,",
            "        info=None,",
            "        query_cls=None,",
            "    ):",
            "        r\"\"\"Construct a new Session.",
            "",
            "        See also the :class:`.sessionmaker` function which is used to",
            "        generate a :class:`.Session`-producing callable with a given",
            "        set of arguments.",
            "",
            "        :param autocommit:",
            "",
            "          .. warning::",
            "",
            "             The autocommit flag is **not for general use**, and if it is",
            "             used, queries should only be invoked within the span of a",
            "             :meth:`.Session.begin` / :meth:`.Session.commit` pair.  Executing",
            "             queries outside of a demarcated transaction is a legacy mode",
            "             of usage, and can in some cases lead to concurrent connection",
            "             checkouts.",
            "",
            "          Defaults to ``False``. When ``True``, the",
            "          :class:`.Session` does not keep a persistent transaction running,",
            "          and will acquire connections from the engine on an as-needed basis,",
            "          returning them immediately after their use. Flushes will begin and",
            "          commit (or possibly rollback) their own transaction if no",
            "          transaction is present. When using this mode, the",
            "          :meth:`.Session.begin` method is used to explicitly start",
            "          transactions.",
            "",
            "          .. seealso::",
            "",
            "            :ref:`session_autocommit`",
            "",
            "        :param autoflush: When ``True``, all query operations will issue a",
            "           :meth:`~.Session.flush` call to this ``Session`` before proceeding.",
            "           This is a convenience feature so that :meth:`~.Session.flush` need",
            "           not be called repeatedly in order for database queries to retrieve",
            "           results. It's typical that ``autoflush`` is used in conjunction",
            "           with ``autocommit=False``. In this scenario, explicit calls to",
            "           :meth:`~.Session.flush` are rarely needed; you usually only need to",
            "           call :meth:`~.Session.commit` (which flushes) to finalize changes.",
            "",
            "        :param bind: An optional :class:`.Engine` or :class:`.Connection` to",
            "           which this ``Session`` should be bound. When specified, all SQL",
            "           operations performed by this session will execute via this",
            "           connectable.",
            "",
            "        :param binds: A dictionary which may specify any number of",
            "           :class:`.Engine` or :class:`.Connection` objects as the source of",
            "           connectivity for SQL operations on a per-entity basis.   The keys",
            "           of the dictionary consist of any series of mapped classes,",
            "           arbitrary Python classes that are bases for mapped classes,",
            "           :class:`.Table` objects and :class:`.Mapper` objects.  The",
            "           values of the dictionary are then instances of :class:`.Engine`",
            "           or less commonly :class:`.Connection` objects.  Operations which",
            "           proceed relative to a particular mapped class will consult this",
            "           dictionary for the closest matching entity in order to determine",
            "           which :class:`.Engine` should be used for a particular SQL",
            "           operation.    The complete heuristics for resolution are",
            "           described at :meth:`.Session.get_bind`.  Usage looks like::",
            "",
            "            Session = sessionmaker(binds={",
            "                SomeMappedClass: create_engine('postgresql://engine1'),",
            "                SomeDeclarativeBase: create_engine('postgresql://engine2'),",
            "                some_mapper: create_engine('postgresql://engine3'),",
            "                some_table: create_engine('postgresql://engine4'),",
            "                })",
            "",
            "           .. seealso::",
            "",
            "                :ref:`session_partitioning`",
            "",
            "                :meth:`.Session.bind_mapper`",
            "",
            "                :meth:`.Session.bind_table`",
            "",
            "                :meth:`.Session.get_bind`",
            "",
            "",
            "        :param \\class_: Specify an alternate class other than",
            "           ``sqlalchemy.orm.session.Session`` which should be used by the",
            "           returned class. This is the only argument that is local to the",
            "           :class:`.sessionmaker` function, and is not sent directly to the",
            "           constructor for ``Session``.",
            "",
            "        :param enable_baked_queries: defaults to ``True``.  A flag consumed",
            "           by the :mod:`sqlalchemy.ext.baked` extension to determine if",
            "           \"baked queries\" should be cached, as is the normal operation",
            "           of this extension.  When set to ``False``, all caching is disabled,",
            "           including baked queries defined by the calling application as",
            "           well as those used internally.  Setting this flag to ``False``",
            "           can significantly reduce memory use, however will also degrade",
            "           performance for those areas that make use of baked queries",
            "           (such as relationship loaders).   Additionally, baked query",
            "           logic in the calling application or potentially within the ORM",
            "           that may be malfunctioning due to cache key collisions or similar",
            "           can be flagged by observing if this flag resolves the issue.",
            "",
            "           .. versionadded:: 1.2",
            "",
            "        :param _enable_transaction_accounting:   A",
            "           legacy-only flag which when ``False`` disables *all* 0.5-style",
            "           object accounting on transaction boundaries.",
            "",
            "        :param expire_on_commit:  Defaults to ``True``. When ``True``, all",
            "           instances will be fully expired after each :meth:`~.commit`,",
            "           so that all attribute/object access subsequent to a completed",
            "           transaction will load from the most recent database state.",
            "",
            "        :param extension: An optional",
            "           :class:`~.SessionExtension` instance, or a list",
            "           of such instances, which will receive pre- and post- commit and",
            "           flush events, as well as a post-rollback event.",
            "",
            "        :param info: optional dictionary of arbitrary data to be associated",
            "           with this :class:`.Session`.  Is available via the",
            "           :attr:`.Session.info` attribute.  Note the dictionary is copied at",
            "           construction time so that modifications to the per-",
            "           :class:`.Session` dictionary will be local to that",
            "           :class:`.Session`.",
            "",
            "           .. versionadded:: 0.9.0",
            "",
            "        :param query_cls:  Class which should be used to create new Query",
            "          objects, as returned by the :meth:`~.Session.query` method.",
            "          Defaults to :class:`.Query`.",
            "",
            "        :param twophase:  When ``True``, all transactions will be started as",
            "            a \"two phase\" transaction, i.e. using the \"two phase\" semantics",
            "            of the database in use along with an XID.  During a",
            "            :meth:`~.commit`, after :meth:`~.flush` has been issued for all",
            "            attached databases, the :meth:`~.TwoPhaseTransaction.prepare`",
            "            method on each database's :class:`.TwoPhaseTransaction` will be",
            "            called. This allows each database to roll back the entire",
            "            transaction, before each transaction is committed.",
            "",
            "        :param weak_identity_map:  Defaults to ``True`` - when set to",
            "           ``False``, objects placed in the :class:`.Session` will be",
            "           strongly referenced until explicitly removed or the",
            "           :class:`.Session` is closed.",
            "",
            "",
            "        \"\"\"",
            "",
            "        if weak_identity_map in (True, None):",
            "            self._identity_cls = identity.WeakInstanceDict",
            "        else:",
            "            self._identity_cls = identity.StrongInstanceDict",
            "",
            "        self.identity_map = self._identity_cls()",
            "",
            "        self._new = {}  # InstanceState->object, strong refs object",
            "        self._deleted = {}  # same",
            "        self.bind = bind",
            "        self.__binds = {}",
            "        self._flushing = False",
            "        self._warn_on_events = False",
            "        self.transaction = None",
            "        self.hash_key = _new_sessionid()",
            "        self.autoflush = autoflush",
            "        self.autocommit = autocommit",
            "        self.expire_on_commit = expire_on_commit",
            "        self.enable_baked_queries = enable_baked_queries",
            "        self._enable_transaction_accounting = _enable_transaction_accounting",
            "",
            "        self.twophase = twophase",
            "        self._query_cls = query_cls if query_cls else query.Query",
            "        if info:",
            "            self.info.update(info)",
            "",
            "        if extension:",
            "            for ext in util.to_list(extension):",
            "                SessionExtension._adapt_listener(self, ext)",
            "",
            "        if binds is not None:",
            "            for key, bind in binds.items():",
            "                self._add_bind(key, bind)",
            "",
            "        if not self.autocommit:",
            "            self.begin()",
            "        _sessions[self.hash_key] = self",
            "",
            "    connection_callable = None",
            "",
            "    transaction = None",
            "    \"\"\"The current active or inactive :class:`.SessionTransaction`.\"\"\"",
            "",
            "    @util.memoized_property",
            "    def info(self):",
            "        \"\"\"A user-modifiable dictionary.",
            "",
            "        The initial value of this dictionary can be populated using the",
            "        ``info`` argument to the :class:`.Session` constructor or",
            "        :class:`.sessionmaker` constructor or factory methods.  The dictionary",
            "        here is always local to this :class:`.Session` and can be modified",
            "        independently of all other :class:`.Session` objects.",
            "",
            "        .. versionadded:: 0.9.0",
            "",
            "        \"\"\"",
            "        return {}",
            "",
            "    def begin(self, subtransactions=False, nested=False):",
            "        \"\"\"Begin a transaction on this :class:`.Session`.",
            "",
            "        .. warning::",
            "",
            "            The :meth:`.Session.begin` method is part of a larger pattern",
            "            of use with the :class:`.Session` known as **autocommit mode**.",
            "            This is essentially a **legacy mode of use** and is",
            "            not necessary for new applications.    The :class:`.Session`",
            "            normally handles the work of \"begin\" transparently, which in",
            "            turn relies upon the Python DBAPI to transparently \"begin\"",
            "            transactions; there is **no need to explicitly begin transactions**",
            "            when using modern :class:`.Session` programming patterns.",
            "            In its default mode of ``autocommit=False``, the",
            "            :class:`.Session` does all of its work within",
            "            the context of a transaction, so as soon as you call",
            "            :meth:`.Session.commit`, the next transaction is implicitly",
            "            started when the next database operation is invoked.  See",
            "            :ref:`session_autocommit` for further background.",
            "",
            "        The method will raise an error if this :class:`.Session` is already",
            "        inside of a transaction, unless",
            "        :paramref:`~.Session.begin.subtransactions` or",
            "        :paramref:`~.Session.begin.nested` are specified.  A \"subtransaction\"",
            "        is essentially a code embedding pattern that does not affect the",
            "        transactional state of the database connection unless a rollback is",
            "        emitted, in which case the whole transaction is rolled back.  For",
            "        documentation on subtransactions, please see",
            "        :ref:`session_subtransactions`.",
            "",
            "        :param subtransactions: if True, indicates that this",
            "         :meth:`~.Session.begin` can create a \"subtransaction\".",
            "",
            "        :param nested: if True, begins a SAVEPOINT transaction and is",
            "         equivalent to calling :meth:`~.Session.begin_nested`. For",
            "         documentation on SAVEPOINT transactions, please see",
            "         :ref:`session_begin_nested`.",
            "",
            "        :return: the :class:`.SessionTransaction` object.  Note that",
            "         :class:`.SessionTransaction`",
            "         acts as a Python context manager, allowing :meth:`.Session.begin`",
            "         to be used in a \"with\" block.  See :ref:`session_autocommit` for",
            "         an example.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_autocommit`",
            "",
            "            :meth:`.Session.begin_nested`",
            "",
            "",
            "        \"\"\"",
            "        if self.transaction is not None:",
            "            if subtransactions or nested:",
            "                self.transaction = self.transaction._begin(nested=nested)",
            "            else:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"A transaction is already begun.  Use \"",
            "                    \"subtransactions=True to allow subtransactions.\"",
            "                )",
            "        else:",
            "            self.transaction = SessionTransaction(self, nested=nested)",
            "        return self.transaction  # needed for __enter__/__exit__ hook",
            "",
            "    def begin_nested(self):",
            "        \"\"\"Begin a \"nested\" transaction on this Session, e.g. SAVEPOINT.",
            "",
            "        The target database(s) and associated drivers must support SQL",
            "        SAVEPOINT for this method to function correctly.",
            "",
            "        For documentation on SAVEPOINT",
            "        transactions, please see :ref:`session_begin_nested`.",
            "",
            "        :return: the :class:`.SessionTransaction` object.  Note that",
            "         :class:`.SessionTransaction` acts as a context manager, allowing",
            "         :meth:`.Session.begin_nested` to be used in a \"with\" block.",
            "         See :ref:`session_begin_nested` for a usage example.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_begin_nested`",
            "",
            "            :ref:`pysqlite_serializable` - special workarounds required",
            "            with the SQLite driver in order for SAVEPOINT to work",
            "            correctly.",
            "",
            "        \"\"\"",
            "        return self.begin(nested=True)",
            "",
            "    def rollback(self):",
            "        \"\"\"Rollback the current transaction in progress.",
            "",
            "        If no transaction is in progress, this method is a pass-through.",
            "",
            "        This method rolls back the current transaction or nested transaction",
            "        regardless of subtransactions being in effect.  All subtransactions up",
            "        to the first real transaction are closed.  Subtransactions occur when",
            "        :meth:`.begin` is called multiple times.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_rollback`",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            pass",
            "        else:",
            "            self.transaction.rollback()",
            "",
            "    def commit(self):",
            "        \"\"\"Flush pending changes and commit the current transaction.",
            "",
            "        If no transaction is in progress, this method raises an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError`.",
            "",
            "        By default, the :class:`.Session` also expires all database",
            "        loaded state on all ORM-managed attributes after transaction commit.",
            "        This so that subsequent operations load the most recent",
            "        data from the database.   This behavior can be disabled using",
            "        the ``expire_on_commit=False`` option to :class:`.sessionmaker` or",
            "        the :class:`.Session` constructor.",
            "",
            "        If a subtransaction is in effect (which occurs when begin() is called",
            "        multiple times), the subtransaction will be closed, and the next call",
            "        to ``commit()`` will operate on the enclosing transaction.",
            "",
            "        When using the :class:`.Session` in its default mode of",
            "        ``autocommit=False``, a new transaction will",
            "        be begun immediately after the commit, but note that the newly begun",
            "        transaction does *not* use any connection resources until the first",
            "        SQL is actually emitted.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_committing`",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            if not self.autocommit:",
            "                self.begin()",
            "            else:",
            "                raise sa_exc.InvalidRequestError(\"No transaction is begun.\")",
            "",
            "        self.transaction.commit()",
            "",
            "    def prepare(self):",
            "        \"\"\"Prepare the current transaction in progress for two phase commit.",
            "",
            "        If no transaction is in progress, this method raises an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError`.",
            "",
            "        Only root transactions of two phase sessions can be prepared. If the",
            "        current transaction is not such, an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError` is raised.",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            if not self.autocommit:",
            "                self.begin()",
            "            else:",
            "                raise sa_exc.InvalidRequestError(\"No transaction is begun.\")",
            "",
            "        self.transaction.prepare()",
            "",
            "    def connection(",
            "        self,",
            "        mapper=None,",
            "        clause=None,",
            "        bind=None,",
            "        close_with_result=False,",
            "        execution_options=None,",
            "        **kw",
            "    ):",
            "        r\"\"\"Return a :class:`.Connection` object corresponding to this",
            "        :class:`.Session` object's transactional state.",
            "",
            "        If this :class:`.Session` is configured with ``autocommit=False``,",
            "        either the :class:`.Connection` corresponding to the current",
            "        transaction is returned, or if no transaction is in progress, a new",
            "        one is begun and the :class:`.Connection` returned (note that no",
            "        transactional state is established with the DBAPI until the first",
            "        SQL statement is emitted).",
            "",
            "        Alternatively, if this :class:`.Session` is configured with",
            "        ``autocommit=True``, an ad-hoc :class:`.Connection` is returned",
            "        using :meth:`.Engine.connect` on the underlying",
            "        :class:`.Engine`.",
            "",
            "        Ambiguity in multi-bind or unbound :class:`.Session` objects can be",
            "        resolved through any of the optional keyword arguments.   This",
            "        ultimately makes usage of the :meth:`.get_bind` method for resolution.",
            "",
            "        :param bind:",
            "          Optional :class:`.Engine` to be used as the bind.  If",
            "          this engine is already involved in an ongoing transaction,",
            "          that connection will be used.  This argument takes precedence",
            "          over ``mapper``, ``clause``.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` mapped class, used to identify",
            "          the appropriate bind.  This argument takes precedence over",
            "          ``clause``.",
            "",
            "        :param clause:",
            "            A :class:`.ClauseElement` (i.e. :func:`~.sql.expression.select`,",
            "            :func:`~.sql.expression.text`,",
            "            etc.) which will be used to locate a bind, if a bind",
            "            cannot otherwise be identified.",
            "",
            "        :param close_with_result: Passed to :meth:`.Engine.connect`,",
            "          indicating the :class:`.Connection` should be considered",
            "          \"single use\", automatically closing when the first result set is",
            "          closed.  This flag only has an effect if this :class:`.Session` is",
            "          configured with ``autocommit=True`` and does not already have a",
            "          transaction in progress.",
            "",
            "        :param execution_options: a dictionary of execution options that will",
            "         be passed to :meth:`.Connection.execution_options`, **when the",
            "         connection is first procured only**.   If the connection is already",
            "         present within the :class:`.Session`, a warning is emitted and",
            "         the arguments are ignored.",
            "",
            "         .. versionadded:: 0.9.9",
            "",
            "         .. seealso::",
            "",
            "            :ref:`session_transaction_isolation`",
            "",
            "        :param \\**kw:",
            "          Additional keyword arguments are sent to :meth:`get_bind()`,",
            "          allowing additional arguments to be passed to custom",
            "          implementations of :meth:`get_bind`.",
            "",
            "        \"\"\"",
            "        if bind is None:",
            "            bind = self.get_bind(mapper, clause=clause, **kw)",
            "",
            "        return self._connection_for_bind(",
            "            bind,",
            "            close_with_result=close_with_result,",
            "            execution_options=execution_options,",
            "        )",
            "",
            "    def _connection_for_bind(self, engine, execution_options=None, **kw):",
            "        if self.transaction is not None:",
            "            return self.transaction._connection_for_bind(",
            "                engine, execution_options",
            "            )",
            "        else:",
            "            conn = engine._contextual_connect(**kw)",
            "            if execution_options:",
            "                conn = conn.execution_options(**execution_options)",
            "            return conn",
            "",
            "    def execute(self, clause, params=None, mapper=None, bind=None, **kw):",
            "        r\"\"\"Execute a SQL expression construct or string statement within",
            "        the current transaction.",
            "",
            "        Returns a :class:`.ResultProxy` representing",
            "        results of the statement execution, in the same manner as that of an",
            "        :class:`.Engine` or",
            "        :class:`.Connection`.",
            "",
            "        E.g.::",
            "",
            "            result = session.execute(",
            "                        user_table.select().where(user_table.c.id == 5)",
            "                    )",
            "",
            "        :meth:`~.Session.execute` accepts any executable clause construct,",
            "        such as :func:`~.sql.expression.select`,",
            "        :func:`~.sql.expression.insert`,",
            "        :func:`~.sql.expression.update`,",
            "        :func:`~.sql.expression.delete`, and",
            "        :func:`~.sql.expression.text`.  Plain SQL strings can be passed",
            "        as well, which in the case of :meth:`.Session.execute` only",
            "        will be interpreted the same as if it were passed via a",
            "        :func:`~.expression.text` construct.  That is, the following usage::",
            "",
            "            result = session.execute(",
            "                        \"SELECT * FROM user WHERE id=:param\",",
            "                        {\"param\":5}",
            "                    )",
            "",
            "        is equivalent to::",
            "",
            "            from sqlalchemy import text",
            "            result = session.execute(",
            "                        text(\"SELECT * FROM user WHERE id=:param\"),",
            "                        {\"param\":5}",
            "                    )",
            "",
            "        The second positional argument to :meth:`.Session.execute` is an",
            "        optional parameter set.  Similar to that of",
            "        :meth:`.Connection.execute`, whether this is passed as a single",
            "        dictionary, or a list of dictionaries, determines whether the DBAPI",
            "        cursor's ``execute()`` or ``executemany()`` is used to execute the",
            "        statement.   An INSERT construct may be invoked for a single row::",
            "",
            "            result = session.execute(",
            "                users.insert(), {\"id\": 7, \"name\": \"somename\"})",
            "",
            "        or for multiple rows::",
            "",
            "            result = session.execute(users.insert(), [",
            "                                    {\"id\": 7, \"name\": \"somename7\"},",
            "                                    {\"id\": 8, \"name\": \"somename8\"},",
            "                                    {\"id\": 9, \"name\": \"somename9\"}",
            "                                ])",
            "",
            "        The statement is executed within the current transactional context of",
            "        this :class:`.Session`.   The :class:`.Connection` which is used",
            "        to execute the statement can also be acquired directly by",
            "        calling the :meth:`.Session.connection` method.  Both methods use",
            "        a rule-based resolution scheme in order to determine the",
            "        :class:`.Connection`, which in the average case is derived directly",
            "        from the \"bind\" of the :class:`.Session` itself, and in other cases",
            "        can be based on the :func:`.mapper`",
            "        and :class:`.Table` objects passed to the method; see the",
            "        documentation for :meth:`.Session.get_bind` for a full description of",
            "        this scheme.",
            "",
            "        The :meth:`.Session.execute` method does *not* invoke autoflush.",
            "",
            "        The :class:`.ResultProxy` returned by the :meth:`.Session.execute`",
            "        method is returned with the \"close_with_result\" flag set to true;",
            "        the significance of this flag is that if this :class:`.Session` is",
            "        autocommitting and does not have a transaction-dedicated",
            "        :class:`.Connection` available, a temporary :class:`.Connection` is",
            "        established for the statement execution, which is closed (meaning,",
            "        returned to the connection pool) when the :class:`.ResultProxy` has",
            "        consumed all available data. This applies *only* when the",
            "        :class:`.Session` is configured with autocommit=True and no",
            "        transaction has been started.",
            "",
            "        :param clause:",
            "            An executable statement (i.e. an :class:`.Executable` expression",
            "            such as :func:`.expression.select`) or string SQL statement",
            "            to be executed.",
            "",
            "        :param params:",
            "            Optional dictionary, or list of dictionaries, containing",
            "            bound parameter values.   If a single dictionary, single-row",
            "            execution occurs; if a list of dictionaries, an",
            "            \"executemany\" will be invoked.  The keys in each dictionary",
            "            must correspond to parameter names present in the statement.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` or mapped class, used to identify",
            "          the appropriate bind.  This argument takes precedence over",
            "          ``clause`` when locating a bind.   See :meth:`.Session.get_bind`",
            "          for more details.",
            "",
            "        :param bind:",
            "          Optional :class:`.Engine` to be used as the bind.  If",
            "          this engine is already involved in an ongoing transaction,",
            "          that connection will be used.  This argument takes",
            "          precedence over ``mapper`` and ``clause`` when locating",
            "          a bind.",
            "",
            "        :param \\**kw:",
            "          Additional keyword arguments are sent to :meth:`.Session.get_bind()`",
            "          to allow extensibility of \"bind\" schemes.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`sqlexpression_toplevel` - Tutorial on using Core SQL",
            "            constructs.",
            "",
            "            :ref:`connections_toplevel` - Further information on direct",
            "            statement execution.",
            "",
            "            :meth:`.Connection.execute` - core level statement execution",
            "            method, which is :meth:`.Session.execute` ultimately uses",
            "            in order to execute the statement.",
            "",
            "        \"\"\"",
            "        clause = expression._literal_as_text(clause)",
            "",
            "        if bind is None:",
            "            bind = self.get_bind(mapper, clause=clause, **kw)",
            "",
            "        return self._connection_for_bind(bind, close_with_result=True).execute(",
            "            clause, params or {}",
            "        )",
            "",
            "    def scalar(self, clause, params=None, mapper=None, bind=None, **kw):",
            "        \"\"\"Like :meth:`~.Session.execute` but return a scalar result.\"\"\"",
            "",
            "        return self.execute(",
            "            clause, params=params, mapper=mapper, bind=bind, **kw",
            "        ).scalar()",
            "",
            "    def close(self):",
            "        \"\"\"Close this Session.",
            "",
            "        This clears all items and ends any transaction in progress.",
            "",
            "        If this session were created with ``autocommit=False``, a new",
            "        transaction is immediately begun.  Note that this new transaction does",
            "        not use any connection resources until they are first needed.",
            "",
            "        \"\"\"",
            "        self._close_impl(invalidate=False)",
            "",
            "    def invalidate(self):",
            "        \"\"\"Close this Session, using connection invalidation.",
            "",
            "        This is a variant of :meth:`.Session.close` that will additionally",
            "        ensure that the :meth:`.Connection.invalidate` method will be called",
            "        on all :class:`.Connection` objects.  This can be called when",
            "        the database is known to be in a state where the connections are",
            "        no longer safe to be used.",
            "",
            "        E.g.::",
            "",
            "            try:",
            "                sess = Session()",
            "                sess.add(User())",
            "                sess.commit()",
            "            except gevent.Timeout:",
            "                sess.invalidate()",
            "                raise",
            "            except:",
            "                sess.rollback()",
            "                raise",
            "",
            "        This clears all items and ends any transaction in progress.",
            "",
            "        If this session were created with ``autocommit=False``, a new",
            "        transaction is immediately begun.  Note that this new transaction does",
            "        not use any connection resources until they are first needed.",
            "",
            "        .. versionadded:: 0.9.9",
            "",
            "        \"\"\"",
            "        self._close_impl(invalidate=True)",
            "",
            "    def _close_impl(self, invalidate):",
            "        self.expunge_all()",
            "        if self.transaction is not None:",
            "            for transaction in self.transaction._iterate_self_and_parents():",
            "                transaction.close(invalidate)",
            "",
            "    def expunge_all(self):",
            "        \"\"\"Remove all object instances from this ``Session``.",
            "",
            "        This is equivalent to calling ``expunge(obj)`` on all objects in this",
            "        ``Session``.",
            "",
            "        \"\"\"",
            "",
            "        all_states = self.identity_map.all_states() + list(self._new)",
            "        self.identity_map = self._identity_cls()",
            "        self._new = {}",
            "        self._deleted = {}",
            "",
            "        statelib.InstanceState._detach_states(all_states, self)",
            "",
            "    def _add_bind(self, key, bind):",
            "        try:",
            "            insp = inspect(key)",
            "        except sa_exc.NoInspectionAvailable:",
            "            if not isinstance(key, type):",
            "                raise sa_exc.ArgumentError(",
            "                    \"Not an acceptable bind target: %s\" % key",
            "                )",
            "            else:",
            "                self.__binds[key] = bind",
            "        else:",
            "            if insp.is_selectable:",
            "                self.__binds[insp] = bind",
            "            elif insp.is_mapper:",
            "                self.__binds[insp.class_] = bind",
            "                for selectable in insp._all_tables:",
            "                    self.__binds[selectable] = bind",
            "            else:",
            "                raise sa_exc.ArgumentError(",
            "                    \"Not an acceptable bind target: %s\" % key",
            "                )",
            "",
            "    def bind_mapper(self, mapper, bind):",
            "        \"\"\"Associate a :class:`.Mapper` or arbitrary Python class with a",
            "        \"bind\", e.g. an :class:`.Engine` or :class:`.Connection`.",
            "",
            "        The given entity is added to a lookup used by the",
            "        :meth:`.Session.get_bind` method.",
            "",
            "        :param mapper: a :class:`.Mapper` object, or an instance of a mapped",
            "         class, or any Python class that is the base of a set of mapped",
            "         classes.",
            "",
            "        :param bind: an :class:`.Engine` or :class:`.Connection` object.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_partitioning`",
            "",
            "            :paramref:`.Session.binds`",
            "",
            "            :meth:`.Session.bind_table`",
            "",
            "",
            "        \"\"\"",
            "        self._add_bind(mapper, bind)",
            "",
            "    def bind_table(self, table, bind):",
            "        \"\"\"Associate a :class:`.Table` with a \"bind\", e.g. an :class:`.Engine`",
            "        or :class:`.Connection`.",
            "",
            "        The given :class:`.Table` is added to a lookup used by the",
            "        :meth:`.Session.get_bind` method.",
            "",
            "        :param table: a :class:`.Table` object, which is typically the target",
            "         of an ORM mapping, or is present within a selectable that is",
            "         mapped.",
            "",
            "        :param bind: an :class:`.Engine` or :class:`.Connection` object.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_partitioning`",
            "",
            "            :paramref:`.Session.binds`",
            "",
            "            :meth:`.Session.bind_mapper`",
            "",
            "",
            "        \"\"\"",
            "        self._add_bind(table, bind)",
            "",
            "    def get_bind(self, mapper=None, clause=None):",
            "        \"\"\"Return a \"bind\" to which this :class:`.Session` is bound.",
            "",
            "        The \"bind\" is usually an instance of :class:`.Engine`,",
            "        except in the case where the :class:`.Session` has been",
            "        explicitly bound directly to a :class:`.Connection`.",
            "",
            "        For a multiply-bound or unbound :class:`.Session`, the",
            "        ``mapper`` or ``clause`` arguments are used to determine the",
            "        appropriate bind to return.",
            "",
            "        Note that the \"mapper\" argument is usually present",
            "        when :meth:`.Session.get_bind` is called via an ORM",
            "        operation such as a :meth:`.Session.query`, each",
            "        individual INSERT/UPDATE/DELETE operation within a",
            "        :meth:`.Session.flush`, call, etc.",
            "",
            "        The order of resolution is:",
            "",
            "        1. if mapper given and session.binds is present,",
            "           locate a bind based first on the mapper in use, then",
            "           on the mapped class in use, then on any base classes that are",
            "           present in the ``__mro__`` of the mapped class, from more specific",
            "           superclasses to more general.",
            "        2. if clause given and session.binds is present,",
            "           locate a bind based on :class:`.Table` objects",
            "           found in the given clause present in session.binds.",
            "        3. if session.bind is present, return that.",
            "        4. if clause given, attempt to return a bind",
            "           linked to the :class:`.MetaData` ultimately",
            "           associated with the clause.",
            "        5. if mapper given, attempt to return a bind",
            "           linked to the :class:`.MetaData` ultimately",
            "           associated with the :class:`.Table` or other",
            "           selectable to which the mapper is mapped.",
            "        6. No bind can be found, :exc:`~sqlalchemy.exc.UnboundExecutionError`",
            "           is raised.",
            "",
            "        Note that the :meth:`.Session.get_bind` method can be overridden on",
            "        a user-defined subclass of :class:`.Session` to provide any kind",
            "        of bind resolution scheme.  See the example at",
            "        :ref:`session_custom_partitioning`.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` mapped class or instance of",
            "          :class:`.Mapper`.   The bind can be derived from a :class:`.Mapper`",
            "          first by consulting the \"binds\" map associated with this",
            "          :class:`.Session`, and secondly by consulting the :class:`.MetaData`",
            "          associated with the :class:`.Table` to which the :class:`.Mapper`",
            "          is mapped for a bind.",
            "",
            "        :param clause:",
            "            A :class:`.ClauseElement` (i.e. :func:`~.sql.expression.select`,",
            "            :func:`~.sql.expression.text`,",
            "            etc.).  If the ``mapper`` argument is not present or could not",
            "            produce a bind, the given expression construct will be searched",
            "            for a bound element, typically a :class:`.Table` associated with",
            "            bound :class:`.MetaData`.",
            "",
            "        .. seealso::",
            "",
            "             :ref:`session_partitioning`",
            "",
            "             :paramref:`.Session.binds`",
            "",
            "             :meth:`.Session.bind_mapper`",
            "",
            "             :meth:`.Session.bind_table`",
            "",
            "        \"\"\"",
            "",
            "        if mapper is clause is None:",
            "            if self.bind:",
            "                return self.bind",
            "            else:",
            "                raise sa_exc.UnboundExecutionError(",
            "                    \"This session is not bound to a single Engine or \"",
            "                    \"Connection, and no context was provided to locate \"",
            "                    \"a binding.\"",
            "                )",
            "",
            "        if mapper is not None:",
            "            try:",
            "                mapper = inspect(mapper)",
            "            except sa_exc.NoInspectionAvailable:",
            "                if isinstance(mapper, type):",
            "                    raise exc.UnmappedClassError(mapper)",
            "                else:",
            "                    raise",
            "",
            "        if self.__binds:",
            "            if mapper:",
            "                for cls in mapper.class_.__mro__:",
            "                    if cls in self.__binds:",
            "                        return self.__binds[cls]",
            "                if clause is None:",
            "                    clause = mapper.persist_selectable",
            "",
            "            if clause is not None:",
            "                for t in sql_util.find_tables(clause, include_crud=True):",
            "                    if t in self.__binds:",
            "                        return self.__binds[t]",
            "",
            "        if self.bind:",
            "            return self.bind",
            "",
            "        if isinstance(clause, sql.expression.ClauseElement) and clause.bind:",
            "            return clause.bind",
            "",
            "        if mapper and mapper.persist_selectable.bind:",
            "            return mapper.persist_selectable.bind",
            "",
            "        context = []",
            "        if mapper is not None:",
            "            context.append(\"mapper %s\" % mapper)",
            "        if clause is not None:",
            "            context.append(\"SQL expression\")",
            "",
            "        raise sa_exc.UnboundExecutionError(",
            "            \"Could not locate a bind configured on %s or this Session\"",
            "            % (\", \".join(context))",
            "        )",
            "",
            "    def query(self, *entities, **kwargs):",
            "        \"\"\"Return a new :class:`.Query` object corresponding to this",
            "        :class:`.Session`.\"\"\"",
            "",
            "        return self._query_cls(entities, self, **kwargs)",
            "",
            "    @property",
            "    @util.contextmanager",
            "    def no_autoflush(self):",
            "        \"\"\"Return a context manager that disables autoflush.",
            "",
            "        e.g.::",
            "",
            "            with session.no_autoflush:",
            "",
            "                some_object = SomeClass()",
            "                session.add(some_object)",
            "                # won't autoflush",
            "                some_object.related_thing = session.query(SomeRelated).first()",
            "",
            "        Operations that proceed within the ``with:`` block",
            "        will not be subject to flushes occurring upon query",
            "        access.  This is useful when initializing a series",
            "        of objects which involve existing database queries,",
            "        where the uncompleted object should not yet be flushed.",
            "",
            "        \"\"\"",
            "        autoflush = self.autoflush",
            "        self.autoflush = False",
            "        try:",
            "            yield self",
            "        finally:",
            "            self.autoflush = autoflush",
            "",
            "    def _autoflush(self):",
            "        if self.autoflush and not self._flushing:",
            "            try:",
            "                self.flush()",
            "            except sa_exc.StatementError as e:",
            "                # note we are reraising StatementError as opposed to",
            "                # raising FlushError with \"chaining\" to remain compatible",
            "                # with code that catches StatementError, IntegrityError,",
            "                # etc.",
            "                e.add_detail(",
            "                    \"raised as a result of Query-invoked autoflush; \"",
            "                    \"consider using a session.no_autoflush block if this \"",
            "                    \"flush is occurring prematurely\"",
            "                )",
            "                util.raise_from_cause(e)",
            "",
            "    def refresh(",
            "        self,",
            "        instance,",
            "        attribute_names=None,",
            "        with_for_update=None,",
            "        lockmode=None,",
            "    ):",
            "        \"\"\"Expire and refresh the attributes on the given instance.",
            "",
            "        A query will be issued to the database and all attributes will be",
            "        refreshed with their current database value.",
            "",
            "        Lazy-loaded relational attributes will remain lazily loaded, so that",
            "        the instance-wide refresh operation will be followed immediately by",
            "        the lazy load of that attribute.",
            "",
            "        Eagerly-loaded relational attributes will eagerly load within the",
            "        single refresh operation.",
            "",
            "        Note that a highly isolated transaction will return the same values as",
            "        were previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction - usage of",
            "        :meth:`~Session.refresh` usually only makes sense if non-ORM SQL",
            "        statement were emitted in the ongoing transaction, or if autocommit",
            "        mode is turned on.",
            "",
            "        :param attribute_names: optional.  An iterable collection of",
            "          string attribute names indicating a subset of attributes to",
            "          be refreshed.",
            "",
            "        :param with_for_update: optional boolean ``True`` indicating FOR UPDATE",
            "          should be used, or may be a dictionary containing flags to",
            "          indicate a more specific set of FOR UPDATE flags for the SELECT;",
            "          flags should match the parameters of :meth:`.Query.with_for_update`.",
            "          Supersedes the :paramref:`.Session.refresh.lockmode` parameter.",
            "",
            "          .. versionadded:: 1.2",
            "",
            "        :param lockmode: Passed to the :class:`~sqlalchemy.orm.query.Query`",
            "          as used by :meth:`~sqlalchemy.orm.query.Query.with_lockmode`.",
            "          Superseded by :paramref:`.Session.refresh.with_for_update`.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.expire_all`",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._expire_state(state, attribute_names)",
            "",
            "        if with_for_update == {}:",
            "            raise sa_exc.ArgumentError(",
            "                \"with_for_update should be the boolean value \"",
            "                \"True, or a dictionary with options.  \"",
            "                \"A blank dictionary is ambiguous.\"",
            "            )",
            "",
            "        if lockmode:",
            "            with_for_update = query.LockmodeArg.parse_legacy_query(lockmode)",
            "        elif with_for_update is not None:",
            "            if with_for_update is True:",
            "                with_for_update = query.LockmodeArg()",
            "            elif with_for_update:",
            "                with_for_update = query.LockmodeArg(**with_for_update)",
            "            else:",
            "                with_for_update = None",
            "",
            "        if (",
            "            loading.load_on_ident(",
            "                self.query(object_mapper(instance)),",
            "                state.key,",
            "                refresh_state=state,",
            "                with_for_update=with_for_update,",
            "                only_load_props=attribute_names,",
            "            )",
            "            is None",
            "        ):",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Could not refresh instance '%s'\" % instance_str(instance)",
            "            )",
            "",
            "    def expire_all(self):",
            "        \"\"\"Expires all persistent instances within this Session.",
            "",
            "        When any attributes on a persistent instance is next accessed,",
            "        a query will be issued using the",
            "        :class:`.Session` object's current transactional context in order to",
            "        load all expired attributes for the given instance.   Note that",
            "        a highly isolated transaction will return the same values as were",
            "        previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction.",
            "",
            "        To expire individual objects and individual attributes",
            "        on those objects, use :meth:`Session.expire`.",
            "",
            "        The :class:`.Session` object's default behavior is to",
            "        expire all state whenever the :meth:`Session.rollback`",
            "        or :meth:`Session.commit` methods are called, so that new",
            "        state can be loaded for the new transaction.   For this reason,",
            "        calling :meth:`Session.expire_all` should not be needed when",
            "        autocommit is ``False``, assuming the transaction is isolated.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.refresh`",
            "",
            "        \"\"\"",
            "        for state in self.identity_map.all_states():",
            "            state._expire(state.dict, self.identity_map._modified)",
            "",
            "    def expire(self, instance, attribute_names=None):",
            "        \"\"\"Expire the attributes on an instance.",
            "",
            "        Marks the attributes of an instance as out of date. When an expired",
            "        attribute is next accessed, a query will be issued to the",
            "        :class:`.Session` object's current transactional context in order to",
            "        load all expired attributes for the given instance.   Note that",
            "        a highly isolated transaction will return the same values as were",
            "        previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction.",
            "",
            "        To expire all objects in the :class:`.Session` simultaneously,",
            "        use :meth:`Session.expire_all`.",
            "",
            "        The :class:`.Session` object's default behavior is to",
            "        expire all state whenever the :meth:`Session.rollback`",
            "        or :meth:`Session.commit` methods are called, so that new",
            "        state can be loaded for the new transaction.   For this reason,",
            "        calling :meth:`Session.expire` only makes sense for the specific",
            "        case that a non-ORM SQL statement was emitted in the current",
            "        transaction.",
            "",
            "        :param instance: The instance to be refreshed.",
            "        :param attribute_names: optional list of string attribute names",
            "          indicating a subset of attributes to be expired.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.refresh`",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        self._expire_state(state, attribute_names)",
            "",
            "    def _expire_state(self, state, attribute_names):",
            "        self._validate_persistent(state)",
            "        if attribute_names:",
            "            state._expire_attributes(state.dict, attribute_names)",
            "        else:",
            "            # pre-fetch the full cascade since the expire is going to",
            "            # remove associations",
            "            cascaded = list(",
            "                state.manager.mapper.cascade_iterator(\"refresh-expire\", state)",
            "            )",
            "            self._conditional_expire(state)",
            "            for o, m, st_, dct_ in cascaded:",
            "                self._conditional_expire(st_)",
            "",
            "    def _conditional_expire(self, state):",
            "        \"\"\"Expire a state if persistent, else expunge if pending\"\"\"",
            "",
            "        if state.key:",
            "            state._expire(state.dict, self.identity_map._modified)",
            "        elif state in self._new:",
            "            self._new.pop(state)",
            "            state._detach(self)",
            "",
            "    @util.deprecated(",
            "        \"0.7\",",
            "        \"The :meth:`.Session.prune` method is deprecated along with \"",
            "        \":paramref:`.Session.weak_identity_map`.  This method will be \"",
            "        \"removed in a future release.\",",
            "    )",
            "    def prune(self):",
            "        \"\"\"Remove unreferenced instances cached in the identity map.",
            "",
            "        Note that this method is only meaningful if \"weak_identity_map\" is set",
            "        to False.  The default weak identity map is self-pruning.",
            "",
            "        Removes any object in this Session's identity map that is not",
            "        referenced in user code, modified, new or scheduled for deletion.",
            "        Returns the number of objects pruned.",
            "",
            "        \"\"\"",
            "        return self.identity_map.prune()",
            "",
            "    def expunge(self, instance):",
            "        \"\"\"Remove the `instance` from this ``Session``.",
            "",
            "        This will free all internal references to the instance.  Cascading",
            "        will be applied according to the *expunge* cascade rule.",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        if state.session_id is not self.hash_key:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance %s is not present in this Session\" % state_str(state)",
            "            )",
            "",
            "        cascaded = list(",
            "            state.manager.mapper.cascade_iterator(\"expunge\", state)",
            "        )",
            "        self._expunge_states([state] + [st_ for o, m, st_, dct_ in cascaded])",
            "",
            "    def _expunge_states(self, states, to_transient=False):",
            "        for state in states:",
            "            if state in self._new:",
            "                self._new.pop(state)",
            "            elif self.identity_map.contains_state(state):",
            "                self.identity_map.safe_discard(state)",
            "                self._deleted.pop(state, None)",
            "            elif self.transaction:",
            "                # state is \"detached\" from being deleted, but still present",
            "                # in the transaction snapshot",
            "                self.transaction._deleted.pop(state, None)",
            "        statelib.InstanceState._detach_states(",
            "            states, self, to_transient=to_transient",
            "        )",
            "",
            "    def _register_newly_persistent(self, states):",
            "        pending_to_persistent = self.dispatch.pending_to_persistent or None",
            "        for state in states:",
            "            mapper = _state_mapper(state)",
            "",
            "            # prevent against last minute dereferences of the object",
            "            obj = state.obj()",
            "            if obj is not None:",
            "",
            "                instance_key = mapper._identity_key_from_state(state)",
            "",
            "                if (",
            "                    _none_set.intersection(instance_key[1])",
            "                    and not mapper.allow_partial_pks",
            "                    or _none_set.issuperset(instance_key[1])",
            "                ):",
            "                    raise exc.FlushError(",
            "                        \"Instance %s has a NULL identity key.  If this is an \"",
            "                        \"auto-generated value, check that the database table \"",
            "                        \"allows generation of new primary key values, and \"",
            "                        \"that the mapped Column object is configured to \"",
            "                        \"expect these generated values.  Ensure also that \"",
            "                        \"this flush() is not occurring at an inappropriate \"",
            "                        \"time, such as within a load() event.\"",
            "                        % state_str(state)",
            "                    )",
            "",
            "                if state.key is None:",
            "                    state.key = instance_key",
            "                elif state.key != instance_key:",
            "                    # primary key switch. use safe_discard() in case another",
            "                    # state has already replaced this one in the identity",
            "                    # map (see test/orm/test_naturalpks.py ReversePKsTest)",
            "                    self.identity_map.safe_discard(state)",
            "                    if state in self.transaction._key_switches:",
            "                        orig_key = self.transaction._key_switches[state][0]",
            "                    else:",
            "                        orig_key = state.key",
            "                    self.transaction._key_switches[state] = (",
            "                        orig_key,",
            "                        instance_key,",
            "                    )",
            "                    state.key = instance_key",
            "",
            "                self.identity_map.replace(state)",
            "                state._orphaned_outside_of_session = False",
            "",
            "        statelib.InstanceState._commit_all_states(",
            "            ((state, state.dict) for state in states), self.identity_map",
            "        )",
            "",
            "        self._register_altered(states)",
            "",
            "        if pending_to_persistent is not None:",
            "            for state in states:",
            "                pending_to_persistent(self, state.obj())",
            "",
            "        # remove from new last, might be the last strong ref",
            "        for state in set(states).intersection(self._new):",
            "            self._new.pop(state)",
            "",
            "    def _register_altered(self, states):",
            "        if self._enable_transaction_accounting and self.transaction:",
            "            for state in states:",
            "                if state in self._new:",
            "                    self.transaction._new[state] = True",
            "                else:",
            "                    self.transaction._dirty[state] = True",
            "",
            "    def _remove_newly_deleted(self, states):",
            "        persistent_to_deleted = self.dispatch.persistent_to_deleted or None",
            "        for state in states:",
            "            if self._enable_transaction_accounting and self.transaction:",
            "                self.transaction._deleted[state] = True",
            "",
            "            if persistent_to_deleted is not None:",
            "                # get a strong reference before we pop out of",
            "                # self._deleted",
            "                obj = state.obj()",
            "",
            "            self.identity_map.safe_discard(state)",
            "            self._deleted.pop(state, None)",
            "            state._deleted = True",
            "            # can't call state._detach() here, because this state",
            "            # is still in the transaction snapshot and needs to be",
            "            # tracked as part of that",
            "            if persistent_to_deleted is not None:",
            "                persistent_to_deleted(self, obj)",
            "",
            "    def add(self, instance, _warn=True):",
            "        \"\"\"Place an object in the ``Session``.",
            "",
            "        Its state will be persisted to the database on the next flush",
            "        operation.",
            "",
            "        Repeated calls to ``add()`` will be ignored. The opposite of ``add()``",
            "        is ``expunge()``.",
            "",
            "        \"\"\"",
            "        if _warn and self._warn_on_events:",
            "            self._flush_warning(\"Session.add()\")",
            "",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._save_or_update_state(state)",
            "",
            "    def add_all(self, instances):",
            "        \"\"\"Add the given collection of instances to this ``Session``.\"\"\"",
            "",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.add_all()\")",
            "",
            "        for instance in instances:",
            "            self.add(instance, _warn=False)",
            "",
            "    def _save_or_update_state(self, state):",
            "        state._orphaned_outside_of_session = False",
            "        self._save_or_update_impl(state)",
            "",
            "        mapper = _state_mapper(state)",
            "        for o, m, st_, dct_ in mapper.cascade_iterator(",
            "            \"save-update\", state, halt_on=self._contains_state",
            "        ):",
            "            self._save_or_update_impl(st_)",
            "",
            "    def delete(self, instance):",
            "        \"\"\"Mark an instance as deleted.",
            "",
            "        The database delete operation occurs upon ``flush()``.",
            "",
            "        \"\"\"",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.delete()\")",
            "",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._delete_impl(state, instance, head=True)",
            "",
            "    def _delete_impl(self, state, obj, head):",
            "",
            "        if state.key is None:",
            "            if head:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Instance '%s' is not persisted\" % state_str(state)",
            "                )",
            "            else:",
            "                return",
            "",
            "        to_attach = self._before_attach(state, obj)",
            "",
            "        if state in self._deleted:",
            "            return",
            "",
            "        self.identity_map.add(state)",
            "",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "        if head:",
            "            # grab the cascades before adding the item to the deleted list",
            "            # so that autoflush does not delete the item",
            "            # the strong reference to the instance itself is significant here",
            "            cascade_states = list(",
            "                state.manager.mapper.cascade_iterator(\"delete\", state)",
            "            )",
            "",
            "        self._deleted[state] = obj",
            "",
            "        if head:",
            "            for o, m, st_, dct_ in cascade_states:",
            "                self._delete_impl(st_, o, False)",
            "",
            "    def merge(self, instance, load=True):",
            "        \"\"\"Copy the state of a given instance into a corresponding instance",
            "        within this :class:`.Session`.",
            "",
            "        :meth:`.Session.merge` examines the primary key attributes of the",
            "        source instance, and attempts to reconcile it with an instance of the",
            "        same primary key in the session.   If not found locally, it attempts",
            "        to load the object from the database based on primary key, and if",
            "        none can be located, creates a new instance.  The state of each",
            "        attribute on the source instance is then copied to the target",
            "        instance.  The resulting target instance is then returned by the",
            "        method; the original source instance is left unmodified, and",
            "        un-associated with the :class:`.Session` if not already.",
            "",
            "        This operation cascades to associated instances if the association is",
            "        mapped with ``cascade=\"merge\"``.",
            "",
            "        See :ref:`unitofwork_merging` for a detailed discussion of merging.",
            "",
            "        .. versionchanged:: 1.1 - :meth:`.Session.merge` will now reconcile",
            "           pending objects with overlapping primary keys in the same way",
            "           as persistent.  See :ref:`change_3601` for discussion.",
            "",
            "        :param instance: Instance to be merged.",
            "        :param load: Boolean, when False, :meth:`.merge` switches into",
            "         a \"high performance\" mode which causes it to forego emitting history",
            "         events as well as all database access.  This flag is used for",
            "         cases such as transferring graphs of objects into a :class:`.Session`",
            "         from a second level cache, or to transfer just-loaded objects",
            "         into the :class:`.Session` owned by a worker thread or process",
            "         without re-querying the database.",
            "",
            "         The ``load=False`` use case adds the caveat that the given",
            "         object has to be in a \"clean\" state, that is, has no pending changes",
            "         to be flushed - even if the incoming object is detached from any",
            "         :class:`.Session`.   This is so that when",
            "         the merge operation populates local attributes and",
            "         cascades to related objects and",
            "         collections, the values can be \"stamped\" onto the",
            "         target object as is, without generating any history or attribute",
            "         events, and without the need to reconcile the incoming data with",
            "         any existing related objects or collections that might not",
            "         be loaded.  The resulting objects from ``load=False`` are always",
            "         produced as \"clean\", so it is only appropriate that the given objects",
            "         should be \"clean\" as well, else this suggests a mis-use of the",
            "         method.",
            "",
            "",
            "        .. seealso::",
            "",
            "            :func:`.make_transient_to_detached` - provides for an alternative",
            "            means of \"merging\" a single object into the :class:`.Session`",
            "",
            "        \"\"\"",
            "",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.merge()\")",
            "",
            "        _recursive = {}",
            "        _resolve_conflict_map = {}",
            "",
            "        if load:",
            "            # flush current contents if we expect to load data",
            "            self._autoflush()",
            "",
            "        object_mapper(instance)  # verify mapped",
            "        autoflush = self.autoflush",
            "        try:",
            "            self.autoflush = False",
            "            return self._merge(",
            "                attributes.instance_state(instance),",
            "                attributes.instance_dict(instance),",
            "                load=load,",
            "                _recursive=_recursive,",
            "                _resolve_conflict_map=_resolve_conflict_map,",
            "            )",
            "        finally:",
            "            self.autoflush = autoflush",
            "",
            "    def _merge(",
            "        self,",
            "        state,",
            "        state_dict,",
            "        load=True,",
            "        _recursive=None,",
            "        _resolve_conflict_map=None,",
            "    ):",
            "        mapper = _state_mapper(state)",
            "        if state in _recursive:",
            "            return _recursive[state]",
            "",
            "        new_instance = False",
            "        key = state.key",
            "",
            "        if key is None:",
            "            if not load:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"merge() with load=False option does not support \"",
            "                    \"objects transient (i.e. unpersisted) objects.  flush() \"",
            "                    \"all changes on mapped instances before merging with \"",
            "                    \"load=False.\"",
            "                )",
            "            key = mapper._identity_key_from_state(state)",
            "            key_is_persistent = attributes.NEVER_SET not in key[1] and (",
            "                not _none_set.intersection(key[1])",
            "                or (",
            "                    mapper.allow_partial_pks",
            "                    and not _none_set.issuperset(key[1])",
            "                )",
            "            )",
            "        else:",
            "            key_is_persistent = True",
            "",
            "        if key in self.identity_map:",
            "            try:",
            "                merged = self.identity_map[key]",
            "            except KeyError:",
            "                # object was GC'ed right as we checked for it",
            "                merged = None",
            "        else:",
            "            merged = None",
            "",
            "        if merged is None:",
            "            if key_is_persistent and key in _resolve_conflict_map:",
            "                merged = _resolve_conflict_map[key]",
            "",
            "            elif not load:",
            "                if state.modified:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"merge() with load=False option does not support \"",
            "                        \"objects marked as 'dirty'.  flush() all changes on \"",
            "                        \"mapped instances before merging with load=False.\"",
            "                    )",
            "                merged = mapper.class_manager.new_instance()",
            "                merged_state = attributes.instance_state(merged)",
            "                merged_state.key = key",
            "                self._update_impl(merged_state)",
            "                new_instance = True",
            "",
            "            elif key_is_persistent:",
            "                merged = self.query(mapper.class_).get(key[1])",
            "",
            "        if merged is None:",
            "            merged = mapper.class_manager.new_instance()",
            "            merged_state = attributes.instance_state(merged)",
            "            merged_dict = attributes.instance_dict(merged)",
            "            new_instance = True",
            "            self._save_or_update_state(merged_state)",
            "        else:",
            "            merged_state = attributes.instance_state(merged)",
            "            merged_dict = attributes.instance_dict(merged)",
            "",
            "        _recursive[state] = merged",
            "        _resolve_conflict_map[key] = merged",
            "",
            "        # check that we didn't just pull the exact same",
            "        # state out.",
            "        if state is not merged_state:",
            "            # version check if applicable",
            "            if mapper.version_id_col is not None:",
            "                existing_version = mapper._get_state_attr_by_column(",
            "                    state,",
            "                    state_dict,",
            "                    mapper.version_id_col,",
            "                    passive=attributes.PASSIVE_NO_INITIALIZE,",
            "                )",
            "",
            "                merged_version = mapper._get_state_attr_by_column(",
            "                    merged_state,",
            "                    merged_dict,",
            "                    mapper.version_id_col,",
            "                    passive=attributes.PASSIVE_NO_INITIALIZE,",
            "                )",
            "",
            "                if (",
            "                    existing_version is not attributes.PASSIVE_NO_RESULT",
            "                    and merged_version is not attributes.PASSIVE_NO_RESULT",
            "                    and existing_version != merged_version",
            "                ):",
            "                    raise exc.StaleDataError(",
            "                        \"Version id '%s' on merged state %s \"",
            "                        \"does not match existing version '%s'. \"",
            "                        \"Leave the version attribute unset when \"",
            "                        \"merging to update the most recent version.\"",
            "                        % (",
            "                            existing_version,",
            "                            state_str(merged_state),",
            "                            merged_version,",
            "                        )",
            "                    )",
            "",
            "            merged_state.load_path = state.load_path",
            "            merged_state.load_options = state.load_options",
            "",
            "            # since we are copying load_options, we need to copy",
            "            # the callables_ that would have been generated by those",
            "            # load_options.",
            "            # assumes that the callables we put in state.callables_",
            "            # are not instance-specific (which they should not be)",
            "            merged_state._copy_callables(state)",
            "",
            "            for prop in mapper.iterate_properties:",
            "                prop.merge(",
            "                    self,",
            "                    state,",
            "                    state_dict,",
            "                    merged_state,",
            "                    merged_dict,",
            "                    load,",
            "                    _recursive,",
            "                    _resolve_conflict_map,",
            "                )",
            "",
            "        if not load:",
            "            # remove any history",
            "            merged_state._commit_all(merged_dict, self.identity_map)",
            "",
            "        if new_instance:",
            "            merged_state.manager.dispatch.load(merged_state, None)",
            "        return merged",
            "",
            "    def _validate_persistent(self, state):",
            "        if not self.identity_map.contains_state(state):",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance '%s' is not persistent within this Session\"",
            "                % state_str(state)",
            "            )",
            "",
            "    def _save_impl(self, state):",
            "        if state.key is not None:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Object '%s' already has an identity - \"",
            "                \"it can't be registered as pending\" % state_str(state)",
            "            )",
            "",
            "        obj = state.obj()",
            "        to_attach = self._before_attach(state, obj)",
            "        if state not in self._new:",
            "            self._new[state] = obj",
            "            state.insert_order = len(self._new)",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "    def _update_impl(self, state, revert_deletion=False):",
            "        if state.key is None:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance '%s' is not persisted\" % state_str(state)",
            "            )",
            "",
            "        if state._deleted:",
            "            if revert_deletion:",
            "                if not state._attached:",
            "                    return",
            "                del state._deleted",
            "            else:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Instance '%s' has been deleted.  \"",
            "                    \"Use the make_transient() \"",
            "                    \"function to send this object back \"",
            "                    \"to the transient state.\" % state_str(state)",
            "                )",
            "",
            "        obj = state.obj()",
            "",
            "        # check for late gc",
            "        if obj is None:",
            "            return",
            "",
            "        to_attach = self._before_attach(state, obj)",
            "",
            "        self._deleted.pop(state, None)",
            "        if revert_deletion:",
            "            self.identity_map.replace(state)",
            "        else:",
            "            self.identity_map.add(state)",
            "",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "        elif revert_deletion:",
            "            self.dispatch.deleted_to_persistent(self, obj)",
            "",
            "    def _save_or_update_impl(self, state):",
            "        if state.key is None:",
            "            self._save_impl(state)",
            "        else:",
            "            self._update_impl(state)",
            "",
            "    def enable_relationship_loading(self, obj):",
            "        \"\"\"Associate an object with this :class:`.Session` for related",
            "        object loading.",
            "",
            "        .. warning::",
            "",
            "            :meth:`.enable_relationship_loading` exists to serve special",
            "            use cases and is not recommended for general use.",
            "",
            "        Accesses of attributes mapped with :func:`.relationship`",
            "        will attempt to load a value from the database using this",
            "        :class:`.Session` as the source of connectivity.  The values",
            "        will be loaded based on foreign key and primary key values",
            "        present on this object - if not present, then those relationships",
            "        will be unavailable.",
            "",
            "        The object will be attached to this session, but will",
            "        **not** participate in any persistence operations; its state",
            "        for almost all purposes will remain either \"transient\" or",
            "        \"detached\", except for the case of relationship loading.",
            "",
            "        Also note that backrefs will often not work as expected.",
            "        Altering a relationship-bound attribute on the target object",
            "        may not fire off a backref event, if the effective value",
            "        is what was already loaded from a foreign-key-holding value.",
            "",
            "        The :meth:`.Session.enable_relationship_loading` method is",
            "        similar to the ``load_on_pending`` flag on :func:`.relationship`.",
            "        Unlike that flag, :meth:`.Session.enable_relationship_loading` allows",
            "        an object to remain transient while still being able to load",
            "        related items.",
            "",
            "        To make a transient object associated with a :class:`.Session`",
            "        via :meth:`.Session.enable_relationship_loading` pending, add",
            "        it to the :class:`.Session` using :meth:`.Session.add` normally.",
            "        If the object instead represents an existing identity in the database,",
            "        it should be merged using :meth:`.Session.merge`.",
            "",
            "        :meth:`.Session.enable_relationship_loading` does not improve",
            "        behavior when the ORM is used normally - object references should be",
            "        constructed at the object level, not at the foreign key level, so",
            "        that they are present in an ordinary way before flush()",
            "        proceeds.  This method is not intended for general use.",
            "",
            "        .. seealso::",
            "",
            "            ``load_on_pending`` at :func:`.relationship` - this flag",
            "            allows per-relationship loading of many-to-ones on items that",
            "            are pending.",
            "",
            "            :func:`.make_transient_to_detached` - allows for an object to",
            "            be added to a :class:`.Session` without SQL emitted, which then",
            "            will unexpire attributes on access.",
            "",
            "        \"\"\"",
            "        state = attributes.instance_state(obj)",
            "        to_attach = self._before_attach(state, obj)",
            "        state._load_pending = True",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "    def _before_attach(self, state, obj):",
            "        if state.session_id == self.hash_key:",
            "            return False",
            "",
            "        if state.session_id and state.session_id in _sessions:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Object '%s' is already attached to session '%s' \"",
            "                \"(this is '%s')\"",
            "                % (state_str(state), state.session_id, self.hash_key)",
            "            )",
            "",
            "        self.dispatch.before_attach(self, obj)",
            "",
            "        return True",
            "",
            "    def _after_attach(self, state, obj):",
            "        state.session_id = self.hash_key",
            "        if state.modified and state._strong_obj is None:",
            "            state._strong_obj = obj",
            "        self.dispatch.after_attach(self, obj)",
            "",
            "        if state.key:",
            "            self.dispatch.detached_to_persistent(self, obj)",
            "        else:",
            "            self.dispatch.transient_to_pending(self, obj)",
            "",
            "    def __contains__(self, instance):",
            "        \"\"\"Return True if the instance is associated with this session.",
            "",
            "        The instance may be pending or persistent within the Session for a",
            "        result of True.",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        return self._contains_state(state)",
            "",
            "    def __iter__(self):",
            "        \"\"\"Iterate over all pending or persistent instances within this",
            "        Session.",
            "",
            "        \"\"\"",
            "        return iter(",
            "            list(self._new.values()) + list(self.identity_map.values())",
            "        )",
            "",
            "    def _contains_state(self, state):",
            "        return state in self._new or self.identity_map.contains_state(state)",
            "",
            "    def flush(self, objects=None):",
            "        \"\"\"Flush all the object changes to the database.",
            "",
            "        Writes out all pending object creations, deletions and modifications",
            "        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are",
            "        automatically ordered by the Session's unit of work dependency",
            "        solver.",
            "",
            "        Database operations will be issued in the current transactional",
            "        context and do not affect the state of the transaction, unless an",
            "        error occurs, in which case the entire transaction is rolled back.",
            "        You may flush() as often as you like within a transaction to move",
            "        changes from Python to the database's transaction buffer.",
            "",
            "        For ``autocommit`` Sessions with no active manual transaction, flush()",
            "        will create a transaction on the fly that surrounds the entire set of",
            "        operations into the flush.",
            "",
            "        :param objects: Optional; restricts the flush operation to operate",
            "          only on elements that are in the given collection.",
            "",
            "          This feature is for an extremely narrow set of use cases where",
            "          particular objects may need to be operated upon before the",
            "          full flush() occurs.  It is not intended for general use.",
            "",
            "        \"\"\"",
            "",
            "        if self._flushing:",
            "            raise sa_exc.InvalidRequestError(\"Session is already flushing\")",
            "",
            "        if self._is_clean():",
            "            return",
            "        try:",
            "            self._flushing = True",
            "            self._flush(objects)",
            "        finally:",
            "            self._flushing = False",
            "",
            "    def _flush_warning(self, method):",
            "        util.warn(",
            "            \"Usage of the '%s' operation is not currently supported \"",
            "            \"within the execution stage of the flush process. \"",
            "            \"Results may not be consistent.  Consider using alternative \"",
            "            \"event listeners or connection-level operations instead.\" % method",
            "        )",
            "",
            "    def _is_clean(self):",
            "        return (",
            "            not self.identity_map.check_modified()",
            "            and not self._deleted",
            "            and not self._new",
            "        )",
            "",
            "    def _flush(self, objects=None):",
            "",
            "        dirty = self._dirty_states",
            "        if not dirty and not self._deleted and not self._new:",
            "            self.identity_map._modified.clear()",
            "            return",
            "",
            "        flush_context = UOWTransaction(self)",
            "",
            "        if self.dispatch.before_flush:",
            "            self.dispatch.before_flush(self, flush_context, objects)",
            "            # re-establish \"dirty states\" in case the listeners",
            "            # added",
            "            dirty = self._dirty_states",
            "",
            "        deleted = set(self._deleted)",
            "        new = set(self._new)",
            "",
            "        dirty = set(dirty).difference(deleted)",
            "",
            "        # create the set of all objects we want to operate upon",
            "        if objects:",
            "            # specific list passed in",
            "            objset = set()",
            "            for o in objects:",
            "                try:",
            "                    state = attributes.instance_state(o)",
            "                except exc.NO_STATE:",
            "                    raise exc.UnmappedInstanceError(o)",
            "                objset.add(state)",
            "        else:",
            "            objset = None",
            "",
            "        # store objects whose fate has been decided",
            "        processed = set()",
            "",
            "        # put all saves/updates into the flush context.  detect top-level",
            "        # orphans and throw them into deleted.",
            "        if objset:",
            "            proc = new.union(dirty).intersection(objset).difference(deleted)",
            "        else:",
            "            proc = new.union(dirty).difference(deleted)",
            "",
            "        for state in proc:",
            "            is_orphan = _state_mapper(state)._is_orphan(state)",
            "",
            "            is_persistent_orphan = is_orphan and state.has_identity",
            "",
            "            if (",
            "                is_orphan",
            "                and not is_persistent_orphan",
            "                and state._orphaned_outside_of_session",
            "            ):",
            "                self._expunge_states([state])",
            "            else:",
            "                _reg = flush_context.register_object(",
            "                    state, isdelete=is_persistent_orphan",
            "                )",
            "                assert _reg, \"Failed to add object to the flush context!\"",
            "                processed.add(state)",
            "",
            "        # put all remaining deletes into the flush context.",
            "        if objset:",
            "            proc = deleted.intersection(objset).difference(processed)",
            "        else:",
            "            proc = deleted.difference(processed)",
            "        for state in proc:",
            "            _reg = flush_context.register_object(state, isdelete=True)",
            "            assert _reg, \"Failed to add object to the flush context!\"",
            "",
            "        if not flush_context.has_work:",
            "            return",
            "",
            "        flush_context.transaction = transaction = self.begin(",
            "            subtransactions=True",
            "        )",
            "        try:",
            "            self._warn_on_events = True",
            "            try:",
            "                flush_context.execute()",
            "            finally:",
            "                self._warn_on_events = False",
            "",
            "            self.dispatch.after_flush(self, flush_context)",
            "",
            "            flush_context.finalize_flush_changes()",
            "",
            "            if not objects and self.identity_map._modified:",
            "                len_ = len(self.identity_map._modified)",
            "",
            "                statelib.InstanceState._commit_all_states(",
            "                    [",
            "                        (state, state.dict)",
            "                        for state in self.identity_map._modified",
            "                    ],",
            "                    instance_dict=self.identity_map,",
            "                )",
            "                util.warn(",
            "                    \"Attribute history events accumulated on %d \"",
            "                    \"previously clean instances \"",
            "                    \"within inner-flush event handlers have been \"",
            "                    \"reset, and will not result in database updates. \"",
            "                    \"Consider using set_committed_value() within \"",
            "                    \"inner-flush event handlers to avoid this warning.\" % len_",
            "                )",
            "",
            "            # useful assertions:",
            "            # if not objects:",
            "            #    assert not self.identity_map._modified",
            "            # else:",
            "            #    assert self.identity_map._modified == \\",
            "            #            self.identity_map._modified.difference(objects)",
            "",
            "            self.dispatch.after_flush_postexec(self, flush_context)",
            "",
            "            transaction.commit()",
            "",
            "        except:",
            "            with util.safe_reraise():",
            "                transaction.rollback(_capture_exception=True)",
            "",
            "    def bulk_save_objects(",
            "        self,",
            "        objects,",
            "        return_defaults=False,",
            "        update_changed_only=True,",
            "        preserve_order=True,",
            "    ):",
            "        \"\"\"Perform a bulk save of the given list of objects.",
            "",
            "        The bulk save feature allows mapped objects to be used as the",
            "        source of simple INSERT and UPDATE operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations; the extraction of data from the objects is also performed",
            "        using a lower-latency process that ignores whether or not attributes",
            "        have actually been modified in the case of UPDATEs, and also ignores",
            "        SQL expressions.",
            "",
            "        The objects as given are not added to the session and no additional",
            "        state is established on them, unless the ``return_defaults`` flag",
            "        is also set, in which case primary key attributes and server-side",
            "        default values will be populated.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk save feature allows for a lower-latency INSERT/UPDATE",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            INSERT/UPDATES of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param objects: a list of mapped object instances.  The mapped",
            "         objects are persisted as is, and are **not** associated with the",
            "         :class:`.Session` afterwards.",
            "",
            "         For each object, whether the object is sent as an INSERT or an",
            "         UPDATE is dependent on the same rules used by the :class:`.Session`",
            "         in traditional operation; if the object has the",
            "         :attr:`.InstanceState.key`",
            "         attribute set, then the object is assumed to be \"detached\" and",
            "         will result in an UPDATE.  Otherwise, an INSERT is used.",
            "",
            "         In the case of an UPDATE, statements are grouped based on which",
            "         attributes have changed, and are thus to be the subject of each",
            "         SET clause.  If ``update_changed_only`` is False, then all",
            "         attributes present within each object are applied to the UPDATE",
            "         statement, which may help in allowing the statements to be grouped",
            "         together into a larger executemany(), and will also reduce the",
            "         overhead of checking history on attributes.",
            "",
            "        :param return_defaults: when True, rows that are missing values which",
            "         generate defaults, namely integer primary key defaults and sequences,",
            "         will be inserted **one at a time**, so that the primary key value",
            "         is available.  In particular this will allow joined-inheritance",
            "         and other multi-table mappings to insert correctly without the need",
            "         to provide primary key values ahead of time; however,",
            "         :paramref:`.Session.bulk_save_objects.return_defaults` **greatly",
            "         reduces the performance gains** of the method overall.",
            "",
            "        :param update_changed_only: when True, UPDATE statements are rendered",
            "         based on those attributes in each state that have logged changes.",
            "         When False, all attributes present are rendered into the SET clause",
            "         with the exception of primary key attributes.",
            "",
            "        :param preserve_order: when True, the order of inserts and updates",
            "         matches exactly the order in which the objects are given.   When",
            "         False, common types of objects are grouped into inserts",
            "         and updates, to allow for more batching opportunities.",
            "",
            "         .. versionadded:: 1.3",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_insert_mappings`",
            "",
            "            :meth:`.Session.bulk_update_mappings`",
            "",
            "        \"\"\"",
            "",
            "        def key(state):",
            "            return (state.mapper, state.key is not None)",
            "",
            "        obj_states = tuple(attributes.instance_state(obj) for obj in objects)",
            "        if not preserve_order:",
            "            obj_states = sorted(obj_states, key=key)",
            "",
            "        for (mapper, isupdate), states in itertools.groupby(obj_states, key):",
            "            self._bulk_save_mappings(",
            "                mapper,",
            "                states,",
            "                isupdate,",
            "                True,",
            "                return_defaults,",
            "                update_changed_only,",
            "                False,",
            "            )",
            "",
            "    def bulk_insert_mappings(",
            "        self, mapper, mappings, return_defaults=False, render_nulls=False",
            "    ):",
            "        \"\"\"Perform a bulk insert of the given list of mapping dictionaries.",
            "",
            "        The bulk insert feature allows plain Python dictionaries to be used as",
            "        the source of simple INSERT operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations.  Using dictionaries, there is no \"history\" or session",
            "        state management features in use, reducing latency when inserting",
            "        large numbers of simple rows.",
            "",
            "        The values within the dictionaries as given are typically passed",
            "        without modification into Core :meth:`.Insert` constructs, after",
            "        organizing the values within them across the tables to which",
            "        the given mapper is mapped.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk insert feature allows for a lower-latency INSERT",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            INSERT of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param mapper: a mapped class, or the actual :class:`.Mapper` object,",
            "         representing the single kind of object represented within the mapping",
            "         list.",
            "",
            "        :param mappings: a list of dictionaries, each one containing the state",
            "         of the mapped row to be inserted, in terms of the attribute names",
            "         on the mapped class.   If the mapping refers to multiple tables,",
            "         such as a joined-inheritance mapping, each dictionary must contain",
            "         all keys to be populated into all tables.",
            "",
            "        :param return_defaults: when True, rows that are missing values which",
            "         generate defaults, namely integer primary key defaults and sequences,",
            "         will be inserted **one at a time**, so that the primary key value",
            "         is available.  In particular this will allow joined-inheritance",
            "         and other multi-table mappings to insert correctly without the need",
            "         to provide primary",
            "         key values ahead of time; however,",
            "         :paramref:`.Session.bulk_insert_mappings.return_defaults`",
            "         **greatly reduces the performance gains** of the method overall.",
            "         If the rows",
            "         to be inserted only refer to a single table, then there is no",
            "         reason this flag should be set as the returned default information",
            "         is not used.",
            "",
            "        :param render_nulls: When True, a value of ``None`` will result",
            "         in a NULL value being included in the INSERT statement, rather",
            "         than the column being omitted from the INSERT.   This allows all",
            "         the rows being INSERTed to have the identical set of columns which",
            "         allows the full set of rows to be batched to the DBAPI.  Normally,",
            "         each column-set that contains a different combination of NULL values",
            "         than the previous row must omit a different series of columns from",
            "         the rendered INSERT statement, which means it must be emitted as a",
            "         separate statement.   By passing this flag, the full set of rows",
            "         are guaranteed to be batchable into one batch; the cost however is",
            "         that server-side defaults which are invoked by an omitted column will",
            "         be skipped, so care must be taken to ensure that these are not",
            "         necessary.",
            "",
            "         .. warning::",
            "",
            "            When this flag is set, **server side default SQL values will",
            "            not be invoked** for those columns that are inserted as NULL;",
            "            the NULL value will be sent explicitly.   Care must be taken",
            "            to ensure that no server-side default functions need to be",
            "            invoked for the operation as a whole.",
            "",
            "         .. versionadded:: 1.1",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_save_objects`",
            "",
            "            :meth:`.Session.bulk_update_mappings`",
            "",
            "        \"\"\"",
            "        self._bulk_save_mappings(",
            "            mapper,",
            "            mappings,",
            "            False,",
            "            False,",
            "            return_defaults,",
            "            False,",
            "            render_nulls,",
            "        )",
            "",
            "    def bulk_update_mappings(self, mapper, mappings):",
            "        \"\"\"Perform a bulk update of the given list of mapping dictionaries.",
            "",
            "        The bulk update feature allows plain Python dictionaries to be used as",
            "        the source of simple UPDATE operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations.  Using dictionaries, there is no \"history\" or session",
            "        state management features in use, reducing latency when updating",
            "        large numbers of simple rows.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk update feature allows for a lower-latency UPDATE",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            UPDATES of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param mapper: a mapped class, or the actual :class:`.Mapper` object,",
            "         representing the single kind of object represented within the mapping",
            "         list.",
            "",
            "        :param mappings: a list of dictionaries, each one containing the state",
            "         of the mapped row to be updated, in terms of the attribute names",
            "         on the mapped class.   If the mapping refers to multiple tables,",
            "         such as a joined-inheritance mapping, each dictionary may contain",
            "         keys corresponding to all tables.   All those keys which are present",
            "         and are not part of the primary key are applied to the SET clause",
            "         of the UPDATE statement; the primary key values, which are required,",
            "         are applied to the WHERE clause.",
            "",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_insert_mappings`",
            "",
            "            :meth:`.Session.bulk_save_objects`",
            "",
            "        \"\"\"",
            "        self._bulk_save_mappings(",
            "            mapper, mappings, True, False, False, False, False",
            "        )",
            "",
            "    def _bulk_save_mappings(",
            "        self,",
            "        mapper,",
            "        mappings,",
            "        isupdate,",
            "        isstates,",
            "        return_defaults,",
            "        update_changed_only,",
            "        render_nulls,",
            "    ):",
            "        mapper = _class_to_mapper(mapper)",
            "        self._flushing = True",
            "",
            "        transaction = self.begin(subtransactions=True)",
            "        try:",
            "            if isupdate:",
            "                persistence._bulk_update(",
            "                    mapper,",
            "                    mappings,",
            "                    transaction,",
            "                    isstates,",
            "                    update_changed_only,",
            "                )",
            "            else:",
            "                persistence._bulk_insert(",
            "                    mapper,",
            "                    mappings,",
            "                    transaction,",
            "                    isstates,",
            "                    return_defaults,",
            "                    render_nulls,",
            "                )",
            "            transaction.commit()",
            "",
            "        except:",
            "            with util.safe_reraise():",
            "                transaction.rollback(_capture_exception=True)",
            "        finally:",
            "            self._flushing = False",
            "",
            "    @util.deprecated_params(",
            "        passive=(",
            "            \"0.8\",",
            "            \"The :paramref:`.Session.is_modified.passive` flag is deprecated \"",
            "            \"and will be removed in a future release.  The flag is no longer \"",
            "            \"used and is ignored.\",",
            "        )",
            "    )",
            "    def is_modified(self, instance, include_collections=True, passive=None):",
            "        r\"\"\"Return ``True`` if the given instance has locally",
            "        modified attributes.",
            "",
            "        This method retrieves the history for each instrumented",
            "        attribute on the instance and performs a comparison of the current",
            "        value to its previously committed value, if any.",
            "",
            "        It is in effect a more expensive and accurate",
            "        version of checking for the given instance in the",
            "        :attr:`.Session.dirty` collection; a full test for",
            "        each attribute's net \"dirty\" status is performed.",
            "",
            "        E.g.::",
            "",
            "            return session.is_modified(someobject)",
            "",
            "        A few caveats to this method apply:",
            "",
            "        * Instances present in the :attr:`.Session.dirty` collection may",
            "          report ``False`` when tested with this method.  This is because",
            "          the object may have received change events via attribute mutation,",
            "          thus placing it in :attr:`.Session.dirty`, but ultimately the state",
            "          is the same as that loaded from the database, resulting in no net",
            "          change here.",
            "        * Scalar attributes may not have recorded the previously set",
            "          value when a new value was applied, if the attribute was not loaded,",
            "          or was expired, at the time the new value was received - in these",
            "          cases, the attribute is assumed to have a change, even if there is",
            "          ultimately no net change against its database value. SQLAlchemy in",
            "          most cases does not need the \"old\" value when a set event occurs, so",
            "          it skips the expense of a SQL call if the old value isn't present,",
            "          based on the assumption that an UPDATE of the scalar value is",
            "          usually needed, and in those few cases where it isn't, is less",
            "          expensive on average than issuing a defensive SELECT.",
            "",
            "          The \"old\" value is fetched unconditionally upon set only if the",
            "          attribute container has the ``active_history`` flag set to ``True``.",
            "          This flag is set typically for primary key attributes and scalar",
            "          object references that are not a simple many-to-one.  To set this",
            "          flag for any arbitrary mapped column, use the ``active_history``",
            "          argument with :func:`.column_property`.",
            "",
            "        :param instance: mapped instance to be tested for pending changes.",
            "        :param include_collections: Indicates if multivalued collections",
            "         should be included in the operation.  Setting this to ``False`` is a",
            "         way to detect only local-column based properties (i.e. scalar columns",
            "         or many-to-one foreign keys) that would result in an UPDATE for this",
            "         instance upon flush.",
            "        :param passive: not used",
            "",
            "        \"\"\"",
            "        state = object_state(instance)",
            "",
            "        if not state.modified:",
            "            return False",
            "",
            "        dict_ = state.dict",
            "",
            "        for attr in state.manager.attributes:",
            "            if (",
            "                not include_collections",
            "                and hasattr(attr.impl, \"get_collection\")",
            "            ) or not hasattr(attr.impl, \"get_history\"):",
            "                continue",
            "",
            "            (added, unchanged, deleted) = attr.impl.get_history(",
            "                state, dict_, passive=attributes.NO_CHANGE",
            "            )",
            "",
            "            if added or deleted:",
            "                return True",
            "        else:",
            "            return False",
            "",
            "    @property",
            "    def is_active(self):",
            "        \"\"\"True if this :class:`.Session` is in \"transaction mode\" and",
            "        is not in \"partial rollback\" state.",
            "",
            "        The :class:`.Session` in its default mode of ``autocommit=False``",
            "        is essentially always in \"transaction mode\", in that a",
            "        :class:`.SessionTransaction` is associated with it as soon as",
            "        it is instantiated.  This :class:`.SessionTransaction` is immediately",
            "        replaced with a new one as soon as it is ended, due to a rollback,",
            "        commit, or close operation.",
            "",
            "        \"Transaction mode\" does *not* indicate whether",
            "        or not actual database connection resources are in use;  the",
            "        :class:`.SessionTransaction` object coordinates among zero or more",
            "        actual database transactions, and starts out with none, accumulating",
            "        individual DBAPI connections as different data sources are used",
            "        within its scope.   The best way to track when a particular",
            "        :class:`.Session` has actually begun to use DBAPI resources is to",
            "        implement a listener using the :meth:`.SessionEvents.after_begin`",
            "        method, which will deliver both the :class:`.Session` as well as the",
            "        target :class:`.Connection` to a user-defined event listener.",
            "",
            "        The \"partial rollback\" state refers to when an \"inner\" transaction,",
            "        typically used during a flush, encounters an error and emits a",
            "        rollback of the DBAPI connection.  At this point, the",
            "        :class:`.Session` is in \"partial rollback\" and awaits for the user to",
            "        call :meth:`.Session.rollback`, in order to close out the",
            "        transaction stack.  It is in this \"partial rollback\" period that the",
            "        :attr:`.is_active` flag returns False.  After the call to",
            "        :meth:`.Session.rollback`, the :class:`.SessionTransaction` is",
            "        replaced with a new one and :attr:`.is_active` returns ``True`` again.",
            "",
            "        When a :class:`.Session` is used in ``autocommit=True`` mode, the",
            "        :class:`.SessionTransaction` is only instantiated within the scope",
            "        of a flush call, or when :meth:`.Session.begin` is called.  So",
            "        :attr:`.is_active` will always be ``False`` outside of a flush or",
            "        :meth:`.Session.begin` block in this mode, and will be ``True``",
            "        within the :meth:`.Session.begin` block as long as it doesn't enter",
            "        \"partial rollback\" state.",
            "",
            "        From all the above, it follows that the only purpose to this flag is",
            "        for application frameworks that wish to detect is a \"rollback\" is",
            "        necessary within a generic error handling routine, for",
            "        :class:`.Session` objects that would otherwise be in",
            "        \"partial rollback\" mode.  In a typical integration case, this is also",
            "        not necessary as it is standard practice to emit",
            "        :meth:`.Session.rollback` unconditionally within the outermost",
            "        exception catch.",
            "",
            "        To track the transactional state of a :class:`.Session` fully,",
            "        use event listeners, primarily the :meth:`.SessionEvents.after_begin`,",
            "        :meth:`.SessionEvents.after_commit`,",
            "        :meth:`.SessionEvents.after_rollback` and related events.",
            "",
            "        \"\"\"",
            "        return self.transaction and self.transaction.is_active",
            "",
            "    identity_map = None",
            "    \"\"\"A mapping of object identities to objects themselves.",
            "",
            "    Iterating through ``Session.identity_map.values()`` provides",
            "    access to the full set of persistent objects (i.e., those",
            "    that have row identity) currently in the session.",
            "",
            "    .. seealso::",
            "",
            "        :func:`.identity_key` - helper function to produce the keys used",
            "        in this dictionary.",
            "",
            "    \"\"\"",
            "",
            "    @property",
            "    def _dirty_states(self):",
            "        \"\"\"The set of all persistent states considered dirty.",
            "",
            "        This method returns all states that were modified including",
            "        those that were possibly deleted.",
            "",
            "        \"\"\"",
            "        return self.identity_map._dirty_states()",
            "",
            "    @property",
            "    def dirty(self):",
            "        \"\"\"The set of all persistent instances considered dirty.",
            "",
            "        E.g.::",
            "",
            "            some_mapped_object in session.dirty",
            "",
            "        Instances are considered dirty when they were modified but not",
            "        deleted.",
            "",
            "        Note that this 'dirty' calculation is 'optimistic'; most",
            "        attribute-setting or collection modification operations will",
            "        mark an instance as 'dirty' and place it in this set, even if",
            "        there is no net change to the attribute's value.  At flush",
            "        time, the value of each attribute is compared to its",
            "        previously saved value, and if there's no net change, no SQL",
            "        operation will occur (this is a more expensive operation so",
            "        it's only done at flush time).",
            "",
            "        To check if an instance has actionable net changes to its",
            "        attributes, use the :meth:`.Session.is_modified` method.",
            "",
            "        \"\"\"",
            "        return util.IdentitySet(",
            "            [",
            "                state.obj()",
            "                for state in self._dirty_states",
            "                if state not in self._deleted",
            "            ]",
            "        )",
            "",
            "    @property",
            "    def deleted(self):",
            "        \"The set of all instances marked as 'deleted' within this ``Session``\"",
            "",
            "        return util.IdentitySet(list(self._deleted.values()))",
            "",
            "    @property",
            "    def new(self):",
            "        \"The set of all instances marked as 'new' within this ``Session``.\"",
            "",
            "        return util.IdentitySet(list(self._new.values()))",
            "",
            "",
            "class sessionmaker(_SessionClassMethods):",
            "    \"\"\"A configurable :class:`.Session` factory.",
            "",
            "    The :class:`.sessionmaker` factory generates new",
            "    :class:`.Session` objects when called, creating them given",
            "    the configurational arguments established here.",
            "",
            "    e.g.::",
            "",
            "        # global scope",
            "        Session = sessionmaker(autoflush=False)",
            "",
            "        # later, in a local scope, create and use a session:",
            "        sess = Session()",
            "",
            "    Any keyword arguments sent to the constructor itself will override the",
            "    \"configured\" keywords::",
            "",
            "        Session = sessionmaker()",
            "",
            "        # bind an individual session to a connection",
            "        sess = Session(bind=connection)",
            "",
            "    The class also includes a method :meth:`.configure`, which can",
            "    be used to specify additional keyword arguments to the factory, which",
            "    will take effect for subsequent :class:`.Session` objects generated.",
            "    This is usually used to associate one or more :class:`.Engine` objects",
            "    with an existing :class:`.sessionmaker` factory before it is first",
            "    used::",
            "",
            "        # application starts",
            "        Session = sessionmaker()",
            "",
            "        # ... later",
            "        engine = create_engine('sqlite:///foo.db')",
            "        Session.configure(bind=engine)",
            "",
            "        sess = Session()",
            "",
            "    .. seealso:",
            "",
            "        :ref:`session_getting` - introductory text on creating",
            "        sessions using :class:`.sessionmaker`.",
            "",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        bind=None,",
            "        class_=Session,",
            "        autoflush=True,",
            "        autocommit=False,",
            "        expire_on_commit=True,",
            "        info=None,",
            "        **kw",
            "    ):",
            "        r\"\"\"Construct a new :class:`.sessionmaker`.",
            "",
            "        All arguments here except for ``class_`` correspond to arguments",
            "        accepted by :class:`.Session` directly.  See the",
            "        :meth:`.Session.__init__` docstring for more details on parameters.",
            "",
            "        :param bind: a :class:`.Engine` or other :class:`.Connectable` with",
            "         which newly created :class:`.Session` objects will be associated.",
            "        :param class_: class to use in order to create new :class:`.Session`",
            "         objects.  Defaults to :class:`.Session`.",
            "        :param autoflush: The autoflush setting to use with newly created",
            "         :class:`.Session` objects.",
            "        :param autocommit: The autocommit setting to use with newly created",
            "         :class:`.Session` objects.",
            "        :param expire_on_commit=True: the expire_on_commit setting to use",
            "         with newly created :class:`.Session` objects.",
            "        :param info: optional dictionary of information that will be available",
            "         via :attr:`.Session.info`.  Note this dictionary is *updated*, not",
            "         replaced, when the ``info`` parameter is specified to the specific",
            "         :class:`.Session` construction operation.",
            "",
            "         .. versionadded:: 0.9.0",
            "",
            "        :param \\**kw: all other keyword arguments are passed to the",
            "         constructor of newly created :class:`.Session` objects.",
            "",
            "        \"\"\"",
            "        kw[\"bind\"] = bind",
            "        kw[\"autoflush\"] = autoflush",
            "        kw[\"autocommit\"] = autocommit",
            "        kw[\"expire_on_commit\"] = expire_on_commit",
            "        if info is not None:",
            "            kw[\"info\"] = info",
            "        self.kw = kw",
            "        # make our own subclass of the given class, so that",
            "        # events can be associated with it specifically.",
            "        self.class_ = type(class_.__name__, (class_,), {})",
            "",
            "    def __call__(self, **local_kw):",
            "        \"\"\"Produce a new :class:`.Session` object using the configuration",
            "        established in this :class:`.sessionmaker`.",
            "",
            "        In Python, the ``__call__`` method is invoked on an object when",
            "        it is \"called\" in the same way as a function::",
            "",
            "            Session = sessionmaker()",
            "            session = Session()  # invokes sessionmaker.__call__()",
            "",
            "        \"\"\"",
            "        for k, v in self.kw.items():",
            "            if k == \"info\" and \"info\" in local_kw:",
            "                d = v.copy()",
            "                d.update(local_kw[\"info\"])",
            "                local_kw[\"info\"] = d",
            "            else:",
            "                local_kw.setdefault(k, v)",
            "        return self.class_(**local_kw)",
            "",
            "    def configure(self, **new_kw):",
            "        \"\"\"(Re)configure the arguments for this sessionmaker.",
            "",
            "        e.g.::",
            "",
            "            Session = sessionmaker()",
            "",
            "            Session.configure(bind=create_engine('sqlite://'))",
            "        \"\"\"",
            "        self.kw.update(new_kw)",
            "",
            "    def __repr__(self):",
            "        return \"%s(class_=%r, %s)\" % (",
            "            self.__class__.__name__,",
            "            self.class_.__name__,",
            "            \", \".join(\"%s=%r\" % (k, v) for k, v in self.kw.items()),",
            "        )",
            "",
            "",
            "def close_all_sessions():",
            "    \"\"\"Close all sessions in memory.",
            "",
            "    This function consults a global registry of all :class:`.Session` objects",
            "    and calls :meth:`.Session.close` on them, which resets them to a clean",
            "    state.",
            "",
            "    This function is not for general use but may be useful for test suites",
            "    within the teardown scheme.",
            "",
            "    .. versionadded:: 1.3",
            "",
            "    \"\"\"",
            "",
            "    for sess in _sessions.values():",
            "        sess.close()",
            "",
            "",
            "def make_transient(instance):",
            "    \"\"\"Alter the state of the given instance so that it is :term:`transient`.",
            "",
            "    .. note::",
            "",
            "        :func:`.make_transient` is a special-case function for",
            "        advanced use cases only.",
            "",
            "    The given mapped instance is assumed to be in the :term:`persistent` or",
            "    :term:`detached` state.   The function will remove its association with any",
            "    :class:`.Session` as well as its :attr:`.InstanceState.identity`. The",
            "    effect is that the object will behave as though it were newly constructed,",
            "    except retaining any attribute / collection values that were loaded at the",
            "    time of the call.   The :attr:`.InstanceState.deleted` flag is also reset",
            "    if this object had been deleted as a result of using",
            "    :meth:`.Session.delete`.",
            "",
            "    .. warning::",
            "",
            "        :func:`.make_transient` does **not** \"unexpire\" or otherwise eagerly",
            "        load ORM-mapped attributes that are not currently loaded at the time",
            "        the function is called.   This includes attributes which:",
            "",
            "        * were expired via :meth:`.Session.expire`",
            "",
            "        * were expired as the natural effect of committing a session",
            "          transaction, e.g. :meth:`.Session.commit`",
            "",
            "        * are normally :term:`lazy loaded` but are not currently loaded",
            "",
            "        * are \"deferred\" via :ref:`deferred` and are not yet loaded",
            "",
            "        * were not present in the query which loaded this object, such as that",
            "          which is common in joined table inheritance and other scenarios.",
            "",
            "        After :func:`.make_transient` is called, unloaded attributes such",
            "        as those above will normally resolve to the value ``None`` when",
            "        accessed, or an empty collection for a collection-oriented attribute.",
            "        As the object is transient and un-associated with any database",
            "        identity, it will no longer retrieve these values.",
            "",
            "    .. seealso::",
            "",
            "        :func:`.make_transient_to_detached`",
            "",
            "    \"\"\"",
            "    state = attributes.instance_state(instance)",
            "    s = _state_session(state)",
            "    if s:",
            "        s._expunge_states([state])",
            "",
            "    # remove expired state",
            "    state.expired_attributes.clear()",
            "",
            "    # remove deferred callables",
            "    if state.callables:",
            "        del state.callables",
            "",
            "    if state.key:",
            "        del state.key",
            "    if state._deleted:",
            "        del state._deleted",
            "",
            "",
            "def make_transient_to_detached(instance):",
            "    \"\"\"Make the given transient instance :term:`detached`.",
            "",
            "    .. note::",
            "",
            "        :func:`.make_transient_to_detached` is a special-case function for",
            "        advanced use cases only.",
            "",
            "    All attribute history on the given instance",
            "    will be reset as though the instance were freshly loaded",
            "    from a query.  Missing attributes will be marked as expired.",
            "    The primary key attributes of the object, which are required, will be made",
            "    into the \"key\" of the instance.",
            "",
            "    The object can then be added to a session, or merged",
            "    possibly with the load=False flag, at which point it will look",
            "    as if it were loaded that way, without emitting SQL.",
            "",
            "    This is a special use case function that differs from a normal",
            "    call to :meth:`.Session.merge` in that a given persistent state",
            "    can be manufactured without any SQL calls.",
            "",
            "    .. versionadded:: 0.9.5",
            "",
            "    .. seealso::",
            "",
            "        :func:`.make_transient`",
            "",
            "        :meth:`.Session.enable_relationship_loading`",
            "",
            "    \"\"\"",
            "    state = attributes.instance_state(instance)",
            "    if state.session_id or state.key:",
            "        raise sa_exc.InvalidRequestError(\"Given object must be transient\")",
            "    state.key = state.mapper._identity_key_from_state(state)",
            "    if state._deleted:",
            "        del state._deleted",
            "    state._commit_all(state.dict)",
            "    state._expire_attributes(state.dict, state.unloaded_expirable)",
            "",
            "",
            "def object_session(instance):",
            "    \"\"\"Return the :class:`.Session` to which the given instance belongs.",
            "",
            "    This is essentially the same as the :attr:`.InstanceState.session`",
            "    accessor.  See that attribute for details.",
            "",
            "    \"\"\"",
            "",
            "    try:",
            "        state = attributes.instance_state(instance)",
            "    except exc.NO_STATE:",
            "        raise exc.UnmappedInstanceError(instance)",
            "    else:",
            "        return _state_session(state)",
            "",
            "",
            "_new_sessionid = util.counter()"
        ],
        "afterPatchFile": [
            "# orm/session.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "\"\"\"Provides the Session class and related utilities.\"\"\"",
            "",
            "",
            "import itertools",
            "import sys",
            "import weakref",
            "",
            "from . import attributes",
            "from . import exc",
            "from . import identity",
            "from . import loading",
            "from . import persistence",
            "from . import query",
            "from . import state as statelib",
            "from .base import _class_to_mapper",
            "from .base import _none_set",
            "from .base import _state_mapper",
            "from .base import instance_str",
            "from .base import object_mapper",
            "from .base import object_state",
            "from .base import state_str",
            "from .deprecated_interfaces import SessionExtension",
            "from .unitofwork import UOWTransaction",
            "from .. import engine",
            "from .. import exc as sa_exc",
            "from .. import sql",
            "from .. import util",
            "from ..inspection import inspect",
            "from ..sql import expression",
            "from ..sql import util as sql_util",
            "",
            "",
            "__all__ = [\"Session\", \"SessionTransaction\", \"SessionExtension\", \"sessionmaker\"]",
            "",
            "_sessions = weakref.WeakValueDictionary()",
            "\"\"\"Weak-referencing dictionary of :class:`.Session` objects.",
            "\"\"\"",
            "",
            "",
            "def _state_session(state):",
            "    \"\"\"Given an :class:`.InstanceState`, return the :class:`.Session`",
            "        associated, if any.",
            "    \"\"\"",
            "    if state.session_id:",
            "        try:",
            "            return _sessions[state.session_id]",
            "        except KeyError:",
            "            pass",
            "    return None",
            "",
            "",
            "class _SessionClassMethods(object):",
            "    \"\"\"Class-level methods for :class:`.Session`, :class:`.sessionmaker`.\"\"\"",
            "",
            "    @classmethod",
            "    @util.deprecated(",
            "        \"1.3\",",
            "        \"The :meth:`.Session.close_all` method is deprecated and will be \"",
            "        \"removed in a future release.  Please refer to \"",
            "        \":func:`.session.close_all_sessions`.\",",
            "    )",
            "    def close_all(cls):",
            "        \"\"\"Close *all* sessions in memory.\"\"\"",
            "",
            "        close_all_sessions()",
            "",
            "    @classmethod",
            "    @util.dependencies(\"sqlalchemy.orm.util\")",
            "    def identity_key(cls, orm_util, *args, **kwargs):",
            "        \"\"\"Return an identity key.",
            "",
            "        This is an alias of :func:`.util.identity_key`.",
            "",
            "        \"\"\"",
            "        return orm_util.identity_key(*args, **kwargs)",
            "",
            "    @classmethod",
            "    def object_session(cls, instance):",
            "        \"\"\"Return the :class:`.Session` to which an object belongs.",
            "",
            "        This is an alias of :func:`.object_session`.",
            "",
            "        \"\"\"",
            "",
            "        return object_session(instance)",
            "",
            "",
            "ACTIVE = util.symbol(\"ACTIVE\")",
            "PREPARED = util.symbol(\"PREPARED\")",
            "COMMITTED = util.symbol(\"COMMITTED\")",
            "DEACTIVE = util.symbol(\"DEACTIVE\")",
            "CLOSED = util.symbol(\"CLOSED\")",
            "",
            "",
            "class SessionTransaction(object):",
            "    \"\"\"A :class:`.Session`-level transaction.",
            "",
            "    :class:`.SessionTransaction` is a mostly behind-the-scenes object",
            "    not normally referenced directly by application code.   It coordinates",
            "    among multiple :class:`.Connection` objects, maintaining a database",
            "    transaction for each one individually, committing or rolling them",
            "    back all at once.   It also provides optional two-phase commit behavior",
            "    which can augment this coordination operation.",
            "",
            "    The :attr:`.Session.transaction` attribute of :class:`.Session`",
            "    refers to the current :class:`.SessionTransaction` object in use, if any.",
            "    The :attr:`.SessionTransaction.parent` attribute refers to the parent",
            "    :class:`.SessionTransaction` in the stack of :class:`.SessionTransaction`",
            "    objects.  If this attribute is ``None``, then this is the top of the stack.",
            "    If non-``None``, then this :class:`.SessionTransaction` refers either",
            "    to a so-called \"subtransaction\" or a \"nested\" transaction.  A",
            "    \"subtransaction\" is a scoping concept that demarcates an inner portion",
            "    of the outermost \"real\" transaction.  A nested transaction, which",
            "    is indicated when the :attr:`.SessionTransaction.nested`",
            "    attribute is also True, indicates that this :class:`.SessionTransaction`",
            "    corresponds to a SAVEPOINT.",
            "",
            "    **Life Cycle**",
            "",
            "    A :class:`.SessionTransaction` is associated with a :class:`.Session`",
            "    in its default mode of ``autocommit=False`` immediately, associated",
            "    with no database connections.  As the :class:`.Session` is called upon",
            "    to emit SQL on behalf of various :class:`.Engine` or :class:`.Connection`",
            "    objects, a corresponding :class:`.Connection` and associated",
            "    :class:`.Transaction` is added to a collection within the",
            "    :class:`.SessionTransaction` object, becoming one of the",
            "    connection/transaction pairs maintained by the",
            "    :class:`.SessionTransaction`.  The start of a :class:`.SessionTransaction`",
            "    can be tracked using the :meth:`.SessionEvents.after_transaction_create`",
            "    event.",
            "",
            "    The lifespan of the :class:`.SessionTransaction` ends when the",
            "    :meth:`.Session.commit`, :meth:`.Session.rollback` or",
            "    :meth:`.Session.close` methods are called.  At this point, the",
            "    :class:`.SessionTransaction` removes its association with its parent",
            "    :class:`.Session`.   A :class:`.Session` that is in ``autocommit=False``",
            "    mode will create a new :class:`.SessionTransaction` to replace it",
            "    immediately, whereas a :class:`.Session` that's in ``autocommit=True``",
            "    mode will remain without a :class:`.SessionTransaction` until the",
            "    :meth:`.Session.begin` method is called.  The end of a",
            "    :class:`.SessionTransaction` can be tracked using the",
            "    :meth:`.SessionEvents.after_transaction_end` event.",
            "",
            "    **Nesting and Subtransactions**",
            "",
            "    Another detail of :class:`.SessionTransaction` behavior is that it is",
            "    capable of \"nesting\".  This means that the :meth:`.Session.begin` method",
            "    can be called while an existing :class:`.SessionTransaction` is already",
            "    present, producing a new :class:`.SessionTransaction` that temporarily",
            "    replaces the parent :class:`.SessionTransaction`.   When a",
            "    :class:`.SessionTransaction` is produced as nested, it assigns itself to",
            "    the :attr:`.Session.transaction` attribute, and it additionally will assign",
            "    the previous :class:`.SessionTransaction` to its :attr:`.Session.parent`",
            "    attribute.  The behavior is effectively a",
            "    stack, where :attr:`.Session.transaction` refers to the current head of",
            "    the stack, and the :attr:`.SessionTransaction.parent` attribute allows",
            "    traversal up the stack until :attr:`.SessionTransaction.parent` is",
            "    ``None``, indicating the top of the stack.",
            "",
            "    When the scope of :class:`.SessionTransaction` is ended via",
            "    :meth:`.Session.commit` or :meth:`.Session.rollback`, it restores its",
            "    parent :class:`.SessionTransaction` back onto the",
            "    :attr:`.Session.transaction` attribute.",
            "",
            "    The purpose of this stack is to allow nesting of",
            "    :meth:`.Session.rollback` or :meth:`.Session.commit` calls in context",
            "    with various flavors of :meth:`.Session.begin`. This nesting behavior",
            "    applies to when :meth:`.Session.begin_nested` is used to emit a",
            "    SAVEPOINT transaction, and is also used to produce a so-called",
            "    \"subtransaction\" which allows a block of code to use a",
            "    begin/rollback/commit sequence regardless of whether or not its enclosing",
            "    code block has begun a transaction.  The :meth:`.flush` method, whether",
            "    called explicitly or via autoflush, is the primary consumer of the",
            "    \"subtransaction\" feature, in that it wishes to guarantee that it works",
            "    within in a transaction block regardless of whether or not the",
            "    :class:`.Session` is in transactional mode when the method is called.",
            "",
            "    Note that the flush process that occurs within the \"autoflush\" feature",
            "    as well as when the :meth:`.Session.flush` method is used **always**",
            "    creates a :class:`.SessionTransaction` object.   This object is normally",
            "    a subtransaction, unless the :class:`.Session` is in autocommit mode",
            "    and no transaction exists at all, in which case it's the outermost",
            "    transaction.   Any event-handling logic or other inspection logic",
            "    needs to take into account whether a :class:`.SessionTransaction`",
            "    is the outermost transaction, a subtransaction, or a \"nested\" / SAVEPOINT",
            "    transaction.",
            "",
            "    .. seealso::",
            "",
            "        :meth:`.Session.rollback`",
            "",
            "        :meth:`.Session.commit`",
            "",
            "        :meth:`.Session.begin`",
            "",
            "        :meth:`.Session.begin_nested`",
            "",
            "        :attr:`.Session.is_active`",
            "",
            "        :meth:`.SessionEvents.after_transaction_create`",
            "",
            "        :meth:`.SessionEvents.after_transaction_end`",
            "",
            "        :meth:`.SessionEvents.after_commit`",
            "",
            "        :meth:`.SessionEvents.after_rollback`",
            "",
            "        :meth:`.SessionEvents.after_soft_rollback`",
            "",
            "    \"\"\"",
            "",
            "    _rollback_exception = None",
            "",
            "    def __init__(self, session, parent=None, nested=False):",
            "        self.session = session",
            "        self._connections = {}",
            "        self._parent = parent",
            "        self.nested = nested",
            "        self._state = ACTIVE",
            "        if not parent and nested:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Can't start a SAVEPOINT transaction when no existing \"",
            "                \"transaction is in progress\"",
            "            )",
            "",
            "        if self.session._enable_transaction_accounting:",
            "            self._take_snapshot()",
            "",
            "        self.session.dispatch.after_transaction_create(self.session, self)",
            "",
            "    @property",
            "    def parent(self):",
            "        \"\"\"The parent :class:`.SessionTransaction` of this",
            "        :class:`.SessionTransaction`.",
            "",
            "        If this attribute is ``None``, indicates this",
            "        :class:`.SessionTransaction` is at the top of the stack, and",
            "        corresponds to a real \"COMMIT\"/\"ROLLBACK\"",
            "        block.  If non-``None``, then this is either a \"subtransaction\"",
            "        or a \"nested\" / SAVEPOINT transaction.  If the",
            "        :attr:`.SessionTransaction.nested` attribute is ``True``, then",
            "        this is a SAVEPOINT, and if ``False``, indicates this a subtransaction.",
            "",
            "        .. versionadded:: 1.0.16 - use ._parent for previous versions",
            "",
            "        \"\"\"",
            "        return self._parent",
            "",
            "    nested = False",
            "    \"\"\"Indicates if this is a nested, or SAVEPOINT, transaction.",
            "",
            "    When :attr:`.SessionTransaction.nested` is True, it is expected",
            "    that :attr:`.SessionTransaction.parent` will be True as well.",
            "",
            "    \"\"\"",
            "",
            "    @property",
            "    def is_active(self):",
            "        return self.session is not None and self._state is ACTIVE",
            "",
            "    def _assert_active(",
            "        self,",
            "        prepared_ok=False,",
            "        rollback_ok=False,",
            "        deactive_ok=False,",
            "        closed_msg=\"This transaction is closed\",",
            "    ):",
            "        if self._state is COMMITTED:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"This session is in 'committed' state; no further \"",
            "                \"SQL can be emitted within this transaction.\"",
            "            )",
            "        elif self._state is PREPARED:",
            "            if not prepared_ok:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"This session is in 'prepared' state; no further \"",
            "                    \"SQL can be emitted within this transaction.\"",
            "                )",
            "        elif self._state is DEACTIVE:",
            "            if not deactive_ok and not rollback_ok:",
            "                if self._rollback_exception:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"This Session's transaction has been rolled back \"",
            "                        \"due to a previous exception during flush.\"",
            "                        \" To begin a new transaction with this Session, \"",
            "                        \"first issue Session.rollback().\"",
            "                        \" Original exception was: %s\"",
            "                        % self._rollback_exception",
            "                    )",
            "                elif not deactive_ok:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"This session is in 'inactive' state, due to the \"",
            "                        \"SQL transaction being rolled back; no further \"",
            "                        \"SQL can be emitted within this transaction.\"",
            "                    )",
            "        elif self._state is CLOSED:",
            "            raise sa_exc.ResourceClosedError(closed_msg)",
            "",
            "    @property",
            "    def _is_transaction_boundary(self):",
            "        return self.nested or not self._parent",
            "",
            "    def connection(self, bindkey, execution_options=None, **kwargs):",
            "        self._assert_active()",
            "        bind = self.session.get_bind(bindkey, **kwargs)",
            "        return self._connection_for_bind(bind, execution_options)",
            "",
            "    def _begin(self, nested=False):",
            "        self._assert_active()",
            "        return SessionTransaction(self.session, self, nested=nested)",
            "",
            "    def _iterate_self_and_parents(self, upto=None):",
            "",
            "        current = self",
            "        result = ()",
            "        while current:",
            "            result += (current,)",
            "            if current._parent is upto:",
            "                break",
            "            elif current._parent is None:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Transaction %s is not on the active transaction list\"",
            "                    % (upto)",
            "                )",
            "            else:",
            "                current = current._parent",
            "",
            "        return result",
            "",
            "    def _take_snapshot(self):",
            "        if not self._is_transaction_boundary:",
            "            self._new = self._parent._new",
            "            self._deleted = self._parent._deleted",
            "            self._dirty = self._parent._dirty",
            "            self._key_switches = self._parent._key_switches",
            "            return",
            "",
            "        if not self.session._flushing:",
            "            self.session.flush()",
            "",
            "        self._new = weakref.WeakKeyDictionary()",
            "        self._deleted = weakref.WeakKeyDictionary()",
            "        self._dirty = weakref.WeakKeyDictionary()",
            "        self._key_switches = weakref.WeakKeyDictionary()",
            "",
            "    def _restore_snapshot(self, dirty_only=False):",
            "        \"\"\"Restore the restoration state taken before a transaction began.",
            "",
            "        Corresponds to a rollback.",
            "",
            "        \"\"\"",
            "        assert self._is_transaction_boundary",
            "",
            "        to_expunge = set(self._new).union(self.session._new)",
            "        self.session._expunge_states(to_expunge, to_transient=True)",
            "",
            "        for s, (oldkey, newkey) in self._key_switches.items():",
            "            # we probably can do this conditionally based on",
            "            # if we expunged or not, but safe_discard does that anyway",
            "            self.session.identity_map.safe_discard(s)",
            "",
            "            # restore the old key",
            "            s.key = oldkey",
            "",
            "            # now restore the object, but only if we didn't expunge",
            "            if s not in to_expunge:",
            "                self.session.identity_map.replace(s)",
            "",
            "        for s in set(self._deleted).union(self.session._deleted):",
            "            self.session._update_impl(s, revert_deletion=True)",
            "",
            "        assert not self.session._deleted",
            "",
            "        for s in self.session.identity_map.all_states():",
            "            if not dirty_only or s.modified or s in self._dirty:",
            "                s._expire(s.dict, self.session.identity_map._modified)",
            "",
            "    def _remove_snapshot(self):",
            "        \"\"\"Remove the restoration state taken before a transaction began.",
            "",
            "        Corresponds to a commit.",
            "",
            "        \"\"\"",
            "        assert self._is_transaction_boundary",
            "",
            "        if not self.nested and self.session.expire_on_commit:",
            "            for s in self.session.identity_map.all_states():",
            "                s._expire(s.dict, self.session.identity_map._modified)",
            "",
            "            statelib.InstanceState._detach_states(",
            "                list(self._deleted), self.session",
            "            )",
            "            self._deleted.clear()",
            "        elif self.nested:",
            "            self._parent._new.update(self._new)",
            "            self._parent._dirty.update(self._dirty)",
            "            self._parent._deleted.update(self._deleted)",
            "            self._parent._key_switches.update(self._key_switches)",
            "",
            "    def _connection_for_bind(self, bind, execution_options):",
            "        self._assert_active()",
            "",
            "        if bind in self._connections:",
            "            if execution_options:",
            "                util.warn(",
            "                    \"Connection is already established for the \"",
            "                    \"given bind; execution_options ignored\"",
            "                )",
            "            return self._connections[bind][0]",
            "",
            "        if self._parent:",
            "            conn = self._parent._connection_for_bind(bind, execution_options)",
            "            if not self.nested:",
            "                return conn",
            "        else:",
            "            if isinstance(bind, engine.Connection):",
            "                conn = bind",
            "                if conn.engine in self._connections:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"Session already has a Connection associated for the \"",
            "                        \"given Connection's Engine\"",
            "                    )",
            "            else:",
            "                conn = bind._contextual_connect()",
            "",
            "        if execution_options:",
            "            conn = conn.execution_options(**execution_options)",
            "",
            "        if self.session.twophase and self._parent is None:",
            "            transaction = conn.begin_twophase()",
            "        elif self.nested:",
            "            transaction = conn.begin_nested()",
            "        else:",
            "            transaction = conn.begin()",
            "",
            "        self._connections[conn] = self._connections[conn.engine] = (",
            "            conn,",
            "            transaction,",
            "            conn is not bind,",
            "        )",
            "        self.session.dispatch.after_begin(self.session, self, conn)",
            "        return conn",
            "",
            "    def prepare(self):",
            "        if self._parent is not None or not self.session.twophase:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"'twophase' mode not enabled, or not root transaction; \"",
            "                \"can't prepare.\"",
            "            )",
            "        self._prepare_impl()",
            "",
            "    def _prepare_impl(self):",
            "        self._assert_active()",
            "        if self._parent is None or self.nested:",
            "            self.session.dispatch.before_commit(self.session)",
            "",
            "        stx = self.session.transaction",
            "        if stx is not self:",
            "            for subtransaction in stx._iterate_self_and_parents(upto=self):",
            "                subtransaction.commit()",
            "",
            "        if not self.session._flushing:",
            "            for _flush_guard in range(100):",
            "                if self.session._is_clean():",
            "                    break",
            "                self.session.flush()",
            "            else:",
            "                raise exc.FlushError(",
            "                    \"Over 100 subsequent flushes have occurred within \"",
            "                    \"session.commit() - is an after_flush() hook \"",
            "                    \"creating new objects?\"",
            "                )",
            "",
            "        if self._parent is None and self.session.twophase:",
            "            try:",
            "                for t in set(self._connections.values()):",
            "                    t[1].prepare()",
            "            except:",
            "                with util.safe_reraise():",
            "                    self.rollback()",
            "",
            "        self._state = PREPARED",
            "",
            "    def commit(self):",
            "        self._assert_active(prepared_ok=True)",
            "        if self._state is not PREPARED:",
            "            self._prepare_impl()",
            "",
            "        if self._parent is None or self.nested:",
            "            for t in set(self._connections.values()):",
            "                t[1].commit()",
            "",
            "            self._state = COMMITTED",
            "            self.session.dispatch.after_commit(self.session)",
            "",
            "            if self.session._enable_transaction_accounting:",
            "                self._remove_snapshot()",
            "",
            "        self.close()",
            "        return self._parent",
            "",
            "    def rollback(self, _capture_exception=False):",
            "        self._assert_active(prepared_ok=True, rollback_ok=True)",
            "",
            "        stx = self.session.transaction",
            "        if stx is not self:",
            "            for subtransaction in stx._iterate_self_and_parents(upto=self):",
            "                subtransaction.close()",
            "",
            "        boundary = self",
            "        rollback_err = None",
            "        if self._state in (ACTIVE, PREPARED):",
            "            for transaction in self._iterate_self_and_parents():",
            "                if transaction._parent is None or transaction.nested:",
            "                    try:",
            "                        for t in set(transaction._connections.values()):",
            "                            t[1].rollback()",
            "",
            "                        transaction._state = DEACTIVE",
            "                        self.session.dispatch.after_rollback(self.session)",
            "                    except:",
            "                        rollback_err = sys.exc_info()",
            "                    finally:",
            "                        transaction._state = DEACTIVE",
            "                        if self.session._enable_transaction_accounting:",
            "                            transaction._restore_snapshot(",
            "                                dirty_only=transaction.nested",
            "                            )",
            "                    boundary = transaction",
            "                    break",
            "                else:",
            "                    transaction._state = DEACTIVE",
            "",
            "        sess = self.session",
            "",
            "        if (",
            "            not rollback_err",
            "            and sess._enable_transaction_accounting",
            "            and not sess._is_clean()",
            "        ):",
            "",
            "            # if items were added, deleted, or mutated",
            "            # here, we need to re-restore the snapshot",
            "            util.warn(",
            "                \"Session's state has been changed on \"",
            "                \"a non-active transaction - this state \"",
            "                \"will be discarded.\"",
            "            )",
            "            boundary._restore_snapshot(dirty_only=boundary.nested)",
            "",
            "        self.close()",
            "",
            "        if self._parent and _capture_exception:",
            "            self._parent._rollback_exception = sys.exc_info()[1]",
            "",
            "        if rollback_err:",
            "            util.reraise(*rollback_err)",
            "",
            "        sess.dispatch.after_soft_rollback(sess, self)",
            "",
            "        return self._parent",
            "",
            "    def close(self, invalidate=False):",
            "        self.session.transaction = self._parent",
            "        if self._parent is None:",
            "            for connection, transaction, autoclose in set(",
            "                self._connections.values()",
            "            ):",
            "                if invalidate:",
            "                    connection.invalidate()",
            "                if autoclose:",
            "                    connection.close()",
            "                else:",
            "                    transaction.close()",
            "",
            "        self._state = CLOSED",
            "        self.session.dispatch.after_transaction_end(self.session, self)",
            "",
            "        if self._parent is None:",
            "            if not self.session.autocommit:",
            "                self.session.begin()",
            "        self.session = None",
            "        self._connections = None",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, type_, value, traceback):",
            "        self._assert_active(deactive_ok=True, prepared_ok=True)",
            "        if self.session.transaction is None:",
            "            return",
            "        if type_ is None:",
            "            try:",
            "                self.commit()",
            "            except:",
            "                with util.safe_reraise():",
            "                    self.rollback()",
            "        else:",
            "            self.rollback()",
            "",
            "",
            "class Session(_SessionClassMethods):",
            "    \"\"\"Manages persistence operations for ORM-mapped objects.",
            "",
            "    The Session's usage paradigm is described at :doc:`/orm/session`.",
            "",
            "",
            "    \"\"\"",
            "",
            "    public_methods = (",
            "        \"__contains__\",",
            "        \"__iter__\",",
            "        \"add\",",
            "        \"add_all\",",
            "        \"begin\",",
            "        \"begin_nested\",",
            "        \"close\",",
            "        \"commit\",",
            "        \"connection\",",
            "        \"delete\",",
            "        \"execute\",",
            "        \"expire\",",
            "        \"expire_all\",",
            "        \"expunge\",",
            "        \"expunge_all\",",
            "        \"flush\",",
            "        \"get_bind\",",
            "        \"is_modified\",",
            "        \"bulk_save_objects\",",
            "        \"bulk_insert_mappings\",",
            "        \"bulk_update_mappings\",",
            "        \"merge\",",
            "        \"query\",",
            "        \"refresh\",",
            "        \"rollback\",",
            "        \"scalar\",",
            "    )",
            "",
            "    @util.deprecated_params(",
            "        weak_identity_map=(",
            "            \"1.0\",",
            "            \"The :paramref:`.Session.weak_identity_map` parameter as well as \"",
            "            \"the strong-referencing identity map are deprecated, and will be \"",
            "            \"removed in a future release.  For the use case where objects \"",
            "            \"present in a :class:`.Session` need to be automatically strong \"",
            "            \"referenced, see the recipe at \"",
            "            \":ref:`session_referencing_behavior` for an event-based approach \"",
            "            \"to maintaining strong identity references. \",",
            "        ),",
            "        _enable_transaction_accounting=(",
            "            \"0.7\",",
            "            \"The :paramref:`.Session._enable_transaction_accounting` \"",
            "            \"parameter is deprecated and will be removed in a future release.\",",
            "        ),",
            "        extension=(",
            "            \"0.7\",",
            "            \":class:`.SessionExtension` is deprecated in favor of the \"",
            "            \":class:`.SessionEvents` listener interface.  The \"",
            "            \":paramref:`.Session.extension` parameter will be \"",
            "            \"removed in a future release.\",",
            "        ),",
            "    )",
            "    def __init__(",
            "        self,",
            "        bind=None,",
            "        autoflush=True,",
            "        expire_on_commit=True,",
            "        _enable_transaction_accounting=True,",
            "        autocommit=False,",
            "        twophase=False,",
            "        weak_identity_map=None,",
            "        binds=None,",
            "        extension=None,",
            "        enable_baked_queries=True,",
            "        info=None,",
            "        query_cls=None,",
            "    ):",
            "        r\"\"\"Construct a new Session.",
            "",
            "        See also the :class:`.sessionmaker` function which is used to",
            "        generate a :class:`.Session`-producing callable with a given",
            "        set of arguments.",
            "",
            "        :param autocommit:",
            "",
            "          .. warning::",
            "",
            "             The autocommit flag is **not for general use**, and if it is",
            "             used, queries should only be invoked within the span of a",
            "             :meth:`.Session.begin` / :meth:`.Session.commit` pair.  Executing",
            "             queries outside of a demarcated transaction is a legacy mode",
            "             of usage, and can in some cases lead to concurrent connection",
            "             checkouts.",
            "",
            "          Defaults to ``False``. When ``True``, the",
            "          :class:`.Session` does not keep a persistent transaction running,",
            "          and will acquire connections from the engine on an as-needed basis,",
            "          returning them immediately after their use. Flushes will begin and",
            "          commit (or possibly rollback) their own transaction if no",
            "          transaction is present. When using this mode, the",
            "          :meth:`.Session.begin` method is used to explicitly start",
            "          transactions.",
            "",
            "          .. seealso::",
            "",
            "            :ref:`session_autocommit`",
            "",
            "        :param autoflush: When ``True``, all query operations will issue a",
            "           :meth:`~.Session.flush` call to this ``Session`` before proceeding.",
            "           This is a convenience feature so that :meth:`~.Session.flush` need",
            "           not be called repeatedly in order for database queries to retrieve",
            "           results. It's typical that ``autoflush`` is used in conjunction",
            "           with ``autocommit=False``. In this scenario, explicit calls to",
            "           :meth:`~.Session.flush` are rarely needed; you usually only need to",
            "           call :meth:`~.Session.commit` (which flushes) to finalize changes.",
            "",
            "        :param bind: An optional :class:`.Engine` or :class:`.Connection` to",
            "           which this ``Session`` should be bound. When specified, all SQL",
            "           operations performed by this session will execute via this",
            "           connectable.",
            "",
            "        :param binds: A dictionary which may specify any number of",
            "           :class:`.Engine` or :class:`.Connection` objects as the source of",
            "           connectivity for SQL operations on a per-entity basis.   The keys",
            "           of the dictionary consist of any series of mapped classes,",
            "           arbitrary Python classes that are bases for mapped classes,",
            "           :class:`.Table` objects and :class:`.Mapper` objects.  The",
            "           values of the dictionary are then instances of :class:`.Engine`",
            "           or less commonly :class:`.Connection` objects.  Operations which",
            "           proceed relative to a particular mapped class will consult this",
            "           dictionary for the closest matching entity in order to determine",
            "           which :class:`.Engine` should be used for a particular SQL",
            "           operation.    The complete heuristics for resolution are",
            "           described at :meth:`.Session.get_bind`.  Usage looks like::",
            "",
            "            Session = sessionmaker(binds={",
            "                SomeMappedClass: create_engine('postgresql://engine1'),",
            "                SomeDeclarativeBase: create_engine('postgresql://engine2'),",
            "                some_mapper: create_engine('postgresql://engine3'),",
            "                some_table: create_engine('postgresql://engine4'),",
            "                })",
            "",
            "           .. seealso::",
            "",
            "                :ref:`session_partitioning`",
            "",
            "                :meth:`.Session.bind_mapper`",
            "",
            "                :meth:`.Session.bind_table`",
            "",
            "                :meth:`.Session.get_bind`",
            "",
            "",
            "        :param \\class_: Specify an alternate class other than",
            "           ``sqlalchemy.orm.session.Session`` which should be used by the",
            "           returned class. This is the only argument that is local to the",
            "           :class:`.sessionmaker` function, and is not sent directly to the",
            "           constructor for ``Session``.",
            "",
            "        :param enable_baked_queries: defaults to ``True``.  A flag consumed",
            "           by the :mod:`sqlalchemy.ext.baked` extension to determine if",
            "           \"baked queries\" should be cached, as is the normal operation",
            "           of this extension.  When set to ``False``, all caching is disabled,",
            "           including baked queries defined by the calling application as",
            "           well as those used internally.  Setting this flag to ``False``",
            "           can significantly reduce memory use, however will also degrade",
            "           performance for those areas that make use of baked queries",
            "           (such as relationship loaders).   Additionally, baked query",
            "           logic in the calling application or potentially within the ORM",
            "           that may be malfunctioning due to cache key collisions or similar",
            "           can be flagged by observing if this flag resolves the issue.",
            "",
            "           .. versionadded:: 1.2",
            "",
            "        :param _enable_transaction_accounting:   A",
            "           legacy-only flag which when ``False`` disables *all* 0.5-style",
            "           object accounting on transaction boundaries.",
            "",
            "        :param expire_on_commit:  Defaults to ``True``. When ``True``, all",
            "           instances will be fully expired after each :meth:`~.commit`,",
            "           so that all attribute/object access subsequent to a completed",
            "           transaction will load from the most recent database state.",
            "",
            "        :param extension: An optional",
            "           :class:`~.SessionExtension` instance, or a list",
            "           of such instances, which will receive pre- and post- commit and",
            "           flush events, as well as a post-rollback event.",
            "",
            "        :param info: optional dictionary of arbitrary data to be associated",
            "           with this :class:`.Session`.  Is available via the",
            "           :attr:`.Session.info` attribute.  Note the dictionary is copied at",
            "           construction time so that modifications to the per-",
            "           :class:`.Session` dictionary will be local to that",
            "           :class:`.Session`.",
            "",
            "           .. versionadded:: 0.9.0",
            "",
            "        :param query_cls:  Class which should be used to create new Query",
            "          objects, as returned by the :meth:`~.Session.query` method.",
            "          Defaults to :class:`.Query`.",
            "",
            "        :param twophase:  When ``True``, all transactions will be started as",
            "            a \"two phase\" transaction, i.e. using the \"two phase\" semantics",
            "            of the database in use along with an XID.  During a",
            "            :meth:`~.commit`, after :meth:`~.flush` has been issued for all",
            "            attached databases, the :meth:`~.TwoPhaseTransaction.prepare`",
            "            method on each database's :class:`.TwoPhaseTransaction` will be",
            "            called. This allows each database to roll back the entire",
            "            transaction, before each transaction is committed.",
            "",
            "        :param weak_identity_map:  Defaults to ``True`` - when set to",
            "           ``False``, objects placed in the :class:`.Session` will be",
            "           strongly referenced until explicitly removed or the",
            "           :class:`.Session` is closed.",
            "",
            "",
            "        \"\"\"",
            "",
            "        if weak_identity_map in (True, None):",
            "            self._identity_cls = identity.WeakInstanceDict",
            "        else:",
            "            self._identity_cls = identity.StrongInstanceDict",
            "",
            "        self.identity_map = self._identity_cls()",
            "",
            "        self._new = {}  # InstanceState->object, strong refs object",
            "        self._deleted = {}  # same",
            "        self.bind = bind",
            "        self.__binds = {}",
            "        self._flushing = False",
            "        self._warn_on_events = False",
            "        self.transaction = None",
            "        self.hash_key = _new_sessionid()",
            "        self.autoflush = autoflush",
            "        self.autocommit = autocommit",
            "        self.expire_on_commit = expire_on_commit",
            "        self.enable_baked_queries = enable_baked_queries",
            "        self._enable_transaction_accounting = _enable_transaction_accounting",
            "",
            "        self.twophase = twophase",
            "        self._query_cls = query_cls if query_cls else query.Query",
            "        if info:",
            "            self.info.update(info)",
            "",
            "        if extension:",
            "            for ext in util.to_list(extension):",
            "                SessionExtension._adapt_listener(self, ext)",
            "",
            "        if binds is not None:",
            "            for key, bind in binds.items():",
            "                self._add_bind(key, bind)",
            "",
            "        if not self.autocommit:",
            "            self.begin()",
            "        _sessions[self.hash_key] = self",
            "",
            "    connection_callable = None",
            "",
            "    transaction = None",
            "    \"\"\"The current active or inactive :class:`.SessionTransaction`.\"\"\"",
            "",
            "    @util.memoized_property",
            "    def info(self):",
            "        \"\"\"A user-modifiable dictionary.",
            "",
            "        The initial value of this dictionary can be populated using the",
            "        ``info`` argument to the :class:`.Session` constructor or",
            "        :class:`.sessionmaker` constructor or factory methods.  The dictionary",
            "        here is always local to this :class:`.Session` and can be modified",
            "        independently of all other :class:`.Session` objects.",
            "",
            "        .. versionadded:: 0.9.0",
            "",
            "        \"\"\"",
            "        return {}",
            "",
            "    def begin(self, subtransactions=False, nested=False):",
            "        \"\"\"Begin a transaction on this :class:`.Session`.",
            "",
            "        .. warning::",
            "",
            "            The :meth:`.Session.begin` method is part of a larger pattern",
            "            of use with the :class:`.Session` known as **autocommit mode**.",
            "            This is essentially a **legacy mode of use** and is",
            "            not necessary for new applications.    The :class:`.Session`",
            "            normally handles the work of \"begin\" transparently, which in",
            "            turn relies upon the Python DBAPI to transparently \"begin\"",
            "            transactions; there is **no need to explicitly begin transactions**",
            "            when using modern :class:`.Session` programming patterns.",
            "            In its default mode of ``autocommit=False``, the",
            "            :class:`.Session` does all of its work within",
            "            the context of a transaction, so as soon as you call",
            "            :meth:`.Session.commit`, the next transaction is implicitly",
            "            started when the next database operation is invoked.  See",
            "            :ref:`session_autocommit` for further background.",
            "",
            "        The method will raise an error if this :class:`.Session` is already",
            "        inside of a transaction, unless",
            "        :paramref:`~.Session.begin.subtransactions` or",
            "        :paramref:`~.Session.begin.nested` are specified.  A \"subtransaction\"",
            "        is essentially a code embedding pattern that does not affect the",
            "        transactional state of the database connection unless a rollback is",
            "        emitted, in which case the whole transaction is rolled back.  For",
            "        documentation on subtransactions, please see",
            "        :ref:`session_subtransactions`.",
            "",
            "        :param subtransactions: if True, indicates that this",
            "         :meth:`~.Session.begin` can create a \"subtransaction\".",
            "",
            "        :param nested: if True, begins a SAVEPOINT transaction and is",
            "         equivalent to calling :meth:`~.Session.begin_nested`. For",
            "         documentation on SAVEPOINT transactions, please see",
            "         :ref:`session_begin_nested`.",
            "",
            "        :return: the :class:`.SessionTransaction` object.  Note that",
            "         :class:`.SessionTransaction`",
            "         acts as a Python context manager, allowing :meth:`.Session.begin`",
            "         to be used in a \"with\" block.  See :ref:`session_autocommit` for",
            "         an example.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_autocommit`",
            "",
            "            :meth:`.Session.begin_nested`",
            "",
            "",
            "        \"\"\"",
            "        if self.transaction is not None:",
            "            if subtransactions or nested:",
            "                self.transaction = self.transaction._begin(nested=nested)",
            "            else:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"A transaction is already begun.  Use \"",
            "                    \"subtransactions=True to allow subtransactions.\"",
            "                )",
            "        else:",
            "            self.transaction = SessionTransaction(self, nested=nested)",
            "        return self.transaction  # needed for __enter__/__exit__ hook",
            "",
            "    def begin_nested(self):",
            "        \"\"\"Begin a \"nested\" transaction on this Session, e.g. SAVEPOINT.",
            "",
            "        The target database(s) and associated drivers must support SQL",
            "        SAVEPOINT for this method to function correctly.",
            "",
            "        For documentation on SAVEPOINT",
            "        transactions, please see :ref:`session_begin_nested`.",
            "",
            "        :return: the :class:`.SessionTransaction` object.  Note that",
            "         :class:`.SessionTransaction` acts as a context manager, allowing",
            "         :meth:`.Session.begin_nested` to be used in a \"with\" block.",
            "         See :ref:`session_begin_nested` for a usage example.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_begin_nested`",
            "",
            "            :ref:`pysqlite_serializable` - special workarounds required",
            "            with the SQLite driver in order for SAVEPOINT to work",
            "            correctly.",
            "",
            "        \"\"\"",
            "        return self.begin(nested=True)",
            "",
            "    def rollback(self):",
            "        \"\"\"Rollback the current transaction in progress.",
            "",
            "        If no transaction is in progress, this method is a pass-through.",
            "",
            "        This method rolls back the current transaction or nested transaction",
            "        regardless of subtransactions being in effect.  All subtransactions up",
            "        to the first real transaction are closed.  Subtransactions occur when",
            "        :meth:`.begin` is called multiple times.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_rollback`",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            pass",
            "        else:",
            "            self.transaction.rollback()",
            "",
            "    def commit(self):",
            "        \"\"\"Flush pending changes and commit the current transaction.",
            "",
            "        If no transaction is in progress, this method raises an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError`.",
            "",
            "        By default, the :class:`.Session` also expires all database",
            "        loaded state on all ORM-managed attributes after transaction commit.",
            "        This so that subsequent operations load the most recent",
            "        data from the database.   This behavior can be disabled using",
            "        the ``expire_on_commit=False`` option to :class:`.sessionmaker` or",
            "        the :class:`.Session` constructor.",
            "",
            "        If a subtransaction is in effect (which occurs when begin() is called",
            "        multiple times), the subtransaction will be closed, and the next call",
            "        to ``commit()`` will operate on the enclosing transaction.",
            "",
            "        When using the :class:`.Session` in its default mode of",
            "        ``autocommit=False``, a new transaction will",
            "        be begun immediately after the commit, but note that the newly begun",
            "        transaction does *not* use any connection resources until the first",
            "        SQL is actually emitted.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_committing`",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            if not self.autocommit:",
            "                self.begin()",
            "            else:",
            "                raise sa_exc.InvalidRequestError(\"No transaction is begun.\")",
            "",
            "        self.transaction.commit()",
            "",
            "    def prepare(self):",
            "        \"\"\"Prepare the current transaction in progress for two phase commit.",
            "",
            "        If no transaction is in progress, this method raises an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError`.",
            "",
            "        Only root transactions of two phase sessions can be prepared. If the",
            "        current transaction is not such, an",
            "        :exc:`~sqlalchemy.exc.InvalidRequestError` is raised.",
            "",
            "        \"\"\"",
            "        if self.transaction is None:",
            "            if not self.autocommit:",
            "                self.begin()",
            "            else:",
            "                raise sa_exc.InvalidRequestError(\"No transaction is begun.\")",
            "",
            "        self.transaction.prepare()",
            "",
            "    def connection(",
            "        self,",
            "        mapper=None,",
            "        clause=None,",
            "        bind=None,",
            "        close_with_result=False,",
            "        execution_options=None,",
            "        **kw",
            "    ):",
            "        r\"\"\"Return a :class:`.Connection` object corresponding to this",
            "        :class:`.Session` object's transactional state.",
            "",
            "        If this :class:`.Session` is configured with ``autocommit=False``,",
            "        either the :class:`.Connection` corresponding to the current",
            "        transaction is returned, or if no transaction is in progress, a new",
            "        one is begun and the :class:`.Connection` returned (note that no",
            "        transactional state is established with the DBAPI until the first",
            "        SQL statement is emitted).",
            "",
            "        Alternatively, if this :class:`.Session` is configured with",
            "        ``autocommit=True``, an ad-hoc :class:`.Connection` is returned",
            "        using :meth:`.Engine.connect` on the underlying",
            "        :class:`.Engine`.",
            "",
            "        Ambiguity in multi-bind or unbound :class:`.Session` objects can be",
            "        resolved through any of the optional keyword arguments.   This",
            "        ultimately makes usage of the :meth:`.get_bind` method for resolution.",
            "",
            "        :param bind:",
            "          Optional :class:`.Engine` to be used as the bind.  If",
            "          this engine is already involved in an ongoing transaction,",
            "          that connection will be used.  This argument takes precedence",
            "          over ``mapper``, ``clause``.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` mapped class, used to identify",
            "          the appropriate bind.  This argument takes precedence over",
            "          ``clause``.",
            "",
            "        :param clause:",
            "            A :class:`.ClauseElement` (i.e. :func:`~.sql.expression.select`,",
            "            :func:`~.sql.expression.text`,",
            "            etc.) which will be used to locate a bind, if a bind",
            "            cannot otherwise be identified.",
            "",
            "        :param close_with_result: Passed to :meth:`.Engine.connect`,",
            "          indicating the :class:`.Connection` should be considered",
            "          \"single use\", automatically closing when the first result set is",
            "          closed.  This flag only has an effect if this :class:`.Session` is",
            "          configured with ``autocommit=True`` and does not already have a",
            "          transaction in progress.",
            "",
            "        :param execution_options: a dictionary of execution options that will",
            "         be passed to :meth:`.Connection.execution_options`, **when the",
            "         connection is first procured only**.   If the connection is already",
            "         present within the :class:`.Session`, a warning is emitted and",
            "         the arguments are ignored.",
            "",
            "         .. versionadded:: 0.9.9",
            "",
            "         .. seealso::",
            "",
            "            :ref:`session_transaction_isolation`",
            "",
            "        :param \\**kw:",
            "          Additional keyword arguments are sent to :meth:`get_bind()`,",
            "          allowing additional arguments to be passed to custom",
            "          implementations of :meth:`get_bind`.",
            "",
            "        \"\"\"",
            "        if bind is None:",
            "            bind = self.get_bind(mapper, clause=clause, **kw)",
            "",
            "        return self._connection_for_bind(",
            "            bind,",
            "            close_with_result=close_with_result,",
            "            execution_options=execution_options,",
            "        )",
            "",
            "    def _connection_for_bind(self, engine, execution_options=None, **kw):",
            "        if self.transaction is not None:",
            "            return self.transaction._connection_for_bind(",
            "                engine, execution_options",
            "            )",
            "        else:",
            "            conn = engine._contextual_connect(**kw)",
            "            if execution_options:",
            "                conn = conn.execution_options(**execution_options)",
            "            return conn",
            "",
            "    def execute(self, clause, params=None, mapper=None, bind=None, **kw):",
            "        r\"\"\"Execute a SQL expression construct or string statement within",
            "        the current transaction.",
            "",
            "        Returns a :class:`.ResultProxy` representing",
            "        results of the statement execution, in the same manner as that of an",
            "        :class:`.Engine` or",
            "        :class:`.Connection`.",
            "",
            "        E.g.::",
            "",
            "            result = session.execute(",
            "                        user_table.select().where(user_table.c.id == 5)",
            "                    )",
            "",
            "        :meth:`~.Session.execute` accepts any executable clause construct,",
            "        such as :func:`~.sql.expression.select`,",
            "        :func:`~.sql.expression.insert`,",
            "        :func:`~.sql.expression.update`,",
            "        :func:`~.sql.expression.delete`, and",
            "        :func:`~.sql.expression.text`.  Plain SQL strings can be passed",
            "        as well, which in the case of :meth:`.Session.execute` only",
            "        will be interpreted the same as if it were passed via a",
            "        :func:`~.expression.text` construct.  That is, the following usage::",
            "",
            "            result = session.execute(",
            "                        \"SELECT * FROM user WHERE id=:param\",",
            "                        {\"param\":5}",
            "                    )",
            "",
            "        is equivalent to::",
            "",
            "            from sqlalchemy import text",
            "            result = session.execute(",
            "                        text(\"SELECT * FROM user WHERE id=:param\"),",
            "                        {\"param\":5}",
            "                    )",
            "",
            "        The second positional argument to :meth:`.Session.execute` is an",
            "        optional parameter set.  Similar to that of",
            "        :meth:`.Connection.execute`, whether this is passed as a single",
            "        dictionary, or a list of dictionaries, determines whether the DBAPI",
            "        cursor's ``execute()`` or ``executemany()`` is used to execute the",
            "        statement.   An INSERT construct may be invoked for a single row::",
            "",
            "            result = session.execute(",
            "                users.insert(), {\"id\": 7, \"name\": \"somename\"})",
            "",
            "        or for multiple rows::",
            "",
            "            result = session.execute(users.insert(), [",
            "                                    {\"id\": 7, \"name\": \"somename7\"},",
            "                                    {\"id\": 8, \"name\": \"somename8\"},",
            "                                    {\"id\": 9, \"name\": \"somename9\"}",
            "                                ])",
            "",
            "        The statement is executed within the current transactional context of",
            "        this :class:`.Session`.   The :class:`.Connection` which is used",
            "        to execute the statement can also be acquired directly by",
            "        calling the :meth:`.Session.connection` method.  Both methods use",
            "        a rule-based resolution scheme in order to determine the",
            "        :class:`.Connection`, which in the average case is derived directly",
            "        from the \"bind\" of the :class:`.Session` itself, and in other cases",
            "        can be based on the :func:`.mapper`",
            "        and :class:`.Table` objects passed to the method; see the",
            "        documentation for :meth:`.Session.get_bind` for a full description of",
            "        this scheme.",
            "",
            "        The :meth:`.Session.execute` method does *not* invoke autoflush.",
            "",
            "        The :class:`.ResultProxy` returned by the :meth:`.Session.execute`",
            "        method is returned with the \"close_with_result\" flag set to true;",
            "        the significance of this flag is that if this :class:`.Session` is",
            "        autocommitting and does not have a transaction-dedicated",
            "        :class:`.Connection` available, a temporary :class:`.Connection` is",
            "        established for the statement execution, which is closed (meaning,",
            "        returned to the connection pool) when the :class:`.ResultProxy` has",
            "        consumed all available data. This applies *only* when the",
            "        :class:`.Session` is configured with autocommit=True and no",
            "        transaction has been started.",
            "",
            "        :param clause:",
            "            An executable statement (i.e. an :class:`.Executable` expression",
            "            such as :func:`.expression.select`) or string SQL statement",
            "            to be executed.",
            "",
            "        :param params:",
            "            Optional dictionary, or list of dictionaries, containing",
            "            bound parameter values.   If a single dictionary, single-row",
            "            execution occurs; if a list of dictionaries, an",
            "            \"executemany\" will be invoked.  The keys in each dictionary",
            "            must correspond to parameter names present in the statement.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` or mapped class, used to identify",
            "          the appropriate bind.  This argument takes precedence over",
            "          ``clause`` when locating a bind.   See :meth:`.Session.get_bind`",
            "          for more details.",
            "",
            "        :param bind:",
            "          Optional :class:`.Engine` to be used as the bind.  If",
            "          this engine is already involved in an ongoing transaction,",
            "          that connection will be used.  This argument takes",
            "          precedence over ``mapper`` and ``clause`` when locating",
            "          a bind.",
            "",
            "        :param \\**kw:",
            "          Additional keyword arguments are sent to :meth:`.Session.get_bind()`",
            "          to allow extensibility of \"bind\" schemes.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`sqlexpression_toplevel` - Tutorial on using Core SQL",
            "            constructs.",
            "",
            "            :ref:`connections_toplevel` - Further information on direct",
            "            statement execution.",
            "",
            "            :meth:`.Connection.execute` - core level statement execution",
            "            method, which is :meth:`.Session.execute` ultimately uses",
            "            in order to execute the statement.",
            "",
            "        \"\"\"",
            "        clause = expression._literal_as_text(",
            "            clause, allow_coercion_to_text=True",
            "        )",
            "",
            "        if bind is None:",
            "            bind = self.get_bind(mapper, clause=clause, **kw)",
            "",
            "        return self._connection_for_bind(bind, close_with_result=True).execute(",
            "            clause, params or {}",
            "        )",
            "",
            "    def scalar(self, clause, params=None, mapper=None, bind=None, **kw):",
            "        \"\"\"Like :meth:`~.Session.execute` but return a scalar result.\"\"\"",
            "",
            "        return self.execute(",
            "            clause, params=params, mapper=mapper, bind=bind, **kw",
            "        ).scalar()",
            "",
            "    def close(self):",
            "        \"\"\"Close this Session.",
            "",
            "        This clears all items and ends any transaction in progress.",
            "",
            "        If this session were created with ``autocommit=False``, a new",
            "        transaction is immediately begun.  Note that this new transaction does",
            "        not use any connection resources until they are first needed.",
            "",
            "        \"\"\"",
            "        self._close_impl(invalidate=False)",
            "",
            "    def invalidate(self):",
            "        \"\"\"Close this Session, using connection invalidation.",
            "",
            "        This is a variant of :meth:`.Session.close` that will additionally",
            "        ensure that the :meth:`.Connection.invalidate` method will be called",
            "        on all :class:`.Connection` objects.  This can be called when",
            "        the database is known to be in a state where the connections are",
            "        no longer safe to be used.",
            "",
            "        E.g.::",
            "",
            "            try:",
            "                sess = Session()",
            "                sess.add(User())",
            "                sess.commit()",
            "            except gevent.Timeout:",
            "                sess.invalidate()",
            "                raise",
            "            except:",
            "                sess.rollback()",
            "                raise",
            "",
            "        This clears all items and ends any transaction in progress.",
            "",
            "        If this session were created with ``autocommit=False``, a new",
            "        transaction is immediately begun.  Note that this new transaction does",
            "        not use any connection resources until they are first needed.",
            "",
            "        .. versionadded:: 0.9.9",
            "",
            "        \"\"\"",
            "        self._close_impl(invalidate=True)",
            "",
            "    def _close_impl(self, invalidate):",
            "        self.expunge_all()",
            "        if self.transaction is not None:",
            "            for transaction in self.transaction._iterate_self_and_parents():",
            "                transaction.close(invalidate)",
            "",
            "    def expunge_all(self):",
            "        \"\"\"Remove all object instances from this ``Session``.",
            "",
            "        This is equivalent to calling ``expunge(obj)`` on all objects in this",
            "        ``Session``.",
            "",
            "        \"\"\"",
            "",
            "        all_states = self.identity_map.all_states() + list(self._new)",
            "        self.identity_map = self._identity_cls()",
            "        self._new = {}",
            "        self._deleted = {}",
            "",
            "        statelib.InstanceState._detach_states(all_states, self)",
            "",
            "    def _add_bind(self, key, bind):",
            "        try:",
            "            insp = inspect(key)",
            "        except sa_exc.NoInspectionAvailable:",
            "            if not isinstance(key, type):",
            "                raise sa_exc.ArgumentError(",
            "                    \"Not an acceptable bind target: %s\" % key",
            "                )",
            "            else:",
            "                self.__binds[key] = bind",
            "        else:",
            "            if insp.is_selectable:",
            "                self.__binds[insp] = bind",
            "            elif insp.is_mapper:",
            "                self.__binds[insp.class_] = bind",
            "                for selectable in insp._all_tables:",
            "                    self.__binds[selectable] = bind",
            "            else:",
            "                raise sa_exc.ArgumentError(",
            "                    \"Not an acceptable bind target: %s\" % key",
            "                )",
            "",
            "    def bind_mapper(self, mapper, bind):",
            "        \"\"\"Associate a :class:`.Mapper` or arbitrary Python class with a",
            "        \"bind\", e.g. an :class:`.Engine` or :class:`.Connection`.",
            "",
            "        The given entity is added to a lookup used by the",
            "        :meth:`.Session.get_bind` method.",
            "",
            "        :param mapper: a :class:`.Mapper` object, or an instance of a mapped",
            "         class, or any Python class that is the base of a set of mapped",
            "         classes.",
            "",
            "        :param bind: an :class:`.Engine` or :class:`.Connection` object.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_partitioning`",
            "",
            "            :paramref:`.Session.binds`",
            "",
            "            :meth:`.Session.bind_table`",
            "",
            "",
            "        \"\"\"",
            "        self._add_bind(mapper, bind)",
            "",
            "    def bind_table(self, table, bind):",
            "        \"\"\"Associate a :class:`.Table` with a \"bind\", e.g. an :class:`.Engine`",
            "        or :class:`.Connection`.",
            "",
            "        The given :class:`.Table` is added to a lookup used by the",
            "        :meth:`.Session.get_bind` method.",
            "",
            "        :param table: a :class:`.Table` object, which is typically the target",
            "         of an ORM mapping, or is present within a selectable that is",
            "         mapped.",
            "",
            "        :param bind: an :class:`.Engine` or :class:`.Connection` object.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_partitioning`",
            "",
            "            :paramref:`.Session.binds`",
            "",
            "            :meth:`.Session.bind_mapper`",
            "",
            "",
            "        \"\"\"",
            "        self._add_bind(table, bind)",
            "",
            "    def get_bind(self, mapper=None, clause=None):",
            "        \"\"\"Return a \"bind\" to which this :class:`.Session` is bound.",
            "",
            "        The \"bind\" is usually an instance of :class:`.Engine`,",
            "        except in the case where the :class:`.Session` has been",
            "        explicitly bound directly to a :class:`.Connection`.",
            "",
            "        For a multiply-bound or unbound :class:`.Session`, the",
            "        ``mapper`` or ``clause`` arguments are used to determine the",
            "        appropriate bind to return.",
            "",
            "        Note that the \"mapper\" argument is usually present",
            "        when :meth:`.Session.get_bind` is called via an ORM",
            "        operation such as a :meth:`.Session.query`, each",
            "        individual INSERT/UPDATE/DELETE operation within a",
            "        :meth:`.Session.flush`, call, etc.",
            "",
            "        The order of resolution is:",
            "",
            "        1. if mapper given and session.binds is present,",
            "           locate a bind based first on the mapper in use, then",
            "           on the mapped class in use, then on any base classes that are",
            "           present in the ``__mro__`` of the mapped class, from more specific",
            "           superclasses to more general.",
            "        2. if clause given and session.binds is present,",
            "           locate a bind based on :class:`.Table` objects",
            "           found in the given clause present in session.binds.",
            "        3. if session.bind is present, return that.",
            "        4. if clause given, attempt to return a bind",
            "           linked to the :class:`.MetaData` ultimately",
            "           associated with the clause.",
            "        5. if mapper given, attempt to return a bind",
            "           linked to the :class:`.MetaData` ultimately",
            "           associated with the :class:`.Table` or other",
            "           selectable to which the mapper is mapped.",
            "        6. No bind can be found, :exc:`~sqlalchemy.exc.UnboundExecutionError`",
            "           is raised.",
            "",
            "        Note that the :meth:`.Session.get_bind` method can be overridden on",
            "        a user-defined subclass of :class:`.Session` to provide any kind",
            "        of bind resolution scheme.  See the example at",
            "        :ref:`session_custom_partitioning`.",
            "",
            "        :param mapper:",
            "          Optional :func:`.mapper` mapped class or instance of",
            "          :class:`.Mapper`.   The bind can be derived from a :class:`.Mapper`",
            "          first by consulting the \"binds\" map associated with this",
            "          :class:`.Session`, and secondly by consulting the :class:`.MetaData`",
            "          associated with the :class:`.Table` to which the :class:`.Mapper`",
            "          is mapped for a bind.",
            "",
            "        :param clause:",
            "            A :class:`.ClauseElement` (i.e. :func:`~.sql.expression.select`,",
            "            :func:`~.sql.expression.text`,",
            "            etc.).  If the ``mapper`` argument is not present or could not",
            "            produce a bind, the given expression construct will be searched",
            "            for a bound element, typically a :class:`.Table` associated with",
            "            bound :class:`.MetaData`.",
            "",
            "        .. seealso::",
            "",
            "             :ref:`session_partitioning`",
            "",
            "             :paramref:`.Session.binds`",
            "",
            "             :meth:`.Session.bind_mapper`",
            "",
            "             :meth:`.Session.bind_table`",
            "",
            "        \"\"\"",
            "",
            "        if mapper is clause is None:",
            "            if self.bind:",
            "                return self.bind",
            "            else:",
            "                raise sa_exc.UnboundExecutionError(",
            "                    \"This session is not bound to a single Engine or \"",
            "                    \"Connection, and no context was provided to locate \"",
            "                    \"a binding.\"",
            "                )",
            "",
            "        if mapper is not None:",
            "            try:",
            "                mapper = inspect(mapper)",
            "            except sa_exc.NoInspectionAvailable:",
            "                if isinstance(mapper, type):",
            "                    raise exc.UnmappedClassError(mapper)",
            "                else:",
            "                    raise",
            "",
            "        if self.__binds:",
            "            if mapper:",
            "                for cls in mapper.class_.__mro__:",
            "                    if cls in self.__binds:",
            "                        return self.__binds[cls]",
            "                if clause is None:",
            "                    clause = mapper.persist_selectable",
            "",
            "            if clause is not None:",
            "                for t in sql_util.find_tables(clause, include_crud=True):",
            "                    if t in self.__binds:",
            "                        return self.__binds[t]",
            "",
            "        if self.bind:",
            "            return self.bind",
            "",
            "        if isinstance(clause, sql.expression.ClauseElement) and clause.bind:",
            "            return clause.bind",
            "",
            "        if mapper and mapper.persist_selectable.bind:",
            "            return mapper.persist_selectable.bind",
            "",
            "        context = []",
            "        if mapper is not None:",
            "            context.append(\"mapper %s\" % mapper)",
            "        if clause is not None:",
            "            context.append(\"SQL expression\")",
            "",
            "        raise sa_exc.UnboundExecutionError(",
            "            \"Could not locate a bind configured on %s or this Session\"",
            "            % (\", \".join(context))",
            "        )",
            "",
            "    def query(self, *entities, **kwargs):",
            "        \"\"\"Return a new :class:`.Query` object corresponding to this",
            "        :class:`.Session`.\"\"\"",
            "",
            "        return self._query_cls(entities, self, **kwargs)",
            "",
            "    @property",
            "    @util.contextmanager",
            "    def no_autoflush(self):",
            "        \"\"\"Return a context manager that disables autoflush.",
            "",
            "        e.g.::",
            "",
            "            with session.no_autoflush:",
            "",
            "                some_object = SomeClass()",
            "                session.add(some_object)",
            "                # won't autoflush",
            "                some_object.related_thing = session.query(SomeRelated).first()",
            "",
            "        Operations that proceed within the ``with:`` block",
            "        will not be subject to flushes occurring upon query",
            "        access.  This is useful when initializing a series",
            "        of objects which involve existing database queries,",
            "        where the uncompleted object should not yet be flushed.",
            "",
            "        \"\"\"",
            "        autoflush = self.autoflush",
            "        self.autoflush = False",
            "        try:",
            "            yield self",
            "        finally:",
            "            self.autoflush = autoflush",
            "",
            "    def _autoflush(self):",
            "        if self.autoflush and not self._flushing:",
            "            try:",
            "                self.flush()",
            "            except sa_exc.StatementError as e:",
            "                # note we are reraising StatementError as opposed to",
            "                # raising FlushError with \"chaining\" to remain compatible",
            "                # with code that catches StatementError, IntegrityError,",
            "                # etc.",
            "                e.add_detail(",
            "                    \"raised as a result of Query-invoked autoflush; \"",
            "                    \"consider using a session.no_autoflush block if this \"",
            "                    \"flush is occurring prematurely\"",
            "                )",
            "                util.raise_from_cause(e)",
            "",
            "    def refresh(",
            "        self,",
            "        instance,",
            "        attribute_names=None,",
            "        with_for_update=None,",
            "        lockmode=None,",
            "    ):",
            "        \"\"\"Expire and refresh the attributes on the given instance.",
            "",
            "        A query will be issued to the database and all attributes will be",
            "        refreshed with their current database value.",
            "",
            "        Lazy-loaded relational attributes will remain lazily loaded, so that",
            "        the instance-wide refresh operation will be followed immediately by",
            "        the lazy load of that attribute.",
            "",
            "        Eagerly-loaded relational attributes will eagerly load within the",
            "        single refresh operation.",
            "",
            "        Note that a highly isolated transaction will return the same values as",
            "        were previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction - usage of",
            "        :meth:`~Session.refresh` usually only makes sense if non-ORM SQL",
            "        statement were emitted in the ongoing transaction, or if autocommit",
            "        mode is turned on.",
            "",
            "        :param attribute_names: optional.  An iterable collection of",
            "          string attribute names indicating a subset of attributes to",
            "          be refreshed.",
            "",
            "        :param with_for_update: optional boolean ``True`` indicating FOR UPDATE",
            "          should be used, or may be a dictionary containing flags to",
            "          indicate a more specific set of FOR UPDATE flags for the SELECT;",
            "          flags should match the parameters of :meth:`.Query.with_for_update`.",
            "          Supersedes the :paramref:`.Session.refresh.lockmode` parameter.",
            "",
            "          .. versionadded:: 1.2",
            "",
            "        :param lockmode: Passed to the :class:`~sqlalchemy.orm.query.Query`",
            "          as used by :meth:`~sqlalchemy.orm.query.Query.with_lockmode`.",
            "          Superseded by :paramref:`.Session.refresh.with_for_update`.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.expire_all`",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._expire_state(state, attribute_names)",
            "",
            "        if with_for_update == {}:",
            "            raise sa_exc.ArgumentError(",
            "                \"with_for_update should be the boolean value \"",
            "                \"True, or a dictionary with options.  \"",
            "                \"A blank dictionary is ambiguous.\"",
            "            )",
            "",
            "        if lockmode:",
            "            with_for_update = query.LockmodeArg.parse_legacy_query(lockmode)",
            "        elif with_for_update is not None:",
            "            if with_for_update is True:",
            "                with_for_update = query.LockmodeArg()",
            "            elif with_for_update:",
            "                with_for_update = query.LockmodeArg(**with_for_update)",
            "            else:",
            "                with_for_update = None",
            "",
            "        if (",
            "            loading.load_on_ident(",
            "                self.query(object_mapper(instance)),",
            "                state.key,",
            "                refresh_state=state,",
            "                with_for_update=with_for_update,",
            "                only_load_props=attribute_names,",
            "            )",
            "            is None",
            "        ):",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Could not refresh instance '%s'\" % instance_str(instance)",
            "            )",
            "",
            "    def expire_all(self):",
            "        \"\"\"Expires all persistent instances within this Session.",
            "",
            "        When any attributes on a persistent instance is next accessed,",
            "        a query will be issued using the",
            "        :class:`.Session` object's current transactional context in order to",
            "        load all expired attributes for the given instance.   Note that",
            "        a highly isolated transaction will return the same values as were",
            "        previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction.",
            "",
            "        To expire individual objects and individual attributes",
            "        on those objects, use :meth:`Session.expire`.",
            "",
            "        The :class:`.Session` object's default behavior is to",
            "        expire all state whenever the :meth:`Session.rollback`",
            "        or :meth:`Session.commit` methods are called, so that new",
            "        state can be loaded for the new transaction.   For this reason,",
            "        calling :meth:`Session.expire_all` should not be needed when",
            "        autocommit is ``False``, assuming the transaction is isolated.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.refresh`",
            "",
            "        \"\"\"",
            "        for state in self.identity_map.all_states():",
            "            state._expire(state.dict, self.identity_map._modified)",
            "",
            "    def expire(self, instance, attribute_names=None):",
            "        \"\"\"Expire the attributes on an instance.",
            "",
            "        Marks the attributes of an instance as out of date. When an expired",
            "        attribute is next accessed, a query will be issued to the",
            "        :class:`.Session` object's current transactional context in order to",
            "        load all expired attributes for the given instance.   Note that",
            "        a highly isolated transaction will return the same values as were",
            "        previously read in that same transaction, regardless of changes",
            "        in database state outside of that transaction.",
            "",
            "        To expire all objects in the :class:`.Session` simultaneously,",
            "        use :meth:`Session.expire_all`.",
            "",
            "        The :class:`.Session` object's default behavior is to",
            "        expire all state whenever the :meth:`Session.rollback`",
            "        or :meth:`Session.commit` methods are called, so that new",
            "        state can be loaded for the new transaction.   For this reason,",
            "        calling :meth:`Session.expire` only makes sense for the specific",
            "        case that a non-ORM SQL statement was emitted in the current",
            "        transaction.",
            "",
            "        :param instance: The instance to be refreshed.",
            "        :param attribute_names: optional list of string attribute names",
            "          indicating a subset of attributes to be expired.",
            "",
            "        .. seealso::",
            "",
            "            :ref:`session_expire` - introductory material",
            "",
            "            :meth:`.Session.expire`",
            "",
            "            :meth:`.Session.refresh`",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        self._expire_state(state, attribute_names)",
            "",
            "    def _expire_state(self, state, attribute_names):",
            "        self._validate_persistent(state)",
            "        if attribute_names:",
            "            state._expire_attributes(state.dict, attribute_names)",
            "        else:",
            "            # pre-fetch the full cascade since the expire is going to",
            "            # remove associations",
            "            cascaded = list(",
            "                state.manager.mapper.cascade_iterator(\"refresh-expire\", state)",
            "            )",
            "            self._conditional_expire(state)",
            "            for o, m, st_, dct_ in cascaded:",
            "                self._conditional_expire(st_)",
            "",
            "    def _conditional_expire(self, state):",
            "        \"\"\"Expire a state if persistent, else expunge if pending\"\"\"",
            "",
            "        if state.key:",
            "            state._expire(state.dict, self.identity_map._modified)",
            "        elif state in self._new:",
            "            self._new.pop(state)",
            "            state._detach(self)",
            "",
            "    @util.deprecated(",
            "        \"0.7\",",
            "        \"The :meth:`.Session.prune` method is deprecated along with \"",
            "        \":paramref:`.Session.weak_identity_map`.  This method will be \"",
            "        \"removed in a future release.\",",
            "    )",
            "    def prune(self):",
            "        \"\"\"Remove unreferenced instances cached in the identity map.",
            "",
            "        Note that this method is only meaningful if \"weak_identity_map\" is set",
            "        to False.  The default weak identity map is self-pruning.",
            "",
            "        Removes any object in this Session's identity map that is not",
            "        referenced in user code, modified, new or scheduled for deletion.",
            "        Returns the number of objects pruned.",
            "",
            "        \"\"\"",
            "        return self.identity_map.prune()",
            "",
            "    def expunge(self, instance):",
            "        \"\"\"Remove the `instance` from this ``Session``.",
            "",
            "        This will free all internal references to the instance.  Cascading",
            "        will be applied according to the *expunge* cascade rule.",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        if state.session_id is not self.hash_key:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance %s is not present in this Session\" % state_str(state)",
            "            )",
            "",
            "        cascaded = list(",
            "            state.manager.mapper.cascade_iterator(\"expunge\", state)",
            "        )",
            "        self._expunge_states([state] + [st_ for o, m, st_, dct_ in cascaded])",
            "",
            "    def _expunge_states(self, states, to_transient=False):",
            "        for state in states:",
            "            if state in self._new:",
            "                self._new.pop(state)",
            "            elif self.identity_map.contains_state(state):",
            "                self.identity_map.safe_discard(state)",
            "                self._deleted.pop(state, None)",
            "            elif self.transaction:",
            "                # state is \"detached\" from being deleted, but still present",
            "                # in the transaction snapshot",
            "                self.transaction._deleted.pop(state, None)",
            "        statelib.InstanceState._detach_states(",
            "            states, self, to_transient=to_transient",
            "        )",
            "",
            "    def _register_newly_persistent(self, states):",
            "        pending_to_persistent = self.dispatch.pending_to_persistent or None",
            "        for state in states:",
            "            mapper = _state_mapper(state)",
            "",
            "            # prevent against last minute dereferences of the object",
            "            obj = state.obj()",
            "            if obj is not None:",
            "",
            "                instance_key = mapper._identity_key_from_state(state)",
            "",
            "                if (",
            "                    _none_set.intersection(instance_key[1])",
            "                    and not mapper.allow_partial_pks",
            "                    or _none_set.issuperset(instance_key[1])",
            "                ):",
            "                    raise exc.FlushError(",
            "                        \"Instance %s has a NULL identity key.  If this is an \"",
            "                        \"auto-generated value, check that the database table \"",
            "                        \"allows generation of new primary key values, and \"",
            "                        \"that the mapped Column object is configured to \"",
            "                        \"expect these generated values.  Ensure also that \"",
            "                        \"this flush() is not occurring at an inappropriate \"",
            "                        \"time, such as within a load() event.\"",
            "                        % state_str(state)",
            "                    )",
            "",
            "                if state.key is None:",
            "                    state.key = instance_key",
            "                elif state.key != instance_key:",
            "                    # primary key switch. use safe_discard() in case another",
            "                    # state has already replaced this one in the identity",
            "                    # map (see test/orm/test_naturalpks.py ReversePKsTest)",
            "                    self.identity_map.safe_discard(state)",
            "                    if state in self.transaction._key_switches:",
            "                        orig_key = self.transaction._key_switches[state][0]",
            "                    else:",
            "                        orig_key = state.key",
            "                    self.transaction._key_switches[state] = (",
            "                        orig_key,",
            "                        instance_key,",
            "                    )",
            "                    state.key = instance_key",
            "",
            "                self.identity_map.replace(state)",
            "                state._orphaned_outside_of_session = False",
            "",
            "        statelib.InstanceState._commit_all_states(",
            "            ((state, state.dict) for state in states), self.identity_map",
            "        )",
            "",
            "        self._register_altered(states)",
            "",
            "        if pending_to_persistent is not None:",
            "            for state in states:",
            "                pending_to_persistent(self, state.obj())",
            "",
            "        # remove from new last, might be the last strong ref",
            "        for state in set(states).intersection(self._new):",
            "            self._new.pop(state)",
            "",
            "    def _register_altered(self, states):",
            "        if self._enable_transaction_accounting and self.transaction:",
            "            for state in states:",
            "                if state in self._new:",
            "                    self.transaction._new[state] = True",
            "                else:",
            "                    self.transaction._dirty[state] = True",
            "",
            "    def _remove_newly_deleted(self, states):",
            "        persistent_to_deleted = self.dispatch.persistent_to_deleted or None",
            "        for state in states:",
            "            if self._enable_transaction_accounting and self.transaction:",
            "                self.transaction._deleted[state] = True",
            "",
            "            if persistent_to_deleted is not None:",
            "                # get a strong reference before we pop out of",
            "                # self._deleted",
            "                obj = state.obj()",
            "",
            "            self.identity_map.safe_discard(state)",
            "            self._deleted.pop(state, None)",
            "            state._deleted = True",
            "            # can't call state._detach() here, because this state",
            "            # is still in the transaction snapshot and needs to be",
            "            # tracked as part of that",
            "            if persistent_to_deleted is not None:",
            "                persistent_to_deleted(self, obj)",
            "",
            "    def add(self, instance, _warn=True):",
            "        \"\"\"Place an object in the ``Session``.",
            "",
            "        Its state will be persisted to the database on the next flush",
            "        operation.",
            "",
            "        Repeated calls to ``add()`` will be ignored. The opposite of ``add()``",
            "        is ``expunge()``.",
            "",
            "        \"\"\"",
            "        if _warn and self._warn_on_events:",
            "            self._flush_warning(\"Session.add()\")",
            "",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._save_or_update_state(state)",
            "",
            "    def add_all(self, instances):",
            "        \"\"\"Add the given collection of instances to this ``Session``.\"\"\"",
            "",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.add_all()\")",
            "",
            "        for instance in instances:",
            "            self.add(instance, _warn=False)",
            "",
            "    def _save_or_update_state(self, state):",
            "        state._orphaned_outside_of_session = False",
            "        self._save_or_update_impl(state)",
            "",
            "        mapper = _state_mapper(state)",
            "        for o, m, st_, dct_ in mapper.cascade_iterator(",
            "            \"save-update\", state, halt_on=self._contains_state",
            "        ):",
            "            self._save_or_update_impl(st_)",
            "",
            "    def delete(self, instance):",
            "        \"\"\"Mark an instance as deleted.",
            "",
            "        The database delete operation occurs upon ``flush()``.",
            "",
            "        \"\"\"",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.delete()\")",
            "",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "",
            "        self._delete_impl(state, instance, head=True)",
            "",
            "    def _delete_impl(self, state, obj, head):",
            "",
            "        if state.key is None:",
            "            if head:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Instance '%s' is not persisted\" % state_str(state)",
            "                )",
            "            else:",
            "                return",
            "",
            "        to_attach = self._before_attach(state, obj)",
            "",
            "        if state in self._deleted:",
            "            return",
            "",
            "        self.identity_map.add(state)",
            "",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "        if head:",
            "            # grab the cascades before adding the item to the deleted list",
            "            # so that autoflush does not delete the item",
            "            # the strong reference to the instance itself is significant here",
            "            cascade_states = list(",
            "                state.manager.mapper.cascade_iterator(\"delete\", state)",
            "            )",
            "",
            "        self._deleted[state] = obj",
            "",
            "        if head:",
            "            for o, m, st_, dct_ in cascade_states:",
            "                self._delete_impl(st_, o, False)",
            "",
            "    def merge(self, instance, load=True):",
            "        \"\"\"Copy the state of a given instance into a corresponding instance",
            "        within this :class:`.Session`.",
            "",
            "        :meth:`.Session.merge` examines the primary key attributes of the",
            "        source instance, and attempts to reconcile it with an instance of the",
            "        same primary key in the session.   If not found locally, it attempts",
            "        to load the object from the database based on primary key, and if",
            "        none can be located, creates a new instance.  The state of each",
            "        attribute on the source instance is then copied to the target",
            "        instance.  The resulting target instance is then returned by the",
            "        method; the original source instance is left unmodified, and",
            "        un-associated with the :class:`.Session` if not already.",
            "",
            "        This operation cascades to associated instances if the association is",
            "        mapped with ``cascade=\"merge\"``.",
            "",
            "        See :ref:`unitofwork_merging` for a detailed discussion of merging.",
            "",
            "        .. versionchanged:: 1.1 - :meth:`.Session.merge` will now reconcile",
            "           pending objects with overlapping primary keys in the same way",
            "           as persistent.  See :ref:`change_3601` for discussion.",
            "",
            "        :param instance: Instance to be merged.",
            "        :param load: Boolean, when False, :meth:`.merge` switches into",
            "         a \"high performance\" mode which causes it to forego emitting history",
            "         events as well as all database access.  This flag is used for",
            "         cases such as transferring graphs of objects into a :class:`.Session`",
            "         from a second level cache, or to transfer just-loaded objects",
            "         into the :class:`.Session` owned by a worker thread or process",
            "         without re-querying the database.",
            "",
            "         The ``load=False`` use case adds the caveat that the given",
            "         object has to be in a \"clean\" state, that is, has no pending changes",
            "         to be flushed - even if the incoming object is detached from any",
            "         :class:`.Session`.   This is so that when",
            "         the merge operation populates local attributes and",
            "         cascades to related objects and",
            "         collections, the values can be \"stamped\" onto the",
            "         target object as is, without generating any history or attribute",
            "         events, and without the need to reconcile the incoming data with",
            "         any existing related objects or collections that might not",
            "         be loaded.  The resulting objects from ``load=False`` are always",
            "         produced as \"clean\", so it is only appropriate that the given objects",
            "         should be \"clean\" as well, else this suggests a mis-use of the",
            "         method.",
            "",
            "",
            "        .. seealso::",
            "",
            "            :func:`.make_transient_to_detached` - provides for an alternative",
            "            means of \"merging\" a single object into the :class:`.Session`",
            "",
            "        \"\"\"",
            "",
            "        if self._warn_on_events:",
            "            self._flush_warning(\"Session.merge()\")",
            "",
            "        _recursive = {}",
            "        _resolve_conflict_map = {}",
            "",
            "        if load:",
            "            # flush current contents if we expect to load data",
            "            self._autoflush()",
            "",
            "        object_mapper(instance)  # verify mapped",
            "        autoflush = self.autoflush",
            "        try:",
            "            self.autoflush = False",
            "            return self._merge(",
            "                attributes.instance_state(instance),",
            "                attributes.instance_dict(instance),",
            "                load=load,",
            "                _recursive=_recursive,",
            "                _resolve_conflict_map=_resolve_conflict_map,",
            "            )",
            "        finally:",
            "            self.autoflush = autoflush",
            "",
            "    def _merge(",
            "        self,",
            "        state,",
            "        state_dict,",
            "        load=True,",
            "        _recursive=None,",
            "        _resolve_conflict_map=None,",
            "    ):",
            "        mapper = _state_mapper(state)",
            "        if state in _recursive:",
            "            return _recursive[state]",
            "",
            "        new_instance = False",
            "        key = state.key",
            "",
            "        if key is None:",
            "            if not load:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"merge() with load=False option does not support \"",
            "                    \"objects transient (i.e. unpersisted) objects.  flush() \"",
            "                    \"all changes on mapped instances before merging with \"",
            "                    \"load=False.\"",
            "                )",
            "            key = mapper._identity_key_from_state(state)",
            "            key_is_persistent = attributes.NEVER_SET not in key[1] and (",
            "                not _none_set.intersection(key[1])",
            "                or (",
            "                    mapper.allow_partial_pks",
            "                    and not _none_set.issuperset(key[1])",
            "                )",
            "            )",
            "        else:",
            "            key_is_persistent = True",
            "",
            "        if key in self.identity_map:",
            "            try:",
            "                merged = self.identity_map[key]",
            "            except KeyError:",
            "                # object was GC'ed right as we checked for it",
            "                merged = None",
            "        else:",
            "            merged = None",
            "",
            "        if merged is None:",
            "            if key_is_persistent and key in _resolve_conflict_map:",
            "                merged = _resolve_conflict_map[key]",
            "",
            "            elif not load:",
            "                if state.modified:",
            "                    raise sa_exc.InvalidRequestError(",
            "                        \"merge() with load=False option does not support \"",
            "                        \"objects marked as 'dirty'.  flush() all changes on \"",
            "                        \"mapped instances before merging with load=False.\"",
            "                    )",
            "                merged = mapper.class_manager.new_instance()",
            "                merged_state = attributes.instance_state(merged)",
            "                merged_state.key = key",
            "                self._update_impl(merged_state)",
            "                new_instance = True",
            "",
            "            elif key_is_persistent:",
            "                merged = self.query(mapper.class_).get(key[1])",
            "",
            "        if merged is None:",
            "            merged = mapper.class_manager.new_instance()",
            "            merged_state = attributes.instance_state(merged)",
            "            merged_dict = attributes.instance_dict(merged)",
            "            new_instance = True",
            "            self._save_or_update_state(merged_state)",
            "        else:",
            "            merged_state = attributes.instance_state(merged)",
            "            merged_dict = attributes.instance_dict(merged)",
            "",
            "        _recursive[state] = merged",
            "        _resolve_conflict_map[key] = merged",
            "",
            "        # check that we didn't just pull the exact same",
            "        # state out.",
            "        if state is not merged_state:",
            "            # version check if applicable",
            "            if mapper.version_id_col is not None:",
            "                existing_version = mapper._get_state_attr_by_column(",
            "                    state,",
            "                    state_dict,",
            "                    mapper.version_id_col,",
            "                    passive=attributes.PASSIVE_NO_INITIALIZE,",
            "                )",
            "",
            "                merged_version = mapper._get_state_attr_by_column(",
            "                    merged_state,",
            "                    merged_dict,",
            "                    mapper.version_id_col,",
            "                    passive=attributes.PASSIVE_NO_INITIALIZE,",
            "                )",
            "",
            "                if (",
            "                    existing_version is not attributes.PASSIVE_NO_RESULT",
            "                    and merged_version is not attributes.PASSIVE_NO_RESULT",
            "                    and existing_version != merged_version",
            "                ):",
            "                    raise exc.StaleDataError(",
            "                        \"Version id '%s' on merged state %s \"",
            "                        \"does not match existing version '%s'. \"",
            "                        \"Leave the version attribute unset when \"",
            "                        \"merging to update the most recent version.\"",
            "                        % (",
            "                            existing_version,",
            "                            state_str(merged_state),",
            "                            merged_version,",
            "                        )",
            "                    )",
            "",
            "            merged_state.load_path = state.load_path",
            "            merged_state.load_options = state.load_options",
            "",
            "            # since we are copying load_options, we need to copy",
            "            # the callables_ that would have been generated by those",
            "            # load_options.",
            "            # assumes that the callables we put in state.callables_",
            "            # are not instance-specific (which they should not be)",
            "            merged_state._copy_callables(state)",
            "",
            "            for prop in mapper.iterate_properties:",
            "                prop.merge(",
            "                    self,",
            "                    state,",
            "                    state_dict,",
            "                    merged_state,",
            "                    merged_dict,",
            "                    load,",
            "                    _recursive,",
            "                    _resolve_conflict_map,",
            "                )",
            "",
            "        if not load:",
            "            # remove any history",
            "            merged_state._commit_all(merged_dict, self.identity_map)",
            "",
            "        if new_instance:",
            "            merged_state.manager.dispatch.load(merged_state, None)",
            "        return merged",
            "",
            "    def _validate_persistent(self, state):",
            "        if not self.identity_map.contains_state(state):",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance '%s' is not persistent within this Session\"",
            "                % state_str(state)",
            "            )",
            "",
            "    def _save_impl(self, state):",
            "        if state.key is not None:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Object '%s' already has an identity - \"",
            "                \"it can't be registered as pending\" % state_str(state)",
            "            )",
            "",
            "        obj = state.obj()",
            "        to_attach = self._before_attach(state, obj)",
            "        if state not in self._new:",
            "            self._new[state] = obj",
            "            state.insert_order = len(self._new)",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "    def _update_impl(self, state, revert_deletion=False):",
            "        if state.key is None:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Instance '%s' is not persisted\" % state_str(state)",
            "            )",
            "",
            "        if state._deleted:",
            "            if revert_deletion:",
            "                if not state._attached:",
            "                    return",
            "                del state._deleted",
            "            else:",
            "                raise sa_exc.InvalidRequestError(",
            "                    \"Instance '%s' has been deleted.  \"",
            "                    \"Use the make_transient() \"",
            "                    \"function to send this object back \"",
            "                    \"to the transient state.\" % state_str(state)",
            "                )",
            "",
            "        obj = state.obj()",
            "",
            "        # check for late gc",
            "        if obj is None:",
            "            return",
            "",
            "        to_attach = self._before_attach(state, obj)",
            "",
            "        self._deleted.pop(state, None)",
            "        if revert_deletion:",
            "            self.identity_map.replace(state)",
            "        else:",
            "            self.identity_map.add(state)",
            "",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "        elif revert_deletion:",
            "            self.dispatch.deleted_to_persistent(self, obj)",
            "",
            "    def _save_or_update_impl(self, state):",
            "        if state.key is None:",
            "            self._save_impl(state)",
            "        else:",
            "            self._update_impl(state)",
            "",
            "    def enable_relationship_loading(self, obj):",
            "        \"\"\"Associate an object with this :class:`.Session` for related",
            "        object loading.",
            "",
            "        .. warning::",
            "",
            "            :meth:`.enable_relationship_loading` exists to serve special",
            "            use cases and is not recommended for general use.",
            "",
            "        Accesses of attributes mapped with :func:`.relationship`",
            "        will attempt to load a value from the database using this",
            "        :class:`.Session` as the source of connectivity.  The values",
            "        will be loaded based on foreign key and primary key values",
            "        present on this object - if not present, then those relationships",
            "        will be unavailable.",
            "",
            "        The object will be attached to this session, but will",
            "        **not** participate in any persistence operations; its state",
            "        for almost all purposes will remain either \"transient\" or",
            "        \"detached\", except for the case of relationship loading.",
            "",
            "        Also note that backrefs will often not work as expected.",
            "        Altering a relationship-bound attribute on the target object",
            "        may not fire off a backref event, if the effective value",
            "        is what was already loaded from a foreign-key-holding value.",
            "",
            "        The :meth:`.Session.enable_relationship_loading` method is",
            "        similar to the ``load_on_pending`` flag on :func:`.relationship`.",
            "        Unlike that flag, :meth:`.Session.enable_relationship_loading` allows",
            "        an object to remain transient while still being able to load",
            "        related items.",
            "",
            "        To make a transient object associated with a :class:`.Session`",
            "        via :meth:`.Session.enable_relationship_loading` pending, add",
            "        it to the :class:`.Session` using :meth:`.Session.add` normally.",
            "        If the object instead represents an existing identity in the database,",
            "        it should be merged using :meth:`.Session.merge`.",
            "",
            "        :meth:`.Session.enable_relationship_loading` does not improve",
            "        behavior when the ORM is used normally - object references should be",
            "        constructed at the object level, not at the foreign key level, so",
            "        that they are present in an ordinary way before flush()",
            "        proceeds.  This method is not intended for general use.",
            "",
            "        .. seealso::",
            "",
            "            ``load_on_pending`` at :func:`.relationship` - this flag",
            "            allows per-relationship loading of many-to-ones on items that",
            "            are pending.",
            "",
            "            :func:`.make_transient_to_detached` - allows for an object to",
            "            be added to a :class:`.Session` without SQL emitted, which then",
            "            will unexpire attributes on access.",
            "",
            "        \"\"\"",
            "        state = attributes.instance_state(obj)",
            "        to_attach = self._before_attach(state, obj)",
            "        state._load_pending = True",
            "        if to_attach:",
            "            self._after_attach(state, obj)",
            "",
            "    def _before_attach(self, state, obj):",
            "        if state.session_id == self.hash_key:",
            "            return False",
            "",
            "        if state.session_id and state.session_id in _sessions:",
            "            raise sa_exc.InvalidRequestError(",
            "                \"Object '%s' is already attached to session '%s' \"",
            "                \"(this is '%s')\"",
            "                % (state_str(state), state.session_id, self.hash_key)",
            "            )",
            "",
            "        self.dispatch.before_attach(self, obj)",
            "",
            "        return True",
            "",
            "    def _after_attach(self, state, obj):",
            "        state.session_id = self.hash_key",
            "        if state.modified and state._strong_obj is None:",
            "            state._strong_obj = obj",
            "        self.dispatch.after_attach(self, obj)",
            "",
            "        if state.key:",
            "            self.dispatch.detached_to_persistent(self, obj)",
            "        else:",
            "            self.dispatch.transient_to_pending(self, obj)",
            "",
            "    def __contains__(self, instance):",
            "        \"\"\"Return True if the instance is associated with this session.",
            "",
            "        The instance may be pending or persistent within the Session for a",
            "        result of True.",
            "",
            "        \"\"\"",
            "        try:",
            "            state = attributes.instance_state(instance)",
            "        except exc.NO_STATE:",
            "            raise exc.UnmappedInstanceError(instance)",
            "        return self._contains_state(state)",
            "",
            "    def __iter__(self):",
            "        \"\"\"Iterate over all pending or persistent instances within this",
            "        Session.",
            "",
            "        \"\"\"",
            "        return iter(",
            "            list(self._new.values()) + list(self.identity_map.values())",
            "        )",
            "",
            "    def _contains_state(self, state):",
            "        return state in self._new or self.identity_map.contains_state(state)",
            "",
            "    def flush(self, objects=None):",
            "        \"\"\"Flush all the object changes to the database.",
            "",
            "        Writes out all pending object creations, deletions and modifications",
            "        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are",
            "        automatically ordered by the Session's unit of work dependency",
            "        solver.",
            "",
            "        Database operations will be issued in the current transactional",
            "        context and do not affect the state of the transaction, unless an",
            "        error occurs, in which case the entire transaction is rolled back.",
            "        You may flush() as often as you like within a transaction to move",
            "        changes from Python to the database's transaction buffer.",
            "",
            "        For ``autocommit`` Sessions with no active manual transaction, flush()",
            "        will create a transaction on the fly that surrounds the entire set of",
            "        operations into the flush.",
            "",
            "        :param objects: Optional; restricts the flush operation to operate",
            "          only on elements that are in the given collection.",
            "",
            "          This feature is for an extremely narrow set of use cases where",
            "          particular objects may need to be operated upon before the",
            "          full flush() occurs.  It is not intended for general use.",
            "",
            "        \"\"\"",
            "",
            "        if self._flushing:",
            "            raise sa_exc.InvalidRequestError(\"Session is already flushing\")",
            "",
            "        if self._is_clean():",
            "            return",
            "        try:",
            "            self._flushing = True",
            "            self._flush(objects)",
            "        finally:",
            "            self._flushing = False",
            "",
            "    def _flush_warning(self, method):",
            "        util.warn(",
            "            \"Usage of the '%s' operation is not currently supported \"",
            "            \"within the execution stage of the flush process. \"",
            "            \"Results may not be consistent.  Consider using alternative \"",
            "            \"event listeners or connection-level operations instead.\" % method",
            "        )",
            "",
            "    def _is_clean(self):",
            "        return (",
            "            not self.identity_map.check_modified()",
            "            and not self._deleted",
            "            and not self._new",
            "        )",
            "",
            "    def _flush(self, objects=None):",
            "",
            "        dirty = self._dirty_states",
            "        if not dirty and not self._deleted and not self._new:",
            "            self.identity_map._modified.clear()",
            "            return",
            "",
            "        flush_context = UOWTransaction(self)",
            "",
            "        if self.dispatch.before_flush:",
            "            self.dispatch.before_flush(self, flush_context, objects)",
            "            # re-establish \"dirty states\" in case the listeners",
            "            # added",
            "            dirty = self._dirty_states",
            "",
            "        deleted = set(self._deleted)",
            "        new = set(self._new)",
            "",
            "        dirty = set(dirty).difference(deleted)",
            "",
            "        # create the set of all objects we want to operate upon",
            "        if objects:",
            "            # specific list passed in",
            "            objset = set()",
            "            for o in objects:",
            "                try:",
            "                    state = attributes.instance_state(o)",
            "                except exc.NO_STATE:",
            "                    raise exc.UnmappedInstanceError(o)",
            "                objset.add(state)",
            "        else:",
            "            objset = None",
            "",
            "        # store objects whose fate has been decided",
            "        processed = set()",
            "",
            "        # put all saves/updates into the flush context.  detect top-level",
            "        # orphans and throw them into deleted.",
            "        if objset:",
            "            proc = new.union(dirty).intersection(objset).difference(deleted)",
            "        else:",
            "            proc = new.union(dirty).difference(deleted)",
            "",
            "        for state in proc:",
            "            is_orphan = _state_mapper(state)._is_orphan(state)",
            "",
            "            is_persistent_orphan = is_orphan and state.has_identity",
            "",
            "            if (",
            "                is_orphan",
            "                and not is_persistent_orphan",
            "                and state._orphaned_outside_of_session",
            "            ):",
            "                self._expunge_states([state])",
            "            else:",
            "                _reg = flush_context.register_object(",
            "                    state, isdelete=is_persistent_orphan",
            "                )",
            "                assert _reg, \"Failed to add object to the flush context!\"",
            "                processed.add(state)",
            "",
            "        # put all remaining deletes into the flush context.",
            "        if objset:",
            "            proc = deleted.intersection(objset).difference(processed)",
            "        else:",
            "            proc = deleted.difference(processed)",
            "        for state in proc:",
            "            _reg = flush_context.register_object(state, isdelete=True)",
            "            assert _reg, \"Failed to add object to the flush context!\"",
            "",
            "        if not flush_context.has_work:",
            "            return",
            "",
            "        flush_context.transaction = transaction = self.begin(",
            "            subtransactions=True",
            "        )",
            "        try:",
            "            self._warn_on_events = True",
            "            try:",
            "                flush_context.execute()",
            "            finally:",
            "                self._warn_on_events = False",
            "",
            "            self.dispatch.after_flush(self, flush_context)",
            "",
            "            flush_context.finalize_flush_changes()",
            "",
            "            if not objects and self.identity_map._modified:",
            "                len_ = len(self.identity_map._modified)",
            "",
            "                statelib.InstanceState._commit_all_states(",
            "                    [",
            "                        (state, state.dict)",
            "                        for state in self.identity_map._modified",
            "                    ],",
            "                    instance_dict=self.identity_map,",
            "                )",
            "                util.warn(",
            "                    \"Attribute history events accumulated on %d \"",
            "                    \"previously clean instances \"",
            "                    \"within inner-flush event handlers have been \"",
            "                    \"reset, and will not result in database updates. \"",
            "                    \"Consider using set_committed_value() within \"",
            "                    \"inner-flush event handlers to avoid this warning.\" % len_",
            "                )",
            "",
            "            # useful assertions:",
            "            # if not objects:",
            "            #    assert not self.identity_map._modified",
            "            # else:",
            "            #    assert self.identity_map._modified == \\",
            "            #            self.identity_map._modified.difference(objects)",
            "",
            "            self.dispatch.after_flush_postexec(self, flush_context)",
            "",
            "            transaction.commit()",
            "",
            "        except:",
            "            with util.safe_reraise():",
            "                transaction.rollback(_capture_exception=True)",
            "",
            "    def bulk_save_objects(",
            "        self,",
            "        objects,",
            "        return_defaults=False,",
            "        update_changed_only=True,",
            "        preserve_order=True,",
            "    ):",
            "        \"\"\"Perform a bulk save of the given list of objects.",
            "",
            "        The bulk save feature allows mapped objects to be used as the",
            "        source of simple INSERT and UPDATE operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations; the extraction of data from the objects is also performed",
            "        using a lower-latency process that ignores whether or not attributes",
            "        have actually been modified in the case of UPDATEs, and also ignores",
            "        SQL expressions.",
            "",
            "        The objects as given are not added to the session and no additional",
            "        state is established on them, unless the ``return_defaults`` flag",
            "        is also set, in which case primary key attributes and server-side",
            "        default values will be populated.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk save feature allows for a lower-latency INSERT/UPDATE",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            INSERT/UPDATES of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param objects: a list of mapped object instances.  The mapped",
            "         objects are persisted as is, and are **not** associated with the",
            "         :class:`.Session` afterwards.",
            "",
            "         For each object, whether the object is sent as an INSERT or an",
            "         UPDATE is dependent on the same rules used by the :class:`.Session`",
            "         in traditional operation; if the object has the",
            "         :attr:`.InstanceState.key`",
            "         attribute set, then the object is assumed to be \"detached\" and",
            "         will result in an UPDATE.  Otherwise, an INSERT is used.",
            "",
            "         In the case of an UPDATE, statements are grouped based on which",
            "         attributes have changed, and are thus to be the subject of each",
            "         SET clause.  If ``update_changed_only`` is False, then all",
            "         attributes present within each object are applied to the UPDATE",
            "         statement, which may help in allowing the statements to be grouped",
            "         together into a larger executemany(), and will also reduce the",
            "         overhead of checking history on attributes.",
            "",
            "        :param return_defaults: when True, rows that are missing values which",
            "         generate defaults, namely integer primary key defaults and sequences,",
            "         will be inserted **one at a time**, so that the primary key value",
            "         is available.  In particular this will allow joined-inheritance",
            "         and other multi-table mappings to insert correctly without the need",
            "         to provide primary key values ahead of time; however,",
            "         :paramref:`.Session.bulk_save_objects.return_defaults` **greatly",
            "         reduces the performance gains** of the method overall.",
            "",
            "        :param update_changed_only: when True, UPDATE statements are rendered",
            "         based on those attributes in each state that have logged changes.",
            "         When False, all attributes present are rendered into the SET clause",
            "         with the exception of primary key attributes.",
            "",
            "        :param preserve_order: when True, the order of inserts and updates",
            "         matches exactly the order in which the objects are given.   When",
            "         False, common types of objects are grouped into inserts",
            "         and updates, to allow for more batching opportunities.",
            "",
            "         .. versionadded:: 1.3",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_insert_mappings`",
            "",
            "            :meth:`.Session.bulk_update_mappings`",
            "",
            "        \"\"\"",
            "",
            "        def key(state):",
            "            return (state.mapper, state.key is not None)",
            "",
            "        obj_states = tuple(attributes.instance_state(obj) for obj in objects)",
            "        if not preserve_order:",
            "            obj_states = sorted(obj_states, key=key)",
            "",
            "        for (mapper, isupdate), states in itertools.groupby(obj_states, key):",
            "            self._bulk_save_mappings(",
            "                mapper,",
            "                states,",
            "                isupdate,",
            "                True,",
            "                return_defaults,",
            "                update_changed_only,",
            "                False,",
            "            )",
            "",
            "    def bulk_insert_mappings(",
            "        self, mapper, mappings, return_defaults=False, render_nulls=False",
            "    ):",
            "        \"\"\"Perform a bulk insert of the given list of mapping dictionaries.",
            "",
            "        The bulk insert feature allows plain Python dictionaries to be used as",
            "        the source of simple INSERT operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations.  Using dictionaries, there is no \"history\" or session",
            "        state management features in use, reducing latency when inserting",
            "        large numbers of simple rows.",
            "",
            "        The values within the dictionaries as given are typically passed",
            "        without modification into Core :meth:`.Insert` constructs, after",
            "        organizing the values within them across the tables to which",
            "        the given mapper is mapped.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk insert feature allows for a lower-latency INSERT",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            INSERT of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param mapper: a mapped class, or the actual :class:`.Mapper` object,",
            "         representing the single kind of object represented within the mapping",
            "         list.",
            "",
            "        :param mappings: a list of dictionaries, each one containing the state",
            "         of the mapped row to be inserted, in terms of the attribute names",
            "         on the mapped class.   If the mapping refers to multiple tables,",
            "         such as a joined-inheritance mapping, each dictionary must contain",
            "         all keys to be populated into all tables.",
            "",
            "        :param return_defaults: when True, rows that are missing values which",
            "         generate defaults, namely integer primary key defaults and sequences,",
            "         will be inserted **one at a time**, so that the primary key value",
            "         is available.  In particular this will allow joined-inheritance",
            "         and other multi-table mappings to insert correctly without the need",
            "         to provide primary",
            "         key values ahead of time; however,",
            "         :paramref:`.Session.bulk_insert_mappings.return_defaults`",
            "         **greatly reduces the performance gains** of the method overall.",
            "         If the rows",
            "         to be inserted only refer to a single table, then there is no",
            "         reason this flag should be set as the returned default information",
            "         is not used.",
            "",
            "        :param render_nulls: When True, a value of ``None`` will result",
            "         in a NULL value being included in the INSERT statement, rather",
            "         than the column being omitted from the INSERT.   This allows all",
            "         the rows being INSERTed to have the identical set of columns which",
            "         allows the full set of rows to be batched to the DBAPI.  Normally,",
            "         each column-set that contains a different combination of NULL values",
            "         than the previous row must omit a different series of columns from",
            "         the rendered INSERT statement, which means it must be emitted as a",
            "         separate statement.   By passing this flag, the full set of rows",
            "         are guaranteed to be batchable into one batch; the cost however is",
            "         that server-side defaults which are invoked by an omitted column will",
            "         be skipped, so care must be taken to ensure that these are not",
            "         necessary.",
            "",
            "         .. warning::",
            "",
            "            When this flag is set, **server side default SQL values will",
            "            not be invoked** for those columns that are inserted as NULL;",
            "            the NULL value will be sent explicitly.   Care must be taken",
            "            to ensure that no server-side default functions need to be",
            "            invoked for the operation as a whole.",
            "",
            "         .. versionadded:: 1.1",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_save_objects`",
            "",
            "            :meth:`.Session.bulk_update_mappings`",
            "",
            "        \"\"\"",
            "        self._bulk_save_mappings(",
            "            mapper,",
            "            mappings,",
            "            False,",
            "            False,",
            "            return_defaults,",
            "            False,",
            "            render_nulls,",
            "        )",
            "",
            "    def bulk_update_mappings(self, mapper, mappings):",
            "        \"\"\"Perform a bulk update of the given list of mapping dictionaries.",
            "",
            "        The bulk update feature allows plain Python dictionaries to be used as",
            "        the source of simple UPDATE operations which can be more easily",
            "        grouped together into higher performing \"executemany\"",
            "        operations.  Using dictionaries, there is no \"history\" or session",
            "        state management features in use, reducing latency when updating",
            "        large numbers of simple rows.",
            "",
            "        .. versionadded:: 1.0.0",
            "",
            "        .. warning::",
            "",
            "            The bulk update feature allows for a lower-latency UPDATE",
            "            of rows at the expense of most other unit-of-work features.",
            "            Features such as object management, relationship handling,",
            "            and SQL clause support are **silently omitted** in favor of raw",
            "            UPDATES of records.",
            "",
            "            **Please read the list of caveats at** :ref:`bulk_operations`",
            "            **before using this method, and fully test and confirm the",
            "            functionality of all code developed using these systems.**",
            "",
            "        :param mapper: a mapped class, or the actual :class:`.Mapper` object,",
            "         representing the single kind of object represented within the mapping",
            "         list.",
            "",
            "        :param mappings: a list of dictionaries, each one containing the state",
            "         of the mapped row to be updated, in terms of the attribute names",
            "         on the mapped class.   If the mapping refers to multiple tables,",
            "         such as a joined-inheritance mapping, each dictionary may contain",
            "         keys corresponding to all tables.   All those keys which are present",
            "         and are not part of the primary key are applied to the SET clause",
            "         of the UPDATE statement; the primary key values, which are required,",
            "         are applied to the WHERE clause.",
            "",
            "",
            "        .. seealso::",
            "",
            "            :ref:`bulk_operations`",
            "",
            "            :meth:`.Session.bulk_insert_mappings`",
            "",
            "            :meth:`.Session.bulk_save_objects`",
            "",
            "        \"\"\"",
            "        self._bulk_save_mappings(",
            "            mapper, mappings, True, False, False, False, False",
            "        )",
            "",
            "    def _bulk_save_mappings(",
            "        self,",
            "        mapper,",
            "        mappings,",
            "        isupdate,",
            "        isstates,",
            "        return_defaults,",
            "        update_changed_only,",
            "        render_nulls,",
            "    ):",
            "        mapper = _class_to_mapper(mapper)",
            "        self._flushing = True",
            "",
            "        transaction = self.begin(subtransactions=True)",
            "        try:",
            "            if isupdate:",
            "                persistence._bulk_update(",
            "                    mapper,",
            "                    mappings,",
            "                    transaction,",
            "                    isstates,",
            "                    update_changed_only,",
            "                )",
            "            else:",
            "                persistence._bulk_insert(",
            "                    mapper,",
            "                    mappings,",
            "                    transaction,",
            "                    isstates,",
            "                    return_defaults,",
            "                    render_nulls,",
            "                )",
            "            transaction.commit()",
            "",
            "        except:",
            "            with util.safe_reraise():",
            "                transaction.rollback(_capture_exception=True)",
            "        finally:",
            "            self._flushing = False",
            "",
            "    @util.deprecated_params(",
            "        passive=(",
            "            \"0.8\",",
            "            \"The :paramref:`.Session.is_modified.passive` flag is deprecated \"",
            "            \"and will be removed in a future release.  The flag is no longer \"",
            "            \"used and is ignored.\",",
            "        )",
            "    )",
            "    def is_modified(self, instance, include_collections=True, passive=None):",
            "        r\"\"\"Return ``True`` if the given instance has locally",
            "        modified attributes.",
            "",
            "        This method retrieves the history for each instrumented",
            "        attribute on the instance and performs a comparison of the current",
            "        value to its previously committed value, if any.",
            "",
            "        It is in effect a more expensive and accurate",
            "        version of checking for the given instance in the",
            "        :attr:`.Session.dirty` collection; a full test for",
            "        each attribute's net \"dirty\" status is performed.",
            "",
            "        E.g.::",
            "",
            "            return session.is_modified(someobject)",
            "",
            "        A few caveats to this method apply:",
            "",
            "        * Instances present in the :attr:`.Session.dirty` collection may",
            "          report ``False`` when tested with this method.  This is because",
            "          the object may have received change events via attribute mutation,",
            "          thus placing it in :attr:`.Session.dirty`, but ultimately the state",
            "          is the same as that loaded from the database, resulting in no net",
            "          change here.",
            "        * Scalar attributes may not have recorded the previously set",
            "          value when a new value was applied, if the attribute was not loaded,",
            "          or was expired, at the time the new value was received - in these",
            "          cases, the attribute is assumed to have a change, even if there is",
            "          ultimately no net change against its database value. SQLAlchemy in",
            "          most cases does not need the \"old\" value when a set event occurs, so",
            "          it skips the expense of a SQL call if the old value isn't present,",
            "          based on the assumption that an UPDATE of the scalar value is",
            "          usually needed, and in those few cases where it isn't, is less",
            "          expensive on average than issuing a defensive SELECT.",
            "",
            "          The \"old\" value is fetched unconditionally upon set only if the",
            "          attribute container has the ``active_history`` flag set to ``True``.",
            "          This flag is set typically for primary key attributes and scalar",
            "          object references that are not a simple many-to-one.  To set this",
            "          flag for any arbitrary mapped column, use the ``active_history``",
            "          argument with :func:`.column_property`.",
            "",
            "        :param instance: mapped instance to be tested for pending changes.",
            "        :param include_collections: Indicates if multivalued collections",
            "         should be included in the operation.  Setting this to ``False`` is a",
            "         way to detect only local-column based properties (i.e. scalar columns",
            "         or many-to-one foreign keys) that would result in an UPDATE for this",
            "         instance upon flush.",
            "        :param passive: not used",
            "",
            "        \"\"\"",
            "        state = object_state(instance)",
            "",
            "        if not state.modified:",
            "            return False",
            "",
            "        dict_ = state.dict",
            "",
            "        for attr in state.manager.attributes:",
            "            if (",
            "                not include_collections",
            "                and hasattr(attr.impl, \"get_collection\")",
            "            ) or not hasattr(attr.impl, \"get_history\"):",
            "                continue",
            "",
            "            (added, unchanged, deleted) = attr.impl.get_history(",
            "                state, dict_, passive=attributes.NO_CHANGE",
            "            )",
            "",
            "            if added or deleted:",
            "                return True",
            "        else:",
            "            return False",
            "",
            "    @property",
            "    def is_active(self):",
            "        \"\"\"True if this :class:`.Session` is in \"transaction mode\" and",
            "        is not in \"partial rollback\" state.",
            "",
            "        The :class:`.Session` in its default mode of ``autocommit=False``",
            "        is essentially always in \"transaction mode\", in that a",
            "        :class:`.SessionTransaction` is associated with it as soon as",
            "        it is instantiated.  This :class:`.SessionTransaction` is immediately",
            "        replaced with a new one as soon as it is ended, due to a rollback,",
            "        commit, or close operation.",
            "",
            "        \"Transaction mode\" does *not* indicate whether",
            "        or not actual database connection resources are in use;  the",
            "        :class:`.SessionTransaction` object coordinates among zero or more",
            "        actual database transactions, and starts out with none, accumulating",
            "        individual DBAPI connections as different data sources are used",
            "        within its scope.   The best way to track when a particular",
            "        :class:`.Session` has actually begun to use DBAPI resources is to",
            "        implement a listener using the :meth:`.SessionEvents.after_begin`",
            "        method, which will deliver both the :class:`.Session` as well as the",
            "        target :class:`.Connection` to a user-defined event listener.",
            "",
            "        The \"partial rollback\" state refers to when an \"inner\" transaction,",
            "        typically used during a flush, encounters an error and emits a",
            "        rollback of the DBAPI connection.  At this point, the",
            "        :class:`.Session` is in \"partial rollback\" and awaits for the user to",
            "        call :meth:`.Session.rollback`, in order to close out the",
            "        transaction stack.  It is in this \"partial rollback\" period that the",
            "        :attr:`.is_active` flag returns False.  After the call to",
            "        :meth:`.Session.rollback`, the :class:`.SessionTransaction` is",
            "        replaced with a new one and :attr:`.is_active` returns ``True`` again.",
            "",
            "        When a :class:`.Session` is used in ``autocommit=True`` mode, the",
            "        :class:`.SessionTransaction` is only instantiated within the scope",
            "        of a flush call, or when :meth:`.Session.begin` is called.  So",
            "        :attr:`.is_active` will always be ``False`` outside of a flush or",
            "        :meth:`.Session.begin` block in this mode, and will be ``True``",
            "        within the :meth:`.Session.begin` block as long as it doesn't enter",
            "        \"partial rollback\" state.",
            "",
            "        From all the above, it follows that the only purpose to this flag is",
            "        for application frameworks that wish to detect is a \"rollback\" is",
            "        necessary within a generic error handling routine, for",
            "        :class:`.Session` objects that would otherwise be in",
            "        \"partial rollback\" mode.  In a typical integration case, this is also",
            "        not necessary as it is standard practice to emit",
            "        :meth:`.Session.rollback` unconditionally within the outermost",
            "        exception catch.",
            "",
            "        To track the transactional state of a :class:`.Session` fully,",
            "        use event listeners, primarily the :meth:`.SessionEvents.after_begin`,",
            "        :meth:`.SessionEvents.after_commit`,",
            "        :meth:`.SessionEvents.after_rollback` and related events.",
            "",
            "        \"\"\"",
            "        return self.transaction and self.transaction.is_active",
            "",
            "    identity_map = None",
            "    \"\"\"A mapping of object identities to objects themselves.",
            "",
            "    Iterating through ``Session.identity_map.values()`` provides",
            "    access to the full set of persistent objects (i.e., those",
            "    that have row identity) currently in the session.",
            "",
            "    .. seealso::",
            "",
            "        :func:`.identity_key` - helper function to produce the keys used",
            "        in this dictionary.",
            "",
            "    \"\"\"",
            "",
            "    @property",
            "    def _dirty_states(self):",
            "        \"\"\"The set of all persistent states considered dirty.",
            "",
            "        This method returns all states that were modified including",
            "        those that were possibly deleted.",
            "",
            "        \"\"\"",
            "        return self.identity_map._dirty_states()",
            "",
            "    @property",
            "    def dirty(self):",
            "        \"\"\"The set of all persistent instances considered dirty.",
            "",
            "        E.g.::",
            "",
            "            some_mapped_object in session.dirty",
            "",
            "        Instances are considered dirty when they were modified but not",
            "        deleted.",
            "",
            "        Note that this 'dirty' calculation is 'optimistic'; most",
            "        attribute-setting or collection modification operations will",
            "        mark an instance as 'dirty' and place it in this set, even if",
            "        there is no net change to the attribute's value.  At flush",
            "        time, the value of each attribute is compared to its",
            "        previously saved value, and if there's no net change, no SQL",
            "        operation will occur (this is a more expensive operation so",
            "        it's only done at flush time).",
            "",
            "        To check if an instance has actionable net changes to its",
            "        attributes, use the :meth:`.Session.is_modified` method.",
            "",
            "        \"\"\"",
            "        return util.IdentitySet(",
            "            [",
            "                state.obj()",
            "                for state in self._dirty_states",
            "                if state not in self._deleted",
            "            ]",
            "        )",
            "",
            "    @property",
            "    def deleted(self):",
            "        \"The set of all instances marked as 'deleted' within this ``Session``\"",
            "",
            "        return util.IdentitySet(list(self._deleted.values()))",
            "",
            "    @property",
            "    def new(self):",
            "        \"The set of all instances marked as 'new' within this ``Session``.\"",
            "",
            "        return util.IdentitySet(list(self._new.values()))",
            "",
            "",
            "class sessionmaker(_SessionClassMethods):",
            "    \"\"\"A configurable :class:`.Session` factory.",
            "",
            "    The :class:`.sessionmaker` factory generates new",
            "    :class:`.Session` objects when called, creating them given",
            "    the configurational arguments established here.",
            "",
            "    e.g.::",
            "",
            "        # global scope",
            "        Session = sessionmaker(autoflush=False)",
            "",
            "        # later, in a local scope, create and use a session:",
            "        sess = Session()",
            "",
            "    Any keyword arguments sent to the constructor itself will override the",
            "    \"configured\" keywords::",
            "",
            "        Session = sessionmaker()",
            "",
            "        # bind an individual session to a connection",
            "        sess = Session(bind=connection)",
            "",
            "    The class also includes a method :meth:`.configure`, which can",
            "    be used to specify additional keyword arguments to the factory, which",
            "    will take effect for subsequent :class:`.Session` objects generated.",
            "    This is usually used to associate one or more :class:`.Engine` objects",
            "    with an existing :class:`.sessionmaker` factory before it is first",
            "    used::",
            "",
            "        # application starts",
            "        Session = sessionmaker()",
            "",
            "        # ... later",
            "        engine = create_engine('sqlite:///foo.db')",
            "        Session.configure(bind=engine)",
            "",
            "        sess = Session()",
            "",
            "    .. seealso:",
            "",
            "        :ref:`session_getting` - introductory text on creating",
            "        sessions using :class:`.sessionmaker`.",
            "",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        bind=None,",
            "        class_=Session,",
            "        autoflush=True,",
            "        autocommit=False,",
            "        expire_on_commit=True,",
            "        info=None,",
            "        **kw",
            "    ):",
            "        r\"\"\"Construct a new :class:`.sessionmaker`.",
            "",
            "        All arguments here except for ``class_`` correspond to arguments",
            "        accepted by :class:`.Session` directly.  See the",
            "        :meth:`.Session.__init__` docstring for more details on parameters.",
            "",
            "        :param bind: a :class:`.Engine` or other :class:`.Connectable` with",
            "         which newly created :class:`.Session` objects will be associated.",
            "        :param class_: class to use in order to create new :class:`.Session`",
            "         objects.  Defaults to :class:`.Session`.",
            "        :param autoflush: The autoflush setting to use with newly created",
            "         :class:`.Session` objects.",
            "        :param autocommit: The autocommit setting to use with newly created",
            "         :class:`.Session` objects.",
            "        :param expire_on_commit=True: the expire_on_commit setting to use",
            "         with newly created :class:`.Session` objects.",
            "        :param info: optional dictionary of information that will be available",
            "         via :attr:`.Session.info`.  Note this dictionary is *updated*, not",
            "         replaced, when the ``info`` parameter is specified to the specific",
            "         :class:`.Session` construction operation.",
            "",
            "         .. versionadded:: 0.9.0",
            "",
            "        :param \\**kw: all other keyword arguments are passed to the",
            "         constructor of newly created :class:`.Session` objects.",
            "",
            "        \"\"\"",
            "        kw[\"bind\"] = bind",
            "        kw[\"autoflush\"] = autoflush",
            "        kw[\"autocommit\"] = autocommit",
            "        kw[\"expire_on_commit\"] = expire_on_commit",
            "        if info is not None:",
            "            kw[\"info\"] = info",
            "        self.kw = kw",
            "        # make our own subclass of the given class, so that",
            "        # events can be associated with it specifically.",
            "        self.class_ = type(class_.__name__, (class_,), {})",
            "",
            "    def __call__(self, **local_kw):",
            "        \"\"\"Produce a new :class:`.Session` object using the configuration",
            "        established in this :class:`.sessionmaker`.",
            "",
            "        In Python, the ``__call__`` method is invoked on an object when",
            "        it is \"called\" in the same way as a function::",
            "",
            "            Session = sessionmaker()",
            "            session = Session()  # invokes sessionmaker.__call__()",
            "",
            "        \"\"\"",
            "        for k, v in self.kw.items():",
            "            if k == \"info\" and \"info\" in local_kw:",
            "                d = v.copy()",
            "                d.update(local_kw[\"info\"])",
            "                local_kw[\"info\"] = d",
            "            else:",
            "                local_kw.setdefault(k, v)",
            "        return self.class_(**local_kw)",
            "",
            "    def configure(self, **new_kw):",
            "        \"\"\"(Re)configure the arguments for this sessionmaker.",
            "",
            "        e.g.::",
            "",
            "            Session = sessionmaker()",
            "",
            "            Session.configure(bind=create_engine('sqlite://'))",
            "        \"\"\"",
            "        self.kw.update(new_kw)",
            "",
            "    def __repr__(self):",
            "        return \"%s(class_=%r, %s)\" % (",
            "            self.__class__.__name__,",
            "            self.class_.__name__,",
            "            \", \".join(\"%s=%r\" % (k, v) for k, v in self.kw.items()),",
            "        )",
            "",
            "",
            "def close_all_sessions():",
            "    \"\"\"Close all sessions in memory.",
            "",
            "    This function consults a global registry of all :class:`.Session` objects",
            "    and calls :meth:`.Session.close` on them, which resets them to a clean",
            "    state.",
            "",
            "    This function is not for general use but may be useful for test suites",
            "    within the teardown scheme.",
            "",
            "    .. versionadded:: 1.3",
            "",
            "    \"\"\"",
            "",
            "    for sess in _sessions.values():",
            "        sess.close()",
            "",
            "",
            "def make_transient(instance):",
            "    \"\"\"Alter the state of the given instance so that it is :term:`transient`.",
            "",
            "    .. note::",
            "",
            "        :func:`.make_transient` is a special-case function for",
            "        advanced use cases only.",
            "",
            "    The given mapped instance is assumed to be in the :term:`persistent` or",
            "    :term:`detached` state.   The function will remove its association with any",
            "    :class:`.Session` as well as its :attr:`.InstanceState.identity`. The",
            "    effect is that the object will behave as though it were newly constructed,",
            "    except retaining any attribute / collection values that were loaded at the",
            "    time of the call.   The :attr:`.InstanceState.deleted` flag is also reset",
            "    if this object had been deleted as a result of using",
            "    :meth:`.Session.delete`.",
            "",
            "    .. warning::",
            "",
            "        :func:`.make_transient` does **not** \"unexpire\" or otherwise eagerly",
            "        load ORM-mapped attributes that are not currently loaded at the time",
            "        the function is called.   This includes attributes which:",
            "",
            "        * were expired via :meth:`.Session.expire`",
            "",
            "        * were expired as the natural effect of committing a session",
            "          transaction, e.g. :meth:`.Session.commit`",
            "",
            "        * are normally :term:`lazy loaded` but are not currently loaded",
            "",
            "        * are \"deferred\" via :ref:`deferred` and are not yet loaded",
            "",
            "        * were not present in the query which loaded this object, such as that",
            "          which is common in joined table inheritance and other scenarios.",
            "",
            "        After :func:`.make_transient` is called, unloaded attributes such",
            "        as those above will normally resolve to the value ``None`` when",
            "        accessed, or an empty collection for a collection-oriented attribute.",
            "        As the object is transient and un-associated with any database",
            "        identity, it will no longer retrieve these values.",
            "",
            "    .. seealso::",
            "",
            "        :func:`.make_transient_to_detached`",
            "",
            "    \"\"\"",
            "    state = attributes.instance_state(instance)",
            "    s = _state_session(state)",
            "    if s:",
            "        s._expunge_states([state])",
            "",
            "    # remove expired state",
            "    state.expired_attributes.clear()",
            "",
            "    # remove deferred callables",
            "    if state.callables:",
            "        del state.callables",
            "",
            "    if state.key:",
            "        del state.key",
            "    if state._deleted:",
            "        del state._deleted",
            "",
            "",
            "def make_transient_to_detached(instance):",
            "    \"\"\"Make the given transient instance :term:`detached`.",
            "",
            "    .. note::",
            "",
            "        :func:`.make_transient_to_detached` is a special-case function for",
            "        advanced use cases only.",
            "",
            "    All attribute history on the given instance",
            "    will be reset as though the instance were freshly loaded",
            "    from a query.  Missing attributes will be marked as expired.",
            "    The primary key attributes of the object, which are required, will be made",
            "    into the \"key\" of the instance.",
            "",
            "    The object can then be added to a session, or merged",
            "    possibly with the load=False flag, at which point it will look",
            "    as if it were loaded that way, without emitting SQL.",
            "",
            "    This is a special use case function that differs from a normal",
            "    call to :meth:`.Session.merge` in that a given persistent state",
            "    can be manufactured without any SQL calls.",
            "",
            "    .. versionadded:: 0.9.5",
            "",
            "    .. seealso::",
            "",
            "        :func:`.make_transient`",
            "",
            "        :meth:`.Session.enable_relationship_loading`",
            "",
            "    \"\"\"",
            "    state = attributes.instance_state(instance)",
            "    if state.session_id or state.key:",
            "        raise sa_exc.InvalidRequestError(\"Given object must be transient\")",
            "    state.key = state.mapper._identity_key_from_state(state)",
            "    if state._deleted:",
            "        del state._deleted",
            "    state._commit_all(state.dict)",
            "    state._expire_attributes(state.dict, state.unloaded_expirable)",
            "",
            "",
            "def object_session(instance):",
            "    \"\"\"Return the :class:`.Session` to which the given instance belongs.",
            "",
            "    This is essentially the same as the :attr:`.InstanceState.session`",
            "    accessor.  See that attribute for details.",
            "",
            "    \"\"\"",
            "",
            "    try:",
            "        state = attributes.instance_state(instance)",
            "    except exc.NO_STATE:",
            "        raise exc.UnmappedInstanceError(instance)",
            "    else:",
            "        return _state_session(state)",
            "",
            "",
            "_new_sessionid = util.counter()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1260": [
                "Session",
                "execute"
            ]
        },
        "addLocation": []
    },
    "lib/sqlalchemy/sql/compiler.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 139,
                "PatchRowcode": " )"
            },
            "1": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 140,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 141,
                "PatchRowcode": " LEGAL_CHARACTERS = re.compile(r\"^[A-Z0-9_$]+$\", re.I)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+LEGAL_CHARACTERS_PLUS_SPACE = re.compile(r\"^[A-Z0-9_ $]+$\", re.I)"
            },
            "4": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 143,
                "PatchRowcode": " ILLEGAL_INITIAL_CHARACTERS = {str(x) for x in range(0, 10)}.union([\"$\"])"
            },
            "5": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 144,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+FK_ON_DELETE = re.compile("
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+    r\"^(?:RESTRICT|CASCADE|SET NULL|NO ACTION|SET DEFAULT)$\", re.I"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+)"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+FK_ON_UPDATE = re.compile("
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+    r\"^(?:RESTRICT|CASCADE|SET NULL|NO ACTION|SET DEFAULT)$\", re.I"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+FK_INITIALLY = re.compile(r\"^(?:DEFERRED|IMMEDIATE)$\", re.I)"
            },
            "13": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 152,
                "PatchRowcode": " BIND_PARAMS = re.compile(r\"(?<![:\\w\\$\\x5c]):([\\w\\$]+)(?![:\\w\\$])\", re.UNICODE)"
            },
            "14": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 153,
                "PatchRowcode": " BIND_PARAMS_ESC = re.compile(r\"\\x5c(:[\\w\\$]*)(?![:\\w\\$])\", re.UNICODE)"
            },
            "15": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 758,
                "afterPatchRowNumber": 766,
                "PatchRowcode": "             else:"
            },
            "17": {
                "beforePatchRowNumber": 759,
                "afterPatchRowNumber": 767,
                "PatchRowcode": "                 col = with_cols[element.element]"
            },
            "18": {
                "beforePatchRowNumber": 760,
                "afterPatchRowNumber": 768,
                "PatchRowcode": "         except KeyError:"
            },
            "19": {
                "beforePatchRowNumber": 761,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # treat it like text()"
            },
            "20": {
                "beforePatchRowNumber": 762,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            util.warn_limited("
            },
            "21": {
                "beforePatchRowNumber": 763,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"Can't resolve label reference %r; converting to text()\","
            },
            "22": {
                "beforePatchRowNumber": 764,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                util.ellipses_string(element.element),"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 769,
                "PatchRowcode": "+            elements._no_text_coercion("
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 770,
                "PatchRowcode": "+                element.element,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 771,
                "PatchRowcode": "+                exc.CompileError,"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 772,
                "PatchRowcode": "+                \"Can't resolve label reference for ORDER BY / GROUP BY.\","
            },
            "27": {
                "beforePatchRowNumber": 765,
                "afterPatchRowNumber": 773,
                "PatchRowcode": "             )"
            },
            "28": {
                "beforePatchRowNumber": 766,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return self.process(element._text_clause)"
            },
            "29": {
                "beforePatchRowNumber": 767,
                "afterPatchRowNumber": 774,
                "PatchRowcode": "         else:"
            },
            "30": {
                "beforePatchRowNumber": 768,
                "afterPatchRowNumber": 775,
                "PatchRowcode": "             kwargs[\"render_label_as_label\"] = col"
            },
            "31": {
                "beforePatchRowNumber": 769,
                "afterPatchRowNumber": 776,
                "PatchRowcode": "             return self.process("
            },
            "32": {
                "beforePatchRowNumber": 1076,
                "afterPatchRowNumber": 1083,
                "PatchRowcode": "                 if func._has_args:"
            },
            "33": {
                "beforePatchRowNumber": 1077,
                "afterPatchRowNumber": 1084,
                "PatchRowcode": "                     name += \"%(expr)s\""
            },
            "34": {
                "beforePatchRowNumber": 1078,
                "afterPatchRowNumber": 1085,
                "PatchRowcode": "             else:"
            },
            "35": {
                "beforePatchRowNumber": 1079,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                name = func.name + \"%(expr)s\""
            },
            "36": {
                "beforePatchRowNumber": 1080,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \".\".join(list(func.packagenames) + [name]) % {"
            },
            "37": {
                "beforePatchRowNumber": 1081,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"expr\": self.function_argspec(func, **kwargs)"
            },
            "38": {
                "beforePatchRowNumber": 1082,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            }"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1086,
                "PatchRowcode": "+                name = func.name"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1087,
                "PatchRowcode": "+                name = ("
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1088,
                "PatchRowcode": "+                    self.preparer.quote(name)"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1089,
                "PatchRowcode": "+                    if self.preparer._requires_quotes_illegal_chars(name)"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1090,
                "PatchRowcode": "+                    else name"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1091,
                "PatchRowcode": "+                )"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1092,
                "PatchRowcode": "+                name = name + \"%(expr)s\""
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1093,
                "PatchRowcode": "+            return \".\".join("
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1094,
                "PatchRowcode": "+                ["
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1095,
                "PatchRowcode": "+                    ("
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1096,
                "PatchRowcode": "+                        self.preparer.quote(tok)"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1097,
                "PatchRowcode": "+                        if self.preparer._requires_quotes_illegal_chars(tok)"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1098,
                "PatchRowcode": "+                        else tok"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1099,
                "PatchRowcode": "+                    )"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1100,
                "PatchRowcode": "+                    for tok in func.packagenames"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1101,
                "PatchRowcode": "+                ]"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1102,
                "PatchRowcode": "+                + [name]"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1103,
                "PatchRowcode": "+            ) % {\"expr\": self.function_argspec(func, **kwargs)}"
            },
            "57": {
                "beforePatchRowNumber": 1083,
                "afterPatchRowNumber": 1104,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 1084,
                "afterPatchRowNumber": 1105,
                "PatchRowcode": "     def visit_next_value_func(self, next_value, **kw):"
            },
            "59": {
                "beforePatchRowNumber": 1085,
                "afterPatchRowNumber": 1106,
                "PatchRowcode": "         return self.visit_sequence(next_value.sequence)"
            },
            "60": {
                "beforePatchRowNumber": 3153,
                "afterPatchRowNumber": 3174,
                "PatchRowcode": "     def define_constraint_cascades(self, constraint):"
            },
            "61": {
                "beforePatchRowNumber": 3154,
                "afterPatchRowNumber": 3175,
                "PatchRowcode": "         text = \"\""
            },
            "62": {
                "beforePatchRowNumber": 3155,
                "afterPatchRowNumber": 3176,
                "PatchRowcode": "         if constraint.ondelete is not None:"
            },
            "63": {
                "beforePatchRowNumber": 3156,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            text += \" ON DELETE %s\" % constraint.ondelete"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3177,
                "PatchRowcode": "+            text += \" ON DELETE %s\" % self.preparer.validate_sql_phrase("
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3178,
                "PatchRowcode": "+                constraint.ondelete, FK_ON_DELETE"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3179,
                "PatchRowcode": "+            )"
            },
            "67": {
                "beforePatchRowNumber": 3157,
                "afterPatchRowNumber": 3180,
                "PatchRowcode": "         if constraint.onupdate is not None:"
            },
            "68": {
                "beforePatchRowNumber": 3158,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            text += \" ON UPDATE %s\" % constraint.onupdate"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3181,
                "PatchRowcode": "+            text += \" ON UPDATE %s\" % self.preparer.validate_sql_phrase("
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3182,
                "PatchRowcode": "+                constraint.onupdate, FK_ON_UPDATE"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3183,
                "PatchRowcode": "+            )"
            },
            "72": {
                "beforePatchRowNumber": 3159,
                "afterPatchRowNumber": 3184,
                "PatchRowcode": "         return text"
            },
            "73": {
                "beforePatchRowNumber": 3160,
                "afterPatchRowNumber": 3185,
                "PatchRowcode": " "
            },
            "74": {
                "beforePatchRowNumber": 3161,
                "afterPatchRowNumber": 3186,
                "PatchRowcode": "     def define_constraint_deferrability(self, constraint):"
            },
            "75": {
                "beforePatchRowNumber": 3166,
                "afterPatchRowNumber": 3191,
                "PatchRowcode": "             else:"
            },
            "76": {
                "beforePatchRowNumber": 3167,
                "afterPatchRowNumber": 3192,
                "PatchRowcode": "                 text += \" NOT DEFERRABLE\""
            },
            "77": {
                "beforePatchRowNumber": 3168,
                "afterPatchRowNumber": 3193,
                "PatchRowcode": "         if constraint.initially is not None:"
            },
            "78": {
                "beforePatchRowNumber": 3169,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            text += \" INITIALLY %s\" % constraint.initially"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3194,
                "PatchRowcode": "+            text += \" INITIALLY %s\" % self.preparer.validate_sql_phrase("
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3195,
                "PatchRowcode": "+                constraint.initially, FK_INITIALLY"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3196,
                "PatchRowcode": "+            )"
            },
            "82": {
                "beforePatchRowNumber": 3170,
                "afterPatchRowNumber": 3197,
                "PatchRowcode": "         return text"
            },
            "83": {
                "beforePatchRowNumber": 3171,
                "afterPatchRowNumber": 3198,
                "PatchRowcode": " "
            },
            "84": {
                "beforePatchRowNumber": 3172,
                "afterPatchRowNumber": 3199,
                "PatchRowcode": "     def define_constraint_match(self, constraint):"
            },
            "85": {
                "beforePatchRowNumber": 3416,
                "afterPatchRowNumber": 3443,
                "PatchRowcode": " "
            },
            "86": {
                "beforePatchRowNumber": 3417,
                "afterPatchRowNumber": 3444,
                "PatchRowcode": "         return value.replace(self.escape_to_quote, self.escape_quote)"
            },
            "87": {
                "beforePatchRowNumber": 3418,
                "afterPatchRowNumber": 3445,
                "PatchRowcode": " "
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3446,
                "PatchRowcode": "+    def validate_sql_phrase(self, element, reg):"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3447,
                "PatchRowcode": "+        \"\"\"keyword sequence filter."
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3448,
                "PatchRowcode": "+"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3449,
                "PatchRowcode": "+        a filter for elements that are intended to represent keyword sequences,"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3450,
                "PatchRowcode": "+        such as \"INITIALLY\", \"INTIALLY DEFERRED\", etc.   no special characters"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3451,
                "PatchRowcode": "+        should be present."
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3452,
                "PatchRowcode": "+"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3453,
                "PatchRowcode": "+        .. versionadded:: 1.3"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3454,
                "PatchRowcode": "+"
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3455,
                "PatchRowcode": "+        \"\"\""
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3456,
                "PatchRowcode": "+"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3457,
                "PatchRowcode": "+        if element is not None and not reg.match(element):"
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3458,
                "PatchRowcode": "+            raise exc.CompileError("
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3459,
                "PatchRowcode": "+                \"Unexpected SQL phrase: %r (matching against %r)\""
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3460,
                "PatchRowcode": "+                % (element, reg.pattern)"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3461,
                "PatchRowcode": "+            )"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3462,
                "PatchRowcode": "+        return element"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3463,
                "PatchRowcode": "+"
            },
            "106": {
                "beforePatchRowNumber": 3419,
                "afterPatchRowNumber": 3464,
                "PatchRowcode": "     def quote_identifier(self, value):"
            },
            "107": {
                "beforePatchRowNumber": 3420,
                "afterPatchRowNumber": 3465,
                "PatchRowcode": "         \"\"\"Quote an identifier."
            },
            "108": {
                "beforePatchRowNumber": 3421,
                "afterPatchRowNumber": 3466,
                "PatchRowcode": " "
            },
            "109": {
                "beforePatchRowNumber": 3439,
                "afterPatchRowNumber": 3484,
                "PatchRowcode": "             or (lc_value != value)"
            },
            "110": {
                "beforePatchRowNumber": 3440,
                "afterPatchRowNumber": 3485,
                "PatchRowcode": "         )"
            },
            "111": {
                "beforePatchRowNumber": 3441,
                "afterPatchRowNumber": 3486,
                "PatchRowcode": " "
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3487,
                "PatchRowcode": "+    def _requires_quotes_illegal_chars(self, value):"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3488,
                "PatchRowcode": "+        \"\"\"Return True if the given identifier requires quoting, but"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3489,
                "PatchRowcode": "+        not taking case convention into account.\"\"\""
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3490,
                "PatchRowcode": "+        return not self.legal_characters.match(util.text_type(value))"
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3491,
                "PatchRowcode": "+"
            },
            "117": {
                "beforePatchRowNumber": 3442,
                "afterPatchRowNumber": 3492,
                "PatchRowcode": "     def quote_schema(self, schema, force=None):"
            },
            "118": {
                "beforePatchRowNumber": 3443,
                "afterPatchRowNumber": 3493,
                "PatchRowcode": "         \"\"\"Conditionally quote a schema name."
            },
            "119": {
                "beforePatchRowNumber": 3444,
                "afterPatchRowNumber": 3494,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# sql/compiler.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "\"\"\"Base SQL and DDL compiler implementations.",
            "",
            "Classes provided include:",
            "",
            ":class:`.compiler.SQLCompiler` - renders SQL",
            "strings",
            "",
            ":class:`.compiler.DDLCompiler` - renders DDL",
            "(data definition language) strings",
            "",
            ":class:`.compiler.GenericTypeCompiler` - renders",
            "type specification strings.",
            "",
            "To generate user-defined SQL strings, see",
            ":doc:`/ext/compiler`.",
            "",
            "\"\"\"",
            "",
            "import contextlib",
            "import itertools",
            "import re",
            "",
            "from . import crud",
            "from . import elements",
            "from . import functions",
            "from . import operators",
            "from . import schema",
            "from . import selectable",
            "from . import sqltypes",
            "from . import visitors",
            "from .. import exc",
            "from .. import util",
            "",
            "",
            "RESERVED_WORDS = set(",
            "    [",
            "        \"all\",",
            "        \"analyse\",",
            "        \"analyze\",",
            "        \"and\",",
            "        \"any\",",
            "        \"array\",",
            "        \"as\",",
            "        \"asc\",",
            "        \"asymmetric\",",
            "        \"authorization\",",
            "        \"between\",",
            "        \"binary\",",
            "        \"both\",",
            "        \"case\",",
            "        \"cast\",",
            "        \"check\",",
            "        \"collate\",",
            "        \"column\",",
            "        \"constraint\",",
            "        \"create\",",
            "        \"cross\",",
            "        \"current_date\",",
            "        \"current_role\",",
            "        \"current_time\",",
            "        \"current_timestamp\",",
            "        \"current_user\",",
            "        \"default\",",
            "        \"deferrable\",",
            "        \"desc\",",
            "        \"distinct\",",
            "        \"do\",",
            "        \"else\",",
            "        \"end\",",
            "        \"except\",",
            "        \"false\",",
            "        \"for\",",
            "        \"foreign\",",
            "        \"freeze\",",
            "        \"from\",",
            "        \"full\",",
            "        \"grant\",",
            "        \"group\",",
            "        \"having\",",
            "        \"ilike\",",
            "        \"in\",",
            "        \"initially\",",
            "        \"inner\",",
            "        \"intersect\",",
            "        \"into\",",
            "        \"is\",",
            "        \"isnull\",",
            "        \"join\",",
            "        \"leading\",",
            "        \"left\",",
            "        \"like\",",
            "        \"limit\",",
            "        \"localtime\",",
            "        \"localtimestamp\",",
            "        \"natural\",",
            "        \"new\",",
            "        \"not\",",
            "        \"notnull\",",
            "        \"null\",",
            "        \"off\",",
            "        \"offset\",",
            "        \"old\",",
            "        \"on\",",
            "        \"only\",",
            "        \"or\",",
            "        \"order\",",
            "        \"outer\",",
            "        \"overlaps\",",
            "        \"placing\",",
            "        \"primary\",",
            "        \"references\",",
            "        \"right\",",
            "        \"select\",",
            "        \"session_user\",",
            "        \"set\",",
            "        \"similar\",",
            "        \"some\",",
            "        \"symmetric\",",
            "        \"table\",",
            "        \"then\",",
            "        \"to\",",
            "        \"trailing\",",
            "        \"true\",",
            "        \"union\",",
            "        \"unique\",",
            "        \"user\",",
            "        \"using\",",
            "        \"verbose\",",
            "        \"when\",",
            "        \"where\",",
            "    ]",
            ")",
            "",
            "LEGAL_CHARACTERS = re.compile(r\"^[A-Z0-9_$]+$\", re.I)",
            "ILLEGAL_INITIAL_CHARACTERS = {str(x) for x in range(0, 10)}.union([\"$\"])",
            "",
            "BIND_PARAMS = re.compile(r\"(?<![:\\w\\$\\x5c]):([\\w\\$]+)(?![:\\w\\$])\", re.UNICODE)",
            "BIND_PARAMS_ESC = re.compile(r\"\\x5c(:[\\w\\$]*)(?![:\\w\\$])\", re.UNICODE)",
            "",
            "BIND_TEMPLATES = {",
            "    \"pyformat\": \"%%(%(name)s)s\",",
            "    \"qmark\": \"?\",",
            "    \"format\": \"%%s\",",
            "    \"numeric\": \":[_POSITION]\",",
            "    \"named\": \":%(name)s\",",
            "}",
            "",
            "",
            "OPERATORS = {",
            "    # binary",
            "    operators.and_: \" AND \",",
            "    operators.or_: \" OR \",",
            "    operators.add: \" + \",",
            "    operators.mul: \" * \",",
            "    operators.sub: \" - \",",
            "    operators.div: \" / \",",
            "    operators.mod: \" % \",",
            "    operators.truediv: \" / \",",
            "    operators.neg: \"-\",",
            "    operators.lt: \" < \",",
            "    operators.le: \" <= \",",
            "    operators.ne: \" != \",",
            "    operators.gt: \" > \",",
            "    operators.ge: \" >= \",",
            "    operators.eq: \" = \",",
            "    operators.is_distinct_from: \" IS DISTINCT FROM \",",
            "    operators.isnot_distinct_from: \" IS NOT DISTINCT FROM \",",
            "    operators.concat_op: \" || \",",
            "    operators.match_op: \" MATCH \",",
            "    operators.notmatch_op: \" NOT MATCH \",",
            "    operators.in_op: \" IN \",",
            "    operators.notin_op: \" NOT IN \",",
            "    operators.comma_op: \", \",",
            "    operators.from_: \" FROM \",",
            "    operators.as_: \" AS \",",
            "    operators.is_: \" IS \",",
            "    operators.isnot: \" IS NOT \",",
            "    operators.collate: \" COLLATE \",",
            "    # unary",
            "    operators.exists: \"EXISTS \",",
            "    operators.distinct_op: \"DISTINCT \",",
            "    operators.inv: \"NOT \",",
            "    operators.any_op: \"ANY \",",
            "    operators.all_op: \"ALL \",",
            "    # modifiers",
            "    operators.desc_op: \" DESC\",",
            "    operators.asc_op: \" ASC\",",
            "    operators.nullsfirst_op: \" NULLS FIRST\",",
            "    operators.nullslast_op: \" NULLS LAST\",",
            "}",
            "",
            "FUNCTIONS = {",
            "    functions.coalesce: \"coalesce\",",
            "    functions.current_date: \"CURRENT_DATE\",",
            "    functions.current_time: \"CURRENT_TIME\",",
            "    functions.current_timestamp: \"CURRENT_TIMESTAMP\",",
            "    functions.current_user: \"CURRENT_USER\",",
            "    functions.localtime: \"LOCALTIME\",",
            "    functions.localtimestamp: \"LOCALTIMESTAMP\",",
            "    functions.random: \"random\",",
            "    functions.sysdate: \"sysdate\",",
            "    functions.session_user: \"SESSION_USER\",",
            "    functions.user: \"USER\",",
            "    functions.cube: \"CUBE\",",
            "    functions.rollup: \"ROLLUP\",",
            "    functions.grouping_sets: \"GROUPING SETS\",",
            "}",
            "",
            "EXTRACT_MAP = {",
            "    \"month\": \"month\",",
            "    \"day\": \"day\",",
            "    \"year\": \"year\",",
            "    \"second\": \"second\",",
            "    \"hour\": \"hour\",",
            "    \"doy\": \"doy\",",
            "    \"minute\": \"minute\",",
            "    \"quarter\": \"quarter\",",
            "    \"dow\": \"dow\",",
            "    \"week\": \"week\",",
            "    \"epoch\": \"epoch\",",
            "    \"milliseconds\": \"milliseconds\",",
            "    \"microseconds\": \"microseconds\",",
            "    \"timezone_hour\": \"timezone_hour\",",
            "    \"timezone_minute\": \"timezone_minute\",",
            "}",
            "",
            "COMPOUND_KEYWORDS = {",
            "    selectable.CompoundSelect.UNION: \"UNION\",",
            "    selectable.CompoundSelect.UNION_ALL: \"UNION ALL\",",
            "    selectable.CompoundSelect.EXCEPT: \"EXCEPT\",",
            "    selectable.CompoundSelect.EXCEPT_ALL: \"EXCEPT ALL\",",
            "    selectable.CompoundSelect.INTERSECT: \"INTERSECT\",",
            "    selectable.CompoundSelect.INTERSECT_ALL: \"INTERSECT ALL\",",
            "}",
            "",
            "",
            "class Compiled(object):",
            "",
            "    \"\"\"Represent a compiled SQL or DDL expression.",
            "",
            "    The ``__str__`` method of the ``Compiled`` object should produce",
            "    the actual text of the statement.  ``Compiled`` objects are",
            "    specific to their underlying database dialect, and also may",
            "    or may not be specific to the columns referenced within a",
            "    particular set of bind parameters.  In no case should the",
            "    ``Compiled`` object be dependent on the actual values of those",
            "    bind parameters, even though it may reference those values as",
            "    defaults.",
            "    \"\"\"",
            "",
            "    _cached_metadata = None",
            "",
            "    execution_options = util.immutabledict()",
            "    \"\"\"",
            "    Execution options propagated from the statement.   In some cases,",
            "    sub-elements of the statement can modify these.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        dialect,",
            "        statement,",
            "        bind=None,",
            "        schema_translate_map=None,",
            "        compile_kwargs=util.immutabledict(),",
            "    ):",
            "        \"\"\"Construct a new :class:`.Compiled` object.",
            "",
            "        :param dialect: :class:`.Dialect` to compile against.",
            "",
            "        :param statement: :class:`.ClauseElement` to be compiled.",
            "",
            "        :param bind: Optional Engine or Connection to compile this",
            "          statement against.",
            "",
            "        :param schema_translate_map: dictionary of schema names to be",
            "         translated when forming the resultant SQL",
            "",
            "         .. versionadded:: 1.1",
            "",
            "         .. seealso::",
            "",
            "            :ref:`schema_translating`",
            "",
            "        :param compile_kwargs: additional kwargs that will be",
            "         passed to the initial call to :meth:`.Compiled.process`.",
            "",
            "",
            "        \"\"\"",
            "",
            "        self.dialect = dialect",
            "        self.bind = bind",
            "        self.preparer = self.dialect.identifier_preparer",
            "        if schema_translate_map:",
            "            self.preparer = self.preparer._with_schema_translate(",
            "                schema_translate_map",
            "            )",
            "",
            "        if statement is not None:",
            "            self.statement = statement",
            "            self.can_execute = statement.supports_execution",
            "            if self.can_execute:",
            "                self.execution_options = statement._execution_options",
            "            self.string = self.process(self.statement, **compile_kwargs)",
            "",
            "    @util.deprecated(",
            "        \"0.7\",",
            "        \"The :meth:`.Compiled.compile` method is deprecated and will be \"",
            "        \"removed in a future release.   The :class:`.Compiled` object \"",
            "        \"now runs its compilation within the constructor, and this method \"",
            "        \"does nothing.\",",
            "    )",
            "    def compile(self):",
            "        \"\"\"Produce the internal string representation of this element.",
            "        \"\"\"",
            "        pass",
            "",
            "    def _execute_on_connection(self, connection, multiparams, params):",
            "        if self.can_execute:",
            "            return connection._execute_compiled(self, multiparams, params)",
            "        else:",
            "            raise exc.ObjectNotExecutableError(self.statement)",
            "",
            "    @property",
            "    def sql_compiler(self):",
            "        \"\"\"Return a Compiled that is capable of processing SQL expressions.",
            "",
            "        If this compiler is one, it would likely just return 'self'.",
            "",
            "        \"\"\"",
            "",
            "        raise NotImplementedError()",
            "",
            "    def process(self, obj, **kwargs):",
            "        return obj._compiler_dispatch(self, **kwargs)",
            "",
            "    def __str__(self):",
            "        \"\"\"Return the string text of the generated SQL or DDL.\"\"\"",
            "",
            "        return self.string or \"\"",
            "",
            "    def construct_params(self, params=None):",
            "        \"\"\"Return the bind params for this compiled object.",
            "",
            "        :param params: a dict of string/object pairs whose values will",
            "                       override bind values compiled in to the",
            "                       statement.",
            "        \"\"\"",
            "",
            "        raise NotImplementedError()",
            "",
            "    @property",
            "    def params(self):",
            "        \"\"\"Return the bind params for this compiled object.\"\"\"",
            "        return self.construct_params()",
            "",
            "    def execute(self, *multiparams, **params):",
            "        \"\"\"Execute this compiled object.\"\"\"",
            "",
            "        e = self.bind",
            "        if e is None:",
            "            raise exc.UnboundExecutionError(",
            "                \"This Compiled object is not bound to any Engine \"",
            "                \"or Connection.\",",
            "                code=\"2afi\",",
            "            )",
            "        return e._execute_compiled(self, multiparams, params)",
            "",
            "    def scalar(self, *multiparams, **params):",
            "        \"\"\"Execute this compiled object and return the result's",
            "        scalar value.\"\"\"",
            "",
            "        return self.execute(*multiparams, **params).scalar()",
            "",
            "",
            "class TypeCompiler(util.with_metaclass(util.EnsureKWArgType, object)):",
            "    \"\"\"Produces DDL specification for TypeEngine objects.\"\"\"",
            "",
            "    ensure_kwarg = r\"visit_\\w+\"",
            "",
            "    def __init__(self, dialect):",
            "        self.dialect = dialect",
            "",
            "    def process(self, type_, **kw):",
            "        return type_._compiler_dispatch(self, **kw)",
            "",
            "",
            "class _CompileLabel(visitors.Visitable):",
            "",
            "    \"\"\"lightweight label object which acts as an expression.Label.\"\"\"",
            "",
            "    __visit_name__ = \"label\"",
            "    __slots__ = \"element\", \"name\"",
            "",
            "    def __init__(self, col, name, alt_names=()):",
            "        self.element = col",
            "        self.name = name",
            "        self._alt_names = (col,) + alt_names",
            "",
            "    @property",
            "    def proxy_set(self):",
            "        return self.element.proxy_set",
            "",
            "    @property",
            "    def type(self):",
            "        return self.element.type",
            "",
            "    def self_group(self, **kw):",
            "        return self",
            "",
            "",
            "class SQLCompiler(Compiled):",
            "    \"\"\"Default implementation of :class:`.Compiled`.",
            "",
            "    Compiles :class:`.ClauseElement` objects into SQL strings.",
            "",
            "    \"\"\"",
            "",
            "    extract_map = EXTRACT_MAP",
            "",
            "    compound_keywords = COMPOUND_KEYWORDS",
            "",
            "    isdelete = isinsert = isupdate = False",
            "    \"\"\"class-level defaults which can be set at the instance",
            "    level to define if this Compiled instance represents",
            "    INSERT/UPDATE/DELETE",
            "    \"\"\"",
            "",
            "    isplaintext = False",
            "",
            "    returning = None",
            "    \"\"\"holds the \"returning\" collection of columns if",
            "    the statement is CRUD and defines returning columns",
            "    either implicitly or explicitly",
            "    \"\"\"",
            "",
            "    returning_precedes_values = False",
            "    \"\"\"set to True classwide to generate RETURNING",
            "    clauses before the VALUES or WHERE clause (i.e. MSSQL)",
            "    \"\"\"",
            "",
            "    render_table_with_column_in_update_from = False",
            "    \"\"\"set to True classwide to indicate the SET clause",
            "    in a multi-table UPDATE statement should qualify",
            "    columns with the table name (i.e. MySQL only)",
            "    \"\"\"",
            "",
            "    contains_expanding_parameters = False",
            "    \"\"\"True if we've encountered bindparam(..., expanding=True).",
            "",
            "    These need to be converted before execution time against the",
            "    string statement.",
            "",
            "    \"\"\"",
            "",
            "    ansi_bind_rules = False",
            "    \"\"\"SQL 92 doesn't allow bind parameters to be used",
            "    in the columns clause of a SELECT, nor does it allow",
            "    ambiguous expressions like \"? = ?\".  A compiler",
            "    subclass can set this flag to False if the target",
            "    driver/DB enforces this",
            "    \"\"\"",
            "",
            "    _textual_ordered_columns = False",
            "    \"\"\"tell the result object that the column names as rendered are important,",
            "    but they are also \"ordered\" vs. what is in the compiled object here.",
            "    \"\"\"",
            "",
            "    _ordered_columns = True",
            "    \"\"\"",
            "    if False, means we can't be sure the list of entries",
            "    in _result_columns is actually the rendered order.  Usually",
            "    True unless using an unordered TextAsFrom.",
            "    \"\"\"",
            "",
            "    _numeric_binds = False",
            "    \"\"\"",
            "    True if paramstyle is \"numeric\".  This paramstyle is trickier than",
            "    all the others.",
            "",
            "    \"\"\"",
            "",
            "    insert_prefetch = update_prefetch = ()",
            "",
            "    def __init__(",
            "        self, dialect, statement, column_keys=None, inline=False, **kwargs",
            "    ):",
            "        \"\"\"Construct a new :class:`.SQLCompiler` object.",
            "",
            "        :param dialect: :class:`.Dialect` to be used",
            "",
            "        :param statement: :class:`.ClauseElement` to be compiled",
            "",
            "        :param column_keys:  a list of column names to be compiled into an",
            "         INSERT or UPDATE statement.",
            "",
            "        :param inline: whether to generate INSERT statements as \"inline\", e.g.",
            "         not formatted to return any generated defaults",
            "",
            "        :param kwargs: additional keyword arguments to be consumed by the",
            "         superclass.",
            "",
            "        \"\"\"",
            "        self.column_keys = column_keys",
            "",
            "        # compile INSERT/UPDATE defaults/sequences inlined (no pre-",
            "        # execute)",
            "        self.inline = inline or getattr(statement, \"inline\", False)",
            "",
            "        # a dictionary of bind parameter keys to BindParameter",
            "        # instances.",
            "        self.binds = {}",
            "",
            "        # a dictionary of BindParameter instances to \"compiled\" names",
            "        # that are actually present in the generated SQL",
            "        self.bind_names = util.column_dict()",
            "",
            "        # stack which keeps track of nested SELECT statements",
            "        self.stack = []",
            "",
            "        # relates label names in the final SQL to a tuple of local",
            "        # column/label name, ColumnElement object (if any) and",
            "        # TypeEngine. ResultProxy uses this for type processing and",
            "        # column targeting",
            "        self._result_columns = []",
            "",
            "        # true if the paramstyle is positional",
            "        self.positional = dialect.positional",
            "        if self.positional:",
            "            self.positiontup = []",
            "            self._numeric_binds = dialect.paramstyle == \"numeric\"",
            "        self.bindtemplate = BIND_TEMPLATES[dialect.paramstyle]",
            "",
            "        self.ctes = None",
            "",
            "        self.label_length = (",
            "            dialect.label_length or dialect.max_identifier_length",
            "        )",
            "",
            "        # a map which tracks \"anonymous\" identifiers that are created on",
            "        # the fly here",
            "        self.anon_map = util.PopulateDict(self._process_anon)",
            "",
            "        # a map which tracks \"truncated\" names based on",
            "        # dialect.label_length or dialect.max_identifier_length",
            "        self.truncated_names = {}",
            "        Compiled.__init__(self, dialect, statement, **kwargs)",
            "",
            "        if (",
            "            self.isinsert or self.isupdate or self.isdelete",
            "        ) and statement._returning:",
            "            self.returning = statement._returning",
            "",
            "        if self.positional and self._numeric_binds:",
            "            self._apply_numbered_params()",
            "",
            "    @property",
            "    def prefetch(self):",
            "        return list(self.insert_prefetch + self.update_prefetch)",
            "",
            "    @util.memoized_instancemethod",
            "    def _init_cte_state(self):",
            "        \"\"\"Initialize collections related to CTEs only if",
            "        a CTE is located, to save on the overhead of",
            "        these collections otherwise.",
            "",
            "        \"\"\"",
            "        # collect CTEs to tack on top of a SELECT",
            "        self.ctes = util.OrderedDict()",
            "        self.ctes_by_name = {}",
            "        self.ctes_recursive = False",
            "        if self.positional:",
            "            self.cte_positional = {}",
            "",
            "    @contextlib.contextmanager",
            "    def _nested_result(self):",
            "        \"\"\"special API to support the use case of 'nested result sets'\"\"\"",
            "        result_columns, ordered_columns = (",
            "            self._result_columns,",
            "            self._ordered_columns,",
            "        )",
            "        self._result_columns, self._ordered_columns = [], False",
            "",
            "        try:",
            "            if self.stack:",
            "                entry = self.stack[-1]",
            "                entry[\"need_result_map_for_nested\"] = True",
            "            else:",
            "                entry = None",
            "            yield self._result_columns, self._ordered_columns",
            "        finally:",
            "            if entry:",
            "                entry.pop(\"need_result_map_for_nested\")",
            "            self._result_columns, self._ordered_columns = (",
            "                result_columns,",
            "                ordered_columns,",
            "            )",
            "",
            "    def _apply_numbered_params(self):",
            "        poscount = itertools.count(1)",
            "        self.string = re.sub(",
            "            r\"\\[_POSITION\\]\", lambda m: str(util.next(poscount)), self.string",
            "        )",
            "",
            "    @util.memoized_property",
            "    def _bind_processors(self):",
            "        return dict(",
            "            (key, value)",
            "            for key, value in (",
            "                (",
            "                    self.bind_names[bindparam],",
            "                    bindparam.type._cached_bind_processor(self.dialect),",
            "                )",
            "                for bindparam in self.bind_names",
            "            )",
            "            if value is not None",
            "        )",
            "",
            "    def is_subquery(self):",
            "        return len(self.stack) > 1",
            "",
            "    @property",
            "    def sql_compiler(self):",
            "        return self",
            "",
            "    def construct_params(self, params=None, _group_number=None, _check=True):",
            "        \"\"\"return a dictionary of bind parameter keys and values\"\"\"",
            "",
            "        if params:",
            "            pd = {}",
            "            for bindparam in self.bind_names:",
            "                name = self.bind_names[bindparam]",
            "                if bindparam.key in params:",
            "                    pd[name] = params[bindparam.key]",
            "                elif name in params:",
            "                    pd[name] = params[name]",
            "",
            "                elif _check and bindparam.required:",
            "                    if _group_number:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r, \"",
            "                            \"in parameter group %d\"",
            "                            % (bindparam.key, _group_number),",
            "                            code=\"cd3x\",",
            "                        )",
            "                    else:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r\"",
            "                            % bindparam.key,",
            "                            code=\"cd3x\",",
            "                        )",
            "",
            "                elif bindparam.callable:",
            "                    pd[name] = bindparam.effective_value",
            "                else:",
            "                    pd[name] = bindparam.value",
            "            return pd",
            "        else:",
            "            pd = {}",
            "            for bindparam in self.bind_names:",
            "                if _check and bindparam.required:",
            "                    if _group_number:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r, \"",
            "                            \"in parameter group %d\"",
            "                            % (bindparam.key, _group_number),",
            "                            code=\"cd3x\",",
            "                        )",
            "                    else:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r\"",
            "                            % bindparam.key,",
            "                            code=\"cd3x\",",
            "                        )",
            "",
            "                if bindparam.callable:",
            "                    pd[self.bind_names[bindparam]] = bindparam.effective_value",
            "                else:",
            "                    pd[self.bind_names[bindparam]] = bindparam.value",
            "            return pd",
            "",
            "    @property",
            "    def params(self):",
            "        \"\"\"Return the bind param dictionary embedded into this",
            "        compiled object, for those values that are present.\"\"\"",
            "        return self.construct_params(_check=False)",
            "",
            "    @util.dependencies(\"sqlalchemy.engine.result\")",
            "    def _create_result_map(self, result):",
            "        \"\"\"utility method used for unit tests only.\"\"\"",
            "        return result.ResultMetaData._create_result_map(self._result_columns)",
            "",
            "    def default_from(self):",
            "        \"\"\"Called when a SELECT statement has no froms, and no FROM clause is",
            "        to be appended.",
            "",
            "        Gives Oracle a chance to tack on a ``FROM DUAL`` to the string output.",
            "",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def visit_grouping(self, grouping, asfrom=False, **kwargs):",
            "        return \"(\" + grouping.element._compiler_dispatch(self, **kwargs) + \")\"",
            "",
            "    def visit_label_reference(",
            "        self, element, within_columns_clause=False, **kwargs",
            "    ):",
            "        if self.stack and self.dialect.supports_simple_order_by_label:",
            "            selectable = self.stack[-1][\"selectable\"]",
            "",
            "            with_cols, only_froms, only_cols = selectable._label_resolve_dict",
            "            if within_columns_clause:",
            "                resolve_dict = only_froms",
            "            else:",
            "                resolve_dict = only_cols",
            "",
            "            # this can be None in the case that a _label_reference()",
            "            # were subject to a replacement operation, in which case",
            "            # the replacement of the Label element may have changed",
            "            # to something else like a ColumnClause expression.",
            "            order_by_elem = element.element._order_by_label_element",
            "",
            "            if (",
            "                order_by_elem is not None",
            "                and order_by_elem.name in resolve_dict",
            "                and order_by_elem.shares_lineage(",
            "                    resolve_dict[order_by_elem.name]",
            "                )",
            "            ):",
            "                kwargs[",
            "                    \"render_label_as_label\"",
            "                ] = element.element._order_by_label_element",
            "        return self.process(",
            "            element.element,",
            "            within_columns_clause=within_columns_clause,",
            "            **kwargs",
            "        )",
            "",
            "    def visit_textual_label_reference(",
            "        self, element, within_columns_clause=False, **kwargs",
            "    ):",
            "        if not self.stack:",
            "            # compiling the element outside of the context of a SELECT",
            "            return self.process(element._text_clause)",
            "",
            "        selectable = self.stack[-1][\"selectable\"]",
            "        with_cols, only_froms, only_cols = selectable._label_resolve_dict",
            "        try:",
            "            if within_columns_clause:",
            "                col = only_froms[element.element]",
            "            else:",
            "                col = with_cols[element.element]",
            "        except KeyError:",
            "            # treat it like text()",
            "            util.warn_limited(",
            "                \"Can't resolve label reference %r; converting to text()\",",
            "                util.ellipses_string(element.element),",
            "            )",
            "            return self.process(element._text_clause)",
            "        else:",
            "            kwargs[\"render_label_as_label\"] = col",
            "            return self.process(",
            "                col, within_columns_clause=within_columns_clause, **kwargs",
            "            )",
            "",
            "    def visit_label(",
            "        self,",
            "        label,",
            "        add_to_result_map=None,",
            "        within_label_clause=False,",
            "        within_columns_clause=False,",
            "        render_label_as_label=None,",
            "        **kw",
            "    ):",
            "        # only render labels within the columns clause",
            "        # or ORDER BY clause of a select.  dialect-specific compilers",
            "        # can modify this behavior.",
            "        render_label_with_as = (",
            "            within_columns_clause and not within_label_clause",
            "        )",
            "        render_label_only = render_label_as_label is label",
            "",
            "        if render_label_only or render_label_with_as:",
            "            if isinstance(label.name, elements._truncated_label):",
            "                labelname = self._truncated_identifier(\"colident\", label.name)",
            "            else:",
            "                labelname = label.name",
            "",
            "        if render_label_with_as:",
            "            if add_to_result_map is not None:",
            "                add_to_result_map(",
            "                    labelname,",
            "                    label.name,",
            "                    (label, labelname) + label._alt_names,",
            "                    label.type,",
            "                )",
            "",
            "            return (",
            "                label.element._compiler_dispatch(",
            "                    self,",
            "                    within_columns_clause=True,",
            "                    within_label_clause=True,",
            "                    **kw",
            "                )",
            "                + OPERATORS[operators.as_]",
            "                + self.preparer.format_label(label, labelname)",
            "            )",
            "        elif render_label_only:",
            "            return self.preparer.format_label(label, labelname)",
            "        else:",
            "            return label.element._compiler_dispatch(",
            "                self, within_columns_clause=False, **kw",
            "            )",
            "",
            "    def _fallback_column_name(self, column):",
            "        raise exc.CompileError(",
            "            \"Cannot compile Column object until \" \"its 'name' is assigned.\"",
            "        )",
            "",
            "    def visit_column(",
            "        self, column, add_to_result_map=None, include_table=True, **kwargs",
            "    ):",
            "        name = orig_name = column.name",
            "        if name is None:",
            "            name = self._fallback_column_name(column)",
            "",
            "        is_literal = column.is_literal",
            "        if not is_literal and isinstance(name, elements._truncated_label):",
            "            name = self._truncated_identifier(\"colident\", name)",
            "",
            "        if add_to_result_map is not None:",
            "            add_to_result_map(",
            "                name, orig_name, (column, name, column.key), column.type",
            "            )",
            "",
            "        if is_literal:",
            "            name = self.escape_literal_column(name)",
            "        else:",
            "            name = self.preparer.quote(name)",
            "        table = column.table",
            "        if table is None or not include_table or not table.named_with_column:",
            "            return name",
            "        else:",
            "            effective_schema = self.preparer.schema_for_object(table)",
            "",
            "            if effective_schema:",
            "                schema_prefix = (",
            "                    self.preparer.quote_schema(effective_schema) + \".\"",
            "                )",
            "            else:",
            "                schema_prefix = \"\"",
            "            tablename = table.name",
            "            if isinstance(tablename, elements._truncated_label):",
            "                tablename = self._truncated_identifier(\"alias\", tablename)",
            "",
            "            return schema_prefix + self.preparer.quote(tablename) + \".\" + name",
            "",
            "    def visit_collation(self, element, **kw):",
            "        return self.preparer.format_collation(element.collation)",
            "",
            "    def visit_fromclause(self, fromclause, **kwargs):",
            "        return fromclause.name",
            "",
            "    def visit_index(self, index, **kwargs):",
            "        return index.name",
            "",
            "    def visit_typeclause(self, typeclause, **kw):",
            "        kw[\"type_expression\"] = typeclause",
            "        return self.dialect.type_compiler.process(typeclause.type, **kw)",
            "",
            "    def post_process_text(self, text):",
            "        if self.preparer._double_percents:",
            "            text = text.replace(\"%\", \"%%\")",
            "        return text",
            "",
            "    def escape_literal_column(self, text):",
            "        if self.preparer._double_percents:",
            "            text = text.replace(\"%\", \"%%\")",
            "        return text",
            "",
            "    def visit_textclause(self, textclause, **kw):",
            "        def do_bindparam(m):",
            "            name = m.group(1)",
            "            if name in textclause._bindparams:",
            "                return self.process(textclause._bindparams[name], **kw)",
            "            else:",
            "                return self.bindparam_string(name, **kw)",
            "",
            "        if not self.stack:",
            "            self.isplaintext = True",
            "",
            "        # un-escape any \\:params",
            "        return BIND_PARAMS_ESC.sub(",
            "            lambda m: m.group(1),",
            "            BIND_PARAMS.sub(",
            "                do_bindparam, self.post_process_text(textclause.text)",
            "            ),",
            "        )",
            "",
            "    def visit_text_as_from(",
            "        self, taf, compound_index=None, asfrom=False, parens=True, **kw",
            "    ):",
            "",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        populate_result_map = (",
            "            toplevel",
            "            or (",
            "                compound_index == 0",
            "                and entry.get(\"need_result_map_for_compound\", False)",
            "            )",
            "            or entry.get(\"need_result_map_for_nested\", False)",
            "        )",
            "",
            "        if populate_result_map:",
            "            self._ordered_columns = (",
            "                self._textual_ordered_columns",
            "            ) = taf.positional",
            "            for c in taf.column_args:",
            "                self.process(",
            "                    c,",
            "                    within_columns_clause=True,",
            "                    add_to_result_map=self._add_to_result_map,",
            "                )",
            "",
            "        text = self.process(taf.element, **kw)",
            "        if asfrom and parens:",
            "            text = \"(%s)\" % text",
            "        return text",
            "",
            "    def visit_null(self, expr, **kw):",
            "        return \"NULL\"",
            "",
            "    def visit_true(self, expr, **kw):",
            "        if self.dialect.supports_native_boolean:",
            "            return \"true\"",
            "        else:",
            "            return \"1\"",
            "",
            "    def visit_false(self, expr, **kw):",
            "        if self.dialect.supports_native_boolean:",
            "            return \"false\"",
            "        else:",
            "            return \"0\"",
            "",
            "    def visit_clauselist(self, clauselist, **kw):",
            "        sep = clauselist.operator",
            "        if sep is None:",
            "            sep = \" \"",
            "        else:",
            "            sep = OPERATORS[clauselist.operator]",
            "        return sep.join(",
            "            s",
            "            for s in (",
            "                c._compiler_dispatch(self, **kw) for c in clauselist.clauses",
            "            )",
            "            if s",
            "        )",
            "",
            "    def visit_case(self, clause, **kwargs):",
            "        x = \"CASE \"",
            "        if clause.value is not None:",
            "            x += clause.value._compiler_dispatch(self, **kwargs) + \" \"",
            "        for cond, result in clause.whens:",
            "            x += (",
            "                \"WHEN \"",
            "                + cond._compiler_dispatch(self, **kwargs)",
            "                + \" THEN \"",
            "                + result._compiler_dispatch(self, **kwargs)",
            "                + \" \"",
            "            )",
            "        if clause.else_ is not None:",
            "            x += (",
            "                \"ELSE \" + clause.else_._compiler_dispatch(self, **kwargs) + \" \"",
            "            )",
            "        x += \"END\"",
            "        return x",
            "",
            "    def visit_type_coerce(self, type_coerce, **kw):",
            "        return type_coerce.typed_expression._compiler_dispatch(self, **kw)",
            "",
            "    def visit_cast(self, cast, **kwargs):",
            "        return \"CAST(%s AS %s)\" % (",
            "            cast.clause._compiler_dispatch(self, **kwargs),",
            "            cast.typeclause._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def _format_frame_clause(self, range_, **kw):",
            "",
            "        return \"%s AND %s\" % (",
            "            \"UNBOUNDED PRECEDING\"",
            "            if range_[0] is elements.RANGE_UNBOUNDED",
            "            else \"CURRENT ROW\"",
            "            if range_[0] is elements.RANGE_CURRENT",
            "            else \"%s PRECEDING\"",
            "            % (self.process(elements.literal(abs(range_[0])), **kw),)",
            "            if range_[0] < 0",
            "            else \"%s FOLLOWING\"",
            "            % (self.process(elements.literal(range_[0]), **kw),),",
            "            \"UNBOUNDED FOLLOWING\"",
            "            if range_[1] is elements.RANGE_UNBOUNDED",
            "            else \"CURRENT ROW\"",
            "            if range_[1] is elements.RANGE_CURRENT",
            "            else \"%s PRECEDING\"",
            "            % (self.process(elements.literal(abs(range_[1])), **kw),)",
            "            if range_[1] < 0",
            "            else \"%s FOLLOWING\"",
            "            % (self.process(elements.literal(range_[1]), **kw),),",
            "        )",
            "",
            "    def visit_over(self, over, **kwargs):",
            "        if over.range_:",
            "            range_ = \"RANGE BETWEEN %s\" % self._format_frame_clause(",
            "                over.range_, **kwargs",
            "            )",
            "        elif over.rows:",
            "            range_ = \"ROWS BETWEEN %s\" % self._format_frame_clause(",
            "                over.rows, **kwargs",
            "            )",
            "        else:",
            "            range_ = None",
            "",
            "        return \"%s OVER (%s)\" % (",
            "            over.element._compiler_dispatch(self, **kwargs),",
            "            \" \".join(",
            "                [",
            "                    \"%s BY %s\"",
            "                    % (word, clause._compiler_dispatch(self, **kwargs))",
            "                    for word, clause in (",
            "                        (\"PARTITION\", over.partition_by),",
            "                        (\"ORDER\", over.order_by),",
            "                    )",
            "                    if clause is not None and len(clause)",
            "                ]",
            "                + ([range_] if range_ else [])",
            "            ),",
            "        )",
            "",
            "    def visit_withingroup(self, withingroup, **kwargs):",
            "        return \"%s WITHIN GROUP (ORDER BY %s)\" % (",
            "            withingroup.element._compiler_dispatch(self, **kwargs),",
            "            withingroup.order_by._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_funcfilter(self, funcfilter, **kwargs):",
            "        return \"%s FILTER (WHERE %s)\" % (",
            "            funcfilter.func._compiler_dispatch(self, **kwargs),",
            "            funcfilter.criterion._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_extract(self, extract, **kwargs):",
            "        field = self.extract_map.get(extract.field, extract.field)",
            "        return \"EXTRACT(%s FROM %s)\" % (",
            "            field,",
            "            extract.expr._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_function(self, func, add_to_result_map=None, **kwargs):",
            "        if add_to_result_map is not None:",
            "            add_to_result_map(func.name, func.name, (), func.type)",
            "",
            "        disp = getattr(self, \"visit_%s_func\" % func.name.lower(), None)",
            "        if disp:",
            "            return disp(func, **kwargs)",
            "        else:",
            "            name = FUNCTIONS.get(func.__class__, None)",
            "            if name:",
            "                if func._has_args:",
            "                    name += \"%(expr)s\"",
            "            else:",
            "                name = func.name + \"%(expr)s\"",
            "            return \".\".join(list(func.packagenames) + [name]) % {",
            "                \"expr\": self.function_argspec(func, **kwargs)",
            "            }",
            "",
            "    def visit_next_value_func(self, next_value, **kw):",
            "        return self.visit_sequence(next_value.sequence)",
            "",
            "    def visit_sequence(self, sequence, **kw):",
            "        raise NotImplementedError(",
            "            \"Dialect '%s' does not support sequence increments.\"",
            "            % self.dialect.name",
            "        )",
            "",
            "    def function_argspec(self, func, **kwargs):",
            "        return func.clause_expr._compiler_dispatch(self, **kwargs)",
            "",
            "    def visit_compound_select(",
            "        self, cs, asfrom=False, parens=True, compound_index=0, **kwargs",
            "    ):",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "        need_result_map = toplevel or (",
            "            compound_index == 0",
            "            and entry.get(\"need_result_map_for_compound\", False)",
            "        )",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": entry[\"correlate_froms\"],",
            "                \"asfrom_froms\": entry[\"asfrom_froms\"],",
            "                \"selectable\": cs,",
            "                \"need_result_map_for_compound\": need_result_map,",
            "            }",
            "        )",
            "",
            "        keyword = self.compound_keywords.get(cs.keyword)",
            "",
            "        text = (\" \" + keyword + \" \").join(",
            "            (",
            "                c._compiler_dispatch(",
            "                    self,",
            "                    asfrom=asfrom,",
            "                    parens=False,",
            "                    compound_index=i,",
            "                    **kwargs",
            "                )",
            "                for i, c in enumerate(cs.selects)",
            "            )",
            "        )",
            "",
            "        text += self.group_by_clause(cs, **dict(asfrom=asfrom, **kwargs))",
            "        text += self.order_by_clause(cs, **kwargs)",
            "        text += (",
            "            (cs._limit_clause is not None or cs._offset_clause is not None)",
            "            and self.limit_clause(cs, **kwargs)",
            "            or \"\"",
            "        )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "        if asfrom and parens:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def _get_operator_dispatch(self, operator_, qualifier1, qualifier2):",
            "        attrname = \"visit_%s_%s%s\" % (",
            "            operator_.__name__,",
            "            qualifier1,",
            "            \"_\" + qualifier2 if qualifier2 else \"\",",
            "        )",
            "        return getattr(self, attrname, None)",
            "",
            "    def visit_unary(self, unary, **kw):",
            "        if unary.operator:",
            "            if unary.modifier:",
            "                raise exc.CompileError(",
            "                    \"Unary expression does not support operator \"",
            "                    \"and modifier simultaneously\"",
            "                )",
            "            disp = self._get_operator_dispatch(",
            "                unary.operator, \"unary\", \"operator\"",
            "            )",
            "            if disp:",
            "                return disp(unary, unary.operator, **kw)",
            "            else:",
            "                return self._generate_generic_unary_operator(",
            "                    unary, OPERATORS[unary.operator], **kw",
            "                )",
            "        elif unary.modifier:",
            "            disp = self._get_operator_dispatch(",
            "                unary.modifier, \"unary\", \"modifier\"",
            "            )",
            "            if disp:",
            "                return disp(unary, unary.modifier, **kw)",
            "            else:",
            "                return self._generate_generic_unary_modifier(",
            "                    unary, OPERATORS[unary.modifier], **kw",
            "                )",
            "        else:",
            "            raise exc.CompileError(",
            "                \"Unary expression has no operator or modifier\"",
            "            )",
            "",
            "    def visit_istrue_unary_operator(self, element, operator, **kw):",
            "        if (",
            "            element._is_implicitly_boolean",
            "            or self.dialect.supports_native_boolean",
            "        ):",
            "            return self.process(element.element, **kw)",
            "        else:",
            "            return \"%s = 1\" % self.process(element.element, **kw)",
            "",
            "    def visit_isfalse_unary_operator(self, element, operator, **kw):",
            "        if (",
            "            element._is_implicitly_boolean",
            "            or self.dialect.supports_native_boolean",
            "        ):",
            "            return \"NOT %s\" % self.process(element.element, **kw)",
            "        else:",
            "            return \"%s = 0\" % self.process(element.element, **kw)",
            "",
            "    def visit_notmatch_op_binary(self, binary, operator, **kw):",
            "        return \"NOT %s\" % self.visit_binary(",
            "            binary, override_operator=operators.match_op",
            "        )",
            "",
            "    def _emit_empty_in_warning(self):",
            "        util.warn(",
            "            \"The IN-predicate was invoked with an \"",
            "            \"empty sequence. This results in a \"",
            "            \"contradiction, which nonetheless can be \"",
            "            \"expensive to evaluate.  Consider alternative \"",
            "            \"strategies for improved performance.\"",
            "        )",
            "",
            "    def visit_empty_in_op_binary(self, binary, operator, **kw):",
            "        if self.dialect._use_static_in:",
            "            return \"1 != 1\"",
            "        else:",
            "            if self.dialect._warn_on_empty_in:",
            "                self._emit_empty_in_warning()",
            "            return self.process(binary.left != binary.left)",
            "",
            "    def visit_empty_notin_op_binary(self, binary, operator, **kw):",
            "        if self.dialect._use_static_in:",
            "            return \"1 = 1\"",
            "        else:",
            "            if self.dialect._warn_on_empty_in:",
            "                self._emit_empty_in_warning()",
            "            return self.process(binary.left == binary.left)",
            "",
            "    def visit_empty_set_expr(self, element_types):",
            "        raise NotImplementedError(",
            "            \"Dialect '%s' does not support empty set expression.\"",
            "            % self.dialect.name",
            "        )",
            "",
            "    def visit_binary(",
            "        self, binary, override_operator=None, eager_grouping=False, **kw",
            "    ):",
            "",
            "        # don't allow \"? = ?\" to render",
            "        if (",
            "            self.ansi_bind_rules",
            "            and isinstance(binary.left, elements.BindParameter)",
            "            and isinstance(binary.right, elements.BindParameter)",
            "        ):",
            "            kw[\"literal_binds\"] = True",
            "",
            "        operator_ = override_operator or binary.operator",
            "        disp = self._get_operator_dispatch(operator_, \"binary\", None)",
            "        if disp:",
            "            return disp(binary, operator_, **kw)",
            "        else:",
            "            try:",
            "                opstring = OPERATORS[operator_]",
            "            except KeyError:",
            "                raise exc.UnsupportedCompilationError(self, operator_)",
            "            else:",
            "                return self._generate_generic_binary(binary, opstring, **kw)",
            "",
            "    def visit_function_as_comparison_op_binary(self, element, operator, **kw):",
            "        return self.process(element.sql_function, **kw)",
            "",
            "    def visit_mod_binary(self, binary, operator, **kw):",
            "        if self.preparer._double_percents:",
            "            return (",
            "                self.process(binary.left, **kw)",
            "                + \" %% \"",
            "                + self.process(binary.right, **kw)",
            "            )",
            "        else:",
            "            return (",
            "                self.process(binary.left, **kw)",
            "                + \" % \"",
            "                + self.process(binary.right, **kw)",
            "            )",
            "",
            "    def visit_custom_op_binary(self, element, operator, **kw):",
            "        kw[\"eager_grouping\"] = operator.eager_grouping",
            "        return self._generate_generic_binary(",
            "            element, \" \" + operator.opstring + \" \", **kw",
            "        )",
            "",
            "    def visit_custom_op_unary_operator(self, element, operator, **kw):",
            "        return self._generate_generic_unary_operator(",
            "            element, operator.opstring + \" \", **kw",
            "        )",
            "",
            "    def visit_custom_op_unary_modifier(self, element, operator, **kw):",
            "        return self._generate_generic_unary_modifier(",
            "            element, \" \" + operator.opstring, **kw",
            "        )",
            "",
            "    def _generate_generic_binary(",
            "        self, binary, opstring, eager_grouping=False, **kw",
            "    ):",
            "",
            "        _in_binary = kw.get(\"_in_binary\", False)",
            "",
            "        kw[\"_in_binary\"] = True",
            "        text = (",
            "            binary.left._compiler_dispatch(",
            "                self, eager_grouping=eager_grouping, **kw",
            "            )",
            "            + opstring",
            "            + binary.right._compiler_dispatch(",
            "                self, eager_grouping=eager_grouping, **kw",
            "            )",
            "        )",
            "",
            "        if _in_binary and eager_grouping:",
            "            text = \"(%s)\" % text",
            "        return text",
            "",
            "    def _generate_generic_unary_operator(self, unary, opstring, **kw):",
            "        return opstring + unary.element._compiler_dispatch(self, **kw)",
            "",
            "    def _generate_generic_unary_modifier(self, unary, opstring, **kw):",
            "        return unary.element._compiler_dispatch(self, **kw) + opstring",
            "",
            "    @util.memoized_property",
            "    def _like_percent_literal(self):",
            "        return elements.literal_column(\"'%'\", type_=sqltypes.STRINGTYPE)",
            "",
            "    def visit_contains_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right).__add__(percent)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notcontains_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right).__add__(percent)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_startswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__radd__(binary.right)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notstartswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__radd__(binary.right)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_endswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notendswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_like_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "",
            "        # TODO: use ternary here, not \"and\"/ \"or\"",
            "        return \"%s LIKE %s\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notlike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"%s NOT LIKE %s\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_ilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"lower(%s) LIKE lower(%s)\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"lower(%s) NOT LIKE lower(%s)\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_between_op_binary(self, binary, operator, **kw):",
            "        symmetric = binary.modifiers.get(\"symmetric\", False)",
            "        return self._generate_generic_binary(",
            "            binary, \" BETWEEN SYMMETRIC \" if symmetric else \" BETWEEN \", **kw",
            "        )",
            "",
            "    def visit_notbetween_op_binary(self, binary, operator, **kw):",
            "        symmetric = binary.modifiers.get(\"symmetric\", False)",
            "        return self._generate_generic_binary(",
            "            binary,",
            "            \" NOT BETWEEN SYMMETRIC \" if symmetric else \" NOT BETWEEN \",",
            "            **kw",
            "        )",
            "",
            "    def visit_bindparam(",
            "        self,",
            "        bindparam,",
            "        within_columns_clause=False,",
            "        literal_binds=False,",
            "        skip_bind_expression=False,",
            "        **kwargs",
            "    ):",
            "",
            "        if not skip_bind_expression:",
            "            impl = bindparam.type.dialect_impl(self.dialect)",
            "            if impl._has_bind_expression:",
            "                bind_expression = impl.bind_expression(bindparam)",
            "                return self.process(",
            "                    bind_expression,",
            "                    skip_bind_expression=True,",
            "                    within_columns_clause=within_columns_clause,",
            "                    literal_binds=literal_binds,",
            "                    **kwargs",
            "                )",
            "",
            "        if literal_binds or (within_columns_clause and self.ansi_bind_rules):",
            "            if bindparam.value is None and bindparam.callable is None:",
            "                raise exc.CompileError(",
            "                    \"Bind parameter '%s' without a \"",
            "                    \"renderable value not allowed here.\" % bindparam.key",
            "                )",
            "            return self.render_literal_bindparam(",
            "                bindparam, within_columns_clause=True, **kwargs",
            "            )",
            "",
            "        name = self._truncate_bindparam(bindparam)",
            "",
            "        if name in self.binds:",
            "            existing = self.binds[name]",
            "            if existing is not bindparam:",
            "                if (",
            "                    existing.unique or bindparam.unique",
            "                ) and not existing.proxy_set.intersection(bindparam.proxy_set):",
            "                    raise exc.CompileError(",
            "                        \"Bind parameter '%s' conflicts with \"",
            "                        \"unique bind parameter of the same name\"",
            "                        % bindparam.key",
            "                    )",
            "                elif existing._is_crud or bindparam._is_crud:",
            "                    raise exc.CompileError(",
            "                        \"bindparam() name '%s' is reserved \"",
            "                        \"for automatic usage in the VALUES or SET \"",
            "                        \"clause of this \"",
            "                        \"insert/update statement.   Please use a \"",
            "                        \"name other than column name when using bindparam() \"",
            "                        \"with insert() or update() (for example, 'b_%s').\"",
            "                        % (bindparam.key, bindparam.key)",
            "                    )",
            "",
            "        self.binds[bindparam.key] = self.binds[name] = bindparam",
            "",
            "        return self.bindparam_string(",
            "            name, expanding=bindparam.expanding, **kwargs",
            "        )",
            "",
            "    def render_literal_bindparam(self, bindparam, **kw):",
            "        value = bindparam.effective_value",
            "        return self.render_literal_value(value, bindparam.type)",
            "",
            "    def render_literal_value(self, value, type_):",
            "        \"\"\"Render the value of a bind parameter as a quoted literal.",
            "",
            "        This is used for statement sections that do not accept bind parameters",
            "        on the target driver/database.",
            "",
            "        This should be implemented by subclasses using the quoting services",
            "        of the DBAPI.",
            "",
            "        \"\"\"",
            "",
            "        processor = type_._cached_literal_processor(self.dialect)",
            "        if processor:",
            "            return processor(value)",
            "        else:",
            "            raise NotImplementedError(",
            "                \"Don't know how to literal-quote value %r\" % value",
            "            )",
            "",
            "    def _truncate_bindparam(self, bindparam):",
            "        if bindparam in self.bind_names:",
            "            return self.bind_names[bindparam]",
            "",
            "        bind_name = bindparam.key",
            "        if isinstance(bind_name, elements._truncated_label):",
            "            bind_name = self._truncated_identifier(\"bindparam\", bind_name)",
            "",
            "        # add to bind_names for translation",
            "        self.bind_names[bindparam] = bind_name",
            "",
            "        return bind_name",
            "",
            "    def _truncated_identifier(self, ident_class, name):",
            "        if (ident_class, name) in self.truncated_names:",
            "            return self.truncated_names[(ident_class, name)]",
            "",
            "        anonname = name.apply_map(self.anon_map)",
            "",
            "        if len(anonname) > self.label_length - 6:",
            "            counter = self.truncated_names.get(ident_class, 1)",
            "            truncname = (",
            "                anonname[0 : max(self.label_length - 6, 0)]",
            "                + \"_\"",
            "                + hex(counter)[2:]",
            "            )",
            "            self.truncated_names[ident_class] = counter + 1",
            "        else:",
            "            truncname = anonname",
            "        self.truncated_names[(ident_class, name)] = truncname",
            "        return truncname",
            "",
            "    def _anonymize(self, name):",
            "        return name % self.anon_map",
            "",
            "    def _process_anon(self, key):",
            "        (ident, derived) = key.split(\" \", 1)",
            "        anonymous_counter = self.anon_map.get(derived, 1)",
            "        self.anon_map[derived] = anonymous_counter + 1",
            "        return derived + \"_\" + str(anonymous_counter)",
            "",
            "    def bindparam_string(",
            "        self, name, positional_names=None, expanding=False, **kw",
            "    ):",
            "        if self.positional:",
            "            if positional_names is not None:",
            "                positional_names.append(name)",
            "            else:",
            "                self.positiontup.append(name)",
            "        if expanding:",
            "            self.contains_expanding_parameters = True",
            "            return \"([EXPANDING_%s])\" % name",
            "        else:",
            "            return self.bindtemplate % {\"name\": name}",
            "",
            "    def visit_cte(",
            "        self,",
            "        cte,",
            "        asfrom=False,",
            "        ashint=False,",
            "        fromhints=None,",
            "        visiting_cte=None,",
            "        **kwargs",
            "    ):",
            "        self._init_cte_state()",
            "",
            "        kwargs[\"visiting_cte\"] = cte",
            "        if isinstance(cte.name, elements._truncated_label):",
            "            cte_name = self._truncated_identifier(\"alias\", cte.name)",
            "        else:",
            "            cte_name = cte.name",
            "",
            "        is_new_cte = True",
            "        embedded_in_current_named_cte = False",
            "",
            "        if cte_name in self.ctes_by_name:",
            "            existing_cte = self.ctes_by_name[cte_name]",
            "            embedded_in_current_named_cte = visiting_cte is existing_cte",
            "",
            "            # we've generated a same-named CTE that we are enclosed in,",
            "            # or this is the same CTE.  just return the name.",
            "            if cte in existing_cte._restates or cte is existing_cte:",
            "                is_new_cte = False",
            "            elif existing_cte in cte._restates:",
            "                # we've generated a same-named CTE that is",
            "                # enclosed in us - we take precedence, so",
            "                # discard the text for the \"inner\".",
            "                del self.ctes[existing_cte]",
            "            else:",
            "                raise exc.CompileError(",
            "                    \"Multiple, unrelated CTEs found with \"",
            "                    \"the same name: %r\" % cte_name",
            "                )",
            "",
            "        if asfrom or is_new_cte:",
            "            if cte._cte_alias is not None:",
            "                pre_alias_cte = cte._cte_alias",
            "                cte_pre_alias_name = cte._cte_alias.name",
            "                if isinstance(cte_pre_alias_name, elements._truncated_label):",
            "                    cte_pre_alias_name = self._truncated_identifier(",
            "                        \"alias\", cte_pre_alias_name",
            "                    )",
            "            else:",
            "                pre_alias_cte = cte",
            "                cte_pre_alias_name = None",
            "",
            "        if is_new_cte:",
            "            self.ctes_by_name[cte_name] = cte",
            "",
            "            # look for embedded DML ctes and propagate autocommit",
            "            if (",
            "                \"autocommit\" in cte.element._execution_options",
            "                and \"autocommit\" not in self.execution_options",
            "            ):",
            "                self.execution_options = self.execution_options.union(",
            "                    {",
            "                        \"autocommit\": cte.element._execution_options[",
            "                            \"autocommit\"",
            "                        ]",
            "                    }",
            "                )",
            "",
            "            if pre_alias_cte not in self.ctes:",
            "                self.visit_cte(pre_alias_cte, **kwargs)",
            "",
            "            if not cte_pre_alias_name and cte not in self.ctes:",
            "                if cte.recursive:",
            "                    self.ctes_recursive = True",
            "                text = self.preparer.format_alias(cte, cte_name)",
            "                if cte.recursive:",
            "                    if isinstance(cte.original, selectable.Select):",
            "                        col_source = cte.original",
            "                    elif isinstance(cte.original, selectable.CompoundSelect):",
            "                        col_source = cte.original.selects[0]",
            "                    else:",
            "                        assert False",
            "                    recur_cols = [",
            "                        c",
            "                        for c in util.unique_list(col_source.inner_columns)",
            "                        if c is not None",
            "                    ]",
            "",
            "                    text += \"(%s)\" % (",
            "                        \", \".join(",
            "                            self.preparer.format_column(ident)",
            "                            for ident in recur_cols",
            "                        )",
            "                    )",
            "",
            "                if self.positional:",
            "                    kwargs[\"positional_names\"] = self.cte_positional[cte] = []",
            "",
            "                text += \" AS \\n\" + cte.original._compiler_dispatch(",
            "                    self, asfrom=True, **kwargs",
            "                )",
            "",
            "                if cte._suffixes:",
            "                    text += \" \" + self._generate_prefixes(",
            "                        cte, cte._suffixes, **kwargs",
            "                    )",
            "",
            "                self.ctes[cte] = text",
            "",
            "        if asfrom:",
            "            if not is_new_cte and embedded_in_current_named_cte:",
            "                return self.preparer.format_alias(cte, cte_name)",
            "",
            "            if cte_pre_alias_name:",
            "                text = self.preparer.format_alias(cte, cte_pre_alias_name)",
            "                if self.preparer._requires_quotes(cte_name):",
            "                    cte_name = self.preparer.quote(cte_name)",
            "                text += self.get_render_as_alias_suffix(cte_name)",
            "                return text",
            "            else:",
            "                return self.preparer.format_alias(cte, cte_name)",
            "",
            "    def visit_alias(",
            "        self,",
            "        alias,",
            "        asfrom=False,",
            "        ashint=False,",
            "        iscrud=False,",
            "        fromhints=None,",
            "        **kwargs",
            "    ):",
            "        if asfrom or ashint:",
            "            if isinstance(alias.name, elements._truncated_label):",
            "                alias_name = self._truncated_identifier(\"alias\", alias.name)",
            "            else:",
            "                alias_name = alias.name",
            "",
            "        if ashint:",
            "            return self.preparer.format_alias(alias, alias_name)",
            "        elif asfrom:",
            "            ret = alias.original._compiler_dispatch(",
            "                self, asfrom=True, **kwargs",
            "            ) + self.get_render_as_alias_suffix(",
            "                self.preparer.format_alias(alias, alias_name)",
            "            )",
            "",
            "            if fromhints and alias in fromhints:",
            "                ret = self.format_from_hint_text(",
            "                    ret, alias, fromhints[alias], iscrud",
            "                )",
            "",
            "            return ret",
            "        else:",
            "            return alias.original._compiler_dispatch(self, **kwargs)",
            "",
            "    def visit_lateral(self, lateral, **kw):",
            "        kw[\"lateral\"] = True",
            "        return \"LATERAL %s\" % self.visit_alias(lateral, **kw)",
            "",
            "    def visit_tablesample(self, tablesample, asfrom=False, **kw):",
            "        text = \"%s TABLESAMPLE %s\" % (",
            "            self.visit_alias(tablesample, asfrom=True, **kw),",
            "            tablesample._get_method()._compiler_dispatch(self, **kw),",
            "        )",
            "",
            "        if tablesample.seed is not None:",
            "            text += \" REPEATABLE (%s)\" % (",
            "                tablesample.seed._compiler_dispatch(self, **kw)",
            "            )",
            "",
            "        return text",
            "",
            "    def get_render_as_alias_suffix(self, alias_name_text):",
            "        return \" AS \" + alias_name_text",
            "",
            "    def _add_to_result_map(self, keyname, name, objects, type_):",
            "        self._result_columns.append((keyname, name, objects, type_))",
            "",
            "    def _label_select_column(",
            "        self,",
            "        select,",
            "        column,",
            "        populate_result_map,",
            "        asfrom,",
            "        column_clause_args,",
            "        name=None,",
            "        within_columns_clause=True,",
            "    ):",
            "        \"\"\"produce labeled columns present in a select().\"\"\"",
            "",
            "        impl = column.type.dialect_impl(self.dialect)",
            "        if impl._has_column_expression and populate_result_map:",
            "            col_expr = impl.column_expression(column)",
            "",
            "            def add_to_result_map(keyname, name, objects, type_):",
            "                self._add_to_result_map(",
            "                    keyname, name, (column,) + objects, type_",
            "                )",
            "",
            "        else:",
            "            col_expr = column",
            "            if populate_result_map:",
            "                add_to_result_map = self._add_to_result_map",
            "            else:",
            "                add_to_result_map = None",
            "",
            "        if not within_columns_clause:",
            "            result_expr = col_expr",
            "        elif isinstance(column, elements.Label):",
            "            if col_expr is not column:",
            "                result_expr = _CompileLabel(",
            "                    col_expr, column.name, alt_names=(column.element,)",
            "                )",
            "            else:",
            "                result_expr = col_expr",
            "",
            "        elif select is not None and name:",
            "            result_expr = _CompileLabel(",
            "                col_expr, name, alt_names=(column._key_label,)",
            "            )",
            "",
            "        elif (",
            "            asfrom",
            "            and isinstance(column, elements.ColumnClause)",
            "            and not column.is_literal",
            "            and column.table is not None",
            "            and not isinstance(column.table, selectable.Select)",
            "        ):",
            "            result_expr = _CompileLabel(",
            "                col_expr,",
            "                elements._as_truncated(column.name),",
            "                alt_names=(column.key,),",
            "            )",
            "        elif (",
            "            not isinstance(column, elements.TextClause)",
            "            and (",
            "                not isinstance(column, elements.UnaryExpression)",
            "                or column.wraps_column_expression",
            "            )",
            "            and (",
            "                not hasattr(column, \"name\")",
            "                or isinstance(column, functions.Function)",
            "            )",
            "        ):",
            "            result_expr = _CompileLabel(col_expr, column.anon_label)",
            "        elif col_expr is not column:",
            "            # TODO: are we sure \"column\" has a .name and .key here ?",
            "            # assert isinstance(column, elements.ColumnClause)",
            "            result_expr = _CompileLabel(",
            "                col_expr,",
            "                elements._as_truncated(column.name),",
            "                alt_names=(column.key,),",
            "            )",
            "        else:",
            "            result_expr = col_expr",
            "",
            "        column_clause_args.update(",
            "            within_columns_clause=within_columns_clause,",
            "            add_to_result_map=add_to_result_map,",
            "        )",
            "        return result_expr._compiler_dispatch(self, **column_clause_args)",
            "",
            "    def format_from_hint_text(self, sqltext, table, hint, iscrud):",
            "        hinttext = self.get_from_hint_text(table, hint)",
            "        if hinttext:",
            "            sqltext += \" \" + hinttext",
            "        return sqltext",
            "",
            "    def get_select_hint_text(self, byfroms):",
            "        return None",
            "",
            "    def get_from_hint_text(self, table, text):",
            "        return None",
            "",
            "    def get_crud_hint_text(self, table, text):",
            "        return None",
            "",
            "    def get_statement_hint_text(self, hint_texts):",
            "        return \" \".join(hint_texts)",
            "",
            "    def _transform_select_for_nested_joins(self, select):",
            "        \"\"\"Rewrite any \"a JOIN (b JOIN c)\" expression as",
            "        \"a JOIN (select * from b JOIN c) AS anon\", to support",
            "        databases that can't parse a parenthesized join correctly",
            "        (i.e. sqlite < 3.7.16).",
            "",
            "        \"\"\"",
            "        cloned = {}",
            "        column_translate = [{}]",
            "",
            "        def visit(element, **kw):",
            "            if element in column_translate[-1]:",
            "                return column_translate[-1][element]",
            "",
            "            elif element in cloned:",
            "                return cloned[element]",
            "",
            "            newelem = cloned[element] = element._clone()",
            "",
            "            if (",
            "                newelem.is_selectable",
            "                and newelem._is_join",
            "                and isinstance(newelem.right, selectable.FromGrouping)",
            "            ):",
            "",
            "                newelem._reset_exported()",
            "                newelem.left = visit(newelem.left, **kw)",
            "",
            "                right = visit(newelem.right, **kw)",
            "",
            "                selectable_ = selectable.Select(",
            "                    [right.element], use_labels=True",
            "                ).alias()",
            "",
            "                for c in selectable_.c:",
            "                    c._key_label = c.key",
            "                    c._label = c.name",
            "",
            "                translate_dict = dict(",
            "                    zip(newelem.right.element.c, selectable_.c)",
            "                )",
            "",
            "                # translating from both the old and the new",
            "                # because different select() structures will lead us",
            "                # to traverse differently",
            "                translate_dict[right.element.left] = selectable_",
            "                translate_dict[right.element.right] = selectable_",
            "                translate_dict[newelem.right.element.left] = selectable_",
            "                translate_dict[newelem.right.element.right] = selectable_",
            "",
            "                # propagate translations that we've gained",
            "                # from nested visit(newelem.right) outwards",
            "                # to the enclosing select here.  this happens",
            "                # only when we have more than one level of right",
            "                # join nesting, i.e. \"a JOIN (b JOIN (c JOIN d))\"",
            "                for k, v in list(column_translate[-1].items()):",
            "                    if v in translate_dict:",
            "                        # remarkably, no current ORM tests (May 2013)",
            "                        # hit this condition, only test_join_rewriting",
            "                        # does.",
            "                        column_translate[-1][k] = translate_dict[v]",
            "",
            "                column_translate[-1].update(translate_dict)",
            "",
            "                newelem.right = selectable_",
            "",
            "                newelem.onclause = visit(newelem.onclause, **kw)",
            "",
            "            elif newelem._is_from_container:",
            "                # if we hit an Alias, CompoundSelect or ScalarSelect, put a",
            "                # marker in the stack.",
            "                kw[\"transform_clue\"] = \"select_container\"",
            "                newelem._copy_internals(clone=visit, **kw)",
            "            elif newelem.is_selectable and newelem._is_select:",
            "                barrier_select = (",
            "                    kw.get(\"transform_clue\", None) == \"select_container\"",
            "                )",
            "                # if we're still descended from an",
            "                # Alias/CompoundSelect/ScalarSelect, we're",
            "                # in a FROM clause, so start with a new translate collection",
            "                if barrier_select:",
            "                    column_translate.append({})",
            "                kw[\"transform_clue\"] = \"inside_select\"",
            "                newelem._copy_internals(clone=visit, **kw)",
            "                if barrier_select:",
            "                    del column_translate[-1]",
            "            else:",
            "                newelem._copy_internals(clone=visit, **kw)",
            "",
            "            return newelem",
            "",
            "        return visit(select)",
            "",
            "    def _transform_result_map_for_nested_joins(",
            "        self, select, transformed_select",
            "    ):",
            "        inner_col = dict(",
            "            (c._key_label, c) for c in transformed_select.inner_columns",
            "        )",
            "",
            "        d = dict((inner_col[c._key_label], c) for c in select.inner_columns)",
            "",
            "        self._result_columns = [",
            "            (key, name, tuple([d.get(col, col) for col in objs]), typ)",
            "            for key, name, objs, typ in self._result_columns",
            "        ]",
            "",
            "    _default_stack_entry = util.immutabledict(",
            "        [(\"correlate_froms\", frozenset()), (\"asfrom_froms\", frozenset())]",
            "    )",
            "",
            "    def _display_froms_for_select(self, select, asfrom, lateral=False):",
            "        # utility method to help external dialects",
            "        # get the correct from list for a select.",
            "        # specifically the oracle dialect needs this feature",
            "        # right now.",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        correlate_froms = entry[\"correlate_froms\"]",
            "        asfrom_froms = entry[\"asfrom_froms\"]",
            "",
            "        if asfrom and not lateral:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms.difference(",
            "                    asfrom_froms",
            "                ),",
            "                implicit_correlate_froms=(),",
            "            )",
            "        else:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms,",
            "                implicit_correlate_froms=asfrom_froms,",
            "            )",
            "        return froms",
            "",
            "    def visit_select(",
            "        self,",
            "        select,",
            "        asfrom=False,",
            "        parens=True,",
            "        fromhints=None,",
            "        compound_index=0,",
            "        nested_join_translation=False,",
            "        select_wraps_for=None,",
            "        lateral=False,",
            "        **kwargs",
            "    ):",
            "",
            "        needs_nested_translation = (",
            "            select.use_labels",
            "            and not nested_join_translation",
            "            and not self.stack",
            "            and not self.dialect.supports_right_nested_joins",
            "        )",
            "",
            "        if needs_nested_translation:",
            "            transformed_select = self._transform_select_for_nested_joins(",
            "                select",
            "            )",
            "            text = self.visit_select(",
            "                transformed_select,",
            "                asfrom=asfrom,",
            "                parens=parens,",
            "                fromhints=fromhints,",
            "                compound_index=compound_index,",
            "                nested_join_translation=True,",
            "                **kwargs",
            "            )",
            "",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        populate_result_map = (",
            "            toplevel",
            "            or (",
            "                compound_index == 0",
            "                and entry.get(\"need_result_map_for_compound\", False)",
            "            )",
            "            or entry.get(\"need_result_map_for_nested\", False)",
            "        )",
            "",
            "        # this was first proposed as part of #3372; however, it is not",
            "        # reached in current tests and could possibly be an assertion",
            "        # instead.",
            "        if not populate_result_map and \"add_to_result_map\" in kwargs:",
            "            del kwargs[\"add_to_result_map\"]",
            "",
            "        if needs_nested_translation:",
            "            if populate_result_map:",
            "                self._transform_result_map_for_nested_joins(",
            "                    select, transformed_select",
            "                )",
            "            return text",
            "",
            "        froms = self._setup_select_stack(select, entry, asfrom, lateral)",
            "",
            "        column_clause_args = kwargs.copy()",
            "        column_clause_args.update(",
            "            {\"within_label_clause\": False, \"within_columns_clause\": False}",
            "        )",
            "",
            "        text = \"SELECT \"  # we're off to a good start !",
            "",
            "        if select._hints:",
            "            hint_text, byfrom = self._setup_select_hints(select)",
            "            if hint_text:",
            "                text += hint_text + \" \"",
            "        else:",
            "            byfrom = None",
            "",
            "        if select._prefixes:",
            "            text += self._generate_prefixes(select, select._prefixes, **kwargs)",
            "",
            "        text += self.get_select_precolumns(select, **kwargs)",
            "        # the actual list of columns to print in the SELECT column list.",
            "        inner_columns = [",
            "            c",
            "            for c in [",
            "                self._label_select_column(",
            "                    select,",
            "                    column,",
            "                    populate_result_map,",
            "                    asfrom,",
            "                    column_clause_args,",
            "                    name=name,",
            "                )",
            "                for name, column in select._columns_plus_names",
            "            ]",
            "            if c is not None",
            "        ]",
            "",
            "        if populate_result_map and select_wraps_for is not None:",
            "            # if this select is a compiler-generated wrapper,",
            "            # rewrite the targeted columns in the result map",
            "",
            "            translate = dict(",
            "                zip(",
            "                    [name for (key, name) in select._columns_plus_names],",
            "                    [",
            "                        name",
            "                        for (key, name) in select_wraps_for._columns_plus_names",
            "                    ],",
            "                )",
            "            )",
            "",
            "            self._result_columns = [",
            "                (key, name, tuple(translate.get(o, o) for o in obj), type_)",
            "                for key, name, obj, type_ in self._result_columns",
            "            ]",
            "",
            "        text = self._compose_select_body(",
            "            text, select, inner_columns, froms, byfrom, kwargs",
            "        )",
            "",
            "        if select._statement_hints:",
            "            per_dialect = [",
            "                ht",
            "                for (dialect_name, ht) in select._statement_hints",
            "                if dialect_name in (\"*\", self.dialect.name)",
            "            ]",
            "            if per_dialect:",
            "                text += \" \" + self.get_statement_hint_text(per_dialect)",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        if select._suffixes:",
            "            text += \" \" + self._generate_prefixes(",
            "                select, select._suffixes, **kwargs",
            "            )",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if (asfrom or lateral) and parens:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def _setup_select_hints(self, select):",
            "        byfrom = dict(",
            "            [",
            "                (",
            "                    from_,",
            "                    hinttext",
            "                    % {\"name\": from_._compiler_dispatch(self, ashint=True)},",
            "                )",
            "                for (from_, dialect), hinttext in select._hints.items()",
            "                if dialect in (\"*\", self.dialect.name)",
            "            ]",
            "        )",
            "        hint_text = self.get_select_hint_text(byfrom)",
            "        return hint_text, byfrom",
            "",
            "    def _setup_select_stack(self, select, entry, asfrom, lateral):",
            "        correlate_froms = entry[\"correlate_froms\"]",
            "        asfrom_froms = entry[\"asfrom_froms\"]",
            "",
            "        if asfrom and not lateral:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms.difference(",
            "                    asfrom_froms",
            "                ),",
            "                implicit_correlate_froms=(),",
            "            )",
            "        else:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms,",
            "                implicit_correlate_froms=asfrom_froms,",
            "            )",
            "",
            "        new_correlate_froms = set(selectable._from_objects(*froms))",
            "        all_correlate_froms = new_correlate_froms.union(correlate_froms)",
            "",
            "        new_entry = {",
            "            \"asfrom_froms\": new_correlate_froms,",
            "            \"correlate_froms\": all_correlate_froms,",
            "            \"selectable\": select,",
            "        }",
            "        self.stack.append(new_entry)",
            "",
            "        return froms",
            "",
            "    def _compose_select_body(",
            "        self, text, select, inner_columns, froms, byfrom, kwargs",
            "    ):",
            "        text += \", \".join(inner_columns)",
            "",
            "        if froms:",
            "            text += \" \\nFROM \"",
            "",
            "            if select._hints:",
            "                text += \", \".join(",
            "                    [",
            "                        f._compiler_dispatch(",
            "                            self, asfrom=True, fromhints=byfrom, **kwargs",
            "                        )",
            "                        for f in froms",
            "                    ]",
            "                )",
            "            else:",
            "                text += \", \".join(",
            "                    [",
            "                        f._compiler_dispatch(self, asfrom=True, **kwargs)",
            "                        for f in froms",
            "                    ]",
            "                )",
            "        else:",
            "            text += self.default_from()",
            "",
            "        if select._whereclause is not None:",
            "            t = select._whereclause._compiler_dispatch(self, **kwargs)",
            "            if t:",
            "                text += \" \\nWHERE \" + t",
            "",
            "        if select._group_by_clause.clauses:",
            "            text += self.group_by_clause(select, **kwargs)",
            "",
            "        if select._having is not None:",
            "            t = select._having._compiler_dispatch(self, **kwargs)",
            "            if t:",
            "                text += \" \\nHAVING \" + t",
            "",
            "        if select._order_by_clause.clauses:",
            "            text += self.order_by_clause(select, **kwargs)",
            "",
            "        if (",
            "            select._limit_clause is not None",
            "            or select._offset_clause is not None",
            "        ):",
            "            text += self.limit_clause(select, **kwargs)",
            "",
            "        if select._for_update_arg is not None:",
            "            text += self.for_update_clause(select, **kwargs)",
            "",
            "        return text",
            "",
            "    def _generate_prefixes(self, stmt, prefixes, **kw):",
            "        clause = \" \".join(",
            "            prefix._compiler_dispatch(self, **kw)",
            "            for prefix, dialect_name in prefixes",
            "            if dialect_name is None or dialect_name == self.dialect.name",
            "        )",
            "        if clause:",
            "            clause += \" \"",
            "        return clause",
            "",
            "    def _render_cte_clause(self):",
            "        if self.positional:",
            "            self.positiontup = (",
            "                sum([self.cte_positional[cte] for cte in self.ctes], [])",
            "                + self.positiontup",
            "            )",
            "        cte_text = self.get_cte_preamble(self.ctes_recursive) + \" \"",
            "        cte_text += \", \\n\".join([txt for txt in self.ctes.values()])",
            "        cte_text += \"\\n \"",
            "        return cte_text",
            "",
            "    def get_cte_preamble(self, recursive):",
            "        if recursive:",
            "            return \"WITH RECURSIVE\"",
            "        else:",
            "            return \"WITH\"",
            "",
            "    def get_select_precolumns(self, select, **kw):",
            "        \"\"\"Called when building a ``SELECT`` statement, position is just",
            "        before column list.",
            "",
            "        \"\"\"",
            "        return select._distinct and \"DISTINCT \" or \"\"",
            "",
            "    def group_by_clause(self, select, **kw):",
            "        \"\"\"allow dialects to customize how GROUP BY is rendered.\"\"\"",
            "",
            "        group_by = select._group_by_clause._compiler_dispatch(self, **kw)",
            "        if group_by:",
            "            return \" GROUP BY \" + group_by",
            "        else:",
            "            return \"\"",
            "",
            "    def order_by_clause(self, select, **kw):",
            "        \"\"\"allow dialects to customize how ORDER BY is rendered.\"\"\"",
            "",
            "        order_by = select._order_by_clause._compiler_dispatch(self, **kw)",
            "        if order_by:",
            "            return \" ORDER BY \" + order_by",
            "        else:",
            "            return \"\"",
            "",
            "    def for_update_clause(self, select, **kw):",
            "        return \" FOR UPDATE\"",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "        raise exc.CompileError(",
            "            \"RETURNING is not supported by this \"",
            "            \"dialect's statement compiler.\"",
            "        )",
            "",
            "    def limit_clause(self, select, **kw):",
            "        text = \"\"",
            "        if select._limit_clause is not None:",
            "            text += \"\\n LIMIT \" + self.process(select._limit_clause, **kw)",
            "        if select._offset_clause is not None:",
            "            if select._limit_clause is None:",
            "                text += \"\\n LIMIT -1\"",
            "            text += \" OFFSET \" + self.process(select._offset_clause, **kw)",
            "        return text",
            "",
            "    def visit_table(",
            "        self,",
            "        table,",
            "        asfrom=False,",
            "        iscrud=False,",
            "        ashint=False,",
            "        fromhints=None,",
            "        use_schema=True,",
            "        **kwargs",
            "    ):",
            "        if asfrom or ashint:",
            "            effective_schema = self.preparer.schema_for_object(table)",
            "",
            "            if use_schema and effective_schema:",
            "                ret = (",
            "                    self.preparer.quote_schema(effective_schema)",
            "                    + \".\"",
            "                    + self.preparer.quote(table.name)",
            "                )",
            "            else:",
            "                ret = self.preparer.quote(table.name)",
            "            if fromhints and table in fromhints:",
            "                ret = self.format_from_hint_text(",
            "                    ret, table, fromhints[table], iscrud",
            "                )",
            "            return ret",
            "        else:",
            "            return \"\"",
            "",
            "    def visit_join(self, join, asfrom=False, **kwargs):",
            "        if join.full:",
            "            join_type = \" FULL OUTER JOIN \"",
            "        elif join.isouter:",
            "            join_type = \" LEFT OUTER JOIN \"",
            "        else:",
            "            join_type = \" JOIN \"",
            "        return (",
            "            join.left._compiler_dispatch(self, asfrom=True, **kwargs)",
            "            + join_type",
            "            + join.right._compiler_dispatch(self, asfrom=True, **kwargs)",
            "            + \" ON \"",
            "            + join.onclause._compiler_dispatch(self, **kwargs)",
            "        )",
            "",
            "    def _setup_crud_hints(self, stmt, table_text):",
            "        dialect_hints = dict(",
            "            [",
            "                (table, hint_text)",
            "                for (table, dialect), hint_text in stmt._hints.items()",
            "                if dialect in (\"*\", self.dialect.name)",
            "            ]",
            "        )",
            "        if stmt.table in dialect_hints:",
            "            table_text = self.format_from_hint_text(",
            "                table_text, stmt.table, dialect_hints[stmt.table], True",
            "            )",
            "        return dialect_hints, table_text",
            "",
            "    def visit_insert(self, insert_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": set(),",
            "                \"asfrom_froms\": set(),",
            "                \"selectable\": insert_stmt,",
            "            }",
            "        )",
            "",
            "        crud_params = crud._setup_crud_params(",
            "            self, insert_stmt, crud.ISINSERT, **kw",
            "        )",
            "",
            "        if (",
            "            not crud_params",
            "            and not self.dialect.supports_default_values",
            "            and not self.dialect.supports_empty_insert",
            "        ):",
            "            raise exc.CompileError(",
            "                \"The '%s' dialect with current database \"",
            "                \"version settings does not support empty \"",
            "                \"inserts.\" % self.dialect.name",
            "            )",
            "",
            "        if insert_stmt._has_multi_parameters:",
            "            if not self.dialect.supports_multivalues_insert:",
            "                raise exc.CompileError(",
            "                    \"The '%s' dialect with current database \"",
            "                    \"version settings does not support \"",
            "                    \"in-place multirow inserts.\" % self.dialect.name",
            "                )",
            "            crud_params_single = crud_params[0]",
            "        else:",
            "            crud_params_single = crud_params",
            "",
            "        preparer = self.preparer",
            "        supports_default_values = self.dialect.supports_default_values",
            "",
            "        text = \"INSERT \"",
            "",
            "        if insert_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                insert_stmt, insert_stmt._prefixes, **kw",
            "            )",
            "",
            "        text += \"INTO \"",
            "        table_text = preparer.format_table(insert_stmt.table)",
            "",
            "        if insert_stmt._hints:",
            "            _, table_text = self._setup_crud_hints(insert_stmt, table_text)",
            "",
            "        text += table_text",
            "",
            "        if crud_params_single or not supports_default_values:",
            "            text += \" (%s)\" % \", \".join(",
            "                [preparer.format_column(c[0]) for c in crud_params_single]",
            "            )",
            "",
            "        if self.returning or insert_stmt._returning:",
            "            returning_clause = self.returning_clause(",
            "                insert_stmt, self.returning or insert_stmt._returning",
            "            )",
            "",
            "            if self.returning_precedes_values:",
            "                text += \" \" + returning_clause",
            "        else:",
            "            returning_clause = None",
            "",
            "        if insert_stmt.select is not None:",
            "            select_text = self.process(self._insert_from_select, **kw)",
            "",
            "            if self.ctes and toplevel and self.dialect.cte_follows_insert:",
            "                text += \" %s%s\" % (self._render_cte_clause(), select_text)",
            "            else:",
            "                text += \" %s\" % select_text",
            "        elif not crud_params and supports_default_values:",
            "            text += \" DEFAULT VALUES\"",
            "        elif insert_stmt._has_multi_parameters:",
            "            text += \" VALUES %s\" % (",
            "                \", \".join(",
            "                    \"(%s)\" % (\", \".join(c[1] for c in crud_param_set))",
            "                    for crud_param_set in crud_params",
            "                )",
            "            )",
            "        else:",
            "            text += \" VALUES (%s)\" % \", \".join([c[1] for c in crud_params])",
            "",
            "        if insert_stmt._post_values_clause is not None:",
            "            post_values_clause = self.process(",
            "                insert_stmt._post_values_clause, **kw",
            "            )",
            "            if post_values_clause:",
            "                text += \" \" + post_values_clause",
            "",
            "        if returning_clause and not self.returning_precedes_values:",
            "            text += \" \" + returning_clause",
            "",
            "        if self.ctes and toplevel and not self.dialect.cte_follows_insert:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def update_limit_clause(self, update_stmt):",
            "        \"\"\"Provide a hook for MySQL to add LIMIT to the UPDATE\"\"\"",
            "        return None",
            "",
            "    def update_tables_clause(self, update_stmt, from_table, extra_froms, **kw):",
            "        \"\"\"Provide a hook to override the initial table clause",
            "        in an UPDATE statement.",
            "",
            "        MySQL overrides this.",
            "",
            "        \"\"\"",
            "        kw[\"asfrom\"] = True",
            "        return from_table._compiler_dispatch(self, iscrud=True, **kw)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Provide a hook to override the generation of an",
            "        UPDATE..FROM clause.",
            "",
            "        MySQL and MSSQL override this.",
            "",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"This backend does not support multiple-table \"",
            "            \"criteria within UPDATE\"",
            "        )",
            "",
            "    def visit_update(self, update_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        extra_froms = update_stmt._extra_froms",
            "        is_multitable = bool(extra_froms)",
            "",
            "        if is_multitable:",
            "            # main table might be a JOIN",
            "            main_froms = set(selectable._from_objects(update_stmt.table))",
            "            render_extra_froms = [",
            "                f for f in extra_froms if f not in main_froms",
            "            ]",
            "            correlate_froms = main_froms.union(extra_froms)",
            "        else:",
            "            render_extra_froms = []",
            "            correlate_froms = {update_stmt.table}",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": correlate_froms,",
            "                \"asfrom_froms\": correlate_froms,",
            "                \"selectable\": update_stmt,",
            "            }",
            "        )",
            "",
            "        text = \"UPDATE \"",
            "",
            "        if update_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                update_stmt, update_stmt._prefixes, **kw",
            "            )",
            "",
            "        table_text = self.update_tables_clause(",
            "            update_stmt, update_stmt.table, render_extra_froms, **kw",
            "        )",
            "        crud_params = crud._setup_crud_params(",
            "            self, update_stmt, crud.ISUPDATE, **kw",
            "        )",
            "",
            "        if update_stmt._hints:",
            "            dialect_hints, table_text = self._setup_crud_hints(",
            "                update_stmt, table_text",
            "            )",
            "        else:",
            "            dialect_hints = None",
            "",
            "        text += table_text",
            "",
            "        text += \" SET \"",
            "        include_table = (",
            "            is_multitable and self.render_table_with_column_in_update_from",
            "        )",
            "        text += \", \".join(",
            "            c[0]._compiler_dispatch(self, include_table=include_table)",
            "            + \"=\"",
            "            + c[1]",
            "            for c in crud_params",
            "        )",
            "",
            "        if self.returning or update_stmt._returning:",
            "            if self.returning_precedes_values:",
            "                text += \" \" + self.returning_clause(",
            "                    update_stmt, self.returning or update_stmt._returning",
            "                )",
            "",
            "        if extra_froms:",
            "            extra_from_text = self.update_from_clause(",
            "                update_stmt,",
            "                update_stmt.table,",
            "                render_extra_froms,",
            "                dialect_hints,",
            "                **kw",
            "            )",
            "            if extra_from_text:",
            "                text += \" \" + extra_from_text",
            "",
            "        if update_stmt._whereclause is not None:",
            "            t = self.process(update_stmt._whereclause, **kw)",
            "            if t:",
            "                text += \" WHERE \" + t",
            "",
            "        limit_clause = self.update_limit_clause(update_stmt)",
            "        if limit_clause:",
            "            text += \" \" + limit_clause",
            "",
            "        if (",
            "            self.returning or update_stmt._returning",
            "        ) and not self.returning_precedes_values:",
            "            text += \" \" + self.returning_clause(",
            "                update_stmt, self.returning or update_stmt._returning",
            "            )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    @util.memoized_property",
            "    def _key_getters_for_crud_column(self):",
            "        return crud._key_getters_for_crud_column(self, self.statement)",
            "",
            "    def delete_extra_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Provide a hook to override the generation of an",
            "        DELETE..FROM clause.",
            "",
            "        This can be used to implement DELETE..USING for example.",
            "",
            "        MySQL and MSSQL override this.",
            "",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"This backend does not support multiple-table \"",
            "            \"criteria within DELETE\"",
            "        )",
            "",
            "    def delete_table_clause(self, delete_stmt, from_table, extra_froms):",
            "        return from_table._compiler_dispatch(self, asfrom=True, iscrud=True)",
            "",
            "    def visit_delete(self, delete_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        crud._setup_crud_params(self, delete_stmt, crud.ISDELETE, **kw)",
            "",
            "        extra_froms = delete_stmt._extra_froms",
            "",
            "        correlate_froms = {delete_stmt.table}.union(extra_froms)",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": correlate_froms,",
            "                \"asfrom_froms\": correlate_froms,",
            "                \"selectable\": delete_stmt,",
            "            }",
            "        )",
            "",
            "        text = \"DELETE \"",
            "",
            "        if delete_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                delete_stmt, delete_stmt._prefixes, **kw",
            "            )",
            "",
            "        text += \"FROM \"",
            "        table_text = self.delete_table_clause(",
            "            delete_stmt, delete_stmt.table, extra_froms",
            "        )",
            "",
            "        if delete_stmt._hints:",
            "            dialect_hints, table_text = self._setup_crud_hints(",
            "                delete_stmt, table_text",
            "            )",
            "        else:",
            "            dialect_hints = None",
            "",
            "        text += table_text",
            "",
            "        if delete_stmt._returning:",
            "            if self.returning_precedes_values:",
            "                text += \" \" + self.returning_clause(",
            "                    delete_stmt, delete_stmt._returning",
            "                )",
            "",
            "        if extra_froms:",
            "            extra_from_text = self.delete_extra_from_clause(",
            "                delete_stmt,",
            "                delete_stmt.table,",
            "                extra_froms,",
            "                dialect_hints,",
            "                **kw",
            "            )",
            "            if extra_from_text:",
            "                text += \" \" + extra_from_text",
            "",
            "        if delete_stmt._whereclause is not None:",
            "            t = delete_stmt._whereclause._compiler_dispatch(self, **kw)",
            "            if t:",
            "                text += \" WHERE \" + t",
            "",
            "        if delete_stmt._returning and not self.returning_precedes_values:",
            "            text += \" \" + self.returning_clause(",
            "                delete_stmt, delete_stmt._returning",
            "            )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def visit_savepoint(self, savepoint_stmt):",
            "        return \"SAVEPOINT %s\" % self.preparer.format_savepoint(savepoint_stmt)",
            "",
            "    def visit_rollback_to_savepoint(self, savepoint_stmt):",
            "        return \"ROLLBACK TO SAVEPOINT %s\" % self.preparer.format_savepoint(",
            "            savepoint_stmt",
            "        )",
            "",
            "    def visit_release_savepoint(self, savepoint_stmt):",
            "        return \"RELEASE SAVEPOINT %s\" % self.preparer.format_savepoint(",
            "            savepoint_stmt",
            "        )",
            "",
            "",
            "class StrSQLCompiler(SQLCompiler):",
            "    \"\"\"\"a compiler subclass with a few non-standard SQL features allowed.",
            "",
            "    Used for stringification of SQL statements when a real dialect is not",
            "    available.",
            "",
            "    \"\"\"",
            "",
            "    def _fallback_column_name(self, column):",
            "        return \"<name unknown>\"",
            "",
            "    def visit_getitem_binary(self, binary, operator, **kw):",
            "        return \"%s[%s]\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_json_getitem_op_binary(self, binary, operator, **kw):",
            "        return self.visit_getitem_binary(binary, operator, **kw)",
            "",
            "    def visit_json_path_getitem_op_binary(self, binary, operator, **kw):",
            "        return self.visit_getitem_binary(binary, operator, **kw)",
            "",
            "    def visit_sequence(self, seq, **kw):",
            "        return \"<next sequence value: %s>\" % self.preparer.format_sequence(seq)",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "        columns = [",
            "            self._label_select_column(None, c, True, False, {})",
            "            for c in elements._select_iterables(returning_cols)",
            "        ]",
            "",
            "        return \"RETURNING \" + \", \".join(columns)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \"FROM \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "    def delete_extra_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \", \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "",
            "class DDLCompiler(Compiled):",
            "    @util.memoized_property",
            "    def sql_compiler(self):",
            "        return self.dialect.statement_compiler(self.dialect, None)",
            "",
            "    @util.memoized_property",
            "    def type_compiler(self):",
            "        return self.dialect.type_compiler",
            "",
            "    def construct_params(self, params=None):",
            "        return None",
            "",
            "    def visit_ddl(self, ddl, **kwargs):",
            "        # table events can substitute table and schema name",
            "        context = ddl.context",
            "        if isinstance(ddl.target, schema.Table):",
            "            context = context.copy()",
            "",
            "            preparer = self.preparer",
            "            path = preparer.format_table_seq(ddl.target)",
            "            if len(path) == 1:",
            "                table, sch = path[0], \"\"",
            "            else:",
            "                table, sch = path[-1], path[0]",
            "",
            "            context.setdefault(\"table\", table)",
            "            context.setdefault(\"schema\", sch)",
            "            context.setdefault(\"fullname\", preparer.format_table(ddl.target))",
            "",
            "        return self.sql_compiler.post_process_text(ddl.statement % context)",
            "",
            "    def visit_create_schema(self, create):",
            "        schema = self.preparer.format_schema(create.element)",
            "        return \"CREATE SCHEMA \" + schema",
            "",
            "    def visit_drop_schema(self, drop):",
            "        schema = self.preparer.format_schema(drop.element)",
            "        text = \"DROP SCHEMA \" + schema",
            "        if drop.cascade:",
            "            text += \" CASCADE\"",
            "        return text",
            "",
            "    def visit_create_table(self, create):",
            "        table = create.element",
            "        preparer = self.preparer",
            "",
            "        text = \"\\nCREATE \"",
            "        if table._prefixes:",
            "            text += \" \".join(table._prefixes) + \" \"",
            "        text += \"TABLE \" + preparer.format_table(table) + \" \"",
            "",
            "        create_table_suffix = self.create_table_suffix(table)",
            "        if create_table_suffix:",
            "            text += create_table_suffix + \" \"",
            "",
            "        text += \"(\"",
            "",
            "        separator = \"\\n\"",
            "",
            "        # if only one primary key, specify it along with the column",
            "        first_pk = False",
            "        for create_column in create.columns:",
            "            column = create_column.element",
            "            try:",
            "                processed = self.process(",
            "                    create_column, first_pk=column.primary_key and not first_pk",
            "                )",
            "                if processed is not None:",
            "                    text += separator",
            "                    separator = \", \\n\"",
            "                    text += \"\\t\" + processed",
            "                if column.primary_key:",
            "                    first_pk = True",
            "            except exc.CompileError as ce:",
            "                util.raise_from_cause(",
            "                    exc.CompileError(",
            "                        util.u(\"(in table '%s', column '%s'): %s\")",
            "                        % (table.description, column.name, ce.args[0])",
            "                    )",
            "                )",
            "",
            "        const = self.create_table_constraints(",
            "            table,",
            "            _include_foreign_key_constraints=create.include_foreign_key_constraints,  # noqa",
            "        )",
            "        if const:",
            "            text += separator + \"\\t\" + const",
            "",
            "        text += \"\\n)%s\\n\\n\" % self.post_create_table(table)",
            "        return text",
            "",
            "    def visit_create_column(self, create, first_pk=False):",
            "        column = create.element",
            "",
            "        if column.system:",
            "            return None",
            "",
            "        text = self.get_column_specification(column, first_pk=first_pk)",
            "        const = \" \".join(",
            "            self.process(constraint) for constraint in column.constraints",
            "        )",
            "        if const:",
            "            text += \" \" + const",
            "",
            "        return text",
            "",
            "    def create_table_constraints(",
            "        self, table, _include_foreign_key_constraints=None",
            "    ):",
            "",
            "        # On some DB order is significant: visit PK first, then the",
            "        # other constraints (engine.ReflectionTest.testbasic failed on FB2)",
            "        constraints = []",
            "        if table.primary_key:",
            "            constraints.append(table.primary_key)",
            "",
            "        all_fkcs = table.foreign_key_constraints",
            "        if _include_foreign_key_constraints is not None:",
            "            omit_fkcs = all_fkcs.difference(_include_foreign_key_constraints)",
            "        else:",
            "            omit_fkcs = set()",
            "",
            "        constraints.extend(",
            "            [",
            "                c",
            "                for c in table._sorted_constraints",
            "                if c is not table.primary_key and c not in omit_fkcs",
            "            ]",
            "        )",
            "",
            "        return \", \\n\\t\".join(",
            "            p",
            "            for p in (",
            "                self.process(constraint)",
            "                for constraint in constraints",
            "                if (",
            "                    constraint._create_rule is None",
            "                    or constraint._create_rule(self)",
            "                )",
            "                and (",
            "                    not self.dialect.supports_alter",
            "                    or not getattr(constraint, \"use_alter\", False)",
            "                )",
            "            )",
            "            if p is not None",
            "        )",
            "",
            "    def visit_drop_table(self, drop):",
            "        return \"\\nDROP TABLE \" + self.preparer.format_table(drop.element)",
            "",
            "    def visit_drop_view(self, drop):",
            "        return \"\\nDROP VIEW \" + self.preparer.format_table(drop.element)",
            "",
            "    def _verify_index_table(self, index):",
            "        if index.table is None:",
            "            raise exc.CompileError(",
            "                \"Index '%s' is not associated \" \"with any table.\" % index.name",
            "            )",
            "",
            "    def visit_create_index(",
            "        self, create, include_schema=False, include_table_schema=True",
            "    ):",
            "        index = create.element",
            "        self._verify_index_table(index)",
            "        preparer = self.preparer",
            "        text = \"CREATE \"",
            "        if index.unique:",
            "            text += \"UNIQUE \"",
            "        text += \"INDEX %s ON %s (%s)\" % (",
            "            self._prepared_index_name(index, include_schema=include_schema),",
            "            preparer.format_table(",
            "                index.table, use_schema=include_table_schema",
            "            ),",
            "            \", \".join(",
            "                self.sql_compiler.process(",
            "                    expr, include_table=False, literal_binds=True",
            "                )",
            "                for expr in index.expressions",
            "            ),",
            "        )",
            "        return text",
            "",
            "    def visit_drop_index(self, drop):",
            "        index = drop.element",
            "        return \"\\nDROP INDEX \" + self._prepared_index_name(",
            "            index, include_schema=True",
            "        )",
            "",
            "    def _prepared_index_name(self, index, include_schema=False):",
            "        if index.table is not None:",
            "            effective_schema = self.preparer.schema_for_object(index.table)",
            "        else:",
            "            effective_schema = None",
            "        if include_schema and effective_schema:",
            "            schema_name = self.preparer.quote_schema(effective_schema)",
            "        else:",
            "            schema_name = None",
            "",
            "        index_name = self.preparer.format_index(index)",
            "",
            "        if schema_name:",
            "            index_name = schema_name + \".\" + index_name",
            "        return index_name",
            "",
            "    def visit_add_constraint(self, create):",
            "        return \"ALTER TABLE %s ADD %s\" % (",
            "            self.preparer.format_table(create.element.table),",
            "            self.process(create.element),",
            "        )",
            "",
            "    def visit_set_table_comment(self, create):",
            "        return \"COMMENT ON TABLE %s IS %s\" % (",
            "            self.preparer.format_table(create.element),",
            "            self.sql_compiler.render_literal_value(",
            "                create.element.comment, sqltypes.String()",
            "            ),",
            "        )",
            "",
            "    def visit_drop_table_comment(self, drop):",
            "        return \"COMMENT ON TABLE %s IS NULL\" % self.preparer.format_table(",
            "            drop.element",
            "        )",
            "",
            "    def visit_set_column_comment(self, create):",
            "        return \"COMMENT ON COLUMN %s IS %s\" % (",
            "            self.preparer.format_column(",
            "                create.element, use_table=True, use_schema=True",
            "            ),",
            "            self.sql_compiler.render_literal_value(",
            "                create.element.comment, sqltypes.String()",
            "            ),",
            "        )",
            "",
            "    def visit_drop_column_comment(self, drop):",
            "        return \"COMMENT ON COLUMN %s IS NULL\" % self.preparer.format_column(",
            "            drop.element, use_table=True",
            "        )",
            "",
            "    def visit_create_sequence(self, create):",
            "        text = \"CREATE SEQUENCE %s\" % self.preparer.format_sequence(",
            "            create.element",
            "        )",
            "        if create.element.increment is not None:",
            "            text += \" INCREMENT BY %d\" % create.element.increment",
            "        if create.element.start is not None:",
            "            text += \" START WITH %d\" % create.element.start",
            "        if create.element.minvalue is not None:",
            "            text += \" MINVALUE %d\" % create.element.minvalue",
            "        if create.element.maxvalue is not None:",
            "            text += \" MAXVALUE %d\" % create.element.maxvalue",
            "        if create.element.nominvalue is not None:",
            "            text += \" NO MINVALUE\"",
            "        if create.element.nomaxvalue is not None:",
            "            text += \" NO MAXVALUE\"",
            "        if create.element.cache is not None:",
            "            text += \" CACHE %d\" % create.element.cache",
            "        if create.element.order is True:",
            "            text += \" ORDER\"",
            "        if create.element.cycle is not None:",
            "            text += \" CYCLE\"",
            "        return text",
            "",
            "    def visit_drop_sequence(self, drop):",
            "        return \"DROP SEQUENCE %s\" % self.preparer.format_sequence(drop.element)",
            "",
            "    def visit_drop_constraint(self, drop):",
            "        constraint = drop.element",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "        else:",
            "            formatted_name = None",
            "",
            "        if formatted_name is None:",
            "            raise exc.CompileError(",
            "                \"Can't emit DROP CONSTRAINT for constraint %r; \"",
            "                \"it has no name\" % drop.element",
            "            )",
            "        return \"ALTER TABLE %s DROP CONSTRAINT %s%s\" % (",
            "            self.preparer.format_table(drop.element.table),",
            "            formatted_name,",
            "            drop.cascade and \" CASCADE\" or \"\",",
            "        )",
            "",
            "    def get_column_specification(self, column, **kwargs):",
            "        colspec = (",
            "            self.preparer.format_column(column)",
            "            + \" \"",
            "            + self.dialect.type_compiler.process(",
            "                column.type, type_expression=column",
            "            )",
            "        )",
            "        default = self.get_column_default_string(column)",
            "        if default is not None:",
            "            colspec += \" DEFAULT \" + default",
            "",
            "        if not column.nullable:",
            "            colspec += \" NOT NULL\"",
            "        return colspec",
            "",
            "    def create_table_suffix(self, table):",
            "        return \"\"",
            "",
            "    def post_create_table(self, table):",
            "        return \"\"",
            "",
            "    def get_column_default_string(self, column):",
            "        if isinstance(column.server_default, schema.DefaultClause):",
            "            if isinstance(column.server_default.arg, util.string_types):",
            "                return self.sql_compiler.render_literal_value(",
            "                    column.server_default.arg, sqltypes.STRINGTYPE",
            "                )",
            "            else:",
            "                return self.sql_compiler.process(",
            "                    column.server_default.arg, literal_binds=True",
            "                )",
            "        else:",
            "            return None",
            "",
            "    def visit_check_constraint(self, constraint):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"CHECK (%s)\" % self.sql_compiler.process(",
            "            constraint.sqltext, include_table=False, literal_binds=True",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_column_check_constraint(self, constraint):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"CHECK (%s)\" % self.sql_compiler.process(",
            "            constraint.sqltext, include_table=False, literal_binds=True",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_primary_key_constraint(self, constraint):",
            "        if len(constraint) == 0:",
            "            return \"\"",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"PRIMARY KEY \"",
            "        text += \"(%s)\" % \", \".join(",
            "            self.preparer.quote(c.name)",
            "            for c in (",
            "                constraint.columns_autoinc_first",
            "                if constraint._implicit_generated",
            "                else constraint.columns",
            "            )",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_foreign_key_constraint(self, constraint):",
            "        preparer = self.preparer",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        remote_table = list(constraint.elements)[0].column.table",
            "        text += \"FOREIGN KEY(%s) REFERENCES %s (%s)\" % (",
            "            \", \".join(",
            "                preparer.quote(f.parent.name) for f in constraint.elements",
            "            ),",
            "            self.define_constraint_remote_table(",
            "                constraint, remote_table, preparer",
            "            ),",
            "            \", \".join(",
            "                preparer.quote(f.column.name) for f in constraint.elements",
            "            ),",
            "        )",
            "        text += self.define_constraint_match(constraint)",
            "        text += self.define_constraint_cascades(constraint)",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def define_constraint_remote_table(self, constraint, table, preparer):",
            "        \"\"\"Format the remote table clause of a CREATE CONSTRAINT clause.\"\"\"",
            "",
            "        return preparer.format_table(table)",
            "",
            "    def visit_unique_constraint(self, constraint):",
            "        if len(constraint) == 0:",
            "            return \"\"",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"UNIQUE (%s)\" % (",
            "            \", \".join(self.preparer.quote(c.name) for c in constraint)",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def define_constraint_cascades(self, constraint):",
            "        text = \"\"",
            "        if constraint.ondelete is not None:",
            "            text += \" ON DELETE %s\" % constraint.ondelete",
            "        if constraint.onupdate is not None:",
            "            text += \" ON UPDATE %s\" % constraint.onupdate",
            "        return text",
            "",
            "    def define_constraint_deferrability(self, constraint):",
            "        text = \"\"",
            "        if constraint.deferrable is not None:",
            "            if constraint.deferrable:",
            "                text += \" DEFERRABLE\"",
            "            else:",
            "                text += \" NOT DEFERRABLE\"",
            "        if constraint.initially is not None:",
            "            text += \" INITIALLY %s\" % constraint.initially",
            "        return text",
            "",
            "    def define_constraint_match(self, constraint):",
            "        text = \"\"",
            "        if constraint.match is not None:",
            "            text += \" MATCH %s\" % constraint.match",
            "        return text",
            "",
            "",
            "class GenericTypeCompiler(TypeCompiler):",
            "    def visit_FLOAT(self, type_, **kw):",
            "        return \"FLOAT\"",
            "",
            "    def visit_REAL(self, type_, **kw):",
            "        return \"REAL\"",
            "",
            "    def visit_NUMERIC(self, type_, **kw):",
            "        if type_.precision is None:",
            "            return \"NUMERIC\"",
            "        elif type_.scale is None:",
            "            return \"NUMERIC(%(precision)s)\" % {\"precision\": type_.precision}",
            "        else:",
            "            return \"NUMERIC(%(precision)s, %(scale)s)\" % {",
            "                \"precision\": type_.precision,",
            "                \"scale\": type_.scale,",
            "            }",
            "",
            "    def visit_DECIMAL(self, type_, **kw):",
            "        if type_.precision is None:",
            "            return \"DECIMAL\"",
            "        elif type_.scale is None:",
            "            return \"DECIMAL(%(precision)s)\" % {\"precision\": type_.precision}",
            "        else:",
            "            return \"DECIMAL(%(precision)s, %(scale)s)\" % {",
            "                \"precision\": type_.precision,",
            "                \"scale\": type_.scale,",
            "            }",
            "",
            "    def visit_INTEGER(self, type_, **kw):",
            "        return \"INTEGER\"",
            "",
            "    def visit_SMALLINT(self, type_, **kw):",
            "        return \"SMALLINT\"",
            "",
            "    def visit_BIGINT(self, type_, **kw):",
            "        return \"BIGINT\"",
            "",
            "    def visit_TIMESTAMP(self, type_, **kw):",
            "        return \"TIMESTAMP\"",
            "",
            "    def visit_DATETIME(self, type_, **kw):",
            "        return \"DATETIME\"",
            "",
            "    def visit_DATE(self, type_, **kw):",
            "        return \"DATE\"",
            "",
            "    def visit_TIME(self, type_, **kw):",
            "        return \"TIME\"",
            "",
            "    def visit_CLOB(self, type_, **kw):",
            "        return \"CLOB\"",
            "",
            "    def visit_NCLOB(self, type_, **kw):",
            "        return \"NCLOB\"",
            "",
            "    def _render_string_type(self, type_, name):",
            "",
            "        text = name",
            "        if type_.length:",
            "            text += \"(%d)\" % type_.length",
            "        if type_.collation:",
            "            text += ' COLLATE \"%s\"' % type_.collation",
            "        return text",
            "",
            "    def visit_CHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"CHAR\")",
            "",
            "    def visit_NCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"NCHAR\")",
            "",
            "    def visit_VARCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"VARCHAR\")",
            "",
            "    def visit_NVARCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"NVARCHAR\")",
            "",
            "    def visit_TEXT(self, type_, **kw):",
            "        return self._render_string_type(type_, \"TEXT\")",
            "",
            "    def visit_BLOB(self, type_, **kw):",
            "        return \"BLOB\"",
            "",
            "    def visit_BINARY(self, type_, **kw):",
            "        return \"BINARY\" + (type_.length and \"(%d)\" % type_.length or \"\")",
            "",
            "    def visit_VARBINARY(self, type_, **kw):",
            "        return \"VARBINARY\" + (type_.length and \"(%d)\" % type_.length or \"\")",
            "",
            "    def visit_BOOLEAN(self, type_, **kw):",
            "        return \"BOOLEAN\"",
            "",
            "    def visit_large_binary(self, type_, **kw):",
            "        return self.visit_BLOB(type_, **kw)",
            "",
            "    def visit_boolean(self, type_, **kw):",
            "        return self.visit_BOOLEAN(type_, **kw)",
            "",
            "    def visit_time(self, type_, **kw):",
            "        return self.visit_TIME(type_, **kw)",
            "",
            "    def visit_datetime(self, type_, **kw):",
            "        return self.visit_DATETIME(type_, **kw)",
            "",
            "    def visit_date(self, type_, **kw):",
            "        return self.visit_DATE(type_, **kw)",
            "",
            "    def visit_big_integer(self, type_, **kw):",
            "        return self.visit_BIGINT(type_, **kw)",
            "",
            "    def visit_small_integer(self, type_, **kw):",
            "        return self.visit_SMALLINT(type_, **kw)",
            "",
            "    def visit_integer(self, type_, **kw):",
            "        return self.visit_INTEGER(type_, **kw)",
            "",
            "    def visit_real(self, type_, **kw):",
            "        return self.visit_REAL(type_, **kw)",
            "",
            "    def visit_float(self, type_, **kw):",
            "        return self.visit_FLOAT(type_, **kw)",
            "",
            "    def visit_numeric(self, type_, **kw):",
            "        return self.visit_NUMERIC(type_, **kw)",
            "",
            "    def visit_string(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_unicode(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_text(self, type_, **kw):",
            "        return self.visit_TEXT(type_, **kw)",
            "",
            "    def visit_unicode_text(self, type_, **kw):",
            "        return self.visit_TEXT(type_, **kw)",
            "",
            "    def visit_enum(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_null(self, type_, **kw):",
            "        raise exc.CompileError(",
            "            \"Can't generate DDL for %r; \"",
            "            \"did you forget to specify a \"",
            "            \"type on this Column?\" % type_",
            "        )",
            "",
            "    def visit_type_decorator(self, type_, **kw):",
            "        return self.process(type_.type_engine(self.dialect), **kw)",
            "",
            "    def visit_user_defined(self, type_, **kw):",
            "        return type_.get_col_spec(**kw)",
            "",
            "",
            "class StrSQLTypeCompiler(GenericTypeCompiler):",
            "    def __getattr__(self, key):",
            "        if key.startswith(\"visit_\"):",
            "            return self._visit_unknown",
            "        else:",
            "            raise AttributeError(key)",
            "",
            "    def _visit_unknown(self, type_, **kw):",
            "        return \"%s\" % type_.__class__.__name__",
            "",
            "",
            "class IdentifierPreparer(object):",
            "",
            "    \"\"\"Handle quoting and case-folding of identifiers based on options.\"\"\"",
            "",
            "    reserved_words = RESERVED_WORDS",
            "",
            "    legal_characters = LEGAL_CHARACTERS",
            "",
            "    illegal_initial_characters = ILLEGAL_INITIAL_CHARACTERS",
            "",
            "    schema_for_object = schema._schema_getter(None)",
            "",
            "    def __init__(",
            "        self,",
            "        dialect,",
            "        initial_quote='\"',",
            "        final_quote=None,",
            "        escape_quote='\"',",
            "        quote_case_sensitive_collations=True,",
            "        omit_schema=False,",
            "    ):",
            "        \"\"\"Construct a new ``IdentifierPreparer`` object.",
            "",
            "        initial_quote",
            "          Character that begins a delimited identifier.",
            "",
            "        final_quote",
            "          Character that ends a delimited identifier. Defaults to",
            "          `initial_quote`.",
            "",
            "        omit_schema",
            "          Prevent prepending schema name. Useful for databases that do",
            "          not support schemae.",
            "        \"\"\"",
            "",
            "        self.dialect = dialect",
            "        self.initial_quote = initial_quote",
            "        self.final_quote = final_quote or self.initial_quote",
            "        self.escape_quote = escape_quote",
            "        self.escape_to_quote = self.escape_quote * 2",
            "        self.omit_schema = omit_schema",
            "        self.quote_case_sensitive_collations = quote_case_sensitive_collations",
            "        self._strings = {}",
            "        self._double_percents = self.dialect.paramstyle in (",
            "            \"format\",",
            "            \"pyformat\",",
            "        )",
            "",
            "    def _with_schema_translate(self, schema_translate_map):",
            "        prep = self.__class__.__new__(self.__class__)",
            "        prep.__dict__.update(self.__dict__)",
            "        prep.schema_for_object = schema._schema_getter(schema_translate_map)",
            "        return prep",
            "",
            "    def _escape_identifier(self, value):",
            "        \"\"\"Escape an identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        escaping behavior.",
            "        \"\"\"",
            "",
            "        value = value.replace(self.escape_quote, self.escape_to_quote)",
            "        if self._double_percents:",
            "            value = value.replace(\"%\", \"%%\")",
            "        return value",
            "",
            "    def _unescape_identifier(self, value):",
            "        \"\"\"Canonicalize an escaped identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        unescaping behavior that reverses _escape_identifier.",
            "        \"\"\"",
            "",
            "        return value.replace(self.escape_to_quote, self.escape_quote)",
            "",
            "    def quote_identifier(self, value):",
            "        \"\"\"Quote an identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        quoting behavior.",
            "        \"\"\"",
            "",
            "        return (",
            "            self.initial_quote",
            "            + self._escape_identifier(value)",
            "            + self.final_quote",
            "        )",
            "",
            "    def _requires_quotes(self, value):",
            "        \"\"\"Return True if the given identifier requires quoting.\"\"\"",
            "        lc_value = value.lower()",
            "        return (",
            "            lc_value in self.reserved_words",
            "            or value[0] in self.illegal_initial_characters",
            "            or not self.legal_characters.match(util.text_type(value))",
            "            or (lc_value != value)",
            "        )",
            "",
            "    def quote_schema(self, schema, force=None):",
            "        \"\"\"Conditionally quote a schema name.",
            "",
            "",
            "        The name is quoted if it is a reserved word, contains quote-necessary",
            "        characters, or is an instance of :class:`.quoted_name` which includes",
            "        ``quote`` set to ``True``.",
            "",
            "        Subclasses can override this to provide database-dependent",
            "        quoting behavior for schema names.",
            "",
            "        :param schema: string schema name",
            "        :param force: unused",
            "",
            "            .. deprecated:: 0.9",
            "",
            "                The :paramref:`.IdentifierPreparer.quote_schema.force`",
            "                parameter is deprecated and will be removed in a future",
            "                release.  This flag has no effect on the behavior of the",
            "                :meth:`.IdentifierPreparer.quote` method; please refer to",
            "                :class:`.quoted_name`.",
            "",
            "        \"\"\"",
            "        if force is not None:",
            "            # not using the util.deprecated_params() decorator in this",
            "            # case because of the additional function call overhead on this",
            "            # very performance-critical spot.",
            "            util.warn_deprecated(",
            "                \"The IdentifierPreparer.quote_schema.force parameter is \"",
            "                \"deprecated and will be removed in a future release.  This \"",
            "                \"flag has no effect on the behavior of the \"",
            "                \"IdentifierPreparer.quote method; please refer to \"",
            "                \"quoted_name().\"",
            "            )",
            "",
            "        return self.quote(schema)",
            "",
            "    def quote(self, ident, force=None):",
            "        \"\"\"Conditionally quote an identfier.",
            "",
            "        The identifier is quoted if it is a reserved word, contains",
            "        quote-necessary characters, or is an instance of",
            "        :class:`.quoted_name` which includes ``quote`` set to ``True``.",
            "",
            "        Subclasses can override this to provide database-dependent",
            "        quoting behavior for identifier names.",
            "",
            "        :param ident: string identifier",
            "        :param force: unused",
            "",
            "            .. deprecated:: 0.9",
            "",
            "                The :paramref:`.IdentifierPreparer.quote.force`",
            "                parameter is deprecated and will be removed in a future",
            "                release.  This flag has no effect on the behavior of the",
            "                :meth:`.IdentifierPreparer.quote` method; please refer to",
            "                :class:`.quoted_name`.",
            "",
            "        \"\"\"",
            "        if force is not None:",
            "            # not using the util.deprecated_params() decorator in this",
            "            # case because of the additional function call overhead on this",
            "            # very performance-critical spot.",
            "            util.warn_deprecated(",
            "                \"The IdentifierPreparer.quote.force parameter is \"",
            "                \"deprecated and will be removed in a future release.  This \"",
            "                \"flag has no effect on the behavior of the \"",
            "                \"IdentifierPreparer.quote method; please refer to \"",
            "                \"quoted_name().\"",
            "            )",
            "",
            "        force = getattr(ident, \"quote\", None)",
            "",
            "        if force is None:",
            "            if ident in self._strings:",
            "                return self._strings[ident]",
            "            else:",
            "                if self._requires_quotes(ident):",
            "                    self._strings[ident] = self.quote_identifier(ident)",
            "                else:",
            "                    self._strings[ident] = ident",
            "                return self._strings[ident]",
            "        elif force:",
            "            return self.quote_identifier(ident)",
            "        else:",
            "            return ident",
            "",
            "    def format_collation(self, collation_name):",
            "        if self.quote_case_sensitive_collations:",
            "            return self.quote(collation_name)",
            "        else:",
            "            return collation_name",
            "",
            "    def format_sequence(self, sequence, use_schema=True):",
            "        name = self.quote(sequence.name)",
            "",
            "        effective_schema = self.schema_for_object(sequence)",
            "",
            "        if (",
            "            not self.omit_schema",
            "            and use_schema",
            "            and effective_schema is not None",
            "        ):",
            "            name = self.quote_schema(effective_schema) + \".\" + name",
            "        return name",
            "",
            "    def format_label(self, label, name=None):",
            "        return self.quote(name or label.name)",
            "",
            "    def format_alias(self, alias, name=None):",
            "        return self.quote(name or alias.name)",
            "",
            "    def format_savepoint(self, savepoint, name=None):",
            "        # Running the savepoint name through quoting is unnecessary",
            "        # for all known dialects.  This is here to support potential",
            "        # third party use cases",
            "        ident = name or savepoint.ident",
            "        if self._requires_quotes(ident):",
            "            ident = self.quote_identifier(ident)",
            "        return ident",
            "",
            "    @util.dependencies(\"sqlalchemy.sql.naming\")",
            "    def format_constraint(self, naming, constraint):",
            "        if isinstance(constraint.name, elements._defer_name):",
            "            name = naming._constraint_name_for_table(",
            "                constraint, constraint.table",
            "            )",
            "",
            "            if name is None:",
            "                if isinstance(constraint.name, elements._defer_none_name):",
            "                    return None",
            "                else:",
            "                    name = constraint.name",
            "        else:",
            "            name = constraint.name",
            "",
            "        if isinstance(name, elements._truncated_label):",
            "            if constraint.__visit_name__ == \"index\":",
            "                max_ = (",
            "                    self.dialect.max_index_name_length",
            "                    or self.dialect.max_identifier_length",
            "                )",
            "            else:",
            "                max_ = self.dialect.max_identifier_length",
            "            if len(name) > max_:",
            "                name = name[0 : max_ - 8] + \"_\" + util.md5_hex(name)[-4:]",
            "        else:",
            "            self.dialect.validate_identifier(name)",
            "",
            "        return self.quote(name)",
            "",
            "    def format_index(self, index):",
            "        return self.format_constraint(index)",
            "",
            "    def format_table(self, table, use_schema=True, name=None):",
            "        \"\"\"Prepare a quoted table and schema name.\"\"\"",
            "",
            "        if name is None:",
            "            name = table.name",
            "        result = self.quote(name)",
            "",
            "        effective_schema = self.schema_for_object(table)",
            "",
            "        if not self.omit_schema and use_schema and effective_schema:",
            "            result = self.quote_schema(effective_schema) + \".\" + result",
            "        return result",
            "",
            "    def format_schema(self, name):",
            "        \"\"\"Prepare a quoted schema name.\"\"\"",
            "",
            "        return self.quote(name)",
            "",
            "    def format_column(",
            "        self,",
            "        column,",
            "        use_table=False,",
            "        name=None,",
            "        table_name=None,",
            "        use_schema=False,",
            "    ):",
            "        \"\"\"Prepare a quoted column name.\"\"\"",
            "",
            "        if name is None:",
            "            name = column.name",
            "        if not getattr(column, \"is_literal\", False):",
            "            if use_table:",
            "                return (",
            "                    self.format_table(",
            "                        column.table, use_schema=use_schema, name=table_name",
            "                    )",
            "                    + \".\"",
            "                    + self.quote(name)",
            "                )",
            "            else:",
            "                return self.quote(name)",
            "        else:",
            "            # literal textual elements get stuck into ColumnClause a lot,",
            "            # which shouldn't get quoted",
            "",
            "            if use_table:",
            "                return (",
            "                    self.format_table(",
            "                        column.table, use_schema=use_schema, name=table_name",
            "                    )",
            "                    + \".\"",
            "                    + name",
            "                )",
            "            else:",
            "                return name",
            "",
            "    def format_table_seq(self, table, use_schema=True):",
            "        \"\"\"Format table name and schema as a tuple.\"\"\"",
            "",
            "        # Dialects with more levels in their fully qualified references",
            "        # ('database', 'owner', etc.) could override this and return",
            "        # a longer sequence.",
            "",
            "        effective_schema = self.schema_for_object(table)",
            "",
            "        if not self.omit_schema and use_schema and effective_schema:",
            "            return (",
            "                self.quote_schema(effective_schema),",
            "                self.format_table(table, use_schema=False),",
            "            )",
            "        else:",
            "            return (self.format_table(table, use_schema=False),)",
            "",
            "    @util.memoized_property",
            "    def _r_identifiers(self):",
            "        initial, final, escaped_final = [",
            "            re.escape(s)",
            "            for s in (",
            "                self.initial_quote,",
            "                self.final_quote,",
            "                self._escape_identifier(self.final_quote),",
            "            )",
            "        ]",
            "        r = re.compile(",
            "            r\"(?:\"",
            "            r\"(?:%(initial)s((?:%(escaped)s|[^%(final)s])+)%(final)s\"",
            "            r\"|([^\\.]+))(?=\\.|$))+\"",
            "            % {\"initial\": initial, \"final\": final, \"escaped\": escaped_final}",
            "        )",
            "        return r",
            "",
            "    def unformat_identifiers(self, identifiers):",
            "        \"\"\"Unpack 'schema.table.column'-like strings into components.\"\"\"",
            "",
            "        r = self._r_identifiers",
            "        return [",
            "            self._unescape_identifier(i)",
            "            for i in [a or b for a, b in r.findall(identifiers)]",
            "        ]"
        ],
        "afterPatchFile": [
            "# sql/compiler.py",
            "# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors",
            "# <see AUTHORS file>",
            "#",
            "# This module is part of SQLAlchemy and is released under",
            "# the MIT License: http://www.opensource.org/licenses/mit-license.php",
            "",
            "\"\"\"Base SQL and DDL compiler implementations.",
            "",
            "Classes provided include:",
            "",
            ":class:`.compiler.SQLCompiler` - renders SQL",
            "strings",
            "",
            ":class:`.compiler.DDLCompiler` - renders DDL",
            "(data definition language) strings",
            "",
            ":class:`.compiler.GenericTypeCompiler` - renders",
            "type specification strings.",
            "",
            "To generate user-defined SQL strings, see",
            ":doc:`/ext/compiler`.",
            "",
            "\"\"\"",
            "",
            "import contextlib",
            "import itertools",
            "import re",
            "",
            "from . import crud",
            "from . import elements",
            "from . import functions",
            "from . import operators",
            "from . import schema",
            "from . import selectable",
            "from . import sqltypes",
            "from . import visitors",
            "from .. import exc",
            "from .. import util",
            "",
            "",
            "RESERVED_WORDS = set(",
            "    [",
            "        \"all\",",
            "        \"analyse\",",
            "        \"analyze\",",
            "        \"and\",",
            "        \"any\",",
            "        \"array\",",
            "        \"as\",",
            "        \"asc\",",
            "        \"asymmetric\",",
            "        \"authorization\",",
            "        \"between\",",
            "        \"binary\",",
            "        \"both\",",
            "        \"case\",",
            "        \"cast\",",
            "        \"check\",",
            "        \"collate\",",
            "        \"column\",",
            "        \"constraint\",",
            "        \"create\",",
            "        \"cross\",",
            "        \"current_date\",",
            "        \"current_role\",",
            "        \"current_time\",",
            "        \"current_timestamp\",",
            "        \"current_user\",",
            "        \"default\",",
            "        \"deferrable\",",
            "        \"desc\",",
            "        \"distinct\",",
            "        \"do\",",
            "        \"else\",",
            "        \"end\",",
            "        \"except\",",
            "        \"false\",",
            "        \"for\",",
            "        \"foreign\",",
            "        \"freeze\",",
            "        \"from\",",
            "        \"full\",",
            "        \"grant\",",
            "        \"group\",",
            "        \"having\",",
            "        \"ilike\",",
            "        \"in\",",
            "        \"initially\",",
            "        \"inner\",",
            "        \"intersect\",",
            "        \"into\",",
            "        \"is\",",
            "        \"isnull\",",
            "        \"join\",",
            "        \"leading\",",
            "        \"left\",",
            "        \"like\",",
            "        \"limit\",",
            "        \"localtime\",",
            "        \"localtimestamp\",",
            "        \"natural\",",
            "        \"new\",",
            "        \"not\",",
            "        \"notnull\",",
            "        \"null\",",
            "        \"off\",",
            "        \"offset\",",
            "        \"old\",",
            "        \"on\",",
            "        \"only\",",
            "        \"or\",",
            "        \"order\",",
            "        \"outer\",",
            "        \"overlaps\",",
            "        \"placing\",",
            "        \"primary\",",
            "        \"references\",",
            "        \"right\",",
            "        \"select\",",
            "        \"session_user\",",
            "        \"set\",",
            "        \"similar\",",
            "        \"some\",",
            "        \"symmetric\",",
            "        \"table\",",
            "        \"then\",",
            "        \"to\",",
            "        \"trailing\",",
            "        \"true\",",
            "        \"union\",",
            "        \"unique\",",
            "        \"user\",",
            "        \"using\",",
            "        \"verbose\",",
            "        \"when\",",
            "        \"where\",",
            "    ]",
            ")",
            "",
            "LEGAL_CHARACTERS = re.compile(r\"^[A-Z0-9_$]+$\", re.I)",
            "LEGAL_CHARACTERS_PLUS_SPACE = re.compile(r\"^[A-Z0-9_ $]+$\", re.I)",
            "ILLEGAL_INITIAL_CHARACTERS = {str(x) for x in range(0, 10)}.union([\"$\"])",
            "",
            "FK_ON_DELETE = re.compile(",
            "    r\"^(?:RESTRICT|CASCADE|SET NULL|NO ACTION|SET DEFAULT)$\", re.I",
            ")",
            "FK_ON_UPDATE = re.compile(",
            "    r\"^(?:RESTRICT|CASCADE|SET NULL|NO ACTION|SET DEFAULT)$\", re.I",
            ")",
            "FK_INITIALLY = re.compile(r\"^(?:DEFERRED|IMMEDIATE)$\", re.I)",
            "BIND_PARAMS = re.compile(r\"(?<![:\\w\\$\\x5c]):([\\w\\$]+)(?![:\\w\\$])\", re.UNICODE)",
            "BIND_PARAMS_ESC = re.compile(r\"\\x5c(:[\\w\\$]*)(?![:\\w\\$])\", re.UNICODE)",
            "",
            "BIND_TEMPLATES = {",
            "    \"pyformat\": \"%%(%(name)s)s\",",
            "    \"qmark\": \"?\",",
            "    \"format\": \"%%s\",",
            "    \"numeric\": \":[_POSITION]\",",
            "    \"named\": \":%(name)s\",",
            "}",
            "",
            "",
            "OPERATORS = {",
            "    # binary",
            "    operators.and_: \" AND \",",
            "    operators.or_: \" OR \",",
            "    operators.add: \" + \",",
            "    operators.mul: \" * \",",
            "    operators.sub: \" - \",",
            "    operators.div: \" / \",",
            "    operators.mod: \" % \",",
            "    operators.truediv: \" / \",",
            "    operators.neg: \"-\",",
            "    operators.lt: \" < \",",
            "    operators.le: \" <= \",",
            "    operators.ne: \" != \",",
            "    operators.gt: \" > \",",
            "    operators.ge: \" >= \",",
            "    operators.eq: \" = \",",
            "    operators.is_distinct_from: \" IS DISTINCT FROM \",",
            "    operators.isnot_distinct_from: \" IS NOT DISTINCT FROM \",",
            "    operators.concat_op: \" || \",",
            "    operators.match_op: \" MATCH \",",
            "    operators.notmatch_op: \" NOT MATCH \",",
            "    operators.in_op: \" IN \",",
            "    operators.notin_op: \" NOT IN \",",
            "    operators.comma_op: \", \",",
            "    operators.from_: \" FROM \",",
            "    operators.as_: \" AS \",",
            "    operators.is_: \" IS \",",
            "    operators.isnot: \" IS NOT \",",
            "    operators.collate: \" COLLATE \",",
            "    # unary",
            "    operators.exists: \"EXISTS \",",
            "    operators.distinct_op: \"DISTINCT \",",
            "    operators.inv: \"NOT \",",
            "    operators.any_op: \"ANY \",",
            "    operators.all_op: \"ALL \",",
            "    # modifiers",
            "    operators.desc_op: \" DESC\",",
            "    operators.asc_op: \" ASC\",",
            "    operators.nullsfirst_op: \" NULLS FIRST\",",
            "    operators.nullslast_op: \" NULLS LAST\",",
            "}",
            "",
            "FUNCTIONS = {",
            "    functions.coalesce: \"coalesce\",",
            "    functions.current_date: \"CURRENT_DATE\",",
            "    functions.current_time: \"CURRENT_TIME\",",
            "    functions.current_timestamp: \"CURRENT_TIMESTAMP\",",
            "    functions.current_user: \"CURRENT_USER\",",
            "    functions.localtime: \"LOCALTIME\",",
            "    functions.localtimestamp: \"LOCALTIMESTAMP\",",
            "    functions.random: \"random\",",
            "    functions.sysdate: \"sysdate\",",
            "    functions.session_user: \"SESSION_USER\",",
            "    functions.user: \"USER\",",
            "    functions.cube: \"CUBE\",",
            "    functions.rollup: \"ROLLUP\",",
            "    functions.grouping_sets: \"GROUPING SETS\",",
            "}",
            "",
            "EXTRACT_MAP = {",
            "    \"month\": \"month\",",
            "    \"day\": \"day\",",
            "    \"year\": \"year\",",
            "    \"second\": \"second\",",
            "    \"hour\": \"hour\",",
            "    \"doy\": \"doy\",",
            "    \"minute\": \"minute\",",
            "    \"quarter\": \"quarter\",",
            "    \"dow\": \"dow\",",
            "    \"week\": \"week\",",
            "    \"epoch\": \"epoch\",",
            "    \"milliseconds\": \"milliseconds\",",
            "    \"microseconds\": \"microseconds\",",
            "    \"timezone_hour\": \"timezone_hour\",",
            "    \"timezone_minute\": \"timezone_minute\",",
            "}",
            "",
            "COMPOUND_KEYWORDS = {",
            "    selectable.CompoundSelect.UNION: \"UNION\",",
            "    selectable.CompoundSelect.UNION_ALL: \"UNION ALL\",",
            "    selectable.CompoundSelect.EXCEPT: \"EXCEPT\",",
            "    selectable.CompoundSelect.EXCEPT_ALL: \"EXCEPT ALL\",",
            "    selectable.CompoundSelect.INTERSECT: \"INTERSECT\",",
            "    selectable.CompoundSelect.INTERSECT_ALL: \"INTERSECT ALL\",",
            "}",
            "",
            "",
            "class Compiled(object):",
            "",
            "    \"\"\"Represent a compiled SQL or DDL expression.",
            "",
            "    The ``__str__`` method of the ``Compiled`` object should produce",
            "    the actual text of the statement.  ``Compiled`` objects are",
            "    specific to their underlying database dialect, and also may",
            "    or may not be specific to the columns referenced within a",
            "    particular set of bind parameters.  In no case should the",
            "    ``Compiled`` object be dependent on the actual values of those",
            "    bind parameters, even though it may reference those values as",
            "    defaults.",
            "    \"\"\"",
            "",
            "    _cached_metadata = None",
            "",
            "    execution_options = util.immutabledict()",
            "    \"\"\"",
            "    Execution options propagated from the statement.   In some cases,",
            "    sub-elements of the statement can modify these.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        dialect,",
            "        statement,",
            "        bind=None,",
            "        schema_translate_map=None,",
            "        compile_kwargs=util.immutabledict(),",
            "    ):",
            "        \"\"\"Construct a new :class:`.Compiled` object.",
            "",
            "        :param dialect: :class:`.Dialect` to compile against.",
            "",
            "        :param statement: :class:`.ClauseElement` to be compiled.",
            "",
            "        :param bind: Optional Engine or Connection to compile this",
            "          statement against.",
            "",
            "        :param schema_translate_map: dictionary of schema names to be",
            "         translated when forming the resultant SQL",
            "",
            "         .. versionadded:: 1.1",
            "",
            "         .. seealso::",
            "",
            "            :ref:`schema_translating`",
            "",
            "        :param compile_kwargs: additional kwargs that will be",
            "         passed to the initial call to :meth:`.Compiled.process`.",
            "",
            "",
            "        \"\"\"",
            "",
            "        self.dialect = dialect",
            "        self.bind = bind",
            "        self.preparer = self.dialect.identifier_preparer",
            "        if schema_translate_map:",
            "            self.preparer = self.preparer._with_schema_translate(",
            "                schema_translate_map",
            "            )",
            "",
            "        if statement is not None:",
            "            self.statement = statement",
            "            self.can_execute = statement.supports_execution",
            "            if self.can_execute:",
            "                self.execution_options = statement._execution_options",
            "            self.string = self.process(self.statement, **compile_kwargs)",
            "",
            "    @util.deprecated(",
            "        \"0.7\",",
            "        \"The :meth:`.Compiled.compile` method is deprecated and will be \"",
            "        \"removed in a future release.   The :class:`.Compiled` object \"",
            "        \"now runs its compilation within the constructor, and this method \"",
            "        \"does nothing.\",",
            "    )",
            "    def compile(self):",
            "        \"\"\"Produce the internal string representation of this element.",
            "        \"\"\"",
            "        pass",
            "",
            "    def _execute_on_connection(self, connection, multiparams, params):",
            "        if self.can_execute:",
            "            return connection._execute_compiled(self, multiparams, params)",
            "        else:",
            "            raise exc.ObjectNotExecutableError(self.statement)",
            "",
            "    @property",
            "    def sql_compiler(self):",
            "        \"\"\"Return a Compiled that is capable of processing SQL expressions.",
            "",
            "        If this compiler is one, it would likely just return 'self'.",
            "",
            "        \"\"\"",
            "",
            "        raise NotImplementedError()",
            "",
            "    def process(self, obj, **kwargs):",
            "        return obj._compiler_dispatch(self, **kwargs)",
            "",
            "    def __str__(self):",
            "        \"\"\"Return the string text of the generated SQL or DDL.\"\"\"",
            "",
            "        return self.string or \"\"",
            "",
            "    def construct_params(self, params=None):",
            "        \"\"\"Return the bind params for this compiled object.",
            "",
            "        :param params: a dict of string/object pairs whose values will",
            "                       override bind values compiled in to the",
            "                       statement.",
            "        \"\"\"",
            "",
            "        raise NotImplementedError()",
            "",
            "    @property",
            "    def params(self):",
            "        \"\"\"Return the bind params for this compiled object.\"\"\"",
            "        return self.construct_params()",
            "",
            "    def execute(self, *multiparams, **params):",
            "        \"\"\"Execute this compiled object.\"\"\"",
            "",
            "        e = self.bind",
            "        if e is None:",
            "            raise exc.UnboundExecutionError(",
            "                \"This Compiled object is not bound to any Engine \"",
            "                \"or Connection.\",",
            "                code=\"2afi\",",
            "            )",
            "        return e._execute_compiled(self, multiparams, params)",
            "",
            "    def scalar(self, *multiparams, **params):",
            "        \"\"\"Execute this compiled object and return the result's",
            "        scalar value.\"\"\"",
            "",
            "        return self.execute(*multiparams, **params).scalar()",
            "",
            "",
            "class TypeCompiler(util.with_metaclass(util.EnsureKWArgType, object)):",
            "    \"\"\"Produces DDL specification for TypeEngine objects.\"\"\"",
            "",
            "    ensure_kwarg = r\"visit_\\w+\"",
            "",
            "    def __init__(self, dialect):",
            "        self.dialect = dialect",
            "",
            "    def process(self, type_, **kw):",
            "        return type_._compiler_dispatch(self, **kw)",
            "",
            "",
            "class _CompileLabel(visitors.Visitable):",
            "",
            "    \"\"\"lightweight label object which acts as an expression.Label.\"\"\"",
            "",
            "    __visit_name__ = \"label\"",
            "    __slots__ = \"element\", \"name\"",
            "",
            "    def __init__(self, col, name, alt_names=()):",
            "        self.element = col",
            "        self.name = name",
            "        self._alt_names = (col,) + alt_names",
            "",
            "    @property",
            "    def proxy_set(self):",
            "        return self.element.proxy_set",
            "",
            "    @property",
            "    def type(self):",
            "        return self.element.type",
            "",
            "    def self_group(self, **kw):",
            "        return self",
            "",
            "",
            "class SQLCompiler(Compiled):",
            "    \"\"\"Default implementation of :class:`.Compiled`.",
            "",
            "    Compiles :class:`.ClauseElement` objects into SQL strings.",
            "",
            "    \"\"\"",
            "",
            "    extract_map = EXTRACT_MAP",
            "",
            "    compound_keywords = COMPOUND_KEYWORDS",
            "",
            "    isdelete = isinsert = isupdate = False",
            "    \"\"\"class-level defaults which can be set at the instance",
            "    level to define if this Compiled instance represents",
            "    INSERT/UPDATE/DELETE",
            "    \"\"\"",
            "",
            "    isplaintext = False",
            "",
            "    returning = None",
            "    \"\"\"holds the \"returning\" collection of columns if",
            "    the statement is CRUD and defines returning columns",
            "    either implicitly or explicitly",
            "    \"\"\"",
            "",
            "    returning_precedes_values = False",
            "    \"\"\"set to True classwide to generate RETURNING",
            "    clauses before the VALUES or WHERE clause (i.e. MSSQL)",
            "    \"\"\"",
            "",
            "    render_table_with_column_in_update_from = False",
            "    \"\"\"set to True classwide to indicate the SET clause",
            "    in a multi-table UPDATE statement should qualify",
            "    columns with the table name (i.e. MySQL only)",
            "    \"\"\"",
            "",
            "    contains_expanding_parameters = False",
            "    \"\"\"True if we've encountered bindparam(..., expanding=True).",
            "",
            "    These need to be converted before execution time against the",
            "    string statement.",
            "",
            "    \"\"\"",
            "",
            "    ansi_bind_rules = False",
            "    \"\"\"SQL 92 doesn't allow bind parameters to be used",
            "    in the columns clause of a SELECT, nor does it allow",
            "    ambiguous expressions like \"? = ?\".  A compiler",
            "    subclass can set this flag to False if the target",
            "    driver/DB enforces this",
            "    \"\"\"",
            "",
            "    _textual_ordered_columns = False",
            "    \"\"\"tell the result object that the column names as rendered are important,",
            "    but they are also \"ordered\" vs. what is in the compiled object here.",
            "    \"\"\"",
            "",
            "    _ordered_columns = True",
            "    \"\"\"",
            "    if False, means we can't be sure the list of entries",
            "    in _result_columns is actually the rendered order.  Usually",
            "    True unless using an unordered TextAsFrom.",
            "    \"\"\"",
            "",
            "    _numeric_binds = False",
            "    \"\"\"",
            "    True if paramstyle is \"numeric\".  This paramstyle is trickier than",
            "    all the others.",
            "",
            "    \"\"\"",
            "",
            "    insert_prefetch = update_prefetch = ()",
            "",
            "    def __init__(",
            "        self, dialect, statement, column_keys=None, inline=False, **kwargs",
            "    ):",
            "        \"\"\"Construct a new :class:`.SQLCompiler` object.",
            "",
            "        :param dialect: :class:`.Dialect` to be used",
            "",
            "        :param statement: :class:`.ClauseElement` to be compiled",
            "",
            "        :param column_keys:  a list of column names to be compiled into an",
            "         INSERT or UPDATE statement.",
            "",
            "        :param inline: whether to generate INSERT statements as \"inline\", e.g.",
            "         not formatted to return any generated defaults",
            "",
            "        :param kwargs: additional keyword arguments to be consumed by the",
            "         superclass.",
            "",
            "        \"\"\"",
            "        self.column_keys = column_keys",
            "",
            "        # compile INSERT/UPDATE defaults/sequences inlined (no pre-",
            "        # execute)",
            "        self.inline = inline or getattr(statement, \"inline\", False)",
            "",
            "        # a dictionary of bind parameter keys to BindParameter",
            "        # instances.",
            "        self.binds = {}",
            "",
            "        # a dictionary of BindParameter instances to \"compiled\" names",
            "        # that are actually present in the generated SQL",
            "        self.bind_names = util.column_dict()",
            "",
            "        # stack which keeps track of nested SELECT statements",
            "        self.stack = []",
            "",
            "        # relates label names in the final SQL to a tuple of local",
            "        # column/label name, ColumnElement object (if any) and",
            "        # TypeEngine. ResultProxy uses this for type processing and",
            "        # column targeting",
            "        self._result_columns = []",
            "",
            "        # true if the paramstyle is positional",
            "        self.positional = dialect.positional",
            "        if self.positional:",
            "            self.positiontup = []",
            "            self._numeric_binds = dialect.paramstyle == \"numeric\"",
            "        self.bindtemplate = BIND_TEMPLATES[dialect.paramstyle]",
            "",
            "        self.ctes = None",
            "",
            "        self.label_length = (",
            "            dialect.label_length or dialect.max_identifier_length",
            "        )",
            "",
            "        # a map which tracks \"anonymous\" identifiers that are created on",
            "        # the fly here",
            "        self.anon_map = util.PopulateDict(self._process_anon)",
            "",
            "        # a map which tracks \"truncated\" names based on",
            "        # dialect.label_length or dialect.max_identifier_length",
            "        self.truncated_names = {}",
            "        Compiled.__init__(self, dialect, statement, **kwargs)",
            "",
            "        if (",
            "            self.isinsert or self.isupdate or self.isdelete",
            "        ) and statement._returning:",
            "            self.returning = statement._returning",
            "",
            "        if self.positional and self._numeric_binds:",
            "            self._apply_numbered_params()",
            "",
            "    @property",
            "    def prefetch(self):",
            "        return list(self.insert_prefetch + self.update_prefetch)",
            "",
            "    @util.memoized_instancemethod",
            "    def _init_cte_state(self):",
            "        \"\"\"Initialize collections related to CTEs only if",
            "        a CTE is located, to save on the overhead of",
            "        these collections otherwise.",
            "",
            "        \"\"\"",
            "        # collect CTEs to tack on top of a SELECT",
            "        self.ctes = util.OrderedDict()",
            "        self.ctes_by_name = {}",
            "        self.ctes_recursive = False",
            "        if self.positional:",
            "            self.cte_positional = {}",
            "",
            "    @contextlib.contextmanager",
            "    def _nested_result(self):",
            "        \"\"\"special API to support the use case of 'nested result sets'\"\"\"",
            "        result_columns, ordered_columns = (",
            "            self._result_columns,",
            "            self._ordered_columns,",
            "        )",
            "        self._result_columns, self._ordered_columns = [], False",
            "",
            "        try:",
            "            if self.stack:",
            "                entry = self.stack[-1]",
            "                entry[\"need_result_map_for_nested\"] = True",
            "            else:",
            "                entry = None",
            "            yield self._result_columns, self._ordered_columns",
            "        finally:",
            "            if entry:",
            "                entry.pop(\"need_result_map_for_nested\")",
            "            self._result_columns, self._ordered_columns = (",
            "                result_columns,",
            "                ordered_columns,",
            "            )",
            "",
            "    def _apply_numbered_params(self):",
            "        poscount = itertools.count(1)",
            "        self.string = re.sub(",
            "            r\"\\[_POSITION\\]\", lambda m: str(util.next(poscount)), self.string",
            "        )",
            "",
            "    @util.memoized_property",
            "    def _bind_processors(self):",
            "        return dict(",
            "            (key, value)",
            "            for key, value in (",
            "                (",
            "                    self.bind_names[bindparam],",
            "                    bindparam.type._cached_bind_processor(self.dialect),",
            "                )",
            "                for bindparam in self.bind_names",
            "            )",
            "            if value is not None",
            "        )",
            "",
            "    def is_subquery(self):",
            "        return len(self.stack) > 1",
            "",
            "    @property",
            "    def sql_compiler(self):",
            "        return self",
            "",
            "    def construct_params(self, params=None, _group_number=None, _check=True):",
            "        \"\"\"return a dictionary of bind parameter keys and values\"\"\"",
            "",
            "        if params:",
            "            pd = {}",
            "            for bindparam in self.bind_names:",
            "                name = self.bind_names[bindparam]",
            "                if bindparam.key in params:",
            "                    pd[name] = params[bindparam.key]",
            "                elif name in params:",
            "                    pd[name] = params[name]",
            "",
            "                elif _check and bindparam.required:",
            "                    if _group_number:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r, \"",
            "                            \"in parameter group %d\"",
            "                            % (bindparam.key, _group_number),",
            "                            code=\"cd3x\",",
            "                        )",
            "                    else:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r\"",
            "                            % bindparam.key,",
            "                            code=\"cd3x\",",
            "                        )",
            "",
            "                elif bindparam.callable:",
            "                    pd[name] = bindparam.effective_value",
            "                else:",
            "                    pd[name] = bindparam.value",
            "            return pd",
            "        else:",
            "            pd = {}",
            "            for bindparam in self.bind_names:",
            "                if _check and bindparam.required:",
            "                    if _group_number:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r, \"",
            "                            \"in parameter group %d\"",
            "                            % (bindparam.key, _group_number),",
            "                            code=\"cd3x\",",
            "                        )",
            "                    else:",
            "                        raise exc.InvalidRequestError(",
            "                            \"A value is required for bind parameter %r\"",
            "                            % bindparam.key,",
            "                            code=\"cd3x\",",
            "                        )",
            "",
            "                if bindparam.callable:",
            "                    pd[self.bind_names[bindparam]] = bindparam.effective_value",
            "                else:",
            "                    pd[self.bind_names[bindparam]] = bindparam.value",
            "            return pd",
            "",
            "    @property",
            "    def params(self):",
            "        \"\"\"Return the bind param dictionary embedded into this",
            "        compiled object, for those values that are present.\"\"\"",
            "        return self.construct_params(_check=False)",
            "",
            "    @util.dependencies(\"sqlalchemy.engine.result\")",
            "    def _create_result_map(self, result):",
            "        \"\"\"utility method used for unit tests only.\"\"\"",
            "        return result.ResultMetaData._create_result_map(self._result_columns)",
            "",
            "    def default_from(self):",
            "        \"\"\"Called when a SELECT statement has no froms, and no FROM clause is",
            "        to be appended.",
            "",
            "        Gives Oracle a chance to tack on a ``FROM DUAL`` to the string output.",
            "",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def visit_grouping(self, grouping, asfrom=False, **kwargs):",
            "        return \"(\" + grouping.element._compiler_dispatch(self, **kwargs) + \")\"",
            "",
            "    def visit_label_reference(",
            "        self, element, within_columns_clause=False, **kwargs",
            "    ):",
            "        if self.stack and self.dialect.supports_simple_order_by_label:",
            "            selectable = self.stack[-1][\"selectable\"]",
            "",
            "            with_cols, only_froms, only_cols = selectable._label_resolve_dict",
            "            if within_columns_clause:",
            "                resolve_dict = only_froms",
            "            else:",
            "                resolve_dict = only_cols",
            "",
            "            # this can be None in the case that a _label_reference()",
            "            # were subject to a replacement operation, in which case",
            "            # the replacement of the Label element may have changed",
            "            # to something else like a ColumnClause expression.",
            "            order_by_elem = element.element._order_by_label_element",
            "",
            "            if (",
            "                order_by_elem is not None",
            "                and order_by_elem.name in resolve_dict",
            "                and order_by_elem.shares_lineage(",
            "                    resolve_dict[order_by_elem.name]",
            "                )",
            "            ):",
            "                kwargs[",
            "                    \"render_label_as_label\"",
            "                ] = element.element._order_by_label_element",
            "        return self.process(",
            "            element.element,",
            "            within_columns_clause=within_columns_clause,",
            "            **kwargs",
            "        )",
            "",
            "    def visit_textual_label_reference(",
            "        self, element, within_columns_clause=False, **kwargs",
            "    ):",
            "        if not self.stack:",
            "            # compiling the element outside of the context of a SELECT",
            "            return self.process(element._text_clause)",
            "",
            "        selectable = self.stack[-1][\"selectable\"]",
            "        with_cols, only_froms, only_cols = selectable._label_resolve_dict",
            "        try:",
            "            if within_columns_clause:",
            "                col = only_froms[element.element]",
            "            else:",
            "                col = with_cols[element.element]",
            "        except KeyError:",
            "            elements._no_text_coercion(",
            "                element.element,",
            "                exc.CompileError,",
            "                \"Can't resolve label reference for ORDER BY / GROUP BY.\",",
            "            )",
            "        else:",
            "            kwargs[\"render_label_as_label\"] = col",
            "            return self.process(",
            "                col, within_columns_clause=within_columns_clause, **kwargs",
            "            )",
            "",
            "    def visit_label(",
            "        self,",
            "        label,",
            "        add_to_result_map=None,",
            "        within_label_clause=False,",
            "        within_columns_clause=False,",
            "        render_label_as_label=None,",
            "        **kw",
            "    ):",
            "        # only render labels within the columns clause",
            "        # or ORDER BY clause of a select.  dialect-specific compilers",
            "        # can modify this behavior.",
            "        render_label_with_as = (",
            "            within_columns_clause and not within_label_clause",
            "        )",
            "        render_label_only = render_label_as_label is label",
            "",
            "        if render_label_only or render_label_with_as:",
            "            if isinstance(label.name, elements._truncated_label):",
            "                labelname = self._truncated_identifier(\"colident\", label.name)",
            "            else:",
            "                labelname = label.name",
            "",
            "        if render_label_with_as:",
            "            if add_to_result_map is not None:",
            "                add_to_result_map(",
            "                    labelname,",
            "                    label.name,",
            "                    (label, labelname) + label._alt_names,",
            "                    label.type,",
            "                )",
            "",
            "            return (",
            "                label.element._compiler_dispatch(",
            "                    self,",
            "                    within_columns_clause=True,",
            "                    within_label_clause=True,",
            "                    **kw",
            "                )",
            "                + OPERATORS[operators.as_]",
            "                + self.preparer.format_label(label, labelname)",
            "            )",
            "        elif render_label_only:",
            "            return self.preparer.format_label(label, labelname)",
            "        else:",
            "            return label.element._compiler_dispatch(",
            "                self, within_columns_clause=False, **kw",
            "            )",
            "",
            "    def _fallback_column_name(self, column):",
            "        raise exc.CompileError(",
            "            \"Cannot compile Column object until \" \"its 'name' is assigned.\"",
            "        )",
            "",
            "    def visit_column(",
            "        self, column, add_to_result_map=None, include_table=True, **kwargs",
            "    ):",
            "        name = orig_name = column.name",
            "        if name is None:",
            "            name = self._fallback_column_name(column)",
            "",
            "        is_literal = column.is_literal",
            "        if not is_literal and isinstance(name, elements._truncated_label):",
            "            name = self._truncated_identifier(\"colident\", name)",
            "",
            "        if add_to_result_map is not None:",
            "            add_to_result_map(",
            "                name, orig_name, (column, name, column.key), column.type",
            "            )",
            "",
            "        if is_literal:",
            "            name = self.escape_literal_column(name)",
            "        else:",
            "            name = self.preparer.quote(name)",
            "        table = column.table",
            "        if table is None or not include_table or not table.named_with_column:",
            "            return name",
            "        else:",
            "            effective_schema = self.preparer.schema_for_object(table)",
            "",
            "            if effective_schema:",
            "                schema_prefix = (",
            "                    self.preparer.quote_schema(effective_schema) + \".\"",
            "                )",
            "            else:",
            "                schema_prefix = \"\"",
            "            tablename = table.name",
            "            if isinstance(tablename, elements._truncated_label):",
            "                tablename = self._truncated_identifier(\"alias\", tablename)",
            "",
            "            return schema_prefix + self.preparer.quote(tablename) + \".\" + name",
            "",
            "    def visit_collation(self, element, **kw):",
            "        return self.preparer.format_collation(element.collation)",
            "",
            "    def visit_fromclause(self, fromclause, **kwargs):",
            "        return fromclause.name",
            "",
            "    def visit_index(self, index, **kwargs):",
            "        return index.name",
            "",
            "    def visit_typeclause(self, typeclause, **kw):",
            "        kw[\"type_expression\"] = typeclause",
            "        return self.dialect.type_compiler.process(typeclause.type, **kw)",
            "",
            "    def post_process_text(self, text):",
            "        if self.preparer._double_percents:",
            "            text = text.replace(\"%\", \"%%\")",
            "        return text",
            "",
            "    def escape_literal_column(self, text):",
            "        if self.preparer._double_percents:",
            "            text = text.replace(\"%\", \"%%\")",
            "        return text",
            "",
            "    def visit_textclause(self, textclause, **kw):",
            "        def do_bindparam(m):",
            "            name = m.group(1)",
            "            if name in textclause._bindparams:",
            "                return self.process(textclause._bindparams[name], **kw)",
            "            else:",
            "                return self.bindparam_string(name, **kw)",
            "",
            "        if not self.stack:",
            "            self.isplaintext = True",
            "",
            "        # un-escape any \\:params",
            "        return BIND_PARAMS_ESC.sub(",
            "            lambda m: m.group(1),",
            "            BIND_PARAMS.sub(",
            "                do_bindparam, self.post_process_text(textclause.text)",
            "            ),",
            "        )",
            "",
            "    def visit_text_as_from(",
            "        self, taf, compound_index=None, asfrom=False, parens=True, **kw",
            "    ):",
            "",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        populate_result_map = (",
            "            toplevel",
            "            or (",
            "                compound_index == 0",
            "                and entry.get(\"need_result_map_for_compound\", False)",
            "            )",
            "            or entry.get(\"need_result_map_for_nested\", False)",
            "        )",
            "",
            "        if populate_result_map:",
            "            self._ordered_columns = (",
            "                self._textual_ordered_columns",
            "            ) = taf.positional",
            "            for c in taf.column_args:",
            "                self.process(",
            "                    c,",
            "                    within_columns_clause=True,",
            "                    add_to_result_map=self._add_to_result_map,",
            "                )",
            "",
            "        text = self.process(taf.element, **kw)",
            "        if asfrom and parens:",
            "            text = \"(%s)\" % text",
            "        return text",
            "",
            "    def visit_null(self, expr, **kw):",
            "        return \"NULL\"",
            "",
            "    def visit_true(self, expr, **kw):",
            "        if self.dialect.supports_native_boolean:",
            "            return \"true\"",
            "        else:",
            "            return \"1\"",
            "",
            "    def visit_false(self, expr, **kw):",
            "        if self.dialect.supports_native_boolean:",
            "            return \"false\"",
            "        else:",
            "            return \"0\"",
            "",
            "    def visit_clauselist(self, clauselist, **kw):",
            "        sep = clauselist.operator",
            "        if sep is None:",
            "            sep = \" \"",
            "        else:",
            "            sep = OPERATORS[clauselist.operator]",
            "        return sep.join(",
            "            s",
            "            for s in (",
            "                c._compiler_dispatch(self, **kw) for c in clauselist.clauses",
            "            )",
            "            if s",
            "        )",
            "",
            "    def visit_case(self, clause, **kwargs):",
            "        x = \"CASE \"",
            "        if clause.value is not None:",
            "            x += clause.value._compiler_dispatch(self, **kwargs) + \" \"",
            "        for cond, result in clause.whens:",
            "            x += (",
            "                \"WHEN \"",
            "                + cond._compiler_dispatch(self, **kwargs)",
            "                + \" THEN \"",
            "                + result._compiler_dispatch(self, **kwargs)",
            "                + \" \"",
            "            )",
            "        if clause.else_ is not None:",
            "            x += (",
            "                \"ELSE \" + clause.else_._compiler_dispatch(self, **kwargs) + \" \"",
            "            )",
            "        x += \"END\"",
            "        return x",
            "",
            "    def visit_type_coerce(self, type_coerce, **kw):",
            "        return type_coerce.typed_expression._compiler_dispatch(self, **kw)",
            "",
            "    def visit_cast(self, cast, **kwargs):",
            "        return \"CAST(%s AS %s)\" % (",
            "            cast.clause._compiler_dispatch(self, **kwargs),",
            "            cast.typeclause._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def _format_frame_clause(self, range_, **kw):",
            "",
            "        return \"%s AND %s\" % (",
            "            \"UNBOUNDED PRECEDING\"",
            "            if range_[0] is elements.RANGE_UNBOUNDED",
            "            else \"CURRENT ROW\"",
            "            if range_[0] is elements.RANGE_CURRENT",
            "            else \"%s PRECEDING\"",
            "            % (self.process(elements.literal(abs(range_[0])), **kw),)",
            "            if range_[0] < 0",
            "            else \"%s FOLLOWING\"",
            "            % (self.process(elements.literal(range_[0]), **kw),),",
            "            \"UNBOUNDED FOLLOWING\"",
            "            if range_[1] is elements.RANGE_UNBOUNDED",
            "            else \"CURRENT ROW\"",
            "            if range_[1] is elements.RANGE_CURRENT",
            "            else \"%s PRECEDING\"",
            "            % (self.process(elements.literal(abs(range_[1])), **kw),)",
            "            if range_[1] < 0",
            "            else \"%s FOLLOWING\"",
            "            % (self.process(elements.literal(range_[1]), **kw),),",
            "        )",
            "",
            "    def visit_over(self, over, **kwargs):",
            "        if over.range_:",
            "            range_ = \"RANGE BETWEEN %s\" % self._format_frame_clause(",
            "                over.range_, **kwargs",
            "            )",
            "        elif over.rows:",
            "            range_ = \"ROWS BETWEEN %s\" % self._format_frame_clause(",
            "                over.rows, **kwargs",
            "            )",
            "        else:",
            "            range_ = None",
            "",
            "        return \"%s OVER (%s)\" % (",
            "            over.element._compiler_dispatch(self, **kwargs),",
            "            \" \".join(",
            "                [",
            "                    \"%s BY %s\"",
            "                    % (word, clause._compiler_dispatch(self, **kwargs))",
            "                    for word, clause in (",
            "                        (\"PARTITION\", over.partition_by),",
            "                        (\"ORDER\", over.order_by),",
            "                    )",
            "                    if clause is not None and len(clause)",
            "                ]",
            "                + ([range_] if range_ else [])",
            "            ),",
            "        )",
            "",
            "    def visit_withingroup(self, withingroup, **kwargs):",
            "        return \"%s WITHIN GROUP (ORDER BY %s)\" % (",
            "            withingroup.element._compiler_dispatch(self, **kwargs),",
            "            withingroup.order_by._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_funcfilter(self, funcfilter, **kwargs):",
            "        return \"%s FILTER (WHERE %s)\" % (",
            "            funcfilter.func._compiler_dispatch(self, **kwargs),",
            "            funcfilter.criterion._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_extract(self, extract, **kwargs):",
            "        field = self.extract_map.get(extract.field, extract.field)",
            "        return \"EXTRACT(%s FROM %s)\" % (",
            "            field,",
            "            extract.expr._compiler_dispatch(self, **kwargs),",
            "        )",
            "",
            "    def visit_function(self, func, add_to_result_map=None, **kwargs):",
            "        if add_to_result_map is not None:",
            "            add_to_result_map(func.name, func.name, (), func.type)",
            "",
            "        disp = getattr(self, \"visit_%s_func\" % func.name.lower(), None)",
            "        if disp:",
            "            return disp(func, **kwargs)",
            "        else:",
            "            name = FUNCTIONS.get(func.__class__, None)",
            "            if name:",
            "                if func._has_args:",
            "                    name += \"%(expr)s\"",
            "            else:",
            "                name = func.name",
            "                name = (",
            "                    self.preparer.quote(name)",
            "                    if self.preparer._requires_quotes_illegal_chars(name)",
            "                    else name",
            "                )",
            "                name = name + \"%(expr)s\"",
            "            return \".\".join(",
            "                [",
            "                    (",
            "                        self.preparer.quote(tok)",
            "                        if self.preparer._requires_quotes_illegal_chars(tok)",
            "                        else tok",
            "                    )",
            "                    for tok in func.packagenames",
            "                ]",
            "                + [name]",
            "            ) % {\"expr\": self.function_argspec(func, **kwargs)}",
            "",
            "    def visit_next_value_func(self, next_value, **kw):",
            "        return self.visit_sequence(next_value.sequence)",
            "",
            "    def visit_sequence(self, sequence, **kw):",
            "        raise NotImplementedError(",
            "            \"Dialect '%s' does not support sequence increments.\"",
            "            % self.dialect.name",
            "        )",
            "",
            "    def function_argspec(self, func, **kwargs):",
            "        return func.clause_expr._compiler_dispatch(self, **kwargs)",
            "",
            "    def visit_compound_select(",
            "        self, cs, asfrom=False, parens=True, compound_index=0, **kwargs",
            "    ):",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "        need_result_map = toplevel or (",
            "            compound_index == 0",
            "            and entry.get(\"need_result_map_for_compound\", False)",
            "        )",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": entry[\"correlate_froms\"],",
            "                \"asfrom_froms\": entry[\"asfrom_froms\"],",
            "                \"selectable\": cs,",
            "                \"need_result_map_for_compound\": need_result_map,",
            "            }",
            "        )",
            "",
            "        keyword = self.compound_keywords.get(cs.keyword)",
            "",
            "        text = (\" \" + keyword + \" \").join(",
            "            (",
            "                c._compiler_dispatch(",
            "                    self,",
            "                    asfrom=asfrom,",
            "                    parens=False,",
            "                    compound_index=i,",
            "                    **kwargs",
            "                )",
            "                for i, c in enumerate(cs.selects)",
            "            )",
            "        )",
            "",
            "        text += self.group_by_clause(cs, **dict(asfrom=asfrom, **kwargs))",
            "        text += self.order_by_clause(cs, **kwargs)",
            "        text += (",
            "            (cs._limit_clause is not None or cs._offset_clause is not None)",
            "            and self.limit_clause(cs, **kwargs)",
            "            or \"\"",
            "        )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "        if asfrom and parens:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def _get_operator_dispatch(self, operator_, qualifier1, qualifier2):",
            "        attrname = \"visit_%s_%s%s\" % (",
            "            operator_.__name__,",
            "            qualifier1,",
            "            \"_\" + qualifier2 if qualifier2 else \"\",",
            "        )",
            "        return getattr(self, attrname, None)",
            "",
            "    def visit_unary(self, unary, **kw):",
            "        if unary.operator:",
            "            if unary.modifier:",
            "                raise exc.CompileError(",
            "                    \"Unary expression does not support operator \"",
            "                    \"and modifier simultaneously\"",
            "                )",
            "            disp = self._get_operator_dispatch(",
            "                unary.operator, \"unary\", \"operator\"",
            "            )",
            "            if disp:",
            "                return disp(unary, unary.operator, **kw)",
            "            else:",
            "                return self._generate_generic_unary_operator(",
            "                    unary, OPERATORS[unary.operator], **kw",
            "                )",
            "        elif unary.modifier:",
            "            disp = self._get_operator_dispatch(",
            "                unary.modifier, \"unary\", \"modifier\"",
            "            )",
            "            if disp:",
            "                return disp(unary, unary.modifier, **kw)",
            "            else:",
            "                return self._generate_generic_unary_modifier(",
            "                    unary, OPERATORS[unary.modifier], **kw",
            "                )",
            "        else:",
            "            raise exc.CompileError(",
            "                \"Unary expression has no operator or modifier\"",
            "            )",
            "",
            "    def visit_istrue_unary_operator(self, element, operator, **kw):",
            "        if (",
            "            element._is_implicitly_boolean",
            "            or self.dialect.supports_native_boolean",
            "        ):",
            "            return self.process(element.element, **kw)",
            "        else:",
            "            return \"%s = 1\" % self.process(element.element, **kw)",
            "",
            "    def visit_isfalse_unary_operator(self, element, operator, **kw):",
            "        if (",
            "            element._is_implicitly_boolean",
            "            or self.dialect.supports_native_boolean",
            "        ):",
            "            return \"NOT %s\" % self.process(element.element, **kw)",
            "        else:",
            "            return \"%s = 0\" % self.process(element.element, **kw)",
            "",
            "    def visit_notmatch_op_binary(self, binary, operator, **kw):",
            "        return \"NOT %s\" % self.visit_binary(",
            "            binary, override_operator=operators.match_op",
            "        )",
            "",
            "    def _emit_empty_in_warning(self):",
            "        util.warn(",
            "            \"The IN-predicate was invoked with an \"",
            "            \"empty sequence. This results in a \"",
            "            \"contradiction, which nonetheless can be \"",
            "            \"expensive to evaluate.  Consider alternative \"",
            "            \"strategies for improved performance.\"",
            "        )",
            "",
            "    def visit_empty_in_op_binary(self, binary, operator, **kw):",
            "        if self.dialect._use_static_in:",
            "            return \"1 != 1\"",
            "        else:",
            "            if self.dialect._warn_on_empty_in:",
            "                self._emit_empty_in_warning()",
            "            return self.process(binary.left != binary.left)",
            "",
            "    def visit_empty_notin_op_binary(self, binary, operator, **kw):",
            "        if self.dialect._use_static_in:",
            "            return \"1 = 1\"",
            "        else:",
            "            if self.dialect._warn_on_empty_in:",
            "                self._emit_empty_in_warning()",
            "            return self.process(binary.left == binary.left)",
            "",
            "    def visit_empty_set_expr(self, element_types):",
            "        raise NotImplementedError(",
            "            \"Dialect '%s' does not support empty set expression.\"",
            "            % self.dialect.name",
            "        )",
            "",
            "    def visit_binary(",
            "        self, binary, override_operator=None, eager_grouping=False, **kw",
            "    ):",
            "",
            "        # don't allow \"? = ?\" to render",
            "        if (",
            "            self.ansi_bind_rules",
            "            and isinstance(binary.left, elements.BindParameter)",
            "            and isinstance(binary.right, elements.BindParameter)",
            "        ):",
            "            kw[\"literal_binds\"] = True",
            "",
            "        operator_ = override_operator or binary.operator",
            "        disp = self._get_operator_dispatch(operator_, \"binary\", None)",
            "        if disp:",
            "            return disp(binary, operator_, **kw)",
            "        else:",
            "            try:",
            "                opstring = OPERATORS[operator_]",
            "            except KeyError:",
            "                raise exc.UnsupportedCompilationError(self, operator_)",
            "            else:",
            "                return self._generate_generic_binary(binary, opstring, **kw)",
            "",
            "    def visit_function_as_comparison_op_binary(self, element, operator, **kw):",
            "        return self.process(element.sql_function, **kw)",
            "",
            "    def visit_mod_binary(self, binary, operator, **kw):",
            "        if self.preparer._double_percents:",
            "            return (",
            "                self.process(binary.left, **kw)",
            "                + \" %% \"",
            "                + self.process(binary.right, **kw)",
            "            )",
            "        else:",
            "            return (",
            "                self.process(binary.left, **kw)",
            "                + \" % \"",
            "                + self.process(binary.right, **kw)",
            "            )",
            "",
            "    def visit_custom_op_binary(self, element, operator, **kw):",
            "        kw[\"eager_grouping\"] = operator.eager_grouping",
            "        return self._generate_generic_binary(",
            "            element, \" \" + operator.opstring + \" \", **kw",
            "        )",
            "",
            "    def visit_custom_op_unary_operator(self, element, operator, **kw):",
            "        return self._generate_generic_unary_operator(",
            "            element, operator.opstring + \" \", **kw",
            "        )",
            "",
            "    def visit_custom_op_unary_modifier(self, element, operator, **kw):",
            "        return self._generate_generic_unary_modifier(",
            "            element, \" \" + operator.opstring, **kw",
            "        )",
            "",
            "    def _generate_generic_binary(",
            "        self, binary, opstring, eager_grouping=False, **kw",
            "    ):",
            "",
            "        _in_binary = kw.get(\"_in_binary\", False)",
            "",
            "        kw[\"_in_binary\"] = True",
            "        text = (",
            "            binary.left._compiler_dispatch(",
            "                self, eager_grouping=eager_grouping, **kw",
            "            )",
            "            + opstring",
            "            + binary.right._compiler_dispatch(",
            "                self, eager_grouping=eager_grouping, **kw",
            "            )",
            "        )",
            "",
            "        if _in_binary and eager_grouping:",
            "            text = \"(%s)\" % text",
            "        return text",
            "",
            "    def _generate_generic_unary_operator(self, unary, opstring, **kw):",
            "        return opstring + unary.element._compiler_dispatch(self, **kw)",
            "",
            "    def _generate_generic_unary_modifier(self, unary, opstring, **kw):",
            "        return unary.element._compiler_dispatch(self, **kw) + opstring",
            "",
            "    @util.memoized_property",
            "    def _like_percent_literal(self):",
            "        return elements.literal_column(\"'%'\", type_=sqltypes.STRINGTYPE)",
            "",
            "    def visit_contains_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right).__add__(percent)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notcontains_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right).__add__(percent)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_startswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__radd__(binary.right)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notstartswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__radd__(binary.right)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_endswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right)",
            "        return self.visit_like_op_binary(binary, operator, **kw)",
            "",
            "    def visit_notendswith_op_binary(self, binary, operator, **kw):",
            "        binary = binary._clone()",
            "        percent = self._like_percent_literal",
            "        binary.right = percent.__add__(binary.right)",
            "        return self.visit_notlike_op_binary(binary, operator, **kw)",
            "",
            "    def visit_like_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "",
            "        # TODO: use ternary here, not \"and\"/ \"or\"",
            "        return \"%s LIKE %s\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notlike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"%s NOT LIKE %s\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_ilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"lower(%s) LIKE lower(%s)\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_notilike_op_binary(self, binary, operator, **kw):",
            "        escape = binary.modifiers.get(\"escape\", None)",
            "        return \"lower(%s) NOT LIKE lower(%s)\" % (",
            "            binary.left._compiler_dispatch(self, **kw),",
            "            binary.right._compiler_dispatch(self, **kw),",
            "        ) + (",
            "            \" ESCAPE \" + self.render_literal_value(escape, sqltypes.STRINGTYPE)",
            "            if escape",
            "            else \"\"",
            "        )",
            "",
            "    def visit_between_op_binary(self, binary, operator, **kw):",
            "        symmetric = binary.modifiers.get(\"symmetric\", False)",
            "        return self._generate_generic_binary(",
            "            binary, \" BETWEEN SYMMETRIC \" if symmetric else \" BETWEEN \", **kw",
            "        )",
            "",
            "    def visit_notbetween_op_binary(self, binary, operator, **kw):",
            "        symmetric = binary.modifiers.get(\"symmetric\", False)",
            "        return self._generate_generic_binary(",
            "            binary,",
            "            \" NOT BETWEEN SYMMETRIC \" if symmetric else \" NOT BETWEEN \",",
            "            **kw",
            "        )",
            "",
            "    def visit_bindparam(",
            "        self,",
            "        bindparam,",
            "        within_columns_clause=False,",
            "        literal_binds=False,",
            "        skip_bind_expression=False,",
            "        **kwargs",
            "    ):",
            "",
            "        if not skip_bind_expression:",
            "            impl = bindparam.type.dialect_impl(self.dialect)",
            "            if impl._has_bind_expression:",
            "                bind_expression = impl.bind_expression(bindparam)",
            "                return self.process(",
            "                    bind_expression,",
            "                    skip_bind_expression=True,",
            "                    within_columns_clause=within_columns_clause,",
            "                    literal_binds=literal_binds,",
            "                    **kwargs",
            "                )",
            "",
            "        if literal_binds or (within_columns_clause and self.ansi_bind_rules):",
            "            if bindparam.value is None and bindparam.callable is None:",
            "                raise exc.CompileError(",
            "                    \"Bind parameter '%s' without a \"",
            "                    \"renderable value not allowed here.\" % bindparam.key",
            "                )",
            "            return self.render_literal_bindparam(",
            "                bindparam, within_columns_clause=True, **kwargs",
            "            )",
            "",
            "        name = self._truncate_bindparam(bindparam)",
            "",
            "        if name in self.binds:",
            "            existing = self.binds[name]",
            "            if existing is not bindparam:",
            "                if (",
            "                    existing.unique or bindparam.unique",
            "                ) and not existing.proxy_set.intersection(bindparam.proxy_set):",
            "                    raise exc.CompileError(",
            "                        \"Bind parameter '%s' conflicts with \"",
            "                        \"unique bind parameter of the same name\"",
            "                        % bindparam.key",
            "                    )",
            "                elif existing._is_crud or bindparam._is_crud:",
            "                    raise exc.CompileError(",
            "                        \"bindparam() name '%s' is reserved \"",
            "                        \"for automatic usage in the VALUES or SET \"",
            "                        \"clause of this \"",
            "                        \"insert/update statement.   Please use a \"",
            "                        \"name other than column name when using bindparam() \"",
            "                        \"with insert() or update() (for example, 'b_%s').\"",
            "                        % (bindparam.key, bindparam.key)",
            "                    )",
            "",
            "        self.binds[bindparam.key] = self.binds[name] = bindparam",
            "",
            "        return self.bindparam_string(",
            "            name, expanding=bindparam.expanding, **kwargs",
            "        )",
            "",
            "    def render_literal_bindparam(self, bindparam, **kw):",
            "        value = bindparam.effective_value",
            "        return self.render_literal_value(value, bindparam.type)",
            "",
            "    def render_literal_value(self, value, type_):",
            "        \"\"\"Render the value of a bind parameter as a quoted literal.",
            "",
            "        This is used for statement sections that do not accept bind parameters",
            "        on the target driver/database.",
            "",
            "        This should be implemented by subclasses using the quoting services",
            "        of the DBAPI.",
            "",
            "        \"\"\"",
            "",
            "        processor = type_._cached_literal_processor(self.dialect)",
            "        if processor:",
            "            return processor(value)",
            "        else:",
            "            raise NotImplementedError(",
            "                \"Don't know how to literal-quote value %r\" % value",
            "            )",
            "",
            "    def _truncate_bindparam(self, bindparam):",
            "        if bindparam in self.bind_names:",
            "            return self.bind_names[bindparam]",
            "",
            "        bind_name = bindparam.key",
            "        if isinstance(bind_name, elements._truncated_label):",
            "            bind_name = self._truncated_identifier(\"bindparam\", bind_name)",
            "",
            "        # add to bind_names for translation",
            "        self.bind_names[bindparam] = bind_name",
            "",
            "        return bind_name",
            "",
            "    def _truncated_identifier(self, ident_class, name):",
            "        if (ident_class, name) in self.truncated_names:",
            "            return self.truncated_names[(ident_class, name)]",
            "",
            "        anonname = name.apply_map(self.anon_map)",
            "",
            "        if len(anonname) > self.label_length - 6:",
            "            counter = self.truncated_names.get(ident_class, 1)",
            "            truncname = (",
            "                anonname[0 : max(self.label_length - 6, 0)]",
            "                + \"_\"",
            "                + hex(counter)[2:]",
            "            )",
            "            self.truncated_names[ident_class] = counter + 1",
            "        else:",
            "            truncname = anonname",
            "        self.truncated_names[(ident_class, name)] = truncname",
            "        return truncname",
            "",
            "    def _anonymize(self, name):",
            "        return name % self.anon_map",
            "",
            "    def _process_anon(self, key):",
            "        (ident, derived) = key.split(\" \", 1)",
            "        anonymous_counter = self.anon_map.get(derived, 1)",
            "        self.anon_map[derived] = anonymous_counter + 1",
            "        return derived + \"_\" + str(anonymous_counter)",
            "",
            "    def bindparam_string(",
            "        self, name, positional_names=None, expanding=False, **kw",
            "    ):",
            "        if self.positional:",
            "            if positional_names is not None:",
            "                positional_names.append(name)",
            "            else:",
            "                self.positiontup.append(name)",
            "        if expanding:",
            "            self.contains_expanding_parameters = True",
            "            return \"([EXPANDING_%s])\" % name",
            "        else:",
            "            return self.bindtemplate % {\"name\": name}",
            "",
            "    def visit_cte(",
            "        self,",
            "        cte,",
            "        asfrom=False,",
            "        ashint=False,",
            "        fromhints=None,",
            "        visiting_cte=None,",
            "        **kwargs",
            "    ):",
            "        self._init_cte_state()",
            "",
            "        kwargs[\"visiting_cte\"] = cte",
            "        if isinstance(cte.name, elements._truncated_label):",
            "            cte_name = self._truncated_identifier(\"alias\", cte.name)",
            "        else:",
            "            cte_name = cte.name",
            "",
            "        is_new_cte = True",
            "        embedded_in_current_named_cte = False",
            "",
            "        if cte_name in self.ctes_by_name:",
            "            existing_cte = self.ctes_by_name[cte_name]",
            "            embedded_in_current_named_cte = visiting_cte is existing_cte",
            "",
            "            # we've generated a same-named CTE that we are enclosed in,",
            "            # or this is the same CTE.  just return the name.",
            "            if cte in existing_cte._restates or cte is existing_cte:",
            "                is_new_cte = False",
            "            elif existing_cte in cte._restates:",
            "                # we've generated a same-named CTE that is",
            "                # enclosed in us - we take precedence, so",
            "                # discard the text for the \"inner\".",
            "                del self.ctes[existing_cte]",
            "            else:",
            "                raise exc.CompileError(",
            "                    \"Multiple, unrelated CTEs found with \"",
            "                    \"the same name: %r\" % cte_name",
            "                )",
            "",
            "        if asfrom or is_new_cte:",
            "            if cte._cte_alias is not None:",
            "                pre_alias_cte = cte._cte_alias",
            "                cte_pre_alias_name = cte._cte_alias.name",
            "                if isinstance(cte_pre_alias_name, elements._truncated_label):",
            "                    cte_pre_alias_name = self._truncated_identifier(",
            "                        \"alias\", cte_pre_alias_name",
            "                    )",
            "            else:",
            "                pre_alias_cte = cte",
            "                cte_pre_alias_name = None",
            "",
            "        if is_new_cte:",
            "            self.ctes_by_name[cte_name] = cte",
            "",
            "            # look for embedded DML ctes and propagate autocommit",
            "            if (",
            "                \"autocommit\" in cte.element._execution_options",
            "                and \"autocommit\" not in self.execution_options",
            "            ):",
            "                self.execution_options = self.execution_options.union(",
            "                    {",
            "                        \"autocommit\": cte.element._execution_options[",
            "                            \"autocommit\"",
            "                        ]",
            "                    }",
            "                )",
            "",
            "            if pre_alias_cte not in self.ctes:",
            "                self.visit_cte(pre_alias_cte, **kwargs)",
            "",
            "            if not cte_pre_alias_name and cte not in self.ctes:",
            "                if cte.recursive:",
            "                    self.ctes_recursive = True",
            "                text = self.preparer.format_alias(cte, cte_name)",
            "                if cte.recursive:",
            "                    if isinstance(cte.original, selectable.Select):",
            "                        col_source = cte.original",
            "                    elif isinstance(cte.original, selectable.CompoundSelect):",
            "                        col_source = cte.original.selects[0]",
            "                    else:",
            "                        assert False",
            "                    recur_cols = [",
            "                        c",
            "                        for c in util.unique_list(col_source.inner_columns)",
            "                        if c is not None",
            "                    ]",
            "",
            "                    text += \"(%s)\" % (",
            "                        \", \".join(",
            "                            self.preparer.format_column(ident)",
            "                            for ident in recur_cols",
            "                        )",
            "                    )",
            "",
            "                if self.positional:",
            "                    kwargs[\"positional_names\"] = self.cte_positional[cte] = []",
            "",
            "                text += \" AS \\n\" + cte.original._compiler_dispatch(",
            "                    self, asfrom=True, **kwargs",
            "                )",
            "",
            "                if cte._suffixes:",
            "                    text += \" \" + self._generate_prefixes(",
            "                        cte, cte._suffixes, **kwargs",
            "                    )",
            "",
            "                self.ctes[cte] = text",
            "",
            "        if asfrom:",
            "            if not is_new_cte and embedded_in_current_named_cte:",
            "                return self.preparer.format_alias(cte, cte_name)",
            "",
            "            if cte_pre_alias_name:",
            "                text = self.preparer.format_alias(cte, cte_pre_alias_name)",
            "                if self.preparer._requires_quotes(cte_name):",
            "                    cte_name = self.preparer.quote(cte_name)",
            "                text += self.get_render_as_alias_suffix(cte_name)",
            "                return text",
            "            else:",
            "                return self.preparer.format_alias(cte, cte_name)",
            "",
            "    def visit_alias(",
            "        self,",
            "        alias,",
            "        asfrom=False,",
            "        ashint=False,",
            "        iscrud=False,",
            "        fromhints=None,",
            "        **kwargs",
            "    ):",
            "        if asfrom or ashint:",
            "            if isinstance(alias.name, elements._truncated_label):",
            "                alias_name = self._truncated_identifier(\"alias\", alias.name)",
            "            else:",
            "                alias_name = alias.name",
            "",
            "        if ashint:",
            "            return self.preparer.format_alias(alias, alias_name)",
            "        elif asfrom:",
            "            ret = alias.original._compiler_dispatch(",
            "                self, asfrom=True, **kwargs",
            "            ) + self.get_render_as_alias_suffix(",
            "                self.preparer.format_alias(alias, alias_name)",
            "            )",
            "",
            "            if fromhints and alias in fromhints:",
            "                ret = self.format_from_hint_text(",
            "                    ret, alias, fromhints[alias], iscrud",
            "                )",
            "",
            "            return ret",
            "        else:",
            "            return alias.original._compiler_dispatch(self, **kwargs)",
            "",
            "    def visit_lateral(self, lateral, **kw):",
            "        kw[\"lateral\"] = True",
            "        return \"LATERAL %s\" % self.visit_alias(lateral, **kw)",
            "",
            "    def visit_tablesample(self, tablesample, asfrom=False, **kw):",
            "        text = \"%s TABLESAMPLE %s\" % (",
            "            self.visit_alias(tablesample, asfrom=True, **kw),",
            "            tablesample._get_method()._compiler_dispatch(self, **kw),",
            "        )",
            "",
            "        if tablesample.seed is not None:",
            "            text += \" REPEATABLE (%s)\" % (",
            "                tablesample.seed._compiler_dispatch(self, **kw)",
            "            )",
            "",
            "        return text",
            "",
            "    def get_render_as_alias_suffix(self, alias_name_text):",
            "        return \" AS \" + alias_name_text",
            "",
            "    def _add_to_result_map(self, keyname, name, objects, type_):",
            "        self._result_columns.append((keyname, name, objects, type_))",
            "",
            "    def _label_select_column(",
            "        self,",
            "        select,",
            "        column,",
            "        populate_result_map,",
            "        asfrom,",
            "        column_clause_args,",
            "        name=None,",
            "        within_columns_clause=True,",
            "    ):",
            "        \"\"\"produce labeled columns present in a select().\"\"\"",
            "",
            "        impl = column.type.dialect_impl(self.dialect)",
            "        if impl._has_column_expression and populate_result_map:",
            "            col_expr = impl.column_expression(column)",
            "",
            "            def add_to_result_map(keyname, name, objects, type_):",
            "                self._add_to_result_map(",
            "                    keyname, name, (column,) + objects, type_",
            "                )",
            "",
            "        else:",
            "            col_expr = column",
            "            if populate_result_map:",
            "                add_to_result_map = self._add_to_result_map",
            "            else:",
            "                add_to_result_map = None",
            "",
            "        if not within_columns_clause:",
            "            result_expr = col_expr",
            "        elif isinstance(column, elements.Label):",
            "            if col_expr is not column:",
            "                result_expr = _CompileLabel(",
            "                    col_expr, column.name, alt_names=(column.element,)",
            "                )",
            "            else:",
            "                result_expr = col_expr",
            "",
            "        elif select is not None and name:",
            "            result_expr = _CompileLabel(",
            "                col_expr, name, alt_names=(column._key_label,)",
            "            )",
            "",
            "        elif (",
            "            asfrom",
            "            and isinstance(column, elements.ColumnClause)",
            "            and not column.is_literal",
            "            and column.table is not None",
            "            and not isinstance(column.table, selectable.Select)",
            "        ):",
            "            result_expr = _CompileLabel(",
            "                col_expr,",
            "                elements._as_truncated(column.name),",
            "                alt_names=(column.key,),",
            "            )",
            "        elif (",
            "            not isinstance(column, elements.TextClause)",
            "            and (",
            "                not isinstance(column, elements.UnaryExpression)",
            "                or column.wraps_column_expression",
            "            )",
            "            and (",
            "                not hasattr(column, \"name\")",
            "                or isinstance(column, functions.Function)",
            "            )",
            "        ):",
            "            result_expr = _CompileLabel(col_expr, column.anon_label)",
            "        elif col_expr is not column:",
            "            # TODO: are we sure \"column\" has a .name and .key here ?",
            "            # assert isinstance(column, elements.ColumnClause)",
            "            result_expr = _CompileLabel(",
            "                col_expr,",
            "                elements._as_truncated(column.name),",
            "                alt_names=(column.key,),",
            "            )",
            "        else:",
            "            result_expr = col_expr",
            "",
            "        column_clause_args.update(",
            "            within_columns_clause=within_columns_clause,",
            "            add_to_result_map=add_to_result_map,",
            "        )",
            "        return result_expr._compiler_dispatch(self, **column_clause_args)",
            "",
            "    def format_from_hint_text(self, sqltext, table, hint, iscrud):",
            "        hinttext = self.get_from_hint_text(table, hint)",
            "        if hinttext:",
            "            sqltext += \" \" + hinttext",
            "        return sqltext",
            "",
            "    def get_select_hint_text(self, byfroms):",
            "        return None",
            "",
            "    def get_from_hint_text(self, table, text):",
            "        return None",
            "",
            "    def get_crud_hint_text(self, table, text):",
            "        return None",
            "",
            "    def get_statement_hint_text(self, hint_texts):",
            "        return \" \".join(hint_texts)",
            "",
            "    def _transform_select_for_nested_joins(self, select):",
            "        \"\"\"Rewrite any \"a JOIN (b JOIN c)\" expression as",
            "        \"a JOIN (select * from b JOIN c) AS anon\", to support",
            "        databases that can't parse a parenthesized join correctly",
            "        (i.e. sqlite < 3.7.16).",
            "",
            "        \"\"\"",
            "        cloned = {}",
            "        column_translate = [{}]",
            "",
            "        def visit(element, **kw):",
            "            if element in column_translate[-1]:",
            "                return column_translate[-1][element]",
            "",
            "            elif element in cloned:",
            "                return cloned[element]",
            "",
            "            newelem = cloned[element] = element._clone()",
            "",
            "            if (",
            "                newelem.is_selectable",
            "                and newelem._is_join",
            "                and isinstance(newelem.right, selectable.FromGrouping)",
            "            ):",
            "",
            "                newelem._reset_exported()",
            "                newelem.left = visit(newelem.left, **kw)",
            "",
            "                right = visit(newelem.right, **kw)",
            "",
            "                selectable_ = selectable.Select(",
            "                    [right.element], use_labels=True",
            "                ).alias()",
            "",
            "                for c in selectable_.c:",
            "                    c._key_label = c.key",
            "                    c._label = c.name",
            "",
            "                translate_dict = dict(",
            "                    zip(newelem.right.element.c, selectable_.c)",
            "                )",
            "",
            "                # translating from both the old and the new",
            "                # because different select() structures will lead us",
            "                # to traverse differently",
            "                translate_dict[right.element.left] = selectable_",
            "                translate_dict[right.element.right] = selectable_",
            "                translate_dict[newelem.right.element.left] = selectable_",
            "                translate_dict[newelem.right.element.right] = selectable_",
            "",
            "                # propagate translations that we've gained",
            "                # from nested visit(newelem.right) outwards",
            "                # to the enclosing select here.  this happens",
            "                # only when we have more than one level of right",
            "                # join nesting, i.e. \"a JOIN (b JOIN (c JOIN d))\"",
            "                for k, v in list(column_translate[-1].items()):",
            "                    if v in translate_dict:",
            "                        # remarkably, no current ORM tests (May 2013)",
            "                        # hit this condition, only test_join_rewriting",
            "                        # does.",
            "                        column_translate[-1][k] = translate_dict[v]",
            "",
            "                column_translate[-1].update(translate_dict)",
            "",
            "                newelem.right = selectable_",
            "",
            "                newelem.onclause = visit(newelem.onclause, **kw)",
            "",
            "            elif newelem._is_from_container:",
            "                # if we hit an Alias, CompoundSelect or ScalarSelect, put a",
            "                # marker in the stack.",
            "                kw[\"transform_clue\"] = \"select_container\"",
            "                newelem._copy_internals(clone=visit, **kw)",
            "            elif newelem.is_selectable and newelem._is_select:",
            "                barrier_select = (",
            "                    kw.get(\"transform_clue\", None) == \"select_container\"",
            "                )",
            "                # if we're still descended from an",
            "                # Alias/CompoundSelect/ScalarSelect, we're",
            "                # in a FROM clause, so start with a new translate collection",
            "                if barrier_select:",
            "                    column_translate.append({})",
            "                kw[\"transform_clue\"] = \"inside_select\"",
            "                newelem._copy_internals(clone=visit, **kw)",
            "                if barrier_select:",
            "                    del column_translate[-1]",
            "            else:",
            "                newelem._copy_internals(clone=visit, **kw)",
            "",
            "            return newelem",
            "",
            "        return visit(select)",
            "",
            "    def _transform_result_map_for_nested_joins(",
            "        self, select, transformed_select",
            "    ):",
            "        inner_col = dict(",
            "            (c._key_label, c) for c in transformed_select.inner_columns",
            "        )",
            "",
            "        d = dict((inner_col[c._key_label], c) for c in select.inner_columns)",
            "",
            "        self._result_columns = [",
            "            (key, name, tuple([d.get(col, col) for col in objs]), typ)",
            "            for key, name, objs, typ in self._result_columns",
            "        ]",
            "",
            "    _default_stack_entry = util.immutabledict(",
            "        [(\"correlate_froms\", frozenset()), (\"asfrom_froms\", frozenset())]",
            "    )",
            "",
            "    def _display_froms_for_select(self, select, asfrom, lateral=False):",
            "        # utility method to help external dialects",
            "        # get the correct from list for a select.",
            "        # specifically the oracle dialect needs this feature",
            "        # right now.",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        correlate_froms = entry[\"correlate_froms\"]",
            "        asfrom_froms = entry[\"asfrom_froms\"]",
            "",
            "        if asfrom and not lateral:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms.difference(",
            "                    asfrom_froms",
            "                ),",
            "                implicit_correlate_froms=(),",
            "            )",
            "        else:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms,",
            "                implicit_correlate_froms=asfrom_froms,",
            "            )",
            "        return froms",
            "",
            "    def visit_select(",
            "        self,",
            "        select,",
            "        asfrom=False,",
            "        parens=True,",
            "        fromhints=None,",
            "        compound_index=0,",
            "        nested_join_translation=False,",
            "        select_wraps_for=None,",
            "        lateral=False,",
            "        **kwargs",
            "    ):",
            "",
            "        needs_nested_translation = (",
            "            select.use_labels",
            "            and not nested_join_translation",
            "            and not self.stack",
            "            and not self.dialect.supports_right_nested_joins",
            "        )",
            "",
            "        if needs_nested_translation:",
            "            transformed_select = self._transform_select_for_nested_joins(",
            "                select",
            "            )",
            "            text = self.visit_select(",
            "                transformed_select,",
            "                asfrom=asfrom,",
            "                parens=parens,",
            "                fromhints=fromhints,",
            "                compound_index=compound_index,",
            "                nested_join_translation=True,",
            "                **kwargs",
            "            )",
            "",
            "        toplevel = not self.stack",
            "        entry = self._default_stack_entry if toplevel else self.stack[-1]",
            "",
            "        populate_result_map = (",
            "            toplevel",
            "            or (",
            "                compound_index == 0",
            "                and entry.get(\"need_result_map_for_compound\", False)",
            "            )",
            "            or entry.get(\"need_result_map_for_nested\", False)",
            "        )",
            "",
            "        # this was first proposed as part of #3372; however, it is not",
            "        # reached in current tests and could possibly be an assertion",
            "        # instead.",
            "        if not populate_result_map and \"add_to_result_map\" in kwargs:",
            "            del kwargs[\"add_to_result_map\"]",
            "",
            "        if needs_nested_translation:",
            "            if populate_result_map:",
            "                self._transform_result_map_for_nested_joins(",
            "                    select, transformed_select",
            "                )",
            "            return text",
            "",
            "        froms = self._setup_select_stack(select, entry, asfrom, lateral)",
            "",
            "        column_clause_args = kwargs.copy()",
            "        column_clause_args.update(",
            "            {\"within_label_clause\": False, \"within_columns_clause\": False}",
            "        )",
            "",
            "        text = \"SELECT \"  # we're off to a good start !",
            "",
            "        if select._hints:",
            "            hint_text, byfrom = self._setup_select_hints(select)",
            "            if hint_text:",
            "                text += hint_text + \" \"",
            "        else:",
            "            byfrom = None",
            "",
            "        if select._prefixes:",
            "            text += self._generate_prefixes(select, select._prefixes, **kwargs)",
            "",
            "        text += self.get_select_precolumns(select, **kwargs)",
            "        # the actual list of columns to print in the SELECT column list.",
            "        inner_columns = [",
            "            c",
            "            for c in [",
            "                self._label_select_column(",
            "                    select,",
            "                    column,",
            "                    populate_result_map,",
            "                    asfrom,",
            "                    column_clause_args,",
            "                    name=name,",
            "                )",
            "                for name, column in select._columns_plus_names",
            "            ]",
            "            if c is not None",
            "        ]",
            "",
            "        if populate_result_map and select_wraps_for is not None:",
            "            # if this select is a compiler-generated wrapper,",
            "            # rewrite the targeted columns in the result map",
            "",
            "            translate = dict(",
            "                zip(",
            "                    [name for (key, name) in select._columns_plus_names],",
            "                    [",
            "                        name",
            "                        for (key, name) in select_wraps_for._columns_plus_names",
            "                    ],",
            "                )",
            "            )",
            "",
            "            self._result_columns = [",
            "                (key, name, tuple(translate.get(o, o) for o in obj), type_)",
            "                for key, name, obj, type_ in self._result_columns",
            "            ]",
            "",
            "        text = self._compose_select_body(",
            "            text, select, inner_columns, froms, byfrom, kwargs",
            "        )",
            "",
            "        if select._statement_hints:",
            "            per_dialect = [",
            "                ht",
            "                for (dialect_name, ht) in select._statement_hints",
            "                if dialect_name in (\"*\", self.dialect.name)",
            "            ]",
            "            if per_dialect:",
            "                text += \" \" + self.get_statement_hint_text(per_dialect)",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        if select._suffixes:",
            "            text += \" \" + self._generate_prefixes(",
            "                select, select._suffixes, **kwargs",
            "            )",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if (asfrom or lateral) and parens:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def _setup_select_hints(self, select):",
            "        byfrom = dict(",
            "            [",
            "                (",
            "                    from_,",
            "                    hinttext",
            "                    % {\"name\": from_._compiler_dispatch(self, ashint=True)},",
            "                )",
            "                for (from_, dialect), hinttext in select._hints.items()",
            "                if dialect in (\"*\", self.dialect.name)",
            "            ]",
            "        )",
            "        hint_text = self.get_select_hint_text(byfrom)",
            "        return hint_text, byfrom",
            "",
            "    def _setup_select_stack(self, select, entry, asfrom, lateral):",
            "        correlate_froms = entry[\"correlate_froms\"]",
            "        asfrom_froms = entry[\"asfrom_froms\"]",
            "",
            "        if asfrom and not lateral:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms.difference(",
            "                    asfrom_froms",
            "                ),",
            "                implicit_correlate_froms=(),",
            "            )",
            "        else:",
            "            froms = select._get_display_froms(",
            "                explicit_correlate_froms=correlate_froms,",
            "                implicit_correlate_froms=asfrom_froms,",
            "            )",
            "",
            "        new_correlate_froms = set(selectable._from_objects(*froms))",
            "        all_correlate_froms = new_correlate_froms.union(correlate_froms)",
            "",
            "        new_entry = {",
            "            \"asfrom_froms\": new_correlate_froms,",
            "            \"correlate_froms\": all_correlate_froms,",
            "            \"selectable\": select,",
            "        }",
            "        self.stack.append(new_entry)",
            "",
            "        return froms",
            "",
            "    def _compose_select_body(",
            "        self, text, select, inner_columns, froms, byfrom, kwargs",
            "    ):",
            "        text += \", \".join(inner_columns)",
            "",
            "        if froms:",
            "            text += \" \\nFROM \"",
            "",
            "            if select._hints:",
            "                text += \", \".join(",
            "                    [",
            "                        f._compiler_dispatch(",
            "                            self, asfrom=True, fromhints=byfrom, **kwargs",
            "                        )",
            "                        for f in froms",
            "                    ]",
            "                )",
            "            else:",
            "                text += \", \".join(",
            "                    [",
            "                        f._compiler_dispatch(self, asfrom=True, **kwargs)",
            "                        for f in froms",
            "                    ]",
            "                )",
            "        else:",
            "            text += self.default_from()",
            "",
            "        if select._whereclause is not None:",
            "            t = select._whereclause._compiler_dispatch(self, **kwargs)",
            "            if t:",
            "                text += \" \\nWHERE \" + t",
            "",
            "        if select._group_by_clause.clauses:",
            "            text += self.group_by_clause(select, **kwargs)",
            "",
            "        if select._having is not None:",
            "            t = select._having._compiler_dispatch(self, **kwargs)",
            "            if t:",
            "                text += \" \\nHAVING \" + t",
            "",
            "        if select._order_by_clause.clauses:",
            "            text += self.order_by_clause(select, **kwargs)",
            "",
            "        if (",
            "            select._limit_clause is not None",
            "            or select._offset_clause is not None",
            "        ):",
            "            text += self.limit_clause(select, **kwargs)",
            "",
            "        if select._for_update_arg is not None:",
            "            text += self.for_update_clause(select, **kwargs)",
            "",
            "        return text",
            "",
            "    def _generate_prefixes(self, stmt, prefixes, **kw):",
            "        clause = \" \".join(",
            "            prefix._compiler_dispatch(self, **kw)",
            "            for prefix, dialect_name in prefixes",
            "            if dialect_name is None or dialect_name == self.dialect.name",
            "        )",
            "        if clause:",
            "            clause += \" \"",
            "        return clause",
            "",
            "    def _render_cte_clause(self):",
            "        if self.positional:",
            "            self.positiontup = (",
            "                sum([self.cte_positional[cte] for cte in self.ctes], [])",
            "                + self.positiontup",
            "            )",
            "        cte_text = self.get_cte_preamble(self.ctes_recursive) + \" \"",
            "        cte_text += \", \\n\".join([txt for txt in self.ctes.values()])",
            "        cte_text += \"\\n \"",
            "        return cte_text",
            "",
            "    def get_cte_preamble(self, recursive):",
            "        if recursive:",
            "            return \"WITH RECURSIVE\"",
            "        else:",
            "            return \"WITH\"",
            "",
            "    def get_select_precolumns(self, select, **kw):",
            "        \"\"\"Called when building a ``SELECT`` statement, position is just",
            "        before column list.",
            "",
            "        \"\"\"",
            "        return select._distinct and \"DISTINCT \" or \"\"",
            "",
            "    def group_by_clause(self, select, **kw):",
            "        \"\"\"allow dialects to customize how GROUP BY is rendered.\"\"\"",
            "",
            "        group_by = select._group_by_clause._compiler_dispatch(self, **kw)",
            "        if group_by:",
            "            return \" GROUP BY \" + group_by",
            "        else:",
            "            return \"\"",
            "",
            "    def order_by_clause(self, select, **kw):",
            "        \"\"\"allow dialects to customize how ORDER BY is rendered.\"\"\"",
            "",
            "        order_by = select._order_by_clause._compiler_dispatch(self, **kw)",
            "        if order_by:",
            "            return \" ORDER BY \" + order_by",
            "        else:",
            "            return \"\"",
            "",
            "    def for_update_clause(self, select, **kw):",
            "        return \" FOR UPDATE\"",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "        raise exc.CompileError(",
            "            \"RETURNING is not supported by this \"",
            "            \"dialect's statement compiler.\"",
            "        )",
            "",
            "    def limit_clause(self, select, **kw):",
            "        text = \"\"",
            "        if select._limit_clause is not None:",
            "            text += \"\\n LIMIT \" + self.process(select._limit_clause, **kw)",
            "        if select._offset_clause is not None:",
            "            if select._limit_clause is None:",
            "                text += \"\\n LIMIT -1\"",
            "            text += \" OFFSET \" + self.process(select._offset_clause, **kw)",
            "        return text",
            "",
            "    def visit_table(",
            "        self,",
            "        table,",
            "        asfrom=False,",
            "        iscrud=False,",
            "        ashint=False,",
            "        fromhints=None,",
            "        use_schema=True,",
            "        **kwargs",
            "    ):",
            "        if asfrom or ashint:",
            "            effective_schema = self.preparer.schema_for_object(table)",
            "",
            "            if use_schema and effective_schema:",
            "                ret = (",
            "                    self.preparer.quote_schema(effective_schema)",
            "                    + \".\"",
            "                    + self.preparer.quote(table.name)",
            "                )",
            "            else:",
            "                ret = self.preparer.quote(table.name)",
            "            if fromhints and table in fromhints:",
            "                ret = self.format_from_hint_text(",
            "                    ret, table, fromhints[table], iscrud",
            "                )",
            "            return ret",
            "        else:",
            "            return \"\"",
            "",
            "    def visit_join(self, join, asfrom=False, **kwargs):",
            "        if join.full:",
            "            join_type = \" FULL OUTER JOIN \"",
            "        elif join.isouter:",
            "            join_type = \" LEFT OUTER JOIN \"",
            "        else:",
            "            join_type = \" JOIN \"",
            "        return (",
            "            join.left._compiler_dispatch(self, asfrom=True, **kwargs)",
            "            + join_type",
            "            + join.right._compiler_dispatch(self, asfrom=True, **kwargs)",
            "            + \" ON \"",
            "            + join.onclause._compiler_dispatch(self, **kwargs)",
            "        )",
            "",
            "    def _setup_crud_hints(self, stmt, table_text):",
            "        dialect_hints = dict(",
            "            [",
            "                (table, hint_text)",
            "                for (table, dialect), hint_text in stmt._hints.items()",
            "                if dialect in (\"*\", self.dialect.name)",
            "            ]",
            "        )",
            "        if stmt.table in dialect_hints:",
            "            table_text = self.format_from_hint_text(",
            "                table_text, stmt.table, dialect_hints[stmt.table], True",
            "            )",
            "        return dialect_hints, table_text",
            "",
            "    def visit_insert(self, insert_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": set(),",
            "                \"asfrom_froms\": set(),",
            "                \"selectable\": insert_stmt,",
            "            }",
            "        )",
            "",
            "        crud_params = crud._setup_crud_params(",
            "            self, insert_stmt, crud.ISINSERT, **kw",
            "        )",
            "",
            "        if (",
            "            not crud_params",
            "            and not self.dialect.supports_default_values",
            "            and not self.dialect.supports_empty_insert",
            "        ):",
            "            raise exc.CompileError(",
            "                \"The '%s' dialect with current database \"",
            "                \"version settings does not support empty \"",
            "                \"inserts.\" % self.dialect.name",
            "            )",
            "",
            "        if insert_stmt._has_multi_parameters:",
            "            if not self.dialect.supports_multivalues_insert:",
            "                raise exc.CompileError(",
            "                    \"The '%s' dialect with current database \"",
            "                    \"version settings does not support \"",
            "                    \"in-place multirow inserts.\" % self.dialect.name",
            "                )",
            "            crud_params_single = crud_params[0]",
            "        else:",
            "            crud_params_single = crud_params",
            "",
            "        preparer = self.preparer",
            "        supports_default_values = self.dialect.supports_default_values",
            "",
            "        text = \"INSERT \"",
            "",
            "        if insert_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                insert_stmt, insert_stmt._prefixes, **kw",
            "            )",
            "",
            "        text += \"INTO \"",
            "        table_text = preparer.format_table(insert_stmt.table)",
            "",
            "        if insert_stmt._hints:",
            "            _, table_text = self._setup_crud_hints(insert_stmt, table_text)",
            "",
            "        text += table_text",
            "",
            "        if crud_params_single or not supports_default_values:",
            "            text += \" (%s)\" % \", \".join(",
            "                [preparer.format_column(c[0]) for c in crud_params_single]",
            "            )",
            "",
            "        if self.returning or insert_stmt._returning:",
            "            returning_clause = self.returning_clause(",
            "                insert_stmt, self.returning or insert_stmt._returning",
            "            )",
            "",
            "            if self.returning_precedes_values:",
            "                text += \" \" + returning_clause",
            "        else:",
            "            returning_clause = None",
            "",
            "        if insert_stmt.select is not None:",
            "            select_text = self.process(self._insert_from_select, **kw)",
            "",
            "            if self.ctes and toplevel and self.dialect.cte_follows_insert:",
            "                text += \" %s%s\" % (self._render_cte_clause(), select_text)",
            "            else:",
            "                text += \" %s\" % select_text",
            "        elif not crud_params and supports_default_values:",
            "            text += \" DEFAULT VALUES\"",
            "        elif insert_stmt._has_multi_parameters:",
            "            text += \" VALUES %s\" % (",
            "                \", \".join(",
            "                    \"(%s)\" % (\", \".join(c[1] for c in crud_param_set))",
            "                    for crud_param_set in crud_params",
            "                )",
            "            )",
            "        else:",
            "            text += \" VALUES (%s)\" % \", \".join([c[1] for c in crud_params])",
            "",
            "        if insert_stmt._post_values_clause is not None:",
            "            post_values_clause = self.process(",
            "                insert_stmt._post_values_clause, **kw",
            "            )",
            "            if post_values_clause:",
            "                text += \" \" + post_values_clause",
            "",
            "        if returning_clause and not self.returning_precedes_values:",
            "            text += \" \" + returning_clause",
            "",
            "        if self.ctes and toplevel and not self.dialect.cte_follows_insert:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def update_limit_clause(self, update_stmt):",
            "        \"\"\"Provide a hook for MySQL to add LIMIT to the UPDATE\"\"\"",
            "        return None",
            "",
            "    def update_tables_clause(self, update_stmt, from_table, extra_froms, **kw):",
            "        \"\"\"Provide a hook to override the initial table clause",
            "        in an UPDATE statement.",
            "",
            "        MySQL overrides this.",
            "",
            "        \"\"\"",
            "        kw[\"asfrom\"] = True",
            "        return from_table._compiler_dispatch(self, iscrud=True, **kw)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Provide a hook to override the generation of an",
            "        UPDATE..FROM clause.",
            "",
            "        MySQL and MSSQL override this.",
            "",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"This backend does not support multiple-table \"",
            "            \"criteria within UPDATE\"",
            "        )",
            "",
            "    def visit_update(self, update_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        extra_froms = update_stmt._extra_froms",
            "        is_multitable = bool(extra_froms)",
            "",
            "        if is_multitable:",
            "            # main table might be a JOIN",
            "            main_froms = set(selectable._from_objects(update_stmt.table))",
            "            render_extra_froms = [",
            "                f for f in extra_froms if f not in main_froms",
            "            ]",
            "            correlate_froms = main_froms.union(extra_froms)",
            "        else:",
            "            render_extra_froms = []",
            "            correlate_froms = {update_stmt.table}",
            "",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": correlate_froms,",
            "                \"asfrom_froms\": correlate_froms,",
            "                \"selectable\": update_stmt,",
            "            }",
            "        )",
            "",
            "        text = \"UPDATE \"",
            "",
            "        if update_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                update_stmt, update_stmt._prefixes, **kw",
            "            )",
            "",
            "        table_text = self.update_tables_clause(",
            "            update_stmt, update_stmt.table, render_extra_froms, **kw",
            "        )",
            "        crud_params = crud._setup_crud_params(",
            "            self, update_stmt, crud.ISUPDATE, **kw",
            "        )",
            "",
            "        if update_stmt._hints:",
            "            dialect_hints, table_text = self._setup_crud_hints(",
            "                update_stmt, table_text",
            "            )",
            "        else:",
            "            dialect_hints = None",
            "",
            "        text += table_text",
            "",
            "        text += \" SET \"",
            "        include_table = (",
            "            is_multitable and self.render_table_with_column_in_update_from",
            "        )",
            "        text += \", \".join(",
            "            c[0]._compiler_dispatch(self, include_table=include_table)",
            "            + \"=\"",
            "            + c[1]",
            "            for c in crud_params",
            "        )",
            "",
            "        if self.returning or update_stmt._returning:",
            "            if self.returning_precedes_values:",
            "                text += \" \" + self.returning_clause(",
            "                    update_stmt, self.returning or update_stmt._returning",
            "                )",
            "",
            "        if extra_froms:",
            "            extra_from_text = self.update_from_clause(",
            "                update_stmt,",
            "                update_stmt.table,",
            "                render_extra_froms,",
            "                dialect_hints,",
            "                **kw",
            "            )",
            "            if extra_from_text:",
            "                text += \" \" + extra_from_text",
            "",
            "        if update_stmt._whereclause is not None:",
            "            t = self.process(update_stmt._whereclause, **kw)",
            "            if t:",
            "                text += \" WHERE \" + t",
            "",
            "        limit_clause = self.update_limit_clause(update_stmt)",
            "        if limit_clause:",
            "            text += \" \" + limit_clause",
            "",
            "        if (",
            "            self.returning or update_stmt._returning",
            "        ) and not self.returning_precedes_values:",
            "            text += \" \" + self.returning_clause(",
            "                update_stmt, self.returning or update_stmt._returning",
            "            )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    @util.memoized_property",
            "    def _key_getters_for_crud_column(self):",
            "        return crud._key_getters_for_crud_column(self, self.statement)",
            "",
            "    def delete_extra_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        \"\"\"Provide a hook to override the generation of an",
            "        DELETE..FROM clause.",
            "",
            "        This can be used to implement DELETE..USING for example.",
            "",
            "        MySQL and MSSQL override this.",
            "",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"This backend does not support multiple-table \"",
            "            \"criteria within DELETE\"",
            "        )",
            "",
            "    def delete_table_clause(self, delete_stmt, from_table, extra_froms):",
            "        return from_table._compiler_dispatch(self, asfrom=True, iscrud=True)",
            "",
            "    def visit_delete(self, delete_stmt, asfrom=False, **kw):",
            "        toplevel = not self.stack",
            "",
            "        crud._setup_crud_params(self, delete_stmt, crud.ISDELETE, **kw)",
            "",
            "        extra_froms = delete_stmt._extra_froms",
            "",
            "        correlate_froms = {delete_stmt.table}.union(extra_froms)",
            "        self.stack.append(",
            "            {",
            "                \"correlate_froms\": correlate_froms,",
            "                \"asfrom_froms\": correlate_froms,",
            "                \"selectable\": delete_stmt,",
            "            }",
            "        )",
            "",
            "        text = \"DELETE \"",
            "",
            "        if delete_stmt._prefixes:",
            "            text += self._generate_prefixes(",
            "                delete_stmt, delete_stmt._prefixes, **kw",
            "            )",
            "",
            "        text += \"FROM \"",
            "        table_text = self.delete_table_clause(",
            "            delete_stmt, delete_stmt.table, extra_froms",
            "        )",
            "",
            "        if delete_stmt._hints:",
            "            dialect_hints, table_text = self._setup_crud_hints(",
            "                delete_stmt, table_text",
            "            )",
            "        else:",
            "            dialect_hints = None",
            "",
            "        text += table_text",
            "",
            "        if delete_stmt._returning:",
            "            if self.returning_precedes_values:",
            "                text += \" \" + self.returning_clause(",
            "                    delete_stmt, delete_stmt._returning",
            "                )",
            "",
            "        if extra_froms:",
            "            extra_from_text = self.delete_extra_from_clause(",
            "                delete_stmt,",
            "                delete_stmt.table,",
            "                extra_froms,",
            "                dialect_hints,",
            "                **kw",
            "            )",
            "            if extra_from_text:",
            "                text += \" \" + extra_from_text",
            "",
            "        if delete_stmt._whereclause is not None:",
            "            t = delete_stmt._whereclause._compiler_dispatch(self, **kw)",
            "            if t:",
            "                text += \" WHERE \" + t",
            "",
            "        if delete_stmt._returning and not self.returning_precedes_values:",
            "            text += \" \" + self.returning_clause(",
            "                delete_stmt, delete_stmt._returning",
            "            )",
            "",
            "        if self.ctes and toplevel:",
            "            text = self._render_cte_clause() + text",
            "",
            "        self.stack.pop(-1)",
            "",
            "        if asfrom:",
            "            return \"(\" + text + \")\"",
            "        else:",
            "            return text",
            "",
            "    def visit_savepoint(self, savepoint_stmt):",
            "        return \"SAVEPOINT %s\" % self.preparer.format_savepoint(savepoint_stmt)",
            "",
            "    def visit_rollback_to_savepoint(self, savepoint_stmt):",
            "        return \"ROLLBACK TO SAVEPOINT %s\" % self.preparer.format_savepoint(",
            "            savepoint_stmt",
            "        )",
            "",
            "    def visit_release_savepoint(self, savepoint_stmt):",
            "        return \"RELEASE SAVEPOINT %s\" % self.preparer.format_savepoint(",
            "            savepoint_stmt",
            "        )",
            "",
            "",
            "class StrSQLCompiler(SQLCompiler):",
            "    \"\"\"\"a compiler subclass with a few non-standard SQL features allowed.",
            "",
            "    Used for stringification of SQL statements when a real dialect is not",
            "    available.",
            "",
            "    \"\"\"",
            "",
            "    def _fallback_column_name(self, column):",
            "        return \"<name unknown>\"",
            "",
            "    def visit_getitem_binary(self, binary, operator, **kw):",
            "        return \"%s[%s]\" % (",
            "            self.process(binary.left, **kw),",
            "            self.process(binary.right, **kw),",
            "        )",
            "",
            "    def visit_json_getitem_op_binary(self, binary, operator, **kw):",
            "        return self.visit_getitem_binary(binary, operator, **kw)",
            "",
            "    def visit_json_path_getitem_op_binary(self, binary, operator, **kw):",
            "        return self.visit_getitem_binary(binary, operator, **kw)",
            "",
            "    def visit_sequence(self, seq, **kw):",
            "        return \"<next sequence value: %s>\" % self.preparer.format_sequence(seq)",
            "",
            "    def returning_clause(self, stmt, returning_cols):",
            "        columns = [",
            "            self._label_select_column(None, c, True, False, {})",
            "            for c in elements._select_iterables(returning_cols)",
            "        ]",
            "",
            "        return \"RETURNING \" + \", \".join(columns)",
            "",
            "    def update_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \"FROM \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "    def delete_extra_from_clause(",
            "        self, update_stmt, from_table, extra_froms, from_hints, **kw",
            "    ):",
            "        return \", \" + \", \".join(",
            "            t._compiler_dispatch(self, asfrom=True, fromhints=from_hints, **kw)",
            "            for t in extra_froms",
            "        )",
            "",
            "",
            "class DDLCompiler(Compiled):",
            "    @util.memoized_property",
            "    def sql_compiler(self):",
            "        return self.dialect.statement_compiler(self.dialect, None)",
            "",
            "    @util.memoized_property",
            "    def type_compiler(self):",
            "        return self.dialect.type_compiler",
            "",
            "    def construct_params(self, params=None):",
            "        return None",
            "",
            "    def visit_ddl(self, ddl, **kwargs):",
            "        # table events can substitute table and schema name",
            "        context = ddl.context",
            "        if isinstance(ddl.target, schema.Table):",
            "            context = context.copy()",
            "",
            "            preparer = self.preparer",
            "            path = preparer.format_table_seq(ddl.target)",
            "            if len(path) == 1:",
            "                table, sch = path[0], \"\"",
            "            else:",
            "                table, sch = path[-1], path[0]",
            "",
            "            context.setdefault(\"table\", table)",
            "            context.setdefault(\"schema\", sch)",
            "            context.setdefault(\"fullname\", preparer.format_table(ddl.target))",
            "",
            "        return self.sql_compiler.post_process_text(ddl.statement % context)",
            "",
            "    def visit_create_schema(self, create):",
            "        schema = self.preparer.format_schema(create.element)",
            "        return \"CREATE SCHEMA \" + schema",
            "",
            "    def visit_drop_schema(self, drop):",
            "        schema = self.preparer.format_schema(drop.element)",
            "        text = \"DROP SCHEMA \" + schema",
            "        if drop.cascade:",
            "            text += \" CASCADE\"",
            "        return text",
            "",
            "    def visit_create_table(self, create):",
            "        table = create.element",
            "        preparer = self.preparer",
            "",
            "        text = \"\\nCREATE \"",
            "        if table._prefixes:",
            "            text += \" \".join(table._prefixes) + \" \"",
            "        text += \"TABLE \" + preparer.format_table(table) + \" \"",
            "",
            "        create_table_suffix = self.create_table_suffix(table)",
            "        if create_table_suffix:",
            "            text += create_table_suffix + \" \"",
            "",
            "        text += \"(\"",
            "",
            "        separator = \"\\n\"",
            "",
            "        # if only one primary key, specify it along with the column",
            "        first_pk = False",
            "        for create_column in create.columns:",
            "            column = create_column.element",
            "            try:",
            "                processed = self.process(",
            "                    create_column, first_pk=column.primary_key and not first_pk",
            "                )",
            "                if processed is not None:",
            "                    text += separator",
            "                    separator = \", \\n\"",
            "                    text += \"\\t\" + processed",
            "                if column.primary_key:",
            "                    first_pk = True",
            "            except exc.CompileError as ce:",
            "                util.raise_from_cause(",
            "                    exc.CompileError(",
            "                        util.u(\"(in table '%s', column '%s'): %s\")",
            "                        % (table.description, column.name, ce.args[0])",
            "                    )",
            "                )",
            "",
            "        const = self.create_table_constraints(",
            "            table,",
            "            _include_foreign_key_constraints=create.include_foreign_key_constraints,  # noqa",
            "        )",
            "        if const:",
            "            text += separator + \"\\t\" + const",
            "",
            "        text += \"\\n)%s\\n\\n\" % self.post_create_table(table)",
            "        return text",
            "",
            "    def visit_create_column(self, create, first_pk=False):",
            "        column = create.element",
            "",
            "        if column.system:",
            "            return None",
            "",
            "        text = self.get_column_specification(column, first_pk=first_pk)",
            "        const = \" \".join(",
            "            self.process(constraint) for constraint in column.constraints",
            "        )",
            "        if const:",
            "            text += \" \" + const",
            "",
            "        return text",
            "",
            "    def create_table_constraints(",
            "        self, table, _include_foreign_key_constraints=None",
            "    ):",
            "",
            "        # On some DB order is significant: visit PK first, then the",
            "        # other constraints (engine.ReflectionTest.testbasic failed on FB2)",
            "        constraints = []",
            "        if table.primary_key:",
            "            constraints.append(table.primary_key)",
            "",
            "        all_fkcs = table.foreign_key_constraints",
            "        if _include_foreign_key_constraints is not None:",
            "            omit_fkcs = all_fkcs.difference(_include_foreign_key_constraints)",
            "        else:",
            "            omit_fkcs = set()",
            "",
            "        constraints.extend(",
            "            [",
            "                c",
            "                for c in table._sorted_constraints",
            "                if c is not table.primary_key and c not in omit_fkcs",
            "            ]",
            "        )",
            "",
            "        return \", \\n\\t\".join(",
            "            p",
            "            for p in (",
            "                self.process(constraint)",
            "                for constraint in constraints",
            "                if (",
            "                    constraint._create_rule is None",
            "                    or constraint._create_rule(self)",
            "                )",
            "                and (",
            "                    not self.dialect.supports_alter",
            "                    or not getattr(constraint, \"use_alter\", False)",
            "                )",
            "            )",
            "            if p is not None",
            "        )",
            "",
            "    def visit_drop_table(self, drop):",
            "        return \"\\nDROP TABLE \" + self.preparer.format_table(drop.element)",
            "",
            "    def visit_drop_view(self, drop):",
            "        return \"\\nDROP VIEW \" + self.preparer.format_table(drop.element)",
            "",
            "    def _verify_index_table(self, index):",
            "        if index.table is None:",
            "            raise exc.CompileError(",
            "                \"Index '%s' is not associated \" \"with any table.\" % index.name",
            "            )",
            "",
            "    def visit_create_index(",
            "        self, create, include_schema=False, include_table_schema=True",
            "    ):",
            "        index = create.element",
            "        self._verify_index_table(index)",
            "        preparer = self.preparer",
            "        text = \"CREATE \"",
            "        if index.unique:",
            "            text += \"UNIQUE \"",
            "        text += \"INDEX %s ON %s (%s)\" % (",
            "            self._prepared_index_name(index, include_schema=include_schema),",
            "            preparer.format_table(",
            "                index.table, use_schema=include_table_schema",
            "            ),",
            "            \", \".join(",
            "                self.sql_compiler.process(",
            "                    expr, include_table=False, literal_binds=True",
            "                )",
            "                for expr in index.expressions",
            "            ),",
            "        )",
            "        return text",
            "",
            "    def visit_drop_index(self, drop):",
            "        index = drop.element",
            "        return \"\\nDROP INDEX \" + self._prepared_index_name(",
            "            index, include_schema=True",
            "        )",
            "",
            "    def _prepared_index_name(self, index, include_schema=False):",
            "        if index.table is not None:",
            "            effective_schema = self.preparer.schema_for_object(index.table)",
            "        else:",
            "            effective_schema = None",
            "        if include_schema and effective_schema:",
            "            schema_name = self.preparer.quote_schema(effective_schema)",
            "        else:",
            "            schema_name = None",
            "",
            "        index_name = self.preparer.format_index(index)",
            "",
            "        if schema_name:",
            "            index_name = schema_name + \".\" + index_name",
            "        return index_name",
            "",
            "    def visit_add_constraint(self, create):",
            "        return \"ALTER TABLE %s ADD %s\" % (",
            "            self.preparer.format_table(create.element.table),",
            "            self.process(create.element),",
            "        )",
            "",
            "    def visit_set_table_comment(self, create):",
            "        return \"COMMENT ON TABLE %s IS %s\" % (",
            "            self.preparer.format_table(create.element),",
            "            self.sql_compiler.render_literal_value(",
            "                create.element.comment, sqltypes.String()",
            "            ),",
            "        )",
            "",
            "    def visit_drop_table_comment(self, drop):",
            "        return \"COMMENT ON TABLE %s IS NULL\" % self.preparer.format_table(",
            "            drop.element",
            "        )",
            "",
            "    def visit_set_column_comment(self, create):",
            "        return \"COMMENT ON COLUMN %s IS %s\" % (",
            "            self.preparer.format_column(",
            "                create.element, use_table=True, use_schema=True",
            "            ),",
            "            self.sql_compiler.render_literal_value(",
            "                create.element.comment, sqltypes.String()",
            "            ),",
            "        )",
            "",
            "    def visit_drop_column_comment(self, drop):",
            "        return \"COMMENT ON COLUMN %s IS NULL\" % self.preparer.format_column(",
            "            drop.element, use_table=True",
            "        )",
            "",
            "    def visit_create_sequence(self, create):",
            "        text = \"CREATE SEQUENCE %s\" % self.preparer.format_sequence(",
            "            create.element",
            "        )",
            "        if create.element.increment is not None:",
            "            text += \" INCREMENT BY %d\" % create.element.increment",
            "        if create.element.start is not None:",
            "            text += \" START WITH %d\" % create.element.start",
            "        if create.element.minvalue is not None:",
            "            text += \" MINVALUE %d\" % create.element.minvalue",
            "        if create.element.maxvalue is not None:",
            "            text += \" MAXVALUE %d\" % create.element.maxvalue",
            "        if create.element.nominvalue is not None:",
            "            text += \" NO MINVALUE\"",
            "        if create.element.nomaxvalue is not None:",
            "            text += \" NO MAXVALUE\"",
            "        if create.element.cache is not None:",
            "            text += \" CACHE %d\" % create.element.cache",
            "        if create.element.order is True:",
            "            text += \" ORDER\"",
            "        if create.element.cycle is not None:",
            "            text += \" CYCLE\"",
            "        return text",
            "",
            "    def visit_drop_sequence(self, drop):",
            "        return \"DROP SEQUENCE %s\" % self.preparer.format_sequence(drop.element)",
            "",
            "    def visit_drop_constraint(self, drop):",
            "        constraint = drop.element",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "        else:",
            "            formatted_name = None",
            "",
            "        if formatted_name is None:",
            "            raise exc.CompileError(",
            "                \"Can't emit DROP CONSTRAINT for constraint %r; \"",
            "                \"it has no name\" % drop.element",
            "            )",
            "        return \"ALTER TABLE %s DROP CONSTRAINT %s%s\" % (",
            "            self.preparer.format_table(drop.element.table),",
            "            formatted_name,",
            "            drop.cascade and \" CASCADE\" or \"\",",
            "        )",
            "",
            "    def get_column_specification(self, column, **kwargs):",
            "        colspec = (",
            "            self.preparer.format_column(column)",
            "            + \" \"",
            "            + self.dialect.type_compiler.process(",
            "                column.type, type_expression=column",
            "            )",
            "        )",
            "        default = self.get_column_default_string(column)",
            "        if default is not None:",
            "            colspec += \" DEFAULT \" + default",
            "",
            "        if not column.nullable:",
            "            colspec += \" NOT NULL\"",
            "        return colspec",
            "",
            "    def create_table_suffix(self, table):",
            "        return \"\"",
            "",
            "    def post_create_table(self, table):",
            "        return \"\"",
            "",
            "    def get_column_default_string(self, column):",
            "        if isinstance(column.server_default, schema.DefaultClause):",
            "            if isinstance(column.server_default.arg, util.string_types):",
            "                return self.sql_compiler.render_literal_value(",
            "                    column.server_default.arg, sqltypes.STRINGTYPE",
            "                )",
            "            else:",
            "                return self.sql_compiler.process(",
            "                    column.server_default.arg, literal_binds=True",
            "                )",
            "        else:",
            "            return None",
            "",
            "    def visit_check_constraint(self, constraint):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"CHECK (%s)\" % self.sql_compiler.process(",
            "            constraint.sqltext, include_table=False, literal_binds=True",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_column_check_constraint(self, constraint):",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"CHECK (%s)\" % self.sql_compiler.process(",
            "            constraint.sqltext, include_table=False, literal_binds=True",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_primary_key_constraint(self, constraint):",
            "        if len(constraint) == 0:",
            "            return \"\"",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"PRIMARY KEY \"",
            "        text += \"(%s)\" % \", \".join(",
            "            self.preparer.quote(c.name)",
            "            for c in (",
            "                constraint.columns_autoinc_first",
            "                if constraint._implicit_generated",
            "                else constraint.columns",
            "            )",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def visit_foreign_key_constraint(self, constraint):",
            "        preparer = self.preparer",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            if formatted_name is not None:",
            "                text += \"CONSTRAINT %s \" % formatted_name",
            "        remote_table = list(constraint.elements)[0].column.table",
            "        text += \"FOREIGN KEY(%s) REFERENCES %s (%s)\" % (",
            "            \", \".join(",
            "                preparer.quote(f.parent.name) for f in constraint.elements",
            "            ),",
            "            self.define_constraint_remote_table(",
            "                constraint, remote_table, preparer",
            "            ),",
            "            \", \".join(",
            "                preparer.quote(f.column.name) for f in constraint.elements",
            "            ),",
            "        )",
            "        text += self.define_constraint_match(constraint)",
            "        text += self.define_constraint_cascades(constraint)",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def define_constraint_remote_table(self, constraint, table, preparer):",
            "        \"\"\"Format the remote table clause of a CREATE CONSTRAINT clause.\"\"\"",
            "",
            "        return preparer.format_table(table)",
            "",
            "    def visit_unique_constraint(self, constraint):",
            "        if len(constraint) == 0:",
            "            return \"\"",
            "        text = \"\"",
            "        if constraint.name is not None:",
            "            formatted_name = self.preparer.format_constraint(constraint)",
            "            text += \"CONSTRAINT %s \" % formatted_name",
            "        text += \"UNIQUE (%s)\" % (",
            "            \", \".join(self.preparer.quote(c.name) for c in constraint)",
            "        )",
            "        text += self.define_constraint_deferrability(constraint)",
            "        return text",
            "",
            "    def define_constraint_cascades(self, constraint):",
            "        text = \"\"",
            "        if constraint.ondelete is not None:",
            "            text += \" ON DELETE %s\" % self.preparer.validate_sql_phrase(",
            "                constraint.ondelete, FK_ON_DELETE",
            "            )",
            "        if constraint.onupdate is not None:",
            "            text += \" ON UPDATE %s\" % self.preparer.validate_sql_phrase(",
            "                constraint.onupdate, FK_ON_UPDATE",
            "            )",
            "        return text",
            "",
            "    def define_constraint_deferrability(self, constraint):",
            "        text = \"\"",
            "        if constraint.deferrable is not None:",
            "            if constraint.deferrable:",
            "                text += \" DEFERRABLE\"",
            "            else:",
            "                text += \" NOT DEFERRABLE\"",
            "        if constraint.initially is not None:",
            "            text += \" INITIALLY %s\" % self.preparer.validate_sql_phrase(",
            "                constraint.initially, FK_INITIALLY",
            "            )",
            "        return text",
            "",
            "    def define_constraint_match(self, constraint):",
            "        text = \"\"",
            "        if constraint.match is not None:",
            "            text += \" MATCH %s\" % constraint.match",
            "        return text",
            "",
            "",
            "class GenericTypeCompiler(TypeCompiler):",
            "    def visit_FLOAT(self, type_, **kw):",
            "        return \"FLOAT\"",
            "",
            "    def visit_REAL(self, type_, **kw):",
            "        return \"REAL\"",
            "",
            "    def visit_NUMERIC(self, type_, **kw):",
            "        if type_.precision is None:",
            "            return \"NUMERIC\"",
            "        elif type_.scale is None:",
            "            return \"NUMERIC(%(precision)s)\" % {\"precision\": type_.precision}",
            "        else:",
            "            return \"NUMERIC(%(precision)s, %(scale)s)\" % {",
            "                \"precision\": type_.precision,",
            "                \"scale\": type_.scale,",
            "            }",
            "",
            "    def visit_DECIMAL(self, type_, **kw):",
            "        if type_.precision is None:",
            "            return \"DECIMAL\"",
            "        elif type_.scale is None:",
            "            return \"DECIMAL(%(precision)s)\" % {\"precision\": type_.precision}",
            "        else:",
            "            return \"DECIMAL(%(precision)s, %(scale)s)\" % {",
            "                \"precision\": type_.precision,",
            "                \"scale\": type_.scale,",
            "            }",
            "",
            "    def visit_INTEGER(self, type_, **kw):",
            "        return \"INTEGER\"",
            "",
            "    def visit_SMALLINT(self, type_, **kw):",
            "        return \"SMALLINT\"",
            "",
            "    def visit_BIGINT(self, type_, **kw):",
            "        return \"BIGINT\"",
            "",
            "    def visit_TIMESTAMP(self, type_, **kw):",
            "        return \"TIMESTAMP\"",
            "",
            "    def visit_DATETIME(self, type_, **kw):",
            "        return \"DATETIME\"",
            "",
            "    def visit_DATE(self, type_, **kw):",
            "        return \"DATE\"",
            "",
            "    def visit_TIME(self, type_, **kw):",
            "        return \"TIME\"",
            "",
            "    def visit_CLOB(self, type_, **kw):",
            "        return \"CLOB\"",
            "",
            "    def visit_NCLOB(self, type_, **kw):",
            "        return \"NCLOB\"",
            "",
            "    def _render_string_type(self, type_, name):",
            "",
            "        text = name",
            "        if type_.length:",
            "            text += \"(%d)\" % type_.length",
            "        if type_.collation:",
            "            text += ' COLLATE \"%s\"' % type_.collation",
            "        return text",
            "",
            "    def visit_CHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"CHAR\")",
            "",
            "    def visit_NCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"NCHAR\")",
            "",
            "    def visit_VARCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"VARCHAR\")",
            "",
            "    def visit_NVARCHAR(self, type_, **kw):",
            "        return self._render_string_type(type_, \"NVARCHAR\")",
            "",
            "    def visit_TEXT(self, type_, **kw):",
            "        return self._render_string_type(type_, \"TEXT\")",
            "",
            "    def visit_BLOB(self, type_, **kw):",
            "        return \"BLOB\"",
            "",
            "    def visit_BINARY(self, type_, **kw):",
            "        return \"BINARY\" + (type_.length and \"(%d)\" % type_.length or \"\")",
            "",
            "    def visit_VARBINARY(self, type_, **kw):",
            "        return \"VARBINARY\" + (type_.length and \"(%d)\" % type_.length or \"\")",
            "",
            "    def visit_BOOLEAN(self, type_, **kw):",
            "        return \"BOOLEAN\"",
            "",
            "    def visit_large_binary(self, type_, **kw):",
            "        return self.visit_BLOB(type_, **kw)",
            "",
            "    def visit_boolean(self, type_, **kw):",
            "        return self.visit_BOOLEAN(type_, **kw)",
            "",
            "    def visit_time(self, type_, **kw):",
            "        return self.visit_TIME(type_, **kw)",
            "",
            "    def visit_datetime(self, type_, **kw):",
            "        return self.visit_DATETIME(type_, **kw)",
            "",
            "    def visit_date(self, type_, **kw):",
            "        return self.visit_DATE(type_, **kw)",
            "",
            "    def visit_big_integer(self, type_, **kw):",
            "        return self.visit_BIGINT(type_, **kw)",
            "",
            "    def visit_small_integer(self, type_, **kw):",
            "        return self.visit_SMALLINT(type_, **kw)",
            "",
            "    def visit_integer(self, type_, **kw):",
            "        return self.visit_INTEGER(type_, **kw)",
            "",
            "    def visit_real(self, type_, **kw):",
            "        return self.visit_REAL(type_, **kw)",
            "",
            "    def visit_float(self, type_, **kw):",
            "        return self.visit_FLOAT(type_, **kw)",
            "",
            "    def visit_numeric(self, type_, **kw):",
            "        return self.visit_NUMERIC(type_, **kw)",
            "",
            "    def visit_string(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_unicode(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_text(self, type_, **kw):",
            "        return self.visit_TEXT(type_, **kw)",
            "",
            "    def visit_unicode_text(self, type_, **kw):",
            "        return self.visit_TEXT(type_, **kw)",
            "",
            "    def visit_enum(self, type_, **kw):",
            "        return self.visit_VARCHAR(type_, **kw)",
            "",
            "    def visit_null(self, type_, **kw):",
            "        raise exc.CompileError(",
            "            \"Can't generate DDL for %r; \"",
            "            \"did you forget to specify a \"",
            "            \"type on this Column?\" % type_",
            "        )",
            "",
            "    def visit_type_decorator(self, type_, **kw):",
            "        return self.process(type_.type_engine(self.dialect), **kw)",
            "",
            "    def visit_user_defined(self, type_, **kw):",
            "        return type_.get_col_spec(**kw)",
            "",
            "",
            "class StrSQLTypeCompiler(GenericTypeCompiler):",
            "    def __getattr__(self, key):",
            "        if key.startswith(\"visit_\"):",
            "            return self._visit_unknown",
            "        else:",
            "            raise AttributeError(key)",
            "",
            "    def _visit_unknown(self, type_, **kw):",
            "        return \"%s\" % type_.__class__.__name__",
            "",
            "",
            "class IdentifierPreparer(object):",
            "",
            "    \"\"\"Handle quoting and case-folding of identifiers based on options.\"\"\"",
            "",
            "    reserved_words = RESERVED_WORDS",
            "",
            "    legal_characters = LEGAL_CHARACTERS",
            "",
            "    illegal_initial_characters = ILLEGAL_INITIAL_CHARACTERS",
            "",
            "    schema_for_object = schema._schema_getter(None)",
            "",
            "    def __init__(",
            "        self,",
            "        dialect,",
            "        initial_quote='\"',",
            "        final_quote=None,",
            "        escape_quote='\"',",
            "        quote_case_sensitive_collations=True,",
            "        omit_schema=False,",
            "    ):",
            "        \"\"\"Construct a new ``IdentifierPreparer`` object.",
            "",
            "        initial_quote",
            "          Character that begins a delimited identifier.",
            "",
            "        final_quote",
            "          Character that ends a delimited identifier. Defaults to",
            "          `initial_quote`.",
            "",
            "        omit_schema",
            "          Prevent prepending schema name. Useful for databases that do",
            "          not support schemae.",
            "        \"\"\"",
            "",
            "        self.dialect = dialect",
            "        self.initial_quote = initial_quote",
            "        self.final_quote = final_quote or self.initial_quote",
            "        self.escape_quote = escape_quote",
            "        self.escape_to_quote = self.escape_quote * 2",
            "        self.omit_schema = omit_schema",
            "        self.quote_case_sensitive_collations = quote_case_sensitive_collations",
            "        self._strings = {}",
            "        self._double_percents = self.dialect.paramstyle in (",
            "            \"format\",",
            "            \"pyformat\",",
            "        )",
            "",
            "    def _with_schema_translate(self, schema_translate_map):",
            "        prep = self.__class__.__new__(self.__class__)",
            "        prep.__dict__.update(self.__dict__)",
            "        prep.schema_for_object = schema._schema_getter(schema_translate_map)",
            "        return prep",
            "",
            "    def _escape_identifier(self, value):",
            "        \"\"\"Escape an identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        escaping behavior.",
            "        \"\"\"",
            "",
            "        value = value.replace(self.escape_quote, self.escape_to_quote)",
            "        if self._double_percents:",
            "            value = value.replace(\"%\", \"%%\")",
            "        return value",
            "",
            "    def _unescape_identifier(self, value):",
            "        \"\"\"Canonicalize an escaped identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        unescaping behavior that reverses _escape_identifier.",
            "        \"\"\"",
            "",
            "        return value.replace(self.escape_to_quote, self.escape_quote)",
            "",
            "    def validate_sql_phrase(self, element, reg):",
            "        \"\"\"keyword sequence filter.",
            "",
            "        a filter for elements that are intended to represent keyword sequences,",
            "        such as \"INITIALLY\", \"INTIALLY DEFERRED\", etc.   no special characters",
            "        should be present.",
            "",
            "        .. versionadded:: 1.3",
            "",
            "        \"\"\"",
            "",
            "        if element is not None and not reg.match(element):",
            "            raise exc.CompileError(",
            "                \"Unexpected SQL phrase: %r (matching against %r)\"",
            "                % (element, reg.pattern)",
            "            )",
            "        return element",
            "",
            "    def quote_identifier(self, value):",
            "        \"\"\"Quote an identifier.",
            "",
            "        Subclasses should override this to provide database-dependent",
            "        quoting behavior.",
            "        \"\"\"",
            "",
            "        return (",
            "            self.initial_quote",
            "            + self._escape_identifier(value)",
            "            + self.final_quote",
            "        )",
            "",
            "    def _requires_quotes(self, value):",
            "        \"\"\"Return True if the given identifier requires quoting.\"\"\"",
            "        lc_value = value.lower()",
            "        return (",
            "            lc_value in self.reserved_words",
            "            or value[0] in self.illegal_initial_characters",
            "            or not self.legal_characters.match(util.text_type(value))",
            "            or (lc_value != value)",
            "        )",
            "",
            "    def _requires_quotes_illegal_chars(self, value):",
            "        \"\"\"Return True if the given identifier requires quoting, but",
            "        not taking case convention into account.\"\"\"",
            "        return not self.legal_characters.match(util.text_type(value))",
            "",
            "    def quote_schema(self, schema, force=None):",
            "        \"\"\"Conditionally quote a schema name.",
            "",
            "",
            "        The name is quoted if it is a reserved word, contains quote-necessary",
            "        characters, or is an instance of :class:`.quoted_name` which includes",
            "        ``quote`` set to ``True``.",
            "",
            "        Subclasses can override this to provide database-dependent",
            "        quoting behavior for schema names.",
            "",
            "        :param schema: string schema name",
            "        :param force: unused",
            "",
            "            .. deprecated:: 0.9",
            "",
            "                The :paramref:`.IdentifierPreparer.quote_schema.force`",
            "                parameter is deprecated and will be removed in a future",
            "                release.  This flag has no effect on the behavior of the",
            "                :meth:`.IdentifierPreparer.quote` method; please refer to",
            "                :class:`.quoted_name`.",
            "",
            "        \"\"\"",
            "        if force is not None:",
            "            # not using the util.deprecated_params() decorator in this",
            "            # case because of the additional function call overhead on this",
            "            # very performance-critical spot.",
            "            util.warn_deprecated(",
            "                \"The IdentifierPreparer.quote_schema.force parameter is \"",
            "                \"deprecated and will be removed in a future release.  This \"",
            "                \"flag has no effect on the behavior of the \"",
            "                \"IdentifierPreparer.quote method; please refer to \"",
            "                \"quoted_name().\"",
            "            )",
            "",
            "        return self.quote(schema)",
            "",
            "    def quote(self, ident, force=None):",
            "        \"\"\"Conditionally quote an identfier.",
            "",
            "        The identifier is quoted if it is a reserved word, contains",
            "        quote-necessary characters, or is an instance of",
            "        :class:`.quoted_name` which includes ``quote`` set to ``True``.",
            "",
            "        Subclasses can override this to provide database-dependent",
            "        quoting behavior for identifier names.",
            "",
            "        :param ident: string identifier",
            "        :param force: unused",
            "",
            "            .. deprecated:: 0.9",
            "",
            "                The :paramref:`.IdentifierPreparer.quote.force`",
            "                parameter is deprecated and will be removed in a future",
            "                release.  This flag has no effect on the behavior of the",
            "                :meth:`.IdentifierPreparer.quote` method; please refer to",
            "                :class:`.quoted_name`.",
            "",
            "        \"\"\"",
            "        if force is not None:",
            "            # not using the util.deprecated_params() decorator in this",
            "            # case because of the additional function call overhead on this",
            "            # very performance-critical spot.",
            "            util.warn_deprecated(",
            "                \"The IdentifierPreparer.quote.force parameter is \"",
            "                \"deprecated and will be removed in a future release.  This \"",
            "                \"flag has no effect on the behavior of the \"",
            "                \"IdentifierPreparer.quote method; please refer to \"",
            "                \"quoted_name().\"",
            "            )",
            "",
            "        force = getattr(ident, \"quote\", None)",
            "",
            "        if force is None:",
            "            if ident in self._strings:",
            "                return self._strings[ident]",
            "            else:",
            "                if self._requires_quotes(ident):",
            "                    self._strings[ident] = self.quote_identifier(ident)",
            "                else:",
            "                    self._strings[ident] = ident",
            "                return self._strings[ident]",
            "        elif force:",
            "            return self.quote_identifier(ident)",
            "        else:",
            "            return ident",
            "",
            "    def format_collation(self, collation_name):",
            "        if self.quote_case_sensitive_collations:",
            "            return self.quote(collation_name)",
            "        else:",
            "            return collation_name",
            "",
            "    def format_sequence(self, sequence, use_schema=True):",
            "        name = self.quote(sequence.name)",
            "",
            "        effective_schema = self.schema_for_object(sequence)",
            "",
            "        if (",
            "            not self.omit_schema",
            "            and use_schema",
            "            and effective_schema is not None",
            "        ):",
            "            name = self.quote_schema(effective_schema) + \".\" + name",
            "        return name",
            "",
            "    def format_label(self, label, name=None):",
            "        return self.quote(name or label.name)",
            "",
            "    def format_alias(self, alias, name=None):",
            "        return self.quote(name or alias.name)",
            "",
            "    def format_savepoint(self, savepoint, name=None):",
            "        # Running the savepoint name through quoting is unnecessary",
            "        # for all known dialects.  This is here to support potential",
            "        # third party use cases",
            "        ident = name or savepoint.ident",
            "        if self._requires_quotes(ident):",
            "            ident = self.quote_identifier(ident)",
            "        return ident",
            "",
            "    @util.dependencies(\"sqlalchemy.sql.naming\")",
            "    def format_constraint(self, naming, constraint):",
            "        if isinstance(constraint.name, elements._defer_name):",
            "            name = naming._constraint_name_for_table(",
            "                constraint, constraint.table",
            "            )",
            "",
            "            if name is None:",
            "                if isinstance(constraint.name, elements._defer_none_name):",
            "                    return None",
            "                else:",
            "                    name = constraint.name",
            "        else:",
            "            name = constraint.name",
            "",
            "        if isinstance(name, elements._truncated_label):",
            "            if constraint.__visit_name__ == \"index\":",
            "                max_ = (",
            "                    self.dialect.max_index_name_length",
            "                    or self.dialect.max_identifier_length",
            "                )",
            "            else:",
            "                max_ = self.dialect.max_identifier_length",
            "            if len(name) > max_:",
            "                name = name[0 : max_ - 8] + \"_\" + util.md5_hex(name)[-4:]",
            "        else:",
            "            self.dialect.validate_identifier(name)",
            "",
            "        return self.quote(name)",
            "",
            "    def format_index(self, index):",
            "        return self.format_constraint(index)",
            "",
            "    def format_table(self, table, use_schema=True, name=None):",
            "        \"\"\"Prepare a quoted table and schema name.\"\"\"",
            "",
            "        if name is None:",
            "            name = table.name",
            "        result = self.quote(name)",
            "",
            "        effective_schema = self.schema_for_object(table)",
            "",
            "        if not self.omit_schema and use_schema and effective_schema:",
            "            result = self.quote_schema(effective_schema) + \".\" + result",
            "        return result",
            "",
            "    def format_schema(self, name):",
            "        \"\"\"Prepare a quoted schema name.\"\"\"",
            "",
            "        return self.quote(name)",
            "",
            "    def format_column(",
            "        self,",
            "        column,",
            "        use_table=False,",
            "        name=None,",
            "        table_name=None,",
            "        use_schema=False,",
            "    ):",
            "        \"\"\"Prepare a quoted column name.\"\"\"",
            "",
            "        if name is None:",
            "            name = column.name",
            "        if not getattr(column, \"is_literal\", False):",
            "            if use_table:",
            "                return (",
            "                    self.format_table(",
            "                        column.table, use_schema=use_schema, name=table_name",
            "                    )",
            "                    + \".\"",
            "                    + self.quote(name)",
            "                )",
            "            else:",
            "                return self.quote(name)",
            "        else:",
            "            # literal textual elements get stuck into ColumnClause a lot,",
            "            # which shouldn't get quoted",
            "",
            "            if use_table:",
            "                return (",
            "                    self.format_table(",
            "                        column.table, use_schema=use_schema, name=table_name",
            "                    )",
            "                    + \".\"",
            "                    + name",
            "                )",
            "            else:",
            "                return name",
            "",
            "    def format_table_seq(self, table, use_schema=True):",
            "        \"\"\"Format table name and schema as a tuple.\"\"\"",
            "",
            "        # Dialects with more levels in their fully qualified references",
            "        # ('database', 'owner', etc.) could override this and return",
            "        # a longer sequence.",
            "",
            "        effective_schema = self.schema_for_object(table)",
            "",
            "        if not self.omit_schema and use_schema and effective_schema:",
            "            return (",
            "                self.quote_schema(effective_schema),",
            "                self.format_table(table, use_schema=False),",
            "            )",
            "        else:",
            "            return (self.format_table(table, use_schema=False),)",
            "",
            "    @util.memoized_property",
            "    def _r_identifiers(self):",
            "        initial, final, escaped_final = [",
            "            re.escape(s)",
            "            for s in (",
            "                self.initial_quote,",
            "                self.final_quote,",
            "                self._escape_identifier(self.final_quote),",
            "            )",
            "        ]",
            "        r = re.compile(",
            "            r\"(?:\"",
            "            r\"(?:%(initial)s((?:%(escaped)s|[^%(final)s])+)%(final)s\"",
            "            r\"|([^\\.]+))(?=\\.|$))+\"",
            "            % {\"initial\": initial, \"final\": final, \"escaped\": escaped_final}",
            "        )",
            "        return r",
            "",
            "    def unformat_identifiers(self, identifiers):",
            "        \"\"\"Unpack 'schema.table.column'-like strings into components.\"\"\"",
            "",
            "        r = self._r_identifiers",
            "        return [",
            "            self._unescape_identifier(i)",
            "            for i in [a or b for a, b in r.findall(identifiers)]",
            "        ]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "761": [
                "SQLCompiler",
                "visit_textual_label_reference"
            ],
            "762": [
                "SQLCompiler",
                "visit_textual_label_reference"
            ],
            "763": [
                "SQLCompiler",
                "visit_textual_label_reference"
            ],
            "764": [
                "SQLCompiler",
                "visit_textual_label_reference"
            ],
            "766": [
                "SQLCompiler",
                "visit_textual_label_reference"
            ],
            "1079": [
                "SQLCompiler",
                "visit_function"
            ],
            "1080": [
                "SQLCompiler",
                "visit_function"
            ],
            "1081": [
                "SQLCompiler",
                "visit_function"
            ],
            "1082": [
                "SQLCompiler",
                "visit_function"
            ],
            "3156": [
                "DDLCompiler",
                "define_constraint_cascades"
            ],
            "3158": [
                "DDLCompiler",
                "define_constraint_cascades"
            ],
            "3169": [
                "DDLCompiler",
                "define_constraint_deferrability"
            ]
        },
        "addLocation": []
    }
}