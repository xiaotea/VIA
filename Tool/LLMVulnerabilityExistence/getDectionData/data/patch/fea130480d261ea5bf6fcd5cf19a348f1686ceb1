{
    "lib/ansible/module_utils/common/json.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": "     Used in ``AnsibleJSONEncoder.iterencode``"
            },
            "1": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "     \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "     if _is_unsafe(value):"
            },
            "3": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        value = {'__ansible_unsafe': to_text(value, errors='surrogate_or_strict', nonstring='strict')}"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+        value = {'__ansible_unsafe': to_text(value._strip_unsafe(), errors='surrogate_or_strict', nonstring='strict')}"
            },
            "5": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "     elif is_sequence(value):"
            },
            "6": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "         value = [_preprocess_unsafe_encode(v) for v in value]"
            },
            "7": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "     elif isinstance(value, Mapping):"
            },
            "8": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "                 value = {'__ansible_vault': to_text(o._ciphertext, errors='surrogate_or_strict', nonstring='strict')}"
            },
            "9": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         elif getattr(o, '__UNSAFE__', False):"
            },
            "10": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "             # unsafe object, this will never be triggered, see ``AnsibleJSONEncoder.iterencode``"
            },
            "11": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            value = {'__ansible_unsafe': to_text(o, errors='surrogate_or_strict', nonstring='strict')}"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+            value = {'__ansible_unsafe': to_text(o._strip_unsafe(), errors='surrogate_or_strict', nonstring='strict')}"
            },
            "13": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "         elif isinstance(o, Mapping):"
            },
            "14": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "             # hostvars and other objects"
            },
            "15": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "             value = dict(o)"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright (c) 2019 Ansible Project",
            "# Simplified BSD License (see licenses/simplified_bsd.txt or https://opensource.org/licenses/BSD-2-Clause)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "import datetime",
            "",
            "from ansible.module_utils._text import to_text",
            "from ansible.module_utils.six.moves.collections_abc import Mapping",
            "from ansible.module_utils.common.collections import is_sequence",
            "",
            "",
            "def _is_unsafe(value):",
            "    return getattr(value, '__UNSAFE__', False) and not getattr(value, '__ENCRYPTED__', False)",
            "",
            "",
            "def _is_vault(value):",
            "    return getattr(value, '__ENCRYPTED__', False)",
            "",
            "",
            "def _preprocess_unsafe_encode(value):",
            "    \"\"\"Recursively preprocess a data structure converting instances of ``AnsibleUnsafe``",
            "    into their JSON dict representations",
            "",
            "    Used in ``AnsibleJSONEncoder.iterencode``",
            "    \"\"\"",
            "    if _is_unsafe(value):",
            "        value = {'__ansible_unsafe': to_text(value, errors='surrogate_or_strict', nonstring='strict')}",
            "    elif is_sequence(value):",
            "        value = [_preprocess_unsafe_encode(v) for v in value]",
            "    elif isinstance(value, Mapping):",
            "        value = dict((k, _preprocess_unsafe_encode(v)) for k, v in value.items())",
            "",
            "    return value",
            "",
            "",
            "def json_dump(structure):",
            "    return json.dumps(structure, cls=AnsibleJSONEncoder, sort_keys=True, indent=4)",
            "",
            "",
            "class AnsibleJSONEncoder(json.JSONEncoder):",
            "    '''",
            "    Simple encoder class to deal with JSON encoding of Ansible internal types",
            "    '''",
            "",
            "    def __init__(self, preprocess_unsafe=False, vault_to_text=False, **kwargs):",
            "        self._preprocess_unsafe = preprocess_unsafe",
            "        self._vault_to_text = vault_to_text",
            "        super(AnsibleJSONEncoder, self).__init__(**kwargs)",
            "",
            "    # NOTE: ALWAYS inform AWS/Tower when new items get added as they consume them downstream via a callback",
            "    def default(self, o):",
            "        if getattr(o, '__ENCRYPTED__', False):",
            "            # vault object",
            "            if self._vault_to_text:",
            "                value = to_text(o, errors='surrogate_or_strict')",
            "            else:",
            "                value = {'__ansible_vault': to_text(o._ciphertext, errors='surrogate_or_strict', nonstring='strict')}",
            "        elif getattr(o, '__UNSAFE__', False):",
            "            # unsafe object, this will never be triggered, see ``AnsibleJSONEncoder.iterencode``",
            "            value = {'__ansible_unsafe': to_text(o, errors='surrogate_or_strict', nonstring='strict')}",
            "        elif isinstance(o, Mapping):",
            "            # hostvars and other objects",
            "            value = dict(o)",
            "        elif isinstance(o, (datetime.date, datetime.datetime)):",
            "            # date object",
            "            value = o.isoformat()",
            "        else:",
            "            # use default encoder",
            "            value = super(AnsibleJSONEncoder, self).default(o)",
            "        return value",
            "",
            "    def iterencode(self, o, **kwargs):",
            "        \"\"\"Custom iterencode, primarily design to handle encoding ``AnsibleUnsafe``",
            "        as the ``AnsibleUnsafe`` subclasses inherit from string types and",
            "        ``json.JSONEncoder`` does not support custom encoders for string types",
            "        \"\"\"",
            "        if self._preprocess_unsafe:",
            "            o = _preprocess_unsafe_encode(o)",
            "",
            "        return super(AnsibleJSONEncoder, self).iterencode(o, **kwargs)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright (c) 2019 Ansible Project",
            "# Simplified BSD License (see licenses/simplified_bsd.txt or https://opensource.org/licenses/BSD-2-Clause)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "import datetime",
            "",
            "from ansible.module_utils._text import to_text",
            "from ansible.module_utils.six.moves.collections_abc import Mapping",
            "from ansible.module_utils.common.collections import is_sequence",
            "",
            "",
            "def _is_unsafe(value):",
            "    return getattr(value, '__UNSAFE__', False) and not getattr(value, '__ENCRYPTED__', False)",
            "",
            "",
            "def _is_vault(value):",
            "    return getattr(value, '__ENCRYPTED__', False)",
            "",
            "",
            "def _preprocess_unsafe_encode(value):",
            "    \"\"\"Recursively preprocess a data structure converting instances of ``AnsibleUnsafe``",
            "    into their JSON dict representations",
            "",
            "    Used in ``AnsibleJSONEncoder.iterencode``",
            "    \"\"\"",
            "    if _is_unsafe(value):",
            "        value = {'__ansible_unsafe': to_text(value._strip_unsafe(), errors='surrogate_or_strict', nonstring='strict')}",
            "    elif is_sequence(value):",
            "        value = [_preprocess_unsafe_encode(v) for v in value]",
            "    elif isinstance(value, Mapping):",
            "        value = dict((k, _preprocess_unsafe_encode(v)) for k, v in value.items())",
            "",
            "    return value",
            "",
            "",
            "def json_dump(structure):",
            "    return json.dumps(structure, cls=AnsibleJSONEncoder, sort_keys=True, indent=4)",
            "",
            "",
            "class AnsibleJSONEncoder(json.JSONEncoder):",
            "    '''",
            "    Simple encoder class to deal with JSON encoding of Ansible internal types",
            "    '''",
            "",
            "    def __init__(self, preprocess_unsafe=False, vault_to_text=False, **kwargs):",
            "        self._preprocess_unsafe = preprocess_unsafe",
            "        self._vault_to_text = vault_to_text",
            "        super(AnsibleJSONEncoder, self).__init__(**kwargs)",
            "",
            "    # NOTE: ALWAYS inform AWS/Tower when new items get added as they consume them downstream via a callback",
            "    def default(self, o):",
            "        if getattr(o, '__ENCRYPTED__', False):",
            "            # vault object",
            "            if self._vault_to_text:",
            "                value = to_text(o, errors='surrogate_or_strict')",
            "            else:",
            "                value = {'__ansible_vault': to_text(o._ciphertext, errors='surrogate_or_strict', nonstring='strict')}",
            "        elif getattr(o, '__UNSAFE__', False):",
            "            # unsafe object, this will never be triggered, see ``AnsibleJSONEncoder.iterencode``",
            "            value = {'__ansible_unsafe': to_text(o._strip_unsafe(), errors='surrogate_or_strict', nonstring='strict')}",
            "        elif isinstance(o, Mapping):",
            "            # hostvars and other objects",
            "            value = dict(o)",
            "        elif isinstance(o, (datetime.date, datetime.datetime)):",
            "            # date object",
            "            value = o.isoformat()",
            "        else:",
            "            # use default encoder",
            "            value = super(AnsibleJSONEncoder, self).default(o)",
            "        return value",
            "",
            "    def iterencode(self, o, **kwargs):",
            "        \"\"\"Custom iterencode, primarily design to handle encoding ``AnsibleUnsafe``",
            "        as the ``AnsibleUnsafe`` subclasses inherit from string types and",
            "        ``json.JSONEncoder`` does not support custom encoders for string types",
            "        \"\"\"",
            "        if self._preprocess_unsafe:",
            "            o = _preprocess_unsafe_encode(o)",
            "",
            "        return super(AnsibleJSONEncoder, self).iterencode(o, **kwargs)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "33": [
                "_preprocess_unsafe_encode"
            ],
            "66": [
                "AnsibleJSONEncoder",
                "default"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/parsing/yaml/dumper.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from ansible.module_utils.six import text_type, binary_type"
            },
            "1": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from ansible.module_utils.common.yaml import SafeDumper"
            },
            "2": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from ansible.parsing.yaml.objects import AnsibleUnicode, AnsibleSequence, AnsibleMapping, AnsibleVaultEncryptedUnicode"
            },
            "3": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from ansible.utils.unsafe_proxy import AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText, NativeJinjaText"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+from ansible.utils.unsafe_proxy import AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText, NativeJinjaText, _is_unsafe"
            },
            "5": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from ansible.template import AnsibleUndefined"
            },
            "6": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from ansible.vars.hostvars import HostVars, HostVarsVars"
            },
            "7": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from ansible.vars.manager import VarsWithSources"
            },
            "8": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 49,
                "PatchRowcode": " def represent_unicode(self, data):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+    if _is_unsafe(data):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+        data = data._strip_unsafe()"
            },
            "13": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     return yaml.representer.SafeRepresenter.represent_str(self, text_type(data))"
            },
            "14": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 53,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " def represent_binary(self, data):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+    if _is_unsafe(data):"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        data = data._strip_unsafe()"
            },
            "19": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "     return yaml.representer.SafeRepresenter.represent_binary(self, binary_type(data))"
            },
            "20": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 59,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import yaml",
            "",
            "from ansible.module_utils.six import text_type, binary_type",
            "from ansible.module_utils.common.yaml import SafeDumper",
            "from ansible.parsing.yaml.objects import AnsibleUnicode, AnsibleSequence, AnsibleMapping, AnsibleVaultEncryptedUnicode",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText, NativeJinjaText",
            "from ansible.template import AnsibleUndefined",
            "from ansible.vars.hostvars import HostVars, HostVarsVars",
            "from ansible.vars.manager import VarsWithSources",
            "",
            "",
            "class AnsibleDumper(SafeDumper):",
            "    '''",
            "    A simple stub class that allows us to add representers",
            "    for our overridden object types.",
            "    '''",
            "",
            "",
            "def represent_hostvars(self, data):",
            "    return self.represent_dict(dict(data))",
            "",
            "",
            "# Note: only want to represent the encrypted data",
            "def represent_vault_encrypted_unicode(self, data):",
            "    return self.represent_scalar(u'!vault', data._ciphertext.decode(), style='|')",
            "",
            "",
            "def represent_unicode(self, data):",
            "    return yaml.representer.SafeRepresenter.represent_str(self, text_type(data))",
            "",
            "",
            "def represent_binary(self, data):",
            "    return yaml.representer.SafeRepresenter.represent_binary(self, binary_type(data))",
            "",
            "",
            "def represent_undefined(self, data):",
            "    # Here bool will ensure _fail_with_undefined_error happens",
            "    # if the value is Undefined.",
            "    # This happens because Jinja sets __bool__ on StrictUndefined",
            "    return bool(data)",
            "",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnicode,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnsafeText,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnsafeBytes,",
            "    represent_binary,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    HostVars,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    HostVarsVars,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    VarsWithSources,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleSequence,",
            "    yaml.representer.SafeRepresenter.represent_list,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleMapping,",
            "    yaml.representer.SafeRepresenter.represent_dict,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleVaultEncryptedUnicode,",
            "    represent_vault_encrypted_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUndefined,",
            "    represent_undefined,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    NativeJinjaUnsafeText,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    NativeJinjaText,",
            "    represent_unicode,",
            ")"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import yaml",
            "",
            "from ansible.module_utils.six import text_type, binary_type",
            "from ansible.module_utils.common.yaml import SafeDumper",
            "from ansible.parsing.yaml.objects import AnsibleUnicode, AnsibleSequence, AnsibleMapping, AnsibleVaultEncryptedUnicode",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText, NativeJinjaText, _is_unsafe",
            "from ansible.template import AnsibleUndefined",
            "from ansible.vars.hostvars import HostVars, HostVarsVars",
            "from ansible.vars.manager import VarsWithSources",
            "",
            "",
            "class AnsibleDumper(SafeDumper):",
            "    '''",
            "    A simple stub class that allows us to add representers",
            "    for our overridden object types.",
            "    '''",
            "",
            "",
            "def represent_hostvars(self, data):",
            "    return self.represent_dict(dict(data))",
            "",
            "",
            "# Note: only want to represent the encrypted data",
            "def represent_vault_encrypted_unicode(self, data):",
            "    return self.represent_scalar(u'!vault', data._ciphertext.decode(), style='|')",
            "",
            "",
            "def represent_unicode(self, data):",
            "    if _is_unsafe(data):",
            "        data = data._strip_unsafe()",
            "    return yaml.representer.SafeRepresenter.represent_str(self, text_type(data))",
            "",
            "",
            "def represent_binary(self, data):",
            "    if _is_unsafe(data):",
            "        data = data._strip_unsafe()",
            "    return yaml.representer.SafeRepresenter.represent_binary(self, binary_type(data))",
            "",
            "",
            "def represent_undefined(self, data):",
            "    # Here bool will ensure _fail_with_undefined_error happens",
            "    # if the value is Undefined.",
            "    # This happens because Jinja sets __bool__ on StrictUndefined",
            "    return bool(data)",
            "",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnicode,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnsafeText,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUnsafeBytes,",
            "    represent_binary,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    HostVars,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    HostVarsVars,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    VarsWithSources,",
            "    represent_hostvars,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleSequence,",
            "    yaml.representer.SafeRepresenter.represent_list,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleMapping,",
            "    yaml.representer.SafeRepresenter.represent_dict,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleVaultEncryptedUnicode,",
            "    represent_vault_encrypted_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    AnsibleUndefined,",
            "    represent_undefined,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    NativeJinjaUnsafeText,",
            "    represent_unicode,",
            ")",
            "",
            "AnsibleDumper.add_representer(",
            "    NativeJinjaText,",
            "    represent_unicode,",
            ")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "27": []
        },
        "addLocation": []
    },
    "lib/ansible/playbook/conditional.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from jinja2.compiler import generate"
            },
            "1": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from jinja2.exceptions import UndefinedError"
            },
            "2": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from ansible.errors import AnsibleError, AnsibleUndefinedVariable"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+from ansible.errors import AnsibleError, AnsibleUndefinedVariable, AnsibleTemplateError"
            },
            "5": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from ansible.module_utils.six import text_type"
            },
            "6": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from ansible.module_utils._text import to_native"
            },
            "7": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from ansible.playbook.attribute import FieldAttribute"
            },
            "8": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "             if not isinstance(conditional, text_type) or conditional == \"\":"
            },
            "9": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "                 return conditional"
            },
            "10": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 134,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # update the lookups flag, as the string returned above may now be unsafe"
            },
            "12": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # and we don't want future templating calls to do unsafe things"
            },
            "13": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            disable_lookups |= hasattr(conditional, '__UNSAFE__')"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+            # If the result of the first-pass template render (to resolve inline templates) is marked unsafe,"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+            # explicitly fail since the next templating operation would never evaluate"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+            if hasattr(conditional, '__UNSAFE__'):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+                raise AnsibleTemplateError('Conditional is marked as unsafe, and cannot be evaluated.')"
            },
            "18": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 139,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "             # First, we do some low-level jinja2 parsing involving the AST format of the"
            },
            "20": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "             # statement to ensure we don't do anything unsafe (using the disable_lookup flag above)"
            },
            "21": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "             # NOTE The spaces around True and False are intentional to short-circuit literal_eval for"
            },
            "22": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "             #      jinja2_native=False and avoid its expensive calls."
            },
            "23": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "             presented = \"{%% if %s %%} True {%% else %%} False {%% endif %%}\" % conditional"
            },
            "24": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            val = templar.template(presented, disable_lookups=disable_lookups).strip()"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+            val = templar.template(presented).strip()"
            },
            "26": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 183,
                "PatchRowcode": "             if val == \"True\":"
            },
            "27": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "                 return True"
            },
            "28": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "             elif val == \"False\":"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import typing as t",
            "",
            "from jinja2.compiler import generate",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible.errors import AnsibleError, AnsibleUndefinedVariable",
            "from ansible.module_utils.six import text_type",
            "from ansible.module_utils._text import to_native",
            "from ansible.playbook.attribute import FieldAttribute",
            "from ansible.template import Templar",
            "from ansible.utils.display import Display",
            "",
            "display = Display()",
            "",
            "",
            "class Conditional:",
            "",
            "    '''",
            "    This is a mix-in class, to be used with Base to allow the object",
            "    to be run conditionally when a condition is met or skipped.",
            "    '''",
            "",
            "    when = FieldAttribute(isa='list', default=list, extend=True, prepend=True)",
            "",
            "    def __init__(self, loader=None):",
            "        # when used directly, this class needs a loader, but we want to",
            "        # make sure we don't trample on the existing one if this class",
            "        # is used as a mix-in with a playbook base class",
            "        if not hasattr(self, '_loader'):",
            "            if loader is None:",
            "                raise AnsibleError(\"a loader must be specified when using Conditional() directly\")",
            "            else:",
            "                self._loader = loader",
            "        super(Conditional, self).__init__()",
            "",
            "    def _validate_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def evaluate_conditional(self, templar: Templar, all_vars: dict[str, t.Any]) -> bool:",
            "        '''",
            "        Loops through the conditionals set on this object, returning",
            "        False if any of them evaluate as such.",
            "        '''",
            "        return self.evaluate_conditional_with_result(templar, all_vars)[0]",
            "",
            "    def evaluate_conditional_with_result(self, templar: Templar, all_vars: dict[str, t.Any]) -> tuple[bool, t.Optional[str]]:",
            "        \"\"\"",
            "        Loops through the conditionals set on this object, returning",
            "        False if any of them evaluate as such as well as the condition",
            "        that was false.",
            "        \"\"\"",
            "",
            "        # since this is a mix-in, it may not have an underlying datastructure",
            "        # associated with it, so we pull it out now in case we need it for",
            "        # error reporting below",
            "        ds = None",
            "        if hasattr(self, '_ds'):",
            "            ds = getattr(self, '_ds')",
            "",
            "        result = True",
            "        false_condition: t.Optional[str] = None",
            "        try:",
            "            for conditional in self.when:",
            "",
            "                # do evaluation",
            "                if conditional is None or conditional == '':",
            "                    res = True",
            "                elif isinstance(conditional, bool):",
            "                    res = conditional",
            "                else:",
            "                    res = self._check_conditional(conditional, templar, all_vars)",
            "",
            "                # only update if still true, preserve false",
            "                if result:",
            "                    result = res",
            "",
            "                display.debug(\"Evaluated conditional (%s): %s\" % (conditional, res))",
            "                if not result:",
            "                    false_condition = conditional",
            "                    break",
            "",
            "        except Exception as e:",
            "            raise AnsibleError(\"The conditional check '%s' failed. The error was: %s\" % (to_native(conditional), to_native(e)), obj=ds)",
            "",
            "        return result, false_condition",
            "",
            "    def _check_conditional(self, conditional, templar, all_vars):",
            "        '''",
            "        This method does the low-level evaluation of each conditional",
            "        set on this object, using jinja2 to wrap the conditionals for",
            "        evaluation.",
            "        '''",
            "",
            "        original = conditional",
            "",
            "        if templar.is_template(conditional):",
            "            display.warning('conditional statements should not include jinja2 '",
            "                            'templating delimiters such as {{ }} or {%% %%}. '",
            "                            'Found: %s' % conditional)",
            "",
            "        # make sure the templar is using the variables specified with this method",
            "        templar.available_variables = all_vars",
            "",
            "        try:",
            "            # if the conditional is \"unsafe\", disable lookups",
            "            disable_lookups = hasattr(conditional, '__UNSAFE__')",
            "            conditional = templar.template(conditional, disable_lookups=disable_lookups)",
            "",
            "            if not isinstance(conditional, text_type) or conditional == \"\":",
            "                return conditional",
            "",
            "            # update the lookups flag, as the string returned above may now be unsafe",
            "            # and we don't want future templating calls to do unsafe things",
            "            disable_lookups |= hasattr(conditional, '__UNSAFE__')",
            "",
            "            # First, we do some low-level jinja2 parsing involving the AST format of the",
            "            # statement to ensure we don't do anything unsafe (using the disable_lookup flag above)",
            "            class CleansingNodeVisitor(ast.NodeVisitor):",
            "                def generic_visit(self, node, inside_call=False, inside_yield=False):",
            "                    if isinstance(node, ast.Call):",
            "                        inside_call = True",
            "                    elif isinstance(node, ast.Yield):",
            "                        inside_yield = True",
            "                    elif isinstance(node, ast.Str):",
            "                        if disable_lookups:",
            "                            if inside_call and node.s.startswith(\"__\"):",
            "                                # calling things with a dunder is generally bad at this point...",
            "                                raise AnsibleError(",
            "                                    \"Invalid access found in the conditional: '%s'\" % conditional",
            "                                )",
            "                            elif inside_yield:",
            "                                # we're inside a yield, so recursively parse and traverse the AST",
            "                                # of the result to catch forbidden syntax from executing",
            "                                parsed = ast.parse(node.s, mode='exec')",
            "                                cnv = CleansingNodeVisitor()",
            "                                cnv.visit(parsed)",
            "                    # iterate over all child nodes",
            "                    for child_node in ast.iter_child_nodes(node):",
            "                        self.generic_visit(",
            "                            child_node,",
            "                            inside_call=inside_call,",
            "                            inside_yield=inside_yield",
            "                        )",
            "            try:",
            "                res = templar.environment.parse(conditional, None, None)",
            "                res = generate(res, templar.environment, None, None)",
            "                parsed = ast.parse(res, mode='exec')",
            "",
            "                cnv = CleansingNodeVisitor()",
            "                cnv.visit(parsed)",
            "            except Exception as e:",
            "                raise AnsibleError(\"Invalid conditional detected: %s\" % to_native(e))",
            "",
            "            # and finally we generate and template the presented string and look at the resulting string",
            "            # NOTE The spaces around True and False are intentional to short-circuit literal_eval for",
            "            #      jinja2_native=False and avoid its expensive calls.",
            "            presented = \"{%% if %s %%} True {%% else %%} False {%% endif %%}\" % conditional",
            "            val = templar.template(presented, disable_lookups=disable_lookups).strip()",
            "            if val == \"True\":",
            "                return True",
            "            elif val == \"False\":",
            "                return False",
            "            else:",
            "                raise AnsibleError(\"unable to evaluate conditional: %s\" % original)",
            "        except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "            raise AnsibleUndefinedVariable(\"error while evaluating conditional (%s): %s\" % (original, e))"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import typing as t",
            "",
            "from jinja2.compiler import generate",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible.errors import AnsibleError, AnsibleUndefinedVariable, AnsibleTemplateError",
            "from ansible.module_utils.six import text_type",
            "from ansible.module_utils._text import to_native",
            "from ansible.playbook.attribute import FieldAttribute",
            "from ansible.template import Templar",
            "from ansible.utils.display import Display",
            "",
            "display = Display()",
            "",
            "",
            "class Conditional:",
            "",
            "    '''",
            "    This is a mix-in class, to be used with Base to allow the object",
            "    to be run conditionally when a condition is met or skipped.",
            "    '''",
            "",
            "    when = FieldAttribute(isa='list', default=list, extend=True, prepend=True)",
            "",
            "    def __init__(self, loader=None):",
            "        # when used directly, this class needs a loader, but we want to",
            "        # make sure we don't trample on the existing one if this class",
            "        # is used as a mix-in with a playbook base class",
            "        if not hasattr(self, '_loader'):",
            "            if loader is None:",
            "                raise AnsibleError(\"a loader must be specified when using Conditional() directly\")",
            "            else:",
            "                self._loader = loader",
            "        super(Conditional, self).__init__()",
            "",
            "    def _validate_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def evaluate_conditional(self, templar: Templar, all_vars: dict[str, t.Any]) -> bool:",
            "        '''",
            "        Loops through the conditionals set on this object, returning",
            "        False if any of them evaluate as such.",
            "        '''",
            "        return self.evaluate_conditional_with_result(templar, all_vars)[0]",
            "",
            "    def evaluate_conditional_with_result(self, templar: Templar, all_vars: dict[str, t.Any]) -> tuple[bool, t.Optional[str]]:",
            "        \"\"\"",
            "        Loops through the conditionals set on this object, returning",
            "        False if any of them evaluate as such as well as the condition",
            "        that was false.",
            "        \"\"\"",
            "",
            "        # since this is a mix-in, it may not have an underlying datastructure",
            "        # associated with it, so we pull it out now in case we need it for",
            "        # error reporting below",
            "        ds = None",
            "        if hasattr(self, '_ds'):",
            "            ds = getattr(self, '_ds')",
            "",
            "        result = True",
            "        false_condition: t.Optional[str] = None",
            "        try:",
            "            for conditional in self.when:",
            "",
            "                # do evaluation",
            "                if conditional is None or conditional == '':",
            "                    res = True",
            "                elif isinstance(conditional, bool):",
            "                    res = conditional",
            "                else:",
            "                    res = self._check_conditional(conditional, templar, all_vars)",
            "",
            "                # only update if still true, preserve false",
            "                if result:",
            "                    result = res",
            "",
            "                display.debug(\"Evaluated conditional (%s): %s\" % (conditional, res))",
            "                if not result:",
            "                    false_condition = conditional",
            "                    break",
            "",
            "        except Exception as e:",
            "            raise AnsibleError(\"The conditional check '%s' failed. The error was: %s\" % (to_native(conditional), to_native(e)), obj=ds)",
            "",
            "        return result, false_condition",
            "",
            "    def _check_conditional(self, conditional, templar, all_vars):",
            "        '''",
            "        This method does the low-level evaluation of each conditional",
            "        set on this object, using jinja2 to wrap the conditionals for",
            "        evaluation.",
            "        '''",
            "",
            "        original = conditional",
            "",
            "        if templar.is_template(conditional):",
            "            display.warning('conditional statements should not include jinja2 '",
            "                            'templating delimiters such as {{ }} or {%% %%}. '",
            "                            'Found: %s' % conditional)",
            "",
            "        # make sure the templar is using the variables specified with this method",
            "        templar.available_variables = all_vars",
            "",
            "        try:",
            "            # if the conditional is \"unsafe\", disable lookups",
            "            disable_lookups = hasattr(conditional, '__UNSAFE__')",
            "            conditional = templar.template(conditional, disable_lookups=disable_lookups)",
            "",
            "            if not isinstance(conditional, text_type) or conditional == \"\":",
            "                return conditional",
            "",
            "            # If the result of the first-pass template render (to resolve inline templates) is marked unsafe,",
            "            # explicitly fail since the next templating operation would never evaluate",
            "            if hasattr(conditional, '__UNSAFE__'):",
            "                raise AnsibleTemplateError('Conditional is marked as unsafe, and cannot be evaluated.')",
            "",
            "            # First, we do some low-level jinja2 parsing involving the AST format of the",
            "            # statement to ensure we don't do anything unsafe (using the disable_lookup flag above)",
            "            class CleansingNodeVisitor(ast.NodeVisitor):",
            "                def generic_visit(self, node, inside_call=False, inside_yield=False):",
            "                    if isinstance(node, ast.Call):",
            "                        inside_call = True",
            "                    elif isinstance(node, ast.Yield):",
            "                        inside_yield = True",
            "                    elif isinstance(node, ast.Str):",
            "                        if disable_lookups:",
            "                            if inside_call and node.s.startswith(\"__\"):",
            "                                # calling things with a dunder is generally bad at this point...",
            "                                raise AnsibleError(",
            "                                    \"Invalid access found in the conditional: '%s'\" % conditional",
            "                                )",
            "                            elif inside_yield:",
            "                                # we're inside a yield, so recursively parse and traverse the AST",
            "                                # of the result to catch forbidden syntax from executing",
            "                                parsed = ast.parse(node.s, mode='exec')",
            "                                cnv = CleansingNodeVisitor()",
            "                                cnv.visit(parsed)",
            "                    # iterate over all child nodes",
            "                    for child_node in ast.iter_child_nodes(node):",
            "                        self.generic_visit(",
            "                            child_node,",
            "                            inside_call=inside_call,",
            "                            inside_yield=inside_yield",
            "                        )",
            "            try:",
            "                res = templar.environment.parse(conditional, None, None)",
            "                res = generate(res, templar.environment, None, None)",
            "                parsed = ast.parse(res, mode='exec')",
            "",
            "                cnv = CleansingNodeVisitor()",
            "                cnv.visit(parsed)",
            "            except Exception as e:",
            "                raise AnsibleError(\"Invalid conditional detected: %s\" % to_native(e))",
            "",
            "            # and finally we generate and template the presented string and look at the resulting string",
            "            # NOTE The spaces around True and False are intentional to short-circuit literal_eval for",
            "            #      jinja2_native=False and avoid its expensive calls.",
            "            presented = \"{%% if %s %%} True {%% else %%} False {%% endif %%}\" % conditional",
            "            val = templar.template(presented).strip()",
            "            if val == \"True\":",
            "                return True",
            "            elif val == \"False\":",
            "                return False",
            "            else:",
            "                raise AnsibleError(\"unable to evaluate conditional: %s\" % original)",
            "        except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "            raise AnsibleUndefinedVariable(\"error while evaluating conditional (%s): %s\" % (original, e))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "28": [],
            "135": [
                "Conditional",
                "_check_conditional"
            ],
            "136": [
                "Conditional",
                "_check_conditional"
            ],
            "137": [
                "Conditional",
                "_check_conditional"
            ],
            "181": [
                "Conditional",
                "_check_conditional"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/playbook/task.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 289,
                "afterPatchRowNumber": 289,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 290,
                "afterPatchRowNumber": 290,
                "PatchRowcode": "         super(Task, self).post_validate(templar)"
            },
            "2": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": 291,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 292,
                "PatchRowcode": "+    def _post_validate_args(self, attr, value, templar):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 293,
                "PatchRowcode": "+        # smuggle an untemplated copy of the task args for actions that need more control over the templating of their"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+        # input (eg, debug's var/msg, assert's \"that\" conditional expressions)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 295,
                "PatchRowcode": "+        self.untemplated_args = value"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 296,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 297,
                "PatchRowcode": "+        # now recursively template the args dict"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 298,
                "PatchRowcode": "+        args = templar.template(value)"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 299,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 300,
                "PatchRowcode": "+        # FIXME: could we just nuke this entirely and/or wrap it up in ModuleArgsParser or something?"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 301,
                "PatchRowcode": "+        if '_variable_params' in args:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 302,
                "PatchRowcode": "+            variable_params = args.pop('_variable_params')"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+            if isinstance(variable_params, dict):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+                if C.INJECT_FACTS_AS_VARS:"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 305,
                "PatchRowcode": "+                    display.warning(\"Using a variable for a task's 'args' is unsafe in some situations \""
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 306,
                "PatchRowcode": "+                                    \"(see https://docs.ansible.com/ansible/devel/reference_appendices/faq.html#argsplat-unsafe)\")"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 307,
                "PatchRowcode": "+                variable_params.update(args)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+                args = variable_params"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 309,
                "PatchRowcode": "+            else:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 310,
                "PatchRowcode": "+                # if we didn't get a dict, it means there's garbage remaining after k=v parsing, just give up"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 311,
                "PatchRowcode": "+                # see https://github.com/ansible/ansible/issues/79862"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 312,
                "PatchRowcode": "+                raise AnsibleError(f\"invalid or malformed argument: '{variable_params}'\")"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 313,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 314,
                "PatchRowcode": "+        return args"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 292,
                "afterPatchRowNumber": 316,
                "PatchRowcode": "     def _post_validate_loop(self, attr, value, templar):"
            },
            "28": {
                "beforePatchRowNumber": 293,
                "afterPatchRowNumber": 317,
                "PatchRowcode": "         '''"
            },
            "29": {
                "beforePatchRowNumber": 294,
                "afterPatchRowNumber": 318,
                "PatchRowcode": "         Override post validation for the loop field, which is templated"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleParserError, AnsibleUndefinedVariable, AnsibleAssertionError",
            "from ansible.module_utils._text import to_native",
            "from ansible.module_utils.six import string_types",
            "from ansible.parsing.mod_args import ModuleArgsParser",
            "from ansible.parsing.yaml.objects import AnsibleBaseYAMLObject, AnsibleMapping",
            "from ansible.plugins.loader import lookup_loader",
            "from ansible.playbook.attribute import NonInheritableFieldAttribute",
            "from ansible.playbook.base import Base",
            "from ansible.playbook.block import Block",
            "from ansible.playbook.collectionsearch import CollectionSearch",
            "from ansible.playbook.conditional import Conditional",
            "from ansible.playbook.delegatable import Delegatable",
            "from ansible.playbook.loop_control import LoopControl",
            "from ansible.playbook.notifiable import Notifiable",
            "from ansible.playbook.role import Role",
            "from ansible.playbook.taggable import Taggable",
            "from ansible.utils.collection_loader import AnsibleCollectionConfig",
            "from ansible.utils.display import Display",
            "from ansible.utils.sentinel import Sentinel",
            "",
            "__all__ = ['Task']",
            "",
            "display = Display()",
            "",
            "",
            "class Task(Base, Conditional, Taggable, CollectionSearch, Notifiable, Delegatable):",
            "",
            "    \"\"\"",
            "    A task is a language feature that represents a call to a module, with given arguments and other parameters.",
            "    A handler is a subclass of a task.",
            "",
            "    Usage:",
            "",
            "       Task.load(datastructure) -> Task",
            "       Task.something(...)",
            "    \"\"\"",
            "",
            "    # =================================================================================",
            "    # ATTRIBUTES",
            "    # load_<attribute_name> and",
            "    # validate_<attribute_name>",
            "    # will be used if defined",
            "    # might be possible to define others",
            "",
            "    # NOTE: ONLY set defaults on task attributes that are not inheritable,",
            "    # inheritance is only triggered if the 'current value' is Sentinel,",
            "    # default can be set at play/top level object and inheritance will take it's course.",
            "",
            "    args = NonInheritableFieldAttribute(isa='dict', default=dict)",
            "    action = NonInheritableFieldAttribute(isa='string')",
            "",
            "    async_val = NonInheritableFieldAttribute(isa='int', default=0, alias='async')",
            "    changed_when = NonInheritableFieldAttribute(isa='list', default=list)",
            "    delay = NonInheritableFieldAttribute(isa='int', default=5)",
            "    failed_when = NonInheritableFieldAttribute(isa='list', default=list)",
            "    loop = NonInheritableFieldAttribute(isa='list')",
            "    loop_control = NonInheritableFieldAttribute(isa='class', class_type=LoopControl, default=LoopControl)",
            "    poll = NonInheritableFieldAttribute(isa='int', default=C.DEFAULT_POLL_INTERVAL)",
            "    register = NonInheritableFieldAttribute(isa='string', static=True)",
            "    retries = NonInheritableFieldAttribute(isa='int', default=3)",
            "    until = NonInheritableFieldAttribute(isa='list', default=list)",
            "",
            "    # deprecated, used to be loop and loop_args but loop has been repurposed",
            "    loop_with = NonInheritableFieldAttribute(isa='string', private=True)",
            "",
            "    def __init__(self, block=None, role=None, task_include=None):",
            "        ''' constructors a task, without the Task.load classmethod, it will be pretty blank '''",
            "",
            "        self._role = role",
            "        self._parent = None",
            "        self.implicit = False",
            "        self.resolved_action = None",
            "",
            "        if task_include:",
            "            self._parent = task_include",
            "        else:",
            "            self._parent = block",
            "",
            "        super(Task, self).__init__()",
            "",
            "    def get_name(self, include_role_fqcn=True):",
            "        ''' return the name of the task '''",
            "",
            "        if self._role:",
            "            role_name = self._role.get_name(include_role_fqcn=include_role_fqcn)",
            "",
            "        if self._role and self.name:",
            "            return \"%s : %s\" % (role_name, self.name)",
            "        elif self.name:",
            "            return self.name",
            "        else:",
            "            if self._role:",
            "                return \"%s : %s\" % (role_name, self.action)",
            "            else:",
            "                return \"%s\" % (self.action,)",
            "",
            "    def _merge_kv(self, ds):",
            "        if ds is None:",
            "            return \"\"",
            "        elif isinstance(ds, string_types):",
            "            return ds",
            "        elif isinstance(ds, dict):",
            "            buf = \"\"",
            "            for (k, v) in ds.items():",
            "                if k.startswith('_'):",
            "                    continue",
            "                buf = buf + \"%s=%s \" % (k, v)",
            "            buf = buf.strip()",
            "            return buf",
            "",
            "    @staticmethod",
            "    def load(data, block=None, role=None, task_include=None, variable_manager=None, loader=None):",
            "        t = Task(block=block, role=role, task_include=task_include)",
            "        return t.load_data(data, variable_manager=variable_manager, loader=loader)",
            "",
            "    def __repr__(self):",
            "        ''' returns a human readable representation of the task '''",
            "        if self.action in C._ACTION_META:",
            "            return \"TASK: meta (%s)\" % self.args['_raw_params']",
            "        else:",
            "            return \"TASK: %s\" % self.get_name()",
            "",
            "    def _preprocess_with_loop(self, ds, new_ds, k, v):",
            "        ''' take a lookup plugin name and store it correctly '''",
            "",
            "        loop_name = k.removeprefix(\"with_\")",
            "        if new_ds.get('loop') is not None or new_ds.get('loop_with') is not None:",
            "            raise AnsibleError(\"duplicate loop in task: %s\" % loop_name, obj=ds)",
            "        if v is None:",
            "            raise AnsibleError(\"you must specify a value when using %s\" % k, obj=ds)",
            "        new_ds['loop_with'] = loop_name",
            "        new_ds['loop'] = v",
            "        # display.deprecated(\"with_ type loops are being phased out, use the 'loop' keyword instead\",",
            "        #                    version=\"2.10\", collection_name='ansible.builtin')",
            "",
            "    def preprocess_data(self, ds):",
            "        '''",
            "        tasks are especially complex arguments so need pre-processing.",
            "        keep it short.",
            "        '''",
            "",
            "        if not isinstance(ds, dict):",
            "            raise AnsibleAssertionError('ds (%s) should be a dict but was a %s' % (ds, type(ds)))",
            "",
            "        # the new, cleaned datastructure, which will have legacy",
            "        # items reduced to a standard structure suitable for the",
            "        # attributes of the task class",
            "        new_ds = AnsibleMapping()",
            "        if isinstance(ds, AnsibleBaseYAMLObject):",
            "            new_ds.ansible_pos = ds.ansible_pos",
            "",
            "        # since this affects the task action parsing, we have to resolve in preprocess instead of in typical validator",
            "        default_collection = AnsibleCollectionConfig.default_collection",
            "",
            "        collections_list = ds.get('collections')",
            "        if collections_list is None:",
            "            # use the parent value if our ds doesn't define it",
            "            collections_list = self.collections",
            "        else:",
            "            # Validate this untemplated field early on to guarantee we are dealing with a list.",
            "            # This is also done in CollectionSearch._load_collections() but this runs before that call.",
            "            collections_list = self.get_validated_value('collections', self.fattributes.get('collections'), collections_list, None)",
            "",
            "        if default_collection and not self._role:  # FIXME: and not a collections role",
            "            if collections_list:",
            "                if default_collection not in collections_list:",
            "                    collections_list.insert(0, default_collection)",
            "            else:",
            "                collections_list = [default_collection]",
            "",
            "        if collections_list and 'ansible.builtin' not in collections_list and 'ansible.legacy' not in collections_list:",
            "            collections_list.append('ansible.legacy')",
            "",
            "        if collections_list:",
            "            ds['collections'] = collections_list",
            "",
            "        # use the args parsing class to determine the action, args,",
            "        # and the delegate_to value from the various possible forms",
            "        # supported as legacy",
            "        args_parser = ModuleArgsParser(task_ds=ds, collection_list=collections_list)",
            "        try:",
            "            (action, args, delegate_to) = args_parser.parse()",
            "        except AnsibleParserError as e:",
            "            # if the raises exception was created with obj=ds args, then it includes the detail",
            "            # so we dont need to add it so we can just re raise.",
            "            if e.obj:",
            "                raise",
            "            # But if it wasn't, we can add the yaml object now to get more detail",
            "            raise AnsibleParserError(to_native(e), obj=ds, orig_exc=e)",
            "        else:",
            "            self.resolved_action = args_parser.resolved_action",
            "",
            "        # the command/shell/script modules used to support the `cmd` arg,",
            "        # which corresponds to what we now call _raw_params, so move that",
            "        # value over to _raw_params (assuming it is empty)",
            "        if action in C._ACTION_HAS_CMD:",
            "            if 'cmd' in args:",
            "                if args.get('_raw_params', '') != '':",
            "                    raise AnsibleError(\"The 'cmd' argument cannot be used when other raw parameters are specified.\"",
            "                                       \" Please put everything in one or the other place.\", obj=ds)",
            "                args['_raw_params'] = args.pop('cmd')",
            "",
            "        new_ds['action'] = action",
            "        new_ds['args'] = args",
            "        new_ds['delegate_to'] = delegate_to",
            "",
            "        # we handle any 'vars' specified in the ds here, as we may",
            "        # be adding things to them below (special handling for includes).",
            "        # When that deprecated feature is removed, this can be too.",
            "        if 'vars' in ds:",
            "            # _load_vars is defined in Base, and is used to load a dictionary",
            "            # or list of dictionaries in a standard way",
            "            new_ds['vars'] = self._load_vars(None, ds.get('vars'))",
            "        else:",
            "            new_ds['vars'] = dict()",
            "",
            "        for (k, v) in ds.items():",
            "            if k in ('action', 'local_action', 'args', 'delegate_to') or k == action or k == 'shell':",
            "                # we don't want to re-assign these values, which were determined by the ModuleArgsParser() above",
            "                continue",
            "            elif k.startswith('with_') and k.removeprefix(\"with_\") in lookup_loader:",
            "                # transform into loop property",
            "                self._preprocess_with_loop(ds, new_ds, k, v)",
            "            elif C.INVALID_TASK_ATTRIBUTE_FAILED or k in self.fattributes:",
            "                new_ds[k] = v",
            "            else:",
            "                display.warning(\"Ignoring invalid attribute: %s\" % k)",
            "",
            "        return super(Task, self).preprocess_data(new_ds)",
            "",
            "    def _load_loop_control(self, attr, ds):",
            "        if not isinstance(ds, dict):",
            "            raise AnsibleParserError(",
            "                \"the `loop_control` value must be specified as a dictionary and cannot \"",
            "                \"be a variable itself (though it can contain variables)\",",
            "                obj=ds,",
            "            )",
            "",
            "        return LoopControl.load(data=ds, variable_manager=self._variable_manager, loader=self._loader)",
            "",
            "    def _validate_attributes(self, ds):",
            "        try:",
            "            super(Task, self)._validate_attributes(ds)",
            "        except AnsibleParserError as e:",
            "            e.message += '\\nThis error can be suppressed as a warning using the \"invalid_task_attribute_failed\" configuration'",
            "            raise e",
            "",
            "    def _validate_changed_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def _validate_failed_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def post_validate(self, templar):",
            "        '''",
            "        Override of base class post_validate, to also do final validation on",
            "        the block and task include (if any) to which this task belongs.",
            "        '''",
            "",
            "        if self._parent:",
            "            self._parent.post_validate(templar)",
            "",
            "        if AnsibleCollectionConfig.default_collection:",
            "            pass",
            "",
            "        super(Task, self).post_validate(templar)",
            "",
            "    def _post_validate_loop(self, attr, value, templar):",
            "        '''",
            "        Override post validation for the loop field, which is templated",
            "        specially in the TaskExecutor class when evaluating loops.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_environment(self, attr, value, templar):",
            "        '''",
            "        Override post validation of vars on the play, as we don't want to",
            "        template these too early.",
            "        '''",
            "        env = {}",
            "        if value is not None:",
            "",
            "            def _parse_env_kv(k, v):",
            "                try:",
            "                    env[k] = templar.template(v, convert_bare=False)",
            "                except AnsibleUndefinedVariable as e:",
            "                    error = to_native(e)",
            "                    if self.action in C._ACTION_FACT_GATHERING and 'ansible_facts.env' in error or 'ansible_env' in error:",
            "                        # ignore as fact gathering is required for 'env' facts",
            "                        return",
            "                    raise",
            "",
            "            if isinstance(value, list):",
            "                for env_item in value:",
            "                    if isinstance(env_item, dict):",
            "                        for k in env_item:",
            "                            _parse_env_kv(k, env_item[k])",
            "                    else:",
            "                        isdict = templar.template(env_item, convert_bare=False)",
            "                        if isinstance(isdict, dict):",
            "                            env |= isdict",
            "                        else:",
            "                            display.warning(\"could not parse environment value, skipping: %s\" % value)",
            "",
            "            elif isinstance(value, dict):",
            "                # should not really happen",
            "                env = dict()",
            "                for env_item in value:",
            "                    _parse_env_kv(env_item, value[env_item])",
            "            else:",
            "                # at this point it should be a simple string, also should not happen",
            "                env = templar.template(value, convert_bare=False)",
            "",
            "        return env",
            "",
            "    def _post_validate_changed_when(self, attr, value, templar):",
            "        '''",
            "        changed_when is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_failed_when(self, attr, value, templar):",
            "        '''",
            "        failed_when is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_until(self, attr, value, templar):",
            "        '''",
            "        until is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def get_vars(self):",
            "        all_vars = dict()",
            "        if self._parent:",
            "            all_vars |= self._parent.get_vars()",
            "",
            "        all_vars |= self.vars",
            "",
            "        if 'tags' in all_vars:",
            "            del all_vars['tags']",
            "        if 'when' in all_vars:",
            "            del all_vars['when']",
            "",
            "        return all_vars",
            "",
            "    def get_include_params(self):",
            "        all_vars = dict()",
            "        if self._parent:",
            "            all_vars |= self._parent.get_include_params()",
            "        if self.action in C._ACTION_ALL_INCLUDES:",
            "            all_vars |= self.vars",
            "        return all_vars",
            "",
            "    def copy(self, exclude_parent=False, exclude_tasks=False):",
            "        new_me = super(Task, self).copy()",
            "",
            "        new_me._parent = None",
            "        if self._parent and not exclude_parent:",
            "            new_me._parent = self._parent.copy(exclude_tasks=exclude_tasks)",
            "",
            "        new_me._role = None",
            "        if self._role:",
            "            new_me._role = self._role",
            "",
            "        new_me.implicit = self.implicit",
            "        new_me.resolved_action = self.resolved_action",
            "        new_me._uuid = self._uuid",
            "",
            "        return new_me",
            "",
            "    def serialize(self):",
            "        data = super(Task, self).serialize()",
            "",
            "        if not self._squashed and not self._finalized:",
            "            if self._parent:",
            "                data['parent'] = self._parent.serialize()",
            "                data['parent_type'] = self._parent.__class__.__name__",
            "",
            "            if self._role:",
            "                data['role'] = self._role.serialize()",
            "",
            "            data['implicit'] = self.implicit",
            "            data['resolved_action'] = self.resolved_action",
            "",
            "        return data",
            "",
            "    def deserialize(self, data):",
            "",
            "        # import is here to avoid import loops",
            "        from ansible.playbook.task_include import TaskInclude",
            "        from ansible.playbook.handler_task_include import HandlerTaskInclude",
            "",
            "        parent_data = data.get('parent', None)",
            "        if parent_data:",
            "            parent_type = data.get('parent_type')",
            "            if parent_type == 'Block':",
            "                p = Block()",
            "            elif parent_type == 'TaskInclude':",
            "                p = TaskInclude()",
            "            elif parent_type == 'HandlerTaskInclude':",
            "                p = HandlerTaskInclude()",
            "            p.deserialize(parent_data)",
            "            self._parent = p",
            "            del data['parent']",
            "",
            "        role_data = data.get('role')",
            "        if role_data:",
            "            r = Role()",
            "            r.deserialize(role_data)",
            "            self._role = r",
            "            del data['role']",
            "",
            "        self.implicit = data.get('implicit', False)",
            "        self.resolved_action = data.get('resolved_action')",
            "",
            "        super(Task, self).deserialize(data)",
            "",
            "    def set_loader(self, loader):",
            "        '''",
            "        Sets the loader on this object and recursively on parent, child objects.",
            "        This is used primarily after the Task has been serialized/deserialized, which",
            "        does not preserve the loader.",
            "        '''",
            "",
            "        self._loader = loader",
            "",
            "        if self._parent:",
            "            self._parent.set_loader(loader)",
            "",
            "    def _get_parent_attribute(self, attr, omit=False):",
            "        '''",
            "        Generic logic to get the attribute or parent attribute for a task value.",
            "        '''",
            "        fattr = self.fattributes[attr]",
            "",
            "        extend = fattr.extend",
            "        prepend = fattr.prepend",
            "",
            "        try:",
            "            # omit self, and only get parent values",
            "            if omit:",
            "                value = Sentinel",
            "            else:",
            "                value = getattr(self, f'_{attr}', Sentinel)",
            "",
            "            # If parent is static, we can grab attrs from the parent",
            "            # otherwise, defer to the grandparent",
            "            if getattr(self._parent, 'statically_loaded', True):",
            "                _parent = self._parent",
            "            else:",
            "                _parent = self._parent._parent",
            "",
            "            if _parent and (value is Sentinel or extend):",
            "                if getattr(_parent, 'statically_loaded', True):",
            "                    # vars are always inheritable, other attributes might not be for the parent but still should be for other ancestors",
            "                    if attr != 'vars' and hasattr(_parent, '_get_parent_attribute'):",
            "                        parent_value = _parent._get_parent_attribute(attr)",
            "                    else:",
            "                        parent_value = getattr(_parent, f'_{attr}', Sentinel)",
            "",
            "                    if extend:",
            "                        value = self._extend_value(value, parent_value, prepend)",
            "                    else:",
            "                        value = parent_value",
            "        except KeyError:",
            "            pass",
            "",
            "        return value",
            "",
            "    def all_parents_static(self):",
            "        if self._parent:",
            "            return self._parent.all_parents_static()",
            "        return True",
            "",
            "    def get_first_parent_include(self):",
            "        from ansible.playbook.task_include import TaskInclude",
            "        if self._parent:",
            "            if isinstance(self._parent, TaskInclude):",
            "                return self._parent",
            "            return self._parent.get_first_parent_include()",
            "        return None",
            "",
            "    def get_play(self):",
            "        parent = self._parent",
            "        while not isinstance(parent, Block):",
            "            parent = parent._parent",
            "        return parent._play"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleParserError, AnsibleUndefinedVariable, AnsibleAssertionError",
            "from ansible.module_utils._text import to_native",
            "from ansible.module_utils.six import string_types",
            "from ansible.parsing.mod_args import ModuleArgsParser",
            "from ansible.parsing.yaml.objects import AnsibleBaseYAMLObject, AnsibleMapping",
            "from ansible.plugins.loader import lookup_loader",
            "from ansible.playbook.attribute import NonInheritableFieldAttribute",
            "from ansible.playbook.base import Base",
            "from ansible.playbook.block import Block",
            "from ansible.playbook.collectionsearch import CollectionSearch",
            "from ansible.playbook.conditional import Conditional",
            "from ansible.playbook.delegatable import Delegatable",
            "from ansible.playbook.loop_control import LoopControl",
            "from ansible.playbook.notifiable import Notifiable",
            "from ansible.playbook.role import Role",
            "from ansible.playbook.taggable import Taggable",
            "from ansible.utils.collection_loader import AnsibleCollectionConfig",
            "from ansible.utils.display import Display",
            "from ansible.utils.sentinel import Sentinel",
            "",
            "__all__ = ['Task']",
            "",
            "display = Display()",
            "",
            "",
            "class Task(Base, Conditional, Taggable, CollectionSearch, Notifiable, Delegatable):",
            "",
            "    \"\"\"",
            "    A task is a language feature that represents a call to a module, with given arguments and other parameters.",
            "    A handler is a subclass of a task.",
            "",
            "    Usage:",
            "",
            "       Task.load(datastructure) -> Task",
            "       Task.something(...)",
            "    \"\"\"",
            "",
            "    # =================================================================================",
            "    # ATTRIBUTES",
            "    # load_<attribute_name> and",
            "    # validate_<attribute_name>",
            "    # will be used if defined",
            "    # might be possible to define others",
            "",
            "    # NOTE: ONLY set defaults on task attributes that are not inheritable,",
            "    # inheritance is only triggered if the 'current value' is Sentinel,",
            "    # default can be set at play/top level object and inheritance will take it's course.",
            "",
            "    args = NonInheritableFieldAttribute(isa='dict', default=dict)",
            "    action = NonInheritableFieldAttribute(isa='string')",
            "",
            "    async_val = NonInheritableFieldAttribute(isa='int', default=0, alias='async')",
            "    changed_when = NonInheritableFieldAttribute(isa='list', default=list)",
            "    delay = NonInheritableFieldAttribute(isa='int', default=5)",
            "    failed_when = NonInheritableFieldAttribute(isa='list', default=list)",
            "    loop = NonInheritableFieldAttribute(isa='list')",
            "    loop_control = NonInheritableFieldAttribute(isa='class', class_type=LoopControl, default=LoopControl)",
            "    poll = NonInheritableFieldAttribute(isa='int', default=C.DEFAULT_POLL_INTERVAL)",
            "    register = NonInheritableFieldAttribute(isa='string', static=True)",
            "    retries = NonInheritableFieldAttribute(isa='int', default=3)",
            "    until = NonInheritableFieldAttribute(isa='list', default=list)",
            "",
            "    # deprecated, used to be loop and loop_args but loop has been repurposed",
            "    loop_with = NonInheritableFieldAttribute(isa='string', private=True)",
            "",
            "    def __init__(self, block=None, role=None, task_include=None):",
            "        ''' constructors a task, without the Task.load classmethod, it will be pretty blank '''",
            "",
            "        self._role = role",
            "        self._parent = None",
            "        self.implicit = False",
            "        self.resolved_action = None",
            "",
            "        if task_include:",
            "            self._parent = task_include",
            "        else:",
            "            self._parent = block",
            "",
            "        super(Task, self).__init__()",
            "",
            "    def get_name(self, include_role_fqcn=True):",
            "        ''' return the name of the task '''",
            "",
            "        if self._role:",
            "            role_name = self._role.get_name(include_role_fqcn=include_role_fqcn)",
            "",
            "        if self._role and self.name:",
            "            return \"%s : %s\" % (role_name, self.name)",
            "        elif self.name:",
            "            return self.name",
            "        else:",
            "            if self._role:",
            "                return \"%s : %s\" % (role_name, self.action)",
            "            else:",
            "                return \"%s\" % (self.action,)",
            "",
            "    def _merge_kv(self, ds):",
            "        if ds is None:",
            "            return \"\"",
            "        elif isinstance(ds, string_types):",
            "            return ds",
            "        elif isinstance(ds, dict):",
            "            buf = \"\"",
            "            for (k, v) in ds.items():",
            "                if k.startswith('_'):",
            "                    continue",
            "                buf = buf + \"%s=%s \" % (k, v)",
            "            buf = buf.strip()",
            "            return buf",
            "",
            "    @staticmethod",
            "    def load(data, block=None, role=None, task_include=None, variable_manager=None, loader=None):",
            "        t = Task(block=block, role=role, task_include=task_include)",
            "        return t.load_data(data, variable_manager=variable_manager, loader=loader)",
            "",
            "    def __repr__(self):",
            "        ''' returns a human readable representation of the task '''",
            "        if self.action in C._ACTION_META:",
            "            return \"TASK: meta (%s)\" % self.args['_raw_params']",
            "        else:",
            "            return \"TASK: %s\" % self.get_name()",
            "",
            "    def _preprocess_with_loop(self, ds, new_ds, k, v):",
            "        ''' take a lookup plugin name and store it correctly '''",
            "",
            "        loop_name = k.removeprefix(\"with_\")",
            "        if new_ds.get('loop') is not None or new_ds.get('loop_with') is not None:",
            "            raise AnsibleError(\"duplicate loop in task: %s\" % loop_name, obj=ds)",
            "        if v is None:",
            "            raise AnsibleError(\"you must specify a value when using %s\" % k, obj=ds)",
            "        new_ds['loop_with'] = loop_name",
            "        new_ds['loop'] = v",
            "        # display.deprecated(\"with_ type loops are being phased out, use the 'loop' keyword instead\",",
            "        #                    version=\"2.10\", collection_name='ansible.builtin')",
            "",
            "    def preprocess_data(self, ds):",
            "        '''",
            "        tasks are especially complex arguments so need pre-processing.",
            "        keep it short.",
            "        '''",
            "",
            "        if not isinstance(ds, dict):",
            "            raise AnsibleAssertionError('ds (%s) should be a dict but was a %s' % (ds, type(ds)))",
            "",
            "        # the new, cleaned datastructure, which will have legacy",
            "        # items reduced to a standard structure suitable for the",
            "        # attributes of the task class",
            "        new_ds = AnsibleMapping()",
            "        if isinstance(ds, AnsibleBaseYAMLObject):",
            "            new_ds.ansible_pos = ds.ansible_pos",
            "",
            "        # since this affects the task action parsing, we have to resolve in preprocess instead of in typical validator",
            "        default_collection = AnsibleCollectionConfig.default_collection",
            "",
            "        collections_list = ds.get('collections')",
            "        if collections_list is None:",
            "            # use the parent value if our ds doesn't define it",
            "            collections_list = self.collections",
            "        else:",
            "            # Validate this untemplated field early on to guarantee we are dealing with a list.",
            "            # This is also done in CollectionSearch._load_collections() but this runs before that call.",
            "            collections_list = self.get_validated_value('collections', self.fattributes.get('collections'), collections_list, None)",
            "",
            "        if default_collection and not self._role:  # FIXME: and not a collections role",
            "            if collections_list:",
            "                if default_collection not in collections_list:",
            "                    collections_list.insert(0, default_collection)",
            "            else:",
            "                collections_list = [default_collection]",
            "",
            "        if collections_list and 'ansible.builtin' not in collections_list and 'ansible.legacy' not in collections_list:",
            "            collections_list.append('ansible.legacy')",
            "",
            "        if collections_list:",
            "            ds['collections'] = collections_list",
            "",
            "        # use the args parsing class to determine the action, args,",
            "        # and the delegate_to value from the various possible forms",
            "        # supported as legacy",
            "        args_parser = ModuleArgsParser(task_ds=ds, collection_list=collections_list)",
            "        try:",
            "            (action, args, delegate_to) = args_parser.parse()",
            "        except AnsibleParserError as e:",
            "            # if the raises exception was created with obj=ds args, then it includes the detail",
            "            # so we dont need to add it so we can just re raise.",
            "            if e.obj:",
            "                raise",
            "            # But if it wasn't, we can add the yaml object now to get more detail",
            "            raise AnsibleParserError(to_native(e), obj=ds, orig_exc=e)",
            "        else:",
            "            self.resolved_action = args_parser.resolved_action",
            "",
            "        # the command/shell/script modules used to support the `cmd` arg,",
            "        # which corresponds to what we now call _raw_params, so move that",
            "        # value over to _raw_params (assuming it is empty)",
            "        if action in C._ACTION_HAS_CMD:",
            "            if 'cmd' in args:",
            "                if args.get('_raw_params', '') != '':",
            "                    raise AnsibleError(\"The 'cmd' argument cannot be used when other raw parameters are specified.\"",
            "                                       \" Please put everything in one or the other place.\", obj=ds)",
            "                args['_raw_params'] = args.pop('cmd')",
            "",
            "        new_ds['action'] = action",
            "        new_ds['args'] = args",
            "        new_ds['delegate_to'] = delegate_to",
            "",
            "        # we handle any 'vars' specified in the ds here, as we may",
            "        # be adding things to them below (special handling for includes).",
            "        # When that deprecated feature is removed, this can be too.",
            "        if 'vars' in ds:",
            "            # _load_vars is defined in Base, and is used to load a dictionary",
            "            # or list of dictionaries in a standard way",
            "            new_ds['vars'] = self._load_vars(None, ds.get('vars'))",
            "        else:",
            "            new_ds['vars'] = dict()",
            "",
            "        for (k, v) in ds.items():",
            "            if k in ('action', 'local_action', 'args', 'delegate_to') or k == action or k == 'shell':",
            "                # we don't want to re-assign these values, which were determined by the ModuleArgsParser() above",
            "                continue",
            "            elif k.startswith('with_') and k.removeprefix(\"with_\") in lookup_loader:",
            "                # transform into loop property",
            "                self._preprocess_with_loop(ds, new_ds, k, v)",
            "            elif C.INVALID_TASK_ATTRIBUTE_FAILED or k in self.fattributes:",
            "                new_ds[k] = v",
            "            else:",
            "                display.warning(\"Ignoring invalid attribute: %s\" % k)",
            "",
            "        return super(Task, self).preprocess_data(new_ds)",
            "",
            "    def _load_loop_control(self, attr, ds):",
            "        if not isinstance(ds, dict):",
            "            raise AnsibleParserError(",
            "                \"the `loop_control` value must be specified as a dictionary and cannot \"",
            "                \"be a variable itself (though it can contain variables)\",",
            "                obj=ds,",
            "            )",
            "",
            "        return LoopControl.load(data=ds, variable_manager=self._variable_manager, loader=self._loader)",
            "",
            "    def _validate_attributes(self, ds):",
            "        try:",
            "            super(Task, self)._validate_attributes(ds)",
            "        except AnsibleParserError as e:",
            "            e.message += '\\nThis error can be suppressed as a warning using the \"invalid_task_attribute_failed\" configuration'",
            "            raise e",
            "",
            "    def _validate_changed_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def _validate_failed_when(self, attr, name, value):",
            "        if not isinstance(value, list):",
            "            setattr(self, name, [value])",
            "",
            "    def post_validate(self, templar):",
            "        '''",
            "        Override of base class post_validate, to also do final validation on",
            "        the block and task include (if any) to which this task belongs.",
            "        '''",
            "",
            "        if self._parent:",
            "            self._parent.post_validate(templar)",
            "",
            "        if AnsibleCollectionConfig.default_collection:",
            "            pass",
            "",
            "        super(Task, self).post_validate(templar)",
            "",
            "    def _post_validate_args(self, attr, value, templar):",
            "        # smuggle an untemplated copy of the task args for actions that need more control over the templating of their",
            "        # input (eg, debug's var/msg, assert's \"that\" conditional expressions)",
            "        self.untemplated_args = value",
            "",
            "        # now recursively template the args dict",
            "        args = templar.template(value)",
            "",
            "        # FIXME: could we just nuke this entirely and/or wrap it up in ModuleArgsParser or something?",
            "        if '_variable_params' in args:",
            "            variable_params = args.pop('_variable_params')",
            "            if isinstance(variable_params, dict):",
            "                if C.INJECT_FACTS_AS_VARS:",
            "                    display.warning(\"Using a variable for a task's 'args' is unsafe in some situations \"",
            "                                    \"(see https://docs.ansible.com/ansible/devel/reference_appendices/faq.html#argsplat-unsafe)\")",
            "                variable_params.update(args)",
            "                args = variable_params",
            "            else:",
            "                # if we didn't get a dict, it means there's garbage remaining after k=v parsing, just give up",
            "                # see https://github.com/ansible/ansible/issues/79862",
            "                raise AnsibleError(f\"invalid or malformed argument: '{variable_params}'\")",
            "",
            "        return args",
            "",
            "    def _post_validate_loop(self, attr, value, templar):",
            "        '''",
            "        Override post validation for the loop field, which is templated",
            "        specially in the TaskExecutor class when evaluating loops.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_environment(self, attr, value, templar):",
            "        '''",
            "        Override post validation of vars on the play, as we don't want to",
            "        template these too early.",
            "        '''",
            "        env = {}",
            "        if value is not None:",
            "",
            "            def _parse_env_kv(k, v):",
            "                try:",
            "                    env[k] = templar.template(v, convert_bare=False)",
            "                except AnsibleUndefinedVariable as e:",
            "                    error = to_native(e)",
            "                    if self.action in C._ACTION_FACT_GATHERING and 'ansible_facts.env' in error or 'ansible_env' in error:",
            "                        # ignore as fact gathering is required for 'env' facts",
            "                        return",
            "                    raise",
            "",
            "            if isinstance(value, list):",
            "                for env_item in value:",
            "                    if isinstance(env_item, dict):",
            "                        for k in env_item:",
            "                            _parse_env_kv(k, env_item[k])",
            "                    else:",
            "                        isdict = templar.template(env_item, convert_bare=False)",
            "                        if isinstance(isdict, dict):",
            "                            env |= isdict",
            "                        else:",
            "                            display.warning(\"could not parse environment value, skipping: %s\" % value)",
            "",
            "            elif isinstance(value, dict):",
            "                # should not really happen",
            "                env = dict()",
            "                for env_item in value:",
            "                    _parse_env_kv(env_item, value[env_item])",
            "            else:",
            "                # at this point it should be a simple string, also should not happen",
            "                env = templar.template(value, convert_bare=False)",
            "",
            "        return env",
            "",
            "    def _post_validate_changed_when(self, attr, value, templar):",
            "        '''",
            "        changed_when is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_failed_when(self, attr, value, templar):",
            "        '''",
            "        failed_when is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def _post_validate_until(self, attr, value, templar):",
            "        '''",
            "        until is evaluated after the execution of the task is complete,",
            "        and should not be templated during the regular post_validate step.",
            "        '''",
            "        return value",
            "",
            "    def get_vars(self):",
            "        all_vars = dict()",
            "        if self._parent:",
            "            all_vars |= self._parent.get_vars()",
            "",
            "        all_vars |= self.vars",
            "",
            "        if 'tags' in all_vars:",
            "            del all_vars['tags']",
            "        if 'when' in all_vars:",
            "            del all_vars['when']",
            "",
            "        return all_vars",
            "",
            "    def get_include_params(self):",
            "        all_vars = dict()",
            "        if self._parent:",
            "            all_vars |= self._parent.get_include_params()",
            "        if self.action in C._ACTION_ALL_INCLUDES:",
            "            all_vars |= self.vars",
            "        return all_vars",
            "",
            "    def copy(self, exclude_parent=False, exclude_tasks=False):",
            "        new_me = super(Task, self).copy()",
            "",
            "        new_me._parent = None",
            "        if self._parent and not exclude_parent:",
            "            new_me._parent = self._parent.copy(exclude_tasks=exclude_tasks)",
            "",
            "        new_me._role = None",
            "        if self._role:",
            "            new_me._role = self._role",
            "",
            "        new_me.implicit = self.implicit",
            "        new_me.resolved_action = self.resolved_action",
            "        new_me._uuid = self._uuid",
            "",
            "        return new_me",
            "",
            "    def serialize(self):",
            "        data = super(Task, self).serialize()",
            "",
            "        if not self._squashed and not self._finalized:",
            "            if self._parent:",
            "                data['parent'] = self._parent.serialize()",
            "                data['parent_type'] = self._parent.__class__.__name__",
            "",
            "            if self._role:",
            "                data['role'] = self._role.serialize()",
            "",
            "            data['implicit'] = self.implicit",
            "            data['resolved_action'] = self.resolved_action",
            "",
            "        return data",
            "",
            "    def deserialize(self, data):",
            "",
            "        # import is here to avoid import loops",
            "        from ansible.playbook.task_include import TaskInclude",
            "        from ansible.playbook.handler_task_include import HandlerTaskInclude",
            "",
            "        parent_data = data.get('parent', None)",
            "        if parent_data:",
            "            parent_type = data.get('parent_type')",
            "            if parent_type == 'Block':",
            "                p = Block()",
            "            elif parent_type == 'TaskInclude':",
            "                p = TaskInclude()",
            "            elif parent_type == 'HandlerTaskInclude':",
            "                p = HandlerTaskInclude()",
            "            p.deserialize(parent_data)",
            "            self._parent = p",
            "            del data['parent']",
            "",
            "        role_data = data.get('role')",
            "        if role_data:",
            "            r = Role()",
            "            r.deserialize(role_data)",
            "            self._role = r",
            "            del data['role']",
            "",
            "        self.implicit = data.get('implicit', False)",
            "        self.resolved_action = data.get('resolved_action')",
            "",
            "        super(Task, self).deserialize(data)",
            "",
            "    def set_loader(self, loader):",
            "        '''",
            "        Sets the loader on this object and recursively on parent, child objects.",
            "        This is used primarily after the Task has been serialized/deserialized, which",
            "        does not preserve the loader.",
            "        '''",
            "",
            "        self._loader = loader",
            "",
            "        if self._parent:",
            "            self._parent.set_loader(loader)",
            "",
            "    def _get_parent_attribute(self, attr, omit=False):",
            "        '''",
            "        Generic logic to get the attribute or parent attribute for a task value.",
            "        '''",
            "        fattr = self.fattributes[attr]",
            "",
            "        extend = fattr.extend",
            "        prepend = fattr.prepend",
            "",
            "        try:",
            "            # omit self, and only get parent values",
            "            if omit:",
            "                value = Sentinel",
            "            else:",
            "                value = getattr(self, f'_{attr}', Sentinel)",
            "",
            "            # If parent is static, we can grab attrs from the parent",
            "            # otherwise, defer to the grandparent",
            "            if getattr(self._parent, 'statically_loaded', True):",
            "                _parent = self._parent",
            "            else:",
            "                _parent = self._parent._parent",
            "",
            "            if _parent and (value is Sentinel or extend):",
            "                if getattr(_parent, 'statically_loaded', True):",
            "                    # vars are always inheritable, other attributes might not be for the parent but still should be for other ancestors",
            "                    if attr != 'vars' and hasattr(_parent, '_get_parent_attribute'):",
            "                        parent_value = _parent._get_parent_attribute(attr)",
            "                    else:",
            "                        parent_value = getattr(_parent, f'_{attr}', Sentinel)",
            "",
            "                    if extend:",
            "                        value = self._extend_value(value, parent_value, prepend)",
            "                    else:",
            "                        value = parent_value",
            "        except KeyError:",
            "            pass",
            "",
            "        return value",
            "",
            "    def all_parents_static(self):",
            "        if self._parent:",
            "            return self._parent.all_parents_static()",
            "        return True",
            "",
            "    def get_first_parent_include(self):",
            "        from ansible.playbook.task_include import TaskInclude",
            "        if self._parent:",
            "            if isinstance(self._parent, TaskInclude):",
            "                return self._parent",
            "            return self._parent.get_first_parent_include()",
            "        return None",
            "",
            "    def get_play(self):",
            "        parent = self._parent",
            "        while not isinstance(parent, Block):",
            "            parent = parent._parent",
            "        return parent._play"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "yt_dlp.YoutubeDL",
            "lib.ansible.playbook.task.Task.load.t",
            "lib.ansible.playbook.task.Task.self"
        ]
    },
    "lib/ansible/plugins/action/assert.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         quiet = boolean(self._task.args.get('quiet', False), strict=False)"
            },
            "2": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+        # directly access 'that' via untemplated args from the task so we can intelligently trust embedded"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+        # templates and preserve the original inputs/locations for better messaging on assert failures and"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+        # errors."
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+        # FIXME: even in devel, things like `that: item` don't always work properly (truthy string value"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+        # is not really an embedded expression)"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+        # we could fix that by doing direct var lookups on the inputs"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+        # FIXME: some form of this code should probably be shared between debug, assert, and"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+        # Task.post_validate, since they"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+        # have a lot of overlapping needs"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+        try:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+            thats = self._task.untemplated_args['that']"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+        except KeyError:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+            # in the case of \"we got our entire args dict from a template\", we can just consult the"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+            # post-templated dict (the damage has likely already been done for embedded templates anyway)"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+            thats = self._task.args['that']"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+        # FIXME: this is a case where we only want to resolve indirections, NOT recurse containers"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+        # (and even then, the leaf-most expression being wrapped is at least suboptimal"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+        # (since its expression will be \"eaten\")."
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+        if isinstance(thats, str):"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+            thats = self._templar.template(thats)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         # make sure the 'that' items are a list"
            },
            "26": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        thats = self._task.args['that']"
            },
            "27": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "         if not isinstance(thats, list):"
            },
            "28": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "             thats = [thats]"
            },
            "29": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 91,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright 2012, Dag Wieers <dag@wieers.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "from ansible.errors import AnsibleError",
            "from ansible.playbook.conditional import Conditional",
            "from ansible.plugins.action import ActionBase",
            "from ansible.module_utils.six import string_types",
            "from ansible.module_utils.parsing.convert_bool import boolean",
            "",
            "",
            "class ActionModule(ActionBase):",
            "    ''' Fail with custom message '''",
            "",
            "    TRANSFERS_FILES = False",
            "    _VALID_ARGS = frozenset(('fail_msg', 'msg', 'quiet', 'success_msg', 'that'))",
            "",
            "    def run(self, tmp=None, task_vars=None):",
            "        if task_vars is None:",
            "            task_vars = dict()",
            "",
            "        result = super(ActionModule, self).run(tmp, task_vars)",
            "        del tmp  # tmp no longer has any effect",
            "",
            "        if 'that' not in self._task.args:",
            "            raise AnsibleError('conditional required in \"that\" string')",
            "",
            "        fail_msg = None",
            "        success_msg = None",
            "",
            "        fail_msg = self._task.args.get('fail_msg', self._task.args.get('msg'))",
            "        if fail_msg is None:",
            "            fail_msg = 'Assertion failed'",
            "        elif isinstance(fail_msg, list):",
            "            if not all(isinstance(x, string_types) for x in fail_msg):",
            "                raise AnsibleError('Type of one of the elements in fail_msg or msg list is not string type')",
            "        elif not isinstance(fail_msg, (string_types, list)):",
            "            raise AnsibleError('Incorrect type for fail_msg or msg, expected a string or list and got %s' % type(fail_msg))",
            "",
            "        success_msg = self._task.args.get('success_msg')",
            "        if success_msg is None:",
            "            success_msg = 'All assertions passed'",
            "        elif isinstance(success_msg, list):",
            "            if not all(isinstance(x, string_types) for x in success_msg):",
            "                raise AnsibleError('Type of one of the elements in success_msg list is not string type')",
            "        elif not isinstance(success_msg, (string_types, list)):",
            "            raise AnsibleError('Incorrect type for success_msg, expected a string or list and got %s' % type(success_msg))",
            "",
            "        quiet = boolean(self._task.args.get('quiet', False), strict=False)",
            "",
            "        # make sure the 'that' items are a list",
            "        thats = self._task.args['that']",
            "        if not isinstance(thats, list):",
            "            thats = [thats]",
            "",
            "        # Now we iterate over the that items, temporarily assigning them",
            "        # to the task's when value so we can evaluate the conditional using",
            "        # the built in evaluate function. The when has already been evaluated",
            "        # by this point, and is not used again, so we don't care about mangling",
            "        # that value now",
            "        cond = Conditional(loader=self._loader)",
            "        if not quiet:",
            "            result['_ansible_verbose_always'] = True",
            "",
            "        for that in thats:",
            "            cond.when = [that]",
            "            test_result = cond.evaluate_conditional(templar=self._templar, all_vars=task_vars)",
            "            if not test_result:",
            "                result['failed'] = True",
            "                result['evaluated_to'] = test_result",
            "                result['assertion'] = that",
            "",
            "                result['msg'] = fail_msg",
            "",
            "                return result",
            "",
            "        result['changed'] = False",
            "        result['msg'] = success_msg",
            "        return result"
        ],
        "afterPatchFile": [
            "# Copyright 2012, Dag Wieers <dag@wieers.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "from ansible.errors import AnsibleError",
            "from ansible.playbook.conditional import Conditional",
            "from ansible.plugins.action import ActionBase",
            "from ansible.module_utils.six import string_types",
            "from ansible.module_utils.parsing.convert_bool import boolean",
            "",
            "",
            "class ActionModule(ActionBase):",
            "    ''' Fail with custom message '''",
            "",
            "    TRANSFERS_FILES = False",
            "    _VALID_ARGS = frozenset(('fail_msg', 'msg', 'quiet', 'success_msg', 'that'))",
            "",
            "    def run(self, tmp=None, task_vars=None):",
            "        if task_vars is None:",
            "            task_vars = dict()",
            "",
            "        result = super(ActionModule, self).run(tmp, task_vars)",
            "        del tmp  # tmp no longer has any effect",
            "",
            "        if 'that' not in self._task.args:",
            "            raise AnsibleError('conditional required in \"that\" string')",
            "",
            "        fail_msg = None",
            "        success_msg = None",
            "",
            "        fail_msg = self._task.args.get('fail_msg', self._task.args.get('msg'))",
            "        if fail_msg is None:",
            "            fail_msg = 'Assertion failed'",
            "        elif isinstance(fail_msg, list):",
            "            if not all(isinstance(x, string_types) for x in fail_msg):",
            "                raise AnsibleError('Type of one of the elements in fail_msg or msg list is not string type')",
            "        elif not isinstance(fail_msg, (string_types, list)):",
            "            raise AnsibleError('Incorrect type for fail_msg or msg, expected a string or list and got %s' % type(fail_msg))",
            "",
            "        success_msg = self._task.args.get('success_msg')",
            "        if success_msg is None:",
            "            success_msg = 'All assertions passed'",
            "        elif isinstance(success_msg, list):",
            "            if not all(isinstance(x, string_types) for x in success_msg):",
            "                raise AnsibleError('Type of one of the elements in success_msg list is not string type')",
            "        elif not isinstance(success_msg, (string_types, list)):",
            "            raise AnsibleError('Incorrect type for success_msg, expected a string or list and got %s' % type(success_msg))",
            "",
            "        quiet = boolean(self._task.args.get('quiet', False), strict=False)",
            "",
            "        # directly access 'that' via untemplated args from the task so we can intelligently trust embedded",
            "        # templates and preserve the original inputs/locations for better messaging on assert failures and",
            "        # errors.",
            "        # FIXME: even in devel, things like `that: item` don't always work properly (truthy string value",
            "        # is not really an embedded expression)",
            "        # we could fix that by doing direct var lookups on the inputs",
            "        # FIXME: some form of this code should probably be shared between debug, assert, and",
            "        # Task.post_validate, since they",
            "        # have a lot of overlapping needs",
            "        try:",
            "            thats = self._task.untemplated_args['that']",
            "        except KeyError:",
            "            # in the case of \"we got our entire args dict from a template\", we can just consult the",
            "            # post-templated dict (the damage has likely already been done for embedded templates anyway)",
            "            thats = self._task.args['that']",
            "",
            "        # FIXME: this is a case where we only want to resolve indirections, NOT recurse containers",
            "        # (and even then, the leaf-most expression being wrapped is at least suboptimal",
            "        # (since its expression will be \"eaten\").",
            "        if isinstance(thats, str):",
            "            thats = self._templar.template(thats)",
            "",
            "        # make sure the 'that' items are a list",
            "        if not isinstance(thats, list):",
            "            thats = [thats]",
            "",
            "        # Now we iterate over the that items, temporarily assigning them",
            "        # to the task's when value so we can evaluate the conditional using",
            "        # the built in evaluate function. The when has already been evaluated",
            "        # by this point, and is not used again, so we don't care about mangling",
            "        # that value now",
            "        cond = Conditional(loader=self._loader)",
            "        if not quiet:",
            "            result['_ansible_verbose_always'] = True",
            "",
            "        for that in thats:",
            "            cond.when = [that]",
            "            test_result = cond.evaluate_conditional(templar=self._templar, all_vars=task_vars)",
            "            if not test_result:",
            "                result['failed'] = True",
            "                result['evaluated_to'] = test_result",
            "                result['assertion'] = that",
            "",
            "                result['msg'] = fail_msg",
            "",
            "                return result",
            "",
            "        result['changed'] = False",
            "        result['msg'] = success_msg",
            "        return result"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "67": [
                "ActionModule",
                "run"
            ]
        },
        "addLocation": [
            "lib.ansible.plugins.action.assert.ActionModule.run.thats",
            "yt_dlp.YoutubeDL"
        ]
    },
    "lib/ansible/plugins/callback/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " from ansible.plugins import AnsiblePlugin"
            },
            "1": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " from ansible.utils.color import stringc"
            },
            "2": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " from ansible.utils.display import Display"
            },
            "3": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from ansible.utils.unsafe_proxy import AnsibleUnsafeText, NativeJinjaUnsafeText"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+from ansible.utils.unsafe_proxy import AnsibleUnsafeText, NativeJinjaUnsafeText, _is_unsafe"
            },
            "5": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " from ansible.vars.clean import strip_internal_keys, module_response_deepcopy"
            },
            "6": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " import yaml"
            },
            "8": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 113,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 114,
                "PatchRowcode": " def _pretty_represent_str(self, data):"
            },
            "10": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     \"\"\"Uses block style for multi-line strings\"\"\""
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+    if _is_unsafe(data):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        data = data._strip_unsafe()"
            },
            "13": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "     data = text_type(data)"
            },
            "14": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "     if _should_use_block(data):"
            },
            "15": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 120,
                "PatchRowcode": "         style = '|'"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import difflib",
            "import json",
            "import re",
            "import sys",
            "import textwrap",
            "",
            "from collections import OrderedDict",
            "from collections.abc import MutableMapping",
            "from copy import deepcopy",
            "",
            "from ansible import constants as C",
            "from ansible.module_utils.common.text.converters import to_text",
            "from ansible.module_utils.six import text_type",
            "from ansible.parsing.ajson import AnsibleJSONEncoder",
            "from ansible.parsing.yaml.dumper import AnsibleDumper",
            "from ansible.parsing.yaml.objects import AnsibleUnicode",
            "from ansible.plugins import AnsiblePlugin",
            "from ansible.utils.color import stringc",
            "from ansible.utils.display import Display",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeText, NativeJinjaUnsafeText",
            "from ansible.vars.clean import strip_internal_keys, module_response_deepcopy",
            "",
            "import yaml",
            "",
            "global_display = Display()",
            "",
            "",
            "__all__ = [\"CallbackBase\"]",
            "",
            "",
            "_DEBUG_ALLOWED_KEYS = frozenset(('msg', 'exception', 'warnings', 'deprecations'))",
            "_YAML_TEXT_TYPES = (text_type, AnsibleUnicode, AnsibleUnsafeText, NativeJinjaUnsafeText)",
            "# Characters that libyaml/pyyaml consider breaks",
            "_YAML_BREAK_CHARS = '\\n\\x85\\u2028\\u2029'  # NL, NEL, LS, PS",
            "# regex representation of libyaml/pyyaml of a space followed by a break character",
            "_SPACE_BREAK_RE = re.compile(fr' +([{_YAML_BREAK_CHARS}])')",
            "",
            "",
            "class _AnsibleCallbackDumper(AnsibleDumper):",
            "    def __init__(self, lossy=False):",
            "        self._lossy = lossy",
            "",
            "    def __call__(self, *args, **kwargs):",
            "        # pyyaml expects that we are passing an object that can be instantiated, but to",
            "        # smuggle the ``lossy`` configuration, we do that in ``__init__`` and then",
            "        # define this ``__call__`` that will mimic the ability for pyyaml to instantiate class",
            "        super().__init__(*args, **kwargs)",
            "        return self",
            "",
            "",
            "def _should_use_block(scalar):",
            "    \"\"\"Returns true if string should be in block format based on the existence of various newline separators\"\"\"",
            "    # This method of searching is faster than using a regex",
            "    for ch in _YAML_BREAK_CHARS:",
            "        if ch in scalar:",
            "            return True",
            "    return False",
            "",
            "",
            "class _SpecialCharacterTranslator:",
            "    def __getitem__(self, ch):",
            "        # \"special character\" logic from pyyaml yaml.emitter.Emitter.analyze_scalar, translated to decimal",
            "        # for perf w/ str.translate",
            "        if (ch == 10 or",
            "            32 <= ch <= 126 or",
            "            ch == 133 or",
            "            160 <= ch <= 55295 or",
            "            57344 <= ch <= 65533 or",
            "            65536 <= ch < 1114111)\\",
            "                and ch != 65279:",
            "            return ch",
            "        return None",
            "",
            "",
            "def _filter_yaml_special(scalar):",
            "    \"\"\"Filter a string removing any character that libyaml/pyyaml declare as special\"\"\"",
            "    return scalar.translate(_SpecialCharacterTranslator())",
            "",
            "",
            "def _munge_data_for_lossy_yaml(scalar):",
            "    \"\"\"Modify a string so that analyze_scalar in libyaml/pyyaml will allow block formatting\"\"\"",
            "    # we care more about readability than accuracy, so...",
            "    # ...libyaml/pyyaml does not permit trailing spaces for block scalars",
            "    scalar = scalar.rstrip()",
            "    # ...libyaml/pyyaml does not permit tabs for block scalars",
            "    scalar = scalar.expandtabs()",
            "    # ...libyaml/pyyaml only permits special characters for double quoted scalars",
            "    scalar = _filter_yaml_special(scalar)",
            "    # ...libyaml/pyyaml only permits spaces followed by breaks for double quoted scalars",
            "    return _SPACE_BREAK_RE.sub(r'\\1', scalar)",
            "",
            "",
            "def _pretty_represent_str(self, data):",
            "    \"\"\"Uses block style for multi-line strings\"\"\"",
            "    data = text_type(data)",
            "    if _should_use_block(data):",
            "        style = '|'",
            "        if self._lossy:",
            "            data = _munge_data_for_lossy_yaml(data)",
            "    else:",
            "        style = self.default_style",
            "",
            "    node = yaml.representer.ScalarNode('tag:yaml.org,2002:str', data, style=style)",
            "    if self.alias_key is not None:",
            "        self.represented_objects[self.alias_key] = node",
            "    return node",
            "",
            "",
            "for data_type in _YAML_TEXT_TYPES:",
            "    _AnsibleCallbackDumper.add_representer(",
            "        data_type,",
            "        _pretty_represent_str",
            "    )",
            "",
            "",
            "class CallbackBase(AnsiblePlugin):",
            "",
            "    '''",
            "    This is a base ansible callback class that does nothing. New callbacks should",
            "    use this class as a base and override any callback methods they wish to execute",
            "    custom actions.",
            "    '''",
            "",
            "    def __init__(self, display=None, options=None):",
            "        if display:",
            "            self._display = display",
            "        else:",
            "            self._display = global_display",
            "",
            "        if self._display.verbosity >= 4:",
            "            name = getattr(self, 'CALLBACK_NAME', 'unnamed')",
            "            ctype = getattr(self, 'CALLBACK_TYPE', 'old')",
            "            version = getattr(self, 'CALLBACK_VERSION', '1.0')",
            "            self._display.vvvv('Loading callback plugin %s of type %s, v%s from %s' % (name, ctype, version, sys.modules[self.__module__].__file__))",
            "",
            "        self.disabled = False",
            "        self.wants_implicit_tasks = False",
            "",
            "        self._plugin_options = {}",
            "        if options is not None:",
            "            self.set_options(options)",
            "",
            "        self._hide_in_debug = ('changed', 'failed', 'skipped', 'invocation', 'skip_reason')",
            "",
            "    # helper for callbacks, so they don't all have to include deepcopy",
            "    _copy_result = deepcopy",
            "",
            "    def set_option(self, k, v):",
            "        self._plugin_options[k] = v",
            "",
            "    def get_option(self, k):",
            "        return self._plugin_options[k]",
            "",
            "    def set_options(self, task_keys=None, var_options=None, direct=None):",
            "        ''' This is different than the normal plugin method as callbacks get called early and really don't accept keywords.",
            "            Also _options was already taken for CLI args and callbacks use _plugin_options instead.",
            "        '''",
            "",
            "        # load from config",
            "        self._plugin_options = C.config.get_plugin_options(self.plugin_type, self._load_name, keys=task_keys, variables=var_options, direct=direct)",
            "",
            "    @staticmethod",
            "    def host_label(result):",
            "        \"\"\"Return label for the hostname (& delegated hostname) of a task",
            "        result.",
            "        \"\"\"",
            "        label = \"%s\" % result._host.get_name()",
            "        if result._task.delegate_to and result._task.delegate_to != result._host.get_name():",
            "            # show delegated host",
            "            label += \" -> %s\" % result._task.delegate_to",
            "            # in case we have 'extra resolution'",
            "            ahost = result._result.get('_ansible_delegated_vars', {}).get('ansible_host', result._task.delegate_to)",
            "            if result._task.delegate_to != ahost:",
            "                label += \"(%s)\" % ahost",
            "        return label",
            "",
            "    def _run_is_verbose(self, result, verbosity=0):",
            "        return ((self._display.verbosity > verbosity or result._result.get('_ansible_verbose_always', False) is True)",
            "                and result._result.get('_ansible_verbose_override', False) is False)",
            "",
            "    def _dump_results(self, result, indent=None, sort_keys=True, keep_invocation=False, serialize=True):",
            "        try:",
            "            result_format = self.get_option('result_format')",
            "        except KeyError:",
            "            # Callback does not declare result_format nor extend result_format_callback",
            "            result_format = 'json'",
            "",
            "        try:",
            "            pretty_results = self.get_option('pretty_results')",
            "        except KeyError:",
            "            # Callback does not declare pretty_results nor extend result_format_callback",
            "            pretty_results = None",
            "",
            "        indent_conditions = (",
            "            result.get('_ansible_verbose_always'),",
            "            pretty_results is None and result_format != 'json',",
            "            pretty_results is True,",
            "            self._display.verbosity > 2,",
            "        )",
            "",
            "        if not indent and any(indent_conditions):",
            "            indent = 4",
            "        if pretty_results is False:",
            "            # pretty_results=False overrides any specified indentation",
            "            indent = None",
            "",
            "        # All result keys stating with _ansible_ are internal, so remove them from the result before we output anything.",
            "        abridged_result = strip_internal_keys(module_response_deepcopy(result))",
            "",
            "        # remove invocation unless specifically wanting it",
            "        if not keep_invocation and self._display.verbosity < 3 and 'invocation' in result:",
            "            del abridged_result['invocation']",
            "",
            "        # remove diff information from screen output",
            "        if self._display.verbosity < 3 and 'diff' in result:",
            "            del abridged_result['diff']",
            "",
            "        # remove exception from screen output",
            "        if 'exception' in abridged_result:",
            "            del abridged_result['exception']",
            "",
            "        if not serialize:",
            "            # Just return ``abridged_result`` without going through serialization",
            "            # to permit callbacks to take advantage of ``_dump_results``",
            "            # that want to further modify the result, or use custom serialization",
            "            return abridged_result",
            "",
            "        if result_format == 'json':",
            "            try:",
            "                return json.dumps(abridged_result, cls=AnsibleJSONEncoder, indent=indent, ensure_ascii=False, sort_keys=sort_keys)",
            "            except TypeError:",
            "                # Python3 bug: throws an exception when keys are non-homogenous types:",
            "                # https://bugs.python.org/issue25457",
            "                # sort into an OrderedDict and then json.dumps() that instead",
            "                if not OrderedDict:",
            "                    raise",
            "                return json.dumps(OrderedDict(sorted(abridged_result.items(), key=to_text)),",
            "                                  cls=AnsibleJSONEncoder, indent=indent,",
            "                                  ensure_ascii=False, sort_keys=False)",
            "        elif result_format == 'yaml':",
            "            # None is a sentinel in this case that indicates default behavior",
            "            # default behavior for yaml is to prettify results",
            "            lossy = pretty_results in (None, True)",
            "            if lossy:",
            "                # if we already have stdout, we don't need stdout_lines",
            "                if 'stdout' in abridged_result and 'stdout_lines' in abridged_result:",
            "                    abridged_result['stdout_lines'] = '<omitted>'",
            "",
            "                # if we already have stderr, we don't need stderr_lines",
            "                if 'stderr' in abridged_result and 'stderr_lines' in abridged_result:",
            "                    abridged_result['stderr_lines'] = '<omitted>'",
            "",
            "            return '\\n%s' % textwrap.indent(",
            "                yaml.dump(",
            "                    abridged_result,",
            "                    allow_unicode=True,",
            "                    Dumper=_AnsibleCallbackDumper(lossy=lossy),",
            "                    default_flow_style=False,",
            "                    indent=indent,",
            "                    # sort_keys=sort_keys  # This requires PyYAML>=5.1",
            "                ),",
            "                ' ' * (indent or 4)",
            "            )",
            "",
            "    def _handle_warnings(self, res):",
            "        ''' display warnings, if enabled and any exist in the result '''",
            "        if C.ACTION_WARNINGS:",
            "            if 'warnings' in res and res['warnings']:",
            "                for warning in res['warnings']:",
            "                    self._display.warning(warning)",
            "                del res['warnings']",
            "            if 'deprecations' in res and res['deprecations']:",
            "                for warning in res['deprecations']:",
            "                    self._display.deprecated(**warning)",
            "                del res['deprecations']",
            "",
            "    def _handle_exception(self, result, use_stderr=False):",
            "",
            "        if 'exception' in result:",
            "            msg = \"An exception occurred during task execution. \"",
            "            exception_str = to_text(result['exception'])",
            "            if self._display.verbosity < 3:",
            "                # extract just the actual error message from the exception text",
            "                error = exception_str.strip().split('\\n')[-1]",
            "                msg += \"To see the full traceback, use -vvv. The error was: %s\" % error",
            "            else:",
            "                msg = \"The full traceback is:\\n\" + exception_str",
            "                del result['exception']",
            "",
            "            self._display.display(msg, color=C.COLOR_ERROR, stderr=use_stderr)",
            "",
            "    def _serialize_diff(self, diff):",
            "        try:",
            "            result_format = self.get_option('result_format')",
            "        except KeyError:",
            "            # Callback does not declare result_format nor extend result_format_callback",
            "            result_format = 'json'",
            "",
            "        try:",
            "            pretty_results = self.get_option('pretty_results')",
            "        except KeyError:",
            "            # Callback does not declare pretty_results nor extend result_format_callback",
            "            pretty_results = None",
            "",
            "        if result_format == 'json':",
            "            return json.dumps(diff, sort_keys=True, indent=4, separators=(u',', u': ')) + u'\\n'",
            "        elif result_format == 'yaml':",
            "            # None is a sentinel in this case that indicates default behavior",
            "            # default behavior for yaml is to prettify results",
            "            lossy = pretty_results in (None, True)",
            "            return '%s\\n' % textwrap.indent(",
            "                yaml.dump(",
            "                    diff,",
            "                    allow_unicode=True,",
            "                    Dumper=_AnsibleCallbackDumper(lossy=lossy),",
            "                    default_flow_style=False,",
            "                    indent=4,",
            "                    # sort_keys=sort_keys  # This requires PyYAML>=5.1",
            "                ),",
            "                '    '",
            "            )",
            "",
            "    def _get_diff(self, difflist):",
            "",
            "        if not isinstance(difflist, list):",
            "            difflist = [difflist]",
            "",
            "        ret = []",
            "        for diff in difflist:",
            "            if 'dst_binary' in diff:",
            "                ret.append(u\"diff skipped: destination file appears to be binary\\n\")",
            "            if 'src_binary' in diff:",
            "                ret.append(u\"diff skipped: source file appears to be binary\\n\")",
            "            if 'dst_larger' in diff:",
            "                ret.append(u\"diff skipped: destination file size is greater than %d\\n\" % diff['dst_larger'])",
            "            if 'src_larger' in diff:",
            "                ret.append(u\"diff skipped: source file size is greater than %d\\n\" % diff['src_larger'])",
            "            if 'before' in diff and 'after' in diff:",
            "                # format complex structures into 'files'",
            "                for x in ['before', 'after']:",
            "                    if isinstance(diff[x], MutableMapping):",
            "                        diff[x] = self._serialize_diff(diff[x])",
            "                    elif diff[x] is None:",
            "                        diff[x] = ''",
            "                if 'before_header' in diff:",
            "                    before_header = u\"before: %s\" % diff['before_header']",
            "                else:",
            "                    before_header = u'before'",
            "                if 'after_header' in diff:",
            "                    after_header = u\"after: %s\" % diff['after_header']",
            "                else:",
            "                    after_header = u'after'",
            "                before_lines = diff['before'].splitlines(True)",
            "                after_lines = diff['after'].splitlines(True)",
            "                if before_lines and not before_lines[-1].endswith(u'\\n'):",
            "                    before_lines[-1] += u'\\n\\\\ No newline at end of file\\n'",
            "                if after_lines and not after_lines[-1].endswith('\\n'):",
            "                    after_lines[-1] += u'\\n\\\\ No newline at end of file\\n'",
            "                differ = difflib.unified_diff(before_lines,",
            "                                              after_lines,",
            "                                              fromfile=before_header,",
            "                                              tofile=after_header,",
            "                                              fromfiledate=u'',",
            "                                              tofiledate=u'',",
            "                                              n=C.DIFF_CONTEXT)",
            "                difflines = list(differ)",
            "                has_diff = False",
            "                for line in difflines:",
            "                    has_diff = True",
            "                    if line.startswith(u'+'):",
            "                        line = stringc(line, C.COLOR_DIFF_ADD)",
            "                    elif line.startswith(u'-'):",
            "                        line = stringc(line, C.COLOR_DIFF_REMOVE)",
            "                    elif line.startswith(u'@@'):",
            "                        line = stringc(line, C.COLOR_DIFF_LINES)",
            "                    ret.append(line)",
            "                if has_diff:",
            "                    ret.append('\\n')",
            "            if 'prepared' in diff:",
            "                ret.append(diff['prepared'])",
            "        return u''.join(ret)",
            "",
            "    def _get_item_label(self, result):",
            "        ''' retrieves the value to be displayed as a label for an item entry from a result object'''",
            "        if result.get('_ansible_no_log', False):",
            "            item = \"(censored due to no_log)\"",
            "        else:",
            "            item = result.get('_ansible_item_label', result.get('item'))",
            "        return item",
            "",
            "    def _process_items(self, result):",
            "        # just remove them as now they get handled by individual callbacks",
            "        del result._result['results']",
            "",
            "    def _clean_results(self, result, task_name):",
            "        ''' removes data from results for display '''",
            "",
            "        # mostly controls that debug only outputs what it was meant to",
            "        if task_name in C._ACTION_DEBUG:",
            "            if 'msg' in result:",
            "                # msg should be alone",
            "                for key in list(result.keys()):",
            "                    if key not in _DEBUG_ALLOWED_KEYS and not key.startswith('_'):",
            "                        result.pop(key)",
            "            else:",
            "                # 'var' value as field, so eliminate others and what is left should be varname",
            "                for hidme in self._hide_in_debug:",
            "                    result.pop(hidme, None)",
            "",
            "    def _print_task_path(self, task, color=C.COLOR_DEBUG):",
            "        path = task.get_path()",
            "        if path:",
            "            self._display.display(u\"task path: %s\" % path, color=color)",
            "",
            "    def set_play_context(self, play_context):",
            "        pass",
            "",
            "    def on_any(self, *args, **kwargs):",
            "        pass",
            "",
            "    def runner_on_failed(self, host, res, ignore_errors=False):",
            "        pass",
            "",
            "    def runner_on_ok(self, host, res):",
            "        pass",
            "",
            "    def runner_on_skipped(self, host, item=None):",
            "        pass",
            "",
            "    def runner_on_unreachable(self, host, res):",
            "        pass",
            "",
            "    def runner_on_no_hosts(self):",
            "        pass",
            "",
            "    def runner_on_async_poll(self, host, res, jid, clock):",
            "        pass",
            "",
            "    def runner_on_async_ok(self, host, res, jid):",
            "        pass",
            "",
            "    def runner_on_async_failed(self, host, res, jid):",
            "        pass",
            "",
            "    def playbook_on_start(self):",
            "        pass",
            "",
            "    def playbook_on_notify(self, host, handler):",
            "        pass",
            "",
            "    def playbook_on_no_hosts_matched(self):",
            "        pass",
            "",
            "    def playbook_on_no_hosts_remaining(self):",
            "        pass",
            "",
            "    def playbook_on_task_start(self, name, is_conditional):",
            "        pass",
            "",
            "    def playbook_on_vars_prompt(self, varname, private=True, prompt=None, encrypt=None, confirm=False, salt_size=None, salt=None, default=None, unsafe=None):",
            "        pass",
            "",
            "    def playbook_on_setup(self):",
            "        pass",
            "",
            "    def playbook_on_import_for_host(self, host, imported_file):",
            "        pass",
            "",
            "    def playbook_on_not_import_for_host(self, host, missing_file):",
            "        pass",
            "",
            "    def playbook_on_play_start(self, name):",
            "        pass",
            "",
            "    def playbook_on_stats(self, stats):",
            "        pass",
            "",
            "    def on_file_diff(self, host, diff):",
            "        pass",
            "",
            "    # V2 METHODS, by default they call v1 counterparts if possible",
            "    def v2_on_any(self, *args, **kwargs):",
            "        self.on_any(args, kwargs)",
            "",
            "    def v2_runner_on_failed(self, result, ignore_errors=False):",
            "        host = result._host.get_name()",
            "        self.runner_on_failed(host, result._result, ignore_errors)",
            "",
            "    def v2_runner_on_ok(self, result):",
            "        host = result._host.get_name()",
            "        self.runner_on_ok(host, result._result)",
            "",
            "    def v2_runner_on_skipped(self, result):",
            "        if C.DISPLAY_SKIPPED_HOSTS:",
            "            host = result._host.get_name()",
            "            self.runner_on_skipped(host, self._get_item_label(getattr(result._result, 'results', {})))",
            "",
            "    def v2_runner_on_unreachable(self, result):",
            "        host = result._host.get_name()",
            "        self.runner_on_unreachable(host, result._result)",
            "",
            "    def v2_runner_on_async_poll(self, result):",
            "        host = result._host.get_name()",
            "        jid = result._result.get('ansible_job_id')",
            "        # FIXME, get real clock",
            "        clock = 0",
            "        self.runner_on_async_poll(host, result._result, jid, clock)",
            "",
            "    def v2_runner_on_async_ok(self, result):",
            "        host = result._host.get_name()",
            "        jid = result._result.get('ansible_job_id')",
            "        self.runner_on_async_ok(host, result._result, jid)",
            "",
            "    def v2_runner_on_async_failed(self, result):",
            "        host = result._host.get_name()",
            "        # Attempt to get the async job ID. If the job does not finish before the",
            "        # async timeout value, the ID may be within the unparsed 'async_result' dict.",
            "        jid = result._result.get('ansible_job_id')",
            "        if not jid and 'async_result' in result._result:",
            "            jid = result._result['async_result'].get('ansible_job_id')",
            "        self.runner_on_async_failed(host, result._result, jid)",
            "",
            "    def v2_playbook_on_start(self, playbook):",
            "        self.playbook_on_start()",
            "",
            "    def v2_playbook_on_notify(self, handler, host):",
            "        self.playbook_on_notify(host, handler)",
            "",
            "    def v2_playbook_on_no_hosts_matched(self):",
            "        self.playbook_on_no_hosts_matched()",
            "",
            "    def v2_playbook_on_no_hosts_remaining(self):",
            "        self.playbook_on_no_hosts_remaining()",
            "",
            "    def v2_playbook_on_task_start(self, task, is_conditional):",
            "        self.playbook_on_task_start(task.name, is_conditional)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_cleanup_task_start(self, task):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_playbook_on_handler_task_start(self, task):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_playbook_on_vars_prompt(self, varname, private=True, prompt=None, encrypt=None, confirm=False, salt_size=None, salt=None, default=None, unsafe=None):",
            "        self.playbook_on_vars_prompt(varname, private, prompt, encrypt, confirm, salt_size, salt, default, unsafe)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_import_for_host(self, result, imported_file):",
            "        host = result._host.get_name()",
            "        self.playbook_on_import_for_host(host, imported_file)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_not_import_for_host(self, result, missing_file):",
            "        host = result._host.get_name()",
            "        self.playbook_on_not_import_for_host(host, missing_file)",
            "",
            "    def v2_playbook_on_play_start(self, play):",
            "        self.playbook_on_play_start(play.name)",
            "",
            "    def v2_playbook_on_stats(self, stats):",
            "        self.playbook_on_stats(stats)",
            "",
            "    def v2_on_file_diff(self, result):",
            "        if 'diff' in result._result:",
            "            host = result._host.get_name()",
            "            self.on_file_diff(host, result._result['diff'])",
            "",
            "    def v2_playbook_on_include(self, included_file):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_runner_item_on_ok(self, result):",
            "        pass",
            "",
            "    def v2_runner_item_on_failed(self, result):",
            "        pass",
            "",
            "    def v2_runner_item_on_skipped(self, result):",
            "        pass",
            "",
            "    def v2_runner_retry(self, result):",
            "        pass",
            "",
            "    def v2_runner_on_start(self, host, task):",
            "        \"\"\"Event used when host begins execution of a task",
            "",
            "        .. versionadded:: 2.8",
            "        \"\"\"",
            "        pass"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import difflib",
            "import json",
            "import re",
            "import sys",
            "import textwrap",
            "",
            "from collections import OrderedDict",
            "from collections.abc import MutableMapping",
            "from copy import deepcopy",
            "",
            "from ansible import constants as C",
            "from ansible.module_utils.common.text.converters import to_text",
            "from ansible.module_utils.six import text_type",
            "from ansible.parsing.ajson import AnsibleJSONEncoder",
            "from ansible.parsing.yaml.dumper import AnsibleDumper",
            "from ansible.parsing.yaml.objects import AnsibleUnicode",
            "from ansible.plugins import AnsiblePlugin",
            "from ansible.utils.color import stringc",
            "from ansible.utils.display import Display",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeText, NativeJinjaUnsafeText, _is_unsafe",
            "from ansible.vars.clean import strip_internal_keys, module_response_deepcopy",
            "",
            "import yaml",
            "",
            "global_display = Display()",
            "",
            "",
            "__all__ = [\"CallbackBase\"]",
            "",
            "",
            "_DEBUG_ALLOWED_KEYS = frozenset(('msg', 'exception', 'warnings', 'deprecations'))",
            "_YAML_TEXT_TYPES = (text_type, AnsibleUnicode, AnsibleUnsafeText, NativeJinjaUnsafeText)",
            "# Characters that libyaml/pyyaml consider breaks",
            "_YAML_BREAK_CHARS = '\\n\\x85\\u2028\\u2029'  # NL, NEL, LS, PS",
            "# regex representation of libyaml/pyyaml of a space followed by a break character",
            "_SPACE_BREAK_RE = re.compile(fr' +([{_YAML_BREAK_CHARS}])')",
            "",
            "",
            "class _AnsibleCallbackDumper(AnsibleDumper):",
            "    def __init__(self, lossy=False):",
            "        self._lossy = lossy",
            "",
            "    def __call__(self, *args, **kwargs):",
            "        # pyyaml expects that we are passing an object that can be instantiated, but to",
            "        # smuggle the ``lossy`` configuration, we do that in ``__init__`` and then",
            "        # define this ``__call__`` that will mimic the ability for pyyaml to instantiate class",
            "        super().__init__(*args, **kwargs)",
            "        return self",
            "",
            "",
            "def _should_use_block(scalar):",
            "    \"\"\"Returns true if string should be in block format based on the existence of various newline separators\"\"\"",
            "    # This method of searching is faster than using a regex",
            "    for ch in _YAML_BREAK_CHARS:",
            "        if ch in scalar:",
            "            return True",
            "    return False",
            "",
            "",
            "class _SpecialCharacterTranslator:",
            "    def __getitem__(self, ch):",
            "        # \"special character\" logic from pyyaml yaml.emitter.Emitter.analyze_scalar, translated to decimal",
            "        # for perf w/ str.translate",
            "        if (ch == 10 or",
            "            32 <= ch <= 126 or",
            "            ch == 133 or",
            "            160 <= ch <= 55295 or",
            "            57344 <= ch <= 65533 or",
            "            65536 <= ch < 1114111)\\",
            "                and ch != 65279:",
            "            return ch",
            "        return None",
            "",
            "",
            "def _filter_yaml_special(scalar):",
            "    \"\"\"Filter a string removing any character that libyaml/pyyaml declare as special\"\"\"",
            "    return scalar.translate(_SpecialCharacterTranslator())",
            "",
            "",
            "def _munge_data_for_lossy_yaml(scalar):",
            "    \"\"\"Modify a string so that analyze_scalar in libyaml/pyyaml will allow block formatting\"\"\"",
            "    # we care more about readability than accuracy, so...",
            "    # ...libyaml/pyyaml does not permit trailing spaces for block scalars",
            "    scalar = scalar.rstrip()",
            "    # ...libyaml/pyyaml does not permit tabs for block scalars",
            "    scalar = scalar.expandtabs()",
            "    # ...libyaml/pyyaml only permits special characters for double quoted scalars",
            "    scalar = _filter_yaml_special(scalar)",
            "    # ...libyaml/pyyaml only permits spaces followed by breaks for double quoted scalars",
            "    return _SPACE_BREAK_RE.sub(r'\\1', scalar)",
            "",
            "",
            "def _pretty_represent_str(self, data):",
            "    \"\"\"Uses block style for multi-line strings\"\"\"",
            "    if _is_unsafe(data):",
            "        data = data._strip_unsafe()",
            "    data = text_type(data)",
            "    if _should_use_block(data):",
            "        style = '|'",
            "        if self._lossy:",
            "            data = _munge_data_for_lossy_yaml(data)",
            "    else:",
            "        style = self.default_style",
            "",
            "    node = yaml.representer.ScalarNode('tag:yaml.org,2002:str', data, style=style)",
            "    if self.alias_key is not None:",
            "        self.represented_objects[self.alias_key] = node",
            "    return node",
            "",
            "",
            "for data_type in _YAML_TEXT_TYPES:",
            "    _AnsibleCallbackDumper.add_representer(",
            "        data_type,",
            "        _pretty_represent_str",
            "    )",
            "",
            "",
            "class CallbackBase(AnsiblePlugin):",
            "",
            "    '''",
            "    This is a base ansible callback class that does nothing. New callbacks should",
            "    use this class as a base and override any callback methods they wish to execute",
            "    custom actions.",
            "    '''",
            "",
            "    def __init__(self, display=None, options=None):",
            "        if display:",
            "            self._display = display",
            "        else:",
            "            self._display = global_display",
            "",
            "        if self._display.verbosity >= 4:",
            "            name = getattr(self, 'CALLBACK_NAME', 'unnamed')",
            "            ctype = getattr(self, 'CALLBACK_TYPE', 'old')",
            "            version = getattr(self, 'CALLBACK_VERSION', '1.0')",
            "            self._display.vvvv('Loading callback plugin %s of type %s, v%s from %s' % (name, ctype, version, sys.modules[self.__module__].__file__))",
            "",
            "        self.disabled = False",
            "        self.wants_implicit_tasks = False",
            "",
            "        self._plugin_options = {}",
            "        if options is not None:",
            "            self.set_options(options)",
            "",
            "        self._hide_in_debug = ('changed', 'failed', 'skipped', 'invocation', 'skip_reason')",
            "",
            "    # helper for callbacks, so they don't all have to include deepcopy",
            "    _copy_result = deepcopy",
            "",
            "    def set_option(self, k, v):",
            "        self._plugin_options[k] = v",
            "",
            "    def get_option(self, k):",
            "        return self._plugin_options[k]",
            "",
            "    def set_options(self, task_keys=None, var_options=None, direct=None):",
            "        ''' This is different than the normal plugin method as callbacks get called early and really don't accept keywords.",
            "            Also _options was already taken for CLI args and callbacks use _plugin_options instead.",
            "        '''",
            "",
            "        # load from config",
            "        self._plugin_options = C.config.get_plugin_options(self.plugin_type, self._load_name, keys=task_keys, variables=var_options, direct=direct)",
            "",
            "    @staticmethod",
            "    def host_label(result):",
            "        \"\"\"Return label for the hostname (& delegated hostname) of a task",
            "        result.",
            "        \"\"\"",
            "        label = \"%s\" % result._host.get_name()",
            "        if result._task.delegate_to and result._task.delegate_to != result._host.get_name():",
            "            # show delegated host",
            "            label += \" -> %s\" % result._task.delegate_to",
            "            # in case we have 'extra resolution'",
            "            ahost = result._result.get('_ansible_delegated_vars', {}).get('ansible_host', result._task.delegate_to)",
            "            if result._task.delegate_to != ahost:",
            "                label += \"(%s)\" % ahost",
            "        return label",
            "",
            "    def _run_is_verbose(self, result, verbosity=0):",
            "        return ((self._display.verbosity > verbosity or result._result.get('_ansible_verbose_always', False) is True)",
            "                and result._result.get('_ansible_verbose_override', False) is False)",
            "",
            "    def _dump_results(self, result, indent=None, sort_keys=True, keep_invocation=False, serialize=True):",
            "        try:",
            "            result_format = self.get_option('result_format')",
            "        except KeyError:",
            "            # Callback does not declare result_format nor extend result_format_callback",
            "            result_format = 'json'",
            "",
            "        try:",
            "            pretty_results = self.get_option('pretty_results')",
            "        except KeyError:",
            "            # Callback does not declare pretty_results nor extend result_format_callback",
            "            pretty_results = None",
            "",
            "        indent_conditions = (",
            "            result.get('_ansible_verbose_always'),",
            "            pretty_results is None and result_format != 'json',",
            "            pretty_results is True,",
            "            self._display.verbosity > 2,",
            "        )",
            "",
            "        if not indent and any(indent_conditions):",
            "            indent = 4",
            "        if pretty_results is False:",
            "            # pretty_results=False overrides any specified indentation",
            "            indent = None",
            "",
            "        # All result keys stating with _ansible_ are internal, so remove them from the result before we output anything.",
            "        abridged_result = strip_internal_keys(module_response_deepcopy(result))",
            "",
            "        # remove invocation unless specifically wanting it",
            "        if not keep_invocation and self._display.verbosity < 3 and 'invocation' in result:",
            "            del abridged_result['invocation']",
            "",
            "        # remove diff information from screen output",
            "        if self._display.verbosity < 3 and 'diff' in result:",
            "            del abridged_result['diff']",
            "",
            "        # remove exception from screen output",
            "        if 'exception' in abridged_result:",
            "            del abridged_result['exception']",
            "",
            "        if not serialize:",
            "            # Just return ``abridged_result`` without going through serialization",
            "            # to permit callbacks to take advantage of ``_dump_results``",
            "            # that want to further modify the result, or use custom serialization",
            "            return abridged_result",
            "",
            "        if result_format == 'json':",
            "            try:",
            "                return json.dumps(abridged_result, cls=AnsibleJSONEncoder, indent=indent, ensure_ascii=False, sort_keys=sort_keys)",
            "            except TypeError:",
            "                # Python3 bug: throws an exception when keys are non-homogenous types:",
            "                # https://bugs.python.org/issue25457",
            "                # sort into an OrderedDict and then json.dumps() that instead",
            "                if not OrderedDict:",
            "                    raise",
            "                return json.dumps(OrderedDict(sorted(abridged_result.items(), key=to_text)),",
            "                                  cls=AnsibleJSONEncoder, indent=indent,",
            "                                  ensure_ascii=False, sort_keys=False)",
            "        elif result_format == 'yaml':",
            "            # None is a sentinel in this case that indicates default behavior",
            "            # default behavior for yaml is to prettify results",
            "            lossy = pretty_results in (None, True)",
            "            if lossy:",
            "                # if we already have stdout, we don't need stdout_lines",
            "                if 'stdout' in abridged_result and 'stdout_lines' in abridged_result:",
            "                    abridged_result['stdout_lines'] = '<omitted>'",
            "",
            "                # if we already have stderr, we don't need stderr_lines",
            "                if 'stderr' in abridged_result and 'stderr_lines' in abridged_result:",
            "                    abridged_result['stderr_lines'] = '<omitted>'",
            "",
            "            return '\\n%s' % textwrap.indent(",
            "                yaml.dump(",
            "                    abridged_result,",
            "                    allow_unicode=True,",
            "                    Dumper=_AnsibleCallbackDumper(lossy=lossy),",
            "                    default_flow_style=False,",
            "                    indent=indent,",
            "                    # sort_keys=sort_keys  # This requires PyYAML>=5.1",
            "                ),",
            "                ' ' * (indent or 4)",
            "            )",
            "",
            "    def _handle_warnings(self, res):",
            "        ''' display warnings, if enabled and any exist in the result '''",
            "        if C.ACTION_WARNINGS:",
            "            if 'warnings' in res and res['warnings']:",
            "                for warning in res['warnings']:",
            "                    self._display.warning(warning)",
            "                del res['warnings']",
            "            if 'deprecations' in res and res['deprecations']:",
            "                for warning in res['deprecations']:",
            "                    self._display.deprecated(**warning)",
            "                del res['deprecations']",
            "",
            "    def _handle_exception(self, result, use_stderr=False):",
            "",
            "        if 'exception' in result:",
            "            msg = \"An exception occurred during task execution. \"",
            "            exception_str = to_text(result['exception'])",
            "            if self._display.verbosity < 3:",
            "                # extract just the actual error message from the exception text",
            "                error = exception_str.strip().split('\\n')[-1]",
            "                msg += \"To see the full traceback, use -vvv. The error was: %s\" % error",
            "            else:",
            "                msg = \"The full traceback is:\\n\" + exception_str",
            "                del result['exception']",
            "",
            "            self._display.display(msg, color=C.COLOR_ERROR, stderr=use_stderr)",
            "",
            "    def _serialize_diff(self, diff):",
            "        try:",
            "            result_format = self.get_option('result_format')",
            "        except KeyError:",
            "            # Callback does not declare result_format nor extend result_format_callback",
            "            result_format = 'json'",
            "",
            "        try:",
            "            pretty_results = self.get_option('pretty_results')",
            "        except KeyError:",
            "            # Callback does not declare pretty_results nor extend result_format_callback",
            "            pretty_results = None",
            "",
            "        if result_format == 'json':",
            "            return json.dumps(diff, sort_keys=True, indent=4, separators=(u',', u': ')) + u'\\n'",
            "        elif result_format == 'yaml':",
            "            # None is a sentinel in this case that indicates default behavior",
            "            # default behavior for yaml is to prettify results",
            "            lossy = pretty_results in (None, True)",
            "            return '%s\\n' % textwrap.indent(",
            "                yaml.dump(",
            "                    diff,",
            "                    allow_unicode=True,",
            "                    Dumper=_AnsibleCallbackDumper(lossy=lossy),",
            "                    default_flow_style=False,",
            "                    indent=4,",
            "                    # sort_keys=sort_keys  # This requires PyYAML>=5.1",
            "                ),",
            "                '    '",
            "            )",
            "",
            "    def _get_diff(self, difflist):",
            "",
            "        if not isinstance(difflist, list):",
            "            difflist = [difflist]",
            "",
            "        ret = []",
            "        for diff in difflist:",
            "            if 'dst_binary' in diff:",
            "                ret.append(u\"diff skipped: destination file appears to be binary\\n\")",
            "            if 'src_binary' in diff:",
            "                ret.append(u\"diff skipped: source file appears to be binary\\n\")",
            "            if 'dst_larger' in diff:",
            "                ret.append(u\"diff skipped: destination file size is greater than %d\\n\" % diff['dst_larger'])",
            "            if 'src_larger' in diff:",
            "                ret.append(u\"diff skipped: source file size is greater than %d\\n\" % diff['src_larger'])",
            "            if 'before' in diff and 'after' in diff:",
            "                # format complex structures into 'files'",
            "                for x in ['before', 'after']:",
            "                    if isinstance(diff[x], MutableMapping):",
            "                        diff[x] = self._serialize_diff(diff[x])",
            "                    elif diff[x] is None:",
            "                        diff[x] = ''",
            "                if 'before_header' in diff:",
            "                    before_header = u\"before: %s\" % diff['before_header']",
            "                else:",
            "                    before_header = u'before'",
            "                if 'after_header' in diff:",
            "                    after_header = u\"after: %s\" % diff['after_header']",
            "                else:",
            "                    after_header = u'after'",
            "                before_lines = diff['before'].splitlines(True)",
            "                after_lines = diff['after'].splitlines(True)",
            "                if before_lines and not before_lines[-1].endswith(u'\\n'):",
            "                    before_lines[-1] += u'\\n\\\\ No newline at end of file\\n'",
            "                if after_lines and not after_lines[-1].endswith('\\n'):",
            "                    after_lines[-1] += u'\\n\\\\ No newline at end of file\\n'",
            "                differ = difflib.unified_diff(before_lines,",
            "                                              after_lines,",
            "                                              fromfile=before_header,",
            "                                              tofile=after_header,",
            "                                              fromfiledate=u'',",
            "                                              tofiledate=u'',",
            "                                              n=C.DIFF_CONTEXT)",
            "                difflines = list(differ)",
            "                has_diff = False",
            "                for line in difflines:",
            "                    has_diff = True",
            "                    if line.startswith(u'+'):",
            "                        line = stringc(line, C.COLOR_DIFF_ADD)",
            "                    elif line.startswith(u'-'):",
            "                        line = stringc(line, C.COLOR_DIFF_REMOVE)",
            "                    elif line.startswith(u'@@'):",
            "                        line = stringc(line, C.COLOR_DIFF_LINES)",
            "                    ret.append(line)",
            "                if has_diff:",
            "                    ret.append('\\n')",
            "            if 'prepared' in diff:",
            "                ret.append(diff['prepared'])",
            "        return u''.join(ret)",
            "",
            "    def _get_item_label(self, result):",
            "        ''' retrieves the value to be displayed as a label for an item entry from a result object'''",
            "        if result.get('_ansible_no_log', False):",
            "            item = \"(censored due to no_log)\"",
            "        else:",
            "            item = result.get('_ansible_item_label', result.get('item'))",
            "        return item",
            "",
            "    def _process_items(self, result):",
            "        # just remove them as now they get handled by individual callbacks",
            "        del result._result['results']",
            "",
            "    def _clean_results(self, result, task_name):",
            "        ''' removes data from results for display '''",
            "",
            "        # mostly controls that debug only outputs what it was meant to",
            "        if task_name in C._ACTION_DEBUG:",
            "            if 'msg' in result:",
            "                # msg should be alone",
            "                for key in list(result.keys()):",
            "                    if key not in _DEBUG_ALLOWED_KEYS and not key.startswith('_'):",
            "                        result.pop(key)",
            "            else:",
            "                # 'var' value as field, so eliminate others and what is left should be varname",
            "                for hidme in self._hide_in_debug:",
            "                    result.pop(hidme, None)",
            "",
            "    def _print_task_path(self, task, color=C.COLOR_DEBUG):",
            "        path = task.get_path()",
            "        if path:",
            "            self._display.display(u\"task path: %s\" % path, color=color)",
            "",
            "    def set_play_context(self, play_context):",
            "        pass",
            "",
            "    def on_any(self, *args, **kwargs):",
            "        pass",
            "",
            "    def runner_on_failed(self, host, res, ignore_errors=False):",
            "        pass",
            "",
            "    def runner_on_ok(self, host, res):",
            "        pass",
            "",
            "    def runner_on_skipped(self, host, item=None):",
            "        pass",
            "",
            "    def runner_on_unreachable(self, host, res):",
            "        pass",
            "",
            "    def runner_on_no_hosts(self):",
            "        pass",
            "",
            "    def runner_on_async_poll(self, host, res, jid, clock):",
            "        pass",
            "",
            "    def runner_on_async_ok(self, host, res, jid):",
            "        pass",
            "",
            "    def runner_on_async_failed(self, host, res, jid):",
            "        pass",
            "",
            "    def playbook_on_start(self):",
            "        pass",
            "",
            "    def playbook_on_notify(self, host, handler):",
            "        pass",
            "",
            "    def playbook_on_no_hosts_matched(self):",
            "        pass",
            "",
            "    def playbook_on_no_hosts_remaining(self):",
            "        pass",
            "",
            "    def playbook_on_task_start(self, name, is_conditional):",
            "        pass",
            "",
            "    def playbook_on_vars_prompt(self, varname, private=True, prompt=None, encrypt=None, confirm=False, salt_size=None, salt=None, default=None, unsafe=None):",
            "        pass",
            "",
            "    def playbook_on_setup(self):",
            "        pass",
            "",
            "    def playbook_on_import_for_host(self, host, imported_file):",
            "        pass",
            "",
            "    def playbook_on_not_import_for_host(self, host, missing_file):",
            "        pass",
            "",
            "    def playbook_on_play_start(self, name):",
            "        pass",
            "",
            "    def playbook_on_stats(self, stats):",
            "        pass",
            "",
            "    def on_file_diff(self, host, diff):",
            "        pass",
            "",
            "    # V2 METHODS, by default they call v1 counterparts if possible",
            "    def v2_on_any(self, *args, **kwargs):",
            "        self.on_any(args, kwargs)",
            "",
            "    def v2_runner_on_failed(self, result, ignore_errors=False):",
            "        host = result._host.get_name()",
            "        self.runner_on_failed(host, result._result, ignore_errors)",
            "",
            "    def v2_runner_on_ok(self, result):",
            "        host = result._host.get_name()",
            "        self.runner_on_ok(host, result._result)",
            "",
            "    def v2_runner_on_skipped(self, result):",
            "        if C.DISPLAY_SKIPPED_HOSTS:",
            "            host = result._host.get_name()",
            "            self.runner_on_skipped(host, self._get_item_label(getattr(result._result, 'results', {})))",
            "",
            "    def v2_runner_on_unreachable(self, result):",
            "        host = result._host.get_name()",
            "        self.runner_on_unreachable(host, result._result)",
            "",
            "    def v2_runner_on_async_poll(self, result):",
            "        host = result._host.get_name()",
            "        jid = result._result.get('ansible_job_id')",
            "        # FIXME, get real clock",
            "        clock = 0",
            "        self.runner_on_async_poll(host, result._result, jid, clock)",
            "",
            "    def v2_runner_on_async_ok(self, result):",
            "        host = result._host.get_name()",
            "        jid = result._result.get('ansible_job_id')",
            "        self.runner_on_async_ok(host, result._result, jid)",
            "",
            "    def v2_runner_on_async_failed(self, result):",
            "        host = result._host.get_name()",
            "        # Attempt to get the async job ID. If the job does not finish before the",
            "        # async timeout value, the ID may be within the unparsed 'async_result' dict.",
            "        jid = result._result.get('ansible_job_id')",
            "        if not jid and 'async_result' in result._result:",
            "            jid = result._result['async_result'].get('ansible_job_id')",
            "        self.runner_on_async_failed(host, result._result, jid)",
            "",
            "    def v2_playbook_on_start(self, playbook):",
            "        self.playbook_on_start()",
            "",
            "    def v2_playbook_on_notify(self, handler, host):",
            "        self.playbook_on_notify(host, handler)",
            "",
            "    def v2_playbook_on_no_hosts_matched(self):",
            "        self.playbook_on_no_hosts_matched()",
            "",
            "    def v2_playbook_on_no_hosts_remaining(self):",
            "        self.playbook_on_no_hosts_remaining()",
            "",
            "    def v2_playbook_on_task_start(self, task, is_conditional):",
            "        self.playbook_on_task_start(task.name, is_conditional)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_cleanup_task_start(self, task):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_playbook_on_handler_task_start(self, task):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_playbook_on_vars_prompt(self, varname, private=True, prompt=None, encrypt=None, confirm=False, salt_size=None, salt=None, default=None, unsafe=None):",
            "        self.playbook_on_vars_prompt(varname, private, prompt, encrypt, confirm, salt_size, salt, default, unsafe)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_import_for_host(self, result, imported_file):",
            "        host = result._host.get_name()",
            "        self.playbook_on_import_for_host(host, imported_file)",
            "",
            "    # FIXME: not called",
            "    def v2_playbook_on_not_import_for_host(self, result, missing_file):",
            "        host = result._host.get_name()",
            "        self.playbook_on_not_import_for_host(host, missing_file)",
            "",
            "    def v2_playbook_on_play_start(self, play):",
            "        self.playbook_on_play_start(play.name)",
            "",
            "    def v2_playbook_on_stats(self, stats):",
            "        self.playbook_on_stats(stats)",
            "",
            "    def v2_on_file_diff(self, result):",
            "        if 'diff' in result._result:",
            "            host = result._host.get_name()",
            "            self.on_file_diff(host, result._result['diff'])",
            "",
            "    def v2_playbook_on_include(self, included_file):",
            "        pass  # no v1 correspondence",
            "",
            "    def v2_runner_item_on_ok(self, result):",
            "        pass",
            "",
            "    def v2_runner_item_on_failed(self, result):",
            "        pass",
            "",
            "    def v2_runner_item_on_skipped(self, result):",
            "        pass",
            "",
            "    def v2_runner_retry(self, result):",
            "        pass",
            "",
            "    def v2_runner_on_start(self, host, task):",
            "        \"\"\"Event used when host begins execution of a task",
            "",
            "        .. versionadded:: 2.8",
            "        \"\"\"",
            "        pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "41": []
        },
        "addLocation": []
    },
    "lib/ansible/plugins/filter/core.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " from ansible.utils.encrypt import passlib_or_crypt, PASSLIB_AVAILABLE"
            },
            "1": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " from ansible.utils.hashing import md5s, checksum_s"
            },
            "2": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " from ansible.utils.unicode import unicode_wrap"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+from ansible.utils.unsafe_proxy import _is_unsafe"
            },
            "4": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 41,
                "PatchRowcode": " from ansible.utils.vars import merge_hash"
            },
            "5": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " display = Display()"
            },
            "7": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "         # The ``text_type`` call here strips any custom"
            },
            "8": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "         # string wrapper class, so that CSafeLoader can"
            },
            "9": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": 218,
                "PatchRowcode": "         # read the data"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+        if _is_unsafe(data):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+            data = data._strip_unsafe()"
            },
            "12": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": 221,
                "PatchRowcode": "         return yaml_load(text_type(to_text(data, errors='surrogate_or_strict')))"
            },
            "13": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": 222,
                "PatchRowcode": "     return data"
            },
            "14": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": 223,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": 227,
                "PatchRowcode": "         # The ``text_type`` call here strips any custom"
            },
            "16": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 228,
                "PatchRowcode": "         # string wrapper class, so that CSafeLoader can"
            },
            "17": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "         # read the data"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+        if _is_unsafe(data):"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+            data = data._strip_unsafe()"
            },
            "20": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "         return yaml_load_all(text_type(to_text(data, errors='surrogate_or_strict')))"
            },
            "21": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 233,
                "PatchRowcode": "     return data"
            },
            "22": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 234,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# (c) 2012, Jeroen Hoekx <jeroen@hoekx.be>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import base64",
            "import glob",
            "import hashlib",
            "import json",
            "import ntpath",
            "import os.path",
            "import re",
            "import shlex",
            "import sys",
            "import time",
            "import uuid",
            "import yaml",
            "import datetime",
            "",
            "from collections.abc import Mapping",
            "from functools import partial",
            "from random import Random, SystemRandom, shuffle",
            "",
            "from jinja2.filters import pass_environment",
            "",
            "from ansible.errors import AnsibleError, AnsibleFilterError, AnsibleFilterTypeError",
            "from ansible.module_utils.six import string_types, integer_types, reraise, text_type",
            "from ansible.module_utils._text import to_bytes, to_native, to_text",
            "from ansible.module_utils.common.collections import is_sequence",
            "from ansible.module_utils.common.yaml import yaml_load, yaml_load_all",
            "from ansible.parsing.ajson import AnsibleJSONEncoder",
            "from ansible.parsing.yaml.dumper import AnsibleDumper",
            "from ansible.template import recursive_check_defined",
            "from ansible.utils.display import Display",
            "from ansible.utils.encrypt import passlib_or_crypt, PASSLIB_AVAILABLE",
            "from ansible.utils.hashing import md5s, checksum_s",
            "from ansible.utils.unicode import unicode_wrap",
            "from ansible.utils.vars import merge_hash",
            "",
            "display = Display()",
            "",
            "UUID_NAMESPACE_ANSIBLE = uuid.UUID('361E6D51-FAEC-444A-9079-341386DA8E2E')",
            "",
            "",
            "def to_yaml(a, *args, **kw):",
            "    '''Make verbose, human readable yaml'''",
            "    default_flow_style = kw.pop('default_flow_style', None)",
            "    try:",
            "        transformed = yaml.dump(a, Dumper=AnsibleDumper, allow_unicode=True, default_flow_style=default_flow_style, **kw)",
            "    except Exception as e:",
            "        raise AnsibleFilterError(\"to_yaml - %s\" % to_native(e), orig_exc=e)",
            "    return to_text(transformed)",
            "",
            "",
            "def to_nice_yaml(a, indent=4, *args, **kw):",
            "    '''Make verbose, human readable yaml'''",
            "    try:",
            "        transformed = yaml.dump(a, Dumper=AnsibleDumper, indent=indent, allow_unicode=True, default_flow_style=False, **kw)",
            "    except Exception as e:",
            "        raise AnsibleFilterError(\"to_nice_yaml - %s\" % to_native(e), orig_exc=e)",
            "    return to_text(transformed)",
            "",
            "",
            "def to_json(a, *args, **kw):",
            "    ''' Convert the value to JSON '''",
            "",
            "    # defaults for filters",
            "    if 'vault_to_text' not in kw:",
            "        kw['vault_to_text'] = True",
            "    if 'preprocess_unsafe' not in kw:",
            "        kw['preprocess_unsafe'] = False",
            "",
            "    return json.dumps(a, cls=AnsibleJSONEncoder, *args, **kw)",
            "",
            "",
            "def to_nice_json(a, indent=4, sort_keys=True, *args, **kw):",
            "    '''Make verbose, human readable JSON'''",
            "    return to_json(a, indent=indent, sort_keys=sort_keys, separators=(',', ': '), *args, **kw)",
            "",
            "",
            "def to_bool(a):",
            "    ''' return a bool for the arg '''",
            "    if a is None or isinstance(a, bool):",
            "        return a",
            "    if isinstance(a, string_types):",
            "        a = a.lower()",
            "    if a in ('yes', 'on', '1', 'true', 1):",
            "        return True",
            "    return False",
            "",
            "",
            "def to_datetime(string, format=\"%Y-%m-%d %H:%M:%S\"):",
            "    return datetime.datetime.strptime(string, format)",
            "",
            "",
            "def strftime(string_format, second=None, utc=False):",
            "    ''' return a date string using string. See https://docs.python.org/3/library/time.html#time.strftime for format '''",
            "    if utc:",
            "        timefn = time.gmtime",
            "    else:",
            "        timefn = time.localtime",
            "    if second is not None:",
            "        try:",
            "            second = float(second)",
            "        except Exception:",
            "            raise AnsibleFilterError('Invalid value for epoch value (%s)' % second)",
            "    return time.strftime(string_format, timefn(second))",
            "",
            "",
            "def quote(a):",
            "    ''' return its argument quoted for shell usage '''",
            "    if a is None:",
            "        a = u''",
            "    return shlex.quote(to_text(a))",
            "",
            "",
            "def fileglob(pathname):",
            "    ''' return list of matched regular files for glob '''",
            "    return [g for g in glob.glob(pathname) if os.path.isfile(g)]",
            "",
            "",
            "def regex_replace(value='', pattern='', replacement='', ignorecase=False, multiline=False):",
            "    ''' Perform a `re.sub` returning a string '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    flags = 0",
            "    if ignorecase:",
            "        flags |= re.I",
            "    if multiline:",
            "        flags |= re.M",
            "    _re = re.compile(pattern, flags=flags)",
            "    return _re.sub(replacement, value)",
            "",
            "",
            "def regex_findall(value, regex, multiline=False, ignorecase=False):",
            "    ''' Perform re.findall and return the list of matches '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    flags = 0",
            "    if ignorecase:",
            "        flags |= re.I",
            "    if multiline:",
            "        flags |= re.M",
            "    return re.findall(regex, value, flags)",
            "",
            "",
            "def regex_search(value, regex, *args, **kwargs):",
            "    ''' Perform re.search and return the list of matches or a backref '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    groups = list()",
            "    for arg in args:",
            "        if arg.startswith('\\\\g'):",
            "            match = re.match(r'\\\\g<(\\S+)>', arg).group(1)",
            "            groups.append(match)",
            "        elif arg.startswith('\\\\'):",
            "            match = int(re.match(r'\\\\(\\d+)', arg).group(1))",
            "            groups.append(match)",
            "        else:",
            "            raise AnsibleFilterError('Unknown argument')",
            "",
            "    flags = 0",
            "    if kwargs.get('ignorecase'):",
            "        flags |= re.I",
            "    if kwargs.get('multiline'):",
            "        flags |= re.M",
            "",
            "    match = re.search(regex, value, flags)",
            "    if match:",
            "        if not groups:",
            "            return match.group()",
            "        else:",
            "            items = list()",
            "            for item in groups:",
            "                items.append(match.group(item))",
            "            return items",
            "",
            "",
            "def ternary(value, true_val, false_val, none_val=None):",
            "    '''  value ? true_val : false_val '''",
            "    if value is None and none_val is not None:",
            "        return none_val",
            "    elif bool(value):",
            "        return true_val",
            "    else:",
            "        return false_val",
            "",
            "",
            "def regex_escape(string, re_type='python'):",
            "    \"\"\"Escape all regular expressions special characters from STRING.\"\"\"",
            "    string = to_text(string, errors='surrogate_or_strict', nonstring='simplerepr')",
            "    if re_type == 'python':",
            "        return re.escape(string)",
            "    elif re_type == 'posix_basic':",
            "        # list of BRE special chars:",
            "        # https://en.wikibooks.org/wiki/Regular_Expressions/POSIX_Basic_Regular_Expressions",
            "        return regex_replace(string, r'([].[^$*\\\\])', r'\\\\\\1')",
            "    # TODO: implement posix_extended",
            "    # It's similar to, but different from python regex, which is similar to,",
            "    # but different from PCRE.  It's possible that re.escape would work here.",
            "    # https://remram44.github.io/regex-cheatsheet/regex.html#programs",
            "    elif re_type == 'posix_extended':",
            "        raise AnsibleFilterError('Regex type (%s) not yet implemented' % re_type)",
            "    else:",
            "        raise AnsibleFilterError('Invalid regex type (%s)' % re_type)",
            "",
            "",
            "def from_yaml(data):",
            "    if isinstance(data, string_types):",
            "        # The ``text_type`` call here strips any custom",
            "        # string wrapper class, so that CSafeLoader can",
            "        # read the data",
            "        return yaml_load(text_type(to_text(data, errors='surrogate_or_strict')))",
            "    return data",
            "",
            "",
            "def from_yaml_all(data):",
            "    if isinstance(data, string_types):",
            "        # The ``text_type`` call here strips any custom",
            "        # string wrapper class, so that CSafeLoader can",
            "        # read the data",
            "        return yaml_load_all(text_type(to_text(data, errors='surrogate_or_strict')))",
            "    return data",
            "",
            "",
            "@pass_environment",
            "def rand(environment, end, start=None, step=None, seed=None):",
            "    if seed is None:",
            "        r = SystemRandom()",
            "    else:",
            "        r = Random(seed)",
            "    if isinstance(end, integer_types):",
            "        if not start:",
            "            start = 0",
            "        if not step:",
            "            step = 1",
            "        return r.randrange(start, end, step)",
            "    elif hasattr(end, '__iter__'):",
            "        if start or step:",
            "            raise AnsibleFilterError('start and step can only be used with integer values')",
            "        return r.choice(end)",
            "    else:",
            "        raise AnsibleFilterError('random can only be used on sequences and integers')",
            "",
            "",
            "def randomize_list(mylist, seed=None):",
            "    try:",
            "        mylist = list(mylist)",
            "        if seed:",
            "            r = Random(seed)",
            "            r.shuffle(mylist)",
            "        else:",
            "            shuffle(mylist)",
            "    except Exception:",
            "        pass",
            "    return mylist",
            "",
            "",
            "def get_hash(data, hashtype='sha1'):",
            "    try:",
            "        h = hashlib.new(hashtype)",
            "    except Exception as e:",
            "        # hash is not supported?",
            "        raise AnsibleFilterError(e)",
            "",
            "    h.update(to_bytes(data, errors='surrogate_or_strict'))",
            "    return h.hexdigest()",
            "",
            "",
            "def get_encrypted_password(password, hashtype='sha512', salt=None, salt_size=None, rounds=None, ident=None):",
            "    passlib_mapping = {",
            "        'md5': 'md5_crypt',",
            "        'blowfish': 'bcrypt',",
            "        'sha256': 'sha256_crypt',",
            "        'sha512': 'sha512_crypt',",
            "    }",
            "",
            "    hashtype = passlib_mapping.get(hashtype, hashtype)",
            "",
            "    unknown_passlib_hashtype = False",
            "    if PASSLIB_AVAILABLE and hashtype not in passlib_mapping and hashtype not in passlib_mapping.values():",
            "        unknown_passlib_hashtype = True",
            "        display.deprecated(",
            "            f\"Checking for unsupported password_hash passlib hashtype '{hashtype}'. \"",
            "            \"This will be an error in the future as all supported hashtypes must be documented.\",",
            "            version='2.19'",
            "        )",
            "",
            "    try:",
            "        return passlib_or_crypt(password, hashtype, salt=salt, salt_size=salt_size, rounds=rounds, ident=ident)",
            "    except AnsibleError as e:",
            "        reraise(AnsibleFilterError, AnsibleFilterError(to_native(e), orig_exc=e), sys.exc_info()[2])",
            "    except Exception as e:",
            "        if unknown_passlib_hashtype:",
            "            # This can occur if passlib.hash has the hashtype attribute, but it has a different signature than the valid choices.",
            "            # In 2.19 this will replace the deprecation warning above and the extra exception handling can be deleted.",
            "            choices = ', '.join(passlib_mapping)",
            "            raise AnsibleFilterError(f\"{hashtype} is not in the list of supported passlib algorithms: {choices}\") from e",
            "        raise",
            "",
            "",
            "def to_uuid(string, namespace=UUID_NAMESPACE_ANSIBLE):",
            "    uuid_namespace = namespace",
            "    if not isinstance(uuid_namespace, uuid.UUID):",
            "        try:",
            "            uuid_namespace = uuid.UUID(namespace)",
            "        except (AttributeError, ValueError) as e:",
            "            raise AnsibleFilterError(\"Invalid value '%s' for 'namespace': %s\" % (to_native(namespace), to_native(e)))",
            "    # uuid.uuid5() requires bytes on Python 2 and bytes or text or Python 3",
            "    return to_text(uuid.uuid5(uuid_namespace, to_native(string, errors='surrogate_or_strict')))",
            "",
            "",
            "def mandatory(a, msg=None):",
            "    \"\"\"Make a variable mandatory.\"\"\"",
            "    from jinja2.runtime import Undefined",
            "",
            "    if isinstance(a, Undefined):",
            "        if a._undefined_name is not None:",
            "            name = \"'%s' \" % to_text(a._undefined_name)",
            "        else:",
            "            name = ''",
            "",
            "        if msg is not None:",
            "            raise AnsibleFilterError(to_native(msg))",
            "        else:",
            "            raise AnsibleFilterError(\"Mandatory variable %s not defined.\" % name)",
            "",
            "    return a",
            "",
            "",
            "def combine(*terms, **kwargs):",
            "    recursive = kwargs.pop('recursive', False)",
            "    list_merge = kwargs.pop('list_merge', 'replace')",
            "    if kwargs:",
            "        raise AnsibleFilterError(\"'recursive' and 'list_merge' are the only valid keyword arguments\")",
            "",
            "    # allow the user to do `[dict1, dict2, ...] | combine`",
            "    dictionaries = flatten(terms, levels=1)",
            "",
            "    # recursively check that every elements are defined (for jinja2)",
            "    recursive_check_defined(dictionaries)",
            "",
            "    if not dictionaries:",
            "        return {}",
            "",
            "    if len(dictionaries) == 1:",
            "        return dictionaries[0]",
            "",
            "    # merge all the dicts so that the dict at the end of the array have precedence",
            "    # over the dict at the beginning.",
            "    # we merge the dicts from the highest to the lowest priority because there is",
            "    # a huge probability that the lowest priority dict will be the biggest in size",
            "    # (as the low prio dict will hold the \"default\" values and the others will be \"patches\")",
            "    # and merge_hash create a copy of it's first argument.",
            "    # so high/right -> low/left is more efficient than low/left -> high/right",
            "    high_to_low_prio_dict_iterator = reversed(dictionaries)",
            "    result = next(high_to_low_prio_dict_iterator)",
            "    for dictionary in high_to_low_prio_dict_iterator:",
            "        result = merge_hash(dictionary, result, recursive, list_merge)",
            "",
            "    return result",
            "",
            "",
            "def comment(text, style='plain', **kw):",
            "    # Predefined comment types",
            "    comment_styles = {",
            "        'plain': {",
            "            'decoration': '# '",
            "        },",
            "        'erlang': {",
            "            'decoration': '% '",
            "        },",
            "        'c': {",
            "            'decoration': '// '",
            "        },",
            "        'cblock': {",
            "            'beginning': '/*',",
            "            'decoration': ' * ',",
            "            'end': ' */'",
            "        },",
            "        'xml': {",
            "            'beginning': '<!--',",
            "            'decoration': ' - ',",
            "            'end': '-->'",
            "        }",
            "    }",
            "",
            "    # Pointer to the right comment type",
            "    style_params = comment_styles[style]",
            "",
            "    if 'decoration' in kw:",
            "        prepostfix = kw['decoration']",
            "    else:",
            "        prepostfix = style_params['decoration']",
            "",
            "    # Default params",
            "    p = {",
            "        'newline': '\\n',",
            "        'beginning': '',",
            "        'prefix': (prepostfix).rstrip(),",
            "        'prefix_count': 1,",
            "        'decoration': '',",
            "        'postfix': (prepostfix).rstrip(),",
            "        'postfix_count': 1,",
            "        'end': ''",
            "    }",
            "",
            "    # Update default params",
            "    p.update(style_params)",
            "    p.update(kw)",
            "",
            "    # Compose substrings for the final string",
            "    str_beginning = ''",
            "    if p['beginning']:",
            "        str_beginning = \"%s%s\" % (p['beginning'], p['newline'])",
            "    str_prefix = ''",
            "    if p['prefix']:",
            "        if p['prefix'] != p['newline']:",
            "            str_prefix = str(",
            "                \"%s%s\" % (p['prefix'], p['newline'])) * int(p['prefix_count'])",
            "        else:",
            "            str_prefix = str(",
            "                \"%s\" % (p['newline'])) * int(p['prefix_count'])",
            "    str_text = (\"%s%s\" % (",
            "        p['decoration'],",
            "        # Prepend each line of the text with the decorator",
            "        text.replace(",
            "            p['newline'], \"%s%s\" % (p['newline'], p['decoration'])))).replace(",
            "                # Remove trailing spaces when only decorator is on the line",
            "                \"%s%s\" % (p['decoration'], p['newline']),",
            "                \"%s%s\" % (p['decoration'].rstrip(), p['newline']))",
            "    str_postfix = p['newline'].join(",
            "        [''] + [p['postfix'] for x in range(p['postfix_count'])])",
            "    str_end = ''",
            "    if p['end']:",
            "        str_end = \"%s%s\" % (p['newline'], p['end'])",
            "",
            "    # Return the final string",
            "    return \"%s%s%s%s%s\" % (",
            "        str_beginning,",
            "        str_prefix,",
            "        str_text,",
            "        str_postfix,",
            "        str_end)",
            "",
            "",
            "@pass_environment",
            "def extract(environment, item, container, morekeys=None):",
            "    if morekeys is None:",
            "        keys = [item]",
            "    elif isinstance(morekeys, list):",
            "        keys = [item] + morekeys",
            "    else:",
            "        keys = [item, morekeys]",
            "",
            "    value = container",
            "    for key in keys:",
            "        value = environment.getitem(value, key)",
            "",
            "    return value",
            "",
            "",
            "def b64encode(string, encoding='utf-8'):",
            "    return to_text(base64.b64encode(to_bytes(string, encoding=encoding, errors='surrogate_or_strict')))",
            "",
            "",
            "def b64decode(string, encoding='utf-8'):",
            "    return to_text(base64.b64decode(to_bytes(string, errors='surrogate_or_strict')), encoding=encoding)",
            "",
            "",
            "def flatten(mylist, levels=None, skip_nulls=True):",
            "",
            "    ret = []",
            "    for element in mylist:",
            "        if skip_nulls and element in (None, 'None', 'null'):",
            "            # ignore null items",
            "            continue",
            "        elif is_sequence(element):",
            "            if levels is None:",
            "                ret.extend(flatten(element, skip_nulls=skip_nulls))",
            "            elif levels >= 1:",
            "                # decrement as we go down the stack",
            "                ret.extend(flatten(element, levels=(int(levels) - 1), skip_nulls=skip_nulls))",
            "            else:",
            "                ret.append(element)",
            "        else:",
            "            ret.append(element)",
            "",
            "    return ret",
            "",
            "",
            "def subelements(obj, subelements, skip_missing=False):",
            "    '''Accepts a dict or list of dicts, and a dotted accessor and produces a product",
            "    of the element and the results of the dotted accessor",
            "",
            "    >>> obj = [{\"name\": \"alice\", \"groups\": [\"wheel\"], \"authorized\": [\"/tmp/alice/onekey.pub\"]}]",
            "    >>> subelements(obj, 'groups')",
            "    [({'name': 'alice', 'groups': ['wheel'], 'authorized': ['/tmp/alice/onekey.pub']}, 'wheel')]",
            "",
            "    '''",
            "    if isinstance(obj, dict):",
            "        element_list = list(obj.values())",
            "    elif isinstance(obj, list):",
            "        element_list = obj[:]",
            "    else:",
            "        raise AnsibleFilterError('obj must be a list of dicts or a nested dict')",
            "",
            "    if isinstance(subelements, list):",
            "        subelement_list = subelements[:]",
            "    elif isinstance(subelements, string_types):",
            "        subelement_list = subelements.split('.')",
            "    else:",
            "        raise AnsibleFilterTypeError('subelements must be a list or a string')",
            "",
            "    results = []",
            "",
            "    for element in element_list:",
            "        values = element",
            "        for subelement in subelement_list:",
            "            try:",
            "                values = values[subelement]",
            "            except KeyError:",
            "                if skip_missing:",
            "                    values = []",
            "                    break",
            "                raise AnsibleFilterError(\"could not find %r key in iterated item %r\" % (subelement, values))",
            "            except TypeError:",
            "                raise AnsibleFilterTypeError(\"the key %s should point to a dictionary, got '%s'\" % (subelement, values))",
            "        if not isinstance(values, list):",
            "            raise AnsibleFilterTypeError(\"the key %r should point to a list, got %r\" % (subelement, values))",
            "",
            "        for value in values:",
            "            results.append((element, value))",
            "",
            "    return results",
            "",
            "",
            "def dict_to_list_of_dict_key_value_elements(mydict, key_name='key', value_name='value'):",
            "    ''' takes a dictionary and transforms it into a list of dictionaries,",
            "        with each having a 'key' and 'value' keys that correspond to the keys and values of the original '''",
            "",
            "    if not isinstance(mydict, Mapping):",
            "        raise AnsibleFilterTypeError(\"dict2items requires a dictionary, got %s instead.\" % type(mydict))",
            "",
            "    ret = []",
            "    for key in mydict:",
            "        ret.append({key_name: key, value_name: mydict[key]})",
            "    return ret",
            "",
            "",
            "def list_of_dict_key_value_elements_to_dict(mylist, key_name='key', value_name='value'):",
            "    ''' takes a list of dicts with each having a 'key' and 'value' keys, and transforms the list into a dictionary,",
            "        effectively as the reverse of dict2items '''",
            "",
            "    if not is_sequence(mylist):",
            "        raise AnsibleFilterTypeError(\"items2dict requires a list, got %s instead.\" % type(mylist))",
            "",
            "    try:",
            "        return dict((item[key_name], item[value_name]) for item in mylist)",
            "    except KeyError:",
            "        raise AnsibleFilterTypeError(",
            "            \"items2dict requires each dictionary in the list to contain the keys '%s' and '%s', got %s instead.\"",
            "            % (key_name, value_name, mylist)",
            "        )",
            "    except TypeError:",
            "        raise AnsibleFilterTypeError(\"items2dict requires a list of dictionaries, got %s instead.\" % mylist)",
            "",
            "",
            "def path_join(paths):",
            "    ''' takes a sequence or a string, and return a concatenation",
            "        of the different members '''",
            "    if isinstance(paths, string_types):",
            "        return os.path.join(paths)",
            "    elif is_sequence(paths):",
            "        return os.path.join(*paths)",
            "    else:",
            "        raise AnsibleFilterTypeError(\"|path_join expects string or sequence, got %s instead.\" % type(paths))",
            "",
            "",
            "def commonpath(paths):",
            "    \"\"\"",
            "    Retrieve the longest common path from the given list.",
            "",
            "    :param paths: A list of file system paths.",
            "    :type paths: List[str]",
            "    :returns: The longest common path.",
            "    :rtype: str",
            "    \"\"\"",
            "    if not is_sequence(paths):",
            "        raise AnsibleFilterTypeError(\"|path_join expects sequence, got %s instead.\" % type(paths))",
            "",
            "    return os.path.commonpath(paths)",
            "",
            "",
            "class FilterModule(object):",
            "    ''' Ansible core jinja2 filters '''",
            "",
            "    def filters(self):",
            "        return {",
            "            # base 64",
            "            'b64decode': b64decode,",
            "            'b64encode': b64encode,",
            "",
            "            # uuid",
            "            'to_uuid': to_uuid,",
            "",
            "            # json",
            "            'to_json': to_json,",
            "            'to_nice_json': to_nice_json,",
            "            'from_json': json.loads,",
            "",
            "            # yaml",
            "            'to_yaml': to_yaml,",
            "            'to_nice_yaml': to_nice_yaml,",
            "            'from_yaml': from_yaml,",
            "            'from_yaml_all': from_yaml_all,",
            "",
            "            # path",
            "            'basename': partial(unicode_wrap, os.path.basename),",
            "            'dirname': partial(unicode_wrap, os.path.dirname),",
            "            'expanduser': partial(unicode_wrap, os.path.expanduser),",
            "            'expandvars': partial(unicode_wrap, os.path.expandvars),",
            "            'path_join': path_join,",
            "            'realpath': partial(unicode_wrap, os.path.realpath),",
            "            'relpath': partial(unicode_wrap, os.path.relpath),",
            "            'splitext': partial(unicode_wrap, os.path.splitext),",
            "            'win_basename': partial(unicode_wrap, ntpath.basename),",
            "            'win_dirname': partial(unicode_wrap, ntpath.dirname),",
            "            'win_splitdrive': partial(unicode_wrap, ntpath.splitdrive),",
            "            'commonpath': commonpath,",
            "            'normpath': partial(unicode_wrap, os.path.normpath),",
            "",
            "            # file glob",
            "            'fileglob': fileglob,",
            "",
            "            # types",
            "            'bool': to_bool,",
            "            'to_datetime': to_datetime,",
            "",
            "            # date formatting",
            "            'strftime': strftime,",
            "",
            "            # quote string for shell usage",
            "            'quote': quote,",
            "",
            "            # hash filters",
            "            # md5 hex digest of string",
            "            'md5': md5s,",
            "            # sha1 hex digest of string",
            "            'sha1': checksum_s,",
            "            # checksum of string as used by ansible for checksumming files",
            "            'checksum': checksum_s,",
            "            # generic hashing",
            "            'password_hash': get_encrypted_password,",
            "            'hash': get_hash,",
            "",
            "            # regex",
            "            'regex_replace': regex_replace,",
            "            'regex_escape': regex_escape,",
            "            'regex_search': regex_search,",
            "            'regex_findall': regex_findall,",
            "",
            "            # ? : ;",
            "            'ternary': ternary,",
            "",
            "            # random stuff",
            "            'random': rand,",
            "            'shuffle': randomize_list,",
            "",
            "            # undefined",
            "            'mandatory': mandatory,",
            "",
            "            # comment-style decoration",
            "            'comment': comment,",
            "",
            "            # debug",
            "            'type_debug': lambda o: o.__class__.__name__,",
            "",
            "            # Data structures",
            "            'combine': combine,",
            "            'extract': extract,",
            "            'flatten': flatten,",
            "            'dict2items': dict_to_list_of_dict_key_value_elements,",
            "            'items2dict': list_of_dict_key_value_elements_to_dict,",
            "            'subelements': subelements,",
            "            'split': partial(unicode_wrap, text_type.split),",
            "        }"
        ],
        "afterPatchFile": [
            "# (c) 2012, Jeroen Hoekx <jeroen@hoekx.be>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import base64",
            "import glob",
            "import hashlib",
            "import json",
            "import ntpath",
            "import os.path",
            "import re",
            "import shlex",
            "import sys",
            "import time",
            "import uuid",
            "import yaml",
            "import datetime",
            "",
            "from collections.abc import Mapping",
            "from functools import partial",
            "from random import Random, SystemRandom, shuffle",
            "",
            "from jinja2.filters import pass_environment",
            "",
            "from ansible.errors import AnsibleError, AnsibleFilterError, AnsibleFilterTypeError",
            "from ansible.module_utils.six import string_types, integer_types, reraise, text_type",
            "from ansible.module_utils._text import to_bytes, to_native, to_text",
            "from ansible.module_utils.common.collections import is_sequence",
            "from ansible.module_utils.common.yaml import yaml_load, yaml_load_all",
            "from ansible.parsing.ajson import AnsibleJSONEncoder",
            "from ansible.parsing.yaml.dumper import AnsibleDumper",
            "from ansible.template import recursive_check_defined",
            "from ansible.utils.display import Display",
            "from ansible.utils.encrypt import passlib_or_crypt, PASSLIB_AVAILABLE",
            "from ansible.utils.hashing import md5s, checksum_s",
            "from ansible.utils.unicode import unicode_wrap",
            "from ansible.utils.unsafe_proxy import _is_unsafe",
            "from ansible.utils.vars import merge_hash",
            "",
            "display = Display()",
            "",
            "UUID_NAMESPACE_ANSIBLE = uuid.UUID('361E6D51-FAEC-444A-9079-341386DA8E2E')",
            "",
            "",
            "def to_yaml(a, *args, **kw):",
            "    '''Make verbose, human readable yaml'''",
            "    default_flow_style = kw.pop('default_flow_style', None)",
            "    try:",
            "        transformed = yaml.dump(a, Dumper=AnsibleDumper, allow_unicode=True, default_flow_style=default_flow_style, **kw)",
            "    except Exception as e:",
            "        raise AnsibleFilterError(\"to_yaml - %s\" % to_native(e), orig_exc=e)",
            "    return to_text(transformed)",
            "",
            "",
            "def to_nice_yaml(a, indent=4, *args, **kw):",
            "    '''Make verbose, human readable yaml'''",
            "    try:",
            "        transformed = yaml.dump(a, Dumper=AnsibleDumper, indent=indent, allow_unicode=True, default_flow_style=False, **kw)",
            "    except Exception as e:",
            "        raise AnsibleFilterError(\"to_nice_yaml - %s\" % to_native(e), orig_exc=e)",
            "    return to_text(transformed)",
            "",
            "",
            "def to_json(a, *args, **kw):",
            "    ''' Convert the value to JSON '''",
            "",
            "    # defaults for filters",
            "    if 'vault_to_text' not in kw:",
            "        kw['vault_to_text'] = True",
            "    if 'preprocess_unsafe' not in kw:",
            "        kw['preprocess_unsafe'] = False",
            "",
            "    return json.dumps(a, cls=AnsibleJSONEncoder, *args, **kw)",
            "",
            "",
            "def to_nice_json(a, indent=4, sort_keys=True, *args, **kw):",
            "    '''Make verbose, human readable JSON'''",
            "    return to_json(a, indent=indent, sort_keys=sort_keys, separators=(',', ': '), *args, **kw)",
            "",
            "",
            "def to_bool(a):",
            "    ''' return a bool for the arg '''",
            "    if a is None or isinstance(a, bool):",
            "        return a",
            "    if isinstance(a, string_types):",
            "        a = a.lower()",
            "    if a in ('yes', 'on', '1', 'true', 1):",
            "        return True",
            "    return False",
            "",
            "",
            "def to_datetime(string, format=\"%Y-%m-%d %H:%M:%S\"):",
            "    return datetime.datetime.strptime(string, format)",
            "",
            "",
            "def strftime(string_format, second=None, utc=False):",
            "    ''' return a date string using string. See https://docs.python.org/3/library/time.html#time.strftime for format '''",
            "    if utc:",
            "        timefn = time.gmtime",
            "    else:",
            "        timefn = time.localtime",
            "    if second is not None:",
            "        try:",
            "            second = float(second)",
            "        except Exception:",
            "            raise AnsibleFilterError('Invalid value for epoch value (%s)' % second)",
            "    return time.strftime(string_format, timefn(second))",
            "",
            "",
            "def quote(a):",
            "    ''' return its argument quoted for shell usage '''",
            "    if a is None:",
            "        a = u''",
            "    return shlex.quote(to_text(a))",
            "",
            "",
            "def fileglob(pathname):",
            "    ''' return list of matched regular files for glob '''",
            "    return [g for g in glob.glob(pathname) if os.path.isfile(g)]",
            "",
            "",
            "def regex_replace(value='', pattern='', replacement='', ignorecase=False, multiline=False):",
            "    ''' Perform a `re.sub` returning a string '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    flags = 0",
            "    if ignorecase:",
            "        flags |= re.I",
            "    if multiline:",
            "        flags |= re.M",
            "    _re = re.compile(pattern, flags=flags)",
            "    return _re.sub(replacement, value)",
            "",
            "",
            "def regex_findall(value, regex, multiline=False, ignorecase=False):",
            "    ''' Perform re.findall and return the list of matches '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    flags = 0",
            "    if ignorecase:",
            "        flags |= re.I",
            "    if multiline:",
            "        flags |= re.M",
            "    return re.findall(regex, value, flags)",
            "",
            "",
            "def regex_search(value, regex, *args, **kwargs):",
            "    ''' Perform re.search and return the list of matches or a backref '''",
            "",
            "    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')",
            "",
            "    groups = list()",
            "    for arg in args:",
            "        if arg.startswith('\\\\g'):",
            "            match = re.match(r'\\\\g<(\\S+)>', arg).group(1)",
            "            groups.append(match)",
            "        elif arg.startswith('\\\\'):",
            "            match = int(re.match(r'\\\\(\\d+)', arg).group(1))",
            "            groups.append(match)",
            "        else:",
            "            raise AnsibleFilterError('Unknown argument')",
            "",
            "    flags = 0",
            "    if kwargs.get('ignorecase'):",
            "        flags |= re.I",
            "    if kwargs.get('multiline'):",
            "        flags |= re.M",
            "",
            "    match = re.search(regex, value, flags)",
            "    if match:",
            "        if not groups:",
            "            return match.group()",
            "        else:",
            "            items = list()",
            "            for item in groups:",
            "                items.append(match.group(item))",
            "            return items",
            "",
            "",
            "def ternary(value, true_val, false_val, none_val=None):",
            "    '''  value ? true_val : false_val '''",
            "    if value is None and none_val is not None:",
            "        return none_val",
            "    elif bool(value):",
            "        return true_val",
            "    else:",
            "        return false_val",
            "",
            "",
            "def regex_escape(string, re_type='python'):",
            "    \"\"\"Escape all regular expressions special characters from STRING.\"\"\"",
            "    string = to_text(string, errors='surrogate_or_strict', nonstring='simplerepr')",
            "    if re_type == 'python':",
            "        return re.escape(string)",
            "    elif re_type == 'posix_basic':",
            "        # list of BRE special chars:",
            "        # https://en.wikibooks.org/wiki/Regular_Expressions/POSIX_Basic_Regular_Expressions",
            "        return regex_replace(string, r'([].[^$*\\\\])', r'\\\\\\1')",
            "    # TODO: implement posix_extended",
            "    # It's similar to, but different from python regex, which is similar to,",
            "    # but different from PCRE.  It's possible that re.escape would work here.",
            "    # https://remram44.github.io/regex-cheatsheet/regex.html#programs",
            "    elif re_type == 'posix_extended':",
            "        raise AnsibleFilterError('Regex type (%s) not yet implemented' % re_type)",
            "    else:",
            "        raise AnsibleFilterError('Invalid regex type (%s)' % re_type)",
            "",
            "",
            "def from_yaml(data):",
            "    if isinstance(data, string_types):",
            "        # The ``text_type`` call here strips any custom",
            "        # string wrapper class, so that CSafeLoader can",
            "        # read the data",
            "        if _is_unsafe(data):",
            "            data = data._strip_unsafe()",
            "        return yaml_load(text_type(to_text(data, errors='surrogate_or_strict')))",
            "    return data",
            "",
            "",
            "def from_yaml_all(data):",
            "    if isinstance(data, string_types):",
            "        # The ``text_type`` call here strips any custom",
            "        # string wrapper class, so that CSafeLoader can",
            "        # read the data",
            "        if _is_unsafe(data):",
            "            data = data._strip_unsafe()",
            "        return yaml_load_all(text_type(to_text(data, errors='surrogate_or_strict')))",
            "    return data",
            "",
            "",
            "@pass_environment",
            "def rand(environment, end, start=None, step=None, seed=None):",
            "    if seed is None:",
            "        r = SystemRandom()",
            "    else:",
            "        r = Random(seed)",
            "    if isinstance(end, integer_types):",
            "        if not start:",
            "            start = 0",
            "        if not step:",
            "            step = 1",
            "        return r.randrange(start, end, step)",
            "    elif hasattr(end, '__iter__'):",
            "        if start or step:",
            "            raise AnsibleFilterError('start and step can only be used with integer values')",
            "        return r.choice(end)",
            "    else:",
            "        raise AnsibleFilterError('random can only be used on sequences and integers')",
            "",
            "",
            "def randomize_list(mylist, seed=None):",
            "    try:",
            "        mylist = list(mylist)",
            "        if seed:",
            "            r = Random(seed)",
            "            r.shuffle(mylist)",
            "        else:",
            "            shuffle(mylist)",
            "    except Exception:",
            "        pass",
            "    return mylist",
            "",
            "",
            "def get_hash(data, hashtype='sha1'):",
            "    try:",
            "        h = hashlib.new(hashtype)",
            "    except Exception as e:",
            "        # hash is not supported?",
            "        raise AnsibleFilterError(e)",
            "",
            "    h.update(to_bytes(data, errors='surrogate_or_strict'))",
            "    return h.hexdigest()",
            "",
            "",
            "def get_encrypted_password(password, hashtype='sha512', salt=None, salt_size=None, rounds=None, ident=None):",
            "    passlib_mapping = {",
            "        'md5': 'md5_crypt',",
            "        'blowfish': 'bcrypt',",
            "        'sha256': 'sha256_crypt',",
            "        'sha512': 'sha512_crypt',",
            "    }",
            "",
            "    hashtype = passlib_mapping.get(hashtype, hashtype)",
            "",
            "    unknown_passlib_hashtype = False",
            "    if PASSLIB_AVAILABLE and hashtype not in passlib_mapping and hashtype not in passlib_mapping.values():",
            "        unknown_passlib_hashtype = True",
            "        display.deprecated(",
            "            f\"Checking for unsupported password_hash passlib hashtype '{hashtype}'. \"",
            "            \"This will be an error in the future as all supported hashtypes must be documented.\",",
            "            version='2.19'",
            "        )",
            "",
            "    try:",
            "        return passlib_or_crypt(password, hashtype, salt=salt, salt_size=salt_size, rounds=rounds, ident=ident)",
            "    except AnsibleError as e:",
            "        reraise(AnsibleFilterError, AnsibleFilterError(to_native(e), orig_exc=e), sys.exc_info()[2])",
            "    except Exception as e:",
            "        if unknown_passlib_hashtype:",
            "            # This can occur if passlib.hash has the hashtype attribute, but it has a different signature than the valid choices.",
            "            # In 2.19 this will replace the deprecation warning above and the extra exception handling can be deleted.",
            "            choices = ', '.join(passlib_mapping)",
            "            raise AnsibleFilterError(f\"{hashtype} is not in the list of supported passlib algorithms: {choices}\") from e",
            "        raise",
            "",
            "",
            "def to_uuid(string, namespace=UUID_NAMESPACE_ANSIBLE):",
            "    uuid_namespace = namespace",
            "    if not isinstance(uuid_namespace, uuid.UUID):",
            "        try:",
            "            uuid_namespace = uuid.UUID(namespace)",
            "        except (AttributeError, ValueError) as e:",
            "            raise AnsibleFilterError(\"Invalid value '%s' for 'namespace': %s\" % (to_native(namespace), to_native(e)))",
            "    # uuid.uuid5() requires bytes on Python 2 and bytes or text or Python 3",
            "    return to_text(uuid.uuid5(uuid_namespace, to_native(string, errors='surrogate_or_strict')))",
            "",
            "",
            "def mandatory(a, msg=None):",
            "    \"\"\"Make a variable mandatory.\"\"\"",
            "    from jinja2.runtime import Undefined",
            "",
            "    if isinstance(a, Undefined):",
            "        if a._undefined_name is not None:",
            "            name = \"'%s' \" % to_text(a._undefined_name)",
            "        else:",
            "            name = ''",
            "",
            "        if msg is not None:",
            "            raise AnsibleFilterError(to_native(msg))",
            "        else:",
            "            raise AnsibleFilterError(\"Mandatory variable %s not defined.\" % name)",
            "",
            "    return a",
            "",
            "",
            "def combine(*terms, **kwargs):",
            "    recursive = kwargs.pop('recursive', False)",
            "    list_merge = kwargs.pop('list_merge', 'replace')",
            "    if kwargs:",
            "        raise AnsibleFilterError(\"'recursive' and 'list_merge' are the only valid keyword arguments\")",
            "",
            "    # allow the user to do `[dict1, dict2, ...] | combine`",
            "    dictionaries = flatten(terms, levels=1)",
            "",
            "    # recursively check that every elements are defined (for jinja2)",
            "    recursive_check_defined(dictionaries)",
            "",
            "    if not dictionaries:",
            "        return {}",
            "",
            "    if len(dictionaries) == 1:",
            "        return dictionaries[0]",
            "",
            "    # merge all the dicts so that the dict at the end of the array have precedence",
            "    # over the dict at the beginning.",
            "    # we merge the dicts from the highest to the lowest priority because there is",
            "    # a huge probability that the lowest priority dict will be the biggest in size",
            "    # (as the low prio dict will hold the \"default\" values and the others will be \"patches\")",
            "    # and merge_hash create a copy of it's first argument.",
            "    # so high/right -> low/left is more efficient than low/left -> high/right",
            "    high_to_low_prio_dict_iterator = reversed(dictionaries)",
            "    result = next(high_to_low_prio_dict_iterator)",
            "    for dictionary in high_to_low_prio_dict_iterator:",
            "        result = merge_hash(dictionary, result, recursive, list_merge)",
            "",
            "    return result",
            "",
            "",
            "def comment(text, style='plain', **kw):",
            "    # Predefined comment types",
            "    comment_styles = {",
            "        'plain': {",
            "            'decoration': '# '",
            "        },",
            "        'erlang': {",
            "            'decoration': '% '",
            "        },",
            "        'c': {",
            "            'decoration': '// '",
            "        },",
            "        'cblock': {",
            "            'beginning': '/*',",
            "            'decoration': ' * ',",
            "            'end': ' */'",
            "        },",
            "        'xml': {",
            "            'beginning': '<!--',",
            "            'decoration': ' - ',",
            "            'end': '-->'",
            "        }",
            "    }",
            "",
            "    # Pointer to the right comment type",
            "    style_params = comment_styles[style]",
            "",
            "    if 'decoration' in kw:",
            "        prepostfix = kw['decoration']",
            "    else:",
            "        prepostfix = style_params['decoration']",
            "",
            "    # Default params",
            "    p = {",
            "        'newline': '\\n',",
            "        'beginning': '',",
            "        'prefix': (prepostfix).rstrip(),",
            "        'prefix_count': 1,",
            "        'decoration': '',",
            "        'postfix': (prepostfix).rstrip(),",
            "        'postfix_count': 1,",
            "        'end': ''",
            "    }",
            "",
            "    # Update default params",
            "    p.update(style_params)",
            "    p.update(kw)",
            "",
            "    # Compose substrings for the final string",
            "    str_beginning = ''",
            "    if p['beginning']:",
            "        str_beginning = \"%s%s\" % (p['beginning'], p['newline'])",
            "    str_prefix = ''",
            "    if p['prefix']:",
            "        if p['prefix'] != p['newline']:",
            "            str_prefix = str(",
            "                \"%s%s\" % (p['prefix'], p['newline'])) * int(p['prefix_count'])",
            "        else:",
            "            str_prefix = str(",
            "                \"%s\" % (p['newline'])) * int(p['prefix_count'])",
            "    str_text = (\"%s%s\" % (",
            "        p['decoration'],",
            "        # Prepend each line of the text with the decorator",
            "        text.replace(",
            "            p['newline'], \"%s%s\" % (p['newline'], p['decoration'])))).replace(",
            "                # Remove trailing spaces when only decorator is on the line",
            "                \"%s%s\" % (p['decoration'], p['newline']),",
            "                \"%s%s\" % (p['decoration'].rstrip(), p['newline']))",
            "    str_postfix = p['newline'].join(",
            "        [''] + [p['postfix'] for x in range(p['postfix_count'])])",
            "    str_end = ''",
            "    if p['end']:",
            "        str_end = \"%s%s\" % (p['newline'], p['end'])",
            "",
            "    # Return the final string",
            "    return \"%s%s%s%s%s\" % (",
            "        str_beginning,",
            "        str_prefix,",
            "        str_text,",
            "        str_postfix,",
            "        str_end)",
            "",
            "",
            "@pass_environment",
            "def extract(environment, item, container, morekeys=None):",
            "    if morekeys is None:",
            "        keys = [item]",
            "    elif isinstance(morekeys, list):",
            "        keys = [item] + morekeys",
            "    else:",
            "        keys = [item, morekeys]",
            "",
            "    value = container",
            "    for key in keys:",
            "        value = environment.getitem(value, key)",
            "",
            "    return value",
            "",
            "",
            "def b64encode(string, encoding='utf-8'):",
            "    return to_text(base64.b64encode(to_bytes(string, encoding=encoding, errors='surrogate_or_strict')))",
            "",
            "",
            "def b64decode(string, encoding='utf-8'):",
            "    return to_text(base64.b64decode(to_bytes(string, errors='surrogate_or_strict')), encoding=encoding)",
            "",
            "",
            "def flatten(mylist, levels=None, skip_nulls=True):",
            "",
            "    ret = []",
            "    for element in mylist:",
            "        if skip_nulls and element in (None, 'None', 'null'):",
            "            # ignore null items",
            "            continue",
            "        elif is_sequence(element):",
            "            if levels is None:",
            "                ret.extend(flatten(element, skip_nulls=skip_nulls))",
            "            elif levels >= 1:",
            "                # decrement as we go down the stack",
            "                ret.extend(flatten(element, levels=(int(levels) - 1), skip_nulls=skip_nulls))",
            "            else:",
            "                ret.append(element)",
            "        else:",
            "            ret.append(element)",
            "",
            "    return ret",
            "",
            "",
            "def subelements(obj, subelements, skip_missing=False):",
            "    '''Accepts a dict or list of dicts, and a dotted accessor and produces a product",
            "    of the element and the results of the dotted accessor",
            "",
            "    >>> obj = [{\"name\": \"alice\", \"groups\": [\"wheel\"], \"authorized\": [\"/tmp/alice/onekey.pub\"]}]",
            "    >>> subelements(obj, 'groups')",
            "    [({'name': 'alice', 'groups': ['wheel'], 'authorized': ['/tmp/alice/onekey.pub']}, 'wheel')]",
            "",
            "    '''",
            "    if isinstance(obj, dict):",
            "        element_list = list(obj.values())",
            "    elif isinstance(obj, list):",
            "        element_list = obj[:]",
            "    else:",
            "        raise AnsibleFilterError('obj must be a list of dicts or a nested dict')",
            "",
            "    if isinstance(subelements, list):",
            "        subelement_list = subelements[:]",
            "    elif isinstance(subelements, string_types):",
            "        subelement_list = subelements.split('.')",
            "    else:",
            "        raise AnsibleFilterTypeError('subelements must be a list or a string')",
            "",
            "    results = []",
            "",
            "    for element in element_list:",
            "        values = element",
            "        for subelement in subelement_list:",
            "            try:",
            "                values = values[subelement]",
            "            except KeyError:",
            "                if skip_missing:",
            "                    values = []",
            "                    break",
            "                raise AnsibleFilterError(\"could not find %r key in iterated item %r\" % (subelement, values))",
            "            except TypeError:",
            "                raise AnsibleFilterTypeError(\"the key %s should point to a dictionary, got '%s'\" % (subelement, values))",
            "        if not isinstance(values, list):",
            "            raise AnsibleFilterTypeError(\"the key %r should point to a list, got %r\" % (subelement, values))",
            "",
            "        for value in values:",
            "            results.append((element, value))",
            "",
            "    return results",
            "",
            "",
            "def dict_to_list_of_dict_key_value_elements(mydict, key_name='key', value_name='value'):",
            "    ''' takes a dictionary and transforms it into a list of dictionaries,",
            "        with each having a 'key' and 'value' keys that correspond to the keys and values of the original '''",
            "",
            "    if not isinstance(mydict, Mapping):",
            "        raise AnsibleFilterTypeError(\"dict2items requires a dictionary, got %s instead.\" % type(mydict))",
            "",
            "    ret = []",
            "    for key in mydict:",
            "        ret.append({key_name: key, value_name: mydict[key]})",
            "    return ret",
            "",
            "",
            "def list_of_dict_key_value_elements_to_dict(mylist, key_name='key', value_name='value'):",
            "    ''' takes a list of dicts with each having a 'key' and 'value' keys, and transforms the list into a dictionary,",
            "        effectively as the reverse of dict2items '''",
            "",
            "    if not is_sequence(mylist):",
            "        raise AnsibleFilterTypeError(\"items2dict requires a list, got %s instead.\" % type(mylist))",
            "",
            "    try:",
            "        return dict((item[key_name], item[value_name]) for item in mylist)",
            "    except KeyError:",
            "        raise AnsibleFilterTypeError(",
            "            \"items2dict requires each dictionary in the list to contain the keys '%s' and '%s', got %s instead.\"",
            "            % (key_name, value_name, mylist)",
            "        )",
            "    except TypeError:",
            "        raise AnsibleFilterTypeError(\"items2dict requires a list of dictionaries, got %s instead.\" % mylist)",
            "",
            "",
            "def path_join(paths):",
            "    ''' takes a sequence or a string, and return a concatenation",
            "        of the different members '''",
            "    if isinstance(paths, string_types):",
            "        return os.path.join(paths)",
            "    elif is_sequence(paths):",
            "        return os.path.join(*paths)",
            "    else:",
            "        raise AnsibleFilterTypeError(\"|path_join expects string or sequence, got %s instead.\" % type(paths))",
            "",
            "",
            "def commonpath(paths):",
            "    \"\"\"",
            "    Retrieve the longest common path from the given list.",
            "",
            "    :param paths: A list of file system paths.",
            "    :type paths: List[str]",
            "    :returns: The longest common path.",
            "    :rtype: str",
            "    \"\"\"",
            "    if not is_sequence(paths):",
            "        raise AnsibleFilterTypeError(\"|path_join expects sequence, got %s instead.\" % type(paths))",
            "",
            "    return os.path.commonpath(paths)",
            "",
            "",
            "class FilterModule(object):",
            "    ''' Ansible core jinja2 filters '''",
            "",
            "    def filters(self):",
            "        return {",
            "            # base 64",
            "            'b64decode': b64decode,",
            "            'b64encode': b64encode,",
            "",
            "            # uuid",
            "            'to_uuid': to_uuid,",
            "",
            "            # json",
            "            'to_json': to_json,",
            "            'to_nice_json': to_nice_json,",
            "            'from_json': json.loads,",
            "",
            "            # yaml",
            "            'to_yaml': to_yaml,",
            "            'to_nice_yaml': to_nice_yaml,",
            "            'from_yaml': from_yaml,",
            "            'from_yaml_all': from_yaml_all,",
            "",
            "            # path",
            "            'basename': partial(unicode_wrap, os.path.basename),",
            "            'dirname': partial(unicode_wrap, os.path.dirname),",
            "            'expanduser': partial(unicode_wrap, os.path.expanduser),",
            "            'expandvars': partial(unicode_wrap, os.path.expandvars),",
            "            'path_join': path_join,",
            "            'realpath': partial(unicode_wrap, os.path.realpath),",
            "            'relpath': partial(unicode_wrap, os.path.relpath),",
            "            'splitext': partial(unicode_wrap, os.path.splitext),",
            "            'win_basename': partial(unicode_wrap, ntpath.basename),",
            "            'win_dirname': partial(unicode_wrap, ntpath.dirname),",
            "            'win_splitdrive': partial(unicode_wrap, ntpath.splitdrive),",
            "            'commonpath': commonpath,",
            "            'normpath': partial(unicode_wrap, os.path.normpath),",
            "",
            "            # file glob",
            "            'fileglob': fileglob,",
            "",
            "            # types",
            "            'bool': to_bool,",
            "            'to_datetime': to_datetime,",
            "",
            "            # date formatting",
            "            'strftime': strftime,",
            "",
            "            # quote string for shell usage",
            "            'quote': quote,",
            "",
            "            # hash filters",
            "            # md5 hex digest of string",
            "            'md5': md5s,",
            "            # sha1 hex digest of string",
            "            'sha1': checksum_s,",
            "            # checksum of string as used by ansible for checksumming files",
            "            'checksum': checksum_s,",
            "            # generic hashing",
            "            'password_hash': get_encrypted_password,",
            "            'hash': get_hash,",
            "",
            "            # regex",
            "            'regex_replace': regex_replace,",
            "            'regex_escape': regex_escape,",
            "            'regex_search': regex_search,",
            "            'regex_findall': regex_findall,",
            "",
            "            # ? : ;",
            "            'ternary': ternary,",
            "",
            "            # random stuff",
            "            'random': rand,",
            "            'shuffle': randomize_list,",
            "",
            "            # undefined",
            "            'mandatory': mandatory,",
            "",
            "            # comment-style decoration",
            "            'comment': comment,",
            "",
            "            # debug",
            "            'type_debug': lambda o: o.__class__.__name__,",
            "",
            "            # Data structures",
            "            'combine': combine,",
            "            'extract': extract,",
            "            'flatten': flatten,",
            "            'dict2items': dict_to_list_of_dict_key_value_elements,",
            "            'items2dict': list_of_dict_key_value_elements_to_dict,",
            "            'subelements': subelements,",
            "            'split': partial(unicode_wrap, text_type.split),",
            "        }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "yt_dlp.YoutubeDL"
        ]
    },
    "lib/ansible/plugins/lookup/first_found.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "     elements: path"
            },
            "1": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 137,
                "PatchRowcode": " \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 138,
                "PatchRowcode": " import os"
            },
            "3": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import re"
            },
            "4": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 139,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 140,
                "PatchRowcode": " from collections.abc import Mapping, Sequence"
            },
            "6": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 141,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 146,
                "PatchRowcode": " from ansible.plugins.lookup import LookupBase"
            },
            "8": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 147,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 148,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+def _splitter(value, chars):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+    chars = set(chars)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+    v = ''"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+    for c in value:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+        if c in chars:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+            yield v"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+            v = ''"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+            continue"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+        v += c"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+    yield v"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 161,
                "PatchRowcode": " def _split_on(terms, spliters=','):"
            },
            "23": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "     termlist = []"
            },
            "24": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "     if isinstance(terms, string_types):"
            },
            "25": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        termlist = re.split(r'[%s]' % ''.join(map(re.escape, spliters)), terms)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 164,
                "PatchRowcode": "+        termlist = list(_splitter(terms, spliters))"
            },
            "27": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "     else:"
            },
            "28": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "         # added since options will already listify"
            },
            "29": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "         for t in terms:"
            }
        },
        "frontPatchFile": [
            "# (c) 2013, seth vidal <skvidal@fedoraproject.org> red hat, inc",
            "# (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "DOCUMENTATION = \"\"\"",
            "    name: first_found",
            "    author: Seth Vidal (!UNKNOWN) <skvidal@fedoraproject.org>",
            "    version_added: historical",
            "    short_description: return first file found from list",
            "    description:",
            "      - This lookup checks a list of files and paths and returns the full path to the first combination found.",
            "      - As all lookups, when fed relative paths it will try use the current task's location first and go up the chain",
            "        to the containing locations of role / play / include and so on.",
            "      - The list of files has precedence over the paths searched.",
            "        For example, A task in a role has a 'file1' in the play's relative path, this will be used, 'file2' in role's relative path will not.",
            "      - Either a list of files C(_terms) or a key C(files) with a list of files is required for this plugin to operate.",
            "    notes:",
            "      - This lookup can be used in 'dual mode', either passing a list of file names or a dictionary that has C(files) and C(paths).",
            "    options:",
            "      _terms:",
            "        description: A list of file names.",
            "      files:",
            "        description: A list of file names.",
            "        type: list",
            "        elements: string",
            "        default: []",
            "      paths:",
            "        description: A list of paths in which to look for the files.",
            "        type: list",
            "        elements: string",
            "        default: []",
            "      skip:",
            "        type: boolean",
            "        default: False",
            "        description:",
            "          - When C(True), return an empty list when no files are matched.",
            "          - This is useful when used with C(with_first_found), as an empty list return to C(with_) calls",
            "            causes the calling task to be skipped.",
            "          - When used as a template via C(lookup) or C(query), setting I(skip=True) will *not* cause the task to skip.",
            "            Tasks must handle the empty list return from the template.",
            "          - When C(False) and C(lookup) or C(query) specifies  I(errors='ignore') all errors (including no file found,",
            "            but potentially others) return an empty string or an empty list respectively.",
            "          - When C(True) and C(lookup) or C(query) specifies I(errors='ignore'), no file found will return an empty",
            "            list and other potential errors return an empty string or empty list depending on the template call",
            "            (in other words return values of C(lookup) v C(query)).",
            "\"\"\"",
            "",
            "EXAMPLES = \"\"\"",
            "- name: Set _found_file to the first existing file, raising an error if a file is not found",
            "  ansible.builtin.set_fact:",
            "    _found_file: \"{{ lookup('ansible.builtin.first_found', findme) }}\"",
            "  vars:",
            "    findme:",
            "      - /path/to/foo.txt",
            "      - bar.txt  # will be looked in files/ dir relative to role and/or play",
            "      - /path/to/biz.txt",
            "",
            "- name: Set _found_file to the first existing file, or an empty list if no files found",
            "  ansible.builtin.set_fact:",
            "    _found_file: \"{{ lookup('ansible.builtin.first_found', files, paths=['/extra/path'], skip=True) }}\"",
            "  vars:",
            "    files:",
            "      - /path/to/foo.txt",
            "      - /path/to/bar.txt",
            "",
            "- name: Include tasks only if one of the files exist, otherwise skip the task",
            "  ansible.builtin.include_tasks:",
            "    file: \"{{ item }}\"",
            "  with_first_found:",
            "    - files:",
            "      - path/tasks.yaml",
            "      - path/other_tasks.yaml",
            "      skip: True",
            "",
            "- name: Include tasks only if one of the files exists, otherwise skip",
            "  ansible.builtin.include_tasks: '{{ tasks_file }}'",
            "  when: tasks_file != \"\"",
            "  vars:",
            "    tasks_file: \"{{ lookup('ansible.builtin.first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}\"",
            "",
            "- name: |",
            "        copy first existing file found to /some/file,",
            "        looking in relative directories from where the task is defined and",
            "        including any play objects that contain it",
            "  ansible.builtin.copy:",
            "    src: \"{{ lookup('ansible.builtin.first_found', findme) }}\"",
            "    dest: /some/file",
            "  vars:",
            "    findme:",
            "      - foo",
            "      - \"{{ inventory_hostname }}\"",
            "      - bar",
            "",
            "- name: same copy but specific paths",
            "  ansible.builtin.copy:",
            "    src: \"{{ lookup('ansible.builtin.first_found', params) }}\"",
            "    dest: /some/file",
            "  vars:",
            "    params:",
            "      files:",
            "        - foo",
            "        - \"{{ inventory_hostname }}\"",
            "        - bar",
            "      paths:",
            "        - /tmp/production",
            "        - /tmp/staging",
            "",
            "- name: INTERFACES | Create Ansible header for /etc/network/interfaces",
            "  ansible.builtin.template:",
            "    src: \"{{ lookup('ansible.builtin.first_found', findme)}}\"",
            "    dest: \"/etc/foo.conf\"",
            "  vars:",
            "    findme:",
            "      - \"{{ ansible_virtualization_type }}_foo.conf\"",
            "      - \"default_foo.conf\"",
            "",
            "- name: read vars from first file found, use 'vars/' relative subdir",
            "  ansible.builtin.include_vars: \"{{lookup('ansible.builtin.first_found', params)}}\"",
            "  vars:",
            "    params:",
            "      files:",
            "        - '{{ ansible_distribution }}.yml'",
            "        - '{{ ansible_os_family }}.yml'",
            "        - default.yml",
            "      paths:",
            "        - 'vars'",
            "\"\"\"",
            "",
            "RETURN = \"\"\"",
            "  _raw:",
            "    description:",
            "      - path to file found",
            "    type: list",
            "    elements: path",
            "\"\"\"",
            "import os",
            "import re",
            "",
            "from collections.abc import Mapping, Sequence",
            "",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible.errors import AnsibleLookupError, AnsibleUndefinedVariable",
            "from ansible.module_utils.six import string_types",
            "from ansible.plugins.lookup import LookupBase",
            "",
            "",
            "def _split_on(terms, spliters=','):",
            "    termlist = []",
            "    if isinstance(terms, string_types):",
            "        termlist = re.split(r'[%s]' % ''.join(map(re.escape, spliters)), terms)",
            "    else:",
            "        # added since options will already listify",
            "        for t in terms:",
            "            termlist.extend(_split_on(t, spliters))",
            "    return termlist",
            "",
            "",
            "class LookupModule(LookupBase):",
            "",
            "    def _process_terms(self, terms, variables, kwargs):",
            "",
            "        total_search = []",
            "        skip = False",
            "",
            "        if not terms and kwargs:",
            "            terms = ['']",
            "",
            "        # can use a dict instead of list item to pass inline config",
            "        for term in terms:",
            "            if isinstance(term, Mapping):",
            "                self.set_options(var_options=variables, direct=term)",
            "            elif isinstance(term, string_types):",
            "                self.set_options(var_options=variables, direct=kwargs)",
            "            elif isinstance(term, Sequence):",
            "                partial, skip = self._process_terms(term, variables, kwargs)",
            "                total_search.extend(partial)",
            "                continue",
            "            else:",
            "                raise AnsibleLookupError(\"Invalid term supplied, can handle string, mapping or list of strings but got: %s for %s\" % (type(term), term))",
            "",
            "            files = self.get_option('files')",
            "            paths = self.get_option('paths')",
            "",
            "            # NOTE: this is used as 'global' but  can be set many times?!?!?",
            "            skip = self.get_option('skip')",
            "",
            "            # magic extra spliting to create lists",
            "            filelist = _split_on(files, ',;')",
            "            pathlist = _split_on(paths, ',:;')",
            "",
            "            # create search structure",
            "            if pathlist:",
            "                for path in pathlist:",
            "                    for fn in filelist:",
            "                        f = os.path.join(path, fn)",
            "                        total_search.append(f)",
            "            elif filelist:",
            "                # NOTE: this seems wrong, should be 'extend' as any option/entry can clobber all",
            "                total_search = filelist",
            "            else:",
            "                total_search.append(term)",
            "",
            "        return total_search, skip",
            "",
            "    def run(self, terms, variables, **kwargs):",
            "",
            "        total_search, skip = self._process_terms(terms, variables, kwargs)",
            "",
            "        # NOTE: during refactor noticed that the 'using a dict' as term",
            "        # is designed to only work with 'one' otherwise inconsistencies will appear.",
            "        # see other notes below.",
            "",
            "        # actually search",
            "        subdir = getattr(self, '_subdir', 'files')",
            "",
            "        path = None",
            "        for fn in total_search:",
            "",
            "            try:",
            "                fn = self._templar.template(fn)",
            "            except (AnsibleUndefinedVariable, UndefinedError):",
            "                continue",
            "",
            "            # get subdir if set by task executor, default to files otherwise",
            "            path = self.find_file_in_search_path(variables, subdir, fn, ignore_missing=True)",
            "",
            "            # exit if we find one!",
            "            if path is not None:",
            "                return [path]",
            "",
            "        # if we get here, no file was found",
            "        if skip:",
            "            # NOTE: global skip wont matter, only last 'skip' value in dict term",
            "            return []",
            "        raise AnsibleLookupError(\"No file was found when using first_found.\")"
        ],
        "afterPatchFile": [
            "# (c) 2013, seth vidal <skvidal@fedoraproject.org> red hat, inc",
            "# (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "DOCUMENTATION = \"\"\"",
            "    name: first_found",
            "    author: Seth Vidal (!UNKNOWN) <skvidal@fedoraproject.org>",
            "    version_added: historical",
            "    short_description: return first file found from list",
            "    description:",
            "      - This lookup checks a list of files and paths and returns the full path to the first combination found.",
            "      - As all lookups, when fed relative paths it will try use the current task's location first and go up the chain",
            "        to the containing locations of role / play / include and so on.",
            "      - The list of files has precedence over the paths searched.",
            "        For example, A task in a role has a 'file1' in the play's relative path, this will be used, 'file2' in role's relative path will not.",
            "      - Either a list of files C(_terms) or a key C(files) with a list of files is required for this plugin to operate.",
            "    notes:",
            "      - This lookup can be used in 'dual mode', either passing a list of file names or a dictionary that has C(files) and C(paths).",
            "    options:",
            "      _terms:",
            "        description: A list of file names.",
            "      files:",
            "        description: A list of file names.",
            "        type: list",
            "        elements: string",
            "        default: []",
            "      paths:",
            "        description: A list of paths in which to look for the files.",
            "        type: list",
            "        elements: string",
            "        default: []",
            "      skip:",
            "        type: boolean",
            "        default: False",
            "        description:",
            "          - When C(True), return an empty list when no files are matched.",
            "          - This is useful when used with C(with_first_found), as an empty list return to C(with_) calls",
            "            causes the calling task to be skipped.",
            "          - When used as a template via C(lookup) or C(query), setting I(skip=True) will *not* cause the task to skip.",
            "            Tasks must handle the empty list return from the template.",
            "          - When C(False) and C(lookup) or C(query) specifies  I(errors='ignore') all errors (including no file found,",
            "            but potentially others) return an empty string or an empty list respectively.",
            "          - When C(True) and C(lookup) or C(query) specifies I(errors='ignore'), no file found will return an empty",
            "            list and other potential errors return an empty string or empty list depending on the template call",
            "            (in other words return values of C(lookup) v C(query)).",
            "\"\"\"",
            "",
            "EXAMPLES = \"\"\"",
            "- name: Set _found_file to the first existing file, raising an error if a file is not found",
            "  ansible.builtin.set_fact:",
            "    _found_file: \"{{ lookup('ansible.builtin.first_found', findme) }}\"",
            "  vars:",
            "    findme:",
            "      - /path/to/foo.txt",
            "      - bar.txt  # will be looked in files/ dir relative to role and/or play",
            "      - /path/to/biz.txt",
            "",
            "- name: Set _found_file to the first existing file, or an empty list if no files found",
            "  ansible.builtin.set_fact:",
            "    _found_file: \"{{ lookup('ansible.builtin.first_found', files, paths=['/extra/path'], skip=True) }}\"",
            "  vars:",
            "    files:",
            "      - /path/to/foo.txt",
            "      - /path/to/bar.txt",
            "",
            "- name: Include tasks only if one of the files exist, otherwise skip the task",
            "  ansible.builtin.include_tasks:",
            "    file: \"{{ item }}\"",
            "  with_first_found:",
            "    - files:",
            "      - path/tasks.yaml",
            "      - path/other_tasks.yaml",
            "      skip: True",
            "",
            "- name: Include tasks only if one of the files exists, otherwise skip",
            "  ansible.builtin.include_tasks: '{{ tasks_file }}'",
            "  when: tasks_file != \"\"",
            "  vars:",
            "    tasks_file: \"{{ lookup('ansible.builtin.first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}\"",
            "",
            "- name: |",
            "        copy first existing file found to /some/file,",
            "        looking in relative directories from where the task is defined and",
            "        including any play objects that contain it",
            "  ansible.builtin.copy:",
            "    src: \"{{ lookup('ansible.builtin.first_found', findme) }}\"",
            "    dest: /some/file",
            "  vars:",
            "    findme:",
            "      - foo",
            "      - \"{{ inventory_hostname }}\"",
            "      - bar",
            "",
            "- name: same copy but specific paths",
            "  ansible.builtin.copy:",
            "    src: \"{{ lookup('ansible.builtin.first_found', params) }}\"",
            "    dest: /some/file",
            "  vars:",
            "    params:",
            "      files:",
            "        - foo",
            "        - \"{{ inventory_hostname }}\"",
            "        - bar",
            "      paths:",
            "        - /tmp/production",
            "        - /tmp/staging",
            "",
            "- name: INTERFACES | Create Ansible header for /etc/network/interfaces",
            "  ansible.builtin.template:",
            "    src: \"{{ lookup('ansible.builtin.first_found', findme)}}\"",
            "    dest: \"/etc/foo.conf\"",
            "  vars:",
            "    findme:",
            "      - \"{{ ansible_virtualization_type }}_foo.conf\"",
            "      - \"default_foo.conf\"",
            "",
            "- name: read vars from first file found, use 'vars/' relative subdir",
            "  ansible.builtin.include_vars: \"{{lookup('ansible.builtin.first_found', params)}}\"",
            "  vars:",
            "    params:",
            "      files:",
            "        - '{{ ansible_distribution }}.yml'",
            "        - '{{ ansible_os_family }}.yml'",
            "        - default.yml",
            "      paths:",
            "        - 'vars'",
            "\"\"\"",
            "",
            "RETURN = \"\"\"",
            "  _raw:",
            "    description:",
            "      - path to file found",
            "    type: list",
            "    elements: path",
            "\"\"\"",
            "import os",
            "",
            "from collections.abc import Mapping, Sequence",
            "",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible.errors import AnsibleLookupError, AnsibleUndefinedVariable",
            "from ansible.module_utils.six import string_types",
            "from ansible.plugins.lookup import LookupBase",
            "",
            "",
            "def _splitter(value, chars):",
            "    chars = set(chars)",
            "    v = ''",
            "    for c in value:",
            "        if c in chars:",
            "            yield v",
            "            v = ''",
            "            continue",
            "        v += c",
            "    yield v",
            "",
            "",
            "def _split_on(terms, spliters=','):",
            "    termlist = []",
            "    if isinstance(terms, string_types):",
            "        termlist = list(_splitter(terms, spliters))",
            "    else:",
            "        # added since options will already listify",
            "        for t in terms:",
            "            termlist.extend(_split_on(t, spliters))",
            "    return termlist",
            "",
            "",
            "class LookupModule(LookupBase):",
            "",
            "    def _process_terms(self, terms, variables, kwargs):",
            "",
            "        total_search = []",
            "        skip = False",
            "",
            "        if not terms and kwargs:",
            "            terms = ['']",
            "",
            "        # can use a dict instead of list item to pass inline config",
            "        for term in terms:",
            "            if isinstance(term, Mapping):",
            "                self.set_options(var_options=variables, direct=term)",
            "            elif isinstance(term, string_types):",
            "                self.set_options(var_options=variables, direct=kwargs)",
            "            elif isinstance(term, Sequence):",
            "                partial, skip = self._process_terms(term, variables, kwargs)",
            "                total_search.extend(partial)",
            "                continue",
            "            else:",
            "                raise AnsibleLookupError(\"Invalid term supplied, can handle string, mapping or list of strings but got: %s for %s\" % (type(term), term))",
            "",
            "            files = self.get_option('files')",
            "            paths = self.get_option('paths')",
            "",
            "            # NOTE: this is used as 'global' but  can be set many times?!?!?",
            "            skip = self.get_option('skip')",
            "",
            "            # magic extra spliting to create lists",
            "            filelist = _split_on(files, ',;')",
            "            pathlist = _split_on(paths, ',:;')",
            "",
            "            # create search structure",
            "            if pathlist:",
            "                for path in pathlist:",
            "                    for fn in filelist:",
            "                        f = os.path.join(path, fn)",
            "                        total_search.append(f)",
            "            elif filelist:",
            "                # NOTE: this seems wrong, should be 'extend' as any option/entry can clobber all",
            "                total_search = filelist",
            "            else:",
            "                total_search.append(term)",
            "",
            "        return total_search, skip",
            "",
            "    def run(self, terms, variables, **kwargs):",
            "",
            "        total_search, skip = self._process_terms(terms, variables, kwargs)",
            "",
            "        # NOTE: during refactor noticed that the 'using a dict' as term",
            "        # is designed to only work with 'one' otherwise inconsistencies will appear.",
            "        # see other notes below.",
            "",
            "        # actually search",
            "        subdir = getattr(self, '_subdir', 'files')",
            "",
            "        path = None",
            "        for fn in total_search:",
            "",
            "            try:",
            "                fn = self._templar.template(fn)",
            "            except (AnsibleUndefinedVariable, UndefinedError):",
            "                continue",
            "",
            "            # get subdir if set by task executor, default to files otherwise",
            "            path = self.find_file_in_search_path(variables, subdir, fn, ignore_missing=True)",
            "",
            "            # exit if we find one!",
            "            if path is not None:",
            "                return [path]",
            "",
            "        # if we get here, no file was found",
            "        if skip:",
            "            # NOTE: global skip wont matter, only last 'skip' value in dict term",
            "            return []",
            "        raise AnsibleLookupError(\"No file was found when using first_found.\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "139": [],
            "153": [
                "_split_on"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/template/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from numbers import Number"
            },
            "1": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from traceback import format_exc"
            },
            "2": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from jinja2.exceptions import TemplateSyntaxError, UndefinedError"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+from jinja2.exceptions import TemplateSyntaxError, UndefinedError, SecurityError"
            },
            "5": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " from jinja2.loaders import FileSystemLoader"
            },
            "6": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " from jinja2.nativetypes import NativeEnvironment"
            },
            "7": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " from jinja2.runtime import Context, StrictUndefined"
            },
            "8": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " from ansible.utils.display import Display"
            },
            "9": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": " from ansible.utils.listify import listify_lookup_plugin_terms"
            },
            "10": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": " from ansible.utils.native_jinja import NativeJinjaText"
            },
            "11": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from ansible.utils.unsafe_proxy import wrap_var"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+from ansible.utils.unsafe_proxy import wrap_var, AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText"
            },
            "13": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " display = Display()"
            },
            "15": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 365,
                "PatchRowcode": "     flag is checked post-templating, and (when set) will result in the"
            },
            "17": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 366,
                "PatchRowcode": "     final templated result being wrapped in AnsibleUnsafe."
            },
            "18": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 367,
                "PatchRowcode": "     '''"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+    _disallowed_callables = frozenset({"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+        AnsibleUnsafeText._strip_unsafe.__qualname__,"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        AnsibleUnsafeBytes._strip_unsafe.__qualname__,"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        NativeJinjaUnsafeText._strip_unsafe.__qualname__,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+    })"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "     def __init__(self, *args, **kwargs):"
            },
            "26": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "         super(AnsibleContext, self).__init__(*args, **kwargs)"
            },
            "27": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "         self.unsafe = False"
            },
            "28": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 377,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+    def call(self, obj, *args, **kwargs):"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+        if getattr(obj, '__qualname__', None) in self._disallowed_callables or obj in self._disallowed_callables:"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 380,
                "PatchRowcode": "+            raise SecurityError(f\"{obj!r} is not safely callable\")"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 381,
                "PatchRowcode": "+        return super().call(obj, *args, **kwargs)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 382,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 383,
                "PatchRowcode": "     def _is_unsafe(self, val):"
            },
            "35": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "         '''"
            },
            "36": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "         Our helper function, which will also recursively check dict and"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import datetime",
            "import os",
            "import pwd",
            "import re",
            "import time",
            "",
            "from collections.abc import Iterator, Sequence, Mapping, MappingView, MutableMapping",
            "from contextlib import contextmanager",
            "from numbers import Number",
            "from traceback import format_exc",
            "",
            "from jinja2.exceptions import TemplateSyntaxError, UndefinedError",
            "from jinja2.loaders import FileSystemLoader",
            "from jinja2.nativetypes import NativeEnvironment",
            "from jinja2.runtime import Context, StrictUndefined",
            "",
            "from ansible import constants as C",
            "from ansible.errors import (",
            "    AnsibleAssertionError,",
            "    AnsibleError,",
            "    AnsibleFilterError,",
            "    AnsibleLookupError,",
            "    AnsibleOptionsError,",
            "    AnsibleUndefinedVariable,",
            ")",
            "from ansible.module_utils.six import string_types, text_type",
            "from ansible.module_utils._text import to_native, to_text, to_bytes",
            "from ansible.module_utils.common.collections import is_sequence",
            "from ansible.plugins.loader import filter_loader, lookup_loader, test_loader",
            "from ansible.template.native_helpers import ansible_native_concat, ansible_eval_concat, ansible_concat",
            "from ansible.template.template import AnsibleJ2Template",
            "from ansible.template.vars import AnsibleJ2Vars",
            "from ansible.utils.display import Display",
            "from ansible.utils.listify import listify_lookup_plugin_terms",
            "from ansible.utils.native_jinja import NativeJinjaText",
            "from ansible.utils.unsafe_proxy import wrap_var",
            "",
            "display = Display()",
            "",
            "",
            "__all__ = ['Templar', 'generate_ansible_template_vars']",
            "",
            "# Primitive Types which we don't want Jinja to convert to strings.",
            "NON_TEMPLATED_TYPES = (bool, Number)",
            "",
            "JINJA2_OVERRIDE = '#jinja2:'",
            "",
            "JINJA2_BEGIN_TOKENS = frozenset(('variable_begin', 'block_begin', 'comment_begin', 'raw_begin'))",
            "JINJA2_END_TOKENS = frozenset(('variable_end', 'block_end', 'comment_end', 'raw_end'))",
            "",
            "RANGE_TYPE = type(range(0))",
            "",
            "",
            "def generate_ansible_template_vars(path, fullpath=None, dest_path=None):",
            "",
            "    if fullpath is None:",
            "        b_path = to_bytes(path)",
            "    else:",
            "        b_path = to_bytes(fullpath)",
            "",
            "    try:",
            "        template_uid = pwd.getpwuid(os.stat(b_path).st_uid).pw_name",
            "    except (KeyError, TypeError):",
            "        template_uid = os.stat(b_path).st_uid",
            "",
            "    temp_vars = {",
            "        'template_host': to_text(os.uname()[1]),",
            "        'template_path': path,",
            "        'template_mtime': datetime.datetime.fromtimestamp(os.path.getmtime(b_path)),",
            "        'template_uid': to_text(template_uid),",
            "        'template_run_date': datetime.datetime.now(),",
            "        'template_destpath': to_native(dest_path) if dest_path else None,",
            "    }",
            "",
            "    if fullpath is None:",
            "        temp_vars['template_fullpath'] = os.path.abspath(path)",
            "    else:",
            "        temp_vars['template_fullpath'] = fullpath",
            "",
            "    managed_default = C.DEFAULT_MANAGED_STR",
            "    managed_str = managed_default.format(",
            "        host=temp_vars['template_host'],",
            "        uid=temp_vars['template_uid'],",
            "        file=temp_vars['template_path'],",
            "    )",
            "    temp_vars['ansible_managed'] = to_text(time.strftime(to_native(managed_str), time.localtime(os.path.getmtime(b_path))))",
            "",
            "    return temp_vars",
            "",
            "",
            "def _escape_backslashes(data, jinja_env):",
            "    \"\"\"Double backslashes within jinja2 expressions",
            "",
            "    A user may enter something like this in a playbook::",
            "",
            "      debug:",
            "        msg: \"Test Case 1\\\\3; {{ test1_name | regex_replace('^(.*)_name$', '\\\\1')}}\"",
            "",
            "    The string inside of the {{ gets interpreted multiple times First by yaml.",
            "    Then by python.  And finally by jinja2 as part of it's variable.  Because",
            "    it is processed by both python and jinja2, the backslash escaped",
            "    characters get unescaped twice.  This means that we'd normally have to use",
            "    four backslashes to escape that.  This is painful for playbook authors as",
            "    they have to remember different rules for inside vs outside of a jinja2",
            "    expression (The backslashes outside of the \"{{ }}\" only get processed by",
            "    yaml and python.  So they only need to be escaped once).  The following",
            "    code fixes this by automatically performing the extra quoting of",
            "    backslashes inside of a jinja2 expression.",
            "",
            "    \"\"\"",
            "    if '\\\\' in data and '{{' in data:",
            "        new_data = []",
            "        d2 = jinja_env.preprocess(data)",
            "        in_var = False",
            "",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] == 'variable_begin':",
            "                in_var = True",
            "                new_data.append(token[2])",
            "            elif token[1] == 'variable_end':",
            "                in_var = False",
            "                new_data.append(token[2])",
            "            elif in_var and token[1] == 'string':",
            "                # Double backslashes only if we're inside of a jinja2 variable",
            "                new_data.append(token[2].replace('\\\\', '\\\\\\\\'))",
            "            else:",
            "                new_data.append(token[2])",
            "",
            "        data = ''.join(new_data)",
            "",
            "    return data",
            "",
            "",
            "def _create_overlay(data, overrides, jinja_env):",
            "    if overrides is None:",
            "        overrides = {}",
            "",
            "    try:",
            "        has_override_header = data.startswith(JINJA2_OVERRIDE)",
            "    except (TypeError, AttributeError):",
            "        has_override_header = False",
            "",
            "    if overrides or has_override_header:",
            "        overlay = jinja_env.overlay(**overrides)",
            "    else:",
            "        overlay = jinja_env",
            "",
            "    # Get jinja env overrides from template",
            "    if has_override_header:",
            "        eol = data.find('\\n')",
            "        line = data[len(JINJA2_OVERRIDE):eol]",
            "        data = data[eol + 1:]",
            "        for pair in line.split(','):",
            "            if ':' not in pair:",
            "                raise AnsibleError(\"failed to parse jinja2 override '%s'.\"",
            "                                   \" Did you use something different from colon as key-value separator?\" % pair.strip())",
            "            (key, val) = pair.split(':', 1)",
            "            key = key.strip()",
            "            if hasattr(overlay, key):",
            "                setattr(overlay, key, ast.literal_eval(val.strip()))",
            "            else:",
            "                display.warning(f\"Could not find Jinja2 environment setting to override: '{key}'\")",
            "",
            "    return data, overlay",
            "",
            "",
            "def is_possibly_template(data, jinja_env):",
            "    \"\"\"Determines if a string looks like a template, by seeing if it",
            "    contains a jinja2 start delimiter. Does not guarantee that the string",
            "    is actually a template.",
            "",
            "    This is different than ``is_template`` which is more strict.",
            "    This method may return ``True`` on a string that is not templatable.",
            "",
            "    Useful when guarding passing a string for templating, but when",
            "    you want to allow the templating engine to make the final",
            "    assessment which may result in ``TemplateSyntaxError``.",
            "    \"\"\"",
            "    if isinstance(data, string_types):",
            "        for marker in (jinja_env.block_start_string, jinja_env.variable_start_string, jinja_env.comment_start_string):",
            "            if marker in data:",
            "                return True",
            "    return False",
            "",
            "",
            "def is_template(data, jinja_env):",
            "    \"\"\"This function attempts to quickly detect whether a value is a jinja2",
            "    template. To do so, we look for the first 2 matching jinja2 tokens for",
            "    start and end delimiters.",
            "    \"\"\"",
            "    found = None",
            "    start = True",
            "    comment = False",
            "    d2 = jinja_env.preprocess(data)",
            "",
            "    # Quick check to see if this is remotely like a template before doing",
            "    # more expensive investigation.",
            "    if not is_possibly_template(d2, jinja_env):",
            "        return False",
            "",
            "    # This wraps a lot of code, but this is due to lex returning a generator",
            "    # so we may get an exception at any part of the loop",
            "    try:",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] in JINJA2_BEGIN_TOKENS:",
            "                if start and token[1] == 'comment_begin':",
            "                    # Comments can wrap other token types",
            "                    comment = True",
            "                start = False",
            "                # Example: variable_end -> variable",
            "                found = token[1].split('_')[0]",
            "            elif token[1] in JINJA2_END_TOKENS:",
            "                if token[1].split('_')[0] == found:",
            "                    return True",
            "                elif comment:",
            "                    continue",
            "                return False",
            "    except TemplateSyntaxError:",
            "        return False",
            "",
            "    return False",
            "",
            "",
            "def _count_newlines_from_end(in_str):",
            "    '''",
            "    Counts the number of newlines at the end of a string. This is used during",
            "    the jinja2 templating to ensure the count matches the input, since some newlines",
            "    may be thrown away during the templating.",
            "    '''",
            "",
            "    try:",
            "        i = len(in_str)",
            "        j = i - 1",
            "        while in_str[j] == '\\n':",
            "            j -= 1",
            "        return i - 1 - j",
            "    except IndexError:",
            "        # Uncommon cases: zero length string and string containing only newlines",
            "        return i",
            "",
            "",
            "def recursive_check_defined(item):",
            "    from jinja2.runtime import Undefined",
            "",
            "    if isinstance(item, MutableMapping):",
            "        for key in item:",
            "            recursive_check_defined(item[key])",
            "    elif isinstance(item, list):",
            "        for i in item:",
            "            recursive_check_defined(i)",
            "    else:",
            "        if isinstance(item, Undefined):",
            "            raise AnsibleFilterError(\"{0} is undefined\".format(item))",
            "",
            "",
            "def _is_rolled(value):",
            "    \"\"\"Helper method to determine if something is an unrolled generator,",
            "    iterator, or similar object",
            "    \"\"\"",
            "    return (",
            "        isinstance(value, Iterator) or",
            "        isinstance(value, MappingView) or",
            "        isinstance(value, RANGE_TYPE)",
            "    )",
            "",
            "",
            "def _unroll_iterator(func):",
            "    \"\"\"Wrapper function, that intercepts the result of a templating",
            "    and auto unrolls a generator, so that users are not required to",
            "    explicitly use ``|list`` to unroll.",
            "    \"\"\"",
            "    def wrapper(*args, **kwargs):",
            "        ret = func(*args, **kwargs)",
            "        if _is_rolled(ret):",
            "            return list(ret)",
            "        return ret",
            "",
            "    return _update_wrapper(wrapper, func)",
            "",
            "",
            "def _update_wrapper(wrapper, func):",
            "    # This code is duplicated from ``functools.update_wrapper`` from Py3.7.",
            "    # ``functools.update_wrapper`` was failing when the func was ``functools.partial``",
            "    for attr in ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'):",
            "        try:",
            "            value = getattr(func, attr)",
            "        except AttributeError:",
            "            pass",
            "        else:",
            "            setattr(wrapper, attr, value)",
            "    for attr in ('__dict__',):",
            "        getattr(wrapper, attr).update(getattr(func, attr, {}))",
            "    wrapper.__wrapped__ = func",
            "    return wrapper",
            "",
            "",
            "def _wrap_native_text(func):",
            "    \"\"\"Wrapper function, that intercepts the result of a filter",
            "    and wraps it into NativeJinjaText which is then used",
            "    in ``ansible_native_concat`` to indicate that it is a text",
            "    which should not be passed into ``literal_eval``.",
            "    \"\"\"",
            "    def wrapper(*args, **kwargs):",
            "        ret = func(*args, **kwargs)",
            "        return NativeJinjaText(ret)",
            "",
            "    return _update_wrapper(wrapper, func)",
            "",
            "",
            "class AnsibleUndefined(StrictUndefined):",
            "    '''",
            "    A custom Undefined class, which returns further Undefined objects on access,",
            "    rather than throwing an exception.",
            "    '''",
            "    def __getattr__(self, name):",
            "        if name == '__UNSAFE__':",
            "            # AnsibleUndefined should never be assumed to be unsafe",
            "            # This prevents ``hasattr(val, '__UNSAFE__')`` from evaluating to ``True``",
            "            raise AttributeError(name)",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "    def __getitem__(self, key):",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "    def __repr__(self):",
            "        return 'AnsibleUndefined(hint={0!r}, obj={1!r}, name={2!r})'.format(",
            "            self._undefined_hint,",
            "            self._undefined_obj,",
            "            self._undefined_name",
            "        )",
            "",
            "    def __contains__(self, item):",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "",
            "class AnsibleContext(Context):",
            "    '''",
            "    A custom context, which intercepts resolve_or_missing() calls and sets a flag",
            "    internally if any variable lookup returns an AnsibleUnsafe value. This",
            "    flag is checked post-templating, and (when set) will result in the",
            "    final templated result being wrapped in AnsibleUnsafe.",
            "    '''",
            "    def __init__(self, *args, **kwargs):",
            "        super(AnsibleContext, self).__init__(*args, **kwargs)",
            "        self.unsafe = False",
            "",
            "    def _is_unsafe(self, val):",
            "        '''",
            "        Our helper function, which will also recursively check dict and",
            "        list entries due to the fact that they may be repr'd and contain",
            "        a key or value which contains jinja2 syntax and would otherwise",
            "        lose the AnsibleUnsafe value.",
            "        '''",
            "        if isinstance(val, dict):",
            "            for key in val.keys():",
            "                if self._is_unsafe(val[key]):",
            "                    return True",
            "        elif isinstance(val, list):",
            "            for item in val:",
            "                if self._is_unsafe(item):",
            "                    return True",
            "        elif getattr(val, '__UNSAFE__', False) is True:",
            "            return True",
            "        return False",
            "",
            "    def _update_unsafe(self, val):",
            "        if val is not None and not self.unsafe and self._is_unsafe(val):",
            "            self.unsafe = True",
            "",
            "    def resolve_or_missing(self, key):",
            "        val = super(AnsibleContext, self).resolve_or_missing(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "    def get_all(self):",
            "        \"\"\"Return the complete context as a dict including the exported",
            "        variables. For optimizations reasons this might not return an",
            "        actual copy so be careful with using it.",
            "",
            "        This is to prevent from running ``AnsibleJ2Vars`` through dict():",
            "",
            "            ``dict(self.parent, **self.vars)``",
            "",
            "        In Ansible this means that ALL variables would be templated in the",
            "        process of re-creating the parent because ``AnsibleJ2Vars`` templates",
            "        each variable in its ``__getitem__`` method. Instead we re-create the",
            "        parent via ``AnsibleJ2Vars.add_locals`` that creates a new",
            "        ``AnsibleJ2Vars`` copy without templating each variable.",
            "",
            "        This will prevent unnecessarily templating unused variables in cases",
            "        like setting a local variable and passing it to {% include %}",
            "        in a template.",
            "",
            "        Also see ``AnsibleJ2Template``and",
            "        https://github.com/pallets/jinja/commit/d67f0fd4cc2a4af08f51f4466150d49da7798729",
            "        \"\"\"",
            "        if not self.vars:",
            "            return self.parent",
            "        if not self.parent:",
            "            return self.vars",
            "",
            "        if isinstance(self.parent, AnsibleJ2Vars):",
            "            return self.parent.add_locals(self.vars)",
            "        else:",
            "            # can this happen in Ansible?",
            "            return dict(self.parent, **self.vars)",
            "",
            "",
            "class JinjaPluginIntercept(MutableMapping):",
            "    ''' Simulated dict class that loads Jinja2Plugins at request",
            "        otherwise all plugins would need to be loaded a priori.",
            "",
            "        NOTE: plugin_loader still loads all 'builtin/legacy' at",
            "        start so only collection plugins are really at request.",
            "    '''",
            "",
            "    def __init__(self, delegatee, pluginloader, *args, **kwargs):",
            "",
            "        super(JinjaPluginIntercept, self).__init__(*args, **kwargs)",
            "",
            "        self._pluginloader = pluginloader",
            "",
            "        # Jinja environment's mapping of known names (initially just J2 builtins)",
            "        self._delegatee = delegatee",
            "",
            "        # our names take precedence over Jinja's, but let things we've tried to resolve skip the pluginloader",
            "        self._seen_it = set()",
            "",
            "    def __getitem__(self, key):",
            "",
            "        if not isinstance(key, string_types):",
            "            raise ValueError('key must be a string, got %s instead' % type(key))",
            "",
            "        original_exc = None",
            "        if key not in self._seen_it:",
            "            # this looks too early to set this- it isn't. Setting it here keeps requests for Jinja builtins from",
            "            # going through the pluginloader more than once, which is extremely slow for something that won't ever succeed.",
            "            self._seen_it.add(key)",
            "            plugin = None",
            "            try:",
            "                plugin = self._pluginloader.get(key)",
            "            except (AnsibleError, KeyError) as e:",
            "                original_exc = e",
            "            except Exception as e:",
            "                display.vvvv('Unexpected plugin load (%s) exception: %s' % (key, to_native(e)))",
            "                raise e",
            "",
            "            # if a plugin was found/loaded",
            "            if plugin:",
            "                # set in filter cache and avoid expensive plugin load",
            "                self._delegatee[key] = plugin.j2_function",
            "",
            "        # raise template syntax error if we could not find ours or jinja2 one",
            "        try:",
            "            func = self._delegatee[key]",
            "        except KeyError as e:",
            "            self._seen_it.remove(key)",
            "            raise TemplateSyntaxError('Could not load \"%s\": %s' % (key, to_native(original_exc or e)), 0)",
            "",
            "        # if i do have func and it is a filter, it nees wrapping",
            "        if self._pluginloader.type == 'filter':",
            "            # filter need wrapping",
            "            if key in C.STRING_TYPE_FILTERS:",
            "                # avoid litera_eval when you WANT strings",
            "                func = _wrap_native_text(func)",
            "            else:",
            "                # conditionally unroll iterators/generators to avoid having to use `|list` after every filter",
            "                func = _unroll_iterator(func)",
            "",
            "        return func",
            "",
            "    def __setitem__(self, key, value):",
            "        return self._delegatee.__setitem__(key, value)",
            "",
            "    def __delitem__(self, key):",
            "        raise NotImplementedError()",
            "",
            "    def __iter__(self):",
            "        # not strictly accurate since we're not counting dynamically-loaded values",
            "        return iter(self._delegatee)",
            "",
            "    def __len__(self):",
            "        # not strictly accurate since we're not counting dynamically-loaded values",
            "        return len(self._delegatee)",
            "",
            "",
            "def _fail_on_undefined(data):",
            "    \"\"\"Recursively find an undefined value in a nested data structure",
            "    and properly raise the undefined exception.",
            "    \"\"\"",
            "    if isinstance(data, Mapping):",
            "        for value in data.values():",
            "            _fail_on_undefined(value)",
            "    elif is_sequence(data):",
            "        for item in data:",
            "            _fail_on_undefined(item)",
            "    else:",
            "        if isinstance(data, StrictUndefined):",
            "            # To actually raise the undefined exception we need to",
            "            # access the undefined object otherwise the exception would",
            "            # be raised on the next access which might not be properly",
            "            # handled.",
            "            # See https://github.com/ansible/ansible/issues/52158",
            "            # and StrictUndefined implementation in upstream Jinja2.",
            "            str(data)",
            "    return data",
            "",
            "",
            "@_unroll_iterator",
            "def _ansible_finalize(thing):",
            "    \"\"\"A custom finalize function for jinja2, which prevents None from being",
            "    returned. This avoids a string of ``\"None\"`` as ``None`` has no",
            "    importance in YAML.",
            "",
            "    The function is decorated with ``_unroll_iterator`` so that users are not",
            "    required to explicitly use ``|list`` to unroll a generator. This only",
            "    affects the scenario where the final result of templating",
            "    is a generator, e.g. ``range``, ``dict.items()`` and so on. Filters",
            "    which can produce a generator in the middle of a template are already",
            "    wrapped with ``_unroll_generator`` in ``JinjaPluginIntercept``.",
            "    \"\"\"",
            "    return thing if _fail_on_undefined(thing) is not None else ''",
            "",
            "",
            "class AnsibleEnvironment(NativeEnvironment):",
            "    '''",
            "    Our custom environment, which simply allows us to override the class-level",
            "    values for the Template and Context classes used by jinja2 internally.",
            "    '''",
            "    context_class = AnsibleContext",
            "    template_class = AnsibleJ2Template",
            "    concat = staticmethod(ansible_eval_concat)  # type: ignore[assignment]",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "",
            "        self.filters = JinjaPluginIntercept(self.filters, filter_loader)",
            "        self.tests = JinjaPluginIntercept(self.tests, test_loader)",
            "",
            "        self.trim_blocks = True",
            "",
            "        self.undefined = AnsibleUndefined",
            "        self.finalize = _ansible_finalize",
            "",
            "",
            "class AnsibleNativeEnvironment(AnsibleEnvironment):",
            "    concat = staticmethod(ansible_native_concat)  # type: ignore[assignment]",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.finalize = _unroll_iterator(_fail_on_undefined)",
            "",
            "",
            "class Templar:",
            "    '''",
            "    The main class for templating, with the main entry-point of template().",
            "    '''",
            "",
            "    def __init__(self, loader, shared_loader_obj=None, variables=None):",
            "        if shared_loader_obj is not None:",
            "            display.deprecated(",
            "                \"The `shared_loader_obj` option to `Templar` is no longer functional, \"",
            "                \"ansible.plugins.loader is used directly instead.\",",
            "                version='2.16',",
            "            )",
            "",
            "        self._loader = loader",
            "        self._available_variables = {} if variables is None else variables",
            "",
            "        self._fail_on_undefined_errors = C.DEFAULT_UNDEFINED_VAR_BEHAVIOR",
            "",
            "        environment_class = AnsibleNativeEnvironment if C.DEFAULT_JINJA2_NATIVE else AnsibleEnvironment",
            "",
            "        self.environment = environment_class(",
            "            extensions=self._get_extensions(),",
            "            loader=FileSystemLoader(loader.get_basedir() if loader else '.'),",
            "        )",
            "        self.environment.template_class.environment_class = environment_class",
            "",
            "        # jinja2 global is inconsistent across versions, this normalizes them",
            "        self.environment.globals['dict'] = dict",
            "",
            "        # Custom globals",
            "        self.environment.globals['lookup'] = self._lookup",
            "        self.environment.globals['query'] = self.environment.globals['q'] = self._query_lookup",
            "        self.environment.globals['now'] = self._now_datetime",
            "        self.environment.globals['undef'] = self._make_undefined",
            "",
            "        # the current rendering context under which the templar class is working",
            "        self.cur_context = None",
            "",
            "        # FIXME this regex should be re-compiled each time variable_start_string and variable_end_string are changed",
            "        self.SINGLE_VAR = re.compile(r\"^%s\\s*(\\w*)\\s*%s$\" % (self.environment.variable_start_string, self.environment.variable_end_string))",
            "",
            "        self.jinja2_native = C.DEFAULT_JINJA2_NATIVE",
            "",
            "    def copy_with_new_env(self, environment_class=AnsibleEnvironment, **kwargs):",
            "        r\"\"\"Creates a new copy of Templar with a new environment.",
            "",
            "        :kwarg environment_class: Environment class used for creating a new environment.",
            "        :kwarg \\*\\*kwargs: Optional arguments for the new environment that override existing",
            "            environment attributes.",
            "",
            "        :returns: Copy of Templar with updated environment.",
            "        \"\"\"",
            "        # We need to use __new__ to skip __init__, mainly not to create a new",
            "        # environment there only to override it below",
            "        new_env = object.__new__(environment_class)",
            "        new_env.__dict__.update(self.environment.__dict__)",
            "",
            "        new_templar = object.__new__(Templar)",
            "        new_templar.__dict__.update(self.__dict__)",
            "        new_templar.environment = new_env",
            "",
            "        new_templar.jinja2_native = environment_class is AnsibleNativeEnvironment",
            "",
            "        mapping = {",
            "            'available_variables': new_templar,",
            "            'searchpath': new_env.loader,",
            "        }",
            "",
            "        for key, value in kwargs.items():",
            "            obj = mapping.get(key, new_env)",
            "            try:",
            "                if value is not None:",
            "                    setattr(obj, key, value)",
            "            except AttributeError:",
            "                # Ignore invalid attrs",
            "                pass",
            "",
            "        return new_templar",
            "",
            "    def _get_extensions(self):",
            "        '''",
            "        Return jinja2 extensions to load.",
            "",
            "        If some extensions are set via jinja_extensions in ansible.cfg, we try",
            "        to load them with the jinja environment.",
            "        '''",
            "",
            "        jinja_exts = []",
            "        if C.DEFAULT_JINJA2_EXTENSIONS:",
            "            # make sure the configuration directive doesn't contain spaces",
            "            # and split extensions in an array",
            "            jinja_exts = C.DEFAULT_JINJA2_EXTENSIONS.replace(\" \", \"\").split(',')",
            "",
            "        return jinja_exts",
            "",
            "    @property",
            "    def available_variables(self):",
            "        return self._available_variables",
            "",
            "    @available_variables.setter",
            "    def available_variables(self, variables):",
            "        '''",
            "        Sets the list of template variables this Templar instance will use",
            "        to template things, so we don't have to pass them around between",
            "        internal methods. We also clear the template cache here, as the variables",
            "        are being changed.",
            "        '''",
            "",
            "        if not isinstance(variables, Mapping):",
            "            raise AnsibleAssertionError(\"the type of 'variables' should be a Mapping but was a %s\" % (type(variables)))",
            "        self._available_variables = variables",
            "",
            "    @contextmanager",
            "    def set_temporary_context(self, **kwargs):",
            "        \"\"\"Context manager used to set temporary templating context, without having to worry about resetting",
            "        original values afterward",
            "",
            "        Use a keyword that maps to the attr you are setting. Applies to ``self.environment`` by default, to",
            "        set context on another object, it must be in ``mapping``.",
            "        \"\"\"",
            "        mapping = {",
            "            'available_variables': self,",
            "            'searchpath': self.environment.loader,",
            "        }",
            "        original = {}",
            "",
            "        for key, value in kwargs.items():",
            "            obj = mapping.get(key, self.environment)",
            "            try:",
            "                original[key] = getattr(obj, key)",
            "                if value is not None:",
            "                    setattr(obj, key, value)",
            "            except AttributeError:",
            "                # Ignore invalid attrs",
            "                pass",
            "",
            "        yield",
            "",
            "        for key in original:",
            "            obj = mapping.get(key, self.environment)",
            "            setattr(obj, key, original[key])",
            "",
            "    def template(self, variable, convert_bare=False, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None,",
            "                 convert_data=True, static_vars=None, cache=None, disable_lookups=False):",
            "        '''",
            "        Templates (possibly recursively) any given data as input. If convert_bare is",
            "        set to True, the given data will be wrapped as a jinja2 variable ('{{foo}}')",
            "        before being sent through the template engine.",
            "        '''",
            "        static_vars = [] if static_vars is None else static_vars",
            "",
            "        if cache is not None:",
            "            display.deprecated(\"The `cache` option to `Templar.template` is no longer functional, and will be removed in a future release.\", version='2.18')",
            "",
            "        # Don't template unsafe variables, just return them.",
            "        if hasattr(variable, '__UNSAFE__'):",
            "            return variable",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        if convert_bare:",
            "            variable = self._convert_bare_variable(variable)",
            "",
            "        if isinstance(variable, string_types):",
            "            if not self.is_possibly_template(variable, overrides):",
            "                return variable",
            "",
            "            # Check to see if the string we are trying to render is just referencing a single",
            "            # var.  In this case we don't want to accidentally change the type of the variable",
            "            # to a string by using the jinja template renderer. We just want to pass it.",
            "            only_one = self.SINGLE_VAR.match(variable)",
            "            if only_one:",
            "                var_name = only_one.group(1)",
            "                if var_name in self._available_variables:",
            "                    resolved_val = self._available_variables[var_name]",
            "                    if isinstance(resolved_val, NON_TEMPLATED_TYPES):",
            "                        return resolved_val",
            "                    elif resolved_val is None:",
            "                        return C.DEFAULT_NULL_REPRESENTATION",
            "",
            "            result = self.do_template(",
            "                variable,",
            "                preserve_trailing_newlines=preserve_trailing_newlines,",
            "                escape_backslashes=escape_backslashes,",
            "                fail_on_undefined=fail_on_undefined,",
            "                overrides=overrides,",
            "                disable_lookups=disable_lookups,",
            "                convert_data=convert_data,",
            "            )",
            "",
            "            return result",
            "",
            "        elif is_sequence(variable):",
            "            return [self.template(",
            "                v,",
            "                preserve_trailing_newlines=preserve_trailing_newlines,",
            "                fail_on_undefined=fail_on_undefined,",
            "                overrides=overrides,",
            "                disable_lookups=disable_lookups,",
            "            ) for v in variable]",
            "        elif isinstance(variable, Mapping):",
            "            d = {}",
            "            # we don't use iteritems() here to avoid problems if the underlying dict",
            "            # changes sizes due to the templating, which can happen with hostvars",
            "            for k in variable.keys():",
            "                if k not in static_vars:",
            "                    d[k] = self.template(",
            "                        variable[k],",
            "                        preserve_trailing_newlines=preserve_trailing_newlines,",
            "                        fail_on_undefined=fail_on_undefined,",
            "                        overrides=overrides,",
            "                        disable_lookups=disable_lookups,",
            "                    )",
            "                else:",
            "                    d[k] = variable[k]",
            "            return d",
            "        else:",
            "            return variable",
            "",
            "    def is_template(self, data):",
            "        '''lets us know if data has a template'''",
            "        if isinstance(data, string_types):",
            "            return is_template(data, self.environment)",
            "        elif isinstance(data, (list, tuple)):",
            "            for v in data:",
            "                if self.is_template(v):",
            "                    return True",
            "        elif isinstance(data, dict):",
            "            for k in data:",
            "                if self.is_template(k) or self.is_template(data[k]):",
            "                    return True",
            "        return False",
            "",
            "    templatable = is_template",
            "",
            "    def is_possibly_template(self, data, overrides=None):",
            "        data, env = _create_overlay(data, overrides, self.environment)",
            "        return is_possibly_template(data, env)",
            "",
            "    def _convert_bare_variable(self, variable):",
            "        '''",
            "        Wraps a bare string, which may have an attribute portion (ie. foo.bar)",
            "        in jinja2 variable braces so that it is evaluated properly.",
            "        '''",
            "",
            "        if isinstance(variable, string_types):",
            "            contains_filters = \"|\" in variable",
            "            first_part = variable.split(\"|\")[0].split(\".\")[0].split(\"[\")[0]",
            "            if (contains_filters or first_part in self._available_variables) and self.environment.variable_start_string not in variable:",
            "                return \"%s%s%s\" % (self.environment.variable_start_string, variable, self.environment.variable_end_string)",
            "",
            "        # the variable didn't meet the conditions to be converted,",
            "        # so just return it as-is",
            "        return variable",
            "",
            "    def _fail_lookup(self, name, *args, **kwargs):",
            "        raise AnsibleError(\"The lookup `%s` was found, however lookups were disabled from templating\" % name)",
            "",
            "    def _now_datetime(self, utc=False, fmt=None):",
            "        '''jinja2 global function to return current datetime, potentially formatted via strftime'''",
            "        if utc:",
            "            now = datetime.datetime.utcnow()",
            "        else:",
            "            now = datetime.datetime.now()",
            "",
            "        if fmt:",
            "            return now.strftime(fmt)",
            "",
            "        return now",
            "",
            "    def _query_lookup(self, name, /, *args, **kwargs):",
            "        ''' wrapper for lookup, force wantlist true'''",
            "        kwargs['wantlist'] = True",
            "        return self._lookup(name, *args, **kwargs)",
            "",
            "    def _lookup(self, name, /, *args, **kwargs):",
            "        instance = lookup_loader.get(name, loader=self._loader, templar=self)",
            "",
            "        if instance is None:",
            "            raise AnsibleError(\"lookup plugin (%s) not found\" % name)",
            "",
            "        wantlist = kwargs.pop('wantlist', False)",
            "        allow_unsafe = kwargs.pop('allow_unsafe', C.DEFAULT_ALLOW_UNSAFE_LOOKUPS)",
            "        errors = kwargs.pop('errors', 'strict')",
            "",
            "        loop_terms = listify_lookup_plugin_terms(terms=args, templar=self, fail_on_undefined=True, convert_bare=False)",
            "        # safely catch run failures per #5059",
            "        try:",
            "            ran = instance.run(loop_terms, variables=self._available_variables, **kwargs)",
            "        except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "            raise AnsibleUndefinedVariable(e)",
            "        except AnsibleOptionsError as e:",
            "            # invalid options given to lookup, just reraise",
            "            raise e",
            "        except AnsibleLookupError as e:",
            "            # lookup handled error but still decided to bail",
            "            msg = 'Lookup failed but the error is being ignored: %s' % to_native(e)",
            "            if errors == 'warn':",
            "                display.warning(msg)",
            "            elif errors == 'ignore':",
            "                display.display(msg, log_only=True)",
            "            else:",
            "                raise e",
            "            return [] if wantlist else None",
            "        except Exception as e:",
            "            # errors not handled by lookup",
            "            msg = u\"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s\" % \\",
            "                  (name, type(e), to_text(e))",
            "            if errors == 'warn':",
            "                display.warning(msg)",
            "            elif errors == 'ignore':",
            "                display.display(msg, log_only=True)",
            "            else:",
            "                display.vvv('exception during Jinja2 execution: {0}'.format(format_exc()))",
            "                raise AnsibleError(to_native(msg), orig_exc=e)",
            "            return [] if wantlist else None",
            "",
            "        if not is_sequence(ran):",
            "            display.deprecated(",
            "                f'The lookup plugin \\'{name}\\' was expected to return a list, got \\'{type(ran)}\\' instead. '",
            "                f'The lookup plugin \\'{name}\\' needs to be changed to return a list. '",
            "                'This will be an error in Ansible 2.18',",
            "                version='2.18'",
            "            )",
            "",
            "        if ran and allow_unsafe is False:",
            "            if self.cur_context:",
            "                self.cur_context.unsafe = True",
            "",
            "            if wantlist:",
            "                return wrap_var(ran)",
            "",
            "            try:",
            "                if isinstance(ran[0], NativeJinjaText):",
            "                    ran = wrap_var(NativeJinjaText(\",\".join(ran)))",
            "                else:",
            "                    ran = wrap_var(\",\".join(ran))",
            "            except TypeError:",
            "                # Lookup Plugins should always return lists.  Throw an error if that's not",
            "                # the case:",
            "                if not isinstance(ran, Sequence):",
            "                    raise AnsibleError(\"The lookup plugin '%s' did not return a list.\"",
            "                                       % name)",
            "",
            "                # The TypeError we can recover from is when the value *inside* of the list",
            "                # is not a string",
            "                if len(ran) == 1:",
            "                    ran = wrap_var(ran[0])",
            "                else:",
            "                    ran = wrap_var(ran)",
            "            except KeyError:",
            "                # Lookup Plugin returned a dict.  Return comma-separated string of keys",
            "                # for backwards compat.",
            "                # FIXME this can be removed when support for non-list return types is removed.",
            "                # See https://github.com/ansible/ansible/pull/77789",
            "                ran = wrap_var(\",\".join(ran))",
            "",
            "        return ran",
            "",
            "    def _make_undefined(self, hint=None):",
            "        from jinja2.runtime import Undefined",
            "",
            "        if hint is None or isinstance(hint, Undefined) or hint == '':",
            "            hint = \"Mandatory variable has not been overridden\"",
            "        return AnsibleUndefined(hint)",
            "",
            "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False,",
            "                    convert_data=False):",
            "        if self.jinja2_native and not isinstance(data, string_types):",
            "            return data",
            "",
            "        # For preserving the number of input newlines in the output (used",
            "        # later in this method)",
            "        data_newlines = _count_newlines_from_end(data)",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            # NOTE Creating an overlay that lives only inside do_template means that overrides are not applied",
            "            # when templating nested variables in AnsibleJ2Vars where Templar.environment is used, not the overlay.",
            "            # This is historic behavior that is kept for backwards compatibility.",
            "            data, myenv = _create_overlay(data, overrides, self.environment)",
            "",
            "            if escape_backslashes:",
            "                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".",
            "                data = _escape_backslashes(data, myenv)",
            "",
            "            try:",
            "                t = myenv.from_string(data)",
            "            except TemplateSyntaxError as e:",
            "                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)), orig_exc=e)",
            "            except Exception as e:",
            "                if 'recursion' in to_native(e):",
            "                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data), orig_exc=e)",
            "                else:",
            "                    return data",
            "",
            "            if disable_lookups:",
            "                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup",
            "",
            "            jvars = AnsibleJ2Vars(self, t.globals)",
            "",
            "            # In case this is a recursive call to do_template we need to",
            "            # save/restore cur_context to prevent overriding __UNSAFE__.",
            "            cached_context = self.cur_context",
            "",
            "            # In case this is a recursive call and we set different concat",
            "            # function up the stack, reset it in case the value of convert_data",
            "            # changed in this call",
            "            myenv.concat = myenv.__class__.concat",
            "            # the concat function is set for each Ansible environment,",
            "            # however for convert_data=False we need to use the concat",
            "            # function that avoids any evaluation and set it temporarily",
            "            # on the environment so it is used correctly even when",
            "            # the concat function is called internally in Jinja,",
            "            # most notably for macro execution",
            "            if not self.jinja2_native and not convert_data:",
            "                myenv.concat = ansible_concat",
            "",
            "            self.cur_context = t.new_context(jvars, shared=True)",
            "            rf = t.root_render_func(self.cur_context)",
            "",
            "            try:",
            "                res = myenv.concat(rf)",
            "                unsafe = getattr(self.cur_context, 'unsafe', False)",
            "                if unsafe:",
            "                    res = wrap_var(res)",
            "            except TypeError as te:",
            "                if 'AnsibleUndefined' in to_native(te):",
            "                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)",
            "                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)",
            "                    raise AnsibleUndefinedVariable(errmsg, orig_exc=te)",
            "                else:",
            "                    display.debug(\"failing because of a type error, template data is: %s\" % to_text(data))",
            "                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)), orig_exc=te)",
            "            finally:",
            "                self.cur_context = cached_context",
            "",
            "            if isinstance(res, string_types) and preserve_trailing_newlines:",
            "                # The low level calls above do not preserve the newline",
            "                # characters at the end of the input data, so we use the",
            "                # calculate the difference in newlines and append them",
            "                # to the resulting output for parity",
            "                #",
            "                # Using Environment's keep_trailing_newline instead would",
            "                # result in change in behavior when trailing newlines",
            "                # would be kept also for included templates, for example:",
            "                # \"Hello {% include 'world.txt' %}!\" would render as",
            "                # \"Hello world\\n!\\n\" instead of \"Hello world!\\n\".",
            "                res_newlines = _count_newlines_from_end(res)",
            "                if data_newlines > res_newlines:",
            "                    res += myenv.newline_sequence * (data_newlines - res_newlines)",
            "                    if unsafe:",
            "                        res = wrap_var(res)",
            "            return res",
            "        except (UndefinedError, AnsibleUndefinedVariable) as e:",
            "            if fail_on_undefined:",
            "                raise AnsibleUndefinedVariable(e, orig_exc=e)",
            "            else:",
            "                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))",
            "                return data",
            "",
            "    # for backwards compatibility in case anyone is using old private method directly",
            "    _do_template = do_template"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import datetime",
            "import os",
            "import pwd",
            "import re",
            "import time",
            "",
            "from collections.abc import Iterator, Sequence, Mapping, MappingView, MutableMapping",
            "from contextlib import contextmanager",
            "from numbers import Number",
            "from traceback import format_exc",
            "",
            "from jinja2.exceptions import TemplateSyntaxError, UndefinedError, SecurityError",
            "from jinja2.loaders import FileSystemLoader",
            "from jinja2.nativetypes import NativeEnvironment",
            "from jinja2.runtime import Context, StrictUndefined",
            "",
            "from ansible import constants as C",
            "from ansible.errors import (",
            "    AnsibleAssertionError,",
            "    AnsibleError,",
            "    AnsibleFilterError,",
            "    AnsibleLookupError,",
            "    AnsibleOptionsError,",
            "    AnsibleUndefinedVariable,",
            ")",
            "from ansible.module_utils.six import string_types, text_type",
            "from ansible.module_utils._text import to_native, to_text, to_bytes",
            "from ansible.module_utils.common.collections import is_sequence",
            "from ansible.plugins.loader import filter_loader, lookup_loader, test_loader",
            "from ansible.template.native_helpers import ansible_native_concat, ansible_eval_concat, ansible_concat",
            "from ansible.template.template import AnsibleJ2Template",
            "from ansible.template.vars import AnsibleJ2Vars",
            "from ansible.utils.display import Display",
            "from ansible.utils.listify import listify_lookup_plugin_terms",
            "from ansible.utils.native_jinja import NativeJinjaText",
            "from ansible.utils.unsafe_proxy import wrap_var, AnsibleUnsafeText, AnsibleUnsafeBytes, NativeJinjaUnsafeText",
            "",
            "display = Display()",
            "",
            "",
            "__all__ = ['Templar', 'generate_ansible_template_vars']",
            "",
            "# Primitive Types which we don't want Jinja to convert to strings.",
            "NON_TEMPLATED_TYPES = (bool, Number)",
            "",
            "JINJA2_OVERRIDE = '#jinja2:'",
            "",
            "JINJA2_BEGIN_TOKENS = frozenset(('variable_begin', 'block_begin', 'comment_begin', 'raw_begin'))",
            "JINJA2_END_TOKENS = frozenset(('variable_end', 'block_end', 'comment_end', 'raw_end'))",
            "",
            "RANGE_TYPE = type(range(0))",
            "",
            "",
            "def generate_ansible_template_vars(path, fullpath=None, dest_path=None):",
            "",
            "    if fullpath is None:",
            "        b_path = to_bytes(path)",
            "    else:",
            "        b_path = to_bytes(fullpath)",
            "",
            "    try:",
            "        template_uid = pwd.getpwuid(os.stat(b_path).st_uid).pw_name",
            "    except (KeyError, TypeError):",
            "        template_uid = os.stat(b_path).st_uid",
            "",
            "    temp_vars = {",
            "        'template_host': to_text(os.uname()[1]),",
            "        'template_path': path,",
            "        'template_mtime': datetime.datetime.fromtimestamp(os.path.getmtime(b_path)),",
            "        'template_uid': to_text(template_uid),",
            "        'template_run_date': datetime.datetime.now(),",
            "        'template_destpath': to_native(dest_path) if dest_path else None,",
            "    }",
            "",
            "    if fullpath is None:",
            "        temp_vars['template_fullpath'] = os.path.abspath(path)",
            "    else:",
            "        temp_vars['template_fullpath'] = fullpath",
            "",
            "    managed_default = C.DEFAULT_MANAGED_STR",
            "    managed_str = managed_default.format(",
            "        host=temp_vars['template_host'],",
            "        uid=temp_vars['template_uid'],",
            "        file=temp_vars['template_path'],",
            "    )",
            "    temp_vars['ansible_managed'] = to_text(time.strftime(to_native(managed_str), time.localtime(os.path.getmtime(b_path))))",
            "",
            "    return temp_vars",
            "",
            "",
            "def _escape_backslashes(data, jinja_env):",
            "    \"\"\"Double backslashes within jinja2 expressions",
            "",
            "    A user may enter something like this in a playbook::",
            "",
            "      debug:",
            "        msg: \"Test Case 1\\\\3; {{ test1_name | regex_replace('^(.*)_name$', '\\\\1')}}\"",
            "",
            "    The string inside of the {{ gets interpreted multiple times First by yaml.",
            "    Then by python.  And finally by jinja2 as part of it's variable.  Because",
            "    it is processed by both python and jinja2, the backslash escaped",
            "    characters get unescaped twice.  This means that we'd normally have to use",
            "    four backslashes to escape that.  This is painful for playbook authors as",
            "    they have to remember different rules for inside vs outside of a jinja2",
            "    expression (The backslashes outside of the \"{{ }}\" only get processed by",
            "    yaml and python.  So they only need to be escaped once).  The following",
            "    code fixes this by automatically performing the extra quoting of",
            "    backslashes inside of a jinja2 expression.",
            "",
            "    \"\"\"",
            "    if '\\\\' in data and '{{' in data:",
            "        new_data = []",
            "        d2 = jinja_env.preprocess(data)",
            "        in_var = False",
            "",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] == 'variable_begin':",
            "                in_var = True",
            "                new_data.append(token[2])",
            "            elif token[1] == 'variable_end':",
            "                in_var = False",
            "                new_data.append(token[2])",
            "            elif in_var and token[1] == 'string':",
            "                # Double backslashes only if we're inside of a jinja2 variable",
            "                new_data.append(token[2].replace('\\\\', '\\\\\\\\'))",
            "            else:",
            "                new_data.append(token[2])",
            "",
            "        data = ''.join(new_data)",
            "",
            "    return data",
            "",
            "",
            "def _create_overlay(data, overrides, jinja_env):",
            "    if overrides is None:",
            "        overrides = {}",
            "",
            "    try:",
            "        has_override_header = data.startswith(JINJA2_OVERRIDE)",
            "    except (TypeError, AttributeError):",
            "        has_override_header = False",
            "",
            "    if overrides or has_override_header:",
            "        overlay = jinja_env.overlay(**overrides)",
            "    else:",
            "        overlay = jinja_env",
            "",
            "    # Get jinja env overrides from template",
            "    if has_override_header:",
            "        eol = data.find('\\n')",
            "        line = data[len(JINJA2_OVERRIDE):eol]",
            "        data = data[eol + 1:]",
            "        for pair in line.split(','):",
            "            if ':' not in pair:",
            "                raise AnsibleError(\"failed to parse jinja2 override '%s'.\"",
            "                                   \" Did you use something different from colon as key-value separator?\" % pair.strip())",
            "            (key, val) = pair.split(':', 1)",
            "            key = key.strip()",
            "            if hasattr(overlay, key):",
            "                setattr(overlay, key, ast.literal_eval(val.strip()))",
            "            else:",
            "                display.warning(f\"Could not find Jinja2 environment setting to override: '{key}'\")",
            "",
            "    return data, overlay",
            "",
            "",
            "def is_possibly_template(data, jinja_env):",
            "    \"\"\"Determines if a string looks like a template, by seeing if it",
            "    contains a jinja2 start delimiter. Does not guarantee that the string",
            "    is actually a template.",
            "",
            "    This is different than ``is_template`` which is more strict.",
            "    This method may return ``True`` on a string that is not templatable.",
            "",
            "    Useful when guarding passing a string for templating, but when",
            "    you want to allow the templating engine to make the final",
            "    assessment which may result in ``TemplateSyntaxError``.",
            "    \"\"\"",
            "    if isinstance(data, string_types):",
            "        for marker in (jinja_env.block_start_string, jinja_env.variable_start_string, jinja_env.comment_start_string):",
            "            if marker in data:",
            "                return True",
            "    return False",
            "",
            "",
            "def is_template(data, jinja_env):",
            "    \"\"\"This function attempts to quickly detect whether a value is a jinja2",
            "    template. To do so, we look for the first 2 matching jinja2 tokens for",
            "    start and end delimiters.",
            "    \"\"\"",
            "    found = None",
            "    start = True",
            "    comment = False",
            "    d2 = jinja_env.preprocess(data)",
            "",
            "    # Quick check to see if this is remotely like a template before doing",
            "    # more expensive investigation.",
            "    if not is_possibly_template(d2, jinja_env):",
            "        return False",
            "",
            "    # This wraps a lot of code, but this is due to lex returning a generator",
            "    # so we may get an exception at any part of the loop",
            "    try:",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] in JINJA2_BEGIN_TOKENS:",
            "                if start and token[1] == 'comment_begin':",
            "                    # Comments can wrap other token types",
            "                    comment = True",
            "                start = False",
            "                # Example: variable_end -> variable",
            "                found = token[1].split('_')[0]",
            "            elif token[1] in JINJA2_END_TOKENS:",
            "                if token[1].split('_')[0] == found:",
            "                    return True",
            "                elif comment:",
            "                    continue",
            "                return False",
            "    except TemplateSyntaxError:",
            "        return False",
            "",
            "    return False",
            "",
            "",
            "def _count_newlines_from_end(in_str):",
            "    '''",
            "    Counts the number of newlines at the end of a string. This is used during",
            "    the jinja2 templating to ensure the count matches the input, since some newlines",
            "    may be thrown away during the templating.",
            "    '''",
            "",
            "    try:",
            "        i = len(in_str)",
            "        j = i - 1",
            "        while in_str[j] == '\\n':",
            "            j -= 1",
            "        return i - 1 - j",
            "    except IndexError:",
            "        # Uncommon cases: zero length string and string containing only newlines",
            "        return i",
            "",
            "",
            "def recursive_check_defined(item):",
            "    from jinja2.runtime import Undefined",
            "",
            "    if isinstance(item, MutableMapping):",
            "        for key in item:",
            "            recursive_check_defined(item[key])",
            "    elif isinstance(item, list):",
            "        for i in item:",
            "            recursive_check_defined(i)",
            "    else:",
            "        if isinstance(item, Undefined):",
            "            raise AnsibleFilterError(\"{0} is undefined\".format(item))",
            "",
            "",
            "def _is_rolled(value):",
            "    \"\"\"Helper method to determine if something is an unrolled generator,",
            "    iterator, or similar object",
            "    \"\"\"",
            "    return (",
            "        isinstance(value, Iterator) or",
            "        isinstance(value, MappingView) or",
            "        isinstance(value, RANGE_TYPE)",
            "    )",
            "",
            "",
            "def _unroll_iterator(func):",
            "    \"\"\"Wrapper function, that intercepts the result of a templating",
            "    and auto unrolls a generator, so that users are not required to",
            "    explicitly use ``|list`` to unroll.",
            "    \"\"\"",
            "    def wrapper(*args, **kwargs):",
            "        ret = func(*args, **kwargs)",
            "        if _is_rolled(ret):",
            "            return list(ret)",
            "        return ret",
            "",
            "    return _update_wrapper(wrapper, func)",
            "",
            "",
            "def _update_wrapper(wrapper, func):",
            "    # This code is duplicated from ``functools.update_wrapper`` from Py3.7.",
            "    # ``functools.update_wrapper`` was failing when the func was ``functools.partial``",
            "    for attr in ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'):",
            "        try:",
            "            value = getattr(func, attr)",
            "        except AttributeError:",
            "            pass",
            "        else:",
            "            setattr(wrapper, attr, value)",
            "    for attr in ('__dict__',):",
            "        getattr(wrapper, attr).update(getattr(func, attr, {}))",
            "    wrapper.__wrapped__ = func",
            "    return wrapper",
            "",
            "",
            "def _wrap_native_text(func):",
            "    \"\"\"Wrapper function, that intercepts the result of a filter",
            "    and wraps it into NativeJinjaText which is then used",
            "    in ``ansible_native_concat`` to indicate that it is a text",
            "    which should not be passed into ``literal_eval``.",
            "    \"\"\"",
            "    def wrapper(*args, **kwargs):",
            "        ret = func(*args, **kwargs)",
            "        return NativeJinjaText(ret)",
            "",
            "    return _update_wrapper(wrapper, func)",
            "",
            "",
            "class AnsibleUndefined(StrictUndefined):",
            "    '''",
            "    A custom Undefined class, which returns further Undefined objects on access,",
            "    rather than throwing an exception.",
            "    '''",
            "    def __getattr__(self, name):",
            "        if name == '__UNSAFE__':",
            "            # AnsibleUndefined should never be assumed to be unsafe",
            "            # This prevents ``hasattr(val, '__UNSAFE__')`` from evaluating to ``True``",
            "            raise AttributeError(name)",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "    def __getitem__(self, key):",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "    def __repr__(self):",
            "        return 'AnsibleUndefined(hint={0!r}, obj={1!r}, name={2!r})'.format(",
            "            self._undefined_hint,",
            "            self._undefined_obj,",
            "            self._undefined_name",
            "        )",
            "",
            "    def __contains__(self, item):",
            "        # Return original Undefined object to preserve the first failure context",
            "        return self",
            "",
            "",
            "class AnsibleContext(Context):",
            "    '''",
            "    A custom context, which intercepts resolve_or_missing() calls and sets a flag",
            "    internally if any variable lookup returns an AnsibleUnsafe value. This",
            "    flag is checked post-templating, and (when set) will result in the",
            "    final templated result being wrapped in AnsibleUnsafe.",
            "    '''",
            "    _disallowed_callables = frozenset({",
            "        AnsibleUnsafeText._strip_unsafe.__qualname__,",
            "        AnsibleUnsafeBytes._strip_unsafe.__qualname__,",
            "        NativeJinjaUnsafeText._strip_unsafe.__qualname__,",
            "    })",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super(AnsibleContext, self).__init__(*args, **kwargs)",
            "        self.unsafe = False",
            "",
            "    def call(self, obj, *args, **kwargs):",
            "        if getattr(obj, '__qualname__', None) in self._disallowed_callables or obj in self._disallowed_callables:",
            "            raise SecurityError(f\"{obj!r} is not safely callable\")",
            "        return super().call(obj, *args, **kwargs)",
            "",
            "    def _is_unsafe(self, val):",
            "        '''",
            "        Our helper function, which will also recursively check dict and",
            "        list entries due to the fact that they may be repr'd and contain",
            "        a key or value which contains jinja2 syntax and would otherwise",
            "        lose the AnsibleUnsafe value.",
            "        '''",
            "        if isinstance(val, dict):",
            "            for key in val.keys():",
            "                if self._is_unsafe(val[key]):",
            "                    return True",
            "        elif isinstance(val, list):",
            "            for item in val:",
            "                if self._is_unsafe(item):",
            "                    return True",
            "        elif getattr(val, '__UNSAFE__', False) is True:",
            "            return True",
            "        return False",
            "",
            "    def _update_unsafe(self, val):",
            "        if val is not None and not self.unsafe and self._is_unsafe(val):",
            "            self.unsafe = True",
            "",
            "    def resolve_or_missing(self, key):",
            "        val = super(AnsibleContext, self).resolve_or_missing(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "    def get_all(self):",
            "        \"\"\"Return the complete context as a dict including the exported",
            "        variables. For optimizations reasons this might not return an",
            "        actual copy so be careful with using it.",
            "",
            "        This is to prevent from running ``AnsibleJ2Vars`` through dict():",
            "",
            "            ``dict(self.parent, **self.vars)``",
            "",
            "        In Ansible this means that ALL variables would be templated in the",
            "        process of re-creating the parent because ``AnsibleJ2Vars`` templates",
            "        each variable in its ``__getitem__`` method. Instead we re-create the",
            "        parent via ``AnsibleJ2Vars.add_locals`` that creates a new",
            "        ``AnsibleJ2Vars`` copy without templating each variable.",
            "",
            "        This will prevent unnecessarily templating unused variables in cases",
            "        like setting a local variable and passing it to {% include %}",
            "        in a template.",
            "",
            "        Also see ``AnsibleJ2Template``and",
            "        https://github.com/pallets/jinja/commit/d67f0fd4cc2a4af08f51f4466150d49da7798729",
            "        \"\"\"",
            "        if not self.vars:",
            "            return self.parent",
            "        if not self.parent:",
            "            return self.vars",
            "",
            "        if isinstance(self.parent, AnsibleJ2Vars):",
            "            return self.parent.add_locals(self.vars)",
            "        else:",
            "            # can this happen in Ansible?",
            "            return dict(self.parent, **self.vars)",
            "",
            "",
            "class JinjaPluginIntercept(MutableMapping):",
            "    ''' Simulated dict class that loads Jinja2Plugins at request",
            "        otherwise all plugins would need to be loaded a priori.",
            "",
            "        NOTE: plugin_loader still loads all 'builtin/legacy' at",
            "        start so only collection plugins are really at request.",
            "    '''",
            "",
            "    def __init__(self, delegatee, pluginloader, *args, **kwargs):",
            "",
            "        super(JinjaPluginIntercept, self).__init__(*args, **kwargs)",
            "",
            "        self._pluginloader = pluginloader",
            "",
            "        # Jinja environment's mapping of known names (initially just J2 builtins)",
            "        self._delegatee = delegatee",
            "",
            "        # our names take precedence over Jinja's, but let things we've tried to resolve skip the pluginloader",
            "        self._seen_it = set()",
            "",
            "    def __getitem__(self, key):",
            "",
            "        if not isinstance(key, string_types):",
            "            raise ValueError('key must be a string, got %s instead' % type(key))",
            "",
            "        original_exc = None",
            "        if key not in self._seen_it:",
            "            # this looks too early to set this- it isn't. Setting it here keeps requests for Jinja builtins from",
            "            # going through the pluginloader more than once, which is extremely slow for something that won't ever succeed.",
            "            self._seen_it.add(key)",
            "            plugin = None",
            "            try:",
            "                plugin = self._pluginloader.get(key)",
            "            except (AnsibleError, KeyError) as e:",
            "                original_exc = e",
            "            except Exception as e:",
            "                display.vvvv('Unexpected plugin load (%s) exception: %s' % (key, to_native(e)))",
            "                raise e",
            "",
            "            # if a plugin was found/loaded",
            "            if plugin:",
            "                # set in filter cache and avoid expensive plugin load",
            "                self._delegatee[key] = plugin.j2_function",
            "",
            "        # raise template syntax error if we could not find ours or jinja2 one",
            "        try:",
            "            func = self._delegatee[key]",
            "        except KeyError as e:",
            "            self._seen_it.remove(key)",
            "            raise TemplateSyntaxError('Could not load \"%s\": %s' % (key, to_native(original_exc or e)), 0)",
            "",
            "        # if i do have func and it is a filter, it nees wrapping",
            "        if self._pluginloader.type == 'filter':",
            "            # filter need wrapping",
            "            if key in C.STRING_TYPE_FILTERS:",
            "                # avoid litera_eval when you WANT strings",
            "                func = _wrap_native_text(func)",
            "            else:",
            "                # conditionally unroll iterators/generators to avoid having to use `|list` after every filter",
            "                func = _unroll_iterator(func)",
            "",
            "        return func",
            "",
            "    def __setitem__(self, key, value):",
            "        return self._delegatee.__setitem__(key, value)",
            "",
            "    def __delitem__(self, key):",
            "        raise NotImplementedError()",
            "",
            "    def __iter__(self):",
            "        # not strictly accurate since we're not counting dynamically-loaded values",
            "        return iter(self._delegatee)",
            "",
            "    def __len__(self):",
            "        # not strictly accurate since we're not counting dynamically-loaded values",
            "        return len(self._delegatee)",
            "",
            "",
            "def _fail_on_undefined(data):",
            "    \"\"\"Recursively find an undefined value in a nested data structure",
            "    and properly raise the undefined exception.",
            "    \"\"\"",
            "    if isinstance(data, Mapping):",
            "        for value in data.values():",
            "            _fail_on_undefined(value)",
            "    elif is_sequence(data):",
            "        for item in data:",
            "            _fail_on_undefined(item)",
            "    else:",
            "        if isinstance(data, StrictUndefined):",
            "            # To actually raise the undefined exception we need to",
            "            # access the undefined object otherwise the exception would",
            "            # be raised on the next access which might not be properly",
            "            # handled.",
            "            # See https://github.com/ansible/ansible/issues/52158",
            "            # and StrictUndefined implementation in upstream Jinja2.",
            "            str(data)",
            "    return data",
            "",
            "",
            "@_unroll_iterator",
            "def _ansible_finalize(thing):",
            "    \"\"\"A custom finalize function for jinja2, which prevents None from being",
            "    returned. This avoids a string of ``\"None\"`` as ``None`` has no",
            "    importance in YAML.",
            "",
            "    The function is decorated with ``_unroll_iterator`` so that users are not",
            "    required to explicitly use ``|list`` to unroll a generator. This only",
            "    affects the scenario where the final result of templating",
            "    is a generator, e.g. ``range``, ``dict.items()`` and so on. Filters",
            "    which can produce a generator in the middle of a template are already",
            "    wrapped with ``_unroll_generator`` in ``JinjaPluginIntercept``.",
            "    \"\"\"",
            "    return thing if _fail_on_undefined(thing) is not None else ''",
            "",
            "",
            "class AnsibleEnvironment(NativeEnvironment):",
            "    '''",
            "    Our custom environment, which simply allows us to override the class-level",
            "    values for the Template and Context classes used by jinja2 internally.",
            "    '''",
            "    context_class = AnsibleContext",
            "    template_class = AnsibleJ2Template",
            "    concat = staticmethod(ansible_eval_concat)  # type: ignore[assignment]",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "",
            "        self.filters = JinjaPluginIntercept(self.filters, filter_loader)",
            "        self.tests = JinjaPluginIntercept(self.tests, test_loader)",
            "",
            "        self.trim_blocks = True",
            "",
            "        self.undefined = AnsibleUndefined",
            "        self.finalize = _ansible_finalize",
            "",
            "",
            "class AnsibleNativeEnvironment(AnsibleEnvironment):",
            "    concat = staticmethod(ansible_native_concat)  # type: ignore[assignment]",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.finalize = _unroll_iterator(_fail_on_undefined)",
            "",
            "",
            "class Templar:",
            "    '''",
            "    The main class for templating, with the main entry-point of template().",
            "    '''",
            "",
            "    def __init__(self, loader, shared_loader_obj=None, variables=None):",
            "        if shared_loader_obj is not None:",
            "            display.deprecated(",
            "                \"The `shared_loader_obj` option to `Templar` is no longer functional, \"",
            "                \"ansible.plugins.loader is used directly instead.\",",
            "                version='2.16',",
            "            )",
            "",
            "        self._loader = loader",
            "        self._available_variables = {} if variables is None else variables",
            "",
            "        self._fail_on_undefined_errors = C.DEFAULT_UNDEFINED_VAR_BEHAVIOR",
            "",
            "        environment_class = AnsibleNativeEnvironment if C.DEFAULT_JINJA2_NATIVE else AnsibleEnvironment",
            "",
            "        self.environment = environment_class(",
            "            extensions=self._get_extensions(),",
            "            loader=FileSystemLoader(loader.get_basedir() if loader else '.'),",
            "        )",
            "        self.environment.template_class.environment_class = environment_class",
            "",
            "        # jinja2 global is inconsistent across versions, this normalizes them",
            "        self.environment.globals['dict'] = dict",
            "",
            "        # Custom globals",
            "        self.environment.globals['lookup'] = self._lookup",
            "        self.environment.globals['query'] = self.environment.globals['q'] = self._query_lookup",
            "        self.environment.globals['now'] = self._now_datetime",
            "        self.environment.globals['undef'] = self._make_undefined",
            "",
            "        # the current rendering context under which the templar class is working",
            "        self.cur_context = None",
            "",
            "        # FIXME this regex should be re-compiled each time variable_start_string and variable_end_string are changed",
            "        self.SINGLE_VAR = re.compile(r\"^%s\\s*(\\w*)\\s*%s$\" % (self.environment.variable_start_string, self.environment.variable_end_string))",
            "",
            "        self.jinja2_native = C.DEFAULT_JINJA2_NATIVE",
            "",
            "    def copy_with_new_env(self, environment_class=AnsibleEnvironment, **kwargs):",
            "        r\"\"\"Creates a new copy of Templar with a new environment.",
            "",
            "        :kwarg environment_class: Environment class used for creating a new environment.",
            "        :kwarg \\*\\*kwargs: Optional arguments for the new environment that override existing",
            "            environment attributes.",
            "",
            "        :returns: Copy of Templar with updated environment.",
            "        \"\"\"",
            "        # We need to use __new__ to skip __init__, mainly not to create a new",
            "        # environment there only to override it below",
            "        new_env = object.__new__(environment_class)",
            "        new_env.__dict__.update(self.environment.__dict__)",
            "",
            "        new_templar = object.__new__(Templar)",
            "        new_templar.__dict__.update(self.__dict__)",
            "        new_templar.environment = new_env",
            "",
            "        new_templar.jinja2_native = environment_class is AnsibleNativeEnvironment",
            "",
            "        mapping = {",
            "            'available_variables': new_templar,",
            "            'searchpath': new_env.loader,",
            "        }",
            "",
            "        for key, value in kwargs.items():",
            "            obj = mapping.get(key, new_env)",
            "            try:",
            "                if value is not None:",
            "                    setattr(obj, key, value)",
            "            except AttributeError:",
            "                # Ignore invalid attrs",
            "                pass",
            "",
            "        return new_templar",
            "",
            "    def _get_extensions(self):",
            "        '''",
            "        Return jinja2 extensions to load.",
            "",
            "        If some extensions are set via jinja_extensions in ansible.cfg, we try",
            "        to load them with the jinja environment.",
            "        '''",
            "",
            "        jinja_exts = []",
            "        if C.DEFAULT_JINJA2_EXTENSIONS:",
            "            # make sure the configuration directive doesn't contain spaces",
            "            # and split extensions in an array",
            "            jinja_exts = C.DEFAULT_JINJA2_EXTENSIONS.replace(\" \", \"\").split(',')",
            "",
            "        return jinja_exts",
            "",
            "    @property",
            "    def available_variables(self):",
            "        return self._available_variables",
            "",
            "    @available_variables.setter",
            "    def available_variables(self, variables):",
            "        '''",
            "        Sets the list of template variables this Templar instance will use",
            "        to template things, so we don't have to pass them around between",
            "        internal methods. We also clear the template cache here, as the variables",
            "        are being changed.",
            "        '''",
            "",
            "        if not isinstance(variables, Mapping):",
            "            raise AnsibleAssertionError(\"the type of 'variables' should be a Mapping but was a %s\" % (type(variables)))",
            "        self._available_variables = variables",
            "",
            "    @contextmanager",
            "    def set_temporary_context(self, **kwargs):",
            "        \"\"\"Context manager used to set temporary templating context, without having to worry about resetting",
            "        original values afterward",
            "",
            "        Use a keyword that maps to the attr you are setting. Applies to ``self.environment`` by default, to",
            "        set context on another object, it must be in ``mapping``.",
            "        \"\"\"",
            "        mapping = {",
            "            'available_variables': self,",
            "            'searchpath': self.environment.loader,",
            "        }",
            "        original = {}",
            "",
            "        for key, value in kwargs.items():",
            "            obj = mapping.get(key, self.environment)",
            "            try:",
            "                original[key] = getattr(obj, key)",
            "                if value is not None:",
            "                    setattr(obj, key, value)",
            "            except AttributeError:",
            "                # Ignore invalid attrs",
            "                pass",
            "",
            "        yield",
            "",
            "        for key in original:",
            "            obj = mapping.get(key, self.environment)",
            "            setattr(obj, key, original[key])",
            "",
            "    def template(self, variable, convert_bare=False, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None,",
            "                 convert_data=True, static_vars=None, cache=None, disable_lookups=False):",
            "        '''",
            "        Templates (possibly recursively) any given data as input. If convert_bare is",
            "        set to True, the given data will be wrapped as a jinja2 variable ('{{foo}}')",
            "        before being sent through the template engine.",
            "        '''",
            "        static_vars = [] if static_vars is None else static_vars",
            "",
            "        if cache is not None:",
            "            display.deprecated(\"The `cache` option to `Templar.template` is no longer functional, and will be removed in a future release.\", version='2.18')",
            "",
            "        # Don't template unsafe variables, just return them.",
            "        if hasattr(variable, '__UNSAFE__'):",
            "            return variable",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        if convert_bare:",
            "            variable = self._convert_bare_variable(variable)",
            "",
            "        if isinstance(variable, string_types):",
            "            if not self.is_possibly_template(variable, overrides):",
            "                return variable",
            "",
            "            # Check to see if the string we are trying to render is just referencing a single",
            "            # var.  In this case we don't want to accidentally change the type of the variable",
            "            # to a string by using the jinja template renderer. We just want to pass it.",
            "            only_one = self.SINGLE_VAR.match(variable)",
            "            if only_one:",
            "                var_name = only_one.group(1)",
            "                if var_name in self._available_variables:",
            "                    resolved_val = self._available_variables[var_name]",
            "                    if isinstance(resolved_val, NON_TEMPLATED_TYPES):",
            "                        return resolved_val",
            "                    elif resolved_val is None:",
            "                        return C.DEFAULT_NULL_REPRESENTATION",
            "",
            "            result = self.do_template(",
            "                variable,",
            "                preserve_trailing_newlines=preserve_trailing_newlines,",
            "                escape_backslashes=escape_backslashes,",
            "                fail_on_undefined=fail_on_undefined,",
            "                overrides=overrides,",
            "                disable_lookups=disable_lookups,",
            "                convert_data=convert_data,",
            "            )",
            "",
            "            return result",
            "",
            "        elif is_sequence(variable):",
            "            return [self.template(",
            "                v,",
            "                preserve_trailing_newlines=preserve_trailing_newlines,",
            "                fail_on_undefined=fail_on_undefined,",
            "                overrides=overrides,",
            "                disable_lookups=disable_lookups,",
            "            ) for v in variable]",
            "        elif isinstance(variable, Mapping):",
            "            d = {}",
            "            # we don't use iteritems() here to avoid problems if the underlying dict",
            "            # changes sizes due to the templating, which can happen with hostvars",
            "            for k in variable.keys():",
            "                if k not in static_vars:",
            "                    d[k] = self.template(",
            "                        variable[k],",
            "                        preserve_trailing_newlines=preserve_trailing_newlines,",
            "                        fail_on_undefined=fail_on_undefined,",
            "                        overrides=overrides,",
            "                        disable_lookups=disable_lookups,",
            "                    )",
            "                else:",
            "                    d[k] = variable[k]",
            "            return d",
            "        else:",
            "            return variable",
            "",
            "    def is_template(self, data):",
            "        '''lets us know if data has a template'''",
            "        if isinstance(data, string_types):",
            "            return is_template(data, self.environment)",
            "        elif isinstance(data, (list, tuple)):",
            "            for v in data:",
            "                if self.is_template(v):",
            "                    return True",
            "        elif isinstance(data, dict):",
            "            for k in data:",
            "                if self.is_template(k) or self.is_template(data[k]):",
            "                    return True",
            "        return False",
            "",
            "    templatable = is_template",
            "",
            "    def is_possibly_template(self, data, overrides=None):",
            "        data, env = _create_overlay(data, overrides, self.environment)",
            "        return is_possibly_template(data, env)",
            "",
            "    def _convert_bare_variable(self, variable):",
            "        '''",
            "        Wraps a bare string, which may have an attribute portion (ie. foo.bar)",
            "        in jinja2 variable braces so that it is evaluated properly.",
            "        '''",
            "",
            "        if isinstance(variable, string_types):",
            "            contains_filters = \"|\" in variable",
            "            first_part = variable.split(\"|\")[0].split(\".\")[0].split(\"[\")[0]",
            "            if (contains_filters or first_part in self._available_variables) and self.environment.variable_start_string not in variable:",
            "                return \"%s%s%s\" % (self.environment.variable_start_string, variable, self.environment.variable_end_string)",
            "",
            "        # the variable didn't meet the conditions to be converted,",
            "        # so just return it as-is",
            "        return variable",
            "",
            "    def _fail_lookup(self, name, *args, **kwargs):",
            "        raise AnsibleError(\"The lookup `%s` was found, however lookups were disabled from templating\" % name)",
            "",
            "    def _now_datetime(self, utc=False, fmt=None):",
            "        '''jinja2 global function to return current datetime, potentially formatted via strftime'''",
            "        if utc:",
            "            now = datetime.datetime.utcnow()",
            "        else:",
            "            now = datetime.datetime.now()",
            "",
            "        if fmt:",
            "            return now.strftime(fmt)",
            "",
            "        return now",
            "",
            "    def _query_lookup(self, name, /, *args, **kwargs):",
            "        ''' wrapper for lookup, force wantlist true'''",
            "        kwargs['wantlist'] = True",
            "        return self._lookup(name, *args, **kwargs)",
            "",
            "    def _lookup(self, name, /, *args, **kwargs):",
            "        instance = lookup_loader.get(name, loader=self._loader, templar=self)",
            "",
            "        if instance is None:",
            "            raise AnsibleError(\"lookup plugin (%s) not found\" % name)",
            "",
            "        wantlist = kwargs.pop('wantlist', False)",
            "        allow_unsafe = kwargs.pop('allow_unsafe', C.DEFAULT_ALLOW_UNSAFE_LOOKUPS)",
            "        errors = kwargs.pop('errors', 'strict')",
            "",
            "        loop_terms = listify_lookup_plugin_terms(terms=args, templar=self, fail_on_undefined=True, convert_bare=False)",
            "        # safely catch run failures per #5059",
            "        try:",
            "            ran = instance.run(loop_terms, variables=self._available_variables, **kwargs)",
            "        except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "            raise AnsibleUndefinedVariable(e)",
            "        except AnsibleOptionsError as e:",
            "            # invalid options given to lookup, just reraise",
            "            raise e",
            "        except AnsibleLookupError as e:",
            "            # lookup handled error but still decided to bail",
            "            msg = 'Lookup failed but the error is being ignored: %s' % to_native(e)",
            "            if errors == 'warn':",
            "                display.warning(msg)",
            "            elif errors == 'ignore':",
            "                display.display(msg, log_only=True)",
            "            else:",
            "                raise e",
            "            return [] if wantlist else None",
            "        except Exception as e:",
            "            # errors not handled by lookup",
            "            msg = u\"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s\" % \\",
            "                  (name, type(e), to_text(e))",
            "            if errors == 'warn':",
            "                display.warning(msg)",
            "            elif errors == 'ignore':",
            "                display.display(msg, log_only=True)",
            "            else:",
            "                display.vvv('exception during Jinja2 execution: {0}'.format(format_exc()))",
            "                raise AnsibleError(to_native(msg), orig_exc=e)",
            "            return [] if wantlist else None",
            "",
            "        if not is_sequence(ran):",
            "            display.deprecated(",
            "                f'The lookup plugin \\'{name}\\' was expected to return a list, got \\'{type(ran)}\\' instead. '",
            "                f'The lookup plugin \\'{name}\\' needs to be changed to return a list. '",
            "                'This will be an error in Ansible 2.18',",
            "                version='2.18'",
            "            )",
            "",
            "        if ran and allow_unsafe is False:",
            "            if self.cur_context:",
            "                self.cur_context.unsafe = True",
            "",
            "            if wantlist:",
            "                return wrap_var(ran)",
            "",
            "            try:",
            "                if isinstance(ran[0], NativeJinjaText):",
            "                    ran = wrap_var(NativeJinjaText(\",\".join(ran)))",
            "                else:",
            "                    ran = wrap_var(\",\".join(ran))",
            "            except TypeError:",
            "                # Lookup Plugins should always return lists.  Throw an error if that's not",
            "                # the case:",
            "                if not isinstance(ran, Sequence):",
            "                    raise AnsibleError(\"The lookup plugin '%s' did not return a list.\"",
            "                                       % name)",
            "",
            "                # The TypeError we can recover from is when the value *inside* of the list",
            "                # is not a string",
            "                if len(ran) == 1:",
            "                    ran = wrap_var(ran[0])",
            "                else:",
            "                    ran = wrap_var(ran)",
            "            except KeyError:",
            "                # Lookup Plugin returned a dict.  Return comma-separated string of keys",
            "                # for backwards compat.",
            "                # FIXME this can be removed when support for non-list return types is removed.",
            "                # See https://github.com/ansible/ansible/pull/77789",
            "                ran = wrap_var(\",\".join(ran))",
            "",
            "        return ran",
            "",
            "    def _make_undefined(self, hint=None):",
            "        from jinja2.runtime import Undefined",
            "",
            "        if hint is None or isinstance(hint, Undefined) or hint == '':",
            "            hint = \"Mandatory variable has not been overridden\"",
            "        return AnsibleUndefined(hint)",
            "",
            "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False,",
            "                    convert_data=False):",
            "        if self.jinja2_native and not isinstance(data, string_types):",
            "            return data",
            "",
            "        # For preserving the number of input newlines in the output (used",
            "        # later in this method)",
            "        data_newlines = _count_newlines_from_end(data)",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            # NOTE Creating an overlay that lives only inside do_template means that overrides are not applied",
            "            # when templating nested variables in AnsibleJ2Vars where Templar.environment is used, not the overlay.",
            "            # This is historic behavior that is kept for backwards compatibility.",
            "            data, myenv = _create_overlay(data, overrides, self.environment)",
            "",
            "            if escape_backslashes:",
            "                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".",
            "                data = _escape_backslashes(data, myenv)",
            "",
            "            try:",
            "                t = myenv.from_string(data)",
            "            except TemplateSyntaxError as e:",
            "                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)), orig_exc=e)",
            "            except Exception as e:",
            "                if 'recursion' in to_native(e):",
            "                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data), orig_exc=e)",
            "                else:",
            "                    return data",
            "",
            "            if disable_lookups:",
            "                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup",
            "",
            "            jvars = AnsibleJ2Vars(self, t.globals)",
            "",
            "            # In case this is a recursive call to do_template we need to",
            "            # save/restore cur_context to prevent overriding __UNSAFE__.",
            "            cached_context = self.cur_context",
            "",
            "            # In case this is a recursive call and we set different concat",
            "            # function up the stack, reset it in case the value of convert_data",
            "            # changed in this call",
            "            myenv.concat = myenv.__class__.concat",
            "            # the concat function is set for each Ansible environment,",
            "            # however for convert_data=False we need to use the concat",
            "            # function that avoids any evaluation and set it temporarily",
            "            # on the environment so it is used correctly even when",
            "            # the concat function is called internally in Jinja,",
            "            # most notably for macro execution",
            "            if not self.jinja2_native and not convert_data:",
            "                myenv.concat = ansible_concat",
            "",
            "            self.cur_context = t.new_context(jvars, shared=True)",
            "            rf = t.root_render_func(self.cur_context)",
            "",
            "            try:",
            "                res = myenv.concat(rf)",
            "                unsafe = getattr(self.cur_context, 'unsafe', False)",
            "                if unsafe:",
            "                    res = wrap_var(res)",
            "            except TypeError as te:",
            "                if 'AnsibleUndefined' in to_native(te):",
            "                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)",
            "                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)",
            "                    raise AnsibleUndefinedVariable(errmsg, orig_exc=te)",
            "                else:",
            "                    display.debug(\"failing because of a type error, template data is: %s\" % to_text(data))",
            "                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)), orig_exc=te)",
            "            finally:",
            "                self.cur_context = cached_context",
            "",
            "            if isinstance(res, string_types) and preserve_trailing_newlines:",
            "                # The low level calls above do not preserve the newline",
            "                # characters at the end of the input data, so we use the",
            "                # calculate the difference in newlines and append them",
            "                # to the resulting output for parity",
            "                #",
            "                # Using Environment's keep_trailing_newline instead would",
            "                # result in change in behavior when trailing newlines",
            "                # would be kept also for included templates, for example:",
            "                # \"Hello {% include 'world.txt' %}!\" would render as",
            "                # \"Hello world\\n!\\n\" instead of \"Hello world!\\n\".",
            "                res_newlines = _count_newlines_from_end(res)",
            "                if data_newlines > res_newlines:",
            "                    res += myenv.newline_sequence * (data_newlines - res_newlines)",
            "                    if unsafe:",
            "                        res = wrap_var(res)",
            "            return res",
            "        except (UndefinedError, AnsibleUndefinedVariable) as e:",
            "            if fail_on_undefined:",
            "                raise AnsibleUndefinedVariable(e, orig_exc=e)",
            "            else:",
            "                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))",
            "                return data",
            "",
            "    # for backwards compatibility in case anyone is using old private method directly",
            "    _do_template = do_template"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "34": [],
            "58": []
        },
        "addLocation": []
    }
}