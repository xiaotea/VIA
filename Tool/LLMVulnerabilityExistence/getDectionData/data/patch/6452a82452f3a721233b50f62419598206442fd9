{
    "lib/ansible/executor/process/worker.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "         self._variable_manager = variable_manager"
            },
            "1": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "         self._shared_loader_obj = shared_loader_obj"
            },
            "2": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+        # NOTE: this works due to fork, if switching to threads this should change to per thread storage of temp files"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+        # clear var to ensure we only delete files for this child"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+        self._loader._tempfiles = set()"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "     def _save_stdin(self):"
            },
            "8": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         self._new_stdin = os.devnull"
            },
            "9": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "         try:"
            },
            "10": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "                 except Exception:"
            },
            "11": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 205,
                "PatchRowcode": "                     display.debug(u\"WORKER EXCEPTION: %s\" % to_text(e))"
            },
            "12": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "                     display.debug(u\"WORKER TRACEBACK: %s\" % to_text(traceback.format_exc()))"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+                finally:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+                    self._clean_up()"
            },
            "15": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": 209,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 210,
                "PatchRowcode": "         display.debug(\"WORKER PROCESS EXITING\")"
            },
            "17": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 211,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "         # ps.print_stats()"
            },
            "19": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "         # with open('worker_%06d.stats' % os.getpid(), 'w') as f:"
            },
            "20": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 218,
                "PatchRowcode": "         #     f.write(s.getvalue())"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+    def _clean_up(self):"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+        # NOTE: see note in init about forks"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+        # ensure we cleanup all temp files for this worker"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+        self._loader.cleanup_all_tmp_files()"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import sys",
            "import traceback",
            "",
            "from jinja2.exceptions import TemplateNotFound",
            "",
            "HAS_PYCRYPTO_ATFORK = False",
            "try:",
            "    from Crypto.Random import atfork",
            "    HAS_PYCRYPTO_ATFORK = True",
            "except Exception:",
            "    # We only need to call atfork if pycrypto is used because it will need to",
            "    # reinitialize its RNG.  Since old paramiko could be using pycrypto, we",
            "    # need to take charge of calling it.",
            "    pass",
            "",
            "from ansible.errors import AnsibleConnectionFailure",
            "from ansible.executor.task_executor import TaskExecutor",
            "from ansible.executor.task_result import TaskResult",
            "from ansible.module_utils._text import to_text",
            "from ansible.utils.display import Display",
            "from ansible.utils.multiprocessing import context as multiprocessing_context",
            "",
            "__all__ = ['WorkerProcess']",
            "",
            "display = Display()",
            "",
            "",
            "class WorkerProcess(multiprocessing_context.Process):",
            "    '''",
            "    The worker thread class, which uses TaskExecutor to run tasks",
            "    read from a job queue and pushes results into a results queue",
            "    for reading later.",
            "    '''",
            "",
            "    def __init__(self, final_q, task_vars, host, task, play_context, loader, variable_manager, shared_loader_obj):",
            "",
            "        super(WorkerProcess, self).__init__()",
            "        # takes a task queue manager as the sole param:",
            "        self._final_q = final_q",
            "        self._task_vars = task_vars",
            "        self._host = host",
            "        self._task = task",
            "        self._play_context = play_context",
            "        self._loader = loader",
            "        self._variable_manager = variable_manager",
            "        self._shared_loader_obj = shared_loader_obj",
            "",
            "    def _save_stdin(self):",
            "        self._new_stdin = os.devnull",
            "        try:",
            "            if sys.stdin.isatty() and sys.stdin.fileno() is not None:",
            "                try:",
            "                    self._new_stdin = os.fdopen(os.dup(sys.stdin.fileno()))",
            "                except OSError:",
            "                    # couldn't dupe stdin, most likely because it's",
            "                    # not a valid file descriptor, so we just rely on",
            "                    # using the one that was passed in",
            "                    pass",
            "        except (AttributeError, ValueError):",
            "            # couldn't get stdin's fileno, so we just carry on",
            "            pass",
            "",
            "    def start(self):",
            "        '''",
            "        multiprocessing.Process replaces the worker's stdin with a new file",
            "        opened on os.devnull, but we wish to preserve it if it is connected to",
            "        a terminal. Therefore dup a copy prior to calling the real start(),",
            "        ensuring the descriptor is preserved somewhere in the new child, and",
            "        make sure it is closed in the parent when start() completes.",
            "        '''",
            "",
            "        self._save_stdin()",
            "        try:",
            "            return super(WorkerProcess, self).start()",
            "        finally:",
            "            if self._new_stdin != os.devnull:",
            "                self._new_stdin.close()",
            "",
            "    def _hard_exit(self, e):",
            "        '''",
            "        There is no safe exception to return to higher level code that does not",
            "        risk an innocent try/except finding itself executing in the wrong",
            "        process. All code executing above WorkerProcess.run() on the stack",
            "        conceptually belongs to another program.",
            "        '''",
            "",
            "        try:",
            "            display.debug(u\"WORKER HARD EXIT: %s\" % to_text(e))",
            "        except BaseException:",
            "            # If the cause of the fault is IOError being generated by stdio,",
            "            # attempting to log a debug message may trigger another IOError.",
            "            # Try printing once then give up.",
            "            pass",
            "",
            "        os._exit(1)",
            "",
            "    def run(self):",
            "        '''",
            "        Wrap _run() to ensure no possibility an errant exception can cause",
            "        control to return to the StrategyBase task loop, or any other code",
            "        higher in the stack.",
            "",
            "        As multiprocessing in Python 2.x provides no protection, it is possible",
            "        a try/except added in far-away code can cause a crashed child process",
            "        to suddenly assume the role and prior state of its parent.",
            "        '''",
            "        try:",
            "            return self._run()",
            "        except BaseException as e:",
            "            self._hard_exit(e)",
            "",
            "    def _run(self):",
            "        '''",
            "        Called when the process is started.  Pushes the result onto the",
            "        results queue. We also remove the host from the blocked hosts list, to",
            "        signify that they are ready for their next task.",
            "        '''",
            "",
            "        # import cProfile, pstats, StringIO",
            "        # pr = cProfile.Profile()",
            "        # pr.enable()",
            "",
            "        if HAS_PYCRYPTO_ATFORK:",
            "            atfork()",
            "",
            "        try:",
            "            # execute the task and build a TaskResult from the result",
            "            display.debug(\"running TaskExecutor() for %s/%s\" % (self._host, self._task))",
            "            executor_result = TaskExecutor(",
            "                self._host,",
            "                self._task,",
            "                self._task_vars,",
            "                self._play_context,",
            "                self._new_stdin,",
            "                self._loader,",
            "                self._shared_loader_obj,",
            "                self._final_q",
            "            ).run()",
            "",
            "            display.debug(\"done running TaskExecutor() for %s/%s [%s]\" % (self._host, self._task, self._task._uuid))",
            "            self._host.vars = dict()",
            "            self._host.groups = []",
            "            task_result = TaskResult(",
            "                self._host.name,",
            "                self._task._uuid,",
            "                executor_result,",
            "                task_fields=self._task.dump_attrs(),",
            "            )",
            "",
            "            # put the result on the result queue",
            "            display.debug(\"sending task result for task %s\" % self._task._uuid)",
            "            self._final_q.put(task_result)",
            "            display.debug(\"done sending task result for task %s\" % self._task._uuid)",
            "",
            "        except AnsibleConnectionFailure:",
            "            self._host.vars = dict()",
            "            self._host.groups = []",
            "            task_result = TaskResult(",
            "                self._host.name,",
            "                self._task._uuid,",
            "                dict(unreachable=True),",
            "                task_fields=self._task.dump_attrs(),",
            "            )",
            "            self._final_q.put(task_result, block=False)",
            "",
            "        except Exception as e:",
            "            if not isinstance(e, (IOError, EOFError, KeyboardInterrupt, SystemExit)) or isinstance(e, TemplateNotFound):",
            "                try:",
            "                    self._host.vars = dict()",
            "                    self._host.groups = []",
            "                    task_result = TaskResult(",
            "                        self._host.name,",
            "                        self._task._uuid,",
            "                        dict(failed=True, exception=to_text(traceback.format_exc()), stdout=''),",
            "                        task_fields=self._task.dump_attrs(),",
            "                    )",
            "                    self._final_q.put(task_result, block=False)",
            "                except Exception:",
            "                    display.debug(u\"WORKER EXCEPTION: %s\" % to_text(e))",
            "                    display.debug(u\"WORKER TRACEBACK: %s\" % to_text(traceback.format_exc()))",
            "",
            "        display.debug(\"WORKER PROCESS EXITING\")",
            "",
            "        # pr.disable()",
            "        # s = StringIO.StringIO()",
            "        # sortby = 'time'",
            "        # ps = pstats.Stats(pr, stream=s).sort_stats(sortby)",
            "        # ps.print_stats()",
            "        # with open('worker_%06d.stats' % os.getpid(), 'w') as f:",
            "        #     f.write(s.getvalue())"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import sys",
            "import traceback",
            "",
            "from jinja2.exceptions import TemplateNotFound",
            "",
            "HAS_PYCRYPTO_ATFORK = False",
            "try:",
            "    from Crypto.Random import atfork",
            "    HAS_PYCRYPTO_ATFORK = True",
            "except Exception:",
            "    # We only need to call atfork if pycrypto is used because it will need to",
            "    # reinitialize its RNG.  Since old paramiko could be using pycrypto, we",
            "    # need to take charge of calling it.",
            "    pass",
            "",
            "from ansible.errors import AnsibleConnectionFailure",
            "from ansible.executor.task_executor import TaskExecutor",
            "from ansible.executor.task_result import TaskResult",
            "from ansible.module_utils._text import to_text",
            "from ansible.utils.display import Display",
            "from ansible.utils.multiprocessing import context as multiprocessing_context",
            "",
            "__all__ = ['WorkerProcess']",
            "",
            "display = Display()",
            "",
            "",
            "class WorkerProcess(multiprocessing_context.Process):",
            "    '''",
            "    The worker thread class, which uses TaskExecutor to run tasks",
            "    read from a job queue and pushes results into a results queue",
            "    for reading later.",
            "    '''",
            "",
            "    def __init__(self, final_q, task_vars, host, task, play_context, loader, variable_manager, shared_loader_obj):",
            "",
            "        super(WorkerProcess, self).__init__()",
            "        # takes a task queue manager as the sole param:",
            "        self._final_q = final_q",
            "        self._task_vars = task_vars",
            "        self._host = host",
            "        self._task = task",
            "        self._play_context = play_context",
            "        self._loader = loader",
            "        self._variable_manager = variable_manager",
            "        self._shared_loader_obj = shared_loader_obj",
            "",
            "        # NOTE: this works due to fork, if switching to threads this should change to per thread storage of temp files",
            "        # clear var to ensure we only delete files for this child",
            "        self._loader._tempfiles = set()",
            "",
            "    def _save_stdin(self):",
            "        self._new_stdin = os.devnull",
            "        try:",
            "            if sys.stdin.isatty() and sys.stdin.fileno() is not None:",
            "                try:",
            "                    self._new_stdin = os.fdopen(os.dup(sys.stdin.fileno()))",
            "                except OSError:",
            "                    # couldn't dupe stdin, most likely because it's",
            "                    # not a valid file descriptor, so we just rely on",
            "                    # using the one that was passed in",
            "                    pass",
            "        except (AttributeError, ValueError):",
            "            # couldn't get stdin's fileno, so we just carry on",
            "            pass",
            "",
            "    def start(self):",
            "        '''",
            "        multiprocessing.Process replaces the worker's stdin with a new file",
            "        opened on os.devnull, but we wish to preserve it if it is connected to",
            "        a terminal. Therefore dup a copy prior to calling the real start(),",
            "        ensuring the descriptor is preserved somewhere in the new child, and",
            "        make sure it is closed in the parent when start() completes.",
            "        '''",
            "",
            "        self._save_stdin()",
            "        try:",
            "            return super(WorkerProcess, self).start()",
            "        finally:",
            "            if self._new_stdin != os.devnull:",
            "                self._new_stdin.close()",
            "",
            "    def _hard_exit(self, e):",
            "        '''",
            "        There is no safe exception to return to higher level code that does not",
            "        risk an innocent try/except finding itself executing in the wrong",
            "        process. All code executing above WorkerProcess.run() on the stack",
            "        conceptually belongs to another program.",
            "        '''",
            "",
            "        try:",
            "            display.debug(u\"WORKER HARD EXIT: %s\" % to_text(e))",
            "        except BaseException:",
            "            # If the cause of the fault is IOError being generated by stdio,",
            "            # attempting to log a debug message may trigger another IOError.",
            "            # Try printing once then give up.",
            "            pass",
            "",
            "        os._exit(1)",
            "",
            "    def run(self):",
            "        '''",
            "        Wrap _run() to ensure no possibility an errant exception can cause",
            "        control to return to the StrategyBase task loop, or any other code",
            "        higher in the stack.",
            "",
            "        As multiprocessing in Python 2.x provides no protection, it is possible",
            "        a try/except added in far-away code can cause a crashed child process",
            "        to suddenly assume the role and prior state of its parent.",
            "        '''",
            "        try:",
            "            return self._run()",
            "        except BaseException as e:",
            "            self._hard_exit(e)",
            "",
            "    def _run(self):",
            "        '''",
            "        Called when the process is started.  Pushes the result onto the",
            "        results queue. We also remove the host from the blocked hosts list, to",
            "        signify that they are ready for their next task.",
            "        '''",
            "",
            "        # import cProfile, pstats, StringIO",
            "        # pr = cProfile.Profile()",
            "        # pr.enable()",
            "",
            "        if HAS_PYCRYPTO_ATFORK:",
            "            atfork()",
            "",
            "        try:",
            "            # execute the task and build a TaskResult from the result",
            "            display.debug(\"running TaskExecutor() for %s/%s\" % (self._host, self._task))",
            "            executor_result = TaskExecutor(",
            "                self._host,",
            "                self._task,",
            "                self._task_vars,",
            "                self._play_context,",
            "                self._new_stdin,",
            "                self._loader,",
            "                self._shared_loader_obj,",
            "                self._final_q",
            "            ).run()",
            "",
            "            display.debug(\"done running TaskExecutor() for %s/%s [%s]\" % (self._host, self._task, self._task._uuid))",
            "            self._host.vars = dict()",
            "            self._host.groups = []",
            "            task_result = TaskResult(",
            "                self._host.name,",
            "                self._task._uuid,",
            "                executor_result,",
            "                task_fields=self._task.dump_attrs(),",
            "            )",
            "",
            "            # put the result on the result queue",
            "            display.debug(\"sending task result for task %s\" % self._task._uuid)",
            "            self._final_q.put(task_result)",
            "            display.debug(\"done sending task result for task %s\" % self._task._uuid)",
            "",
            "        except AnsibleConnectionFailure:",
            "            self._host.vars = dict()",
            "            self._host.groups = []",
            "            task_result = TaskResult(",
            "                self._host.name,",
            "                self._task._uuid,",
            "                dict(unreachable=True),",
            "                task_fields=self._task.dump_attrs(),",
            "            )",
            "            self._final_q.put(task_result, block=False)",
            "",
            "        except Exception as e:",
            "            if not isinstance(e, (IOError, EOFError, KeyboardInterrupt, SystemExit)) or isinstance(e, TemplateNotFound):",
            "                try:",
            "                    self._host.vars = dict()",
            "                    self._host.groups = []",
            "                    task_result = TaskResult(",
            "                        self._host.name,",
            "                        self._task._uuid,",
            "                        dict(failed=True, exception=to_text(traceback.format_exc()), stdout=''),",
            "                        task_fields=self._task.dump_attrs(),",
            "                    )",
            "                    self._final_q.put(task_result, block=False)",
            "                except Exception:",
            "                    display.debug(u\"WORKER EXCEPTION: %s\" % to_text(e))",
            "                    display.debug(u\"WORKER TRACEBACK: %s\" % to_text(traceback.format_exc()))",
            "                finally:",
            "                    self._clean_up()",
            "",
            "        display.debug(\"WORKER PROCESS EXITING\")",
            "",
            "        # pr.disable()",
            "        # s = StringIO.StringIO()",
            "        # sortby = 'time'",
            "        # ps = pstats.Stats(pr, stream=s).sort_stats(sortby)",
            "        # ps.print_stats()",
            "        # with open('worker_%06d.stats' % os.getpid(), 'w') as f:",
            "        #     f.write(s.getvalue())",
            "",
            "    def _clean_up(self):",
            "        # NOTE: see note in init about forks",
            "        # ensure we cleanup all temp files for this worker",
            "        self._loader.cleanup_all_tmp_files()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "lib.ansible.executor.process.worker.WorkerProcess.run",
            "lib.ansible.executor.process.worker.WorkerProcess",
            "lib.ansible.parsing.dataloader.DataLoader.path_dwim_relative_stack",
            "lib.ansible.executor.process.worker.WorkerProcess.self"
        ]
    },
    "lib/ansible/parsing/dataloader.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "     '''"
            },
            "1": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 52,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     def __init__(self):"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "         self._basedir = '.'"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        # NOTE: not effective with forks as the main copy does not get updated."
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+        # avoids rereading files"
            },
            "8": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         self._FILE_CACHE = dict()"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+        # NOTE: not thread safe, also issues with forks not returning data to main proc"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+        #       so they need to be cleaned independantly. See WorkerProcess for example."
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+        # used to keep track of temp files for cleaning"
            },
            "13": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         self._tempfiles = set()"
            },
            "14": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "         # initialize the vault stuff with an empty password"
            },
            "16": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 330,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "     def _create_content_tempfile(self, content):"
            },
            "18": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 332,
                "PatchRowcode": "         ''' Create a tempfile containing defined content '''"
            },
            "19": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        fd, content_tempfile = tempfile.mkstemp()"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+        fd, content_tempfile = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)"
            },
            "21": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "         f = os.fdopen(fd, 'wb')"
            },
            "22": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 335,
                "PatchRowcode": "         content = to_bytes(content)"
            },
            "23": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "         try:"
            },
            "24": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 393,
                "PatchRowcode": "             self._tempfiles.remove(file_path)"
            },
            "25": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 394,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "     def cleanup_all_tmp_files(self):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+        \"\"\""
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+        Removes all temporary files that DataLoader has created"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+        NOTE: not thread safe, forks also need special handling see __init__ for details."
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+        \"\"\""
            },
            "31": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 400,
                "PatchRowcode": "         for f in self._tempfiles:"
            },
            "32": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 401,
                "PatchRowcode": "             try:"
            },
            "33": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 402,
                "PatchRowcode": "                 self.cleanup_tmp_file(f)"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# Copyright: (c) 2017, Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import copy",
            "import os",
            "import os.path",
            "import re",
            "import tempfile",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleFileNotFound, AnsibleParserError",
            "from ansible.module_utils.basic import is_executable",
            "from ansible.module_utils.six import binary_type, text_type",
            "from ansible.module_utils._text import to_bytes, to_native, to_text",
            "from ansible.parsing.quoting import unquote",
            "from ansible.parsing.utils.yaml import from_yaml",
            "from ansible.parsing.vault import VaultLib, b_HEADER, is_encrypted, is_encrypted_file, parse_vaulttext_envelope",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.display import Display",
            "",
            "display = Display()",
            "",
            "",
            "# Tries to determine if a path is inside a role, last dir must be 'tasks'",
            "# this is not perfect but people should really avoid 'tasks' dirs outside roles when using Ansible.",
            "RE_TASKS = re.compile(u'(?:^|%s)+tasks%s?$' % (os.path.sep, os.path.sep))",
            "",
            "",
            "class DataLoader:",
            "",
            "    '''",
            "    The DataLoader class is used to load and parse YAML or JSON content,",
            "    either from a given file name or from a string that was previously",
            "    read in through other means. A Vault password can be specified, and",
            "    any vault-encrypted files will be decrypted.",
            "",
            "    Data read from files will also be cached, so the file will never be",
            "    read from disk more than once.",
            "",
            "    Usage:",
            "",
            "        dl = DataLoader()",
            "        # optionally: dl.set_vault_password('foo')",
            "        ds = dl.load('...')",
            "        ds = dl.load_from_file('/path/to/file')",
            "    '''",
            "",
            "    def __init__(self):",
            "        self._basedir = '.'",
            "        self._FILE_CACHE = dict()",
            "        self._tempfiles = set()",
            "",
            "        # initialize the vault stuff with an empty password",
            "        # TODO: replace with a ref to something that can get the password",
            "        #       a creds/auth provider",
            "        # self.set_vault_password(None)",
            "        self._vaults = {}",
            "        self._vault = VaultLib()",
            "        self.set_vault_secrets(None)",
            "",
            "    # TODO: since we can query vault_secrets late, we could provide this to DataLoader init",
            "    def set_vault_secrets(self, vault_secrets):",
            "        self._vault.secrets = vault_secrets",
            "",
            "    def load(self, data, file_name='<string>', show_content=True):",
            "        '''Backwards compat for now'''",
            "        return from_yaml(data, file_name, show_content, self._vault.secrets)",
            "",
            "    def load_from_file(self, file_name, cache=True, unsafe=False):",
            "        ''' Loads data from a file, which can contain either JSON or YAML.  '''",
            "",
            "        file_name = self.path_dwim(file_name)",
            "        display.debug(\"Loading data from %s\" % file_name)",
            "",
            "        # if the file has already been read in and cached, we'll",
            "        # return those results to avoid more file/vault operations",
            "        if cache and file_name in self._FILE_CACHE:",
            "            parsed_data = self._FILE_CACHE[file_name]",
            "        else:",
            "            # read the file contents and load the data structure from them",
            "            (b_file_data, show_content) = self._get_file_contents(file_name)",
            "",
            "            file_data = to_text(b_file_data, errors='surrogate_or_strict')",
            "            parsed_data = self.load(data=file_data, file_name=file_name, show_content=show_content)",
            "",
            "            # cache the file contents for next time",
            "            self._FILE_CACHE[file_name] = parsed_data",
            "",
            "        if unsafe:",
            "            return parsed_data",
            "        else:",
            "            # return a deep copy here, so the cache is not affected",
            "            return copy.deepcopy(parsed_data)",
            "",
            "    def path_exists(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.exists(to_bytes(path, errors='surrogate_or_strict'))",
            "",
            "    def is_file(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.isfile(to_bytes(path, errors='surrogate_or_strict')) or path == os.devnull",
            "",
            "    def is_directory(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.isdir(to_bytes(path, errors='surrogate_or_strict'))",
            "",
            "    def list_directory(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.listdir(path)",
            "",
            "    def is_executable(self, path):",
            "        '''is the given path executable?'''",
            "        path = self.path_dwim(path)",
            "        return is_executable(path)",
            "",
            "    def _decrypt_if_vault_data(self, b_vault_data, b_file_name=None):",
            "        '''Decrypt b_vault_data if encrypted and return b_data and the show_content flag'''",
            "",
            "        if not is_encrypted(b_vault_data):",
            "            show_content = True",
            "            return b_vault_data, show_content",
            "",
            "        b_ciphertext, b_version, cipher_name, vault_id = parse_vaulttext_envelope(b_vault_data)",
            "        b_data = self._vault.decrypt(b_vault_data, filename=b_file_name)",
            "",
            "        show_content = False",
            "        return b_data, show_content",
            "",
            "    def _get_file_contents(self, file_name):",
            "        '''",
            "        Reads the file contents from the given file name",
            "",
            "        If the contents are vault-encrypted, it will decrypt them and return",
            "        the decrypted data",
            "",
            "        :arg file_name: The name of the file to read.  If this is a relative",
            "            path, it will be expanded relative to the basedir",
            "        :raises AnsibleFileNotFound: if the file_name does not refer to a file",
            "        :raises AnsibleParserError: if we were unable to read the file",
            "        :return: Returns a byte string of the file contents",
            "        '''",
            "        if not file_name or not isinstance(file_name, (binary_type, text_type)):",
            "            raise AnsibleParserError(\"Invalid filename: '%s'\" % to_native(file_name))",
            "",
            "        b_file_name = to_bytes(self.path_dwim(file_name))",
            "        # This is what we really want but have to fix unittests to make it pass",
            "        # if not os.path.exists(b_file_name) or not os.path.isfile(b_file_name):",
            "        if not self.path_exists(b_file_name):",
            "            raise AnsibleFileNotFound(\"Unable to retrieve file contents\", file_name=file_name)",
            "",
            "        try:",
            "            with open(b_file_name, 'rb') as f:",
            "                data = f.read()",
            "                return self._decrypt_if_vault_data(data, b_file_name)",
            "        except (IOError, OSError) as e:",
            "            raise AnsibleParserError(\"an error occurred while trying to read the file '%s': %s\" % (file_name, to_native(e)), orig_exc=e)",
            "",
            "    def get_basedir(self):",
            "        ''' returns the current basedir '''",
            "        return self._basedir",
            "",
            "    def set_basedir(self, basedir):",
            "        ''' sets the base directory, used to find files when a relative path is given '''",
            "",
            "        if basedir is not None:",
            "            self._basedir = to_text(basedir)",
            "",
            "    def path_dwim(self, given):",
            "        '''",
            "        make relative paths work like folks expect.",
            "        '''",
            "",
            "        given = unquote(given)",
            "        given = to_text(given, errors='surrogate_or_strict')",
            "",
            "        if given.startswith(to_text(os.path.sep)) or given.startswith(u'~'):",
            "            path = given",
            "        else:",
            "            basedir = to_text(self._basedir, errors='surrogate_or_strict')",
            "            path = os.path.join(basedir, given)",
            "",
            "        return unfrackpath(path, follow=False)",
            "",
            "    def _is_role(self, path):",
            "        ''' imperfect role detection, roles are still valid w/o tasks|meta/main.yml|yaml|etc '''",
            "",
            "        b_path = to_bytes(path, errors='surrogate_or_strict')",
            "        b_upath = to_bytes(unfrackpath(path, follow=False), errors='surrogate_or_strict')",
            "",
            "        for b_finddir in (b'meta', b'tasks'):",
            "            for b_suffix in (b'.yml', b'.yaml', b''):",
            "                b_main = b'main%s' % (b_suffix)",
            "                b_tasked = os.path.join(b_finddir, b_main)",
            "",
            "                if (",
            "                    RE_TASKS.search(path) and",
            "                    os.path.exists(os.path.join(b_path, b_main)) or",
            "                    os.path.exists(os.path.join(b_upath, b_tasked)) or",
            "                    os.path.exists(os.path.join(os.path.dirname(b_path), b_tasked))",
            "                ):",
            "                    return True",
            "        return False",
            "",
            "    def path_dwim_relative(self, path, dirname, source, is_role=False):",
            "        '''",
            "        find one file in either a role or playbook dir with or without",
            "        explicitly named dirname subdirs",
            "",
            "        Used in action plugins and lookups to find supplemental files that",
            "        could be in either place.",
            "        '''",
            "",
            "        search = []",
            "        source = to_text(source, errors='surrogate_or_strict')",
            "",
            "        # I have full path, nothing else needs to be looked at",
            "        if source.startswith(to_text(os.path.sep)) or source.startswith(u'~'):",
            "            search.append(unfrackpath(source, follow=False))",
            "        else:",
            "            # base role/play path + templates/files/vars + relative filename",
            "            search.append(os.path.join(path, dirname, source))",
            "            basedir = unfrackpath(path, follow=False)",
            "",
            "            # not told if role, but detect if it is a role and if so make sure you get correct base path",
            "            if not is_role:",
            "                is_role = self._is_role(path)",
            "",
            "            if is_role and RE_TASKS.search(path):",
            "                basedir = unfrackpath(os.path.dirname(path), follow=False)",
            "",
            "            cur_basedir = self._basedir",
            "            self.set_basedir(basedir)",
            "            # resolved base role/play path + templates/files/vars + relative filename",
            "            search.append(unfrackpath(os.path.join(basedir, dirname, source), follow=False))",
            "            self.set_basedir(cur_basedir)",
            "",
            "            if is_role and not source.endswith(dirname):",
            "                # look in role's tasks dir w/o dirname",
            "                search.append(unfrackpath(os.path.join(basedir, 'tasks', source), follow=False))",
            "",
            "            # try to create absolute path for loader basedir + templates/files/vars + filename",
            "            search.append(unfrackpath(os.path.join(dirname, source), follow=False))",
            "",
            "            # try to create absolute path for loader basedir",
            "            search.append(unfrackpath(os.path.join(basedir, source), follow=False))",
            "",
            "            # try to create absolute path for  dirname + filename",
            "            search.append(self.path_dwim(os.path.join(dirname, source)))",
            "",
            "            # try to create absolute path for filename",
            "            search.append(self.path_dwim(source))",
            "",
            "        for candidate in search:",
            "            if os.path.exists(to_bytes(candidate, errors='surrogate_or_strict')):",
            "                break",
            "",
            "        return candidate",
            "",
            "    def path_dwim_relative_stack(self, paths, dirname, source, is_role=False):",
            "        '''",
            "        find one file in first path in stack taking roles into account and adding play basedir as fallback",
            "",
            "        :arg paths: A list of text strings which are the paths to look for the filename in.",
            "        :arg dirname: A text string representing a directory.  The directory",
            "            is prepended to the source to form the path to search for.",
            "        :arg source: A text string which is the filename to search for",
            "        :rtype: A text string",
            "        :returns: An absolute path to the filename ``source`` if found",
            "        :raises: An AnsibleFileNotFound Exception if the file is found to exist in the search paths",
            "        '''",
            "        b_dirname = to_bytes(dirname, errors='surrogate_or_strict')",
            "        b_source = to_bytes(source, errors='surrogate_or_strict')",
            "",
            "        result = None",
            "        search = []",
            "        if source is None:",
            "            display.warning('Invalid request to find a file that matches a \"null\" value')",
            "        elif source and (source.startswith('~') or source.startswith(os.path.sep)):",
            "            # path is absolute, no relative needed, check existence and return source",
            "            test_path = unfrackpath(b_source, follow=False)",
            "            if os.path.exists(to_bytes(test_path, errors='surrogate_or_strict')):",
            "                result = test_path",
            "        else:",
            "            display.debug(u'evaluation_path:\\n\\t%s' % '\\n\\t'.join(paths))",
            "            for path in paths:",
            "                upath = unfrackpath(path, follow=False)",
            "                b_upath = to_bytes(upath, errors='surrogate_or_strict')",
            "                b_pb_base_dir = os.path.dirname(b_upath)",
            "",
            "                # if path is in role and 'tasks' not there already, add it into the search",
            "                if (is_role or self._is_role(path)) and b_pb_base_dir.endswith(b'/tasks'):",
            "                    search.append(os.path.join(os.path.dirname(b_pb_base_dir), b_dirname, b_source))",
            "                    search.append(os.path.join(b_pb_base_dir, b_source))",
            "                else:",
            "                    # don't add dirname if user already is using it in source",
            "                    if b_source.split(b'/')[0] != dirname:",
            "                        search.append(os.path.join(b_upath, b_dirname, b_source))",
            "                    search.append(os.path.join(b_upath, b_source))",
            "",
            "            # always append basedir as last resort",
            "            # don't add dirname if user already is using it in source",
            "            if b_source.split(b'/')[0] != dirname:",
            "                search.append(os.path.join(to_bytes(self.get_basedir(), errors='surrogate_or_strict'), b_dirname, b_source))",
            "            search.append(os.path.join(to_bytes(self.get_basedir(), errors='surrogate_or_strict'), b_source))",
            "",
            "            display.debug(u'search_path:\\n\\t%s' % to_text(b'\\n\\t'.join(search)))",
            "            for b_candidate in search:",
            "                display.vvvvv(u'looking for \"%s\" at \"%s\"' % (source, to_text(b_candidate)))",
            "                if os.path.exists(b_candidate):",
            "                    result = to_text(b_candidate)",
            "                    break",
            "",
            "        if result is None:",
            "            raise AnsibleFileNotFound(file_name=source, paths=[to_native(p) for p in search])",
            "",
            "        return result",
            "",
            "    def _create_content_tempfile(self, content):",
            "        ''' Create a tempfile containing defined content '''",
            "        fd, content_tempfile = tempfile.mkstemp()",
            "        f = os.fdopen(fd, 'wb')",
            "        content = to_bytes(content)",
            "        try:",
            "            f.write(content)",
            "        except Exception as err:",
            "            os.remove(content_tempfile)",
            "            raise Exception(err)",
            "        finally:",
            "            f.close()",
            "        return content_tempfile",
            "",
            "    def get_real_file(self, file_path, decrypt=True):",
            "        \"\"\"",
            "        If the file is vault encrypted return a path to a temporary decrypted file",
            "        If the file is not encrypted then the path is returned",
            "        Temporary files are cleanup in the destructor",
            "        \"\"\"",
            "",
            "        if not file_path or not isinstance(file_path, (binary_type, text_type)):",
            "            raise AnsibleParserError(\"Invalid filename: '%s'\" % to_native(file_path))",
            "",
            "        b_file_path = to_bytes(file_path, errors='surrogate_or_strict')",
            "        if not self.path_exists(b_file_path) or not self.is_file(b_file_path):",
            "            raise AnsibleFileNotFound(file_name=file_path)",
            "",
            "        real_path = self.path_dwim(file_path)",
            "",
            "        try:",
            "            if decrypt:",
            "                with open(to_bytes(real_path), 'rb') as f:",
            "                    # Limit how much of the file is read since we do not know",
            "                    # whether this is a vault file and therefore it could be very",
            "                    # large.",
            "                    if is_encrypted_file(f, count=len(b_HEADER)):",
            "                        # if the file is encrypted and no password was specified,",
            "                        # the decrypt call would throw an error, but we check first",
            "                        # since the decrypt function doesn't know the file name",
            "                        data = f.read()",
            "                        if not self._vault.secrets:",
            "                            raise AnsibleParserError(\"A vault password or secret must be specified to decrypt %s\" % to_native(file_path))",
            "",
            "                        data = self._vault.decrypt(data, filename=real_path)",
            "                        # Make a temp file",
            "                        real_path = self._create_content_tempfile(data)",
            "                        self._tempfiles.add(real_path)",
            "",
            "            return real_path",
            "",
            "        except (IOError, OSError) as e:",
            "            raise AnsibleParserError(\"an error occurred while trying to read the file '%s': %s\" % (to_native(real_path), to_native(e)), orig_exc=e)",
            "",
            "    def cleanup_tmp_file(self, file_path):",
            "        \"\"\"",
            "        Removes any temporary files created from a previous call to",
            "        get_real_file. file_path must be the path returned from a",
            "        previous call to get_real_file.",
            "        \"\"\"",
            "        if file_path in self._tempfiles:",
            "            os.unlink(file_path)",
            "            self._tempfiles.remove(file_path)",
            "",
            "    def cleanup_all_tmp_files(self):",
            "        for f in self._tempfiles:",
            "            try:",
            "                self.cleanup_tmp_file(f)",
            "            except Exception as e:",
            "                display.warning(\"Unable to cleanup temp files: %s\" % to_text(e))",
            "",
            "    def find_vars_files(self, path, name, extensions=None, allow_dir=True):",
            "        \"\"\"",
            "        Find vars files in a given path with specified name. This will find",
            "        files in a dir named <name>/ or a file called <name> ending in known",
            "        extensions.",
            "        \"\"\"",
            "",
            "        b_path = to_bytes(os.path.join(path, name))",
            "        found = []",
            "",
            "        if extensions is None:",
            "            # Look for file with no extension first to find dir before file",
            "            extensions = [''] + C.YAML_FILENAME_EXTENSIONS",
            "        # add valid extensions to name",
            "        for ext in extensions:",
            "",
            "            if '.' in ext:",
            "                full_path = b_path + to_bytes(ext)",
            "            elif ext:",
            "                full_path = b'.'.join([b_path, to_bytes(ext)])",
            "            else:",
            "                full_path = b_path",
            "",
            "            if self.path_exists(full_path):",
            "                if self.is_directory(full_path):",
            "                    if allow_dir:",
            "                        found.extend(self._get_dir_vars_files(to_text(full_path), extensions))",
            "                    else:",
            "                        continue",
            "                else:",
            "                    found.append(full_path)",
            "                break",
            "        return found",
            "",
            "    def _get_dir_vars_files(self, path, extensions):",
            "        found = []",
            "        for spath in sorted(self.list_directory(path)):",
            "            if not spath.startswith(u'.') and not spath.endswith(u'~'):  # skip hidden and backups",
            "",
            "                ext = os.path.splitext(spath)[-1]",
            "                full_spath = os.path.join(path, spath)",
            "",
            "                if self.is_directory(full_spath) and not ext:  # recursive search if dir",
            "                    found.extend(self._get_dir_vars_files(full_spath, extensions))",
            "                elif self.is_file(full_spath) and (not ext or to_text(ext) in extensions):",
            "                    # only consider files with valid extensions or no extension",
            "                    found.append(full_spath)",
            "",
            "        return found"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# Copyright: (c) 2017, Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import copy",
            "import os",
            "import os.path",
            "import re",
            "import tempfile",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleFileNotFound, AnsibleParserError",
            "from ansible.module_utils.basic import is_executable",
            "from ansible.module_utils.six import binary_type, text_type",
            "from ansible.module_utils._text import to_bytes, to_native, to_text",
            "from ansible.parsing.quoting import unquote",
            "from ansible.parsing.utils.yaml import from_yaml",
            "from ansible.parsing.vault import VaultLib, b_HEADER, is_encrypted, is_encrypted_file, parse_vaulttext_envelope",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.display import Display",
            "",
            "display = Display()",
            "",
            "",
            "# Tries to determine if a path is inside a role, last dir must be 'tasks'",
            "# this is not perfect but people should really avoid 'tasks' dirs outside roles when using Ansible.",
            "RE_TASKS = re.compile(u'(?:^|%s)+tasks%s?$' % (os.path.sep, os.path.sep))",
            "",
            "",
            "class DataLoader:",
            "",
            "    '''",
            "    The DataLoader class is used to load and parse YAML or JSON content,",
            "    either from a given file name or from a string that was previously",
            "    read in through other means. A Vault password can be specified, and",
            "    any vault-encrypted files will be decrypted.",
            "",
            "    Data read from files will also be cached, so the file will never be",
            "    read from disk more than once.",
            "",
            "    Usage:",
            "",
            "        dl = DataLoader()",
            "        # optionally: dl.set_vault_password('foo')",
            "        ds = dl.load('...')",
            "        ds = dl.load_from_file('/path/to/file')",
            "    '''",
            "",
            "    def __init__(self):",
            "",
            "        self._basedir = '.'",
            "",
            "        # NOTE: not effective with forks as the main copy does not get updated.",
            "        # avoids rereading files",
            "        self._FILE_CACHE = dict()",
            "",
            "        # NOTE: not thread safe, also issues with forks not returning data to main proc",
            "        #       so they need to be cleaned independantly. See WorkerProcess for example.",
            "        # used to keep track of temp files for cleaning",
            "        self._tempfiles = set()",
            "",
            "        # initialize the vault stuff with an empty password",
            "        # TODO: replace with a ref to something that can get the password",
            "        #       a creds/auth provider",
            "        # self.set_vault_password(None)",
            "        self._vaults = {}",
            "        self._vault = VaultLib()",
            "        self.set_vault_secrets(None)",
            "",
            "    # TODO: since we can query vault_secrets late, we could provide this to DataLoader init",
            "    def set_vault_secrets(self, vault_secrets):",
            "        self._vault.secrets = vault_secrets",
            "",
            "    def load(self, data, file_name='<string>', show_content=True):",
            "        '''Backwards compat for now'''",
            "        return from_yaml(data, file_name, show_content, self._vault.secrets)",
            "",
            "    def load_from_file(self, file_name, cache=True, unsafe=False):",
            "        ''' Loads data from a file, which can contain either JSON or YAML.  '''",
            "",
            "        file_name = self.path_dwim(file_name)",
            "        display.debug(\"Loading data from %s\" % file_name)",
            "",
            "        # if the file has already been read in and cached, we'll",
            "        # return those results to avoid more file/vault operations",
            "        if cache and file_name in self._FILE_CACHE:",
            "            parsed_data = self._FILE_CACHE[file_name]",
            "        else:",
            "            # read the file contents and load the data structure from them",
            "            (b_file_data, show_content) = self._get_file_contents(file_name)",
            "",
            "            file_data = to_text(b_file_data, errors='surrogate_or_strict')",
            "            parsed_data = self.load(data=file_data, file_name=file_name, show_content=show_content)",
            "",
            "            # cache the file contents for next time",
            "            self._FILE_CACHE[file_name] = parsed_data",
            "",
            "        if unsafe:",
            "            return parsed_data",
            "        else:",
            "            # return a deep copy here, so the cache is not affected",
            "            return copy.deepcopy(parsed_data)",
            "",
            "    def path_exists(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.exists(to_bytes(path, errors='surrogate_or_strict'))",
            "",
            "    def is_file(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.isfile(to_bytes(path, errors='surrogate_or_strict')) or path == os.devnull",
            "",
            "    def is_directory(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.path.isdir(to_bytes(path, errors='surrogate_or_strict'))",
            "",
            "    def list_directory(self, path):",
            "        path = self.path_dwim(path)",
            "        return os.listdir(path)",
            "",
            "    def is_executable(self, path):",
            "        '''is the given path executable?'''",
            "        path = self.path_dwim(path)",
            "        return is_executable(path)",
            "",
            "    def _decrypt_if_vault_data(self, b_vault_data, b_file_name=None):",
            "        '''Decrypt b_vault_data if encrypted and return b_data and the show_content flag'''",
            "",
            "        if not is_encrypted(b_vault_data):",
            "            show_content = True",
            "            return b_vault_data, show_content",
            "",
            "        b_ciphertext, b_version, cipher_name, vault_id = parse_vaulttext_envelope(b_vault_data)",
            "        b_data = self._vault.decrypt(b_vault_data, filename=b_file_name)",
            "",
            "        show_content = False",
            "        return b_data, show_content",
            "",
            "    def _get_file_contents(self, file_name):",
            "        '''",
            "        Reads the file contents from the given file name",
            "",
            "        If the contents are vault-encrypted, it will decrypt them and return",
            "        the decrypted data",
            "",
            "        :arg file_name: The name of the file to read.  If this is a relative",
            "            path, it will be expanded relative to the basedir",
            "        :raises AnsibleFileNotFound: if the file_name does not refer to a file",
            "        :raises AnsibleParserError: if we were unable to read the file",
            "        :return: Returns a byte string of the file contents",
            "        '''",
            "        if not file_name or not isinstance(file_name, (binary_type, text_type)):",
            "            raise AnsibleParserError(\"Invalid filename: '%s'\" % to_native(file_name))",
            "",
            "        b_file_name = to_bytes(self.path_dwim(file_name))",
            "        # This is what we really want but have to fix unittests to make it pass",
            "        # if not os.path.exists(b_file_name) or not os.path.isfile(b_file_name):",
            "        if not self.path_exists(b_file_name):",
            "            raise AnsibleFileNotFound(\"Unable to retrieve file contents\", file_name=file_name)",
            "",
            "        try:",
            "            with open(b_file_name, 'rb') as f:",
            "                data = f.read()",
            "                return self._decrypt_if_vault_data(data, b_file_name)",
            "        except (IOError, OSError) as e:",
            "            raise AnsibleParserError(\"an error occurred while trying to read the file '%s': %s\" % (file_name, to_native(e)), orig_exc=e)",
            "",
            "    def get_basedir(self):",
            "        ''' returns the current basedir '''",
            "        return self._basedir",
            "",
            "    def set_basedir(self, basedir):",
            "        ''' sets the base directory, used to find files when a relative path is given '''",
            "",
            "        if basedir is not None:",
            "            self._basedir = to_text(basedir)",
            "",
            "    def path_dwim(self, given):",
            "        '''",
            "        make relative paths work like folks expect.",
            "        '''",
            "",
            "        given = unquote(given)",
            "        given = to_text(given, errors='surrogate_or_strict')",
            "",
            "        if given.startswith(to_text(os.path.sep)) or given.startswith(u'~'):",
            "            path = given",
            "        else:",
            "            basedir = to_text(self._basedir, errors='surrogate_or_strict')",
            "            path = os.path.join(basedir, given)",
            "",
            "        return unfrackpath(path, follow=False)",
            "",
            "    def _is_role(self, path):",
            "        ''' imperfect role detection, roles are still valid w/o tasks|meta/main.yml|yaml|etc '''",
            "",
            "        b_path = to_bytes(path, errors='surrogate_or_strict')",
            "        b_upath = to_bytes(unfrackpath(path, follow=False), errors='surrogate_or_strict')",
            "",
            "        for b_finddir in (b'meta', b'tasks'):",
            "            for b_suffix in (b'.yml', b'.yaml', b''):",
            "                b_main = b'main%s' % (b_suffix)",
            "                b_tasked = os.path.join(b_finddir, b_main)",
            "",
            "                if (",
            "                    RE_TASKS.search(path) and",
            "                    os.path.exists(os.path.join(b_path, b_main)) or",
            "                    os.path.exists(os.path.join(b_upath, b_tasked)) or",
            "                    os.path.exists(os.path.join(os.path.dirname(b_path), b_tasked))",
            "                ):",
            "                    return True",
            "        return False",
            "",
            "    def path_dwim_relative(self, path, dirname, source, is_role=False):",
            "        '''",
            "        find one file in either a role or playbook dir with or without",
            "        explicitly named dirname subdirs",
            "",
            "        Used in action plugins and lookups to find supplemental files that",
            "        could be in either place.",
            "        '''",
            "",
            "        search = []",
            "        source = to_text(source, errors='surrogate_or_strict')",
            "",
            "        # I have full path, nothing else needs to be looked at",
            "        if source.startswith(to_text(os.path.sep)) or source.startswith(u'~'):",
            "            search.append(unfrackpath(source, follow=False))",
            "        else:",
            "            # base role/play path + templates/files/vars + relative filename",
            "            search.append(os.path.join(path, dirname, source))",
            "            basedir = unfrackpath(path, follow=False)",
            "",
            "            # not told if role, but detect if it is a role and if so make sure you get correct base path",
            "            if not is_role:",
            "                is_role = self._is_role(path)",
            "",
            "            if is_role and RE_TASKS.search(path):",
            "                basedir = unfrackpath(os.path.dirname(path), follow=False)",
            "",
            "            cur_basedir = self._basedir",
            "            self.set_basedir(basedir)",
            "            # resolved base role/play path + templates/files/vars + relative filename",
            "            search.append(unfrackpath(os.path.join(basedir, dirname, source), follow=False))",
            "            self.set_basedir(cur_basedir)",
            "",
            "            if is_role and not source.endswith(dirname):",
            "                # look in role's tasks dir w/o dirname",
            "                search.append(unfrackpath(os.path.join(basedir, 'tasks', source), follow=False))",
            "",
            "            # try to create absolute path for loader basedir + templates/files/vars + filename",
            "            search.append(unfrackpath(os.path.join(dirname, source), follow=False))",
            "",
            "            # try to create absolute path for loader basedir",
            "            search.append(unfrackpath(os.path.join(basedir, source), follow=False))",
            "",
            "            # try to create absolute path for  dirname + filename",
            "            search.append(self.path_dwim(os.path.join(dirname, source)))",
            "",
            "            # try to create absolute path for filename",
            "            search.append(self.path_dwim(source))",
            "",
            "        for candidate in search:",
            "            if os.path.exists(to_bytes(candidate, errors='surrogate_or_strict')):",
            "                break",
            "",
            "        return candidate",
            "",
            "    def path_dwim_relative_stack(self, paths, dirname, source, is_role=False):",
            "        '''",
            "        find one file in first path in stack taking roles into account and adding play basedir as fallback",
            "",
            "        :arg paths: A list of text strings which are the paths to look for the filename in.",
            "        :arg dirname: A text string representing a directory.  The directory",
            "            is prepended to the source to form the path to search for.",
            "        :arg source: A text string which is the filename to search for",
            "        :rtype: A text string",
            "        :returns: An absolute path to the filename ``source`` if found",
            "        :raises: An AnsibleFileNotFound Exception if the file is found to exist in the search paths",
            "        '''",
            "        b_dirname = to_bytes(dirname, errors='surrogate_or_strict')",
            "        b_source = to_bytes(source, errors='surrogate_or_strict')",
            "",
            "        result = None",
            "        search = []",
            "        if source is None:",
            "            display.warning('Invalid request to find a file that matches a \"null\" value')",
            "        elif source and (source.startswith('~') or source.startswith(os.path.sep)):",
            "            # path is absolute, no relative needed, check existence and return source",
            "            test_path = unfrackpath(b_source, follow=False)",
            "            if os.path.exists(to_bytes(test_path, errors='surrogate_or_strict')):",
            "                result = test_path",
            "        else:",
            "            display.debug(u'evaluation_path:\\n\\t%s' % '\\n\\t'.join(paths))",
            "            for path in paths:",
            "                upath = unfrackpath(path, follow=False)",
            "                b_upath = to_bytes(upath, errors='surrogate_or_strict')",
            "                b_pb_base_dir = os.path.dirname(b_upath)",
            "",
            "                # if path is in role and 'tasks' not there already, add it into the search",
            "                if (is_role or self._is_role(path)) and b_pb_base_dir.endswith(b'/tasks'):",
            "                    search.append(os.path.join(os.path.dirname(b_pb_base_dir), b_dirname, b_source))",
            "                    search.append(os.path.join(b_pb_base_dir, b_source))",
            "                else:",
            "                    # don't add dirname if user already is using it in source",
            "                    if b_source.split(b'/')[0] != dirname:",
            "                        search.append(os.path.join(b_upath, b_dirname, b_source))",
            "                    search.append(os.path.join(b_upath, b_source))",
            "",
            "            # always append basedir as last resort",
            "            # don't add dirname if user already is using it in source",
            "            if b_source.split(b'/')[0] != dirname:",
            "                search.append(os.path.join(to_bytes(self.get_basedir(), errors='surrogate_or_strict'), b_dirname, b_source))",
            "            search.append(os.path.join(to_bytes(self.get_basedir(), errors='surrogate_or_strict'), b_source))",
            "",
            "            display.debug(u'search_path:\\n\\t%s' % to_text(b'\\n\\t'.join(search)))",
            "            for b_candidate in search:",
            "                display.vvvvv(u'looking for \"%s\" at \"%s\"' % (source, to_text(b_candidate)))",
            "                if os.path.exists(b_candidate):",
            "                    result = to_text(b_candidate)",
            "                    break",
            "",
            "        if result is None:",
            "            raise AnsibleFileNotFound(file_name=source, paths=[to_native(p) for p in search])",
            "",
            "        return result",
            "",
            "    def _create_content_tempfile(self, content):",
            "        ''' Create a tempfile containing defined content '''",
            "        fd, content_tempfile = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)",
            "        f = os.fdopen(fd, 'wb')",
            "        content = to_bytes(content)",
            "        try:",
            "            f.write(content)",
            "        except Exception as err:",
            "            os.remove(content_tempfile)",
            "            raise Exception(err)",
            "        finally:",
            "            f.close()",
            "        return content_tempfile",
            "",
            "    def get_real_file(self, file_path, decrypt=True):",
            "        \"\"\"",
            "        If the file is vault encrypted return a path to a temporary decrypted file",
            "        If the file is not encrypted then the path is returned",
            "        Temporary files are cleanup in the destructor",
            "        \"\"\"",
            "",
            "        if not file_path or not isinstance(file_path, (binary_type, text_type)):",
            "            raise AnsibleParserError(\"Invalid filename: '%s'\" % to_native(file_path))",
            "",
            "        b_file_path = to_bytes(file_path, errors='surrogate_or_strict')",
            "        if not self.path_exists(b_file_path) or not self.is_file(b_file_path):",
            "            raise AnsibleFileNotFound(file_name=file_path)",
            "",
            "        real_path = self.path_dwim(file_path)",
            "",
            "        try:",
            "            if decrypt:",
            "                with open(to_bytes(real_path), 'rb') as f:",
            "                    # Limit how much of the file is read since we do not know",
            "                    # whether this is a vault file and therefore it could be very",
            "                    # large.",
            "                    if is_encrypted_file(f, count=len(b_HEADER)):",
            "                        # if the file is encrypted and no password was specified,",
            "                        # the decrypt call would throw an error, but we check first",
            "                        # since the decrypt function doesn't know the file name",
            "                        data = f.read()",
            "                        if not self._vault.secrets:",
            "                            raise AnsibleParserError(\"A vault password or secret must be specified to decrypt %s\" % to_native(file_path))",
            "",
            "                        data = self._vault.decrypt(data, filename=real_path)",
            "                        # Make a temp file",
            "                        real_path = self._create_content_tempfile(data)",
            "                        self._tempfiles.add(real_path)",
            "",
            "            return real_path",
            "",
            "        except (IOError, OSError) as e:",
            "            raise AnsibleParserError(\"an error occurred while trying to read the file '%s': %s\" % (to_native(real_path), to_native(e)), orig_exc=e)",
            "",
            "    def cleanup_tmp_file(self, file_path):",
            "        \"\"\"",
            "        Removes any temporary files created from a previous call to",
            "        get_real_file. file_path must be the path returned from a",
            "        previous call to get_real_file.",
            "        \"\"\"",
            "        if file_path in self._tempfiles:",
            "            os.unlink(file_path)",
            "            self._tempfiles.remove(file_path)",
            "",
            "    def cleanup_all_tmp_files(self):",
            "        \"\"\"",
            "        Removes all temporary files that DataLoader has created",
            "        NOTE: not thread safe, forks also need special handling see __init__ for details.",
            "        \"\"\"",
            "        for f in self._tempfiles:",
            "            try:",
            "                self.cleanup_tmp_file(f)",
            "            except Exception as e:",
            "                display.warning(\"Unable to cleanup temp files: %s\" % to_text(e))",
            "",
            "    def find_vars_files(self, path, name, extensions=None, allow_dir=True):",
            "        \"\"\"",
            "        Find vars files in a given path with specified name. This will find",
            "        files in a dir named <name>/ or a file called <name> ending in known",
            "        extensions.",
            "        \"\"\"",
            "",
            "        b_path = to_bytes(os.path.join(path, name))",
            "        found = []",
            "",
            "        if extensions is None:",
            "            # Look for file with no extension first to find dir before file",
            "            extensions = [''] + C.YAML_FILENAME_EXTENSIONS",
            "        # add valid extensions to name",
            "        for ext in extensions:",
            "",
            "            if '.' in ext:",
            "                full_path = b_path + to_bytes(ext)",
            "            elif ext:",
            "                full_path = b'.'.join([b_path, to_bytes(ext)])",
            "            else:",
            "                full_path = b_path",
            "",
            "            if self.path_exists(full_path):",
            "                if self.is_directory(full_path):",
            "                    if allow_dir:",
            "                        found.extend(self._get_dir_vars_files(to_text(full_path), extensions))",
            "                    else:",
            "                        continue",
            "                else:",
            "                    found.append(full_path)",
            "                break",
            "        return found",
            "",
            "    def _get_dir_vars_files(self, path, extensions):",
            "        found = []",
            "        for spath in sorted(self.list_directory(path)):",
            "            if not spath.startswith(u'.') and not spath.endswith(u'~'):  # skip hidden and backups",
            "",
            "                ext = os.path.splitext(spath)[-1]",
            "                full_spath = os.path.join(path, spath)",
            "",
            "                if self.is_directory(full_spath) and not ext:  # recursive search if dir",
            "                    found.extend(self._get_dir_vars_files(full_spath, extensions))",
            "                elif self.is_file(full_spath) and (not ext or to_text(ext) in extensions):",
            "                    # only consider files with valid extensions or no extension",
            "                    found.append(full_spath)",
            "",
            "        return found"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "325": [
                "DataLoader",
                "_create_content_tempfile"
            ]
        },
        "addLocation": [
            "lib.ansible.parsing.dataloader.DataLoader",
            "lib.ansible.parsing.dataloader.DataLoader._vaults",
            "lib.ansible.parsing.dataloader.DataLoader.path_dwim_relative_stack"
        ]
    },
    "lib/ansible/parsing/vault/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 850,
                "afterPatchRowNumber": 850,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 851,
                "afterPatchRowNumber": 851,
                "PatchRowcode": "         # Create a tempfile"
            },
            "2": {
                "beforePatchRowNumber": 852,
                "afterPatchRowNumber": 852,
                "PatchRowcode": "         root, ext = os.path.splitext(os.path.realpath(filename))"
            },
            "3": {
                "beforePatchRowNumber": 853,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        fd, tmp_path = tempfile.mkstemp(suffix=ext)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 853,
                "PatchRowcode": "+        fd, tmp_path = tempfile.mkstemp(suffix=ext, dir=C.DEFAULT_LOCAL_TMP)"
            },
            "5": {
                "beforePatchRowNumber": 854,
                "afterPatchRowNumber": 854,
                "PatchRowcode": "         os.close(fd)"
            },
            "6": {
                "beforePatchRowNumber": 855,
                "afterPatchRowNumber": 855,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 856,
                "afterPatchRowNumber": 856,
                "PatchRowcode": "         cmd = self._editor_shell_command(tmp_path)"
            }
        },
        "frontPatchFile": [
            "# (c) 2014, James Tanner <tanner.jc@gmail.com>",
            "# (c) 2016, Adrian Likins <alikins@redhat.com>",
            "# (c) 2016 Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import random",
            "import shlex",
            "import shutil",
            "import subprocess",
            "import sys",
            "import tempfile",
            "import warnings",
            "from binascii import hexlify",
            "from binascii import unhexlify",
            "from binascii import Error as BinasciiError",
            "",
            "HAS_CRYPTOGRAPHY = False",
            "HAS_PYCRYPTO = False",
            "HAS_SOME_PYCRYPTO = False",
            "CRYPTOGRAPHY_BACKEND = None",
            "try:",
            "    with warnings.catch_warnings():",
            "        warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "        from cryptography.exceptions import InvalidSignature",
            "    from cryptography.hazmat.backends import default_backend",
            "    from cryptography.hazmat.primitives import hashes, padding",
            "    from cryptography.hazmat.primitives.hmac import HMAC",
            "    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC",
            "    from cryptography.hazmat.primitives.ciphers import (",
            "        Cipher as C_Cipher, algorithms, modes",
            "    )",
            "    CRYPTOGRAPHY_BACKEND = default_backend()",
            "    HAS_CRYPTOGRAPHY = True",
            "except ImportError:",
            "    pass",
            "",
            "try:",
            "    from Crypto.Cipher import AES as AES_pycrypto",
            "    HAS_SOME_PYCRYPTO = True",
            "",
            "    # Note: Only used for loading obsolete VaultAES files.  All files are written",
            "    # using the newer VaultAES256 which does not require md5",
            "    from Crypto.Hash import SHA256 as SHA256_pycrypto",
            "    from Crypto.Hash import HMAC as HMAC_pycrypto",
            "",
            "    # Counter import fails for 2.0.1, requires >= 2.6.1 from pip",
            "    from Crypto.Util import Counter as Counter_pycrypto",
            "",
            "    # KDF import fails for 2.0.1, requires >= 2.6.1 from pip",
            "    from Crypto.Protocol.KDF import PBKDF2 as PBKDF2_pycrypto",
            "    HAS_PYCRYPTO = True",
            "except ImportError:",
            "    pass",
            "",
            "from ansible.errors import AnsibleError, AnsibleAssertionError",
            "from ansible import constants as C",
            "from ansible.module_utils.six import PY3, binary_type",
            "# Note: on py2, this zip is izip not the list based zip() builtin",
            "from ansible.module_utils.six.moves import zip",
            "from ansible.module_utils._text import to_bytes, to_text, to_native",
            "from ansible.utils.display import Display",
            "from ansible.utils.path import makedirs_safe",
            "",
            "display = Display()",
            "",
            "",
            "b_HEADER = b'$ANSIBLE_VAULT'",
            "CIPHER_WHITELIST = frozenset((u'AES256',))",
            "CIPHER_WRITE_WHITELIST = frozenset((u'AES256',))",
            "# See also CIPHER_MAPPING at the bottom of the file which maps cipher strings",
            "# (used in VaultFile header) to a cipher class",
            "",
            "NEED_CRYPTO_LIBRARY = \"ansible-vault requires either the cryptography library (preferred) or\"",
            "if HAS_SOME_PYCRYPTO:",
            "    NEED_CRYPTO_LIBRARY += \" a newer version of\"",
            "NEED_CRYPTO_LIBRARY += \" pycrypto in order to function.\"",
            "",
            "",
            "class AnsibleVaultError(AnsibleError):",
            "    pass",
            "",
            "",
            "class AnsibleVaultPasswordError(AnsibleVaultError):",
            "    pass",
            "",
            "",
            "class AnsibleVaultFormatError(AnsibleError):",
            "    pass",
            "",
            "",
            "def is_encrypted(data):",
            "    \"\"\" Test if this is vault encrypted data blob",
            "",
            "    :arg data: a byte or text string to test whether it is recognized as vault",
            "        encrypted data",
            "    :returns: True if it is recognized.  Otherwise, False.",
            "    \"\"\"",
            "    try:",
            "        # Make sure we have a byte string and that it only contains ascii",
            "        # bytes.",
            "        b_data = to_bytes(to_text(data, encoding='ascii', errors='strict', nonstring='strict'), encoding='ascii', errors='strict')",
            "    except (UnicodeError, TypeError):",
            "        # The vault format is pure ascii so if we failed to encode to bytes",
            "        # via ascii we know that this is not vault data.",
            "        # Similarly, if it's not a string, it's not vault data",
            "        return False",
            "",
            "    if b_data.startswith(b_HEADER):",
            "        return True",
            "    return False",
            "",
            "",
            "def is_encrypted_file(file_obj, start_pos=0, count=-1):",
            "    \"\"\"Test if the contents of a file obj are a vault encrypted data blob.",
            "",
            "    :arg file_obj: A file object that will be read from.",
            "    :kwarg start_pos: A byte offset in the file to start reading the header",
            "        from.  Defaults to 0, the beginning of the file.",
            "    :kwarg count: Read up to this number of bytes from the file to determine",
            "        if it looks like encrypted vault data.  The default is -1, read to the",
            "        end of file.",
            "    :returns: True if the file looks like a vault file. Otherwise, False.",
            "    \"\"\"",
            "    # read the header and reset the file stream to where it started",
            "    current_position = file_obj.tell()",
            "    try:",
            "        file_obj.seek(start_pos)",
            "        return is_encrypted(file_obj.read(count))",
            "",
            "    finally:",
            "        file_obj.seek(current_position)",
            "",
            "",
            "def _parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id=None):",
            "",
            "    b_tmpdata = b_vaulttext_envelope.splitlines()",
            "    b_tmpheader = b_tmpdata[0].strip().split(b';')",
            "",
            "    b_version = b_tmpheader[1].strip()",
            "    cipher_name = to_text(b_tmpheader[2].strip())",
            "    vault_id = default_vault_id",
            "",
            "    # Only attempt to find vault_id if the vault file is version 1.2 or newer",
            "    # if self.b_version == b'1.2':",
            "    if len(b_tmpheader) >= 4:",
            "        vault_id = to_text(b_tmpheader[3].strip())",
            "",
            "    b_ciphertext = b''.join(b_tmpdata[1:])",
            "",
            "    return b_ciphertext, b_version, cipher_name, vault_id",
            "",
            "",
            "def parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id=None, filename=None):",
            "    \"\"\"Parse the vaulttext envelope",
            "",
            "    When data is saved, it has a header prepended and is formatted into 80",
            "    character lines.  This method extracts the information from the header",
            "    and then removes the header and the inserted newlines.  The string returned",
            "    is suitable for processing by the Cipher classes.",
            "",
            "    :arg b_vaulttext: byte str containing the data from a save file",
            "    :kwarg default_vault_id: The vault_id name to use if the vaulttext does not provide one.",
            "    :kwarg filename: The filename that the data came from.  This is only",
            "        used to make better error messages in case the data cannot be",
            "        decrypted. This is optional.",
            "    :returns: A tuple of byte str of the vaulttext suitable to pass to parse_vaultext,",
            "        a byte str of the vault format version,",
            "        the name of the cipher used, and the vault_id.",
            "    :raises: AnsibleVaultFormatError: if the vaulttext_envelope format is invalid",
            "    \"\"\"",
            "    # used by decrypt",
            "    default_vault_id = default_vault_id or C.DEFAULT_VAULT_IDENTITY",
            "",
            "    try:",
            "        return _parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id)",
            "    except Exception as exc:",
            "        msg = \"Vault envelope format error\"",
            "        if filename:",
            "            msg += ' in %s' % (filename)",
            "        msg += ': %s' % exc",
            "        raise AnsibleVaultFormatError(msg)",
            "",
            "",
            "def format_vaulttext_envelope(b_ciphertext, cipher_name, version=None, vault_id=None):",
            "    \"\"\" Add header and format to 80 columns",
            "",
            "        :arg b_ciphertext: the encrypted and hexlified data as a byte string",
            "        :arg cipher_name: unicode cipher name (for ex, u'AES256')",
            "        :arg version: unicode vault version (for ex, '1.2'). Optional ('1.1' is default)",
            "        :arg vault_id: unicode vault identifier. If provided, the version will be bumped to 1.2.",
            "        :returns: a byte str that should be dumped into a file.  It's",
            "            formatted to 80 char columns and has the header prepended",
            "    \"\"\"",
            "",
            "    if not cipher_name:",
            "        raise AnsibleError(\"the cipher must be set before adding a header\")",
            "",
            "    version = version or '1.1'",
            "",
            "    # If we specify a vault_id, use format version 1.2. For no vault_id, stick to 1.1",
            "    if vault_id and vault_id != u'default':",
            "        version = '1.2'",
            "",
            "    b_version = to_bytes(version, 'utf-8', errors='strict')",
            "    b_vault_id = to_bytes(vault_id, 'utf-8', errors='strict')",
            "    b_cipher_name = to_bytes(cipher_name, 'utf-8', errors='strict')",
            "",
            "    header_parts = [b_HEADER,",
            "                    b_version,",
            "                    b_cipher_name]",
            "",
            "    if b_version == b'1.2' and b_vault_id:",
            "        header_parts.append(b_vault_id)",
            "",
            "    header = b';'.join(header_parts)",
            "",
            "    b_vaulttext = [header]",
            "    b_vaulttext += [b_ciphertext[i:i + 80] for i in range(0, len(b_ciphertext), 80)]",
            "    b_vaulttext += [b'']",
            "    b_vaulttext = b'\\n'.join(b_vaulttext)",
            "",
            "    return b_vaulttext",
            "",
            "",
            "def _unhexlify(b_data):",
            "    try:",
            "        return unhexlify(b_data)",
            "    except (BinasciiError, TypeError) as exc:",
            "        raise AnsibleVaultFormatError('Vault format unhexlify error: %s' % exc)",
            "",
            "",
            "def _parse_vaulttext(b_vaulttext):",
            "    b_vaulttext = _unhexlify(b_vaulttext)",
            "    b_salt, b_crypted_hmac, b_ciphertext = b_vaulttext.split(b\"\\n\", 2)",
            "    b_salt = _unhexlify(b_salt)",
            "    b_ciphertext = _unhexlify(b_ciphertext)",
            "",
            "    return b_ciphertext, b_salt, b_crypted_hmac",
            "",
            "",
            "def parse_vaulttext(b_vaulttext):",
            "    \"\"\"Parse the vaulttext",
            "",
            "    :arg b_vaulttext: byte str containing the vaulttext (ciphertext, salt, crypted_hmac)",
            "    :returns: A tuple of byte str of the ciphertext suitable for passing to a",
            "        Cipher class's decrypt() function, a byte str of the salt,",
            "        and a byte str of the crypted_hmac",
            "    :raises: AnsibleVaultFormatError: if the vaulttext format is invalid",
            "    \"\"\"",
            "    # SPLIT SALT, DIGEST, AND DATA",
            "    try:",
            "        return _parse_vaulttext(b_vaulttext)",
            "    except AnsibleVaultFormatError:",
            "        raise",
            "    except Exception as exc:",
            "        msg = \"Vault vaulttext format error: %s\" % exc",
            "        raise AnsibleVaultFormatError(msg)",
            "",
            "",
            "def verify_secret_is_not_empty(secret, msg=None):",
            "    '''Check the secret against minimal requirements.",
            "",
            "    Raises: AnsibleVaultPasswordError if the password does not meet requirements.",
            "",
            "    Currently, only requirement is that the password is not None or an empty string.",
            "    '''",
            "    msg = msg or 'Invalid vault password was provided'",
            "    if not secret:",
            "        raise AnsibleVaultPasswordError(msg)",
            "",
            "",
            "class VaultSecret:",
            "    '''Opaque/abstract objects for a single vault secret. ie, a password or a key.'''",
            "",
            "    def __init__(self, _bytes=None):",
            "        # FIXME: ? that seems wrong... Unset etc?",
            "        self._bytes = _bytes",
            "",
            "    @property",
            "    def bytes(self):",
            "        '''The secret as a bytestring.",
            "",
            "        Sub classes that store text types will need to override to encode the text to bytes.",
            "        '''",
            "        return self._bytes",
            "",
            "    def load(self):",
            "        return self._bytes",
            "",
            "",
            "class PromptVaultSecret(VaultSecret):",
            "    default_prompt_formats = [\"Vault password (%s): \"]",
            "",
            "    def __init__(self, _bytes=None, vault_id=None, prompt_formats=None):",
            "        super(PromptVaultSecret, self).__init__(_bytes=_bytes)",
            "        self.vault_id = vault_id",
            "",
            "        if prompt_formats is None:",
            "            self.prompt_formats = self.default_prompt_formats",
            "        else:",
            "            self.prompt_formats = prompt_formats",
            "",
            "    @property",
            "    def bytes(self):",
            "        return self._bytes",
            "",
            "    def load(self):",
            "        self._bytes = self.ask_vault_passwords()",
            "",
            "    def ask_vault_passwords(self):",
            "        b_vault_passwords = []",
            "",
            "        for prompt_format in self.prompt_formats:",
            "            prompt = prompt_format % {'vault_id': self.vault_id}",
            "            try:",
            "                vault_pass = display.prompt(prompt, private=True)",
            "            except EOFError:",
            "                raise AnsibleVaultError('EOFError (ctrl-d) on prompt for (%s)' % self.vault_id)",
            "",
            "            verify_secret_is_not_empty(vault_pass)",
            "",
            "            b_vault_pass = to_bytes(vault_pass, errors='strict', nonstring='simplerepr').strip()",
            "            b_vault_passwords.append(b_vault_pass)",
            "",
            "        # Make sure the passwords match by comparing them all to the first password",
            "        for b_vault_password in b_vault_passwords:",
            "            self.confirm(b_vault_passwords[0], b_vault_password)",
            "",
            "        if b_vault_passwords:",
            "            return b_vault_passwords[0]",
            "",
            "        return None",
            "",
            "    def confirm(self, b_vault_pass_1, b_vault_pass_2):",
            "        # enforce no newline chars at the end of passwords",
            "",
            "        if b_vault_pass_1 != b_vault_pass_2:",
            "            # FIXME: more specific exception",
            "            raise AnsibleError(\"Passwords do not match\")",
            "",
            "",
            "def script_is_client(filename):",
            "    '''Determine if a vault secret script is a client script that can be given --vault-id args'''",
            "",
            "    # if password script is 'something-client' or 'something-client.[sh|py|rb|etc]'",
            "    # script_name can still have '.' or could be entire filename if there is no ext",
            "    script_name, dummy = os.path.splitext(filename)",
            "",
            "    # TODO: for now, this is entirely based on filename",
            "    if script_name.endswith('-client'):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def get_file_vault_secret(filename=None, vault_id=None, encoding=None, loader=None):",
            "    this_path = os.path.realpath(os.path.expanduser(filename))",
            "",
            "    if not os.path.exists(this_path):",
            "        raise AnsibleError(\"The vault password file %s was not found\" % this_path)",
            "",
            "    if loader.is_executable(this_path):",
            "        if script_is_client(filename):",
            "            display.vvvv(u'The vault password file %s is a client script.' % to_text(filename))",
            "            # TODO: pass vault_id_name to script via cli",
            "            return ClientScriptVaultSecret(filename=this_path, vault_id=vault_id,",
            "                                           encoding=encoding, loader=loader)",
            "        # just a plain vault password script. No args, returns a byte array",
            "        return ScriptVaultSecret(filename=this_path, encoding=encoding, loader=loader)",
            "",
            "    return FileVaultSecret(filename=this_path, encoding=encoding, loader=loader)",
            "",
            "",
            "# TODO: mv these classes to a separate file so we don't pollute vault with 'subprocess' etc",
            "class FileVaultSecret(VaultSecret):",
            "    def __init__(self, filename=None, encoding=None, loader=None):",
            "        super(FileVaultSecret, self).__init__()",
            "        self.filename = filename",
            "        self.loader = loader",
            "",
            "        self.encoding = encoding or 'utf8'",
            "",
            "        # We could load from file here, but that is eventually a pain to test",
            "        self._bytes = None",
            "        self._text = None",
            "",
            "    @property",
            "    def bytes(self):",
            "        if self._bytes:",
            "            return self._bytes",
            "        if self._text:",
            "            return self._text.encode(self.encoding)",
            "        return None",
            "",
            "    def load(self):",
            "        self._bytes = self._read_file(self.filename)",
            "",
            "    def _read_file(self, filename):",
            "        \"\"\"",
            "        Read a vault password from a file or if executable, execute the script and",
            "        retrieve password from STDOUT",
            "        \"\"\"",
            "",
            "        # TODO: replace with use of self.loader",
            "        try:",
            "            f = open(filename, \"rb\")",
            "            vault_pass = f.read().strip()",
            "            f.close()",
            "        except (OSError, IOError) as e:",
            "            raise AnsibleError(\"Could not read vault password file %s: %s\" % (filename, e))",
            "",
            "        b_vault_data, dummy = self.loader._decrypt_if_vault_data(vault_pass, filename)",
            "",
            "        vault_pass = b_vault_data.strip(b'\\r\\n')",
            "",
            "        verify_secret_is_not_empty(vault_pass,",
            "                                   msg='Invalid vault password was provided from file (%s)' % filename)",
            "",
            "        return vault_pass",
            "",
            "    def __repr__(self):",
            "        if self.filename:",
            "            return \"%s(filename='%s')\" % (self.__class__.__name__, self.filename)",
            "        return \"%s()\" % (self.__class__.__name__)",
            "",
            "",
            "class ScriptVaultSecret(FileVaultSecret):",
            "    def _read_file(self, filename):",
            "        if not self.loader.is_executable(filename):",
            "            raise AnsibleVaultError(\"The vault password script %s was not executable\" % filename)",
            "",
            "        command = self._build_command()",
            "",
            "        stdout, stderr, p = self._run(command)",
            "",
            "        self._check_results(stdout, stderr, p)",
            "",
            "        vault_pass = stdout.strip(b'\\r\\n')",
            "",
            "        empty_password_msg = 'Invalid vault password was provided from script (%s)' % filename",
            "        verify_secret_is_not_empty(vault_pass,",
            "                                   msg=empty_password_msg)",
            "",
            "        return vault_pass",
            "",
            "    def _run(self, command):",
            "        try:",
            "            # STDERR not captured to make it easier for users to prompt for input in their scripts",
            "            p = subprocess.Popen(command, stdout=subprocess.PIPE)",
            "        except OSError as e:",
            "            msg_format = \"Problem running vault password script %s (%s).\" \\",
            "                \" If this is not a script, remove the executable bit from the file.\"",
            "            msg = msg_format % (self.filename, e)",
            "",
            "            raise AnsibleError(msg)",
            "",
            "        stdout, stderr = p.communicate()",
            "        return stdout, stderr, p",
            "",
            "    def _check_results(self, stdout, stderr, popen):",
            "        if popen.returncode != 0:",
            "            raise AnsibleError(\"Vault password script %s returned non-zero (%s): %s\" %",
            "                               (self.filename, popen.returncode, stderr))",
            "",
            "    def _build_command(self):",
            "        return [self.filename]",
            "",
            "",
            "class ClientScriptVaultSecret(ScriptVaultSecret):",
            "    VAULT_ID_UNKNOWN_RC = 2",
            "",
            "    def __init__(self, filename=None, encoding=None, loader=None, vault_id=None):",
            "        super(ClientScriptVaultSecret, self).__init__(filename=filename,",
            "                                                      encoding=encoding,",
            "                                                      loader=loader)",
            "        self._vault_id = vault_id",
            "        display.vvvv(u'Executing vault password client script: %s --vault-id %s' % (to_text(filename), to_text(vault_id)))",
            "",
            "    def _run(self, command):",
            "        try:",
            "            p = subprocess.Popen(command,",
            "                                 stdout=subprocess.PIPE,",
            "                                 stderr=subprocess.PIPE)",
            "        except OSError as e:",
            "            msg_format = \"Problem running vault password client script %s (%s).\" \\",
            "                \" If this is not a script, remove the executable bit from the file.\"",
            "            msg = msg_format % (self.filename, e)",
            "",
            "            raise AnsibleError(msg)",
            "",
            "        stdout, stderr = p.communicate()",
            "        return stdout, stderr, p",
            "",
            "    def _check_results(self, stdout, stderr, popen):",
            "        if popen.returncode == self.VAULT_ID_UNKNOWN_RC:",
            "            raise AnsibleError('Vault password client script %s did not find a secret for vault-id=%s: %s' %",
            "                               (self.filename, self._vault_id, stderr))",
            "",
            "        if popen.returncode != 0:",
            "            raise AnsibleError(\"Vault password client script %s returned non-zero (%s) when getting secret for vault-id=%s: %s\" %",
            "                               (self.filename, popen.returncode, self._vault_id, stderr))",
            "",
            "    def _build_command(self):",
            "        command = [self.filename]",
            "        if self._vault_id:",
            "            command.extend(['--vault-id', self._vault_id])",
            "",
            "        return command",
            "",
            "    def __repr__(self):",
            "        if self.filename:",
            "            return \"%s(filename='%s', vault_id='%s')\" % \\",
            "                (self.__class__.__name__, self.filename, self._vault_id)",
            "        return \"%s()\" % (self.__class__.__name__)",
            "",
            "",
            "def match_secrets(secrets, target_vault_ids):",
            "    '''Find all VaultSecret objects that are mapped to any of the target_vault_ids in secrets'''",
            "    if not secrets:",
            "        return []",
            "",
            "    matches = [(vault_id, secret) for vault_id, secret in secrets if vault_id in target_vault_ids]",
            "    return matches",
            "",
            "",
            "def match_best_secret(secrets, target_vault_ids):",
            "    '''Find the best secret from secrets that matches target_vault_ids",
            "",
            "    Since secrets should be ordered so the early secrets are 'better' than later ones, this",
            "    just finds all the matches, then returns the first secret'''",
            "    matches = match_secrets(secrets, target_vault_ids)",
            "    if matches:",
            "        return matches[0]",
            "    # raise exception?",
            "    return None",
            "",
            "",
            "def match_encrypt_vault_id_secret(secrets, encrypt_vault_id=None):",
            "    # See if the --encrypt-vault-id matches a vault-id",
            "    display.vvvv(u'encrypt_vault_id=%s' % to_text(encrypt_vault_id))",
            "",
            "    if encrypt_vault_id is None:",
            "        raise AnsibleError('match_encrypt_vault_id_secret requires a non None encrypt_vault_id')",
            "",
            "    encrypt_vault_id_matchers = [encrypt_vault_id]",
            "    encrypt_secret = match_best_secret(secrets, encrypt_vault_id_matchers)",
            "",
            "    # return the best match for --encrypt-vault-id",
            "    if encrypt_secret:",
            "        return encrypt_secret",
            "",
            "    # If we specified a encrypt_vault_id and we couldn't find it, dont",
            "    # fallback to using the first/best secret",
            "    raise AnsibleVaultError('Did not find a match for --encrypt-vault-id=%s in the known vault-ids %s' % (encrypt_vault_id,",
            "                                                                                                          [_v for _v, _vs in secrets]))",
            "",
            "",
            "def match_encrypt_secret(secrets, encrypt_vault_id=None):",
            "    '''Find the best/first/only secret in secrets to use for encrypting'''",
            "",
            "    display.vvvv(u'encrypt_vault_id=%s' % to_text(encrypt_vault_id))",
            "    # See if the --encrypt-vault-id matches a vault-id",
            "    if encrypt_vault_id:",
            "        return match_encrypt_vault_id_secret(secrets,",
            "                                             encrypt_vault_id=encrypt_vault_id)",
            "",
            "    # Find the best/first secret from secrets since we didnt specify otherwise",
            "    # ie, consider all of the available secrets as matches",
            "    _vault_id_matchers = [_vault_id for _vault_id, dummy in secrets]",
            "    best_secret = match_best_secret(secrets, _vault_id_matchers)",
            "",
            "    # can be empty list sans any tuple",
            "    return best_secret",
            "",
            "",
            "class VaultLib:",
            "    def __init__(self, secrets=None):",
            "        self.secrets = secrets or []",
            "        self.cipher_name = None",
            "        self.b_version = b'1.2'",
            "",
            "    def encrypt(self, plaintext, secret=None, vault_id=None):",
            "        \"\"\"Vault encrypt a piece of data.",
            "",
            "        :arg plaintext: a text or byte string to encrypt.",
            "        :returns: a utf-8 encoded byte str of encrypted data.  The string",
            "            contains a header identifying this as vault encrypted data and",
            "            formatted to newline terminated lines of 80 characters.  This is",
            "            suitable for dumping as is to a vault file.",
            "",
            "        If the string passed in is a text string, it will be encoded to UTF-8",
            "        before encryption.",
            "        \"\"\"",
            "",
            "        if secret is None:",
            "            if self.secrets:",
            "                dummy, secret = match_encrypt_secret(self.secrets)",
            "            else:",
            "                raise AnsibleVaultError(\"A vault password must be specified to encrypt data\")",
            "",
            "        b_plaintext = to_bytes(plaintext, errors='surrogate_or_strict')",
            "",
            "        if is_encrypted(b_plaintext):",
            "            raise AnsibleError(\"input is already encrypted\")",
            "",
            "        if not self.cipher_name or self.cipher_name not in CIPHER_WRITE_WHITELIST:",
            "            self.cipher_name = u\"AES256\"",
            "",
            "        try:",
            "            this_cipher = CIPHER_MAPPING[self.cipher_name]()",
            "        except KeyError:",
            "            raise AnsibleError(u\"{0} cipher could not be found\".format(self.cipher_name))",
            "",
            "        # encrypt data",
            "        if vault_id:",
            "            display.vvvvv(u'Encrypting with vault_id \"%s\" and vault secret %s' % (to_text(vault_id), to_text(secret)))",
            "        else:",
            "            display.vvvvv(u'Encrypting without a vault_id using vault secret %s' % to_text(secret))",
            "",
            "        b_ciphertext = this_cipher.encrypt(b_plaintext, secret)",
            "",
            "        # format the data for output to the file",
            "        b_vaulttext = format_vaulttext_envelope(b_ciphertext,",
            "                                                self.cipher_name,",
            "                                                vault_id=vault_id)",
            "        return b_vaulttext",
            "",
            "    def decrypt(self, vaulttext, filename=None):",
            "        '''Decrypt a piece of vault encrypted data.",
            "",
            "        :arg vaulttext: a string to decrypt.  Since vault encrypted data is an",
            "            ascii text format this can be either a byte str or unicode string.",
            "        :kwarg filename: a filename that the data came from.  This is only",
            "            used to make better error messages in case the data cannot be",
            "            decrypted.",
            "        :returns: a byte string containing the decrypted data and the vault-id that was used",
            "",
            "        '''",
            "        plaintext, vault_id, vault_secret = self.decrypt_and_get_vault_id(vaulttext, filename=filename)",
            "        return plaintext",
            "",
            "    def decrypt_and_get_vault_id(self, vaulttext, filename=None):",
            "        \"\"\"Decrypt a piece of vault encrypted data.",
            "",
            "        :arg vaulttext: a string to decrypt.  Since vault encrypted data is an",
            "            ascii text format this can be either a byte str or unicode string.",
            "        :kwarg filename: a filename that the data came from.  This is only",
            "            used to make better error messages in case the data cannot be",
            "            decrypted.",
            "        :returns: a byte string containing the decrypted data and the vault-id vault-secret that was used",
            "",
            "        \"\"\"",
            "        b_vaulttext = to_bytes(vaulttext, errors='strict', encoding='utf-8')",
            "",
            "        if self.secrets is None:",
            "            raise AnsibleVaultError(\"A vault password must be specified to decrypt data\")",
            "",
            "        if not is_encrypted(b_vaulttext):",
            "            msg = \"input is not vault encrypted data\"",
            "            if filename:",
            "                msg += \"%s is not a vault encrypted file\" % to_native(filename)",
            "            raise AnsibleError(msg)",
            "",
            "        b_vaulttext, dummy, cipher_name, vault_id = parse_vaulttext_envelope(b_vaulttext,",
            "                                                                             filename=filename)",
            "",
            "        # create the cipher object, note that the cipher used for decrypt can",
            "        # be different than the cipher used for encrypt",
            "        if cipher_name in CIPHER_WHITELIST:",
            "            this_cipher = CIPHER_MAPPING[cipher_name]()",
            "        else:",
            "            raise AnsibleError(\"{0} cipher could not be found\".format(cipher_name))",
            "",
            "        b_plaintext = None",
            "",
            "        if not self.secrets:",
            "            raise AnsibleVaultError('Attempting to decrypt but no vault secrets found')",
            "",
            "        # WARNING: Currently, the vault id is not required to match the vault id in the vault blob to",
            "        #          decrypt a vault properly. The vault id in the vault blob is not part of the encrypted",
            "        #          or signed vault payload. There is no cryptographic checking/verification/validation of the",
            "        #          vault blobs vault id. It can be tampered with and changed. The vault id is just a nick",
            "        #          name to use to pick the best secret and provide some ux/ui info.",
            "",
            "        # iterate over all the applicable secrets (all of them by default) until one works...",
            "        # if we specify a vault_id, only the corresponding vault secret is checked and",
            "        # we check it first.",
            "",
            "        vault_id_matchers = []",
            "        vault_id_used = None",
            "        vault_secret_used = None",
            "",
            "        if vault_id:",
            "            display.vvvvv(u'Found a vault_id (%s) in the vaulttext' % to_text(vault_id))",
            "            vault_id_matchers.append(vault_id)",
            "            _matches = match_secrets(self.secrets, vault_id_matchers)",
            "            if _matches:",
            "                display.vvvvv(u'We have a secret associated with vault id (%s), will try to use to decrypt %s' % (to_text(vault_id), to_text(filename)))",
            "            else:",
            "                display.vvvvv(u'Found a vault_id (%s) in the vault text, but we do not have a associated secret (--vault-id)' % to_text(vault_id))",
            "",
            "        # Not adding the other secrets to vault_secret_ids enforces a match between the vault_id from the vault_text and",
            "        # the known vault secrets.",
            "        if not C.DEFAULT_VAULT_ID_MATCH:",
            "            # Add all of the known vault_ids as candidates for decrypting a vault.",
            "            vault_id_matchers.extend([_vault_id for _vault_id, _dummy in self.secrets if _vault_id != vault_id])",
            "",
            "        matched_secrets = match_secrets(self.secrets, vault_id_matchers)",
            "",
            "        # for vault_secret_id in vault_secret_ids:",
            "        for vault_secret_id, vault_secret in matched_secrets:",
            "            display.vvvvv(u'Trying to use vault secret=(%s) id=%s to decrypt %s' % (to_text(vault_secret), to_text(vault_secret_id), to_text(filename)))",
            "",
            "            try:",
            "                # secret = self.secrets[vault_secret_id]",
            "                display.vvvv(u'Trying secret %s for vault_id=%s' % (to_text(vault_secret), to_text(vault_secret_id)))",
            "                b_plaintext = this_cipher.decrypt(b_vaulttext, vault_secret)",
            "                if b_plaintext is not None:",
            "                    vault_id_used = vault_secret_id",
            "                    vault_secret_used = vault_secret",
            "                    file_slug = ''",
            "                    if filename:",
            "                        file_slug = ' of \"%s\"' % filename",
            "                    display.vvvvv(",
            "                        u'Decrypt%s successful with secret=%s and vault_id=%s' % (to_text(file_slug), to_text(vault_secret), to_text(vault_secret_id))",
            "                    )",
            "                    break",
            "            except AnsibleVaultFormatError as exc:",
            "                msg = u\"There was a vault format error\"",
            "                if filename:",
            "                    msg += u' in %s' % (to_text(filename))",
            "                msg += u': %s' % exc",
            "                display.warning(msg)",
            "                raise",
            "            except AnsibleError as e:",
            "                display.vvvv(u'Tried to use the vault secret (%s) to decrypt (%s) but it failed. Error: %s' %",
            "                             (to_text(vault_secret_id), to_text(filename), e))",
            "                continue",
            "        else:",
            "            msg = \"Decryption failed (no vault secrets were found that could decrypt)\"",
            "            if filename:",
            "                msg += \" on %s\" % to_native(filename)",
            "            raise AnsibleVaultError(msg)",
            "",
            "        if b_plaintext is None:",
            "            msg = \"Decryption failed\"",
            "            if filename:",
            "                msg += \" on %s\" % to_native(filename)",
            "            raise AnsibleError(msg)",
            "",
            "        return b_plaintext, vault_id_used, vault_secret_used",
            "",
            "",
            "class VaultEditor:",
            "",
            "    def __init__(self, vault=None):",
            "        # TODO: it may be more useful to just make VaultSecrets and index of VaultLib objects...",
            "        self.vault = vault or VaultLib()",
            "",
            "    # TODO: mv shred file stuff to it's own class",
            "    def _shred_file_custom(self, tmp_path):",
            "        \"\"\"\"Destroy a file, when shred (core-utils) is not available",
            "",
            "        Unix `shred' destroys files \"so that they can be recovered only with great difficulty with",
            "        specialised hardware, if at all\". It is based on the method from the paper",
            "        \"Secure Deletion of Data from Magnetic and Solid-State Memory\",",
            "        Proceedings of the Sixth USENIX Security Symposium (San Jose, California, July 22-25, 1996).",
            "",
            "        We do not go to that length to re-implement shred in Python; instead, overwriting with a block",
            "        of random data should suffice.",
            "",
            "        See https://github.com/ansible/ansible/pull/13700 .",
            "        \"\"\"",
            "",
            "        file_len = os.path.getsize(tmp_path)",
            "",
            "        if file_len > 0:  # avoid work when file was empty",
            "            max_chunk_len = min(1024 * 1024 * 2, file_len)",
            "",
            "            passes = 3",
            "            with open(tmp_path, \"wb\") as fh:",
            "                for _ in range(passes):",
            "                    fh.seek(0, 0)",
            "                    # get a random chunk of data, each pass with other length",
            "                    chunk_len = random.randint(max_chunk_len // 2, max_chunk_len)",
            "                    data = os.urandom(chunk_len)",
            "",
            "                    for _ in range(0, file_len // chunk_len):",
            "                        fh.write(data)",
            "                    fh.write(data[:file_len % chunk_len])",
            "",
            "                    # FIXME remove this assert once we have unittests to check its accuracy",
            "                    if fh.tell() != file_len:",
            "                        raise AnsibleAssertionError()",
            "",
            "                    os.fsync(fh)",
            "",
            "    def _shred_file(self, tmp_path):",
            "        \"\"\"Securely destroy a decrypted file",
            "",
            "        Note standard limitations of GNU shred apply (For flash, overwriting would have no effect",
            "        due to wear leveling; for other storage systems, the async kernel->filesystem->disk calls never",
            "        guarantee data hits the disk; etc). Furthermore, if your tmp dirs is on tmpfs (ramdisks),",
            "        it is a non-issue.",
            "",
            "        Nevertheless, some form of overwriting the data (instead of just removing the fs index entry) is",
            "        a good idea. If shred is not available (e.g. on windows, or no core-utils installed), fall back on",
            "        a custom shredding method.",
            "        \"\"\"",
            "",
            "        if not os.path.isfile(tmp_path):",
            "            # file is already gone",
            "            return",
            "",
            "        try:",
            "            r = subprocess.call(['shred', tmp_path])",
            "        except (OSError, ValueError):",
            "            # shred is not available on this system, or some other error occurred.",
            "            # ValueError caught because macOS El Capitan is raising an",
            "            # exception big enough to hit a limit in python2-2.7.11 and below.",
            "            # Symptom is ValueError: insecure pickle when shred is not",
            "            # installed there.",
            "            r = 1",
            "",
            "        if r != 0:",
            "            # we could not successfully execute unix shred; therefore, do custom shred.",
            "            self._shred_file_custom(tmp_path)",
            "",
            "        os.remove(tmp_path)",
            "",
            "    def _edit_file_helper(self, filename, secret,",
            "                          existing_data=None, force_save=False, vault_id=None):",
            "",
            "        # Create a tempfile",
            "        root, ext = os.path.splitext(os.path.realpath(filename))",
            "        fd, tmp_path = tempfile.mkstemp(suffix=ext)",
            "        os.close(fd)",
            "",
            "        cmd = self._editor_shell_command(tmp_path)",
            "        try:",
            "            if existing_data:",
            "                self.write_data(existing_data, tmp_path, shred=False)",
            "",
            "            # drop the user into an editor on the tmp file",
            "            subprocess.call(cmd)",
            "        except Exception as e:",
            "            # whatever happens, destroy the decrypted file",
            "            self._shred_file(tmp_path)",
            "            raise AnsibleError('Unable to execute the command \"%s\": %s' % (' '.join(cmd), to_native(e)))",
            "",
            "        b_tmpdata = self.read_data(tmp_path)",
            "",
            "        # Do nothing if the content has not changed",
            "        if existing_data == b_tmpdata and not force_save:",
            "            self._shred_file(tmp_path)",
            "            return",
            "",
            "        # encrypt new data and write out to tmp",
            "        # An existing vaultfile will always be UTF-8,",
            "        # so decode to unicode here",
            "        b_ciphertext = self.vault.encrypt(b_tmpdata, secret, vault_id=vault_id)",
            "        self.write_data(b_ciphertext, tmp_path)",
            "",
            "        # shuffle tmp file into place",
            "        self.shuffle_files(tmp_path, filename)",
            "        display.vvvvv(u'Saved edited file \"%s\" encrypted using %s and  vault id \"%s\"' % (to_text(filename), to_text(secret), to_text(vault_id)))",
            "",
            "    def _real_path(self, filename):",
            "        # '-' is special to VaultEditor, dont expand it.",
            "        if filename == '-':",
            "            return filename",
            "",
            "        real_path = os.path.realpath(filename)",
            "        return real_path",
            "",
            "    def encrypt_bytes(self, b_plaintext, secret, vault_id=None):",
            "",
            "        b_ciphertext = self.vault.encrypt(b_plaintext, secret, vault_id=vault_id)",
            "",
            "        return b_ciphertext",
            "",
            "    def encrypt_file(self, filename, secret, vault_id=None, output_file=None):",
            "",
            "        # A file to be encrypted into a vaultfile could be any encoding",
            "        # so treat the contents as a byte string.",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        b_plaintext = self.read_data(filename)",
            "        b_ciphertext = self.vault.encrypt(b_plaintext, secret, vault_id=vault_id)",
            "        self.write_data(b_ciphertext, output_file or filename)",
            "",
            "    def decrypt_file(self, filename, output_file=None):",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        ciphertext = self.read_data(filename)",
            "",
            "        try:",
            "            plaintext = self.vault.decrypt(ciphertext, filename=filename)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "        self.write_data(plaintext, output_file or filename, shred=False)",
            "",
            "    def create_file(self, filename, secret, vault_id=None):",
            "        \"\"\" create a new encrypted file \"\"\"",
            "",
            "        dirname = os.path.dirname(filename)",
            "        if dirname and not os.path.exists(dirname):",
            "            display.warning(u\"%s does not exist, creating...\" % to_text(dirname))",
            "            makedirs_safe(dirname)",
            "",
            "        # FIXME: If we can raise an error here, we can probably just make it",
            "        # behave like edit instead.",
            "        if os.path.isfile(filename):",
            "            raise AnsibleError(\"%s exists, please use 'edit' instead\" % filename)",
            "",
            "        self._edit_file_helper(filename, secret, vault_id=vault_id)",
            "",
            "    def edit_file(self, filename):",
            "        vault_id_used = None",
            "        vault_secret_used = None",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        b_vaulttext = self.read_data(filename)",
            "",
            "        # vault or yaml files are always utf8",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        try:",
            "            # vaulttext gets converted back to bytes, but alas",
            "            # TODO: return the vault_id that worked?",
            "            plaintext, vault_id_used, vault_secret_used = self.vault.decrypt_and_get_vault_id(vaulttext)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "        # Figure out the vault id from the file, to select the right secret to re-encrypt it",
            "        # (duplicates parts of decrypt, but alas...)",
            "        dummy, dummy, cipher_name, vault_id = parse_vaulttext_envelope(b_vaulttext,",
            "                                                                       filename=filename)",
            "",
            "        # vault id here may not be the vault id actually used for decrypting",
            "        # as when the edited file has no vault-id but is decrypted by non-default id in secrets",
            "        # (vault_id=default, while a different vault-id decrypted)",
            "",
            "        # Keep the same vault-id (and version) as in the header",
            "        if cipher_name not in CIPHER_WRITE_WHITELIST:",
            "            # we want to get rid of files encrypted with the AES cipher",
            "            self._edit_file_helper(filename, vault_secret_used, existing_data=plaintext,",
            "                                   force_save=True, vault_id=vault_id)",
            "        else:",
            "            self._edit_file_helper(filename, vault_secret_used, existing_data=plaintext,",
            "                                   force_save=False, vault_id=vault_id)",
            "",
            "    def plaintext(self, filename):",
            "",
            "        b_vaulttext = self.read_data(filename)",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        try:",
            "            plaintext = self.vault.decrypt(vaulttext, filename=filename)",
            "            return plaintext",
            "        except AnsibleError as e:",
            "            raise AnsibleVaultError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "    # FIXME/TODO: make this use VaultSecret",
            "    def rekey_file(self, filename, new_vault_secret, new_vault_id=None):",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        prev = os.stat(filename)",
            "        b_vaulttext = self.read_data(filename)",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        display.vvvvv(u'Rekeying file \"%s\" to with new vault-id \"%s\" and vault secret %s' %",
            "                      (to_text(filename), to_text(new_vault_id), to_text(new_vault_secret)))",
            "        try:",
            "            plaintext, vault_id_used, _dummy = self.vault.decrypt_and_get_vault_id(vaulttext)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "        # This is more or less an assert, see #18247",
            "        if new_vault_secret is None:",
            "            raise AnsibleError('The value for the new_password to rekey %s with is not valid' % filename)",
            "",
            "        # FIXME: VaultContext...?  could rekey to a different vault_id in the same VaultSecrets",
            "",
            "        # Need a new VaultLib because the new vault data can be a different",
            "        # vault lib format or cipher (for ex, when we migrate 1.0 style vault data to",
            "        # 1.1 style data we change the version and the cipher). This is where a VaultContext might help",
            "",
            "        # the new vault will only be used for encrypting, so it doesn't need the vault secrets",
            "        # (we will pass one in directly to encrypt)",
            "        new_vault = VaultLib(secrets={})",
            "        b_new_vaulttext = new_vault.encrypt(plaintext, new_vault_secret, vault_id=new_vault_id)",
            "",
            "        self.write_data(b_new_vaulttext, filename)",
            "",
            "        # preserve permissions",
            "        os.chmod(filename, prev.st_mode)",
            "        os.chown(filename, prev.st_uid, prev.st_gid)",
            "",
            "        display.vvvvv(u'Rekeyed file \"%s\" (decrypted with vault id \"%s\") was encrypted with new vault-id \"%s\" and vault secret %s' %",
            "                      (to_text(filename), to_text(vault_id_used), to_text(new_vault_id), to_text(new_vault_secret)))",
            "",
            "    def read_data(self, filename):",
            "",
            "        try:",
            "            if filename == '-':",
            "                data = sys.stdin.read()",
            "            else:",
            "                with open(filename, \"rb\") as fh:",
            "                    data = fh.read()",
            "        except Exception as e:",
            "            msg = to_native(e)",
            "            if not msg:",
            "                msg = repr(e)",
            "            raise AnsibleError('Unable to read source file (%s): %s' % (to_native(filename), msg))",
            "",
            "        return data",
            "",
            "    # TODO: add docstrings for arg types since this code is picky about that",
            "    def write_data(self, data, filename, shred=True):",
            "        \"\"\"Write the data bytes to given path",
            "",
            "        This is used to write a byte string to a file or stdout. It is used for",
            "        writing the results of vault encryption or decryption. It is used for",
            "        saving the ciphertext after encryption and it is also used for saving the",
            "        plaintext after decrypting a vault. The type of the 'data' arg should be bytes,",
            "        since in the plaintext case, the original contents can be of any text encoding",
            "        or arbitrary binary data.",
            "",
            "        When used to write the result of vault encryption, the val of the 'data' arg",
            "        should be a utf-8 encoded byte string and not a text typ and not a text type..",
            "",
            "        When used to write the result of vault decryption, the val of the 'data' arg",
            "        should be a byte string and not a text type.",
            "",
            "        :arg data: the byte string (bytes) data",
            "        :arg filename: filename to save 'data' to.",
            "        :arg shred: if shred==True, make sure that the original data is first shredded so that is cannot be recovered.",
            "        :returns: None",
            "        \"\"\"",
            "        # FIXME: do we need this now? data_bytes should always be a utf-8 byte string",
            "        b_file_data = to_bytes(data, errors='strict')",
            "",
            "        # get a ref to either sys.stdout.buffer for py3 or plain old sys.stdout for py2",
            "        # We need sys.stdout.buffer on py3 so we can write bytes to it since the plaintext",
            "        # of the vaulted object could be anything/binary/etc",
            "        output = getattr(sys.stdout, 'buffer', sys.stdout)",
            "",
            "        if filename == '-':",
            "            output.write(b_file_data)",
            "        else:",
            "            if os.path.isfile(filename):",
            "                if shred:",
            "                    self._shred_file(filename)",
            "                else:",
            "                    os.remove(filename)",
            "            with open(filename, \"wb\") as fh:",
            "                fh.write(b_file_data)",
            "",
            "    def shuffle_files(self, src, dest):",
            "        prev = None",
            "        # overwrite dest with src",
            "        if os.path.isfile(dest):",
            "            prev = os.stat(dest)",
            "            # old file 'dest' was encrypted, no need to _shred_file",
            "            os.remove(dest)",
            "        shutil.move(src, dest)",
            "",
            "        # reset permissions if needed",
            "        if prev is not None:",
            "            # TODO: selinux, ACLs, xattr?",
            "            os.chmod(dest, prev.st_mode)",
            "            os.chown(dest, prev.st_uid, prev.st_gid)",
            "",
            "    def _editor_shell_command(self, filename):",
            "        env_editor = os.environ.get('EDITOR', 'vi')",
            "        editor = shlex.split(env_editor)",
            "        editor.append(filename)",
            "",
            "        return editor",
            "",
            "",
            "########################################",
            "#               CIPHERS                #",
            "########################################",
            "",
            "class VaultAES256:",
            "",
            "    \"\"\"",
            "    Vault implementation using AES-CTR with an HMAC-SHA256 authentication code.",
            "    Keys are derived using PBKDF2",
            "    \"\"\"",
            "",
            "    # http://www.daemonology.net/blog/2009-06-11-cryptographic-right-answers.html",
            "",
            "    # Note: strings in this class should be byte strings by default.",
            "",
            "    def __init__(self):",
            "        if not HAS_CRYPTOGRAPHY and not HAS_PYCRYPTO:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY)",
            "",
            "    @staticmethod",
            "    def _create_key_cryptography(b_password, b_salt, key_length, iv_length):",
            "        kdf = PBKDF2HMAC(",
            "            algorithm=hashes.SHA256(),",
            "            length=2 * key_length + iv_length,",
            "            salt=b_salt,",
            "            iterations=10000,",
            "            backend=CRYPTOGRAPHY_BACKEND)",
            "        b_derivedkey = kdf.derive(b_password)",
            "",
            "        return b_derivedkey",
            "",
            "    @staticmethod",
            "    def _pbkdf2_prf(p, s):",
            "        hash_function = SHA256_pycrypto",
            "        return HMAC_pycrypto.new(p, s, hash_function).digest()",
            "",
            "    @classmethod",
            "    def _create_key_pycrypto(cls, b_password, b_salt, key_length, iv_length):",
            "",
            "        # make two keys and one iv",
            "",
            "        b_derivedkey = PBKDF2_pycrypto(b_password, b_salt, dkLen=(2 * key_length) + iv_length,",
            "                                       count=10000, prf=cls._pbkdf2_prf)",
            "        return b_derivedkey",
            "",
            "    @classmethod",
            "    def _gen_key_initctr(cls, b_password, b_salt):",
            "        # 16 for AES 128, 32 for AES256",
            "        key_length = 32",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            # AES is a 128-bit block cipher, so IVs and counter nonces are 16 bytes",
            "            iv_length = algorithms.AES.block_size // 8",
            "",
            "            b_derivedkey = cls._create_key_cryptography(b_password, b_salt, key_length, iv_length)",
            "            b_iv = b_derivedkey[(key_length * 2):(key_length * 2) + iv_length]",
            "        elif HAS_PYCRYPTO:",
            "            # match the size used for counter.new to avoid extra work",
            "            iv_length = 16",
            "",
            "            b_derivedkey = cls._create_key_pycrypto(b_password, b_salt, key_length, iv_length)",
            "            b_iv = hexlify(b_derivedkey[(key_length * 2):(key_length * 2) + iv_length])",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in initctr)')",
            "",
            "        b_key1 = b_derivedkey[:key_length]",
            "        b_key2 = b_derivedkey[key_length:(key_length * 2)]",
            "",
            "        return b_key1, b_key2, b_iv",
            "",
            "    @staticmethod",
            "    def _encrypt_cryptography(b_plaintext, b_key1, b_key2, b_iv):",
            "        cipher = C_Cipher(algorithms.AES(b_key1), modes.CTR(b_iv), CRYPTOGRAPHY_BACKEND)",
            "        encryptor = cipher.encryptor()",
            "        padder = padding.PKCS7(algorithms.AES.block_size).padder()",
            "        b_ciphertext = encryptor.update(padder.update(b_plaintext) + padder.finalize())",
            "        b_ciphertext += encryptor.finalize()",
            "",
            "        # COMBINE SALT, DIGEST AND DATA",
            "        hmac = HMAC(b_key2, hashes.SHA256(), CRYPTOGRAPHY_BACKEND)",
            "        hmac.update(b_ciphertext)",
            "        b_hmac = hmac.finalize()",
            "",
            "        return to_bytes(hexlify(b_hmac), errors='surrogate_or_strict'), hexlify(b_ciphertext)",
            "",
            "    @staticmethod",
            "    def _encrypt_pycrypto(b_plaintext, b_key1, b_key2, b_iv):",
            "        # PKCS#7 PAD DATA http://tools.ietf.org/html/rfc5652#section-6.3",
            "        bs = AES_pycrypto.block_size",
            "        padding_length = (bs - len(b_plaintext) % bs) or bs",
            "        b_plaintext += to_bytes(padding_length * chr(padding_length), encoding='ascii', errors='strict')",
            "",
            "        # COUNTER.new PARAMETERS",
            "        # 1) nbits (integer) - Length of the counter, in bits.",
            "        # 2) initial_value (integer) - initial value of the counter. \"iv\" from _gen_key_initctr",
            "",
            "        ctr = Counter_pycrypto.new(128, initial_value=int(b_iv, 16))",
            "",
            "        # AES.new PARAMETERS",
            "        # 1) AES key, must be either 16, 24, or 32 bytes long -- \"key\" from _gen_key_initctr",
            "        # 2) MODE_CTR, is the recommended mode",
            "        # 3) counter=<CounterObject>",
            "",
            "        cipher = AES_pycrypto.new(b_key1, AES_pycrypto.MODE_CTR, counter=ctr)",
            "",
            "        # ENCRYPT PADDED DATA",
            "        b_ciphertext = cipher.encrypt(b_plaintext)",
            "",
            "        # COMBINE SALT, DIGEST AND DATA",
            "        hmac = HMAC_pycrypto.new(b_key2, b_ciphertext, SHA256_pycrypto)",
            "",
            "        return to_bytes(hmac.hexdigest(), errors='surrogate_or_strict'), hexlify(b_ciphertext)",
            "",
            "    @classmethod",
            "    def encrypt(cls, b_plaintext, secret):",
            "        if secret is None:",
            "            raise AnsibleVaultError('The secret passed to encrypt() was None')",
            "        b_salt = os.urandom(32)",
            "        b_password = secret.bytes",
            "        b_key1, b_key2, b_iv = cls._gen_key_initctr(b_password, b_salt)",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            b_hmac, b_ciphertext = cls._encrypt_cryptography(b_plaintext, b_key1, b_key2, b_iv)",
            "        elif HAS_PYCRYPTO:",
            "            b_hmac, b_ciphertext = cls._encrypt_pycrypto(b_plaintext, b_key1, b_key2, b_iv)",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in encrypt)')",
            "",
            "        b_vaulttext = b'\\n'.join([hexlify(b_salt), b_hmac, b_ciphertext])",
            "        # Unnecessary but getting rid of it is a backwards incompatible vault",
            "        # format change",
            "        b_vaulttext = hexlify(b_vaulttext)",
            "        return b_vaulttext",
            "",
            "    @classmethod",
            "    def _decrypt_cryptography(cls, b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv):",
            "        # b_key1, b_key2, b_iv = self._gen_key_initctr(b_password, b_salt)",
            "        # EXIT EARLY IF DIGEST DOESN'T MATCH",
            "        hmac = HMAC(b_key2, hashes.SHA256(), CRYPTOGRAPHY_BACKEND)",
            "        hmac.update(b_ciphertext)",
            "        try:",
            "            hmac.verify(_unhexlify(b_crypted_hmac))",
            "        except InvalidSignature as e:",
            "            raise AnsibleVaultError('HMAC verification failed: %s' % e)",
            "",
            "        cipher = C_Cipher(algorithms.AES(b_key1), modes.CTR(b_iv), CRYPTOGRAPHY_BACKEND)",
            "        decryptor = cipher.decryptor()",
            "        unpadder = padding.PKCS7(128).unpadder()",
            "        b_plaintext = unpadder.update(",
            "            decryptor.update(b_ciphertext) + decryptor.finalize()",
            "        ) + unpadder.finalize()",
            "",
            "        return b_plaintext",
            "",
            "    @staticmethod",
            "    def _is_equal(b_a, b_b):",
            "        \"\"\"",
            "        Comparing 2 byte arrrays in constant time",
            "        to avoid timing attacks.",
            "",
            "        It would be nice if there was a library for this but",
            "        hey.",
            "        \"\"\"",
            "        if not (isinstance(b_a, binary_type) and isinstance(b_b, binary_type)):",
            "            raise TypeError('_is_equal can only be used to compare two byte strings')",
            "",
            "        # http://codahale.com/a-lesson-in-timing-attacks/",
            "        if len(b_a) != len(b_b):",
            "            return False",
            "",
            "        result = 0",
            "        for b_x, b_y in zip(b_a, b_b):",
            "            if PY3:",
            "                result |= b_x ^ b_y",
            "            else:",
            "                result |= ord(b_x) ^ ord(b_y)",
            "        return result == 0",
            "",
            "    @classmethod",
            "    def _decrypt_pycrypto(cls, b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv):",
            "        # EXIT EARLY IF DIGEST DOESN'T MATCH",
            "        hmac_decrypt = HMAC_pycrypto.new(b_key2, b_ciphertext, SHA256_pycrypto)",
            "        if not cls._is_equal(b_crypted_hmac, to_bytes(hmac_decrypt.hexdigest())):",
            "            return None",
            "",
            "        # SET THE COUNTER AND THE CIPHER",
            "        ctr = Counter_pycrypto.new(128, initial_value=int(b_iv, 16))",
            "        cipher = AES_pycrypto.new(b_key1, AES_pycrypto.MODE_CTR, counter=ctr)",
            "",
            "        # DECRYPT PADDED DATA",
            "        b_plaintext = cipher.decrypt(b_ciphertext)",
            "",
            "        # UNPAD DATA",
            "        if PY3:",
            "            padding_length = b_plaintext[-1]",
            "        else:",
            "            padding_length = ord(b_plaintext[-1])",
            "",
            "        b_plaintext = b_plaintext[:-padding_length]",
            "        return b_plaintext",
            "",
            "    @classmethod",
            "    def decrypt(cls, b_vaulttext, secret):",
            "",
            "        b_ciphertext, b_salt, b_crypted_hmac = parse_vaulttext(b_vaulttext)",
            "",
            "        # TODO: would be nice if a VaultSecret could be passed directly to _decrypt_*",
            "        #       (move _gen_key_initctr() to a AES256 VaultSecret or VaultContext impl?)",
            "        # though, likely needs to be python cryptography specific impl that basically",
            "        # creates a Cipher() with b_key1, a Mode.CTR() with b_iv, and a HMAC() with sign key b_key2",
            "        b_password = secret.bytes",
            "",
            "        b_key1, b_key2, b_iv = cls._gen_key_initctr(b_password, b_salt)",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            b_plaintext = cls._decrypt_cryptography(b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv)",
            "        elif HAS_PYCRYPTO:",
            "            b_plaintext = cls._decrypt_pycrypto(b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv)",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in decrypt)')",
            "",
            "        return b_plaintext",
            "",
            "",
            "# Keys could be made bytes later if the code that gets the data is more",
            "# naturally byte-oriented",
            "CIPHER_MAPPING = {",
            "    u'AES256': VaultAES256,",
            "}"
        ],
        "afterPatchFile": [
            "# (c) 2014, James Tanner <tanner.jc@gmail.com>",
            "# (c) 2016, Adrian Likins <alikins@redhat.com>",
            "# (c) 2016 Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import random",
            "import shlex",
            "import shutil",
            "import subprocess",
            "import sys",
            "import tempfile",
            "import warnings",
            "from binascii import hexlify",
            "from binascii import unhexlify",
            "from binascii import Error as BinasciiError",
            "",
            "HAS_CRYPTOGRAPHY = False",
            "HAS_PYCRYPTO = False",
            "HAS_SOME_PYCRYPTO = False",
            "CRYPTOGRAPHY_BACKEND = None",
            "try:",
            "    with warnings.catch_warnings():",
            "        warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "        from cryptography.exceptions import InvalidSignature",
            "    from cryptography.hazmat.backends import default_backend",
            "    from cryptography.hazmat.primitives import hashes, padding",
            "    from cryptography.hazmat.primitives.hmac import HMAC",
            "    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC",
            "    from cryptography.hazmat.primitives.ciphers import (",
            "        Cipher as C_Cipher, algorithms, modes",
            "    )",
            "    CRYPTOGRAPHY_BACKEND = default_backend()",
            "    HAS_CRYPTOGRAPHY = True",
            "except ImportError:",
            "    pass",
            "",
            "try:",
            "    from Crypto.Cipher import AES as AES_pycrypto",
            "    HAS_SOME_PYCRYPTO = True",
            "",
            "    # Note: Only used for loading obsolete VaultAES files.  All files are written",
            "    # using the newer VaultAES256 which does not require md5",
            "    from Crypto.Hash import SHA256 as SHA256_pycrypto",
            "    from Crypto.Hash import HMAC as HMAC_pycrypto",
            "",
            "    # Counter import fails for 2.0.1, requires >= 2.6.1 from pip",
            "    from Crypto.Util import Counter as Counter_pycrypto",
            "",
            "    # KDF import fails for 2.0.1, requires >= 2.6.1 from pip",
            "    from Crypto.Protocol.KDF import PBKDF2 as PBKDF2_pycrypto",
            "    HAS_PYCRYPTO = True",
            "except ImportError:",
            "    pass",
            "",
            "from ansible.errors import AnsibleError, AnsibleAssertionError",
            "from ansible import constants as C",
            "from ansible.module_utils.six import PY3, binary_type",
            "# Note: on py2, this zip is izip not the list based zip() builtin",
            "from ansible.module_utils.six.moves import zip",
            "from ansible.module_utils._text import to_bytes, to_text, to_native",
            "from ansible.utils.display import Display",
            "from ansible.utils.path import makedirs_safe",
            "",
            "display = Display()",
            "",
            "",
            "b_HEADER = b'$ANSIBLE_VAULT'",
            "CIPHER_WHITELIST = frozenset((u'AES256',))",
            "CIPHER_WRITE_WHITELIST = frozenset((u'AES256',))",
            "# See also CIPHER_MAPPING at the bottom of the file which maps cipher strings",
            "# (used in VaultFile header) to a cipher class",
            "",
            "NEED_CRYPTO_LIBRARY = \"ansible-vault requires either the cryptography library (preferred) or\"",
            "if HAS_SOME_PYCRYPTO:",
            "    NEED_CRYPTO_LIBRARY += \" a newer version of\"",
            "NEED_CRYPTO_LIBRARY += \" pycrypto in order to function.\"",
            "",
            "",
            "class AnsibleVaultError(AnsibleError):",
            "    pass",
            "",
            "",
            "class AnsibleVaultPasswordError(AnsibleVaultError):",
            "    pass",
            "",
            "",
            "class AnsibleVaultFormatError(AnsibleError):",
            "    pass",
            "",
            "",
            "def is_encrypted(data):",
            "    \"\"\" Test if this is vault encrypted data blob",
            "",
            "    :arg data: a byte or text string to test whether it is recognized as vault",
            "        encrypted data",
            "    :returns: True if it is recognized.  Otherwise, False.",
            "    \"\"\"",
            "    try:",
            "        # Make sure we have a byte string and that it only contains ascii",
            "        # bytes.",
            "        b_data = to_bytes(to_text(data, encoding='ascii', errors='strict', nonstring='strict'), encoding='ascii', errors='strict')",
            "    except (UnicodeError, TypeError):",
            "        # The vault format is pure ascii so if we failed to encode to bytes",
            "        # via ascii we know that this is not vault data.",
            "        # Similarly, if it's not a string, it's not vault data",
            "        return False",
            "",
            "    if b_data.startswith(b_HEADER):",
            "        return True",
            "    return False",
            "",
            "",
            "def is_encrypted_file(file_obj, start_pos=0, count=-1):",
            "    \"\"\"Test if the contents of a file obj are a vault encrypted data blob.",
            "",
            "    :arg file_obj: A file object that will be read from.",
            "    :kwarg start_pos: A byte offset in the file to start reading the header",
            "        from.  Defaults to 0, the beginning of the file.",
            "    :kwarg count: Read up to this number of bytes from the file to determine",
            "        if it looks like encrypted vault data.  The default is -1, read to the",
            "        end of file.",
            "    :returns: True if the file looks like a vault file. Otherwise, False.",
            "    \"\"\"",
            "    # read the header and reset the file stream to where it started",
            "    current_position = file_obj.tell()",
            "    try:",
            "        file_obj.seek(start_pos)",
            "        return is_encrypted(file_obj.read(count))",
            "",
            "    finally:",
            "        file_obj.seek(current_position)",
            "",
            "",
            "def _parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id=None):",
            "",
            "    b_tmpdata = b_vaulttext_envelope.splitlines()",
            "    b_tmpheader = b_tmpdata[0].strip().split(b';')",
            "",
            "    b_version = b_tmpheader[1].strip()",
            "    cipher_name = to_text(b_tmpheader[2].strip())",
            "    vault_id = default_vault_id",
            "",
            "    # Only attempt to find vault_id if the vault file is version 1.2 or newer",
            "    # if self.b_version == b'1.2':",
            "    if len(b_tmpheader) >= 4:",
            "        vault_id = to_text(b_tmpheader[3].strip())",
            "",
            "    b_ciphertext = b''.join(b_tmpdata[1:])",
            "",
            "    return b_ciphertext, b_version, cipher_name, vault_id",
            "",
            "",
            "def parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id=None, filename=None):",
            "    \"\"\"Parse the vaulttext envelope",
            "",
            "    When data is saved, it has a header prepended and is formatted into 80",
            "    character lines.  This method extracts the information from the header",
            "    and then removes the header and the inserted newlines.  The string returned",
            "    is suitable for processing by the Cipher classes.",
            "",
            "    :arg b_vaulttext: byte str containing the data from a save file",
            "    :kwarg default_vault_id: The vault_id name to use if the vaulttext does not provide one.",
            "    :kwarg filename: The filename that the data came from.  This is only",
            "        used to make better error messages in case the data cannot be",
            "        decrypted. This is optional.",
            "    :returns: A tuple of byte str of the vaulttext suitable to pass to parse_vaultext,",
            "        a byte str of the vault format version,",
            "        the name of the cipher used, and the vault_id.",
            "    :raises: AnsibleVaultFormatError: if the vaulttext_envelope format is invalid",
            "    \"\"\"",
            "    # used by decrypt",
            "    default_vault_id = default_vault_id or C.DEFAULT_VAULT_IDENTITY",
            "",
            "    try:",
            "        return _parse_vaulttext_envelope(b_vaulttext_envelope, default_vault_id)",
            "    except Exception as exc:",
            "        msg = \"Vault envelope format error\"",
            "        if filename:",
            "            msg += ' in %s' % (filename)",
            "        msg += ': %s' % exc",
            "        raise AnsibleVaultFormatError(msg)",
            "",
            "",
            "def format_vaulttext_envelope(b_ciphertext, cipher_name, version=None, vault_id=None):",
            "    \"\"\" Add header and format to 80 columns",
            "",
            "        :arg b_ciphertext: the encrypted and hexlified data as a byte string",
            "        :arg cipher_name: unicode cipher name (for ex, u'AES256')",
            "        :arg version: unicode vault version (for ex, '1.2'). Optional ('1.1' is default)",
            "        :arg vault_id: unicode vault identifier. If provided, the version will be bumped to 1.2.",
            "        :returns: a byte str that should be dumped into a file.  It's",
            "            formatted to 80 char columns and has the header prepended",
            "    \"\"\"",
            "",
            "    if not cipher_name:",
            "        raise AnsibleError(\"the cipher must be set before adding a header\")",
            "",
            "    version = version or '1.1'",
            "",
            "    # If we specify a vault_id, use format version 1.2. For no vault_id, stick to 1.1",
            "    if vault_id and vault_id != u'default':",
            "        version = '1.2'",
            "",
            "    b_version = to_bytes(version, 'utf-8', errors='strict')",
            "    b_vault_id = to_bytes(vault_id, 'utf-8', errors='strict')",
            "    b_cipher_name = to_bytes(cipher_name, 'utf-8', errors='strict')",
            "",
            "    header_parts = [b_HEADER,",
            "                    b_version,",
            "                    b_cipher_name]",
            "",
            "    if b_version == b'1.2' and b_vault_id:",
            "        header_parts.append(b_vault_id)",
            "",
            "    header = b';'.join(header_parts)",
            "",
            "    b_vaulttext = [header]",
            "    b_vaulttext += [b_ciphertext[i:i + 80] for i in range(0, len(b_ciphertext), 80)]",
            "    b_vaulttext += [b'']",
            "    b_vaulttext = b'\\n'.join(b_vaulttext)",
            "",
            "    return b_vaulttext",
            "",
            "",
            "def _unhexlify(b_data):",
            "    try:",
            "        return unhexlify(b_data)",
            "    except (BinasciiError, TypeError) as exc:",
            "        raise AnsibleVaultFormatError('Vault format unhexlify error: %s' % exc)",
            "",
            "",
            "def _parse_vaulttext(b_vaulttext):",
            "    b_vaulttext = _unhexlify(b_vaulttext)",
            "    b_salt, b_crypted_hmac, b_ciphertext = b_vaulttext.split(b\"\\n\", 2)",
            "    b_salt = _unhexlify(b_salt)",
            "    b_ciphertext = _unhexlify(b_ciphertext)",
            "",
            "    return b_ciphertext, b_salt, b_crypted_hmac",
            "",
            "",
            "def parse_vaulttext(b_vaulttext):",
            "    \"\"\"Parse the vaulttext",
            "",
            "    :arg b_vaulttext: byte str containing the vaulttext (ciphertext, salt, crypted_hmac)",
            "    :returns: A tuple of byte str of the ciphertext suitable for passing to a",
            "        Cipher class's decrypt() function, a byte str of the salt,",
            "        and a byte str of the crypted_hmac",
            "    :raises: AnsibleVaultFormatError: if the vaulttext format is invalid",
            "    \"\"\"",
            "    # SPLIT SALT, DIGEST, AND DATA",
            "    try:",
            "        return _parse_vaulttext(b_vaulttext)",
            "    except AnsibleVaultFormatError:",
            "        raise",
            "    except Exception as exc:",
            "        msg = \"Vault vaulttext format error: %s\" % exc",
            "        raise AnsibleVaultFormatError(msg)",
            "",
            "",
            "def verify_secret_is_not_empty(secret, msg=None):",
            "    '''Check the secret against minimal requirements.",
            "",
            "    Raises: AnsibleVaultPasswordError if the password does not meet requirements.",
            "",
            "    Currently, only requirement is that the password is not None or an empty string.",
            "    '''",
            "    msg = msg or 'Invalid vault password was provided'",
            "    if not secret:",
            "        raise AnsibleVaultPasswordError(msg)",
            "",
            "",
            "class VaultSecret:",
            "    '''Opaque/abstract objects for a single vault secret. ie, a password or a key.'''",
            "",
            "    def __init__(self, _bytes=None):",
            "        # FIXME: ? that seems wrong... Unset etc?",
            "        self._bytes = _bytes",
            "",
            "    @property",
            "    def bytes(self):",
            "        '''The secret as a bytestring.",
            "",
            "        Sub classes that store text types will need to override to encode the text to bytes.",
            "        '''",
            "        return self._bytes",
            "",
            "    def load(self):",
            "        return self._bytes",
            "",
            "",
            "class PromptVaultSecret(VaultSecret):",
            "    default_prompt_formats = [\"Vault password (%s): \"]",
            "",
            "    def __init__(self, _bytes=None, vault_id=None, prompt_formats=None):",
            "        super(PromptVaultSecret, self).__init__(_bytes=_bytes)",
            "        self.vault_id = vault_id",
            "",
            "        if prompt_formats is None:",
            "            self.prompt_formats = self.default_prompt_formats",
            "        else:",
            "            self.prompt_formats = prompt_formats",
            "",
            "    @property",
            "    def bytes(self):",
            "        return self._bytes",
            "",
            "    def load(self):",
            "        self._bytes = self.ask_vault_passwords()",
            "",
            "    def ask_vault_passwords(self):",
            "        b_vault_passwords = []",
            "",
            "        for prompt_format in self.prompt_formats:",
            "            prompt = prompt_format % {'vault_id': self.vault_id}",
            "            try:",
            "                vault_pass = display.prompt(prompt, private=True)",
            "            except EOFError:",
            "                raise AnsibleVaultError('EOFError (ctrl-d) on prompt for (%s)' % self.vault_id)",
            "",
            "            verify_secret_is_not_empty(vault_pass)",
            "",
            "            b_vault_pass = to_bytes(vault_pass, errors='strict', nonstring='simplerepr').strip()",
            "            b_vault_passwords.append(b_vault_pass)",
            "",
            "        # Make sure the passwords match by comparing them all to the first password",
            "        for b_vault_password in b_vault_passwords:",
            "            self.confirm(b_vault_passwords[0], b_vault_password)",
            "",
            "        if b_vault_passwords:",
            "            return b_vault_passwords[0]",
            "",
            "        return None",
            "",
            "    def confirm(self, b_vault_pass_1, b_vault_pass_2):",
            "        # enforce no newline chars at the end of passwords",
            "",
            "        if b_vault_pass_1 != b_vault_pass_2:",
            "            # FIXME: more specific exception",
            "            raise AnsibleError(\"Passwords do not match\")",
            "",
            "",
            "def script_is_client(filename):",
            "    '''Determine if a vault secret script is a client script that can be given --vault-id args'''",
            "",
            "    # if password script is 'something-client' or 'something-client.[sh|py|rb|etc]'",
            "    # script_name can still have '.' or could be entire filename if there is no ext",
            "    script_name, dummy = os.path.splitext(filename)",
            "",
            "    # TODO: for now, this is entirely based on filename",
            "    if script_name.endswith('-client'):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def get_file_vault_secret(filename=None, vault_id=None, encoding=None, loader=None):",
            "    this_path = os.path.realpath(os.path.expanduser(filename))",
            "",
            "    if not os.path.exists(this_path):",
            "        raise AnsibleError(\"The vault password file %s was not found\" % this_path)",
            "",
            "    if loader.is_executable(this_path):",
            "        if script_is_client(filename):",
            "            display.vvvv(u'The vault password file %s is a client script.' % to_text(filename))",
            "            # TODO: pass vault_id_name to script via cli",
            "            return ClientScriptVaultSecret(filename=this_path, vault_id=vault_id,",
            "                                           encoding=encoding, loader=loader)",
            "        # just a plain vault password script. No args, returns a byte array",
            "        return ScriptVaultSecret(filename=this_path, encoding=encoding, loader=loader)",
            "",
            "    return FileVaultSecret(filename=this_path, encoding=encoding, loader=loader)",
            "",
            "",
            "# TODO: mv these classes to a separate file so we don't pollute vault with 'subprocess' etc",
            "class FileVaultSecret(VaultSecret):",
            "    def __init__(self, filename=None, encoding=None, loader=None):",
            "        super(FileVaultSecret, self).__init__()",
            "        self.filename = filename",
            "        self.loader = loader",
            "",
            "        self.encoding = encoding or 'utf8'",
            "",
            "        # We could load from file here, but that is eventually a pain to test",
            "        self._bytes = None",
            "        self._text = None",
            "",
            "    @property",
            "    def bytes(self):",
            "        if self._bytes:",
            "            return self._bytes",
            "        if self._text:",
            "            return self._text.encode(self.encoding)",
            "        return None",
            "",
            "    def load(self):",
            "        self._bytes = self._read_file(self.filename)",
            "",
            "    def _read_file(self, filename):",
            "        \"\"\"",
            "        Read a vault password from a file or if executable, execute the script and",
            "        retrieve password from STDOUT",
            "        \"\"\"",
            "",
            "        # TODO: replace with use of self.loader",
            "        try:",
            "            f = open(filename, \"rb\")",
            "            vault_pass = f.read().strip()",
            "            f.close()",
            "        except (OSError, IOError) as e:",
            "            raise AnsibleError(\"Could not read vault password file %s: %s\" % (filename, e))",
            "",
            "        b_vault_data, dummy = self.loader._decrypt_if_vault_data(vault_pass, filename)",
            "",
            "        vault_pass = b_vault_data.strip(b'\\r\\n')",
            "",
            "        verify_secret_is_not_empty(vault_pass,",
            "                                   msg='Invalid vault password was provided from file (%s)' % filename)",
            "",
            "        return vault_pass",
            "",
            "    def __repr__(self):",
            "        if self.filename:",
            "            return \"%s(filename='%s')\" % (self.__class__.__name__, self.filename)",
            "        return \"%s()\" % (self.__class__.__name__)",
            "",
            "",
            "class ScriptVaultSecret(FileVaultSecret):",
            "    def _read_file(self, filename):",
            "        if not self.loader.is_executable(filename):",
            "            raise AnsibleVaultError(\"The vault password script %s was not executable\" % filename)",
            "",
            "        command = self._build_command()",
            "",
            "        stdout, stderr, p = self._run(command)",
            "",
            "        self._check_results(stdout, stderr, p)",
            "",
            "        vault_pass = stdout.strip(b'\\r\\n')",
            "",
            "        empty_password_msg = 'Invalid vault password was provided from script (%s)' % filename",
            "        verify_secret_is_not_empty(vault_pass,",
            "                                   msg=empty_password_msg)",
            "",
            "        return vault_pass",
            "",
            "    def _run(self, command):",
            "        try:",
            "            # STDERR not captured to make it easier for users to prompt for input in their scripts",
            "            p = subprocess.Popen(command, stdout=subprocess.PIPE)",
            "        except OSError as e:",
            "            msg_format = \"Problem running vault password script %s (%s).\" \\",
            "                \" If this is not a script, remove the executable bit from the file.\"",
            "            msg = msg_format % (self.filename, e)",
            "",
            "            raise AnsibleError(msg)",
            "",
            "        stdout, stderr = p.communicate()",
            "        return stdout, stderr, p",
            "",
            "    def _check_results(self, stdout, stderr, popen):",
            "        if popen.returncode != 0:",
            "            raise AnsibleError(\"Vault password script %s returned non-zero (%s): %s\" %",
            "                               (self.filename, popen.returncode, stderr))",
            "",
            "    def _build_command(self):",
            "        return [self.filename]",
            "",
            "",
            "class ClientScriptVaultSecret(ScriptVaultSecret):",
            "    VAULT_ID_UNKNOWN_RC = 2",
            "",
            "    def __init__(self, filename=None, encoding=None, loader=None, vault_id=None):",
            "        super(ClientScriptVaultSecret, self).__init__(filename=filename,",
            "                                                      encoding=encoding,",
            "                                                      loader=loader)",
            "        self._vault_id = vault_id",
            "        display.vvvv(u'Executing vault password client script: %s --vault-id %s' % (to_text(filename), to_text(vault_id)))",
            "",
            "    def _run(self, command):",
            "        try:",
            "            p = subprocess.Popen(command,",
            "                                 stdout=subprocess.PIPE,",
            "                                 stderr=subprocess.PIPE)",
            "        except OSError as e:",
            "            msg_format = \"Problem running vault password client script %s (%s).\" \\",
            "                \" If this is not a script, remove the executable bit from the file.\"",
            "            msg = msg_format % (self.filename, e)",
            "",
            "            raise AnsibleError(msg)",
            "",
            "        stdout, stderr = p.communicate()",
            "        return stdout, stderr, p",
            "",
            "    def _check_results(self, stdout, stderr, popen):",
            "        if popen.returncode == self.VAULT_ID_UNKNOWN_RC:",
            "            raise AnsibleError('Vault password client script %s did not find a secret for vault-id=%s: %s' %",
            "                               (self.filename, self._vault_id, stderr))",
            "",
            "        if popen.returncode != 0:",
            "            raise AnsibleError(\"Vault password client script %s returned non-zero (%s) when getting secret for vault-id=%s: %s\" %",
            "                               (self.filename, popen.returncode, self._vault_id, stderr))",
            "",
            "    def _build_command(self):",
            "        command = [self.filename]",
            "        if self._vault_id:",
            "            command.extend(['--vault-id', self._vault_id])",
            "",
            "        return command",
            "",
            "    def __repr__(self):",
            "        if self.filename:",
            "            return \"%s(filename='%s', vault_id='%s')\" % \\",
            "                (self.__class__.__name__, self.filename, self._vault_id)",
            "        return \"%s()\" % (self.__class__.__name__)",
            "",
            "",
            "def match_secrets(secrets, target_vault_ids):",
            "    '''Find all VaultSecret objects that are mapped to any of the target_vault_ids in secrets'''",
            "    if not secrets:",
            "        return []",
            "",
            "    matches = [(vault_id, secret) for vault_id, secret in secrets if vault_id in target_vault_ids]",
            "    return matches",
            "",
            "",
            "def match_best_secret(secrets, target_vault_ids):",
            "    '''Find the best secret from secrets that matches target_vault_ids",
            "",
            "    Since secrets should be ordered so the early secrets are 'better' than later ones, this",
            "    just finds all the matches, then returns the first secret'''",
            "    matches = match_secrets(secrets, target_vault_ids)",
            "    if matches:",
            "        return matches[0]",
            "    # raise exception?",
            "    return None",
            "",
            "",
            "def match_encrypt_vault_id_secret(secrets, encrypt_vault_id=None):",
            "    # See if the --encrypt-vault-id matches a vault-id",
            "    display.vvvv(u'encrypt_vault_id=%s' % to_text(encrypt_vault_id))",
            "",
            "    if encrypt_vault_id is None:",
            "        raise AnsibleError('match_encrypt_vault_id_secret requires a non None encrypt_vault_id')",
            "",
            "    encrypt_vault_id_matchers = [encrypt_vault_id]",
            "    encrypt_secret = match_best_secret(secrets, encrypt_vault_id_matchers)",
            "",
            "    # return the best match for --encrypt-vault-id",
            "    if encrypt_secret:",
            "        return encrypt_secret",
            "",
            "    # If we specified a encrypt_vault_id and we couldn't find it, dont",
            "    # fallback to using the first/best secret",
            "    raise AnsibleVaultError('Did not find a match for --encrypt-vault-id=%s in the known vault-ids %s' % (encrypt_vault_id,",
            "                                                                                                          [_v for _v, _vs in secrets]))",
            "",
            "",
            "def match_encrypt_secret(secrets, encrypt_vault_id=None):",
            "    '''Find the best/first/only secret in secrets to use for encrypting'''",
            "",
            "    display.vvvv(u'encrypt_vault_id=%s' % to_text(encrypt_vault_id))",
            "    # See if the --encrypt-vault-id matches a vault-id",
            "    if encrypt_vault_id:",
            "        return match_encrypt_vault_id_secret(secrets,",
            "                                             encrypt_vault_id=encrypt_vault_id)",
            "",
            "    # Find the best/first secret from secrets since we didnt specify otherwise",
            "    # ie, consider all of the available secrets as matches",
            "    _vault_id_matchers = [_vault_id for _vault_id, dummy in secrets]",
            "    best_secret = match_best_secret(secrets, _vault_id_matchers)",
            "",
            "    # can be empty list sans any tuple",
            "    return best_secret",
            "",
            "",
            "class VaultLib:",
            "    def __init__(self, secrets=None):",
            "        self.secrets = secrets or []",
            "        self.cipher_name = None",
            "        self.b_version = b'1.2'",
            "",
            "    def encrypt(self, plaintext, secret=None, vault_id=None):",
            "        \"\"\"Vault encrypt a piece of data.",
            "",
            "        :arg plaintext: a text or byte string to encrypt.",
            "        :returns: a utf-8 encoded byte str of encrypted data.  The string",
            "            contains a header identifying this as vault encrypted data and",
            "            formatted to newline terminated lines of 80 characters.  This is",
            "            suitable for dumping as is to a vault file.",
            "",
            "        If the string passed in is a text string, it will be encoded to UTF-8",
            "        before encryption.",
            "        \"\"\"",
            "",
            "        if secret is None:",
            "            if self.secrets:",
            "                dummy, secret = match_encrypt_secret(self.secrets)",
            "            else:",
            "                raise AnsibleVaultError(\"A vault password must be specified to encrypt data\")",
            "",
            "        b_plaintext = to_bytes(plaintext, errors='surrogate_or_strict')",
            "",
            "        if is_encrypted(b_plaintext):",
            "            raise AnsibleError(\"input is already encrypted\")",
            "",
            "        if not self.cipher_name or self.cipher_name not in CIPHER_WRITE_WHITELIST:",
            "            self.cipher_name = u\"AES256\"",
            "",
            "        try:",
            "            this_cipher = CIPHER_MAPPING[self.cipher_name]()",
            "        except KeyError:",
            "            raise AnsibleError(u\"{0} cipher could not be found\".format(self.cipher_name))",
            "",
            "        # encrypt data",
            "        if vault_id:",
            "            display.vvvvv(u'Encrypting with vault_id \"%s\" and vault secret %s' % (to_text(vault_id), to_text(secret)))",
            "        else:",
            "            display.vvvvv(u'Encrypting without a vault_id using vault secret %s' % to_text(secret))",
            "",
            "        b_ciphertext = this_cipher.encrypt(b_plaintext, secret)",
            "",
            "        # format the data for output to the file",
            "        b_vaulttext = format_vaulttext_envelope(b_ciphertext,",
            "                                                self.cipher_name,",
            "                                                vault_id=vault_id)",
            "        return b_vaulttext",
            "",
            "    def decrypt(self, vaulttext, filename=None):",
            "        '''Decrypt a piece of vault encrypted data.",
            "",
            "        :arg vaulttext: a string to decrypt.  Since vault encrypted data is an",
            "            ascii text format this can be either a byte str or unicode string.",
            "        :kwarg filename: a filename that the data came from.  This is only",
            "            used to make better error messages in case the data cannot be",
            "            decrypted.",
            "        :returns: a byte string containing the decrypted data and the vault-id that was used",
            "",
            "        '''",
            "        plaintext, vault_id, vault_secret = self.decrypt_and_get_vault_id(vaulttext, filename=filename)",
            "        return plaintext",
            "",
            "    def decrypt_and_get_vault_id(self, vaulttext, filename=None):",
            "        \"\"\"Decrypt a piece of vault encrypted data.",
            "",
            "        :arg vaulttext: a string to decrypt.  Since vault encrypted data is an",
            "            ascii text format this can be either a byte str or unicode string.",
            "        :kwarg filename: a filename that the data came from.  This is only",
            "            used to make better error messages in case the data cannot be",
            "            decrypted.",
            "        :returns: a byte string containing the decrypted data and the vault-id vault-secret that was used",
            "",
            "        \"\"\"",
            "        b_vaulttext = to_bytes(vaulttext, errors='strict', encoding='utf-8')",
            "",
            "        if self.secrets is None:",
            "            raise AnsibleVaultError(\"A vault password must be specified to decrypt data\")",
            "",
            "        if not is_encrypted(b_vaulttext):",
            "            msg = \"input is not vault encrypted data\"",
            "            if filename:",
            "                msg += \"%s is not a vault encrypted file\" % to_native(filename)",
            "            raise AnsibleError(msg)",
            "",
            "        b_vaulttext, dummy, cipher_name, vault_id = parse_vaulttext_envelope(b_vaulttext,",
            "                                                                             filename=filename)",
            "",
            "        # create the cipher object, note that the cipher used for decrypt can",
            "        # be different than the cipher used for encrypt",
            "        if cipher_name in CIPHER_WHITELIST:",
            "            this_cipher = CIPHER_MAPPING[cipher_name]()",
            "        else:",
            "            raise AnsibleError(\"{0} cipher could not be found\".format(cipher_name))",
            "",
            "        b_plaintext = None",
            "",
            "        if not self.secrets:",
            "            raise AnsibleVaultError('Attempting to decrypt but no vault secrets found')",
            "",
            "        # WARNING: Currently, the vault id is not required to match the vault id in the vault blob to",
            "        #          decrypt a vault properly. The vault id in the vault blob is not part of the encrypted",
            "        #          or signed vault payload. There is no cryptographic checking/verification/validation of the",
            "        #          vault blobs vault id. It can be tampered with and changed. The vault id is just a nick",
            "        #          name to use to pick the best secret and provide some ux/ui info.",
            "",
            "        # iterate over all the applicable secrets (all of them by default) until one works...",
            "        # if we specify a vault_id, only the corresponding vault secret is checked and",
            "        # we check it first.",
            "",
            "        vault_id_matchers = []",
            "        vault_id_used = None",
            "        vault_secret_used = None",
            "",
            "        if vault_id:",
            "            display.vvvvv(u'Found a vault_id (%s) in the vaulttext' % to_text(vault_id))",
            "            vault_id_matchers.append(vault_id)",
            "            _matches = match_secrets(self.secrets, vault_id_matchers)",
            "            if _matches:",
            "                display.vvvvv(u'We have a secret associated with vault id (%s), will try to use to decrypt %s' % (to_text(vault_id), to_text(filename)))",
            "            else:",
            "                display.vvvvv(u'Found a vault_id (%s) in the vault text, but we do not have a associated secret (--vault-id)' % to_text(vault_id))",
            "",
            "        # Not adding the other secrets to vault_secret_ids enforces a match between the vault_id from the vault_text and",
            "        # the known vault secrets.",
            "        if not C.DEFAULT_VAULT_ID_MATCH:",
            "            # Add all of the known vault_ids as candidates for decrypting a vault.",
            "            vault_id_matchers.extend([_vault_id for _vault_id, _dummy in self.secrets if _vault_id != vault_id])",
            "",
            "        matched_secrets = match_secrets(self.secrets, vault_id_matchers)",
            "",
            "        # for vault_secret_id in vault_secret_ids:",
            "        for vault_secret_id, vault_secret in matched_secrets:",
            "            display.vvvvv(u'Trying to use vault secret=(%s) id=%s to decrypt %s' % (to_text(vault_secret), to_text(vault_secret_id), to_text(filename)))",
            "",
            "            try:",
            "                # secret = self.secrets[vault_secret_id]",
            "                display.vvvv(u'Trying secret %s for vault_id=%s' % (to_text(vault_secret), to_text(vault_secret_id)))",
            "                b_plaintext = this_cipher.decrypt(b_vaulttext, vault_secret)",
            "                if b_plaintext is not None:",
            "                    vault_id_used = vault_secret_id",
            "                    vault_secret_used = vault_secret",
            "                    file_slug = ''",
            "                    if filename:",
            "                        file_slug = ' of \"%s\"' % filename",
            "                    display.vvvvv(",
            "                        u'Decrypt%s successful with secret=%s and vault_id=%s' % (to_text(file_slug), to_text(vault_secret), to_text(vault_secret_id))",
            "                    )",
            "                    break",
            "            except AnsibleVaultFormatError as exc:",
            "                msg = u\"There was a vault format error\"",
            "                if filename:",
            "                    msg += u' in %s' % (to_text(filename))",
            "                msg += u': %s' % exc",
            "                display.warning(msg)",
            "                raise",
            "            except AnsibleError as e:",
            "                display.vvvv(u'Tried to use the vault secret (%s) to decrypt (%s) but it failed. Error: %s' %",
            "                             (to_text(vault_secret_id), to_text(filename), e))",
            "                continue",
            "        else:",
            "            msg = \"Decryption failed (no vault secrets were found that could decrypt)\"",
            "            if filename:",
            "                msg += \" on %s\" % to_native(filename)",
            "            raise AnsibleVaultError(msg)",
            "",
            "        if b_plaintext is None:",
            "            msg = \"Decryption failed\"",
            "            if filename:",
            "                msg += \" on %s\" % to_native(filename)",
            "            raise AnsibleError(msg)",
            "",
            "        return b_plaintext, vault_id_used, vault_secret_used",
            "",
            "",
            "class VaultEditor:",
            "",
            "    def __init__(self, vault=None):",
            "        # TODO: it may be more useful to just make VaultSecrets and index of VaultLib objects...",
            "        self.vault = vault or VaultLib()",
            "",
            "    # TODO: mv shred file stuff to it's own class",
            "    def _shred_file_custom(self, tmp_path):",
            "        \"\"\"\"Destroy a file, when shred (core-utils) is not available",
            "",
            "        Unix `shred' destroys files \"so that they can be recovered only with great difficulty with",
            "        specialised hardware, if at all\". It is based on the method from the paper",
            "        \"Secure Deletion of Data from Magnetic and Solid-State Memory\",",
            "        Proceedings of the Sixth USENIX Security Symposium (San Jose, California, July 22-25, 1996).",
            "",
            "        We do not go to that length to re-implement shred in Python; instead, overwriting with a block",
            "        of random data should suffice.",
            "",
            "        See https://github.com/ansible/ansible/pull/13700 .",
            "        \"\"\"",
            "",
            "        file_len = os.path.getsize(tmp_path)",
            "",
            "        if file_len > 0:  # avoid work when file was empty",
            "            max_chunk_len = min(1024 * 1024 * 2, file_len)",
            "",
            "            passes = 3",
            "            with open(tmp_path, \"wb\") as fh:",
            "                for _ in range(passes):",
            "                    fh.seek(0, 0)",
            "                    # get a random chunk of data, each pass with other length",
            "                    chunk_len = random.randint(max_chunk_len // 2, max_chunk_len)",
            "                    data = os.urandom(chunk_len)",
            "",
            "                    for _ in range(0, file_len // chunk_len):",
            "                        fh.write(data)",
            "                    fh.write(data[:file_len % chunk_len])",
            "",
            "                    # FIXME remove this assert once we have unittests to check its accuracy",
            "                    if fh.tell() != file_len:",
            "                        raise AnsibleAssertionError()",
            "",
            "                    os.fsync(fh)",
            "",
            "    def _shred_file(self, tmp_path):",
            "        \"\"\"Securely destroy a decrypted file",
            "",
            "        Note standard limitations of GNU shred apply (For flash, overwriting would have no effect",
            "        due to wear leveling; for other storage systems, the async kernel->filesystem->disk calls never",
            "        guarantee data hits the disk; etc). Furthermore, if your tmp dirs is on tmpfs (ramdisks),",
            "        it is a non-issue.",
            "",
            "        Nevertheless, some form of overwriting the data (instead of just removing the fs index entry) is",
            "        a good idea. If shred is not available (e.g. on windows, or no core-utils installed), fall back on",
            "        a custom shredding method.",
            "        \"\"\"",
            "",
            "        if not os.path.isfile(tmp_path):",
            "            # file is already gone",
            "            return",
            "",
            "        try:",
            "            r = subprocess.call(['shred', tmp_path])",
            "        except (OSError, ValueError):",
            "            # shred is not available on this system, or some other error occurred.",
            "            # ValueError caught because macOS El Capitan is raising an",
            "            # exception big enough to hit a limit in python2-2.7.11 and below.",
            "            # Symptom is ValueError: insecure pickle when shred is not",
            "            # installed there.",
            "            r = 1",
            "",
            "        if r != 0:",
            "            # we could not successfully execute unix shred; therefore, do custom shred.",
            "            self._shred_file_custom(tmp_path)",
            "",
            "        os.remove(tmp_path)",
            "",
            "    def _edit_file_helper(self, filename, secret,",
            "                          existing_data=None, force_save=False, vault_id=None):",
            "",
            "        # Create a tempfile",
            "        root, ext = os.path.splitext(os.path.realpath(filename))",
            "        fd, tmp_path = tempfile.mkstemp(suffix=ext, dir=C.DEFAULT_LOCAL_TMP)",
            "        os.close(fd)",
            "",
            "        cmd = self._editor_shell_command(tmp_path)",
            "        try:",
            "            if existing_data:",
            "                self.write_data(existing_data, tmp_path, shred=False)",
            "",
            "            # drop the user into an editor on the tmp file",
            "            subprocess.call(cmd)",
            "        except Exception as e:",
            "            # whatever happens, destroy the decrypted file",
            "            self._shred_file(tmp_path)",
            "            raise AnsibleError('Unable to execute the command \"%s\": %s' % (' '.join(cmd), to_native(e)))",
            "",
            "        b_tmpdata = self.read_data(tmp_path)",
            "",
            "        # Do nothing if the content has not changed",
            "        if existing_data == b_tmpdata and not force_save:",
            "            self._shred_file(tmp_path)",
            "            return",
            "",
            "        # encrypt new data and write out to tmp",
            "        # An existing vaultfile will always be UTF-8,",
            "        # so decode to unicode here",
            "        b_ciphertext = self.vault.encrypt(b_tmpdata, secret, vault_id=vault_id)",
            "        self.write_data(b_ciphertext, tmp_path)",
            "",
            "        # shuffle tmp file into place",
            "        self.shuffle_files(tmp_path, filename)",
            "        display.vvvvv(u'Saved edited file \"%s\" encrypted using %s and  vault id \"%s\"' % (to_text(filename), to_text(secret), to_text(vault_id)))",
            "",
            "    def _real_path(self, filename):",
            "        # '-' is special to VaultEditor, dont expand it.",
            "        if filename == '-':",
            "            return filename",
            "",
            "        real_path = os.path.realpath(filename)",
            "        return real_path",
            "",
            "    def encrypt_bytes(self, b_plaintext, secret, vault_id=None):",
            "",
            "        b_ciphertext = self.vault.encrypt(b_plaintext, secret, vault_id=vault_id)",
            "",
            "        return b_ciphertext",
            "",
            "    def encrypt_file(self, filename, secret, vault_id=None, output_file=None):",
            "",
            "        # A file to be encrypted into a vaultfile could be any encoding",
            "        # so treat the contents as a byte string.",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        b_plaintext = self.read_data(filename)",
            "        b_ciphertext = self.vault.encrypt(b_plaintext, secret, vault_id=vault_id)",
            "        self.write_data(b_ciphertext, output_file or filename)",
            "",
            "    def decrypt_file(self, filename, output_file=None):",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        ciphertext = self.read_data(filename)",
            "",
            "        try:",
            "            plaintext = self.vault.decrypt(ciphertext, filename=filename)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "        self.write_data(plaintext, output_file or filename, shred=False)",
            "",
            "    def create_file(self, filename, secret, vault_id=None):",
            "        \"\"\" create a new encrypted file \"\"\"",
            "",
            "        dirname = os.path.dirname(filename)",
            "        if dirname and not os.path.exists(dirname):",
            "            display.warning(u\"%s does not exist, creating...\" % to_text(dirname))",
            "            makedirs_safe(dirname)",
            "",
            "        # FIXME: If we can raise an error here, we can probably just make it",
            "        # behave like edit instead.",
            "        if os.path.isfile(filename):",
            "            raise AnsibleError(\"%s exists, please use 'edit' instead\" % filename)",
            "",
            "        self._edit_file_helper(filename, secret, vault_id=vault_id)",
            "",
            "    def edit_file(self, filename):",
            "        vault_id_used = None",
            "        vault_secret_used = None",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        b_vaulttext = self.read_data(filename)",
            "",
            "        # vault or yaml files are always utf8",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        try:",
            "            # vaulttext gets converted back to bytes, but alas",
            "            # TODO: return the vault_id that worked?",
            "            plaintext, vault_id_used, vault_secret_used = self.vault.decrypt_and_get_vault_id(vaulttext)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "        # Figure out the vault id from the file, to select the right secret to re-encrypt it",
            "        # (duplicates parts of decrypt, but alas...)",
            "        dummy, dummy, cipher_name, vault_id = parse_vaulttext_envelope(b_vaulttext,",
            "                                                                       filename=filename)",
            "",
            "        # vault id here may not be the vault id actually used for decrypting",
            "        # as when the edited file has no vault-id but is decrypted by non-default id in secrets",
            "        # (vault_id=default, while a different vault-id decrypted)",
            "",
            "        # Keep the same vault-id (and version) as in the header",
            "        if cipher_name not in CIPHER_WRITE_WHITELIST:",
            "            # we want to get rid of files encrypted with the AES cipher",
            "            self._edit_file_helper(filename, vault_secret_used, existing_data=plaintext,",
            "                                   force_save=True, vault_id=vault_id)",
            "        else:",
            "            self._edit_file_helper(filename, vault_secret_used, existing_data=plaintext,",
            "                                   force_save=False, vault_id=vault_id)",
            "",
            "    def plaintext(self, filename):",
            "",
            "        b_vaulttext = self.read_data(filename)",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        try:",
            "            plaintext = self.vault.decrypt(vaulttext, filename=filename)",
            "            return plaintext",
            "        except AnsibleError as e:",
            "            raise AnsibleVaultError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "    # FIXME/TODO: make this use VaultSecret",
            "    def rekey_file(self, filename, new_vault_secret, new_vault_id=None):",
            "",
            "        # follow the symlink",
            "        filename = self._real_path(filename)",
            "",
            "        prev = os.stat(filename)",
            "        b_vaulttext = self.read_data(filename)",
            "        vaulttext = to_text(b_vaulttext)",
            "",
            "        display.vvvvv(u'Rekeying file \"%s\" to with new vault-id \"%s\" and vault secret %s' %",
            "                      (to_text(filename), to_text(new_vault_id), to_text(new_vault_secret)))",
            "        try:",
            "            plaintext, vault_id_used, _dummy = self.vault.decrypt_and_get_vault_id(vaulttext)",
            "        except AnsibleError as e:",
            "            raise AnsibleError(\"%s for %s\" % (to_native(e), to_native(filename)))",
            "",
            "        # This is more or less an assert, see #18247",
            "        if new_vault_secret is None:",
            "            raise AnsibleError('The value for the new_password to rekey %s with is not valid' % filename)",
            "",
            "        # FIXME: VaultContext...?  could rekey to a different vault_id in the same VaultSecrets",
            "",
            "        # Need a new VaultLib because the new vault data can be a different",
            "        # vault lib format or cipher (for ex, when we migrate 1.0 style vault data to",
            "        # 1.1 style data we change the version and the cipher). This is where a VaultContext might help",
            "",
            "        # the new vault will only be used for encrypting, so it doesn't need the vault secrets",
            "        # (we will pass one in directly to encrypt)",
            "        new_vault = VaultLib(secrets={})",
            "        b_new_vaulttext = new_vault.encrypt(plaintext, new_vault_secret, vault_id=new_vault_id)",
            "",
            "        self.write_data(b_new_vaulttext, filename)",
            "",
            "        # preserve permissions",
            "        os.chmod(filename, prev.st_mode)",
            "        os.chown(filename, prev.st_uid, prev.st_gid)",
            "",
            "        display.vvvvv(u'Rekeyed file \"%s\" (decrypted with vault id \"%s\") was encrypted with new vault-id \"%s\" and vault secret %s' %",
            "                      (to_text(filename), to_text(vault_id_used), to_text(new_vault_id), to_text(new_vault_secret)))",
            "",
            "    def read_data(self, filename):",
            "",
            "        try:",
            "            if filename == '-':",
            "                data = sys.stdin.read()",
            "            else:",
            "                with open(filename, \"rb\") as fh:",
            "                    data = fh.read()",
            "        except Exception as e:",
            "            msg = to_native(e)",
            "            if not msg:",
            "                msg = repr(e)",
            "            raise AnsibleError('Unable to read source file (%s): %s' % (to_native(filename), msg))",
            "",
            "        return data",
            "",
            "    # TODO: add docstrings for arg types since this code is picky about that",
            "    def write_data(self, data, filename, shred=True):",
            "        \"\"\"Write the data bytes to given path",
            "",
            "        This is used to write a byte string to a file or stdout. It is used for",
            "        writing the results of vault encryption or decryption. It is used for",
            "        saving the ciphertext after encryption and it is also used for saving the",
            "        plaintext after decrypting a vault. The type of the 'data' arg should be bytes,",
            "        since in the plaintext case, the original contents can be of any text encoding",
            "        or arbitrary binary data.",
            "",
            "        When used to write the result of vault encryption, the val of the 'data' arg",
            "        should be a utf-8 encoded byte string and not a text typ and not a text type..",
            "",
            "        When used to write the result of vault decryption, the val of the 'data' arg",
            "        should be a byte string and not a text type.",
            "",
            "        :arg data: the byte string (bytes) data",
            "        :arg filename: filename to save 'data' to.",
            "        :arg shred: if shred==True, make sure that the original data is first shredded so that is cannot be recovered.",
            "        :returns: None",
            "        \"\"\"",
            "        # FIXME: do we need this now? data_bytes should always be a utf-8 byte string",
            "        b_file_data = to_bytes(data, errors='strict')",
            "",
            "        # get a ref to either sys.stdout.buffer for py3 or plain old sys.stdout for py2",
            "        # We need sys.stdout.buffer on py3 so we can write bytes to it since the plaintext",
            "        # of the vaulted object could be anything/binary/etc",
            "        output = getattr(sys.stdout, 'buffer', sys.stdout)",
            "",
            "        if filename == '-':",
            "            output.write(b_file_data)",
            "        else:",
            "            if os.path.isfile(filename):",
            "                if shred:",
            "                    self._shred_file(filename)",
            "                else:",
            "                    os.remove(filename)",
            "            with open(filename, \"wb\") as fh:",
            "                fh.write(b_file_data)",
            "",
            "    def shuffle_files(self, src, dest):",
            "        prev = None",
            "        # overwrite dest with src",
            "        if os.path.isfile(dest):",
            "            prev = os.stat(dest)",
            "            # old file 'dest' was encrypted, no need to _shred_file",
            "            os.remove(dest)",
            "        shutil.move(src, dest)",
            "",
            "        # reset permissions if needed",
            "        if prev is not None:",
            "            # TODO: selinux, ACLs, xattr?",
            "            os.chmod(dest, prev.st_mode)",
            "            os.chown(dest, prev.st_uid, prev.st_gid)",
            "",
            "    def _editor_shell_command(self, filename):",
            "        env_editor = os.environ.get('EDITOR', 'vi')",
            "        editor = shlex.split(env_editor)",
            "        editor.append(filename)",
            "",
            "        return editor",
            "",
            "",
            "########################################",
            "#               CIPHERS                #",
            "########################################",
            "",
            "class VaultAES256:",
            "",
            "    \"\"\"",
            "    Vault implementation using AES-CTR with an HMAC-SHA256 authentication code.",
            "    Keys are derived using PBKDF2",
            "    \"\"\"",
            "",
            "    # http://www.daemonology.net/blog/2009-06-11-cryptographic-right-answers.html",
            "",
            "    # Note: strings in this class should be byte strings by default.",
            "",
            "    def __init__(self):",
            "        if not HAS_CRYPTOGRAPHY and not HAS_PYCRYPTO:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY)",
            "",
            "    @staticmethod",
            "    def _create_key_cryptography(b_password, b_salt, key_length, iv_length):",
            "        kdf = PBKDF2HMAC(",
            "            algorithm=hashes.SHA256(),",
            "            length=2 * key_length + iv_length,",
            "            salt=b_salt,",
            "            iterations=10000,",
            "            backend=CRYPTOGRAPHY_BACKEND)",
            "        b_derivedkey = kdf.derive(b_password)",
            "",
            "        return b_derivedkey",
            "",
            "    @staticmethod",
            "    def _pbkdf2_prf(p, s):",
            "        hash_function = SHA256_pycrypto",
            "        return HMAC_pycrypto.new(p, s, hash_function).digest()",
            "",
            "    @classmethod",
            "    def _create_key_pycrypto(cls, b_password, b_salt, key_length, iv_length):",
            "",
            "        # make two keys and one iv",
            "",
            "        b_derivedkey = PBKDF2_pycrypto(b_password, b_salt, dkLen=(2 * key_length) + iv_length,",
            "                                       count=10000, prf=cls._pbkdf2_prf)",
            "        return b_derivedkey",
            "",
            "    @classmethod",
            "    def _gen_key_initctr(cls, b_password, b_salt):",
            "        # 16 for AES 128, 32 for AES256",
            "        key_length = 32",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            # AES is a 128-bit block cipher, so IVs and counter nonces are 16 bytes",
            "            iv_length = algorithms.AES.block_size // 8",
            "",
            "            b_derivedkey = cls._create_key_cryptography(b_password, b_salt, key_length, iv_length)",
            "            b_iv = b_derivedkey[(key_length * 2):(key_length * 2) + iv_length]",
            "        elif HAS_PYCRYPTO:",
            "            # match the size used for counter.new to avoid extra work",
            "            iv_length = 16",
            "",
            "            b_derivedkey = cls._create_key_pycrypto(b_password, b_salt, key_length, iv_length)",
            "            b_iv = hexlify(b_derivedkey[(key_length * 2):(key_length * 2) + iv_length])",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in initctr)')",
            "",
            "        b_key1 = b_derivedkey[:key_length]",
            "        b_key2 = b_derivedkey[key_length:(key_length * 2)]",
            "",
            "        return b_key1, b_key2, b_iv",
            "",
            "    @staticmethod",
            "    def _encrypt_cryptography(b_plaintext, b_key1, b_key2, b_iv):",
            "        cipher = C_Cipher(algorithms.AES(b_key1), modes.CTR(b_iv), CRYPTOGRAPHY_BACKEND)",
            "        encryptor = cipher.encryptor()",
            "        padder = padding.PKCS7(algorithms.AES.block_size).padder()",
            "        b_ciphertext = encryptor.update(padder.update(b_plaintext) + padder.finalize())",
            "        b_ciphertext += encryptor.finalize()",
            "",
            "        # COMBINE SALT, DIGEST AND DATA",
            "        hmac = HMAC(b_key2, hashes.SHA256(), CRYPTOGRAPHY_BACKEND)",
            "        hmac.update(b_ciphertext)",
            "        b_hmac = hmac.finalize()",
            "",
            "        return to_bytes(hexlify(b_hmac), errors='surrogate_or_strict'), hexlify(b_ciphertext)",
            "",
            "    @staticmethod",
            "    def _encrypt_pycrypto(b_plaintext, b_key1, b_key2, b_iv):",
            "        # PKCS#7 PAD DATA http://tools.ietf.org/html/rfc5652#section-6.3",
            "        bs = AES_pycrypto.block_size",
            "        padding_length = (bs - len(b_plaintext) % bs) or bs",
            "        b_plaintext += to_bytes(padding_length * chr(padding_length), encoding='ascii', errors='strict')",
            "",
            "        # COUNTER.new PARAMETERS",
            "        # 1) nbits (integer) - Length of the counter, in bits.",
            "        # 2) initial_value (integer) - initial value of the counter. \"iv\" from _gen_key_initctr",
            "",
            "        ctr = Counter_pycrypto.new(128, initial_value=int(b_iv, 16))",
            "",
            "        # AES.new PARAMETERS",
            "        # 1) AES key, must be either 16, 24, or 32 bytes long -- \"key\" from _gen_key_initctr",
            "        # 2) MODE_CTR, is the recommended mode",
            "        # 3) counter=<CounterObject>",
            "",
            "        cipher = AES_pycrypto.new(b_key1, AES_pycrypto.MODE_CTR, counter=ctr)",
            "",
            "        # ENCRYPT PADDED DATA",
            "        b_ciphertext = cipher.encrypt(b_plaintext)",
            "",
            "        # COMBINE SALT, DIGEST AND DATA",
            "        hmac = HMAC_pycrypto.new(b_key2, b_ciphertext, SHA256_pycrypto)",
            "",
            "        return to_bytes(hmac.hexdigest(), errors='surrogate_or_strict'), hexlify(b_ciphertext)",
            "",
            "    @classmethod",
            "    def encrypt(cls, b_plaintext, secret):",
            "        if secret is None:",
            "            raise AnsibleVaultError('The secret passed to encrypt() was None')",
            "        b_salt = os.urandom(32)",
            "        b_password = secret.bytes",
            "        b_key1, b_key2, b_iv = cls._gen_key_initctr(b_password, b_salt)",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            b_hmac, b_ciphertext = cls._encrypt_cryptography(b_plaintext, b_key1, b_key2, b_iv)",
            "        elif HAS_PYCRYPTO:",
            "            b_hmac, b_ciphertext = cls._encrypt_pycrypto(b_plaintext, b_key1, b_key2, b_iv)",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in encrypt)')",
            "",
            "        b_vaulttext = b'\\n'.join([hexlify(b_salt), b_hmac, b_ciphertext])",
            "        # Unnecessary but getting rid of it is a backwards incompatible vault",
            "        # format change",
            "        b_vaulttext = hexlify(b_vaulttext)",
            "        return b_vaulttext",
            "",
            "    @classmethod",
            "    def _decrypt_cryptography(cls, b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv):",
            "        # b_key1, b_key2, b_iv = self._gen_key_initctr(b_password, b_salt)",
            "        # EXIT EARLY IF DIGEST DOESN'T MATCH",
            "        hmac = HMAC(b_key2, hashes.SHA256(), CRYPTOGRAPHY_BACKEND)",
            "        hmac.update(b_ciphertext)",
            "        try:",
            "            hmac.verify(_unhexlify(b_crypted_hmac))",
            "        except InvalidSignature as e:",
            "            raise AnsibleVaultError('HMAC verification failed: %s' % e)",
            "",
            "        cipher = C_Cipher(algorithms.AES(b_key1), modes.CTR(b_iv), CRYPTOGRAPHY_BACKEND)",
            "        decryptor = cipher.decryptor()",
            "        unpadder = padding.PKCS7(128).unpadder()",
            "        b_plaintext = unpadder.update(",
            "            decryptor.update(b_ciphertext) + decryptor.finalize()",
            "        ) + unpadder.finalize()",
            "",
            "        return b_plaintext",
            "",
            "    @staticmethod",
            "    def _is_equal(b_a, b_b):",
            "        \"\"\"",
            "        Comparing 2 byte arrrays in constant time",
            "        to avoid timing attacks.",
            "",
            "        It would be nice if there was a library for this but",
            "        hey.",
            "        \"\"\"",
            "        if not (isinstance(b_a, binary_type) and isinstance(b_b, binary_type)):",
            "            raise TypeError('_is_equal can only be used to compare two byte strings')",
            "",
            "        # http://codahale.com/a-lesson-in-timing-attacks/",
            "        if len(b_a) != len(b_b):",
            "            return False",
            "",
            "        result = 0",
            "        for b_x, b_y in zip(b_a, b_b):",
            "            if PY3:",
            "                result |= b_x ^ b_y",
            "            else:",
            "                result |= ord(b_x) ^ ord(b_y)",
            "        return result == 0",
            "",
            "    @classmethod",
            "    def _decrypt_pycrypto(cls, b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv):",
            "        # EXIT EARLY IF DIGEST DOESN'T MATCH",
            "        hmac_decrypt = HMAC_pycrypto.new(b_key2, b_ciphertext, SHA256_pycrypto)",
            "        if not cls._is_equal(b_crypted_hmac, to_bytes(hmac_decrypt.hexdigest())):",
            "            return None",
            "",
            "        # SET THE COUNTER AND THE CIPHER",
            "        ctr = Counter_pycrypto.new(128, initial_value=int(b_iv, 16))",
            "        cipher = AES_pycrypto.new(b_key1, AES_pycrypto.MODE_CTR, counter=ctr)",
            "",
            "        # DECRYPT PADDED DATA",
            "        b_plaintext = cipher.decrypt(b_ciphertext)",
            "",
            "        # UNPAD DATA",
            "        if PY3:",
            "            padding_length = b_plaintext[-1]",
            "        else:",
            "            padding_length = ord(b_plaintext[-1])",
            "",
            "        b_plaintext = b_plaintext[:-padding_length]",
            "        return b_plaintext",
            "",
            "    @classmethod",
            "    def decrypt(cls, b_vaulttext, secret):",
            "",
            "        b_ciphertext, b_salt, b_crypted_hmac = parse_vaulttext(b_vaulttext)",
            "",
            "        # TODO: would be nice if a VaultSecret could be passed directly to _decrypt_*",
            "        #       (move _gen_key_initctr() to a AES256 VaultSecret or VaultContext impl?)",
            "        # though, likely needs to be python cryptography specific impl that basically",
            "        # creates a Cipher() with b_key1, a Mode.CTR() with b_iv, and a HMAC() with sign key b_key2",
            "        b_password = secret.bytes",
            "",
            "        b_key1, b_key2, b_iv = cls._gen_key_initctr(b_password, b_salt)",
            "",
            "        if HAS_CRYPTOGRAPHY:",
            "            b_plaintext = cls._decrypt_cryptography(b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv)",
            "        elif HAS_PYCRYPTO:",
            "            b_plaintext = cls._decrypt_pycrypto(b_ciphertext, b_crypted_hmac, b_key1, b_key2, b_iv)",
            "        else:",
            "            raise AnsibleError(NEED_CRYPTO_LIBRARY + '(Detected in decrypt)')",
            "",
            "        return b_plaintext",
            "",
            "",
            "# Keys could be made bytes later if the code that gets the data is more",
            "# naturally byte-oriented",
            "CIPHER_MAPPING = {",
            "    u'AES256': VaultAES256,",
            "}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "853": [
                "VaultEditor",
                "_edit_file_helper"
            ]
        },
        "addLocation": []
    }
}