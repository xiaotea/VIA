{
    "sydent/http/httpcommon.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " # limitations under the License."
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import logging"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+from io import BytesIO"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import twisted.internet.ssl"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+from twisted.internet import defer, protocol"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+from twisted.internet.protocol import connectionDone"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from twisted.web._newclient import ResponseDone"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from twisted.web.http import PotentialDataLoss"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+from twisted.web.iweb import UNKNOWN_LENGTH"
            },
            "11": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "13": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "             return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])"
            },
            "15": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "         else:"
            },
            "16": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "             return twisted.internet.ssl.OpenSSLDefaultPaths()"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+class BodyExceededMaxSize(Exception):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+    \"\"\"The maximum allowed size of the HTTP body was exceeded.\"\"\""
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+class _DiscardBodyWithMaxSizeProtocol(protocol.Protocol):"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+    \"\"\"A protocol which immediately errors upon receiving data.\"\"\""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+    def __init__(self, deferred):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+        self.deferred = deferred"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+    def _maybe_fail(self):"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+        \"\"\""
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+        Report a max size exceed error and disconnect the first time this is called."
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+        \"\"\""
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        if not self.deferred.called:"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+            self.deferred.errback(BodyExceededMaxSize())"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            # Close the connection (forcefully) since all the data will get"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            # discarded anyway."
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+            self.transport.abortConnection()"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+    def dataReceived(self, data) -> None:"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+        self._maybe_fail()"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+    def connectionLost(self, reason) -> None:"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+        self._maybe_fail()"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+class _ReadBodyWithMaxSizeProtocol(protocol.Protocol):"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+    \"\"\"A protocol which reads body to a stream, erroring if the body exceeds a maximum size.\"\"\""
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+    def __init__(self, deferred, max_size):"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+        self.stream = BytesIO()"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        self.deferred = deferred"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+        self.length = 0"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+        self.max_size = max_size"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+    def dataReceived(self, data) -> None:"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        # If the deferred was called, bail early."
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+        if self.deferred.called:"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+            return"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 115,
                "PatchRowcode": "+        self.stream.write(data)"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+        self.length += len(data)"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        # The first time the maximum size is exceeded, error and cancel the"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+        # connection. dataReceived might be called again if data was received"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+        # in the meantime."
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+        if self.max_size is not None and self.length >= self.max_size:"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+            self.deferred.errback(BodyExceededMaxSize())"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+            # Close the connection (forcefully) since all the data will get"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+            # discarded anyway."
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+            self.transport.abortConnection()"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+    def connectionLost(self, reason = connectionDone) -> None:"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+        # If the maximum size was already exceeded, there's nothing to do."
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+        if self.deferred.called:"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+            return"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+        if reason.check(ResponseDone):"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+            self.deferred.callback(self.stream.getvalue())"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+        elif reason.check(PotentialDataLoss):"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+            # stolen from https://github.com/twisted/treq/pull/49/files"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+            # http://twistedmatrix.com/trac/ticket/4840"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+            self.deferred.callback(self.stream.getvalue())"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+        else:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+            self.deferred.errback(reason)"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+def read_body_with_max_size(response, max_size):"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+    \"\"\""
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+    Read a HTTP response body to a file-object. Optionally enforcing a maximum file size."
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+    If the maximum file size is reached, the returned Deferred will resolve to a"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+    Failure with a BodyExceededMaxSize exception."
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+    Args:"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+        response: The HTTP response to read from."
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+        max_size: The maximum file size to allow."
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+"
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+    Returns:"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+        A Deferred which resolves to the read body."
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+    \"\"\""
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+    d = defer.Deferred()"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+    # If the Content-Length header gives a size larger than the maximum allowed"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+    # size, do not bother downloading the body."
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+    if max_size is not None and response.length != UNKNOWN_LENGTH:"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+        if response.length > max_size:"
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+            response.deliverBody(_DiscardBodyWithMaxSizeProtocol(d))"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 162,
                "PatchRowcode": "+            return d"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 164,
                "PatchRowcode": "+    response.deliverBody(_ReadBodyWithMaxSizeProtocol(d, max_size))"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+    return d"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "",
            "# Copyright 2014 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "",
            "import twisted.internet.ssl",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "class SslComponents:",
            "    def __init__(self, sydent):",
            "        self.sydent = sydent",
            "",
            "        self.myPrivateCertificate = self.makeMyCertificate()",
            "        self.trustRoot = self.makeTrustRoot()",
            "",
            "    def makeMyCertificate(self):",
            "        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')",
            "        if privKeyAndCertFilename == '':",
            "            logger.warn(\"No HTTPS private key / cert found: not starting replication server \"",
            "                        \"or doing replication pushes\")",
            "            return None",
            "",
            "        try:",
            "            fp = open(privKeyAndCertFilename)",
            "        except IOError:",
            "            logger.warn(\"Unable to read private key / cert file from %s: not starting the replication HTTPS server \"",
            "                        \"or doing replication pushes.\",",
            "                        privKeyAndCertFilename)",
            "            return None",
            "",
            "        authData = fp.read()",
            "        fp.close()",
            "        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)",
            "",
            "    def makeTrustRoot(self):",
            "        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not",
            "        # practical to get the client cert signed by a real root CA but should never be used on a production server.",
            "        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')",
            "        if len(caCertFilename) > 0:",
            "            try:",
            "                fp = open(caCertFilename)",
            "                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())",
            "                fp.close()",
            "            except:",
            "                logger.warn(\"Failed to open CA cert file %s\", caCertFilename)",
            "                raise",
            "            logger.warn(\"Using custom CA cert file: %s\", caCertFilename)",
            "            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])",
            "        else:",
            "            return twisted.internet.ssl.OpenSSLDefaultPaths()"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "",
            "# Copyright 2014 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "from io import BytesIO",
            "",
            "import twisted.internet.ssl",
            "from twisted.internet import defer, protocol",
            "from twisted.internet.protocol import connectionDone",
            "from twisted.web._newclient import ResponseDone",
            "from twisted.web.http import PotentialDataLoss",
            "from twisted.web.iweb import UNKNOWN_LENGTH",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "class SslComponents:",
            "    def __init__(self, sydent):",
            "        self.sydent = sydent",
            "",
            "        self.myPrivateCertificate = self.makeMyCertificate()",
            "        self.trustRoot = self.makeTrustRoot()",
            "",
            "    def makeMyCertificate(self):",
            "        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')",
            "        if privKeyAndCertFilename == '':",
            "            logger.warn(\"No HTTPS private key / cert found: not starting replication server \"",
            "                        \"or doing replication pushes\")",
            "            return None",
            "",
            "        try:",
            "            fp = open(privKeyAndCertFilename)",
            "        except IOError:",
            "            logger.warn(\"Unable to read private key / cert file from %s: not starting the replication HTTPS server \"",
            "                        \"or doing replication pushes.\",",
            "                        privKeyAndCertFilename)",
            "            return None",
            "",
            "        authData = fp.read()",
            "        fp.close()",
            "        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)",
            "",
            "    def makeTrustRoot(self):",
            "        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not",
            "        # practical to get the client cert signed by a real root CA but should never be used on a production server.",
            "        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')",
            "        if len(caCertFilename) > 0:",
            "            try:",
            "                fp = open(caCertFilename)",
            "                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())",
            "                fp.close()",
            "            except:",
            "                logger.warn(\"Failed to open CA cert file %s\", caCertFilename)",
            "                raise",
            "            logger.warn(\"Using custom CA cert file: %s\", caCertFilename)",
            "            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])",
            "        else:",
            "            return twisted.internet.ssl.OpenSSLDefaultPaths()",
            "",
            "",
            "",
            "class BodyExceededMaxSize(Exception):",
            "    \"\"\"The maximum allowed size of the HTTP body was exceeded.\"\"\"",
            "",
            "",
            "class _DiscardBodyWithMaxSizeProtocol(protocol.Protocol):",
            "    \"\"\"A protocol which immediately errors upon receiving data.\"\"\"",
            "",
            "    def __init__(self, deferred):",
            "        self.deferred = deferred",
            "",
            "    def _maybe_fail(self):",
            "        \"\"\"",
            "        Report a max size exceed error and disconnect the first time this is called.",
            "        \"\"\"",
            "        if not self.deferred.called:",
            "            self.deferred.errback(BodyExceededMaxSize())",
            "            # Close the connection (forcefully) since all the data will get",
            "            # discarded anyway.",
            "            self.transport.abortConnection()",
            "",
            "    def dataReceived(self, data) -> None:",
            "        self._maybe_fail()",
            "",
            "    def connectionLost(self, reason) -> None:",
            "        self._maybe_fail()",
            "",
            "",
            "class _ReadBodyWithMaxSizeProtocol(protocol.Protocol):",
            "    \"\"\"A protocol which reads body to a stream, erroring if the body exceeds a maximum size.\"\"\"",
            "",
            "    def __init__(self, deferred, max_size):",
            "        self.stream = BytesIO()",
            "        self.deferred = deferred",
            "        self.length = 0",
            "        self.max_size = max_size",
            "",
            "    def dataReceived(self, data) -> None:",
            "        # If the deferred was called, bail early.",
            "        if self.deferred.called:",
            "            return",
            "",
            "        self.stream.write(data)",
            "        self.length += len(data)",
            "        # The first time the maximum size is exceeded, error and cancel the",
            "        # connection. dataReceived might be called again if data was received",
            "        # in the meantime.",
            "        if self.max_size is not None and self.length >= self.max_size:",
            "            self.deferred.errback(BodyExceededMaxSize())",
            "            # Close the connection (forcefully) since all the data will get",
            "            # discarded anyway.",
            "            self.transport.abortConnection()",
            "",
            "    def connectionLost(self, reason = connectionDone) -> None:",
            "        # If the maximum size was already exceeded, there's nothing to do.",
            "        if self.deferred.called:",
            "            return",
            "",
            "        if reason.check(ResponseDone):",
            "            self.deferred.callback(self.stream.getvalue())",
            "        elif reason.check(PotentialDataLoss):",
            "            # stolen from https://github.com/twisted/treq/pull/49/files",
            "            # http://twistedmatrix.com/trac/ticket/4840",
            "            self.deferred.callback(self.stream.getvalue())",
            "        else:",
            "            self.deferred.errback(reason)",
            "",
            "",
            "def read_body_with_max_size(response, max_size):",
            "    \"\"\"",
            "    Read a HTTP response body to a file-object. Optionally enforcing a maximum file size.",
            "",
            "    If the maximum file size is reached, the returned Deferred will resolve to a",
            "    Failure with a BodyExceededMaxSize exception.",
            "",
            "    Args:",
            "        response: The HTTP response to read from.",
            "        max_size: The maximum file size to allow.",
            "",
            "    Returns:",
            "        A Deferred which resolves to the read body.",
            "    \"\"\"",
            "    d = defer.Deferred()",
            "",
            "    # If the Content-Length header gives a size larger than the maximum allowed",
            "    # size, do not bother downloading the body.",
            "    if max_size is not None and response.length != UNKNOWN_LENGTH:",
            "        if response.length > max_size:",
            "            response.deliverBody(_DiscardBodyWithMaxSizeProtocol(d))",
            "            return d",
            "",
            "    response.deliverBody(_ReadBodyWithMaxSizeProtocol(d, max_size))",
            "    return d"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "pypdf.generic._data_structures"
        ]
    },
    "sydent/http/matrixfederationagent.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from twisted.internet import defer"
            },
            "1": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS"
            },
            "2": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from twisted.internet.interfaces import IStreamClientEndpoint"
            },
            "3": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent, readBody"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+from twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent"
            },
            "5": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from twisted.web.http import stringToDatetime"
            },
            "6": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from twisted.web.http_headers import Headers"
            },
            "7": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from twisted.web.iweb import IAgent"
            },
            "8": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+from sydent.http.httpcommon import BodyExceededMaxSize, read_body_with_max_size"
            },
            "10": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " from sydent.http.srvresolver import SrvResolver, pick_server_from_list"
            },
            "11": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " from sydent.util.ttlcache import TTLCache"
            },
            "12": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " # cap for .well-known cache period"
            },
            "14": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " WELL_KNOWN_MAX_CACHE_PERIOD = 48 * 3600"
            },
            "15": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 49,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+# The maximum size (in bytes) to allow a well-known file to be."
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+WELL_KNOWN_MAX_SIZE = 50 * 1024  # 50 KiB"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 53,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "20": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " well_known_cache = TTLCache('well-known')"
            },
            "21": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 320,
                "PatchRowcode": "         logger.info(\"Fetching %s\", uri_str)"
            },
            "23": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": 321,
                "PatchRowcode": "         try:"
            },
            "24": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": 322,
                "PatchRowcode": "             response = yield self._well_known_agent.request(b\"GET\", uri)"
            },
            "25": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            body = yield readBody(response)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 323,
                "PatchRowcode": "+            body = yield read_body_with_max_size(response, WELL_KNOWN_MAX_SIZE)"
            },
            "27": {
                "beforePatchRowNumber": 320,
                "afterPatchRowNumber": 324,
                "PatchRowcode": "             if response.code != 200:"
            },
            "28": {
                "beforePatchRowNumber": 321,
                "afterPatchRowNumber": 325,
                "PatchRowcode": "                 raise Exception(\"Non-200 response %s\" % (response.code, ))"
            },
            "29": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 326,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "             cache_period = WELL_KNOWN_INVALID_CACHE_PERIOD"
            },
            "31": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 339,
                "PatchRowcode": "             cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)"
            },
            "32": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "             defer.returnValue((None, cache_period))"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+            return"
            },
            "34": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 342,
                "PatchRowcode": " "
            },
            "35": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "         result = parsed_body[\"m.server\"].encode(\"ascii\")"
            },
            "36": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 344,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2019 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "from __future__ import absolute_import",
            "",
            "import json",
            "import logging",
            "import random",
            "import time",
            "",
            "import attr",
            "from netaddr import IPAddress",
            "from zope.interface import implementer",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS",
            "from twisted.internet.interfaces import IStreamClientEndpoint",
            "from twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent, readBody",
            "from twisted.web.http import stringToDatetime",
            "from twisted.web.http_headers import Headers",
            "from twisted.web.iweb import IAgent",
            "",
            "from sydent.http.srvresolver import SrvResolver, pick_server_from_list",
            "from sydent.util.ttlcache import TTLCache",
            "",
            "# period to cache .well-known results for by default",
            "WELL_KNOWN_DEFAULT_CACHE_PERIOD = 24 * 3600",
            "",
            "# jitter to add to the .well-known default cache ttl",
            "WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER = 10 * 60",
            "",
            "# period to cache failure to fetch .well-known for",
            "WELL_KNOWN_INVALID_CACHE_PERIOD = 1 * 3600",
            "",
            "# cap for .well-known cache period",
            "WELL_KNOWN_MAX_CACHE_PERIOD = 48 * 3600",
            "",
            "logger = logging.getLogger(__name__)",
            "well_known_cache = TTLCache('well-known')",
            "",
            "@implementer(IAgent)",
            "class MatrixFederationAgent(object):",
            "    \"\"\"An Agent-like thing which provides a `request` method which will look up a matrix",
            "    server and send an HTTP request to it.",
            "    Doesn't implement any retries. (Those are done in MatrixFederationHttpClient.)",
            "",
            "    :param reactor: twisted reactor to use for underlying requests",
            "    :type reactor: IReactor",
            "",
            "    :param tls_client_options_factory: Factory to use for fetching client tls",
            "        options, or none to disable TLS.",
            "    :type tls_client_options_factory: ClientTLSOptionsFactory, None",
            "",
            "    :param _well_known_tls_policy: TLS policy to use for fetching .well-known",
            "        files. None to use a default (browser-like) implementation.",
            "    :type _well_known_tls_policy: IPolicyForHTTPS, None",
            "",
            "    :param _srv_resolver: SRVResolver impl to use for looking up SRV records.",
            "        None to use a default implementation.",
            "    :type _srv_resolver: SrvResolver, None",
            "",
            "    :param _well_known_cache: TTLCache impl for storing cached well-known",
            "        lookups. None to use a default implementation.",
            "    :type _well_known_cache: TTLCache, None",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self, reactor, tls_client_options_factory,",
            "        _well_known_tls_policy=None,",
            "        _srv_resolver=None,",
            "        _well_known_cache=well_known_cache,",
            "    ):",
            "        self._reactor = reactor",
            "",
            "        self._tls_client_options_factory = tls_client_options_factory",
            "        if _srv_resolver is None:",
            "            _srv_resolver = SrvResolver()",
            "        self._srv_resolver = _srv_resolver",
            "",
            "        self._pool = HTTPConnectionPool(reactor)",
            "        self._pool.retryAutomatically = False",
            "        self._pool.maxPersistentPerHost = 5",
            "        self._pool.cachedConnectionTimeout = 2 * 60",
            "",
            "        agent_args = {}",
            "        if _well_known_tls_policy is not None:",
            "            # the param is called 'contextFactory', but actually passing a",
            "            # contextfactory is deprecated, and it expects an IPolicyForHTTPS.",
            "            agent_args['contextFactory'] = _well_known_tls_policy",
            "        _well_known_agent = RedirectAgent(",
            "            Agent(self._reactor, pool=self._pool, **agent_args),",
            "        )",
            "        self._well_known_agent = _well_known_agent",
            "",
            "        # our cache of .well-known lookup results, mapping from server name",
            "        # to delegated name. The values can be:",
            "        #   `bytes`:     a valid server-name",
            "        #   `None`:      there is no (valid) .well-known here",
            "        self._well_known_cache = _well_known_cache",
            "",
            "    @defer.inlineCallbacks",
            "    def request(self, method, uri, headers=None, bodyProducer=None):",
            "        \"\"\"",
            "        :param method: HTTP method (GET/POST/etc).",
            "        :type method: bytes",
            "",
            "        :param uri: Absolute URI to be retrieved.",
            "        :type uri: bytes",
            "",
            "        :param headers: HTTP headers to send with the request, or None to",
            "            send no extra headers.",
            "        :type headers: twisted.web.http_headers.Headers, None",
            "",
            "        :param bodyProducer: An object which can generate bytes to make up the",
            "            body of this request (for example, the properly encoded contents of",
            "            a file for a file upload).  Or None if the request is to have",
            "            no body.",
            "        :type bodyProducer: twisted.web.iweb.IBodyProducer, None",
            "",
            "        :returns a deferred that fires when the header of the response has",
            "            been received (regardless of the response status code). Fails if",
            "            there is any problem which prevents that response from being received",
            "            (including problems that prevent the request from being sent).",
            "        :rtype: Deferred[twisted.web.iweb.IResponse]",
            "        \"\"\"",
            "        parsed_uri = URI.fromBytes(uri, defaultPort=-1)",
            "        res = yield self._route_matrix_uri(parsed_uri)",
            "",
            "        # set up the TLS connection params",
            "        #",
            "        # XXX disabling TLS is really only supported here for the benefit of the",
            "        # unit tests. We should make the UTs cope with TLS rather than having to make",
            "        # the code support the unit tests.",
            "        if self._tls_client_options_factory is None:",
            "            tls_options = None",
            "        else:",
            "            tls_options = self._tls_client_options_factory.get_options(",
            "                res.tls_server_name.decode(\"ascii\")",
            "            )",
            "",
            "        # make sure that the Host header is set correctly",
            "        if headers is None:",
            "            headers = Headers()",
            "        else:",
            "            headers = headers.copy()",
            "",
            "        if not headers.hasHeader(b'host'):",
            "            headers.addRawHeader(b'host', res.host_header)",
            "",
            "        class EndpointFactory(object):",
            "            @staticmethod",
            "            def endpointForURI(_uri):",
            "                ep = LoggingHostnameEndpoint(",
            "                    self._reactor, res.target_host, res.target_port,",
            "                )",
            "                if tls_options is not None:",
            "                    ep = wrapClientTLS(tls_options, ep)",
            "                return ep",
            "",
            "        agent = Agent.usingEndpointFactory(self._reactor, EndpointFactory(), self._pool)",
            "        res = yield agent.request(method, uri, headers, bodyProducer)",
            "        defer.returnValue(res)",
            "",
            "    @defer.inlineCallbacks",
            "    def _route_matrix_uri(self, parsed_uri, lookup_well_known=True):",
            "        \"\"\"Helper for `request`: determine the routing for a Matrix URI",
            "",
            "        :param parsed_uri: uri to route. Note that it should be parsed with",
            "            URI.fromBytes(uri, defaultPort=-1) to set the `port` to -1 if there",
            "            is no explicit port given.",
            "        :type parsed_uri: twisted.web.client.URI",
            "        :param lookup_well_known: True if we should look up the .well-known",
            "            file if there is no SRV record.",
            "        :type lookup_well_known: bool",
            "",
            "        :returns a routing result.",
            "        :rtype: Deferred[_RoutingResult]",
            "        \"\"\"",
            "        # check for an IP literal",
            "        try:",
            "            ip_address = IPAddress(parsed_uri.host.decode(\"ascii\"))",
            "        except Exception:",
            "            # not an IP address",
            "            ip_address = None",
            "",
            "        if ip_address:",
            "            port = parsed_uri.port",
            "            if port == -1:",
            "                port = 8448",
            "            defer.returnValue(_RoutingResult(",
            "                host_header=parsed_uri.netloc,",
            "                tls_server_name=parsed_uri.host,",
            "                target_host=parsed_uri.host,",
            "                target_port=port,",
            "            ))",
            "",
            "        if parsed_uri.port != -1:",
            "            # there is an explicit port",
            "            defer.returnValue(_RoutingResult(",
            "                host_header=parsed_uri.netloc,",
            "                tls_server_name=parsed_uri.host,",
            "                target_host=parsed_uri.host,",
            "                target_port=parsed_uri.port,",
            "            ))",
            "",
            "        if lookup_well_known:",
            "            # try a .well-known lookup",
            "            well_known_server = yield self._get_well_known(parsed_uri.host)",
            "",
            "            if well_known_server:",
            "                # if we found a .well-known, start again, but don't do another",
            "                # .well-known lookup.",
            "",
            "                # parse the server name in the .well-known response into host/port.",
            "                # (This code is lifted from twisted.web.client.URI.fromBytes).",
            "                if b':' in well_known_server:",
            "                    well_known_host, well_known_port = well_known_server.rsplit(b':', 1)",
            "                    try:",
            "                        well_known_port = int(well_known_port)",
            "                    except ValueError:",
            "                        # the part after the colon could not be parsed as an int",
            "                        # - we assume it is an IPv6 literal with no port (the closing",
            "                        # ']' stops it being parsed as an int)",
            "                        well_known_host, well_known_port = well_known_server, -1",
            "                else:",
            "                    well_known_host, well_known_port = well_known_server, -1",
            "",
            "                new_uri = URI(",
            "                    scheme=parsed_uri.scheme,",
            "                    netloc=well_known_server,",
            "                    host=well_known_host,",
            "                    port=well_known_port,",
            "                    path=parsed_uri.path,",
            "                    params=parsed_uri.params,",
            "                    query=parsed_uri.query,",
            "                    fragment=parsed_uri.fragment,",
            "                )",
            "",
            "                res = yield self._route_matrix_uri(new_uri, lookup_well_known=False)",
            "                defer.returnValue(res)",
            "",
            "        # try a SRV lookup",
            "        service_name = b\"_matrix._tcp.%s\" % (parsed_uri.host,)",
            "        server_list = yield self._srv_resolver.resolve_service(service_name)",
            "",
            "        if not server_list:",
            "            target_host = parsed_uri.host",
            "            port = 8448",
            "            logger.debug(",
            "                \"No SRV record for %s, using %s:%i\",",
            "                parsed_uri.host.decode(\"ascii\"), target_host.decode(\"ascii\"), port,",
            "            )",
            "        else:",
            "            target_host, port = pick_server_from_list(server_list)",
            "            logger.debug(",
            "                \"Picked %s:%i from SRV records for %s\",",
            "                target_host.decode(\"ascii\"), port, parsed_uri.host.decode(\"ascii\"),",
            "            )",
            "",
            "        defer.returnValue(_RoutingResult(",
            "            host_header=parsed_uri.netloc,",
            "            tls_server_name=parsed_uri.host,",
            "            target_host=target_host,",
            "            target_port=port,",
            "        ))",
            "",
            "    @defer.inlineCallbacks",
            "    def _get_well_known(self, server_name):",
            "        \"\"\"Attempt to fetch and parse a .well-known file for the given server",
            "",
            "        :param server_name: Name of the server, from the requested url.",
            "        :type server_name: bytes",
            "",
            "        :returns either the new server name, from the .well-known, or None if",
            "            there was no .well-known file.",
            "        :rtype: Deferred[bytes|None]",
            "        \"\"\"",
            "        try:",
            "            result = self._well_known_cache[server_name]",
            "        except KeyError:",
            "            # TODO: should we linearise so that we don't end up doing two .well-known",
            "            # requests for the same server in parallel?",
            "            result, cache_period = yield self._do_get_well_known(server_name)",
            "",
            "            if cache_period > 0:",
            "                self._well_known_cache.set(server_name, result, cache_period)",
            "",
            "        defer.returnValue(result)",
            "",
            "    @defer.inlineCallbacks",
            "    def _do_get_well_known(self, server_name):",
            "        \"\"\"Actually fetch and parse a .well-known, without checking the cache",
            "",
            "        :param server_name: Name of the server, from the requested url",
            "        :type server_name: bytes",
            "",
            "        :returns a tuple of (result, cache period), where result is one of:",
            "            - the new server name from the .well-known (as a `bytes`)",
            "            - None if there was no .well-known file.",
            "            - INVALID_WELL_KNOWN if the .well-known was invalid",
            "        :rtype: Deferred[Tuple[bytes|None|object],int]",
            "        \"\"\"",
            "        uri = b\"https://%s/.well-known/matrix/server\" % (server_name, )",
            "        uri_str = uri.decode(\"ascii\")",
            "        logger.info(\"Fetching %s\", uri_str)",
            "        try:",
            "            response = yield self._well_known_agent.request(b\"GET\", uri)",
            "            body = yield readBody(response)",
            "            if response.code != 200:",
            "                raise Exception(\"Non-200 response %s\" % (response.code, ))",
            "",
            "            parsed_body = json.loads(body.decode('utf-8'))",
            "            logger.info(\"Response from .well-known: %s\", parsed_body)",
            "            if not isinstance(parsed_body, dict):",
            "                raise Exception(\"not a dict\")",
            "            if \"m.server\" not in parsed_body:",
            "                raise Exception(\"Missing key 'm.server'\")",
            "        except Exception as e:",
            "            logger.info(\"Error fetching %s: %s\", uri_str, e)",
            "",
            "            # add some randomness to the TTL to avoid a stampeding herd every hour",
            "            # after startup",
            "            cache_period = WELL_KNOWN_INVALID_CACHE_PERIOD",
            "            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)",
            "            defer.returnValue((None, cache_period))",
            "",
            "        result = parsed_body[\"m.server\"].encode(\"ascii\")",
            "",
            "        cache_period = _cache_period_from_headers(",
            "            response.headers,",
            "            time_now=self._reactor.seconds,",
            "        )",
            "        if cache_period is None:",
            "            cache_period = WELL_KNOWN_DEFAULT_CACHE_PERIOD",
            "            # add some randomness to the TTL to avoid a stampeding herd every 24 hours",
            "            # after startup",
            "            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)",
            "        else:",
            "            cache_period = min(cache_period, WELL_KNOWN_MAX_CACHE_PERIOD)",
            "",
            "        defer.returnValue((result, cache_period))",
            "",
            "",
            "@implementer(IStreamClientEndpoint)",
            "class LoggingHostnameEndpoint(object):",
            "    \"\"\"A wrapper for HostnameEndpint which logs when it connects\"\"\"",
            "    def __init__(self, reactor, host, port, *args, **kwargs):",
            "        self.host = host",
            "        self.port = port",
            "        self.ep = HostnameEndpoint(reactor, host, port, *args, **kwargs)",
            "        logger.info(\"Endpoint created with %s:%d\", host, port)",
            "",
            "    def connect(self, protocol_factory):",
            "        logger.info(\"Connecting to %s:%i\", self.host.decode(\"ascii\"), self.port)",
            "        return self.ep.connect(protocol_factory)",
            "",
            "",
            "def _cache_period_from_headers(headers, time_now=time.time):",
            "    cache_controls = _parse_cache_control(headers)",
            "",
            "    if b'no-store' in cache_controls:",
            "        return 0",
            "",
            "    if b'max-age' in cache_controls:",
            "        try:",
            "            max_age = int(cache_controls[b'max-age'])",
            "            return max_age",
            "        except ValueError:",
            "            pass",
            "",
            "    expires = headers.getRawHeaders(b'expires')",
            "    if expires is not None:",
            "        try:",
            "            expires_date = stringToDatetime(expires[-1])",
            "            return expires_date - time_now()",
            "        except ValueError:",
            "            # RFC7234 says 'A cache recipient MUST interpret invalid date formats,",
            "            # especially the value \"0\", as representing a time in the past (i.e.,",
            "            # \"already expired\").",
            "            return 0",
            "",
            "    return None",
            "",
            "",
            "def _parse_cache_control(headers):",
            "    cache_controls = {}",
            "    for hdr in headers.getRawHeaders(b'cache-control', []):",
            "        for directive in hdr.split(b','):",
            "            splits = [x.strip() for x in directive.split(b'=', 1)]",
            "            k = splits[0].lower()",
            "            v = splits[1] if len(splits) > 1 else None",
            "            cache_controls[k] = v",
            "    return cache_controls",
            "",
            "",
            "@attr.s",
            "class _RoutingResult(object):",
            "    \"\"\"The result returned by `_route_matrix_uri`.",
            "    Contains the parameters needed to direct a federation connection to a particular",
            "    server.",
            "    Where a SRV record points to several servers, this object contains a single server",
            "    chosen from the list.",
            "    \"\"\"",
            "",
            "    host_header = attr.ib()",
            "    \"\"\"",
            "    The value we should assign to the Host header (host:port from the matrix",
            "    URI, or .well-known).",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    tls_server_name = attr.ib()",
            "    \"\"\"",
            "    The server name we should set in the SNI (typically host, without port, from the",
            "    matrix URI or .well-known)",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    target_host = attr.ib()",
            "    \"\"\"",
            "    The hostname (or IP literal) we should route the TCP connection to (the target of the",
            "    SRV record, or the hostname from the URL/.well-known)",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    target_port = attr.ib()",
            "    \"\"\"",
            "    The port we should route the TCP connection to (the target of the SRV record, or",
            "    the port from the URL/.well-known, or 8448)",
            "    :type: int",
            "    \"\"\""
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2019 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "from __future__ import absolute_import",
            "",
            "import json",
            "import logging",
            "import random",
            "import time",
            "",
            "import attr",
            "from netaddr import IPAddress",
            "from zope.interface import implementer",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS",
            "from twisted.internet.interfaces import IStreamClientEndpoint",
            "from twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent",
            "from twisted.web.http import stringToDatetime",
            "from twisted.web.http_headers import Headers",
            "from twisted.web.iweb import IAgent",
            "",
            "from sydent.http.httpcommon import BodyExceededMaxSize, read_body_with_max_size",
            "from sydent.http.srvresolver import SrvResolver, pick_server_from_list",
            "from sydent.util.ttlcache import TTLCache",
            "",
            "# period to cache .well-known results for by default",
            "WELL_KNOWN_DEFAULT_CACHE_PERIOD = 24 * 3600",
            "",
            "# jitter to add to the .well-known default cache ttl",
            "WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER = 10 * 60",
            "",
            "# period to cache failure to fetch .well-known for",
            "WELL_KNOWN_INVALID_CACHE_PERIOD = 1 * 3600",
            "",
            "# cap for .well-known cache period",
            "WELL_KNOWN_MAX_CACHE_PERIOD = 48 * 3600",
            "",
            "# The maximum size (in bytes) to allow a well-known file to be.",
            "WELL_KNOWN_MAX_SIZE = 50 * 1024  # 50 KiB",
            "",
            "logger = logging.getLogger(__name__)",
            "well_known_cache = TTLCache('well-known')",
            "",
            "@implementer(IAgent)",
            "class MatrixFederationAgent(object):",
            "    \"\"\"An Agent-like thing which provides a `request` method which will look up a matrix",
            "    server and send an HTTP request to it.",
            "    Doesn't implement any retries. (Those are done in MatrixFederationHttpClient.)",
            "",
            "    :param reactor: twisted reactor to use for underlying requests",
            "    :type reactor: IReactor",
            "",
            "    :param tls_client_options_factory: Factory to use for fetching client tls",
            "        options, or none to disable TLS.",
            "    :type tls_client_options_factory: ClientTLSOptionsFactory, None",
            "",
            "    :param _well_known_tls_policy: TLS policy to use for fetching .well-known",
            "        files. None to use a default (browser-like) implementation.",
            "    :type _well_known_tls_policy: IPolicyForHTTPS, None",
            "",
            "    :param _srv_resolver: SRVResolver impl to use for looking up SRV records.",
            "        None to use a default implementation.",
            "    :type _srv_resolver: SrvResolver, None",
            "",
            "    :param _well_known_cache: TTLCache impl for storing cached well-known",
            "        lookups. None to use a default implementation.",
            "    :type _well_known_cache: TTLCache, None",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self, reactor, tls_client_options_factory,",
            "        _well_known_tls_policy=None,",
            "        _srv_resolver=None,",
            "        _well_known_cache=well_known_cache,",
            "    ):",
            "        self._reactor = reactor",
            "",
            "        self._tls_client_options_factory = tls_client_options_factory",
            "        if _srv_resolver is None:",
            "            _srv_resolver = SrvResolver()",
            "        self._srv_resolver = _srv_resolver",
            "",
            "        self._pool = HTTPConnectionPool(reactor)",
            "        self._pool.retryAutomatically = False",
            "        self._pool.maxPersistentPerHost = 5",
            "        self._pool.cachedConnectionTimeout = 2 * 60",
            "",
            "        agent_args = {}",
            "        if _well_known_tls_policy is not None:",
            "            # the param is called 'contextFactory', but actually passing a",
            "            # contextfactory is deprecated, and it expects an IPolicyForHTTPS.",
            "            agent_args['contextFactory'] = _well_known_tls_policy",
            "        _well_known_agent = RedirectAgent(",
            "            Agent(self._reactor, pool=self._pool, **agent_args),",
            "        )",
            "        self._well_known_agent = _well_known_agent",
            "",
            "        # our cache of .well-known lookup results, mapping from server name",
            "        # to delegated name. The values can be:",
            "        #   `bytes`:     a valid server-name",
            "        #   `None`:      there is no (valid) .well-known here",
            "        self._well_known_cache = _well_known_cache",
            "",
            "    @defer.inlineCallbacks",
            "    def request(self, method, uri, headers=None, bodyProducer=None):",
            "        \"\"\"",
            "        :param method: HTTP method (GET/POST/etc).",
            "        :type method: bytes",
            "",
            "        :param uri: Absolute URI to be retrieved.",
            "        :type uri: bytes",
            "",
            "        :param headers: HTTP headers to send with the request, or None to",
            "            send no extra headers.",
            "        :type headers: twisted.web.http_headers.Headers, None",
            "",
            "        :param bodyProducer: An object which can generate bytes to make up the",
            "            body of this request (for example, the properly encoded contents of",
            "            a file for a file upload).  Or None if the request is to have",
            "            no body.",
            "        :type bodyProducer: twisted.web.iweb.IBodyProducer, None",
            "",
            "        :returns a deferred that fires when the header of the response has",
            "            been received (regardless of the response status code). Fails if",
            "            there is any problem which prevents that response from being received",
            "            (including problems that prevent the request from being sent).",
            "        :rtype: Deferred[twisted.web.iweb.IResponse]",
            "        \"\"\"",
            "        parsed_uri = URI.fromBytes(uri, defaultPort=-1)",
            "        res = yield self._route_matrix_uri(parsed_uri)",
            "",
            "        # set up the TLS connection params",
            "        #",
            "        # XXX disabling TLS is really only supported here for the benefit of the",
            "        # unit tests. We should make the UTs cope with TLS rather than having to make",
            "        # the code support the unit tests.",
            "        if self._tls_client_options_factory is None:",
            "            tls_options = None",
            "        else:",
            "            tls_options = self._tls_client_options_factory.get_options(",
            "                res.tls_server_name.decode(\"ascii\")",
            "            )",
            "",
            "        # make sure that the Host header is set correctly",
            "        if headers is None:",
            "            headers = Headers()",
            "        else:",
            "            headers = headers.copy()",
            "",
            "        if not headers.hasHeader(b'host'):",
            "            headers.addRawHeader(b'host', res.host_header)",
            "",
            "        class EndpointFactory(object):",
            "            @staticmethod",
            "            def endpointForURI(_uri):",
            "                ep = LoggingHostnameEndpoint(",
            "                    self._reactor, res.target_host, res.target_port,",
            "                )",
            "                if tls_options is not None:",
            "                    ep = wrapClientTLS(tls_options, ep)",
            "                return ep",
            "",
            "        agent = Agent.usingEndpointFactory(self._reactor, EndpointFactory(), self._pool)",
            "        res = yield agent.request(method, uri, headers, bodyProducer)",
            "        defer.returnValue(res)",
            "",
            "    @defer.inlineCallbacks",
            "    def _route_matrix_uri(self, parsed_uri, lookup_well_known=True):",
            "        \"\"\"Helper for `request`: determine the routing for a Matrix URI",
            "",
            "        :param parsed_uri: uri to route. Note that it should be parsed with",
            "            URI.fromBytes(uri, defaultPort=-1) to set the `port` to -1 if there",
            "            is no explicit port given.",
            "        :type parsed_uri: twisted.web.client.URI",
            "        :param lookup_well_known: True if we should look up the .well-known",
            "            file if there is no SRV record.",
            "        :type lookup_well_known: bool",
            "",
            "        :returns a routing result.",
            "        :rtype: Deferred[_RoutingResult]",
            "        \"\"\"",
            "        # check for an IP literal",
            "        try:",
            "            ip_address = IPAddress(parsed_uri.host.decode(\"ascii\"))",
            "        except Exception:",
            "            # not an IP address",
            "            ip_address = None",
            "",
            "        if ip_address:",
            "            port = parsed_uri.port",
            "            if port == -1:",
            "                port = 8448",
            "            defer.returnValue(_RoutingResult(",
            "                host_header=parsed_uri.netloc,",
            "                tls_server_name=parsed_uri.host,",
            "                target_host=parsed_uri.host,",
            "                target_port=port,",
            "            ))",
            "",
            "        if parsed_uri.port != -1:",
            "            # there is an explicit port",
            "            defer.returnValue(_RoutingResult(",
            "                host_header=parsed_uri.netloc,",
            "                tls_server_name=parsed_uri.host,",
            "                target_host=parsed_uri.host,",
            "                target_port=parsed_uri.port,",
            "            ))",
            "",
            "        if lookup_well_known:",
            "            # try a .well-known lookup",
            "            well_known_server = yield self._get_well_known(parsed_uri.host)",
            "",
            "            if well_known_server:",
            "                # if we found a .well-known, start again, but don't do another",
            "                # .well-known lookup.",
            "",
            "                # parse the server name in the .well-known response into host/port.",
            "                # (This code is lifted from twisted.web.client.URI.fromBytes).",
            "                if b':' in well_known_server:",
            "                    well_known_host, well_known_port = well_known_server.rsplit(b':', 1)",
            "                    try:",
            "                        well_known_port = int(well_known_port)",
            "                    except ValueError:",
            "                        # the part after the colon could not be parsed as an int",
            "                        # - we assume it is an IPv6 literal with no port (the closing",
            "                        # ']' stops it being parsed as an int)",
            "                        well_known_host, well_known_port = well_known_server, -1",
            "                else:",
            "                    well_known_host, well_known_port = well_known_server, -1",
            "",
            "                new_uri = URI(",
            "                    scheme=parsed_uri.scheme,",
            "                    netloc=well_known_server,",
            "                    host=well_known_host,",
            "                    port=well_known_port,",
            "                    path=parsed_uri.path,",
            "                    params=parsed_uri.params,",
            "                    query=parsed_uri.query,",
            "                    fragment=parsed_uri.fragment,",
            "                )",
            "",
            "                res = yield self._route_matrix_uri(new_uri, lookup_well_known=False)",
            "                defer.returnValue(res)",
            "",
            "        # try a SRV lookup",
            "        service_name = b\"_matrix._tcp.%s\" % (parsed_uri.host,)",
            "        server_list = yield self._srv_resolver.resolve_service(service_name)",
            "",
            "        if not server_list:",
            "            target_host = parsed_uri.host",
            "            port = 8448",
            "            logger.debug(",
            "                \"No SRV record for %s, using %s:%i\",",
            "                parsed_uri.host.decode(\"ascii\"), target_host.decode(\"ascii\"), port,",
            "            )",
            "        else:",
            "            target_host, port = pick_server_from_list(server_list)",
            "            logger.debug(",
            "                \"Picked %s:%i from SRV records for %s\",",
            "                target_host.decode(\"ascii\"), port, parsed_uri.host.decode(\"ascii\"),",
            "            )",
            "",
            "        defer.returnValue(_RoutingResult(",
            "            host_header=parsed_uri.netloc,",
            "            tls_server_name=parsed_uri.host,",
            "            target_host=target_host,",
            "            target_port=port,",
            "        ))",
            "",
            "    @defer.inlineCallbacks",
            "    def _get_well_known(self, server_name):",
            "        \"\"\"Attempt to fetch and parse a .well-known file for the given server",
            "",
            "        :param server_name: Name of the server, from the requested url.",
            "        :type server_name: bytes",
            "",
            "        :returns either the new server name, from the .well-known, or None if",
            "            there was no .well-known file.",
            "        :rtype: Deferred[bytes|None]",
            "        \"\"\"",
            "        try:",
            "            result = self._well_known_cache[server_name]",
            "        except KeyError:",
            "            # TODO: should we linearise so that we don't end up doing two .well-known",
            "            # requests for the same server in parallel?",
            "            result, cache_period = yield self._do_get_well_known(server_name)",
            "",
            "            if cache_period > 0:",
            "                self._well_known_cache.set(server_name, result, cache_period)",
            "",
            "        defer.returnValue(result)",
            "",
            "    @defer.inlineCallbacks",
            "    def _do_get_well_known(self, server_name):",
            "        \"\"\"Actually fetch and parse a .well-known, without checking the cache",
            "",
            "        :param server_name: Name of the server, from the requested url",
            "        :type server_name: bytes",
            "",
            "        :returns a tuple of (result, cache period), where result is one of:",
            "            - the new server name from the .well-known (as a `bytes`)",
            "            - None if there was no .well-known file.",
            "            - INVALID_WELL_KNOWN if the .well-known was invalid",
            "        :rtype: Deferred[Tuple[bytes|None|object],int]",
            "        \"\"\"",
            "        uri = b\"https://%s/.well-known/matrix/server\" % (server_name, )",
            "        uri_str = uri.decode(\"ascii\")",
            "        logger.info(\"Fetching %s\", uri_str)",
            "        try:",
            "            response = yield self._well_known_agent.request(b\"GET\", uri)",
            "            body = yield read_body_with_max_size(response, WELL_KNOWN_MAX_SIZE)",
            "            if response.code != 200:",
            "                raise Exception(\"Non-200 response %s\" % (response.code, ))",
            "",
            "            parsed_body = json.loads(body.decode('utf-8'))",
            "            logger.info(\"Response from .well-known: %s\", parsed_body)",
            "            if not isinstance(parsed_body, dict):",
            "                raise Exception(\"not a dict\")",
            "            if \"m.server\" not in parsed_body:",
            "                raise Exception(\"Missing key 'm.server'\")",
            "        except Exception as e:",
            "            logger.info(\"Error fetching %s: %s\", uri_str, e)",
            "",
            "            # add some randomness to the TTL to avoid a stampeding herd every hour",
            "            # after startup",
            "            cache_period = WELL_KNOWN_INVALID_CACHE_PERIOD",
            "            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)",
            "            defer.returnValue((None, cache_period))",
            "            return",
            "",
            "        result = parsed_body[\"m.server\"].encode(\"ascii\")",
            "",
            "        cache_period = _cache_period_from_headers(",
            "            response.headers,",
            "            time_now=self._reactor.seconds,",
            "        )",
            "        if cache_period is None:",
            "            cache_period = WELL_KNOWN_DEFAULT_CACHE_PERIOD",
            "            # add some randomness to the TTL to avoid a stampeding herd every 24 hours",
            "            # after startup",
            "            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)",
            "        else:",
            "            cache_period = min(cache_period, WELL_KNOWN_MAX_CACHE_PERIOD)",
            "",
            "        defer.returnValue((result, cache_period))",
            "",
            "",
            "@implementer(IStreamClientEndpoint)",
            "class LoggingHostnameEndpoint(object):",
            "    \"\"\"A wrapper for HostnameEndpint which logs when it connects\"\"\"",
            "    def __init__(self, reactor, host, port, *args, **kwargs):",
            "        self.host = host",
            "        self.port = port",
            "        self.ep = HostnameEndpoint(reactor, host, port, *args, **kwargs)",
            "        logger.info(\"Endpoint created with %s:%d\", host, port)",
            "",
            "    def connect(self, protocol_factory):",
            "        logger.info(\"Connecting to %s:%i\", self.host.decode(\"ascii\"), self.port)",
            "        return self.ep.connect(protocol_factory)",
            "",
            "",
            "def _cache_period_from_headers(headers, time_now=time.time):",
            "    cache_controls = _parse_cache_control(headers)",
            "",
            "    if b'no-store' in cache_controls:",
            "        return 0",
            "",
            "    if b'max-age' in cache_controls:",
            "        try:",
            "            max_age = int(cache_controls[b'max-age'])",
            "            return max_age",
            "        except ValueError:",
            "            pass",
            "",
            "    expires = headers.getRawHeaders(b'expires')",
            "    if expires is not None:",
            "        try:",
            "            expires_date = stringToDatetime(expires[-1])",
            "            return expires_date - time_now()",
            "        except ValueError:",
            "            # RFC7234 says 'A cache recipient MUST interpret invalid date formats,",
            "            # especially the value \"0\", as representing a time in the past (i.e.,",
            "            # \"already expired\").",
            "            return 0",
            "",
            "    return None",
            "",
            "",
            "def _parse_cache_control(headers):",
            "    cache_controls = {}",
            "    for hdr in headers.getRawHeaders(b'cache-control', []):",
            "        for directive in hdr.split(b','):",
            "            splits = [x.strip() for x in directive.split(b'=', 1)]",
            "            k = splits[0].lower()",
            "            v = splits[1] if len(splits) > 1 else None",
            "            cache_controls[k] = v",
            "    return cache_controls",
            "",
            "",
            "@attr.s",
            "class _RoutingResult(object):",
            "    \"\"\"The result returned by `_route_matrix_uri`.",
            "    Contains the parameters needed to direct a federation connection to a particular",
            "    server.",
            "    Where a SRV record points to several servers, this object contains a single server",
            "    chosen from the list.",
            "    \"\"\"",
            "",
            "    host_header = attr.ib()",
            "    \"\"\"",
            "    The value we should assign to the Host header (host:port from the matrix",
            "    URI, or .well-known).",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    tls_server_name = attr.ib()",
            "    \"\"\"",
            "    The server name we should set in the SNI (typically host, without port, from the",
            "    matrix URI or .well-known)",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    target_host = attr.ib()",
            "    \"\"\"",
            "    The hostname (or IP literal) we should route the TCP connection to (the target of the",
            "    SRV record, or the hostname from the URL/.well-known)",
            "    :type: bytes",
            "    \"\"\"",
            "",
            "    target_port = attr.ib()",
            "    \"\"\"",
            "    The port we should route the TCP connection to (the target of the SRV record, or",
            "    the port from the URL/.well-known, or 8448)",
            "    :type: int",
            "    \"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "29": [],
            "319": [
                "MatrixFederationAgent",
                "_do_get_well_known"
            ]
        },
        "addLocation": []
    }
}