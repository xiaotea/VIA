{
    "dparse/parser.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from configparser import ConfigParser, NoOptionError"
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from .regex import URL_REGEX, HASH_REGEX"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+from .regex import HASH_REGEX"
            },
            "5": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " from .dependencies import DependencyFile, Dependency"
            },
            "7": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from packaging.requirements import Requirement as PackagingRequirement, InvalidRequirement"
            },
            "8": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "         :param line:"
            },
            "9": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "         :return:"
            },
            "10": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "         \"\"\""
            },
            "11": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        matches = URL_REGEX.findall(line)"
            },
            "12": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if matches:"
            },
            "13": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            url = matches[0]"
            },
            "14": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return url if url.endswith(\"/\") else url + \"/\""
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 179,
                "PatchRowcode": "+        groups = re.split(pattern=\"[=\\s]+\", string=line.strip(), maxsplit=100)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+        if len(groups) >= 2:"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+            return groups[1] if groups[1].endswith(\"/\") else groups[1] + \"/\""
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         return None"
            },
            "21": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 185,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "     @classmethod"
            },
            "23": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 347,
                "PatchRowcode": "         except (toml.TomlDecodeError, IndexError) as e:"
            },
            "24": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 348,
                "PatchRowcode": "             pass"
            },
            "25": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 349,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 350,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 351,
                "PatchRowcode": " class PipfileLockParser(Parser):"
            },
            "28": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 352,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": 353,
                "PatchRowcode": "     def parse(self):"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "from __future__ import unicode_literals, absolute_import",
            "from collections import OrderedDict",
            "import re",
            "import yaml",
            "",
            "from io import StringIO",
            "",
            "from configparser import ConfigParser, NoOptionError",
            "",
            "",
            "from .regex import URL_REGEX, HASH_REGEX",
            "",
            "from .dependencies import DependencyFile, Dependency",
            "from packaging.requirements import Requirement as PackagingRequirement, InvalidRequirement",
            "from . import filetypes",
            "import toml",
            "from packaging.specifiers import SpecifierSet",
            "import json",
            "",
            "",
            "# this is a backport from setuptools 26.1",
            "def setuptools_parse_requirements_backport(strs):  # pragma: no cover",
            "    # Copyright (C) 2016 Jason R Coombs <jaraco@jaraco.com>",
            "    #",
            "    # Permission is hereby granted, free of charge, to any person obtaining a copy of",
            "    # this software and associated documentation files (the \"Software\"), to deal in",
            "    # the Software without restriction, including without limitation the rights to",
            "    # use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies",
            "    # of the Software, and to permit persons to whom the Software is furnished to do",
            "    # so, subject to the following conditions:",
            "    #",
            "    # The above copyright notice and this permission notice shall be included in all",
            "    # copies or substantial portions of the Software.",
            "    #",
            "    # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
            "    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
            "    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE",
            "    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
            "    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
            "    # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE",
            "    # SOFTWARE.",
            "    \"\"\"Yield ``Requirement`` objects for each specification in `strs`",
            "",
            "    `strs` must be a string, or a (possibly-nested) iterable thereof.",
            "    \"\"\"",
            "    # create a steppable iterator, so we can handle \\-continuations",
            "    def yield_lines(strs):",
            "        \"\"\"Yield non-empty/non-comment lines of a string or sequence\"\"\"",
            "        if isinstance(strs, str):",
            "            for s in strs.splitlines():",
            "                s = s.strip()",
            "                # skip blank lines/comments",
            "                if s and not s.startswith('#'):",
            "                    yield s",
            "        else:",
            "            for ss in strs:",
            "                for s in yield_lines(ss):",
            "                    yield s",
            "    lines = iter(yield_lines(strs))",
            "",
            "    for line in lines:",
            "        # Drop comments -- a hash without a space may be in a URL.",
            "        if ' #' in line:",
            "            line = line[:line.find(' #')]",
            "        # If there is a line continuation, drop it, and append the next line.",
            "        if line.endswith('\\\\'):",
            "            line = line[:-2].strip()",
            "            line += next(lines)",
            "        yield PackagingRequirement(line)",
            "",
            "",
            "class RequirementsTXTLineParser(object):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def parse(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            # setuptools requires a space before the comment. If this isn't the case, add it.",
            "            if \"\\t#\" in line:",
            "                parsed, = setuptools_parse_requirements_backport(line.replace(\"\\t#\", \"\\t #\"))",
            "            else:",
            "                parsed, = setuptools_parse_requirements_backport(line)",
            "        except InvalidRequirement:",
            "            return None",
            "        dep = Dependency(",
            "            name=parsed.name,",
            "            specs=parsed.specifier,",
            "            line=line,",
            "            extras=parsed.extras,",
            "            dependency_type=filetypes.requirements_txt",
            "        )",
            "        return dep",
            "",
            "",
            "class Parser(object):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, obj):",
            "        \"\"\"",
            "",
            "        :param obj:",
            "        \"\"\"",
            "        self.obj = obj",
            "        self._lines = None",
            "",
            "    def iter_lines(self, lineno=0):",
            "        \"\"\"",
            "",
            "        :param lineno:",
            "        :return:",
            "        \"\"\"",
            "        for line in self.lines[lineno:]:",
            "            yield line",
            "",
            "    @property",
            "    def lines(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        if self._lines is None:",
            "            self._lines = self.obj.content.splitlines()",
            "        return self._lines",
            "",
            "    @property",
            "    def is_marked_file(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        for n, line in enumerate(self.iter_lines()):",
            "            for marker in self.obj.file_marker:",
            "                if marker in line:",
            "                    return True",
            "            if n >= 2:",
            "                break",
            "        return False",
            "",
            "    def is_marked_line(self, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        for marker in self.obj.line_marker:",
            "            if marker in line:",
            "                return True",
            "        return False",
            "",
            "    @classmethod",
            "    def parse_hashes(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        hashes = []",
            "        for match in re.finditer(HASH_REGEX, line):",
            "            hashes.append(line[match.start():match.end()])",
            "        return re.sub(HASH_REGEX, \"\", line).strip(), hashes",
            "",
            "    @classmethod",
            "    def parse_index_server(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        matches = URL_REGEX.findall(line)",
            "        if matches:",
            "            url = matches[0]",
            "            return url if url.endswith(\"/\") else url + \"/\"",
            "        return None",
            "",
            "    @classmethod",
            "    def resolve_file(cls, file_path, line):",
            "        \"\"\"",
            "",
            "        :param file_path:",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        line = line.replace(\"-r \", \"\").replace(\"--requirement \", \"\")",
            "        parts = file_path.split(\"/\")",
            "        if \" #\" in line:",
            "            line = line.split(\"#\")[0].strip()",
            "        if len(parts) == 1:",
            "            return line",
            "        return \"/\".join(parts[:-1]) + \"/\" + line",
            "",
            "",
            "class RequirementsTXTParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parses a requirements.txt-like file",
            "        \"\"\"",
            "        index_server = None",
            "        for num, line in enumerate(self.iter_lines()):",
            "            line = line.rstrip()",
            "            if not line:",
            "                continue",
            "            if line.startswith('#'):",
            "                # comments are lines that start with # only",
            "                continue",
            "            if line.startswith('-i') or \\",
            "                line.startswith('--index-url') or \\",
            "                line.startswith('--extra-index-url'):",
            "                # this file is using a private index server, try to parse it",
            "                index_server = self.parse_index_server(line)",
            "                continue",
            "            elif self.obj.path and (line.startswith('-r') or line.startswith('--requirement')):",
            "                self.obj.resolved_files.append(self.resolve_file(self.obj.path, line))",
            "            elif line.startswith('-f') or line.startswith('--find-links') or \\",
            "                line.startswith('--no-index') or line.startswith('--allow-external') or \\",
            "                line.startswith('--allow-unverified') or line.startswith('-Z') or \\",
            "                line.startswith('--always-unzip'):",
            "                continue",
            "            elif self.is_marked_line(line):",
            "                continue",
            "            else:",
            "                try:",
            "",
            "                    parseable_line = line",
            "",
            "                    # multiline requirements are not parseable",
            "                    if \"\\\\\" in line:",
            "                        parseable_line = line.replace(\"\\\\\", \"\")",
            "                        for next_line in self.iter_lines(num + 1):",
            "                            parseable_line += next_line.strip().replace(\"\\\\\", \"\")",
            "                            line += \"\\n\" + next_line",
            "                            if \"\\\\\" in next_line:",
            "                                continue",
            "                            break",
            "                        # ignore multiline requirements if they are marked",
            "                        if self.is_marked_line(parseable_line):",
            "                            continue",
            "",
            "                    hashes = []",
            "                    if \"--hash\" in parseable_line:",
            "                        parseable_line, hashes = Parser.parse_hashes(parseable_line)",
            "",
            "                    req = RequirementsTXTLineParser.parse(parseable_line)",
            "                    if req:",
            "                        req.hashes = hashes",
            "                        req.index_server = index_server",
            "                        # replace the requirements line with the 'real' line",
            "                        req.line = line",
            "                        self.obj.dependencies.append(req)",
            "                except ValueError:",
            "                    continue",
            "",
            "",
            "class ToxINIParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        parser = ConfigParser()",
            "        parser.readfp(StringIO(self.obj.content))",
            "        for section in parser.sections():",
            "            try:",
            "                content = parser.get(section=section, option=\"deps\")",
            "                for n, line in enumerate(content.splitlines()):",
            "                    if self.is_marked_line(line):",
            "                        continue",
            "                    if line:",
            "                        req = RequirementsTXTLineParser.parse(line)",
            "                        if req:",
            "                            req.dependency_type = self.obj.file_type",
            "                            self.obj.dependencies.append(req)",
            "            except NoOptionError:",
            "                pass",
            "",
            "",
            "class CondaYMLParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = yaml.safe_load(self.obj.content)",
            "            if data and 'dependencies' in data and isinstance(data['dependencies'], list):",
            "                for dep in data['dependencies']:",
            "                    if isinstance(dep, dict) and 'pip' in dep:",
            "                        for n, line in enumerate(dep['pip']):",
            "                            if self.is_marked_line(line):",
            "                                continue",
            "                            req = RequirementsTXTLineParser.parse(line)",
            "                            if req:",
            "                                req.dependency_type = self.obj.file_type",
            "                                self.obj.dependencies.append(req)",
            "        except yaml.YAMLError:",
            "            pass",
            "",
            "",
            "class PipfileParser(Parser):",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parse a Pipfile (as seen in pipenv)",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = toml.loads(self.obj.content, _dict=OrderedDict)",
            "            if data:",
            "                for package_type in ['packages', 'dev-packages']:",
            "                    if package_type in data:",
            "                        for name, specs in data[package_type].items():",
            "                            # skip on VCS dependencies",
            "                            if not isinstance(specs, str):",
            "                                continue",
            "                            if specs == '*':",
            "                                specs = ''",
            "                            self.obj.dependencies.append(",
            "                                Dependency(",
            "                                    name=name, specs=SpecifierSet(specs),",
            "                                    dependency_type=filetypes.pipfile,",
            "                                    line=''.join([name, specs]),",
            "                                    section=package_type",
            "                                )",
            "                            )",
            "        except (toml.TomlDecodeError, IndexError) as e:",
            "            pass",
            "",
            "class PipfileLockParser(Parser):",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parse a Pipfile.lock (as seen in pipenv)",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = json.loads(self.obj.content, object_pairs_hook=OrderedDict)",
            "            if data:",
            "                for package_type in ['default', 'develop']:",
            "                    if package_type in data:",
            "                        for name, meta in data[package_type].items():",
            "                            # skip VCS dependencies",
            "                            if 'version' not in meta:",
            "                                continue",
            "                            specs = meta['version']",
            "                            hashes = meta['hashes']",
            "                            self.obj.dependencies.append(",
            "                                Dependency(",
            "                                    name=name, specs=SpecifierSet(specs),",
            "                                    dependency_type=filetypes.pipfile_lock,",
            "                                    hashes=hashes,",
            "                                    line=''.join([name, specs]),",
            "                                    section=package_type",
            "                                )",
            "                            )",
            "        except ValueError:",
            "            pass",
            "",
            "",
            "class SetupCfgParser(Parser):",
            "    def parse(self):",
            "        parser = ConfigParser()",
            "        parser.readfp(StringIO(self.obj.content))",
            "        for section in parser.values():",
            "            if section.name == 'options':",
            "                options = 'install_requires', 'setup_requires', 'test_require'",
            "                for name in options:",
            "                    content = section.get(name)",
            "                    if not content:",
            "                        continue",
            "                    self._parse_content(content)",
            "            elif section.name == 'options.extras_require':",
            "                for content in section.values():",
            "                    self._parse_content(content)",
            "",
            "    def _parse_content(self, content):",
            "        for n, line in enumerate(content.splitlines()):",
            "            if self.is_marked_line(line):",
            "                continue",
            "            if line:",
            "                req = RequirementsTXTLineParser.parse(line)",
            "                if req:",
            "                    req.dependency_type = self.obj.file_type",
            "                    self.obj.dependencies.append(req)",
            "",
            "",
            "def parse(content, file_type=None, path=None, sha=None, marker=((), ()), parser=None):",
            "    \"\"\"",
            "",
            "    :param content:",
            "    :param file_type:",
            "    :param path:",
            "    :param sha:",
            "    :param marker:",
            "    :param parser:",
            "    :return:",
            "    \"\"\"",
            "    dep_file = DependencyFile(",
            "        content=content,",
            "        path=path,",
            "        sha=sha,",
            "        marker=marker,",
            "        file_type=file_type,",
            "        parser=parser",
            "    )",
            "",
            "    return dep_file.parse()"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "from __future__ import unicode_literals, absolute_import",
            "from collections import OrderedDict",
            "import re",
            "import yaml",
            "",
            "from io import StringIO",
            "",
            "from configparser import ConfigParser, NoOptionError",
            "",
            "",
            "from .regex import HASH_REGEX",
            "",
            "from .dependencies import DependencyFile, Dependency",
            "from packaging.requirements import Requirement as PackagingRequirement, InvalidRequirement",
            "from . import filetypes",
            "import toml",
            "from packaging.specifiers import SpecifierSet",
            "import json",
            "",
            "",
            "# this is a backport from setuptools 26.1",
            "def setuptools_parse_requirements_backport(strs):  # pragma: no cover",
            "    # Copyright (C) 2016 Jason R Coombs <jaraco@jaraco.com>",
            "    #",
            "    # Permission is hereby granted, free of charge, to any person obtaining a copy of",
            "    # this software and associated documentation files (the \"Software\"), to deal in",
            "    # the Software without restriction, including without limitation the rights to",
            "    # use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies",
            "    # of the Software, and to permit persons to whom the Software is furnished to do",
            "    # so, subject to the following conditions:",
            "    #",
            "    # The above copyright notice and this permission notice shall be included in all",
            "    # copies or substantial portions of the Software.",
            "    #",
            "    # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
            "    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
            "    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE",
            "    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
            "    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
            "    # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE",
            "    # SOFTWARE.",
            "    \"\"\"Yield ``Requirement`` objects for each specification in `strs`",
            "",
            "    `strs` must be a string, or a (possibly-nested) iterable thereof.",
            "    \"\"\"",
            "    # create a steppable iterator, so we can handle \\-continuations",
            "    def yield_lines(strs):",
            "        \"\"\"Yield non-empty/non-comment lines of a string or sequence\"\"\"",
            "        if isinstance(strs, str):",
            "            for s in strs.splitlines():",
            "                s = s.strip()",
            "                # skip blank lines/comments",
            "                if s and not s.startswith('#'):",
            "                    yield s",
            "        else:",
            "            for ss in strs:",
            "                for s in yield_lines(ss):",
            "                    yield s",
            "    lines = iter(yield_lines(strs))",
            "",
            "    for line in lines:",
            "        # Drop comments -- a hash without a space may be in a URL.",
            "        if ' #' in line:",
            "            line = line[:line.find(' #')]",
            "        # If there is a line continuation, drop it, and append the next line.",
            "        if line.endswith('\\\\'):",
            "            line = line[:-2].strip()",
            "            line += next(lines)",
            "        yield PackagingRequirement(line)",
            "",
            "",
            "class RequirementsTXTLineParser(object):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def parse(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            # setuptools requires a space before the comment. If this isn't the case, add it.",
            "            if \"\\t#\" in line:",
            "                parsed, = setuptools_parse_requirements_backport(line.replace(\"\\t#\", \"\\t #\"))",
            "            else:",
            "                parsed, = setuptools_parse_requirements_backport(line)",
            "        except InvalidRequirement:",
            "            return None",
            "        dep = Dependency(",
            "            name=parsed.name,",
            "            specs=parsed.specifier,",
            "            line=line,",
            "            extras=parsed.extras,",
            "            dependency_type=filetypes.requirements_txt",
            "        )",
            "        return dep",
            "",
            "",
            "class Parser(object):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, obj):",
            "        \"\"\"",
            "",
            "        :param obj:",
            "        \"\"\"",
            "        self.obj = obj",
            "        self._lines = None",
            "",
            "    def iter_lines(self, lineno=0):",
            "        \"\"\"",
            "",
            "        :param lineno:",
            "        :return:",
            "        \"\"\"",
            "        for line in self.lines[lineno:]:",
            "            yield line",
            "",
            "    @property",
            "    def lines(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        if self._lines is None:",
            "            self._lines = self.obj.content.splitlines()",
            "        return self._lines",
            "",
            "    @property",
            "    def is_marked_file(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        for n, line in enumerate(self.iter_lines()):",
            "            for marker in self.obj.file_marker:",
            "                if marker in line:",
            "                    return True",
            "            if n >= 2:",
            "                break",
            "        return False",
            "",
            "    def is_marked_line(self, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        for marker in self.obj.line_marker:",
            "            if marker in line:",
            "                return True",
            "        return False",
            "",
            "    @classmethod",
            "    def parse_hashes(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        hashes = []",
            "        for match in re.finditer(HASH_REGEX, line):",
            "            hashes.append(line[match.start():match.end()])",
            "        return re.sub(HASH_REGEX, \"\", line).strip(), hashes",
            "",
            "    @classmethod",
            "    def parse_index_server(cls, line):",
            "        \"\"\"",
            "",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        groups = re.split(pattern=\"[=\\s]+\", string=line.strip(), maxsplit=100)",
            "",
            "        if len(groups) >= 2:",
            "            return groups[1] if groups[1].endswith(\"/\") else groups[1] + \"/\"",
            "",
            "        return None",
            "",
            "    @classmethod",
            "    def resolve_file(cls, file_path, line):",
            "        \"\"\"",
            "",
            "        :param file_path:",
            "        :param line:",
            "        :return:",
            "        \"\"\"",
            "        line = line.replace(\"-r \", \"\").replace(\"--requirement \", \"\")",
            "        parts = file_path.split(\"/\")",
            "        if \" #\" in line:",
            "            line = line.split(\"#\")[0].strip()",
            "        if len(parts) == 1:",
            "            return line",
            "        return \"/\".join(parts[:-1]) + \"/\" + line",
            "",
            "",
            "class RequirementsTXTParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parses a requirements.txt-like file",
            "        \"\"\"",
            "        index_server = None",
            "        for num, line in enumerate(self.iter_lines()):",
            "            line = line.rstrip()",
            "            if not line:",
            "                continue",
            "            if line.startswith('#'):",
            "                # comments are lines that start with # only",
            "                continue",
            "            if line.startswith('-i') or \\",
            "                line.startswith('--index-url') or \\",
            "                line.startswith('--extra-index-url'):",
            "                # this file is using a private index server, try to parse it",
            "                index_server = self.parse_index_server(line)",
            "                continue",
            "            elif self.obj.path and (line.startswith('-r') or line.startswith('--requirement')):",
            "                self.obj.resolved_files.append(self.resolve_file(self.obj.path, line))",
            "            elif line.startswith('-f') or line.startswith('--find-links') or \\",
            "                line.startswith('--no-index') or line.startswith('--allow-external') or \\",
            "                line.startswith('--allow-unverified') or line.startswith('-Z') or \\",
            "                line.startswith('--always-unzip'):",
            "                continue",
            "            elif self.is_marked_line(line):",
            "                continue",
            "            else:",
            "                try:",
            "",
            "                    parseable_line = line",
            "",
            "                    # multiline requirements are not parseable",
            "                    if \"\\\\\" in line:",
            "                        parseable_line = line.replace(\"\\\\\", \"\")",
            "                        for next_line in self.iter_lines(num + 1):",
            "                            parseable_line += next_line.strip().replace(\"\\\\\", \"\")",
            "                            line += \"\\n\" + next_line",
            "                            if \"\\\\\" in next_line:",
            "                                continue",
            "                            break",
            "                        # ignore multiline requirements if they are marked",
            "                        if self.is_marked_line(parseable_line):",
            "                            continue",
            "",
            "                    hashes = []",
            "                    if \"--hash\" in parseable_line:",
            "                        parseable_line, hashes = Parser.parse_hashes(parseable_line)",
            "",
            "                    req = RequirementsTXTLineParser.parse(parseable_line)",
            "                    if req:",
            "                        req.hashes = hashes",
            "                        req.index_server = index_server",
            "                        # replace the requirements line with the 'real' line",
            "                        req.line = line",
            "                        self.obj.dependencies.append(req)",
            "                except ValueError:",
            "                    continue",
            "",
            "",
            "class ToxINIParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        parser = ConfigParser()",
            "        parser.readfp(StringIO(self.obj.content))",
            "        for section in parser.sections():",
            "            try:",
            "                content = parser.get(section=section, option=\"deps\")",
            "                for n, line in enumerate(content.splitlines()):",
            "                    if self.is_marked_line(line):",
            "                        continue",
            "                    if line:",
            "                        req = RequirementsTXTLineParser.parse(line)",
            "                        if req:",
            "                            req.dependency_type = self.obj.file_type",
            "                            self.obj.dependencies.append(req)",
            "            except NoOptionError:",
            "                pass",
            "",
            "",
            "class CondaYMLParser(Parser):",
            "    \"\"\"",
            "",
            "    \"\"\"",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = yaml.safe_load(self.obj.content)",
            "            if data and 'dependencies' in data and isinstance(data['dependencies'], list):",
            "                for dep in data['dependencies']:",
            "                    if isinstance(dep, dict) and 'pip' in dep:",
            "                        for n, line in enumerate(dep['pip']):",
            "                            if self.is_marked_line(line):",
            "                                continue",
            "                            req = RequirementsTXTLineParser.parse(line)",
            "                            if req:",
            "                                req.dependency_type = self.obj.file_type",
            "                                self.obj.dependencies.append(req)",
            "        except yaml.YAMLError:",
            "            pass",
            "",
            "",
            "class PipfileParser(Parser):",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parse a Pipfile (as seen in pipenv)",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = toml.loads(self.obj.content, _dict=OrderedDict)",
            "            if data:",
            "                for package_type in ['packages', 'dev-packages']:",
            "                    if package_type in data:",
            "                        for name, specs in data[package_type].items():",
            "                            # skip on VCS dependencies",
            "                            if not isinstance(specs, str):",
            "                                continue",
            "                            if specs == '*':",
            "                                specs = ''",
            "                            self.obj.dependencies.append(",
            "                                Dependency(",
            "                                    name=name, specs=SpecifierSet(specs),",
            "                                    dependency_type=filetypes.pipfile,",
            "                                    line=''.join([name, specs]),",
            "                                    section=package_type",
            "                                )",
            "                            )",
            "        except (toml.TomlDecodeError, IndexError) as e:",
            "            pass",
            "",
            "",
            "class PipfileLockParser(Parser):",
            "",
            "    def parse(self):",
            "        \"\"\"",
            "        Parse a Pipfile.lock (as seen in pipenv)",
            "        :return:",
            "        \"\"\"",
            "        try:",
            "            data = json.loads(self.obj.content, object_pairs_hook=OrderedDict)",
            "            if data:",
            "                for package_type in ['default', 'develop']:",
            "                    if package_type in data:",
            "                        for name, meta in data[package_type].items():",
            "                            # skip VCS dependencies",
            "                            if 'version' not in meta:",
            "                                continue",
            "                            specs = meta['version']",
            "                            hashes = meta['hashes']",
            "                            self.obj.dependencies.append(",
            "                                Dependency(",
            "                                    name=name, specs=SpecifierSet(specs),",
            "                                    dependency_type=filetypes.pipfile_lock,",
            "                                    hashes=hashes,",
            "                                    line=''.join([name, specs]),",
            "                                    section=package_type",
            "                                )",
            "                            )",
            "        except ValueError:",
            "            pass",
            "",
            "",
            "class SetupCfgParser(Parser):",
            "    def parse(self):",
            "        parser = ConfigParser()",
            "        parser.readfp(StringIO(self.obj.content))",
            "        for section in parser.values():",
            "            if section.name == 'options':",
            "                options = 'install_requires', 'setup_requires', 'test_require'",
            "                for name in options:",
            "                    content = section.get(name)",
            "                    if not content:",
            "                        continue",
            "                    self._parse_content(content)",
            "            elif section.name == 'options.extras_require':",
            "                for content in section.values():",
            "                    self._parse_content(content)",
            "",
            "    def _parse_content(self, content):",
            "        for n, line in enumerate(content.splitlines()):",
            "            if self.is_marked_line(line):",
            "                continue",
            "            if line:",
            "                req = RequirementsTXTLineParser.parse(line)",
            "                if req:",
            "                    req.dependency_type = self.obj.file_type",
            "                    self.obj.dependencies.append(req)",
            "",
            "",
            "def parse(content, file_type=None, path=None, sha=None, marker=((), ()), parser=None):",
            "    \"\"\"",
            "",
            "    :param content:",
            "    :param file_type:",
            "    :param path:",
            "    :param sha:",
            "    :param marker:",
            "    :param parser:",
            "    :return:",
            "    \"\"\"",
            "    dep_file = DependencyFile(",
            "        content=content,",
            "        path=path,",
            "        sha=sha,",
            "        marker=marker,",
            "        file_type=file_type,",
            "        parser=parser",
            "    )",
            "",
            "    return dep_file.parse()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "12": [],
            "179": [
                "Parser",
                "parse_index_server"
            ],
            "180": [
                "Parser",
                "parse_index_server"
            ],
            "181": [
                "Parser",
                "parse_index_server"
            ],
            "182": [
                "Parser",
                "parse_index_server"
            ]
        },
        "addLocation": []
    },
    "dparse/regex.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " # -*- coding: utf-8 -*-"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " from __future__ import absolute_import, print_function, unicode_literals"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import re"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# see https://gist.github.com/dperini/729294"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-URL_REGEX = re.compile("
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # protocol identifier"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:(?:https?|ftp)://)\""
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # user:pass authentication"
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\\S+(?::\\S*)?@)?\""
            },
            "10": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\""
            },
            "11": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # IP address exclusion"
            },
            "12": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # private & local networks"
            },
            "13": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?!(?:10|127)(?:\\.\\d{1,3}){3})\""
            },
            "14": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})\""
            },
            "15": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})\""
            },
            "16": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # IP address dotted notation octets"
            },
            "17": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # excludes loopback network 0.0.0.0"
            },
            "18": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # excludes reserved space >= 224.0.0.0"
            },
            "19": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # excludes network & broadcast addresses"
            },
            "20": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # (first & last IP address of each class)"
            },
            "21": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])\""
            },
            "22": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}\""
            },
            "23": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))\""
            },
            "24": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"|\""
            },
            "25": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # host name"
            },
            "26": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)\""
            },
            "27": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # domain name"
            },
            "28": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)*\""
            },
            "29": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # TLD identifier"
            },
            "30": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))\""
            },
            "31": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \")\""
            },
            "32": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # port number"
            },
            "33": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?::\\d{2,5})?\""
            },
            "34": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # resource path"
            },
            "35": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"(?:/\\S*)?\","
            },
            "36": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    re.UNICODE)"
            },
            "37": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "38": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-HASH_REGEX = r\"--hash[=| ][\\w]+:[\\w]+\""
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 4,
                "PatchRowcode": "+HASH_REGEX = r\"--hash[=| ]\\w+:\\w+\""
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "from __future__ import absolute_import, print_function, unicode_literals",
            "",
            "import re",
            "# see https://gist.github.com/dperini/729294",
            "URL_REGEX = re.compile(",
            "    # protocol identifier",
            "    \"(?:(?:https?|ftp)://)\"",
            "    # user:pass authentication",
            "    \"(?:\\S+(?::\\S*)?@)?\"",
            "    \"(?:\"",
            "    # IP address exclusion",
            "    # private & local networks",
            "    \"(?!(?:10|127)(?:\\.\\d{1,3}){3})\"",
            "    \"(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})\"",
            "    \"(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})\"",
            "    # IP address dotted notation octets",
            "    # excludes loopback network 0.0.0.0",
            "    # excludes reserved space >= 224.0.0.0",
            "    # excludes network & broadcast addresses",
            "    # (first & last IP address of each class)",
            "    \"(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])\"",
            "    \"(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}\"",
            "    \"(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))\"",
            "    \"|\"",
            "    # host name",
            "    \"(?:(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)\"",
            "    # domain name",
            "    \"(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)*\"",
            "    # TLD identifier",
            "    \"(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))\"",
            "    \")\"",
            "    # port number",
            "    \"(?::\\d{2,5})?\"",
            "    # resource path",
            "    \"(?:/\\S*)?\",",
            "    re.UNICODE)",
            "",
            "HASH_REGEX = r\"--hash[=| ][\\w]+:[\\w]+\""
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "from __future__ import absolute_import, print_function, unicode_literals",
            "",
            "HASH_REGEX = r\"--hash[=| ]\\w+:\\w+\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "4": [],
            "5": [],
            "6": [
                "URL_REGEX"
            ],
            "7": [],
            "8": [],
            "9": [],
            "10": [],
            "11": [],
            "12": [],
            "13": [],
            "14": [],
            "15": [],
            "16": [],
            "17": [],
            "18": [],
            "19": [],
            "20": [],
            "21": [],
            "22": [],
            "23": [],
            "24": [],
            "25": [],
            "26": [],
            "27": [],
            "28": [],
            "29": [],
            "30": [],
            "31": [],
            "32": [],
            "33": [],
            "34": [],
            "35": [],
            "36": [],
            "37": [],
            "38": [],
            "39": [
                "HASH_REGEX"
            ]
        },
        "addLocation": []
    }
}