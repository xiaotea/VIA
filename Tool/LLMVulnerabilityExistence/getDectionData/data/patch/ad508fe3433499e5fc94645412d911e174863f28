{
    "django_celery_results/backends/database.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "                 return True"
            },
            "1": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "         return False"
            },
            "2": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+    def _get_extended_properties(self, request, traceback):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+        extended_props = {"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+            'periodic_task_name': None,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+            'task_args': None,"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+            'task_kwargs': None,"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+            'task_name': None,"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+            'traceback': None,"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+            'worker': None,"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+        }"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+        if request and self.app.conf.find_value_for_key('extended', 'result'):"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+            if getattr(request, 'argsrepr', None) is not None:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+                # task protocol 2"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+                task_args = request.argsrepr"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+            else:"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+                # task protocol 1"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+                task_args = getattr(request, 'args', None)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+            if getattr(request, 'kwargsrepr', None) is not None:"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+                # task protocol 2"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+                task_kwargs = request.kwargsrepr"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+            else:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+                # task protocol 1"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+                task_kwargs = getattr(request, 'kwargs', None)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+            # Encode input arguments"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+            if task_args is not None:"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+                _, _, task_args = self.encode_content(task_args)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+            if task_kwargs is not None:"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+                _, _, task_kwargs = self.encode_content(task_kwargs)"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+            properties = getattr(request, 'properties', {}) or {}"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            periodic_task_name = properties.get('periodic_task_name', None)"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            extended_props.update({"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+                'periodic_task_name': periodic_task_name,"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+                'task_args': task_args,"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+                'task_kwargs': task_kwargs,"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+                'task_name': getattr(request, 'task', None),"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+                'traceback': traceback,"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+                'worker': getattr(request, 'hostname', None),"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+            })"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+        return extended_props"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+"
            },
            "48": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "     def _store_result("
            },
            "49": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "             self,"
            },
            "50": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "             task_id,"
            },
            "51": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "             {'children': self.current_task_children(request)}"
            },
            "52": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         )"
            },
            "53": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 116,
                "PatchRowcode": " "
            },
            "54": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        task_name = getattr(request, 'task', None)"
            },
            "55": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        properties = getattr(request, 'properties', {}) or {}"
            },
            "56": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        periodic_task_name = properties.get('periodic_task_name', None)"
            },
            "57": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        worker = getattr(request, 'hostname', None)"
            },
            "58": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "59": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Get input arguments"
            },
            "60": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if getattr(request, 'argsrepr', None) is not None:"
            },
            "61": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # task protocol 2"
            },
            "62": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_args = request.argsrepr"
            },
            "63": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else:"
            },
            "64": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # task protocol 1"
            },
            "65": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_args = getattr(request, 'args', None)"
            },
            "66": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "67": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if getattr(request, 'kwargsrepr', None) is not None:"
            },
            "68": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # task protocol 2"
            },
            "69": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_kwargs = request.kwargsrepr"
            },
            "70": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else:"
            },
            "71": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # task protocol 1"
            },
            "72": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_kwargs = getattr(request, 'kwargs', None)"
            },
            "73": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "74": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Encode input arguments"
            },
            "75": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if task_args is not None:"
            },
            "76": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            _, _, task_args = self.encode_content(task_args)"
            },
            "77": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "78": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if task_kwargs is not None:"
            },
            "79": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            _, _, task_kwargs = self.encode_content(task_kwargs)"
            },
            "80": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "81": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.TaskModel._default_manager.store_result("
            },
            "82": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            content_type,"
            },
            "83": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            content_encoding,"
            },
            "84": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_id,"
            },
            "85": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            result,"
            },
            "86": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            status,"
            },
            "87": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            traceback=traceback,"
            },
            "88": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            meta=meta,"
            },
            "89": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            periodic_task_name=periodic_task_name,"
            },
            "90": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_name=task_name,"
            },
            "91": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_args=task_args,"
            },
            "92": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            task_kwargs=task_kwargs,"
            },
            "93": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            worker=worker,"
            },
            "94": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            using=using,"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        task_props = {"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+            'content_encoding': content_encoding,"
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+            'content_type': content_type,"
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+            'meta': meta,"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+            'result': result,"
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+            'status': status,"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+            'task_id': task_id,"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+            'traceback': traceback,"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+            'using': using,"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+        }"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+        task_props.update("
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+            self._get_extended_properties(request, traceback)"
            },
            "108": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "         )"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+        self.TaskModel._default_manager.store_result(**task_props)"
            },
            "111": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "         return result"
            },
            "112": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 134,
                "PatchRowcode": " "
            },
            "113": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "     def _get_task_meta_for(self, task_id):"
            }
        },
        "frontPatchFile": [
            "import binascii",
            "import json",
            "",
            "from celery import maybe_signature",
            "from celery.backends.base import BaseDictBackend",
            "from celery.exceptions import ChordError",
            "from celery.result import GroupResult, allow_join_result, result_from_tuple",
            "from celery.utils.log import get_logger",
            "from celery.utils.serialization import b64decode, b64encode",
            "from django.db import connection, transaction",
            "from django.db.utils import InterfaceError",
            "from kombu.exceptions import DecodeError",
            "",
            "from ..models import ChordCounter",
            "from ..models import GroupResult as GroupResultModel",
            "from ..models import TaskResult",
            "",
            "EXCEPTIONS_TO_CATCH = (InterfaceError,)",
            "",
            "try:",
            "    from psycopg2 import InterfaceError as Psycopg2InterfaceError",
            "    EXCEPTIONS_TO_CATCH += (Psycopg2InterfaceError,)",
            "except ImportError:",
            "    pass",
            "",
            "logger = get_logger(__name__)",
            "",
            "",
            "class DatabaseBackend(BaseDictBackend):",
            "    \"\"\"The Django database backend, using models to store task state.\"\"\"",
            "",
            "    TaskModel = TaskResult",
            "    GroupModel = GroupResultModel",
            "    subpolling_interval = 0.5",
            "",
            "    def exception_safe_to_retry(self, exc):",
            "        \"\"\"Check if an exception is safe to retry.",
            "",
            "        Backends have to overload this method with correct predicates",
            "        dealing with their exceptions.",
            "",
            "        By default no exception is safe to retry, it's up to",
            "        backend implementation to define which exceptions are safe.",
            "",
            "        For Celery / django-celery-results, retry Django / Psycopg2",
            "        InterfaceErrors, like \"Connection already closed\", with new connection.",
            "",
            "        Set result_backend_always_retry to True in order to enable retries.",
            "        \"\"\"",
            "        for exc_type in EXCEPTIONS_TO_CATCH:",
            "            if isinstance(exc, exc_type):",
            "                # Only called if InterfaceError occurs and always_retry is True",
            "                connection.close()",
            "                return True",
            "        return False",
            "",
            "    def _store_result(",
            "            self,",
            "            task_id,",
            "            result,",
            "            status,",
            "            traceback=None,",
            "            request=None,",
            "            using=None",
            "    ):",
            "        \"\"\"Store return value and status of an executed task.\"\"\"",
            "        content_type, content_encoding, result = self.encode_content(result)",
            "        _, _, meta = self.encode_content(",
            "            {'children': self.current_task_children(request)}",
            "        )",
            "",
            "        task_name = getattr(request, 'task', None)",
            "        properties = getattr(request, 'properties', {}) or {}",
            "        periodic_task_name = properties.get('periodic_task_name', None)",
            "        worker = getattr(request, 'hostname', None)",
            "",
            "        # Get input arguments",
            "        if getattr(request, 'argsrepr', None) is not None:",
            "            # task protocol 2",
            "            task_args = request.argsrepr",
            "        else:",
            "            # task protocol 1",
            "            task_args = getattr(request, 'args', None)",
            "",
            "        if getattr(request, 'kwargsrepr', None) is not None:",
            "            # task protocol 2",
            "            task_kwargs = request.kwargsrepr",
            "        else:",
            "            # task protocol 1",
            "            task_kwargs = getattr(request, 'kwargs', None)",
            "",
            "        # Encode input arguments",
            "        if task_args is not None:",
            "            _, _, task_args = self.encode_content(task_args)",
            "",
            "        if task_kwargs is not None:",
            "            _, _, task_kwargs = self.encode_content(task_kwargs)",
            "",
            "        self.TaskModel._default_manager.store_result(",
            "            content_type,",
            "            content_encoding,",
            "            task_id,",
            "            result,",
            "            status,",
            "            traceback=traceback,",
            "            meta=meta,",
            "            periodic_task_name=periodic_task_name,",
            "            task_name=task_name,",
            "            task_args=task_args,",
            "            task_kwargs=task_kwargs,",
            "            worker=worker,",
            "            using=using,",
            "        )",
            "        return result",
            "",
            "    def _get_task_meta_for(self, task_id):",
            "        \"\"\"Get task metadata for a task by id.\"\"\"",
            "        obj = self.TaskModel._default_manager.get_task(task_id)",
            "        res = obj.as_dict()",
            "        meta = self.decode_content(obj, res.pop('meta', None)) or {}",
            "        result = self.decode_content(obj, res.get('result'))",
            "",
            "        task_args = res.get('task_args')",
            "        task_kwargs = res.get('task_kwargs')",
            "        try:",
            "            task_args = self.decode_content(obj, task_args)",
            "            task_kwargs = self.decode_content(obj, task_kwargs)",
            "        except (DecodeError, binascii.Error):",
            "            pass",
            "",
            "        # the right names are args/kwargs, not task_args/task_kwargs,",
            "        # keep both for backward compatibility",
            "        res.update(",
            "            meta,",
            "            result=result,",
            "            task_args=task_args,",
            "            task_kwargs=task_kwargs,",
            "            args=task_args,",
            "            kwargs=task_kwargs,",
            "        )",
            "        return self.meta_from_decoded(res)",
            "",
            "    def encode_content(self, data):",
            "        content_type, content_encoding, content = self._encode(data)",
            "        if content_encoding == 'binary':",
            "            content = b64encode(content)",
            "        return content_type, content_encoding, content",
            "",
            "    def decode_content(self, obj, content):",
            "        if content:",
            "            if obj.content_encoding == 'binary':",
            "                content = b64decode(content)",
            "            return self.decode(content)",
            "",
            "    def _forget(self, task_id):",
            "        try:",
            "            self.TaskModel._default_manager.get(task_id=task_id).delete()",
            "        except self.TaskModel.DoesNotExist:",
            "            pass",
            "",
            "    def cleanup(self):",
            "        \"\"\"Delete expired metadata.\"\"\"",
            "        self.TaskModel._default_manager.delete_expired(self.expires)",
            "        self.GroupModel._default_manager.delete_expired(self.expires)",
            "",
            "    def _restore_group(self, group_id):",
            "        \"\"\"return result value for a group by id.\"\"\"",
            "        group_result = self.GroupModel._default_manager.get_group(group_id)",
            "",
            "        if group_result:",
            "            res = group_result.as_dict()",
            "            decoded_result = self.decode_content(group_result, res[\"result\"])",
            "            res[\"result\"] = None",
            "            if decoded_result:",
            "                res[\"result\"] = result_from_tuple(decoded_result, app=self.app)",
            "            return res",
            "",
            "    def _save_group(self, group_id, group_result):",
            "        \"\"\"Store return value of group\"\"\"",
            "        content_type, content_encoding, result = self.encode_content(",
            "            group_result.as_tuple()",
            "        )",
            "        self.GroupModel._default_manager.store_group_result(",
            "            content_type, content_encoding, group_id, result",
            "        )",
            "        return group_result",
            "",
            "    def _delete_group(self, group_id):",
            "        try:",
            "            self.GroupModel._default_manager.get_group(group_id).delete()",
            "        except self.TaskModel.DoesNotExist:",
            "            pass",
            "",
            "    def apply_chord(self, header_result_args, body, **kwargs):",
            "        \"\"\"Add a ChordCounter with the expected number of results\"\"\"",
            "        if not isinstance(header_result_args, GroupResult):",
            "            # Celery 5.1 provides the GroupResult args",
            "            header_result = self.app.GroupResult(*header_result_args)",
            "        else:",
            "            # celery <5.1 will pass a GroupResult object",
            "            header_result = header_result_args",
            "        results = [r.as_tuple() for r in header_result]",
            "        chord_size = body.get(\"chord_size\", None) or len(results)",
            "        data = json.dumps(results)",
            "        ChordCounter.objects.create(",
            "            group_id=header_result.id, sub_tasks=data, count=chord_size",
            "        )",
            "",
            "    def on_chord_part_return(self, request, state, result, **kwargs):",
            "        \"\"\"Called on finishing each part of a Chord header\"\"\"",
            "        tid, gid = request.id, request.group",
            "        if not gid or not tid:",
            "            return",
            "        call_callback = False",
            "        with transaction.atomic():",
            "            # We need to know if `count` hits 0.",
            "            # wrap the update in a transaction",
            "            # with a `select_for_update` lock to prevent race conditions.",
            "            # SELECT FOR UPDATE is not supported on all databases",
            "            chord_counter = (",
            "                ChordCounter.objects.select_for_update()",
            "                .filter(group_id=gid).first()",
            "            )",
            "            if chord_counter is None:",
            "                logger.warning(\"Can't find ChordCounter for Group %s\", gid)",
            "                return",
            "            chord_counter.count -= 1",
            "            if chord_counter.count != 0:",
            "                chord_counter.save()",
            "            else:",
            "                # Last task in the chord header has finished",
            "                call_callback = True",
            "                chord_counter.delete()",
            "",
            "        if call_callback:",
            "            deps = chord_counter.group_result(app=self.app)",
            "            if deps.ready():",
            "                callback = maybe_signature(request.chord, app=self.app)",
            "                trigger_callback(",
            "                    app=self.app,",
            "                    callback=callback,",
            "                    group_result=deps",
            "                )",
            "",
            "",
            "def trigger_callback(app, callback, group_result):",
            "    \"\"\"Add the callback to the queue or mark the callback as failed",
            "    Implementation borrowed from `celery.app.builtins.unlock_chord`",
            "    \"\"\"",
            "    if group_result.supports_native_join:",
            "        j = group_result.join_native",
            "    else:",
            "        j = group_result.join",
            "",
            "    try:",
            "        with allow_join_result():",
            "            ret = j(timeout=app.conf.result_chord_join_timeout, propagate=True)",
            "    except Exception as exc:  # pylint: disable=broad-except",
            "        try:",
            "            culprit = next(group_result._failed_join_report())",
            "            reason = f\"Dependency {culprit.id} raised {exc!r}\"",
            "        except StopIteration:",
            "            reason = repr(exc)",
            "        logger.exception(\"Chord %r raised: %r\", group_result.id, exc)",
            "        app.backend.chord_error_from_stack(callback, ChordError(reason))",
            "    else:",
            "        try:",
            "            callback.delay(ret)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            logger.exception(\"Chord %r raised: %r\", group_result.id, exc)",
            "            app.backend.chord_error_from_stack(",
            "                callback, exc=ChordError(f\"Callback error: {exc!r}\")",
            "            )"
        ],
        "afterPatchFile": [
            "import binascii",
            "import json",
            "",
            "from celery import maybe_signature",
            "from celery.backends.base import BaseDictBackend",
            "from celery.exceptions import ChordError",
            "from celery.result import GroupResult, allow_join_result, result_from_tuple",
            "from celery.utils.log import get_logger",
            "from celery.utils.serialization import b64decode, b64encode",
            "from django.db import connection, transaction",
            "from django.db.utils import InterfaceError",
            "from kombu.exceptions import DecodeError",
            "",
            "from ..models import ChordCounter",
            "from ..models import GroupResult as GroupResultModel",
            "from ..models import TaskResult",
            "",
            "EXCEPTIONS_TO_CATCH = (InterfaceError,)",
            "",
            "try:",
            "    from psycopg2 import InterfaceError as Psycopg2InterfaceError",
            "    EXCEPTIONS_TO_CATCH += (Psycopg2InterfaceError,)",
            "except ImportError:",
            "    pass",
            "",
            "logger = get_logger(__name__)",
            "",
            "",
            "class DatabaseBackend(BaseDictBackend):",
            "    \"\"\"The Django database backend, using models to store task state.\"\"\"",
            "",
            "    TaskModel = TaskResult",
            "    GroupModel = GroupResultModel",
            "    subpolling_interval = 0.5",
            "",
            "    def exception_safe_to_retry(self, exc):",
            "        \"\"\"Check if an exception is safe to retry.",
            "",
            "        Backends have to overload this method with correct predicates",
            "        dealing with their exceptions.",
            "",
            "        By default no exception is safe to retry, it's up to",
            "        backend implementation to define which exceptions are safe.",
            "",
            "        For Celery / django-celery-results, retry Django / Psycopg2",
            "        InterfaceErrors, like \"Connection already closed\", with new connection.",
            "",
            "        Set result_backend_always_retry to True in order to enable retries.",
            "        \"\"\"",
            "        for exc_type in EXCEPTIONS_TO_CATCH:",
            "            if isinstance(exc, exc_type):",
            "                # Only called if InterfaceError occurs and always_retry is True",
            "                connection.close()",
            "                return True",
            "        return False",
            "",
            "    def _get_extended_properties(self, request, traceback):",
            "        extended_props = {",
            "            'periodic_task_name': None,",
            "            'task_args': None,",
            "            'task_kwargs': None,",
            "            'task_name': None,",
            "            'traceback': None,",
            "            'worker': None,",
            "        }",
            "        if request and self.app.conf.find_value_for_key('extended', 'result'):",
            "",
            "            if getattr(request, 'argsrepr', None) is not None:",
            "                # task protocol 2",
            "                task_args = request.argsrepr",
            "            else:",
            "                # task protocol 1",
            "                task_args = getattr(request, 'args', None)",
            "",
            "            if getattr(request, 'kwargsrepr', None) is not None:",
            "                # task protocol 2",
            "                task_kwargs = request.kwargsrepr",
            "            else:",
            "                # task protocol 1",
            "                task_kwargs = getattr(request, 'kwargs', None)",
            "",
            "            # Encode input arguments",
            "            if task_args is not None:",
            "                _, _, task_args = self.encode_content(task_args)",
            "",
            "            if task_kwargs is not None:",
            "                _, _, task_kwargs = self.encode_content(task_kwargs)",
            "",
            "            properties = getattr(request, 'properties', {}) or {}",
            "            periodic_task_name = properties.get('periodic_task_name', None)",
            "            extended_props.update({",
            "                'periodic_task_name': periodic_task_name,",
            "                'task_args': task_args,",
            "                'task_kwargs': task_kwargs,",
            "                'task_name': getattr(request, 'task', None),",
            "                'traceback': traceback,",
            "                'worker': getattr(request, 'hostname', None),",
            "            })",
            "",
            "        return extended_props",
            "",
            "    def _store_result(",
            "            self,",
            "            task_id,",
            "            result,",
            "            status,",
            "            traceback=None,",
            "            request=None,",
            "            using=None",
            "    ):",
            "        \"\"\"Store return value and status of an executed task.\"\"\"",
            "        content_type, content_encoding, result = self.encode_content(result)",
            "        _, _, meta = self.encode_content(",
            "            {'children': self.current_task_children(request)}",
            "        )",
            "",
            "        task_props = {",
            "            'content_encoding': content_encoding,",
            "            'content_type': content_type,",
            "            'meta': meta,",
            "            'result': result,",
            "            'status': status,",
            "            'task_id': task_id,",
            "            'traceback': traceback,",
            "            'using': using,",
            "        }",
            "",
            "        task_props.update(",
            "            self._get_extended_properties(request, traceback)",
            "        )",
            "",
            "        self.TaskModel._default_manager.store_result(**task_props)",
            "        return result",
            "",
            "    def _get_task_meta_for(self, task_id):",
            "        \"\"\"Get task metadata for a task by id.\"\"\"",
            "        obj = self.TaskModel._default_manager.get_task(task_id)",
            "        res = obj.as_dict()",
            "        meta = self.decode_content(obj, res.pop('meta', None)) or {}",
            "        result = self.decode_content(obj, res.get('result'))",
            "",
            "        task_args = res.get('task_args')",
            "        task_kwargs = res.get('task_kwargs')",
            "        try:",
            "            task_args = self.decode_content(obj, task_args)",
            "            task_kwargs = self.decode_content(obj, task_kwargs)",
            "        except (DecodeError, binascii.Error):",
            "            pass",
            "",
            "        # the right names are args/kwargs, not task_args/task_kwargs,",
            "        # keep both for backward compatibility",
            "        res.update(",
            "            meta,",
            "            result=result,",
            "            task_args=task_args,",
            "            task_kwargs=task_kwargs,",
            "            args=task_args,",
            "            kwargs=task_kwargs,",
            "        )",
            "        return self.meta_from_decoded(res)",
            "",
            "    def encode_content(self, data):",
            "        content_type, content_encoding, content = self._encode(data)",
            "        if content_encoding == 'binary':",
            "            content = b64encode(content)",
            "        return content_type, content_encoding, content",
            "",
            "    def decode_content(self, obj, content):",
            "        if content:",
            "            if obj.content_encoding == 'binary':",
            "                content = b64decode(content)",
            "            return self.decode(content)",
            "",
            "    def _forget(self, task_id):",
            "        try:",
            "            self.TaskModel._default_manager.get(task_id=task_id).delete()",
            "        except self.TaskModel.DoesNotExist:",
            "            pass",
            "",
            "    def cleanup(self):",
            "        \"\"\"Delete expired metadata.\"\"\"",
            "        self.TaskModel._default_manager.delete_expired(self.expires)",
            "        self.GroupModel._default_manager.delete_expired(self.expires)",
            "",
            "    def _restore_group(self, group_id):",
            "        \"\"\"return result value for a group by id.\"\"\"",
            "        group_result = self.GroupModel._default_manager.get_group(group_id)",
            "",
            "        if group_result:",
            "            res = group_result.as_dict()",
            "            decoded_result = self.decode_content(group_result, res[\"result\"])",
            "            res[\"result\"] = None",
            "            if decoded_result:",
            "                res[\"result\"] = result_from_tuple(decoded_result, app=self.app)",
            "            return res",
            "",
            "    def _save_group(self, group_id, group_result):",
            "        \"\"\"Store return value of group\"\"\"",
            "        content_type, content_encoding, result = self.encode_content(",
            "            group_result.as_tuple()",
            "        )",
            "        self.GroupModel._default_manager.store_group_result(",
            "            content_type, content_encoding, group_id, result",
            "        )",
            "        return group_result",
            "",
            "    def _delete_group(self, group_id):",
            "        try:",
            "            self.GroupModel._default_manager.get_group(group_id).delete()",
            "        except self.TaskModel.DoesNotExist:",
            "            pass",
            "",
            "    def apply_chord(self, header_result_args, body, **kwargs):",
            "        \"\"\"Add a ChordCounter with the expected number of results\"\"\"",
            "        if not isinstance(header_result_args, GroupResult):",
            "            # Celery 5.1 provides the GroupResult args",
            "            header_result = self.app.GroupResult(*header_result_args)",
            "        else:",
            "            # celery <5.1 will pass a GroupResult object",
            "            header_result = header_result_args",
            "        results = [r.as_tuple() for r in header_result]",
            "        chord_size = body.get(\"chord_size\", None) or len(results)",
            "        data = json.dumps(results)",
            "        ChordCounter.objects.create(",
            "            group_id=header_result.id, sub_tasks=data, count=chord_size",
            "        )",
            "",
            "    def on_chord_part_return(self, request, state, result, **kwargs):",
            "        \"\"\"Called on finishing each part of a Chord header\"\"\"",
            "        tid, gid = request.id, request.group",
            "        if not gid or not tid:",
            "            return",
            "        call_callback = False",
            "        with transaction.atomic():",
            "            # We need to know if `count` hits 0.",
            "            # wrap the update in a transaction",
            "            # with a `select_for_update` lock to prevent race conditions.",
            "            # SELECT FOR UPDATE is not supported on all databases",
            "            chord_counter = (",
            "                ChordCounter.objects.select_for_update()",
            "                .filter(group_id=gid).first()",
            "            )",
            "            if chord_counter is None:",
            "                logger.warning(\"Can't find ChordCounter for Group %s\", gid)",
            "                return",
            "            chord_counter.count -= 1",
            "            if chord_counter.count != 0:",
            "                chord_counter.save()",
            "            else:",
            "                # Last task in the chord header has finished",
            "                call_callback = True",
            "                chord_counter.delete()",
            "",
            "        if call_callback:",
            "            deps = chord_counter.group_result(app=self.app)",
            "            if deps.ready():",
            "                callback = maybe_signature(request.chord, app=self.app)",
            "                trigger_callback(",
            "                    app=self.app,",
            "                    callback=callback,",
            "                    group_result=deps",
            "                )",
            "",
            "",
            "def trigger_callback(app, callback, group_result):",
            "    \"\"\"Add the callback to the queue or mark the callback as failed",
            "    Implementation borrowed from `celery.app.builtins.unlock_chord`",
            "    \"\"\"",
            "    if group_result.supports_native_join:",
            "        j = group_result.join_native",
            "    else:",
            "        j = group_result.join",
            "",
            "    try:",
            "        with allow_join_result():",
            "            ret = j(timeout=app.conf.result_chord_join_timeout, propagate=True)",
            "    except Exception as exc:  # pylint: disable=broad-except",
            "        try:",
            "            culprit = next(group_result._failed_join_report())",
            "            reason = f\"Dependency {culprit.id} raised {exc!r}\"",
            "        except StopIteration:",
            "            reason = repr(exc)",
            "        logger.exception(\"Chord %r raised: %r\", group_result.id, exc)",
            "        app.backend.chord_error_from_stack(callback, ChordError(reason))",
            "    else:",
            "        try:",
            "            callback.delay(ret)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            logger.exception(\"Chord %r raised: %r\", group_result.id, exc)",
            "            app.backend.chord_error_from_stack(",
            "                callback, exc=ChordError(f\"Callback error: {exc!r}\")",
            "            )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "72": [
                "DatabaseBackend",
                "_store_result"
            ],
            "73": [
                "DatabaseBackend",
                "_store_result"
            ],
            "74": [
                "DatabaseBackend",
                "_store_result"
            ],
            "75": [
                "DatabaseBackend",
                "_store_result"
            ],
            "76": [
                "DatabaseBackend",
                "_store_result"
            ],
            "77": [
                "DatabaseBackend",
                "_store_result"
            ],
            "78": [
                "DatabaseBackend",
                "_store_result"
            ],
            "79": [
                "DatabaseBackend",
                "_store_result"
            ],
            "80": [
                "DatabaseBackend",
                "_store_result"
            ],
            "81": [
                "DatabaseBackend",
                "_store_result"
            ],
            "82": [
                "DatabaseBackend",
                "_store_result"
            ],
            "83": [
                "DatabaseBackend",
                "_store_result"
            ],
            "84": [
                "DatabaseBackend",
                "_store_result"
            ],
            "85": [
                "DatabaseBackend",
                "_store_result"
            ],
            "86": [
                "DatabaseBackend",
                "_store_result"
            ],
            "87": [
                "DatabaseBackend",
                "_store_result"
            ],
            "88": [
                "DatabaseBackend",
                "_store_result"
            ],
            "89": [
                "DatabaseBackend",
                "_store_result"
            ],
            "90": [
                "DatabaseBackend",
                "_store_result"
            ],
            "91": [
                "DatabaseBackend",
                "_store_result"
            ],
            "92": [
                "DatabaseBackend",
                "_store_result"
            ],
            "93": [
                "DatabaseBackend",
                "_store_result"
            ],
            "94": [
                "DatabaseBackend",
                "_store_result"
            ],
            "95": [
                "DatabaseBackend",
                "_store_result"
            ],
            "96": [
                "DatabaseBackend",
                "_store_result"
            ],
            "97": [
                "DatabaseBackend",
                "_store_result"
            ],
            "98": [
                "DatabaseBackend",
                "_store_result"
            ],
            "99": [
                "DatabaseBackend",
                "_store_result"
            ],
            "100": [
                "DatabaseBackend",
                "_store_result"
            ],
            "101": [
                "DatabaseBackend",
                "_store_result"
            ],
            "102": [
                "DatabaseBackend",
                "_store_result"
            ],
            "103": [
                "DatabaseBackend",
                "_store_result"
            ],
            "104": [
                "DatabaseBackend",
                "_store_result"
            ],
            "105": [
                "DatabaseBackend",
                "_store_result"
            ],
            "106": [
                "DatabaseBackend",
                "_store_result"
            ],
            "107": [
                "DatabaseBackend",
                "_store_result"
            ],
            "108": [
                "DatabaseBackend",
                "_store_result"
            ],
            "109": [
                "DatabaseBackend",
                "_store_result"
            ],
            "110": [
                "DatabaseBackend",
                "_store_result"
            ],
            "111": [
                "DatabaseBackend",
                "_store_result"
            ],
            "112": [
                "DatabaseBackend",
                "_store_result"
            ]
        },
        "addLocation": [
            "django_celery_results.backends.database.DatabaseBackend.self",
            "mistune.inline_parser"
        ]
    },
    "t/unit/backends/test_database.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "         self.app.conf.result_serializer = 'json'"
            },
            "1": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "         self.app.conf.result_backend = ("
            },
            "2": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "             'django_celery_results.backends:DatabaseBackend')"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+        self.app.conf.result_extended = True"
            },
            "4": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "         self.b = DatabaseBackend(app=self.app)"
            },
            "5": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "     def _create_request(self, task_id, name, args, kwargs,"
            },
            "7": {
                "beforePatchRowNumber": 859,
                "afterPatchRowNumber": 860,
                "PatchRowcode": "         restored_group = self.b.restore_group(group_id=group_id)"
            },
            "8": {
                "beforePatchRowNumber": 860,
                "afterPatchRowNumber": 861,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 861,
                "afterPatchRowNumber": 862,
                "PatchRowcode": "         assert restored_group == group"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 863,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 864,
                "PatchRowcode": "+    def test_backend_result_extended_is_false(self):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 865,
                "PatchRowcode": "+        self.app.conf.result_extended = False"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 866,
                "PatchRowcode": "+        self.b = DatabaseBackend(app=self.app)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 867,
                "PatchRowcode": "+        tid2 = uuid()"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 868,
                "PatchRowcode": "+        request = self._create_request("
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 869,
                "PatchRowcode": "+            task_id=tid2,"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 870,
                "PatchRowcode": "+            name='my_task',"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 871,
                "PatchRowcode": "+            args=['a', 1, True],"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 872,
                "PatchRowcode": "+            kwargs={'c': 6, 'd': 'e', 'f': False},"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 873,
                "PatchRowcode": "+        )"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 874,
                "PatchRowcode": "+        result = 'foo'"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 875,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 876,
                "PatchRowcode": "+        self.b.mark_as_done(tid2, result, request=request)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 877,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 878,
                "PatchRowcode": "+        mindb = self.b.get_task_meta(tid2)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 879,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 880,
                "PatchRowcode": "+        # check meta data"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 881,
                "PatchRowcode": "+        assert mindb.get('result') == 'foo'"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 882,
                "PatchRowcode": "+        assert mindb.get('task_name') is None"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 883,
                "PatchRowcode": "+        assert mindb.get('task_args') is None"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 884,
                "PatchRowcode": "+        assert mindb.get('task_kwargs') is None"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 885,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 886,
                "PatchRowcode": "+        # check task_result object"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 887,
                "PatchRowcode": "+        tr = TaskResult.objects.get(task_id=tid2)"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 888,
                "PatchRowcode": "+        assert tr.task_args is None"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 889,
                "PatchRowcode": "+        assert tr.task_kwargs is None"
            }
        },
        "frontPatchFile": [
            "import json",
            "import pickle",
            "import re",
            "from unittest import mock",
            "",
            "import celery",
            "import pytest",
            "from celery import states, uuid",
            "from celery.app.task import Context",
            "from celery.result import AsyncResult, GroupResult",
            "from celery.utils.serialization import b64decode",
            "from celery.worker.request import Request",
            "from celery.worker.strategy import hybrid_to_proto2",
            "",
            "from django_celery_results.backends.database import DatabaseBackend",
            "from django_celery_results.models import ChordCounter, TaskResult",
            "",
            "",
            "class SomeClass:",
            "",
            "    def __init__(self, data):",
            "        self.data = data",
            "",
            "",
            "@pytest.mark.django_db()",
            "@pytest.mark.usefixtures('depends_on_current_app')",
            "class test_DatabaseBackend:",
            "",
            "    @pytest.fixture(autouse=True)",
            "    def setup_backend(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.result_backend = (",
            "            'django_celery_results.backends:DatabaseBackend')",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "    def _create_request(self, task_id, name, args, kwargs,",
            "                        argsrepr=None, kwargsrepr=None, task_protocol=2):",
            "        msg = self.app.amqp.task_protocols[task_protocol](",
            "            task_id=task_id,",
            "            name=name,",
            "            args=args,",
            "            kwargs=kwargs,",
            "            argsrepr=argsrepr,",
            "            kwargsrepr=kwargsrepr,",
            "        )",
            "        if task_protocol == 1:",
            "            body, headers, _, _ = hybrid_to_proto2(msg, msg.body)",
            "            properties = None",
            "            sent_event = {}",
            "        else:",
            "            headers, properties, body, sent_event = msg",
            "        context = Context(",
            "            headers=headers,",
            "            properties=properties,",
            "            body=body,",
            "            sent_event=sent_event,",
            "        )",
            "        request = Request(context, decoded=True, task=name)",
            "        if task_protocol == 1:",
            "            assert request.argsrepr is None",
            "            assert request.kwargsrepr is None",
            "        else:",
            "            assert request.argsrepr is not None",
            "            assert request.kwargsrepr is not None",
            "        return request",
            "",
            "    def test_backend__pickle_serialization__dict_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = {'foo': 'baz', 'bar': SomeClass(12345)}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar').data == 12345",
            "        assert len(mindb.get('worker')) > 1",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        # check backward compatibility",
            "        task_kwargs2 = str(request.kwargs)",
            "        task_args2 = str(request.args)",
            "        assert tr.task_args != task_args2",
            "        assert tr.task_kwargs != task_kwargs2",
            "        tr.task_args = task_args2",
            "        tr.task_kwargs = task_kwargs2",
            "        tr.save()",
            "        mindb = self.b.get_task_meta(tid2)",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__pickle_serialization__str_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert len(mindb.get('worker')) > 1",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__pickle_serialization__bytes_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = b'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == b'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert len(mindb.get('worker')) > 1",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result objects",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__json_serialization__dict_result(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "        )",
            "        result = {'foo': 'baz', 'bar': True}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar') is True",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == \"['a', 1, True]\"",
            "        assert json.loads(tr.task_kwargs) == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        # check backward compatibility",
            "        task_kwargs2 = str(request.kwargs)",
            "        task_args2 = str(request.args)",
            "        assert tr.task_args != task_args2",
            "        assert tr.task_kwargs != task_kwargs2",
            "        tr.task_args = task_args2",
            "        tr.task_kwargs = task_kwargs2",
            "        tr.save()",
            "        mindb = self.b.get_task_meta(tid2)",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__json_serialization__str_result(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == \"['a', 1, True]\"",
            "        assert json.loads(tr.task_kwargs) == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__pickle_serialization__dict_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz', 'bar': SomeClass(12345)}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar').data == 12345",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__pickle_serialization__str_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_backend__pickle_serialization__bytes_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = b'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == b'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_backend__json_serialization__dict_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz', 'bar': True}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar') is True",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__json_serialization__str_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            task_protocol=1,",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "    def xxx_backend(self):",
            "        tid = uuid()",
            "",
            "        assert self.b.get_status(tid) == states.PENDING",
            "        assert self.b.get_result(tid) is None",
            "",
            "        self.b.mark_as_done(tid, 42)",
            "        assert self.b.get_status(tid) == states.SUCCESS",
            "        assert self.b.get_result(tid) == 42",
            "",
            "        tid2 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid2, exception)",
            "",
            "        assert self.b.get_status(tid2) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid2), KeyError)",
            "",
            "    def test_forget(self):",
            "        tid = uuid()",
            "        self.b.mark_as_done(tid, {'foo': 'bar'})",
            "        x = self.app.AsyncResult(tid)",
            "        assert x.result.get('foo') == 'bar'",
            "        x.forget()",
            "        if celery.VERSION[0:3] == (3, 1, 10):",
            "            # bug in 3.1.10 means result did not clear cache after forget.",
            "            x._cache = None",
            "        assert x.result is None",
            "",
            "    def test_secrets__pickle_serialization(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, 'password'],",
            "            kwargs={'c': 3, 'd': 'e', 'password': 'password'},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_args') == 'argsrepr'",
            "        assert mindb.get('task_kwargs') == 'kwargsrepr'",
            "        assert len(mindb.get('worker')) > 1",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == 'argsrepr'",
            "        assert task_kwargs == 'kwargsrepr'",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_secrets__json_serialization(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_args') == 'argsrepr'",
            "        assert mindb.get('task_kwargs') == 'kwargsrepr'",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        assert json.loads(tr.task_args) == 'argsrepr'",
            "        assert json.loads(tr.task_kwargs) == 'kwargsrepr'",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_secrets__pickle_serialization__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "",
            "        mindb = self.b.get_task_meta(tid)",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_secrets__json_serialization__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "    def test_apply_chord_header_result_arg(self):",
            "        \"\"\"Test if apply_chord can handle Celery <= 5.1 call signature\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        # Celery < 5.1",
            "        self.b.apply_chord(group, self.add.s())",
            "        # Celery 5.1",
            "        self.b.apply_chord((uuid(), subtasks), self.add.s())",
            "",
            "    def test_on_chord_part_return(self):",
            "        \"\"\"Test if the ChordCounter is properly decremented and the callback is",
            "        triggered after all chord parts have returned\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = subtasks[0].id",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.ignore_result = False",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_called_once()",
            "",
            "    def test_on_chord_part_return_counter_not_found(self):",
            "        \"\"\"Test if the chord does not raise an error if the ChordCounter is not found",
            "",
            "        Basically this covers the case where a chord was created with a version",
            "        <2.0.0 and the update was done before the chord was finished",
            "        \"\"\"",
            "        request = mock.MagicMock()",
            "        request.id = uuid()",
            "        request.group = uuid()",
            "        self.b.on_chord_part_return(request=request, state=None, result=None)",
            "",
            "    def test_callback_failure(self):",
            "        \"\"\"Test if a failure in the chord callback is properly handled\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        cid = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = subtasks[0].id",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.ignore_result = False",
            "        request.chord.id = cid",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        # Trigger an exception when the callback is triggered",
            "        request.chord.delay.side_effect = ValueError()",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_called_once()",
            "",
            "        assert TaskResult.objects.get(task_id=cid).status == states.FAILURE",
            "",
            "    def test_on_chord_part_return_failure(self):",
            "        \"\"\"Test if a failure in one of the chord header tasks is properly handled",
            "        and the callback was not triggered",
            "        \"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        cid = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = tid1",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.chord.id = cid",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        request.id = tid2",
            "        self.b.mark_as_failure(tid2, ValueError(), request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_not_called()",
            "",
            "    def test_groupresult_save_restore(self):",
            "        \"\"\"Test if we can save and restore a GroupResult\"\"\"",
            "        group_id = uuid()",
            "        results = [AsyncResult(id=uuid())]",
            "        group = GroupResult(id=group_id, results=results)",
            "",
            "        group.save(backend=self.b)",
            "",
            "        restored_group = self.b.restore_group(group_id=group_id)",
            "",
            "        assert restored_group == group",
            "",
            "    def test_groupresult_save_restore_nested(self):",
            "        \"\"\"Test if we can save and restore a nested GroupResult\"\"\"",
            "        group_id = uuid()",
            "        async_result = AsyncResult(id=uuid())",
            "        nested_results = [AsyncResult(id=uuid()), AsyncResult(id=uuid())]",
            "        nested_group = GroupResult(id=uuid(), results=nested_results)",
            "        group = GroupResult(id=group_id, results=[nested_group, async_result])",
            "",
            "        group.save(backend=self.b)",
            "",
            "        restored_group = self.b.restore_group(group_id=group_id)",
            "",
            "        assert restored_group == group"
        ],
        "afterPatchFile": [
            "import json",
            "import pickle",
            "import re",
            "from unittest import mock",
            "",
            "import celery",
            "import pytest",
            "from celery import states, uuid",
            "from celery.app.task import Context",
            "from celery.result import AsyncResult, GroupResult",
            "from celery.utils.serialization import b64decode",
            "from celery.worker.request import Request",
            "from celery.worker.strategy import hybrid_to_proto2",
            "",
            "from django_celery_results.backends.database import DatabaseBackend",
            "from django_celery_results.models import ChordCounter, TaskResult",
            "",
            "",
            "class SomeClass:",
            "",
            "    def __init__(self, data):",
            "        self.data = data",
            "",
            "",
            "@pytest.mark.django_db()",
            "@pytest.mark.usefixtures('depends_on_current_app')",
            "class test_DatabaseBackend:",
            "",
            "    @pytest.fixture(autouse=True)",
            "    def setup_backend(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.result_backend = (",
            "            'django_celery_results.backends:DatabaseBackend')",
            "        self.app.conf.result_extended = True",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "    def _create_request(self, task_id, name, args, kwargs,",
            "                        argsrepr=None, kwargsrepr=None, task_protocol=2):",
            "        msg = self.app.amqp.task_protocols[task_protocol](",
            "            task_id=task_id,",
            "            name=name,",
            "            args=args,",
            "            kwargs=kwargs,",
            "            argsrepr=argsrepr,",
            "            kwargsrepr=kwargsrepr,",
            "        )",
            "        if task_protocol == 1:",
            "            body, headers, _, _ = hybrid_to_proto2(msg, msg.body)",
            "            properties = None",
            "            sent_event = {}",
            "        else:",
            "            headers, properties, body, sent_event = msg",
            "        context = Context(",
            "            headers=headers,",
            "            properties=properties,",
            "            body=body,",
            "            sent_event=sent_event,",
            "        )",
            "        request = Request(context, decoded=True, task=name)",
            "        if task_protocol == 1:",
            "            assert request.argsrepr is None",
            "            assert request.kwargsrepr is None",
            "        else:",
            "            assert request.argsrepr is not None",
            "            assert request.kwargsrepr is not None",
            "        return request",
            "",
            "    def test_backend__pickle_serialization__dict_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = {'foo': 'baz', 'bar': SomeClass(12345)}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar').data == 12345",
            "        assert len(mindb.get('worker')) > 1",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        # check backward compatibility",
            "        task_kwargs2 = str(request.kwargs)",
            "        task_args2 = str(request.args)",
            "        assert tr.task_args != task_args2",
            "        assert tr.task_kwargs != task_kwargs2",
            "        tr.task_args = task_args2",
            "        tr.task_kwargs = task_kwargs2",
            "        tr.save()",
            "        mindb = self.b.get_task_meta(tid2)",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__pickle_serialization__str_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert len(mindb.get('worker')) > 1",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__pickle_serialization__bytes_result(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "        )",
            "        result = b'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == b'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert len(mindb.get('worker')) > 1",
            "        assert bool(re.match(",
            "            r\"\\['a', 1, <.*SomeClass object at .*>\\]\",",
            "            mindb.get('task_args')",
            "        ))",
            "        assert bool(re.match(",
            "            r\"{'c': 6, 'd': 'e', 'f': <.*SomeClass object at .*>}\",",
            "            mindb.get('task_kwargs')",
            "        ))",
            "",
            "        # check task_result objects",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == mindb.get('task_args')",
            "        assert task_kwargs == mindb.get('task_kwargs')",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__json_serialization__dict_result(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "        )",
            "        result = {'foo': 'baz', 'bar': True}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar') is True",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == \"['a', 1, True]\"",
            "        assert json.loads(tr.task_kwargs) == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        # check backward compatibility",
            "        task_kwargs2 = str(request.kwargs)",
            "        task_args2 = str(request.args)",
            "        assert tr.task_args != task_args2",
            "        assert tr.task_kwargs != task_kwargs2",
            "        tr.task_args = task_args2",
            "        tr.task_kwargs = task_kwargs2",
            "        tr.save()",
            "        mindb = self.b.get_task_meta(tid2)",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__json_serialization__str_result(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == \"['a', 1, True]\"",
            "        assert mindb.get('task_kwargs') == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == \"['a', 1, True]\"",
            "        assert json.loads(tr.task_kwargs) == \"{'c': 6, 'd': 'e', 'f': False}\"",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid2)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_backend__pickle_serialization__dict_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz', 'bar': SomeClass(12345)}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar').data == 12345",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__pickle_serialization__str_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_backend__pickle_serialization__bytes_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            task_protocol=1,",
            "        )",
            "        result = b'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == b'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_backend__json_serialization__dict_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz', 'bar': True}",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result').get('foo') == 'baz'",
            "        assert mindb.get('result').get('bar') is True",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        tid3 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid3, exception)",
            "",
            "        assert self.b.get_status(tid3) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid3), KeyError)",
            "",
            "    def test_backend__json_serialization__str_result__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            task_protocol=1,",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "    def xxx_backend(self):",
            "        tid = uuid()",
            "",
            "        assert self.b.get_status(tid) == states.PENDING",
            "        assert self.b.get_result(tid) is None",
            "",
            "        self.b.mark_as_done(tid, 42)",
            "        assert self.b.get_status(tid) == states.SUCCESS",
            "        assert self.b.get_result(tid) == 42",
            "",
            "        tid2 = uuid()",
            "        try:",
            "            raise KeyError('foo')",
            "        except KeyError as exception:",
            "            self.b.mark_as_failure(tid2, exception)",
            "",
            "        assert self.b.get_status(tid2) == states.FAILURE",
            "        assert isinstance(self.b.get_result(tid2), KeyError)",
            "",
            "    def test_forget(self):",
            "        tid = uuid()",
            "        self.b.mark_as_done(tid, {'foo': 'bar'})",
            "        x = self.app.AsyncResult(tid)",
            "        assert x.result.get('foo') == 'bar'",
            "        x.forget()",
            "        if celery.VERSION[0:3] == (3, 1, 10):",
            "            # bug in 3.1.10 means result did not clear cache after forget.",
            "            x._cache = None",
            "        assert x.result is None",
            "",
            "    def test_secrets__pickle_serialization(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, 'password'],",
            "            kwargs={'c': 3, 'd': 'e', 'password': 'password'},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_args') == 'argsrepr'",
            "        assert mindb.get('task_kwargs') == 'kwargsrepr'",
            "        assert len(mindb.get('worker')) > 1",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_args == 'argsrepr'",
            "        assert task_kwargs == 'kwargsrepr'",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_secrets__json_serialization(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        # check task meta",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_args') == 'argsrepr'",
            "        assert mindb.get('task_kwargs') == 'kwargsrepr'",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        assert json.loads(tr.task_args) == 'argsrepr'",
            "        assert json.loads(tr.task_kwargs) == 'kwargsrepr'",
            "",
            "        # check async_result",
            "        ar = AsyncResult(tid)",
            "        assert ar.args == mindb.get('task_args')",
            "        assert ar.kwargs == mindb.get('task_kwargs')",
            "",
            "    def test_secrets__pickle_serialization__protocol_1(self):",
            "        self.app.conf.result_serializer = 'pickle'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, SomeClass(67)],",
            "            kwargs={'c': 6, 'd': 'e', 'f': SomeClass(89)},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "",
            "        mindb = self.b.get_task_meta(tid)",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "",
            "        assert mindb.get('task_args')[0] == 'a'",
            "        assert mindb.get('task_args')[1] == 1",
            "        assert mindb.get('task_args')[2].data == 67",
            "",
            "        assert mindb.get('task_kwargs')['c'] == 6",
            "        assert mindb.get('task_kwargs')['d'] == 'e'",
            "        assert mindb.get('task_kwargs')['f'].data == 89",
            "",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        task_args = pickle.loads(b64decode(tr.task_args))",
            "        assert task_args[0] == 'a'",
            "        assert task_args[1] == 1",
            "        assert task_args[2].data == 67",
            "",
            "        task_kwargs = pickle.loads(b64decode(tr.task_kwargs))",
            "        assert task_kwargs['c'] == 6",
            "        assert task_kwargs['d'] == 'e'",
            "        assert task_kwargs['f'].data == 89",
            "",
            "    def test_secrets__json_serialization__protocol_1(self):",
            "        self.app.conf.result_serializer = 'json'",
            "        self.app.conf.accept_content = {'pickle', 'json'}",
            "        self.b = DatabaseBackend(app=self.app)",
            "",
            "        tid = uuid()",
            "        request = self._create_request(",
            "            task_id=tid,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "            argsrepr='argsrepr',",
            "            kwargsrepr='kwargsrepr',",
            "            task_protocol=1,",
            "        )",
            "        result = {'foo': 'baz'}",
            "",
            "        self.b.mark_as_done(tid, result, request=request)",
            "",
            "        mindb = self.b.get_task_meta(tid)",
            "",
            "        assert mindb.get('result') == {'foo': 'baz'}",
            "        assert mindb.get('task_name') == 'my_task'",
            "        assert mindb.get('task_args') == ['a', 1, True]",
            "        assert mindb.get('task_kwargs') == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "        tr = TaskResult.objects.get(task_id=tid)",
            "        assert json.loads(tr.task_args) == ['a', 1, True]",
            "        assert json.loads(tr.task_kwargs) == {'c': 6, 'd': 'e', 'f': False}",
            "",
            "    def test_apply_chord_header_result_arg(self):",
            "        \"\"\"Test if apply_chord can handle Celery <= 5.1 call signature\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        # Celery < 5.1",
            "        self.b.apply_chord(group, self.add.s())",
            "        # Celery 5.1",
            "        self.b.apply_chord((uuid(), subtasks), self.add.s())",
            "",
            "    def test_on_chord_part_return(self):",
            "        \"\"\"Test if the ChordCounter is properly decremented and the callback is",
            "        triggered after all chord parts have returned\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = subtasks[0].id",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.ignore_result = False",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_called_once()",
            "",
            "    def test_on_chord_part_return_counter_not_found(self):",
            "        \"\"\"Test if the chord does not raise an error if the ChordCounter is not found",
            "",
            "        Basically this covers the case where a chord was created with a version",
            "        <2.0.0 and the update was done before the chord was finished",
            "        \"\"\"",
            "        request = mock.MagicMock()",
            "        request.id = uuid()",
            "        request.group = uuid()",
            "        self.b.on_chord_part_return(request=request, state=None, result=None)",
            "",
            "    def test_callback_failure(self):",
            "        \"\"\"Test if a failure in the chord callback is properly handled\"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        cid = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = subtasks[0].id",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.ignore_result = False",
            "        request.chord.id = cid",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        # Trigger an exception when the callback is triggered",
            "        request.chord.delay.side_effect = ValueError()",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_called_once()",
            "",
            "        assert TaskResult.objects.get(task_id=cid).status == states.FAILURE",
            "",
            "    def test_on_chord_part_return_failure(self):",
            "        \"\"\"Test if a failure in one of the chord header tasks is properly handled",
            "        and the callback was not triggered",
            "        \"\"\"",
            "        gid = uuid()",
            "        tid1 = uuid()",
            "        tid2 = uuid()",
            "        cid = uuid()",
            "        subtasks = [AsyncResult(tid1), AsyncResult(tid2)]",
            "        group = GroupResult(id=gid, results=subtasks)",
            "        self.b.apply_chord(group, self.add.s())",
            "",
            "        chord_counter = ChordCounter.objects.get(group_id=gid)",
            "        assert chord_counter.count == 2",
            "",
            "        request = mock.MagicMock()",
            "        request.id = tid1",
            "        request.group = gid",
            "        request.task = \"my_task\"",
            "        request.args = [\"a\", 1, \"password\"]",
            "        request.kwargs = {\"c\": 3, \"d\": \"e\", \"password\": \"password\"}",
            "        request.argsrepr = \"argsrepr\"",
            "        request.kwargsrepr = \"kwargsrepr\"",
            "        request.hostname = \"celery@ip-0-0-0-0\"",
            "        request.properties = {\"periodic_task_name\": \"my_periodic_task\"}",
            "        request.chord.id = cid",
            "        result = {\"foo\": \"baz\"}",
            "",
            "        self.b.mark_as_done(tid1, result, request=request)",
            "",
            "        chord_counter.refresh_from_db()",
            "        assert chord_counter.count == 1",
            "",
            "        request.id = tid2",
            "        self.b.mark_as_failure(tid2, ValueError(), request=request)",
            "",
            "        with pytest.raises(ChordCounter.DoesNotExist):",
            "            ChordCounter.objects.get(group_id=gid)",
            "",
            "        request.chord.delay.assert_not_called()",
            "",
            "    def test_groupresult_save_restore(self):",
            "        \"\"\"Test if we can save and restore a GroupResult\"\"\"",
            "        group_id = uuid()",
            "        results = [AsyncResult(id=uuid())]",
            "        group = GroupResult(id=group_id, results=results)",
            "",
            "        group.save(backend=self.b)",
            "",
            "        restored_group = self.b.restore_group(group_id=group_id)",
            "",
            "        assert restored_group == group",
            "",
            "    def test_groupresult_save_restore_nested(self):",
            "        \"\"\"Test if we can save and restore a nested GroupResult\"\"\"",
            "        group_id = uuid()",
            "        async_result = AsyncResult(id=uuid())",
            "        nested_results = [AsyncResult(id=uuid()), AsyncResult(id=uuid())]",
            "        nested_group = GroupResult(id=uuid(), results=nested_results)",
            "        group = GroupResult(id=group_id, results=[nested_group, async_result])",
            "",
            "        group.save(backend=self.b)",
            "",
            "        restored_group = self.b.restore_group(group_id=group_id)",
            "",
            "        assert restored_group == group",
            "",
            "    def test_backend_result_extended_is_false(self):",
            "        self.app.conf.result_extended = False",
            "        self.b = DatabaseBackend(app=self.app)",
            "        tid2 = uuid()",
            "        request = self._create_request(",
            "            task_id=tid2,",
            "            name='my_task',",
            "            args=['a', 1, True],",
            "            kwargs={'c': 6, 'd': 'e', 'f': False},",
            "        )",
            "        result = 'foo'",
            "",
            "        self.b.mark_as_done(tid2, result, request=request)",
            "",
            "        mindb = self.b.get_task_meta(tid2)",
            "",
            "        # check meta data",
            "        assert mindb.get('result') == 'foo'",
            "        assert mindb.get('task_name') is None",
            "        assert mindb.get('task_args') is None",
            "        assert mindb.get('task_kwargs') is None",
            "",
            "        # check task_result object",
            "        tr = TaskResult.objects.get(task_id=tid2)",
            "        assert tr.task_args is None",
            "        assert tr.task_kwargs is None"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "t.unit.backends.test_database.test_DatabaseBackend._create_request.args",
            "t.unit.backends.test_database.test_DatabaseBackend._create_request.kwargs",
            "t.unit.backends.test_database.test_DatabaseBackend.self",
            "mistune.inline_parser"
        ]
    }
}