{
    "magnum/common/keystone.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "                 project=trustor_project_id,"
            },
            "1": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 205,
                "PatchRowcode": "                 trustee_user=trustee_user,"
            },
            "2": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "                 impersonation=True,"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+                delegation_depth=0,"
            },
            "4": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "                 role_names=roles)"
            },
            "5": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "         except Exception:"
            },
            "6": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 210,
                "PatchRowcode": "             LOG.exception(_LE('Failed to create trust'))"
            }
        },
        "frontPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "from keystoneauth1.access import access as ka_access",
            "from keystoneauth1 import exceptions as ka_exception",
            "from keystoneauth1.identity import access as ka_access_plugin",
            "from keystoneauth1.identity import v3 as ka_v3",
            "from keystoneauth1 import loading as ka_loading",
            "import keystoneclient.exceptions as kc_exception",
            "from keystoneclient.v3 import client as kc_v3",
            "from oslo_log import log as logging",
            "",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.conf import keystone as ksconf",
            "from magnum.i18n import _",
            "from magnum.i18n import _LE",
            "from magnum.i18n import _LW",
            "",
            "CONF = magnum.conf.CONF",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "class KeystoneClientV3(object):",
            "    \"\"\"Keystone client wrapper so we can encapsulate logic in one place.\"\"\"",
            "",
            "    def __init__(self, context):",
            "        self.context = context",
            "        self._client = None",
            "        self._domain_admin_auth = None",
            "        self._domain_admin_session = None",
            "        self._domain_admin_client = None",
            "        self._trustee_domain_id = None",
            "        self._session = None",
            "",
            "    @property",
            "    def auth_url(self):",
            "        # FIXME(pauloewerton): auth_url should be retrieved from keystone_auth",
            "        # section by default",
            "        return CONF[ksconf.CFG_LEGACY_GROUP].auth_uri.replace('v2.0', 'v3')",
            "",
            "    @property",
            "    def auth_token(self):",
            "        return self.session.get_token()",
            "",
            "    @property",
            "    def session(self):",
            "        if self._session:",
            "            return self._session",
            "        auth = self._get_auth()",
            "        session = self._get_session(auth)",
            "        self._session = session",
            "        return session",
            "",
            "    def _get_session(self, auth):",
            "        session = ka_loading.load_session_from_conf_options(",
            "            CONF, ksconf.CFG_GROUP, auth=auth)",
            "        return session",
            "",
            "    def _get_auth(self):",
            "        if self.context.is_admin:",
            "            try:",
            "                auth = ka_loading.load_auth_from_conf_options(",
            "                    CONF, ksconf.CFG_GROUP)",
            "            except ka_exception.MissingRequiredOptions:",
            "                auth = self._get_legacy_auth()",
            "        elif self.context.auth_token_info:",
            "            access_info = ka_access.create(body=self.context.auth_token_info,",
            "                                           auth_token=self.context.auth_token)",
            "            auth = ka_access_plugin.AccessInfoPlugin(access_info)",
            "        elif self.context.auth_token:",
            "            auth = ka_v3.Token(auth_url=self.auth_url,",
            "                               token=self.context.auth_token)",
            "        elif self.context.trust_id:",
            "            auth_info = {",
            "                'auth_url': self.auth_url,",
            "                'username': self.context.user_name,",
            "                'password': self.context.password,",
            "                'user_domain_id': self.context.user_domain_id,",
            "                'user_domain_name': self.context.user_domain_name,",
            "                'trust_id': self.context.trust_id",
            "            }",
            "",
            "            auth = ka_v3.Password(**auth_info)",
            "",
            "        else:",
            "            LOG.error(_LE('Keystone API connection failed: no password, '",
            "                          'trust_id or token found.'))",
            "            raise exception.AuthorizationFailure()",
            "",
            "        return auth",
            "",
            "    def _get_legacy_auth(self):",
            "        LOG.warning(_LW('Auth plugin and its options for service user '",
            "                        'must be provided in [%(new)s] section. '",
            "                        'Using values from [%(old)s] section is '",
            "                        'deprecated.'), {'new': ksconf.CFG_GROUP,",
            "                                         'old': ksconf.CFG_LEGACY_GROUP})",
            "",
            "        conf = getattr(CONF, ksconf.CFG_LEGACY_GROUP)",
            "",
            "        # FIXME(htruta, pauloewerton): Conductor layer does not have",
            "        # new v3 variables, such as project_name and project_domain_id.",
            "        # The use of admin_* variables is related to Identity API v2.0,",
            "        # which is now deprecated. We should also stop using hard-coded",
            "        # domain info, as well as variables that refer to `tenant`,",
            "        # as they are also v2 related.",
            "        auth = ka_v3.Password(auth_url=self.auth_url,",
            "                              username=conf.admin_user,",
            "                              password=conf.admin_password,",
            "                              project_name=conf.admin_tenant_name,",
            "                              project_domain_id='default',",
            "                              user_domain_id='default')",
            "        return auth",
            "",
            "    @property",
            "    def client(self):",
            "        if self._client:",
            "            return self._client",
            "        client = kc_v3.Client(session=self.session,",
            "                              trust_id=self.context.trust_id)",
            "        self._client = client",
            "        return client",
            "",
            "    @property",
            "    def domain_admin_auth(self):",
            "        user_domain_id = (",
            "            CONF.trust.trustee_domain_admin_domain_id or",
            "            CONF.trust.trustee_domain_id",
            "        )",
            "        user_domain_name = (",
            "            CONF.trust.trustee_domain_admin_domain_name or",
            "            CONF.trust.trustee_domain_name",
            "        )",
            "        if not self._domain_admin_auth:",
            "            self._domain_admin_auth = ka_v3.Password(",
            "                auth_url=self.auth_url,",
            "                user_id=CONF.trust.trustee_domain_admin_id,",
            "                username=CONF.trust.trustee_domain_admin_name,",
            "                user_domain_id=user_domain_id,",
            "                user_domain_name=user_domain_name,",
            "                domain_id=CONF.trust.trustee_domain_id,",
            "                domain_name=CONF.trust.trustee_domain_name,",
            "                password=CONF.trust.trustee_domain_admin_password)",
            "        return self._domain_admin_auth",
            "",
            "    @property",
            "    def domain_admin_session(self):",
            "        if not self._domain_admin_session:",
            "            session = ka_loading.session.Session().load_from_options(",
            "                auth=self.domain_admin_auth,",
            "                insecure=CONF[ksconf.CFG_LEGACY_GROUP].insecure,",
            "                cacert=CONF[ksconf.CFG_LEGACY_GROUP].cafile,",
            "                key=CONF[ksconf.CFG_LEGACY_GROUP].keyfile,",
            "                cert=CONF[ksconf.CFG_LEGACY_GROUP].certfile)",
            "            self._domain_admin_session = session",
            "        return self._domain_admin_session",
            "",
            "    @property",
            "    def domain_admin_client(self):",
            "        if not self._domain_admin_client:",
            "            self._domain_admin_client = kc_v3.Client(",
            "                session=self.domain_admin_session",
            "            )",
            "        return self._domain_admin_client",
            "",
            "    @property",
            "    def trustee_domain_id(self):",
            "        if not self._trustee_domain_id:",
            "            try:",
            "                access = self.domain_admin_auth.get_access(",
            "                    self.domain_admin_session",
            "                )",
            "            except kc_exception.Unauthorized:",
            "                LOG.error(_LE(\"Keystone client authentication failed\"))",
            "                raise exception.AuthorizationFailure()",
            "",
            "            self._trustee_domain_id = access.domain_id",
            "",
            "        return self._trustee_domain_id",
            "",
            "    def create_trust(self, trustee_user):",
            "        trustor_user_id = self.session.get_user_id()",
            "        trustor_project_id = self.session.get_project_id()",
            "",
            "        # inherit the role of the trustor, unless set CONF.trust.roles",
            "        if CONF.trust.roles:",
            "            roles = CONF.trust.roles",
            "        else:",
            "            roles = self.context.roles",
            "",
            "        try:",
            "            trust = self.client.trusts.create(",
            "                trustor_user=trustor_user_id,",
            "                project=trustor_project_id,",
            "                trustee_user=trustee_user,",
            "                impersonation=True,",
            "                role_names=roles)",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to create trust'))",
            "            raise exception.TrustCreateFailed(",
            "                trustee_user_id=trustee_user)",
            "        return trust",
            "",
            "    def delete_trust(self, context, cluster):",
            "        if cluster.trust_id is None:",
            "            return",
            "",
            "        # Trust can only be deleted by the user who creates it. So when",
            "        # other users in the same project want to delete the cluster, we need",
            "        # use the trustee which can impersonate the trustor to delete the",
            "        # trust.",
            "        if context.user_id == cluster.user_id:",
            "            client = self.client",
            "        else:",
            "            auth = ka_v3.Password(auth_url=self.auth_url,",
            "                                  user_id=cluster.trustee_user_id,",
            "                                  password=cluster.trustee_password,",
            "                                  trust_id=cluster.trust_id)",
            "",
            "            sess = ka_loading.session.Session().load_from_options(",
            "                auth=auth,",
            "                insecure=CONF[ksconf.CFG_LEGACY_GROUP].insecure,",
            "                cacert=CONF[ksconf.CFG_LEGACY_GROUP].cafile,",
            "                key=CONF[ksconf.CFG_LEGACY_GROUP].keyfile,",
            "                cert=CONF[ksconf.CFG_LEGACY_GROUP].certfile)",
            "            client = kc_v3.Client(session=sess)",
            "        try:",
            "            client.trusts.delete(cluster.trust_id)",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to delete trust'))",
            "            raise exception.TrustDeleteFailed(trust_id=cluster.trust_id)",
            "",
            "    def create_trustee(self, username, password):",
            "        domain_id = self.trustee_domain_id",
            "        try:",
            "            user = self.domain_admin_client.users.create(",
            "                name=username,",
            "                password=password,",
            "                domain=domain_id)",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to create trustee'))",
            "            raise exception.TrusteeCreateFailed(username=username,",
            "                                                domain_id=domain_id)",
            "        return user",
            "",
            "    def delete_trustee(self, trustee_id):",
            "        try:",
            "            self.domain_admin_client.users.delete(trustee_id)",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to delete trustee'))",
            "            raise exception.TrusteeDeleteFailed(trustee_id=trustee_id)",
            "",
            "    def get_validate_region_name(self, region_name):",
            "        if region_name is None:",
            "            message = _(\"region_name needs to be configured in magnum.conf\")",
            "            raise exception.InvalidParameterValue(message)",
            "        \"\"\"matches the region of a public endpoint for the Keystone",
            "        service.\"\"\"",
            "        try:",
            "            regions = self.client.regions.list()",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to list regions'))",
            "            raise exception.RegionsListFailed()",
            "        region_list = []",
            "        for region in regions:",
            "            region_list.append(region.id)",
            "        if region_name not in region_list:",
            "            raise exception.InvalidParameterValue(_(",
            "                'region_name %(region_name)s is invalid, '",
            "                'expecting a region_name in %(region_name_list)s.') % {",
            "                    'region_name': region_name,",
            "                    'region_name_list': '/'.join(",
            "                        region_list + ['unspecified'])})",
            "        return region_name"
        ],
        "afterPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "from keystoneauth1.access import access as ka_access",
            "from keystoneauth1 import exceptions as ka_exception",
            "from keystoneauth1.identity import access as ka_access_plugin",
            "from keystoneauth1.identity import v3 as ka_v3",
            "from keystoneauth1 import loading as ka_loading",
            "import keystoneclient.exceptions as kc_exception",
            "from keystoneclient.v3 import client as kc_v3",
            "from oslo_log import log as logging",
            "",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.conf import keystone as ksconf",
            "from magnum.i18n import _",
            "from magnum.i18n import _LE",
            "from magnum.i18n import _LW",
            "",
            "CONF = magnum.conf.CONF",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "class KeystoneClientV3(object):",
            "    \"\"\"Keystone client wrapper so we can encapsulate logic in one place.\"\"\"",
            "",
            "    def __init__(self, context):",
            "        self.context = context",
            "        self._client = None",
            "        self._domain_admin_auth = None",
            "        self._domain_admin_session = None",
            "        self._domain_admin_client = None",
            "        self._trustee_domain_id = None",
            "        self._session = None",
            "",
            "    @property",
            "    def auth_url(self):",
            "        # FIXME(pauloewerton): auth_url should be retrieved from keystone_auth",
            "        # section by default",
            "        return CONF[ksconf.CFG_LEGACY_GROUP].auth_uri.replace('v2.0', 'v3')",
            "",
            "    @property",
            "    def auth_token(self):",
            "        return self.session.get_token()",
            "",
            "    @property",
            "    def session(self):",
            "        if self._session:",
            "            return self._session",
            "        auth = self._get_auth()",
            "        session = self._get_session(auth)",
            "        self._session = session",
            "        return session",
            "",
            "    def _get_session(self, auth):",
            "        session = ka_loading.load_session_from_conf_options(",
            "            CONF, ksconf.CFG_GROUP, auth=auth)",
            "        return session",
            "",
            "    def _get_auth(self):",
            "        if self.context.is_admin:",
            "            try:",
            "                auth = ka_loading.load_auth_from_conf_options(",
            "                    CONF, ksconf.CFG_GROUP)",
            "            except ka_exception.MissingRequiredOptions:",
            "                auth = self._get_legacy_auth()",
            "        elif self.context.auth_token_info:",
            "            access_info = ka_access.create(body=self.context.auth_token_info,",
            "                                           auth_token=self.context.auth_token)",
            "            auth = ka_access_plugin.AccessInfoPlugin(access_info)",
            "        elif self.context.auth_token:",
            "            auth = ka_v3.Token(auth_url=self.auth_url,",
            "                               token=self.context.auth_token)",
            "        elif self.context.trust_id:",
            "            auth_info = {",
            "                'auth_url': self.auth_url,",
            "                'username': self.context.user_name,",
            "                'password': self.context.password,",
            "                'user_domain_id': self.context.user_domain_id,",
            "                'user_domain_name': self.context.user_domain_name,",
            "                'trust_id': self.context.trust_id",
            "            }",
            "",
            "            auth = ka_v3.Password(**auth_info)",
            "",
            "        else:",
            "            LOG.error(_LE('Keystone API connection failed: no password, '",
            "                          'trust_id or token found.'))",
            "            raise exception.AuthorizationFailure()",
            "",
            "        return auth",
            "",
            "    def _get_legacy_auth(self):",
            "        LOG.warning(_LW('Auth plugin and its options for service user '",
            "                        'must be provided in [%(new)s] section. '",
            "                        'Using values from [%(old)s] section is '",
            "                        'deprecated.'), {'new': ksconf.CFG_GROUP,",
            "                                         'old': ksconf.CFG_LEGACY_GROUP})",
            "",
            "        conf = getattr(CONF, ksconf.CFG_LEGACY_GROUP)",
            "",
            "        # FIXME(htruta, pauloewerton): Conductor layer does not have",
            "        # new v3 variables, such as project_name and project_domain_id.",
            "        # The use of admin_* variables is related to Identity API v2.0,",
            "        # which is now deprecated. We should also stop using hard-coded",
            "        # domain info, as well as variables that refer to `tenant`,",
            "        # as they are also v2 related.",
            "        auth = ka_v3.Password(auth_url=self.auth_url,",
            "                              username=conf.admin_user,",
            "                              password=conf.admin_password,",
            "                              project_name=conf.admin_tenant_name,",
            "                              project_domain_id='default',",
            "                              user_domain_id='default')",
            "        return auth",
            "",
            "    @property",
            "    def client(self):",
            "        if self._client:",
            "            return self._client",
            "        client = kc_v3.Client(session=self.session,",
            "                              trust_id=self.context.trust_id)",
            "        self._client = client",
            "        return client",
            "",
            "    @property",
            "    def domain_admin_auth(self):",
            "        user_domain_id = (",
            "            CONF.trust.trustee_domain_admin_domain_id or",
            "            CONF.trust.trustee_domain_id",
            "        )",
            "        user_domain_name = (",
            "            CONF.trust.trustee_domain_admin_domain_name or",
            "            CONF.trust.trustee_domain_name",
            "        )",
            "        if not self._domain_admin_auth:",
            "            self._domain_admin_auth = ka_v3.Password(",
            "                auth_url=self.auth_url,",
            "                user_id=CONF.trust.trustee_domain_admin_id,",
            "                username=CONF.trust.trustee_domain_admin_name,",
            "                user_domain_id=user_domain_id,",
            "                user_domain_name=user_domain_name,",
            "                domain_id=CONF.trust.trustee_domain_id,",
            "                domain_name=CONF.trust.trustee_domain_name,",
            "                password=CONF.trust.trustee_domain_admin_password)",
            "        return self._domain_admin_auth",
            "",
            "    @property",
            "    def domain_admin_session(self):",
            "        if not self._domain_admin_session:",
            "            session = ka_loading.session.Session().load_from_options(",
            "                auth=self.domain_admin_auth,",
            "                insecure=CONF[ksconf.CFG_LEGACY_GROUP].insecure,",
            "                cacert=CONF[ksconf.CFG_LEGACY_GROUP].cafile,",
            "                key=CONF[ksconf.CFG_LEGACY_GROUP].keyfile,",
            "                cert=CONF[ksconf.CFG_LEGACY_GROUP].certfile)",
            "            self._domain_admin_session = session",
            "        return self._domain_admin_session",
            "",
            "    @property",
            "    def domain_admin_client(self):",
            "        if not self._domain_admin_client:",
            "            self._domain_admin_client = kc_v3.Client(",
            "                session=self.domain_admin_session",
            "            )",
            "        return self._domain_admin_client",
            "",
            "    @property",
            "    def trustee_domain_id(self):",
            "        if not self._trustee_domain_id:",
            "            try:",
            "                access = self.domain_admin_auth.get_access(",
            "                    self.domain_admin_session",
            "                )",
            "            except kc_exception.Unauthorized:",
            "                LOG.error(_LE(\"Keystone client authentication failed\"))",
            "                raise exception.AuthorizationFailure()",
            "",
            "            self._trustee_domain_id = access.domain_id",
            "",
            "        return self._trustee_domain_id",
            "",
            "    def create_trust(self, trustee_user):",
            "        trustor_user_id = self.session.get_user_id()",
            "        trustor_project_id = self.session.get_project_id()",
            "",
            "        # inherit the role of the trustor, unless set CONF.trust.roles",
            "        if CONF.trust.roles:",
            "            roles = CONF.trust.roles",
            "        else:",
            "            roles = self.context.roles",
            "",
            "        try:",
            "            trust = self.client.trusts.create(",
            "                trustor_user=trustor_user_id,",
            "                project=trustor_project_id,",
            "                trustee_user=trustee_user,",
            "                impersonation=True,",
            "                delegation_depth=0,",
            "                role_names=roles)",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to create trust'))",
            "            raise exception.TrustCreateFailed(",
            "                trustee_user_id=trustee_user)",
            "        return trust",
            "",
            "    def delete_trust(self, context, cluster):",
            "        if cluster.trust_id is None:",
            "            return",
            "",
            "        # Trust can only be deleted by the user who creates it. So when",
            "        # other users in the same project want to delete the cluster, we need",
            "        # use the trustee which can impersonate the trustor to delete the",
            "        # trust.",
            "        if context.user_id == cluster.user_id:",
            "            client = self.client",
            "        else:",
            "            auth = ka_v3.Password(auth_url=self.auth_url,",
            "                                  user_id=cluster.trustee_user_id,",
            "                                  password=cluster.trustee_password,",
            "                                  trust_id=cluster.trust_id)",
            "",
            "            sess = ka_loading.session.Session().load_from_options(",
            "                auth=auth,",
            "                insecure=CONF[ksconf.CFG_LEGACY_GROUP].insecure,",
            "                cacert=CONF[ksconf.CFG_LEGACY_GROUP].cafile,",
            "                key=CONF[ksconf.CFG_LEGACY_GROUP].keyfile,",
            "                cert=CONF[ksconf.CFG_LEGACY_GROUP].certfile)",
            "            client = kc_v3.Client(session=sess)",
            "        try:",
            "            client.trusts.delete(cluster.trust_id)",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to delete trust'))",
            "            raise exception.TrustDeleteFailed(trust_id=cluster.trust_id)",
            "",
            "    def create_trustee(self, username, password):",
            "        domain_id = self.trustee_domain_id",
            "        try:",
            "            user = self.domain_admin_client.users.create(",
            "                name=username,",
            "                password=password,",
            "                domain=domain_id)",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to create trustee'))",
            "            raise exception.TrusteeCreateFailed(username=username,",
            "                                                domain_id=domain_id)",
            "        return user",
            "",
            "    def delete_trustee(self, trustee_id):",
            "        try:",
            "            self.domain_admin_client.users.delete(trustee_id)",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to delete trustee'))",
            "            raise exception.TrusteeDeleteFailed(trustee_id=trustee_id)",
            "",
            "    def get_validate_region_name(self, region_name):",
            "        if region_name is None:",
            "            message = _(\"region_name needs to be configured in magnum.conf\")",
            "            raise exception.InvalidParameterValue(message)",
            "        \"\"\"matches the region of a public endpoint for the Keystone",
            "        service.\"\"\"",
            "        try:",
            "            regions = self.client.regions.list()",
            "        except kc_exception.NotFound:",
            "            pass",
            "        except Exception:",
            "            LOG.exception(_LE('Failed to list regions'))",
            "            raise exception.RegionsListFailed()",
            "        region_list = []",
            "        for region in regions:",
            "            region_list.append(region.id)",
            "        if region_name not in region_list:",
            "            raise exception.InvalidParameterValue(_(",
            "                'region_name %(region_name)s is invalid, '",
            "                'expecting a region_name in %(region_name_list)s.') % {",
            "                    'region_name': region_name,",
            "                    'region_name_list': '/'.join(",
            "                        region_list + ['unspecified'])})",
            "        return region_name"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "magnum/common/policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from oslo_policy import policy"
            },
            "1": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " import pecan"
            },
            "2": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from magnum.common import clients"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from magnum.common import context"
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from magnum.common import exception"
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "     if target is None:"
            },
            "9": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "         target = {'project_id': context.project_id,"
            },
            "10": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "                   'user_id': context.user_id}"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+    add_policy_attributes(target)"
            },
            "12": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "     return enforcer.enforce(rule, target, credentials,"
            },
            "13": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 99,
                "PatchRowcode": "                             do_raise=do_raise, exc=exc, *args, **kwargs)"
            },
            "14": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 100,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 101,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+def add_policy_attributes(target):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    \"\"\"Adds extra information for policy enforcement to raw target object\"\"\""
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+    admin_context = context.make_admin_context()"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+    admin_osc = clients.OpenStackClients(admin_context)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+    trustee_domain_id = admin_osc.keystone().trustee_domain_id"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+    target['trustee_domain_id'] = trustee_domain_id"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+    return target"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 111,
                "PatchRowcode": " def enforce_wsgi(api_name, act=None):"
            },
            "26": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 112,
                "PatchRowcode": "     \"\"\"This is a decorator to simplify wsgi action policy rule check."
            },
            "27": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 113,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2015 OpenStack Foundation",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"Policy Engine For magnum.\"\"\"",
            "",
            "import decorator",
            "from oslo_config import cfg",
            "from oslo_policy import policy",
            "import pecan",
            "",
            "from magnum.common import exception",
            "",
            "",
            "_ENFORCER = None",
            "CONF = cfg.CONF",
            "",
            "",
            "# we can get a policy enforcer by this init.",
            "# oslo policy support change policy rule dynamically.",
            "# at present, policy.enforce will reload the policy rules when it checks",
            "# the policy files have been touched.",
            "def init(policy_file=None, rules=None,",
            "         default_rule=None, use_conf=True, overwrite=True):",
            "    \"\"\"Init an Enforcer class.",
            "",
            "        :param policy_file: Custom policy file to use, if none is",
            "                            specified, ``conf.policy_file`` will be",
            "                            used.",
            "        :param rules: Default dictionary / Rules to use. It will be",
            "                      considered just in the first instantiation. If",
            "                      :meth:`load_rules` with ``force_reload=True``,",
            "                      :meth:`clear` or :meth:`set_rules` with",
            "                      ``overwrite=True`` is called this will be overwritten.",
            "        :param default_rule: Default rule to use, conf.default_rule will",
            "                             be used if none is specified.",
            "        :param use_conf: Whether to load rules from cache or config file.",
            "        :param overwrite: Whether to overwrite existing rules when reload rules",
            "                          from config file.",
            "    \"\"\"",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        # http://docs.openstack.org/developer/oslo.policy/usage.html",
            "        _ENFORCER = policy.Enforcer(CONF,",
            "                                    policy_file=policy_file,",
            "                                    rules=rules,",
            "                                    default_rule=default_rule,",
            "                                    use_conf=use_conf,",
            "                                    overwrite=overwrite)",
            "    return _ENFORCER",
            "",
            "",
            "def enforce(context, rule=None, target=None,",
            "            do_raise=True, exc=None, *args, **kwargs):",
            "",
            "    \"\"\"Checks authorization of a rule against the target and credentials.",
            "",
            "        :param dict context: As much information about the user performing the",
            "                             action as possible.",
            "        :param rule: The rule to evaluate.",
            "        :param dict target: As much information about the object being operated",
            "                            on as possible.",
            "        :param do_raise: Whether to raise an exception or not if check",
            "                         fails.",
            "        :param exc: Class of the exception to raise if the check fails.",
            "                    Any remaining arguments passed to :meth:`enforce` (both",
            "                    positional and keyword arguments) will be passed to",
            "                    the exception class. If not specified,",
            "                    :class:`PolicyNotAuthorized` will be used.",
            "",
            "        :return: ``False`` if the policy does not allow the action and `exc` is",
            "                 not provided; otherwise, returns a value that evaluates to",
            "                 ``True``.  Note: for rules using the \"case\" expression, this",
            "                 ``True`` value will be the specified string from the",
            "                 expression.",
            "    \"\"\"",
            "    enforcer = init()",
            "    credentials = context.to_dict()",
            "    if not exc:",
            "        exc = exception.PolicyNotAuthorized",
            "    if target is None:",
            "        target = {'project_id': context.project_id,",
            "                  'user_id': context.user_id}",
            "    return enforcer.enforce(rule, target, credentials,",
            "                            do_raise=do_raise, exc=exc, *args, **kwargs)",
            "",
            "",
            "def enforce_wsgi(api_name, act=None):",
            "    \"\"\"This is a decorator to simplify wsgi action policy rule check.",
            "",
            "        :param api_name: The collection name to be evaluate.",
            "        :param act: The function name of wsgi action.",
            "",
            "       example:",
            "           from magnum.common import policy",
            "           class ClustersController(rest.RestController):",
            "               ....",
            "               @policy.enforce_wsgi(\"cluster\", \"delete\")",
            "               @wsme_pecan.wsexpose(None, types.uuid_or_name, status_code=204)",
            "               def delete(self, cluster_ident):",
            "                   ...",
            "    \"\"\"",
            "    @decorator.decorator",
            "    def wrapper(fn, *args, **kwargs):",
            "        action = \"%s:%s\" % (api_name, (act or fn.__name__))",
            "        enforce(pecan.request.context, action,",
            "                exc=exception.PolicyNotAuthorized, action=action)",
            "        return fn(*args, **kwargs)",
            "    return wrapper"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2015 OpenStack Foundation",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"Policy Engine For magnum.\"\"\"",
            "",
            "import decorator",
            "from oslo_config import cfg",
            "from oslo_policy import policy",
            "import pecan",
            "",
            "from magnum.common import clients",
            "from magnum.common import context",
            "from magnum.common import exception",
            "",
            "",
            "_ENFORCER = None",
            "CONF = cfg.CONF",
            "",
            "",
            "# we can get a policy enforcer by this init.",
            "# oslo policy support change policy rule dynamically.",
            "# at present, policy.enforce will reload the policy rules when it checks",
            "# the policy files have been touched.",
            "def init(policy_file=None, rules=None,",
            "         default_rule=None, use_conf=True, overwrite=True):",
            "    \"\"\"Init an Enforcer class.",
            "",
            "        :param policy_file: Custom policy file to use, if none is",
            "                            specified, ``conf.policy_file`` will be",
            "                            used.",
            "        :param rules: Default dictionary / Rules to use. It will be",
            "                      considered just in the first instantiation. If",
            "                      :meth:`load_rules` with ``force_reload=True``,",
            "                      :meth:`clear` or :meth:`set_rules` with",
            "                      ``overwrite=True`` is called this will be overwritten.",
            "        :param default_rule: Default rule to use, conf.default_rule will",
            "                             be used if none is specified.",
            "        :param use_conf: Whether to load rules from cache or config file.",
            "        :param overwrite: Whether to overwrite existing rules when reload rules",
            "                          from config file.",
            "    \"\"\"",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        # http://docs.openstack.org/developer/oslo.policy/usage.html",
            "        _ENFORCER = policy.Enforcer(CONF,",
            "                                    policy_file=policy_file,",
            "                                    rules=rules,",
            "                                    default_rule=default_rule,",
            "                                    use_conf=use_conf,",
            "                                    overwrite=overwrite)",
            "    return _ENFORCER",
            "",
            "",
            "def enforce(context, rule=None, target=None,",
            "            do_raise=True, exc=None, *args, **kwargs):",
            "",
            "    \"\"\"Checks authorization of a rule against the target and credentials.",
            "",
            "        :param dict context: As much information about the user performing the",
            "                             action as possible.",
            "        :param rule: The rule to evaluate.",
            "        :param dict target: As much information about the object being operated",
            "                            on as possible.",
            "        :param do_raise: Whether to raise an exception or not if check",
            "                         fails.",
            "        :param exc: Class of the exception to raise if the check fails.",
            "                    Any remaining arguments passed to :meth:`enforce` (both",
            "                    positional and keyword arguments) will be passed to",
            "                    the exception class. If not specified,",
            "                    :class:`PolicyNotAuthorized` will be used.",
            "",
            "        :return: ``False`` if the policy does not allow the action and `exc` is",
            "                 not provided; otherwise, returns a value that evaluates to",
            "                 ``True``.  Note: for rules using the \"case\" expression, this",
            "                 ``True`` value will be the specified string from the",
            "                 expression.",
            "    \"\"\"",
            "    enforcer = init()",
            "    credentials = context.to_dict()",
            "    if not exc:",
            "        exc = exception.PolicyNotAuthorized",
            "    if target is None:",
            "        target = {'project_id': context.project_id,",
            "                  'user_id': context.user_id}",
            "    add_policy_attributes(target)",
            "    return enforcer.enforce(rule, target, credentials,",
            "                            do_raise=do_raise, exc=exc, *args, **kwargs)",
            "",
            "",
            "def add_policy_attributes(target):",
            "    \"\"\"Adds extra information for policy enforcement to raw target object\"\"\"",
            "    admin_context = context.make_admin_context()",
            "    admin_osc = clients.OpenStackClients(admin_context)",
            "    trustee_domain_id = admin_osc.keystone().trustee_domain_id",
            "    target['trustee_domain_id'] = trustee_domain_id",
            "    return target",
            "",
            "",
            "def enforce_wsgi(api_name, act=None):",
            "    \"\"\"This is a decorator to simplify wsgi action policy rule check.",
            "",
            "        :param api_name: The collection name to be evaluate.",
            "        :param act: The function name of wsgi action.",
            "",
            "       example:",
            "           from magnum.common import policy",
            "           class ClustersController(rest.RestController):",
            "               ....",
            "               @policy.enforce_wsgi(\"cluster\", \"delete\")",
            "               @wsme_pecan.wsexpose(None, types.uuid_or_name, status_code=204)",
            "               def delete(self, cluster_ident):",
            "                   ...",
            "    \"\"\"",
            "    @decorator.decorator",
            "    def wrapper(fn, *args, **kwargs):",
            "        action = \"%s:%s\" % (api_name, (act or fn.__name__))",
            "        enforce(pecan.request.context, action,",
            "                exc=exception.PolicyNotAuthorized, action=action)",
            "        return fn(*args, **kwargs)",
            "    return wrapper"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "magnum.common.policy.enforce.target",
            "magnum.common.policy.enforce"
        ]
    },
    "magnum/conductor/handlers/common/trust_manager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " def create_trustee_and_trust(osc, cluster):"
            },
            "1": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "     try:"
            },
            "2": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": "         password = utils.generate_password(length=18)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": "         trustee = osc.keystone().create_trustee("
            },
            "5": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            cluster.uuid,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+            \"%s_%s\" % (cluster.uuid, cluster.project_id),"
            },
            "7": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "             password,"
            },
            "8": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": "         )"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+"
            },
            "10": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "         cluster.trustee_username = trustee.name"
            },
            "11": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "         cluster.trustee_user_id = trustee.id"
            },
            "12": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "         cluster.trustee_password = password"
            },
            "13": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        trust = osc.keystone().create_trust(trustee.id)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+        trust = osc.keystone().create_trust("
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+            cluster.trustee_user_id)"
            },
            "17": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         cluster.trust_id = trust.id"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     except Exception:"
            },
            "20": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "         LOG.exception("
            },
            "21": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "             _LE('Failed to create trustee and trust for Cluster: %s'),"
            },
            "22": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " def delete_trustee_and_trust(osc, context, cluster):"
            },
            "24": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "     try:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+        kst = osc.keystone()"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "         # The cluster which is upgraded from Liberty doesn't have trust_id"
            },
            "28": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "         if cluster.trust_id:"
            },
            "29": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            osc.keystone().delete_trust(context, cluster)"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+            kst.delete_trust(context, cluster)"
            },
            "31": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "     except Exception:"
            },
            "32": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "         # Exceptions are already logged by keystone().delete_trust"
            },
            "33": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "         pass"
            }
        },
        "frontPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "from oslo_log import log as logging",
            "",
            "from magnum.common import exception",
            "from magnum.common import utils",
            "from magnum.i18n import _LE",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "def create_trustee_and_trust(osc, cluster):",
            "    try:",
            "        password = utils.generate_password(length=18)",
            "        trustee = osc.keystone().create_trustee(",
            "            cluster.uuid,",
            "            password,",
            "        )",
            "        cluster.trustee_username = trustee.name",
            "        cluster.trustee_user_id = trustee.id",
            "        cluster.trustee_password = password",
            "        trust = osc.keystone().create_trust(trustee.id)",
            "        cluster.trust_id = trust.id",
            "    except Exception:",
            "        LOG.exception(",
            "            _LE('Failed to create trustee and trust for Cluster: %s'),",
            "            cluster.uuid)",
            "        raise exception.TrusteeOrTrustToClusterFailed(",
            "            cluster_uuid=cluster.uuid)",
            "",
            "",
            "def delete_trustee_and_trust(osc, context, cluster):",
            "    try:",
            "        # The cluster which is upgraded from Liberty doesn't have trust_id",
            "        if cluster.trust_id:",
            "            osc.keystone().delete_trust(context, cluster)",
            "    except Exception:",
            "        # Exceptions are already logged by keystone().delete_trust",
            "        pass",
            "    try:",
            "        # The cluster which is upgraded from Liberty doesn't have",
            "        # trustee_user_id",
            "        if cluster.trustee_user_id:",
            "            osc.keystone().delete_trustee(cluster.trustee_user_id)",
            "    except Exception:",
            "        # Exceptions are already logged by keystone().delete_trustee",
            "        pass"
        ],
        "afterPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "from oslo_log import log as logging",
            "",
            "from magnum.common import exception",
            "from magnum.common import utils",
            "from magnum.i18n import _LE",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "def create_trustee_and_trust(osc, cluster):",
            "    try:",
            "        password = utils.generate_password(length=18)",
            "",
            "        trustee = osc.keystone().create_trustee(",
            "            \"%s_%s\" % (cluster.uuid, cluster.project_id),",
            "            password,",
            "        )",
            "",
            "        cluster.trustee_username = trustee.name",
            "        cluster.trustee_user_id = trustee.id",
            "        cluster.trustee_password = password",
            "",
            "        trust = osc.keystone().create_trust(",
            "            cluster.trustee_user_id)",
            "        cluster.trust_id = trust.id",
            "",
            "    except Exception:",
            "        LOG.exception(",
            "            _LE('Failed to create trustee and trust for Cluster: %s'),",
            "            cluster.uuid)",
            "        raise exception.TrusteeOrTrustToClusterFailed(",
            "            cluster_uuid=cluster.uuid)",
            "",
            "",
            "def delete_trustee_and_trust(osc, context, cluster):",
            "    try:",
            "        kst = osc.keystone()",
            "",
            "        # The cluster which is upgraded from Liberty doesn't have trust_id",
            "        if cluster.trust_id:",
            "            kst.delete_trust(context, cluster)",
            "    except Exception:",
            "        # Exceptions are already logged by keystone().delete_trust",
            "        pass",
            "    try:",
            "        # The cluster which is upgraded from Liberty doesn't have",
            "        # trustee_user_id",
            "        if cluster.trustee_user_id:",
            "            osc.keystone().delete_trustee(cluster.trustee_user_id)",
            "    except Exception:",
            "        # Exceptions are already logged by keystone().delete_trustee",
            "        pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "26": [
                "create_trustee_and_trust"
            ],
            "32": [
                "create_trustee_and_trust"
            ],
            "46": [
                "delete_trustee_and_trust"
            ]
        },
        "addLocation": []
    },
    "magnum/conf/trust.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": "                            title='Trustee options for the magnum services')"
            },
            "1": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " trust_opts = ["
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+    cfg.BoolOpt('cluster_user_trust',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+                default=False,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+                help=_('This setting controls whether to assign a trust to'"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+                       ' the cluster user or not. You will need to set it to'"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+                       ' True for clusters with volume_driver=cinder or'"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+                       ' registry_enabled=true in the underlying cluster'"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+                       ' template to work. This is a potential security risk'"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+                       ' since the trust gives instances OpenStack API access'"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+                       \" to the cluster's project. Note that this setting\""
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+                       ' does not affect per-cluster trusts assigned to the'"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+                       'Magnum service user.')),"
            },
            "14": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "     cfg.StrOpt('trustee_domain_id',"
            },
            "15": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "                help=_('Id of the domain to create trustee for clusters')),"
            },
            "16": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "     cfg.StrOpt('trustee_domain_name',"
            }
        },
        "frontPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not",
            "# use this file except in compliance with the License. You may obtain a copy",
            "# of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "from oslo_config import cfg",
            "",
            "from magnum.i18n import _",
            "",
            "trust_group = cfg.OptGroup(name='trust',",
            "                           title='Trustee options for the magnum services')",
            "",
            "trust_opts = [",
            "    cfg.StrOpt('trustee_domain_id',",
            "               help=_('Id of the domain to create trustee for clusters')),",
            "    cfg.StrOpt('trustee_domain_name',",
            "               help=_('Name of the domain to create trustee for s')),",
            "    cfg.StrOpt('trustee_domain_admin_id',",
            "               help=_('Id of the admin with roles sufficient to manage users'",
            "                      ' in the trustee_domain')),",
            "    cfg.StrOpt('trustee_domain_admin_name',",
            "               help=_('Name of the admin with roles sufficient to manage users'",
            "                      ' in the trustee_domain')),",
            "    cfg.StrOpt('trustee_domain_admin_domain_id',",
            "               help=_('Id of the domain admin user\\'s domain.'",
            "                      ' trustee_domain_id is used by default')),",
            "    cfg.StrOpt('trustee_domain_admin_domain_name',",
            "               help=_('Name of the domain admin user\\'s domain.'",
            "                      ' trustee_domain_name is used by default')),",
            "    cfg.StrOpt('trustee_domain_admin_password', secret=True,",
            "               help=_('Password of trustee_domain_admin')),",
            "    cfg.ListOpt('roles',",
            "                default=[],",
            "                help=_('The roles which are delegated to the trustee '",
            "                       'by the trustor'))",
            "]",
            "",
            "",
            "def register_opts(conf):",
            "    conf.register_group(trust_group)",
            "    conf.register_opts(trust_opts, group=trust_group)",
            "",
            "",
            "def list_opts():",
            "    return {",
            "        trust_group: trust_opts",
            "    }"
        ],
        "afterPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not",
            "# use this file except in compliance with the License. You may obtain a copy",
            "# of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "from oslo_config import cfg",
            "",
            "from magnum.i18n import _",
            "",
            "trust_group = cfg.OptGroup(name='trust',",
            "                           title='Trustee options for the magnum services')",
            "",
            "trust_opts = [",
            "    cfg.BoolOpt('cluster_user_trust',",
            "                default=False,",
            "                help=_('This setting controls whether to assign a trust to'",
            "                       ' the cluster user or not. You will need to set it to'",
            "                       ' True for clusters with volume_driver=cinder or'",
            "                       ' registry_enabled=true in the underlying cluster'",
            "                       ' template to work. This is a potential security risk'",
            "                       ' since the trust gives instances OpenStack API access'",
            "                       \" to the cluster's project. Note that this setting\"",
            "                       ' does not affect per-cluster trusts assigned to the'",
            "                       'Magnum service user.')),",
            "    cfg.StrOpt('trustee_domain_id',",
            "               help=_('Id of the domain to create trustee for clusters')),",
            "    cfg.StrOpt('trustee_domain_name',",
            "               help=_('Name of the domain to create trustee for s')),",
            "    cfg.StrOpt('trustee_domain_admin_id',",
            "               help=_('Id of the admin with roles sufficient to manage users'",
            "                      ' in the trustee_domain')),",
            "    cfg.StrOpt('trustee_domain_admin_name',",
            "               help=_('Name of the admin with roles sufficient to manage users'",
            "                      ' in the trustee_domain')),",
            "    cfg.StrOpt('trustee_domain_admin_domain_id',",
            "               help=_('Id of the domain admin user\\'s domain.'",
            "                      ' trustee_domain_id is used by default')),",
            "    cfg.StrOpt('trustee_domain_admin_domain_name',",
            "               help=_('Name of the domain admin user\\'s domain.'",
            "                      ' trustee_domain_name is used by default')),",
            "    cfg.StrOpt('trustee_domain_admin_password', secret=True,",
            "               help=_('Password of trustee_domain_admin')),",
            "    cfg.ListOpt('roles',",
            "                default=[],",
            "                help=_('The roles which are delegated to the trustee '",
            "                       'by the trustor'))",
            "]",
            "",
            "",
            "def register_opts(conf):",
            "    conf.register_group(trust_group)",
            "    conf.register_opts(trust_opts, group=trust_group)",
            "",
            "",
            "def list_opts():",
            "    return {",
            "        trust_group: trust_opts",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "magnum/db/sqlalchemy/api.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from sqlalchemy.orm.exc import NoResultFound"
            },
            "1": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from sqlalchemy.sql import func"
            },
            "2": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+from magnum.common import clients"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+from magnum.common import context as request_context"
            },
            "5": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from magnum.common import exception"
            },
            "6": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " import magnum.conf"
            },
            "7": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " from magnum.db import api"
            },
            "8": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "         if context.is_admin and context.all_tenants:"
            },
            "9": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "             return query"
            },
            "10": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 126,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if context.project_id:"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+        admin_context = request_context.make_admin_context(all_tenants=True)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+        osc = clients.OpenStackClients(admin_context)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+        kst = osc.keystone()"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+        # User in a regular project (not in the trustee domain)"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+        if context.project_id and context.domain_id != kst.trustee_domain_id:"
            },
            "18": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "             query = query.filter_by(project_id=context.project_id)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+        # Match project ID component in trustee user's user name against"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+        # cluster's project_id to associate per-cluster trustee users who have"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+        # no project information with the project their clusters/cluster models"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+        # reside in. This is equivalent to the project filtering above."
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+        elif context.domain_id == kst.trustee_domain_id:"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+            user_name = kst.client.users.get(context.user_id).name"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+            user_project = user_name.split('_', 2)[1]"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+            query = query.filter_by(project_id=user_project)"
            },
            "27": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "         else:"
            },
            "28": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "             query = query.filter_by(user_id=context.user_id)"
            },
            "29": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 144,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright 2013 Hewlett-Packard Development Company, L.P.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "\"\"\"SQLAlchemy storage backend.\"\"\"",
            "",
            "from oslo_db import exception as db_exc",
            "from oslo_db.sqlalchemy import session as db_session",
            "from oslo_db.sqlalchemy import utils as db_utils",
            "from oslo_utils import importutils",
            "from oslo_utils import strutils",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import sqlalchemy as sa",
            "from sqlalchemy.orm.exc import MultipleResultsFound",
            "from sqlalchemy.orm.exc import NoResultFound",
            "from sqlalchemy.sql import func",
            "",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.db import api",
            "from magnum.db.sqlalchemy import models",
            "from magnum.i18n import _",
            "",
            "profiler_sqlalchemy = importutils.try_import('osprofiler.sqlalchemy')",
            "",
            "CONF = magnum.conf.CONF",
            "",
            "",
            "_FACADE = None",
            "",
            "",
            "def _create_facade_lazily():",
            "    global _FACADE",
            "    if _FACADE is None:",
            "        _FACADE = db_session.EngineFacade.from_config(CONF)",
            "        if profiler_sqlalchemy:",
            "            if CONF.profiler.enabled and CONF.profiler.trace_sqlalchemy:",
            "                profiler_sqlalchemy.add_tracing(sa, _FACADE.get_engine(), \"db\")",
            "",
            "    return _FACADE",
            "",
            "",
            "def get_engine():",
            "    facade = _create_facade_lazily()",
            "    return facade.get_engine()",
            "",
            "",
            "def get_session(**kwargs):",
            "    facade = _create_facade_lazily()",
            "    return facade.get_session(**kwargs)",
            "",
            "",
            "def get_backend():",
            "    \"\"\"The backend is this module itself.\"\"\"",
            "    return Connection()",
            "",
            "",
            "def model_query(model, *args, **kwargs):",
            "    \"\"\"Query helper for simpler session usage.",
            "",
            "    :param session: if present, the session to use",
            "    \"\"\"",
            "",
            "    session = kwargs.get('session') or get_session()",
            "    query = session.query(model, *args)",
            "    return query",
            "",
            "",
            "def add_identity_filter(query, value):",
            "    \"\"\"Adds an identity filter to a query.",
            "",
            "    Filters results by ID, if supplied value is a valid integer.",
            "    Otherwise attempts to filter results by UUID.",
            "",
            "    :param query: Initial query to add filter to.",
            "    :param value: Value for filtering results by.",
            "    :return: Modified query.",
            "    \"\"\"",
            "    if strutils.is_int_like(value):",
            "        return query.filter_by(id=value)",
            "    elif uuidutils.is_uuid_like(value):",
            "        return query.filter_by(uuid=value)",
            "    else:",
            "        raise exception.InvalidIdentity(identity=value)",
            "",
            "",
            "def _paginate_query(model, limit=None, marker=None, sort_key=None,",
            "                    sort_dir=None, query=None):",
            "    if not query:",
            "        query = model_query(model)",
            "    sort_keys = ['id']",
            "    if sort_key and sort_key not in sort_keys:",
            "        sort_keys.insert(0, sort_key)",
            "    try:",
            "        query = db_utils.paginate_query(query, model, limit, sort_keys,",
            "                                        marker=marker, sort_dir=sort_dir)",
            "    except db_exc.InvalidSortKey:",
            "        raise exception.InvalidParameterValue(",
            "            _('The sort_key value \"%(key)s\" is an invalid field for sorting')",
            "            % {'key': sort_key})",
            "    return query.all()",
            "",
            "",
            "class Connection(api.Connection):",
            "    \"\"\"SqlAlchemy connection.\"\"\"",
            "",
            "    def __init__(self):",
            "        pass",
            "",
            "    def _add_tenant_filters(self, context, query):",
            "        if context.is_admin and context.all_tenants:",
            "            return query",
            "",
            "        if context.project_id:",
            "            query = query.filter_by(project_id=context.project_id)",
            "        else:",
            "            query = query.filter_by(user_id=context.user_id)",
            "",
            "        return query",
            "",
            "    def _add_clusters_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"cluster_template_id\", \"name\", \"node_count\",",
            "                            \"master_count\", \"stack_id\", \"api_address\",",
            "                            \"node_addresses\", \"project_id\", \"user_id\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        query = query.filter_by(**filter_dict)",
            "",
            "        if 'status' in filters:",
            "            query = query.filter(models.Cluster.status.in_(filters['status']))",
            "",
            "        return query",
            "",
            "    def get_cluster_list(self, context, filters=None, limit=None, marker=None,",
            "                         sort_key=None, sort_dir=None):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_clusters_filters(query, filters)",
            "        return _paginate_query(models.Cluster, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_cluster(self, values):",
            "        # ensure defaults are present for new clusters",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        cluster = models.Cluster()",
            "        cluster.update(values)",
            "        try:",
            "            cluster.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.ClusterAlreadyExists(uuid=values['uuid'])",
            "        return cluster",
            "",
            "    def get_cluster_by_id(self, context, cluster_id):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(id=cluster_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "    def get_cluster_by_name(self, context, cluster_name):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(name=cluster_name)",
            "        try:",
            "            return query.one()",
            "        except MultipleResultsFound:",
            "            raise exception.Conflict('Multiple clusters exist with same name.'",
            "                                     ' Please use the cluster uuid instead.')",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_name)",
            "",
            "    def get_cluster_by_uuid(self, context, cluster_uuid):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(uuid=cluster_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_uuid)",
            "",
            "    def get_cluster_stats(self, context, project_id=None):",
            "        query = model_query(models.Cluster)",
            "        node_count_col = models.Cluster.node_count",
            "        master_count_col = models.Cluster.master_count",
            "        ncfunc = func.sum(node_count_col + master_count_col)",
            "",
            "        if project_id:",
            "            query = query.filter_by(project_id=project_id)",
            "            nquery = query.session.query(ncfunc.label(\"nodes\")).filter_by(",
            "                project_id=project_id)",
            "        else:",
            "            nquery = query.session.query(ncfunc.label(\"nodes\"))",
            "",
            "        clusters = query.count()",
            "        nodes = int(nquery.one()[0]) if nquery.one()[0] else 0",
            "        return clusters, nodes",
            "",
            "    def get_cluster_count_all(self, context, filters=None):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_clusters_filters(query, filters)",
            "        return query.count()",
            "",
            "    def destroy_cluster(self, cluster_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Cluster, session=session)",
            "            query = add_identity_filter(query, cluster_id)",
            "",
            "            try:",
            "                query.one()",
            "            except NoResultFound:",
            "                raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "            query.delete()",
            "",
            "    def update_cluster(self, cluster_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing Cluster.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_cluster(cluster_id, values)",
            "",
            "    def _do_update_cluster(self, cluster_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Cluster, session=session)",
            "            query = add_identity_filter(query, cluster_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def _add_cluster_template_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"name\", \"image_id\", \"flavor_id\",",
            "                            \"master_flavor_id\", \"keypair_id\",",
            "                            \"external_network_id\", \"dns_nameserver\",",
            "                            \"project_id\", \"user_id\", \"labels\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        return query.filter_by(**filter_dict)",
            "",
            "    def get_cluster_template_list(self, context, filters=None, limit=None,",
            "                                  marker=None, sort_key=None, sort_dir=None):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_cluster_template_filters(query, filters)",
            "        # include public ClusterTemplates",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "",
            "        return _paginate_query(models.ClusterTemplate, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_cluster_template(self, values):",
            "        # ensure defaults are present for new ClusterTemplates",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        cluster_template = models.ClusterTemplate()",
            "        cluster_template.update(values)",
            "        try:",
            "            cluster_template.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.ClusterTemplateAlreadyExists(uuid=values['uuid'])",
            "        return cluster_template",
            "",
            "    def get_cluster_template_by_id(self, context, cluster_template_id):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(id=cluster_template_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_id)",
            "",
            "    def get_cluster_template_by_uuid(self, context, cluster_template_uuid):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(uuid=cluster_template_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_uuid)",
            "",
            "    def get_cluster_template_by_name(self, context, cluster_template_name):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(name=cluster_template_name)",
            "        try:",
            "            return query.one()",
            "        except MultipleResultsFound:",
            "            raise exception.Conflict('Multiple ClusterTemplates exist with'",
            "                                     ' same name. Please use the '",
            "                                     'ClusterTemplate uuid instead.')",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_name)",
            "",
            "    def _is_cluster_template_referenced(self, session, cluster_template_uuid):",
            "        \"\"\"Checks whether the ClusterTemplate is referenced by cluster(s).\"\"\"",
            "        query = model_query(models.Cluster, session=session)",
            "        query = self._add_clusters_filters(query, {'cluster_template_id':",
            "                                                   cluster_template_uuid})",
            "        return query.count() != 0",
            "",
            "    def _is_publishing_cluster_template(self, values):",
            "        if (len(values) == 1 and",
            "                'public' in values and values['public'] is True):",
            "            return True",
            "        return False",
            "",
            "    def destroy_cluster_template(self, cluster_template_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.ClusterTemplate, session=session)",
            "            query = add_identity_filter(query, cluster_template_id)",
            "",
            "            try:",
            "                cluster_template_ref = query.one()",
            "            except NoResultFound:",
            "                raise exception.ClusterTemplateNotFound(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            if self._is_cluster_template_referenced(",
            "                    session, cluster_template_ref['uuid']):",
            "                raise exception.ClusterTemplateReferenced(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            query.delete()",
            "",
            "    def update_cluster_template(self, cluster_template_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing ClusterTemplate.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_cluster_template(cluster_template_id, values)",
            "",
            "    def _do_update_cluster_template(self, cluster_template_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.ClusterTemplate, session=session)",
            "            query = add_identity_filter(query, cluster_template_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.ClusterTemplateNotFound(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            if self._is_cluster_template_referenced(session, ref['uuid']):",
            "                # we only allow to update ClusterTemplate to be public",
            "                if not self._is_publishing_cluster_template(values):",
            "                    raise exception.ClusterTemplateReferenced(",
            "                        clustertemplate=cluster_template_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def create_x509keypair(self, values):",
            "        # ensure defaults are present for new x509keypairs",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        x509keypair = models.X509KeyPair()",
            "        x509keypair.update(values)",
            "        try:",
            "            x509keypair.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.X509KeyPairAlreadyExists(uuid=values['uuid'])",
            "        return x509keypair",
            "",
            "    def get_x509keypair_by_id(self, context, x509keypair_id):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(id=x509keypair_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.X509KeyPairNotFound(x509keypair=x509keypair_id)",
            "",
            "    def get_x509keypair_by_uuid(self, context, x509keypair_uuid):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(uuid=x509keypair_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.X509KeyPairNotFound(x509keypair=x509keypair_uuid)",
            "",
            "    def destroy_x509keypair(self, x509keypair_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.X509KeyPair, session=session)",
            "            query = add_identity_filter(query, x509keypair_id)",
            "            count = query.delete()",
            "            if count != 1:",
            "                raise exception.X509KeyPairNotFound(x509keypair_id)",
            "",
            "    def update_x509keypair(self, x509keypair_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing X509KeyPair.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_x509keypair(x509keypair_id, values)",
            "",
            "    def _do_update_x509keypair(self, x509keypair_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.X509KeyPair, session=session)",
            "            query = add_identity_filter(query, x509keypair_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.X509KeyPairNotFound(x509keypair=x509keypair_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def _add_x509keypairs_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        if 'project_id' in filters:",
            "            query = query.filter_by(project_id=filters['project_id'])",
            "        if 'user_id' in filters:",
            "            query = query.filter_by(user_id=filters['user_id'])",
            "",
            "        return query",
            "",
            "    def get_x509keypair_list(self, context, filters=None, limit=None,",
            "                             marker=None, sort_key=None, sort_dir=None):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_x509keypairs_filters(query, filters)",
            "        return _paginate_query(models.X509KeyPair, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def destroy_magnum_service(self, magnum_service_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.MagnumService, session=session)",
            "            query = add_identity_filter(query, magnum_service_id)",
            "            count = query.delete()",
            "            if count != 1:",
            "                raise exception.MagnumServiceNotFound(",
            "                    magnum_service_id=magnum_service_id)",
            "",
            "    def update_magnum_service(self, magnum_service_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.MagnumService, session=session)",
            "            query = add_identity_filter(query, magnum_service_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.MagnumServiceNotFound(",
            "                    magnum_service_id=magnum_service_id)",
            "",
            "            if 'report_count' in values:",
            "                if values['report_count'] > ref.report_count:",
            "                    ref.last_seen_up = timeutils.utcnow()",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def get_magnum_service_by_host_and_binary(self, host, binary):",
            "        query = model_query(models.MagnumService)",
            "        query = query.filter_by(host=host, binary=binary)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            return None",
            "",
            "    def create_magnum_service(self, values):",
            "        magnum_service = models.MagnumService()",
            "        magnum_service.update(values)",
            "        try:",
            "            magnum_service.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.MagnumServiceAlreadyExists(id=magnum_service['id'])",
            "        return magnum_service",
            "",
            "    def get_magnum_service_list(self, disabled=None, limit=None,",
            "                                marker=None, sort_key=None, sort_dir=None",
            "                                ):",
            "        query = model_query(models.MagnumService)",
            "        if disabled:",
            "            query = query.filter_by(disabled=disabled)",
            "",
            "        return _paginate_query(models.MagnumService, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_quota(self, values):",
            "        quotas = models.Quota()",
            "        quotas.update(values)",
            "        try:",
            "            quotas.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.QuotaAlreadyExists(project_id=values['project_id'],",
            "                                               resource=values['resource'])",
            "        return quotas",
            "",
            "    def _add_quota_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"resource\", \"project_id\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        query = query.filter_by(**filter_dict)",
            "        return query",
            "",
            "    def get_quota_list(self, context, filters=None, limit=None, marker=None,",
            "                       sort_key=None, sort_dir=None):",
            "        query = model_query(models.Quota)",
            "        query = self._add_quota_filters(query, filters)",
            "        return _paginate_query(models.Quota, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def update_quota(self, project_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Quota, session=session)",
            "            resource = values['resource']",
            "            try:",
            "                query = query.filter_by(project_id=project_id).filter_by(",
            "                    resource=resource)",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                       {'project_id': project_id, 'resource': resource})",
            "                raise exception.QuotaNotFound(msg=msg)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def delete_quota(self, project_id, resource):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Quota, session=session)",
            "",
            "            try:",
            "                query.filter_by(project_id=project_id).filter_by(",
            "                    resource=resource).one()",
            "            except NoResultFound:",
            "                msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                       {'project_id': project_id, 'resource': resource})",
            "                raise exception.QuotaNotFound(msg=msg)",
            "",
            "            query.delete()",
            "",
            "    def get_quota_by_id(self, context, quota_id):",
            "        query = model_query(models.Quota)",
            "        query = query.filter_by(id=quota_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            msg = _('quota id %s .') % quota_id",
            "            raise exception.QuotaNotFound(msg=msg)",
            "",
            "    def quota_get_all_by_project_id(self, project_id):",
            "        query = model_query(models.Quota)",
            "        result = query.filter_by(project_id=project_id).all()",
            "",
            "        return result",
            "",
            "    def get_quota_by_project_id_resource(self, project_id, resource):",
            "        query = model_query(models.Quota)",
            "        query = query.filter_by(project_id=project_id).filter_by(",
            "            resource=resource)",
            "",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                   {'project_id': project_id, 'resource': resource})",
            "            raise exception.QuotaNotFound(msg=msg)"
        ],
        "afterPatchFile": [
            "# Copyright 2013 Hewlett-Packard Development Company, L.P.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "\"\"\"SQLAlchemy storage backend.\"\"\"",
            "",
            "from oslo_db import exception as db_exc",
            "from oslo_db.sqlalchemy import session as db_session",
            "from oslo_db.sqlalchemy import utils as db_utils",
            "from oslo_utils import importutils",
            "from oslo_utils import strutils",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import sqlalchemy as sa",
            "from sqlalchemy.orm.exc import MultipleResultsFound",
            "from sqlalchemy.orm.exc import NoResultFound",
            "from sqlalchemy.sql import func",
            "",
            "from magnum.common import clients",
            "from magnum.common import context as request_context",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.db import api",
            "from magnum.db.sqlalchemy import models",
            "from magnum.i18n import _",
            "",
            "profiler_sqlalchemy = importutils.try_import('osprofiler.sqlalchemy')",
            "",
            "CONF = magnum.conf.CONF",
            "",
            "",
            "_FACADE = None",
            "",
            "",
            "def _create_facade_lazily():",
            "    global _FACADE",
            "    if _FACADE is None:",
            "        _FACADE = db_session.EngineFacade.from_config(CONF)",
            "        if profiler_sqlalchemy:",
            "            if CONF.profiler.enabled and CONF.profiler.trace_sqlalchemy:",
            "                profiler_sqlalchemy.add_tracing(sa, _FACADE.get_engine(), \"db\")",
            "",
            "    return _FACADE",
            "",
            "",
            "def get_engine():",
            "    facade = _create_facade_lazily()",
            "    return facade.get_engine()",
            "",
            "",
            "def get_session(**kwargs):",
            "    facade = _create_facade_lazily()",
            "    return facade.get_session(**kwargs)",
            "",
            "",
            "def get_backend():",
            "    \"\"\"The backend is this module itself.\"\"\"",
            "    return Connection()",
            "",
            "",
            "def model_query(model, *args, **kwargs):",
            "    \"\"\"Query helper for simpler session usage.",
            "",
            "    :param session: if present, the session to use",
            "    \"\"\"",
            "",
            "    session = kwargs.get('session') or get_session()",
            "    query = session.query(model, *args)",
            "    return query",
            "",
            "",
            "def add_identity_filter(query, value):",
            "    \"\"\"Adds an identity filter to a query.",
            "",
            "    Filters results by ID, if supplied value is a valid integer.",
            "    Otherwise attempts to filter results by UUID.",
            "",
            "    :param query: Initial query to add filter to.",
            "    :param value: Value for filtering results by.",
            "    :return: Modified query.",
            "    \"\"\"",
            "    if strutils.is_int_like(value):",
            "        return query.filter_by(id=value)",
            "    elif uuidutils.is_uuid_like(value):",
            "        return query.filter_by(uuid=value)",
            "    else:",
            "        raise exception.InvalidIdentity(identity=value)",
            "",
            "",
            "def _paginate_query(model, limit=None, marker=None, sort_key=None,",
            "                    sort_dir=None, query=None):",
            "    if not query:",
            "        query = model_query(model)",
            "    sort_keys = ['id']",
            "    if sort_key and sort_key not in sort_keys:",
            "        sort_keys.insert(0, sort_key)",
            "    try:",
            "        query = db_utils.paginate_query(query, model, limit, sort_keys,",
            "                                        marker=marker, sort_dir=sort_dir)",
            "    except db_exc.InvalidSortKey:",
            "        raise exception.InvalidParameterValue(",
            "            _('The sort_key value \"%(key)s\" is an invalid field for sorting')",
            "            % {'key': sort_key})",
            "    return query.all()",
            "",
            "",
            "class Connection(api.Connection):",
            "    \"\"\"SqlAlchemy connection.\"\"\"",
            "",
            "    def __init__(self):",
            "        pass",
            "",
            "    def _add_tenant_filters(self, context, query):",
            "        if context.is_admin and context.all_tenants:",
            "            return query",
            "",
            "        admin_context = request_context.make_admin_context(all_tenants=True)",
            "        osc = clients.OpenStackClients(admin_context)",
            "        kst = osc.keystone()",
            "",
            "        # User in a regular project (not in the trustee domain)",
            "        if context.project_id and context.domain_id != kst.trustee_domain_id:",
            "            query = query.filter_by(project_id=context.project_id)",
            "        # Match project ID component in trustee user's user name against",
            "        # cluster's project_id to associate per-cluster trustee users who have",
            "        # no project information with the project their clusters/cluster models",
            "        # reside in. This is equivalent to the project filtering above.",
            "        elif context.domain_id == kst.trustee_domain_id:",
            "            user_name = kst.client.users.get(context.user_id).name",
            "            user_project = user_name.split('_', 2)[1]",
            "            query = query.filter_by(project_id=user_project)",
            "        else:",
            "            query = query.filter_by(user_id=context.user_id)",
            "",
            "        return query",
            "",
            "    def _add_clusters_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"cluster_template_id\", \"name\", \"node_count\",",
            "                            \"master_count\", \"stack_id\", \"api_address\",",
            "                            \"node_addresses\", \"project_id\", \"user_id\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        query = query.filter_by(**filter_dict)",
            "",
            "        if 'status' in filters:",
            "            query = query.filter(models.Cluster.status.in_(filters['status']))",
            "",
            "        return query",
            "",
            "    def get_cluster_list(self, context, filters=None, limit=None, marker=None,",
            "                         sort_key=None, sort_dir=None):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_clusters_filters(query, filters)",
            "        return _paginate_query(models.Cluster, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_cluster(self, values):",
            "        # ensure defaults are present for new clusters",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        cluster = models.Cluster()",
            "        cluster.update(values)",
            "        try:",
            "            cluster.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.ClusterAlreadyExists(uuid=values['uuid'])",
            "        return cluster",
            "",
            "    def get_cluster_by_id(self, context, cluster_id):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(id=cluster_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "    def get_cluster_by_name(self, context, cluster_name):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(name=cluster_name)",
            "        try:",
            "            return query.one()",
            "        except MultipleResultsFound:",
            "            raise exception.Conflict('Multiple clusters exist with same name.'",
            "                                     ' Please use the cluster uuid instead.')",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_name)",
            "",
            "    def get_cluster_by_uuid(self, context, cluster_uuid):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(uuid=cluster_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterNotFound(cluster=cluster_uuid)",
            "",
            "    def get_cluster_stats(self, context, project_id=None):",
            "        query = model_query(models.Cluster)",
            "        node_count_col = models.Cluster.node_count",
            "        master_count_col = models.Cluster.master_count",
            "        ncfunc = func.sum(node_count_col + master_count_col)",
            "",
            "        if project_id:",
            "            query = query.filter_by(project_id=project_id)",
            "            nquery = query.session.query(ncfunc.label(\"nodes\")).filter_by(",
            "                project_id=project_id)",
            "        else:",
            "            nquery = query.session.query(ncfunc.label(\"nodes\"))",
            "",
            "        clusters = query.count()",
            "        nodes = int(nquery.one()[0]) if nquery.one()[0] else 0",
            "        return clusters, nodes",
            "",
            "    def get_cluster_count_all(self, context, filters=None):",
            "        query = model_query(models.Cluster)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_clusters_filters(query, filters)",
            "        return query.count()",
            "",
            "    def destroy_cluster(self, cluster_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Cluster, session=session)",
            "            query = add_identity_filter(query, cluster_id)",
            "",
            "            try:",
            "                query.one()",
            "            except NoResultFound:",
            "                raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "            query.delete()",
            "",
            "    def update_cluster(self, cluster_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing Cluster.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_cluster(cluster_id, values)",
            "",
            "    def _do_update_cluster(self, cluster_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Cluster, session=session)",
            "            query = add_identity_filter(query, cluster_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.ClusterNotFound(cluster=cluster_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def _add_cluster_template_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"name\", \"image_id\", \"flavor_id\",",
            "                            \"master_flavor_id\", \"keypair_id\",",
            "                            \"external_network_id\", \"dns_nameserver\",",
            "                            \"project_id\", \"user_id\", \"labels\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        return query.filter_by(**filter_dict)",
            "",
            "    def get_cluster_template_list(self, context, filters=None, limit=None,",
            "                                  marker=None, sort_key=None, sort_dir=None):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_cluster_template_filters(query, filters)",
            "        # include public ClusterTemplates",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "",
            "        return _paginate_query(models.ClusterTemplate, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_cluster_template(self, values):",
            "        # ensure defaults are present for new ClusterTemplates",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        cluster_template = models.ClusterTemplate()",
            "        cluster_template.update(values)",
            "        try:",
            "            cluster_template.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.ClusterTemplateAlreadyExists(uuid=values['uuid'])",
            "        return cluster_template",
            "",
            "    def get_cluster_template_by_id(self, context, cluster_template_id):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(id=cluster_template_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_id)",
            "",
            "    def get_cluster_template_by_uuid(self, context, cluster_template_uuid):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(uuid=cluster_template_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_uuid)",
            "",
            "    def get_cluster_template_by_name(self, context, cluster_template_name):",
            "        query = model_query(models.ClusterTemplate)",
            "        query = self._add_tenant_filters(context, query)",
            "        public_q = model_query(models.ClusterTemplate).filter_by(public=True)",
            "        query = query.union(public_q)",
            "        query = query.filter_by(name=cluster_template_name)",
            "        try:",
            "            return query.one()",
            "        except MultipleResultsFound:",
            "            raise exception.Conflict('Multiple ClusterTemplates exist with'",
            "                                     ' same name. Please use the '",
            "                                     'ClusterTemplate uuid instead.')",
            "        except NoResultFound:",
            "            raise exception.ClusterTemplateNotFound(",
            "                clustertemplate=cluster_template_name)",
            "",
            "    def _is_cluster_template_referenced(self, session, cluster_template_uuid):",
            "        \"\"\"Checks whether the ClusterTemplate is referenced by cluster(s).\"\"\"",
            "        query = model_query(models.Cluster, session=session)",
            "        query = self._add_clusters_filters(query, {'cluster_template_id':",
            "                                                   cluster_template_uuid})",
            "        return query.count() != 0",
            "",
            "    def _is_publishing_cluster_template(self, values):",
            "        if (len(values) == 1 and",
            "                'public' in values and values['public'] is True):",
            "            return True",
            "        return False",
            "",
            "    def destroy_cluster_template(self, cluster_template_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.ClusterTemplate, session=session)",
            "            query = add_identity_filter(query, cluster_template_id)",
            "",
            "            try:",
            "                cluster_template_ref = query.one()",
            "            except NoResultFound:",
            "                raise exception.ClusterTemplateNotFound(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            if self._is_cluster_template_referenced(",
            "                    session, cluster_template_ref['uuid']):",
            "                raise exception.ClusterTemplateReferenced(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            query.delete()",
            "",
            "    def update_cluster_template(self, cluster_template_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing ClusterTemplate.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_cluster_template(cluster_template_id, values)",
            "",
            "    def _do_update_cluster_template(self, cluster_template_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.ClusterTemplate, session=session)",
            "            query = add_identity_filter(query, cluster_template_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.ClusterTemplateNotFound(",
            "                    clustertemplate=cluster_template_id)",
            "",
            "            if self._is_cluster_template_referenced(session, ref['uuid']):",
            "                # we only allow to update ClusterTemplate to be public",
            "                if not self._is_publishing_cluster_template(values):",
            "                    raise exception.ClusterTemplateReferenced(",
            "                        clustertemplate=cluster_template_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def create_x509keypair(self, values):",
            "        # ensure defaults are present for new x509keypairs",
            "        if not values.get('uuid'):",
            "            values['uuid'] = uuidutils.generate_uuid()",
            "",
            "        x509keypair = models.X509KeyPair()",
            "        x509keypair.update(values)",
            "        try:",
            "            x509keypair.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.X509KeyPairAlreadyExists(uuid=values['uuid'])",
            "        return x509keypair",
            "",
            "    def get_x509keypair_by_id(self, context, x509keypair_id):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(id=x509keypair_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.X509KeyPairNotFound(x509keypair=x509keypair_id)",
            "",
            "    def get_x509keypair_by_uuid(self, context, x509keypair_uuid):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = query.filter_by(uuid=x509keypair_uuid)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            raise exception.X509KeyPairNotFound(x509keypair=x509keypair_uuid)",
            "",
            "    def destroy_x509keypair(self, x509keypair_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.X509KeyPair, session=session)",
            "            query = add_identity_filter(query, x509keypair_id)",
            "            count = query.delete()",
            "            if count != 1:",
            "                raise exception.X509KeyPairNotFound(x509keypair_id)",
            "",
            "    def update_x509keypair(self, x509keypair_id, values):",
            "        # NOTE(dtantsur): this can lead to very strange errors",
            "        if 'uuid' in values:",
            "            msg = _(\"Cannot overwrite UUID for an existing X509KeyPair.\")",
            "            raise exception.InvalidParameterValue(err=msg)",
            "",
            "        return self._do_update_x509keypair(x509keypair_id, values)",
            "",
            "    def _do_update_x509keypair(self, x509keypair_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.X509KeyPair, session=session)",
            "            query = add_identity_filter(query, x509keypair_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.X509KeyPairNotFound(x509keypair=x509keypair_id)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def _add_x509keypairs_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        if 'project_id' in filters:",
            "            query = query.filter_by(project_id=filters['project_id'])",
            "        if 'user_id' in filters:",
            "            query = query.filter_by(user_id=filters['user_id'])",
            "",
            "        return query",
            "",
            "    def get_x509keypair_list(self, context, filters=None, limit=None,",
            "                             marker=None, sort_key=None, sort_dir=None):",
            "        query = model_query(models.X509KeyPair)",
            "        query = self._add_tenant_filters(context, query)",
            "        query = self._add_x509keypairs_filters(query, filters)",
            "        return _paginate_query(models.X509KeyPair, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def destroy_magnum_service(self, magnum_service_id):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.MagnumService, session=session)",
            "            query = add_identity_filter(query, magnum_service_id)",
            "            count = query.delete()",
            "            if count != 1:",
            "                raise exception.MagnumServiceNotFound(",
            "                    magnum_service_id=magnum_service_id)",
            "",
            "    def update_magnum_service(self, magnum_service_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.MagnumService, session=session)",
            "            query = add_identity_filter(query, magnum_service_id)",
            "            try:",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                raise exception.MagnumServiceNotFound(",
            "                    magnum_service_id=magnum_service_id)",
            "",
            "            if 'report_count' in values:",
            "                if values['report_count'] > ref.report_count:",
            "                    ref.last_seen_up = timeutils.utcnow()",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def get_magnum_service_by_host_and_binary(self, host, binary):",
            "        query = model_query(models.MagnumService)",
            "        query = query.filter_by(host=host, binary=binary)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            return None",
            "",
            "    def create_magnum_service(self, values):",
            "        magnum_service = models.MagnumService()",
            "        magnum_service.update(values)",
            "        try:",
            "            magnum_service.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.MagnumServiceAlreadyExists(id=magnum_service['id'])",
            "        return magnum_service",
            "",
            "    def get_magnum_service_list(self, disabled=None, limit=None,",
            "                                marker=None, sort_key=None, sort_dir=None",
            "                                ):",
            "        query = model_query(models.MagnumService)",
            "        if disabled:",
            "            query = query.filter_by(disabled=disabled)",
            "",
            "        return _paginate_query(models.MagnumService, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def create_quota(self, values):",
            "        quotas = models.Quota()",
            "        quotas.update(values)",
            "        try:",
            "            quotas.save()",
            "        except db_exc.DBDuplicateEntry:",
            "            raise exception.QuotaAlreadyExists(project_id=values['project_id'],",
            "                                               resource=values['resource'])",
            "        return quotas",
            "",
            "    def _add_quota_filters(self, query, filters):",
            "        if filters is None:",
            "            filters = {}",
            "",
            "        possible_filters = [\"resource\", \"project_id\"]",
            "",
            "        filter_names = set(filters).intersection(possible_filters)",
            "        filter_dict = {filter_name: filters[filter_name]",
            "                       for filter_name in filter_names}",
            "",
            "        query = query.filter_by(**filter_dict)",
            "        return query",
            "",
            "    def get_quota_list(self, context, filters=None, limit=None, marker=None,",
            "                       sort_key=None, sort_dir=None):",
            "        query = model_query(models.Quota)",
            "        query = self._add_quota_filters(query, filters)",
            "        return _paginate_query(models.Quota, limit, marker,",
            "                               sort_key, sort_dir, query)",
            "",
            "    def update_quota(self, project_id, values):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Quota, session=session)",
            "            resource = values['resource']",
            "            try:",
            "                query = query.filter_by(project_id=project_id).filter_by(",
            "                    resource=resource)",
            "                ref = query.with_lockmode('update').one()",
            "            except NoResultFound:",
            "                msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                       {'project_id': project_id, 'resource': resource})",
            "                raise exception.QuotaNotFound(msg=msg)",
            "",
            "            ref.update(values)",
            "        return ref",
            "",
            "    def delete_quota(self, project_id, resource):",
            "        session = get_session()",
            "        with session.begin():",
            "            query = model_query(models.Quota, session=session)",
            "",
            "            try:",
            "                query.filter_by(project_id=project_id).filter_by(",
            "                    resource=resource).one()",
            "            except NoResultFound:",
            "                msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                       {'project_id': project_id, 'resource': resource})",
            "                raise exception.QuotaNotFound(msg=msg)",
            "",
            "            query.delete()",
            "",
            "    def get_quota_by_id(self, context, quota_id):",
            "        query = model_query(models.Quota)",
            "        query = query.filter_by(id=quota_id)",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            msg = _('quota id %s .') % quota_id",
            "            raise exception.QuotaNotFound(msg=msg)",
            "",
            "    def quota_get_all_by_project_id(self, project_id):",
            "        query = model_query(models.Quota)",
            "        result = query.filter_by(project_id=project_id).all()",
            "",
            "        return result",
            "",
            "    def get_quota_by_project_id_resource(self, project_id, resource):",
            "        query = model_query(models.Quota)",
            "        query = query.filter_by(project_id=project_id).filter_by(",
            "            resource=resource)",
            "",
            "        try:",
            "            return query.one()",
            "        except NoResultFound:",
            "            msg = (_('project_id %(project_id)s resource %(resource)s.') %",
            "                   {'project_id': project_id, 'resource': resource})",
            "            raise exception.QuotaNotFound(msg=msg)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "125": [
                "Connection",
                "_add_tenant_filters"
            ]
        },
        "addLocation": []
    },
    "magnum/drivers/common/templates/swarm/fragments/make-cert.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "                     \"password\": \"%(trustee_password)s\""
            },
            "1": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "                 }"
            },
            "2": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "             }"
            },
            "3": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        },"
            },
            "4": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"scope\": {"
            },
            "5": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"OS-TRUST:trust\": {"
            },
            "6": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"id\": \"%(trust_id)s\""
            },
            "7": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            }"
            },
            "8": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "         }"
            },
            "9": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "     }"
            },
            "10": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 155,
                "PatchRowcode": " }"
            },
            "11": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 156,
                "PatchRowcode": " '''"
            },
            "12": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "     params = {"
            },
            "13": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "         'trustee_user_id': config['TRUSTEE_USER_ID'],"
            },
            "14": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "         'trustee_password': config['TRUSTEE_PASSWORD'],"
            },
            "15": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'trust_id': config['TRUST_ID']"
            },
            "16": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 160,
                "PatchRowcode": "     }"
            },
            "17": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 161,
                "PatchRowcode": "     creds = creds_str % params"
            },
            "18": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "     headers = {'Content-Type': 'application/json'}"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2015 Rackspace, Inc.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import json",
            "import os",
            "import subprocess",
            "import sys",
            "",
            "import requests",
            "",
            "HEAT_PARAMS_PATH = '/etc/sysconfig/heat-params'",
            "PUBLIC_IP_URL = 'http://169.254.169.254/latest/meta-data/public-ipv4'",
            "CERT_DIR = '/etc/docker'",
            "CERT_CONF_DIR = '%s/conf' % CERT_DIR",
            "CA_CERT_PATH = '%s/ca.crt' % CERT_DIR",
            "SERVER_CONF_PATH = '%s/server.conf' % CERT_CONF_DIR",
            "SERVER_KEY_PATH = '%s/server.key' % CERT_DIR",
            "SERVER_CSR_PATH = '%s/server.csr' % CERT_DIR",
            "SERVER_CERT_PATH = '%s/server.crt' % CERT_DIR",
            "",
            "CSR_CONFIG_TEMPLATE = \"\"\"",
            "[req]",
            "distinguished_name = req_distinguished_name",
            "req_extensions     = req_ext",
            "x509_extensions    = req_ext",
            "prompt = no",
            "copy_extensions = copyall",
            "[req_distinguished_name]",
            "CN = swarm.invalid",
            "[req_ext]",
            "subjectAltName = %(subject_alt_names)s",
            "extendedKeyUsage = clientAuth,serverAuth",
            "\"\"\"",
            "",
            "",
            "def _parse_config_value(value):",
            "    parsed_value = value",
            "    if parsed_value[-1] == '\\n':",
            "        parsed_value = parsed_value[:-1]",
            "    return parsed_value[1:-1]",
            "",
            "",
            "def load_config():",
            "    config = dict()",
            "    with open(HEAT_PARAMS_PATH, 'r') as fp:",
            "        for line in fp.readlines():",
            "            key, value = line.split('=', 1)",
            "            config[key] = _parse_config_value(value)",
            "    return config",
            "",
            "",
            "def create_dirs():",
            "    os.makedirs(CERT_CONF_DIR)",
            "",
            "",
            "def _get_public_ip():",
            "    return requests.get(PUBLIC_IP_URL).text",
            "",
            "",
            "def _build_subject_alt_names(config):",
            "    subject_alt_names = [",
            "        'IP:%s' % _get_public_ip(),",
            "        'IP:%s' % config['API_IP_ADDRESS'],",
            "        'IP:%s' % config['SWARM_NODE_IP'],",
            "        'IP:%s' % config['SWARM_API_IP'],",
            "        'IP:127.0.0.1'",
            "    ]",
            "    return ','.join(subject_alt_names)",
            "",
            "",
            "def write_ca_cert(config):",
            "    cluster_cert_url = '%s/certificates/%s' % (config['MAGNUM_URL'],",
            "                                               config['CLUSTER_UUID'])",
            "    headers = {'X-Auth-Token': config['USER_TOKEN'],",
            "               'OpenStack-API-Version': 'container-infra latest'}",
            "    ca_cert_resp = requests.get(cluster_cert_url,",
            "                                headers=headers)",
            "",
            "    with open(CA_CERT_PATH, 'w') as fp:",
            "        fp.write(ca_cert_resp.json()['pem'])",
            "",
            "",
            "def write_server_key():",
            "    subprocess.call(['openssl', 'genrsa',",
            "                     '-out', SERVER_KEY_PATH,",
            "                     '4096'])",
            "",
            "",
            "def _write_csr_config(config):",
            "    with open(SERVER_CONF_PATH, 'w') as fp:",
            "        params = {",
            "            'subject_alt_names': _build_subject_alt_names(config)",
            "        }",
            "        fp.write(CSR_CONFIG_TEMPLATE % params)",
            "",
            "",
            "def create_server_csr(config):",
            "    _write_csr_config(config)",
            "    subprocess.call(['openssl', 'req', '-new',",
            "                     '-days', '1000',",
            "                     '-key', SERVER_KEY_PATH,",
            "                     '-out', SERVER_CSR_PATH,",
            "                     '-reqexts', 'req_ext',",
            "                     '-extensions', 'req_ext',",
            "                     '-config', SERVER_CONF_PATH])",
            "",
            "    with open(SERVER_CSR_PATH, 'r') as fp:",
            "        return {'cluster_uuid': config['CLUSTER_UUID'], 'csr': fp.read()}",
            "",
            "",
            "def write_server_cert(config, csr_req):",
            "    cert_url = '%s/certificates' % config['MAGNUM_URL']",
            "    headers = {",
            "        'Content-Type': 'application/json',",
            "        'X-Auth-Token': config['USER_TOKEN'],",
            "        'OpenStack-API-Version': 'container-infra latest'",
            "    }",
            "    csr_resp = requests.post(cert_url,",
            "                             data=json.dumps(csr_req),",
            "                             headers=headers)",
            "",
            "    with open(SERVER_CERT_PATH, 'w') as fp:",
            "        fp.write(csr_resp.json()['pem'])",
            "",
            "",
            "def get_user_token(config):",
            "    creds_str = '''",
            "{",
            "    \"auth\": {",
            "        \"identity\": {",
            "            \"methods\": [",
            "                \"password\"",
            "            ],",
            "            \"password\": {",
            "                \"user\": {",
            "                    \"id\": \"%(trustee_user_id)s\",",
            "                    \"password\": \"%(trustee_password)s\"",
            "                }",
            "            }",
            "        },",
            "        \"scope\": {",
            "            \"OS-TRUST:trust\": {",
            "                \"id\": \"%(trust_id)s\"",
            "            }",
            "        }",
            "    }",
            "}",
            "'''",
            "    params = {",
            "        'trustee_user_id': config['TRUSTEE_USER_ID'],",
            "        'trustee_password': config['TRUSTEE_PASSWORD'],",
            "        'trust_id': config['TRUST_ID']",
            "    }",
            "    creds = creds_str % params",
            "    headers = {'Content-Type': 'application/json'}",
            "    url = config['AUTH_URL'].replace('v2.0', 'v3') + '/auth/tokens'",
            "    r = requests.post(url, headers=headers, data=creds)",
            "    config['USER_TOKEN'] = r.headers['X-Subject-Token']",
            "    return config",
            "",
            "",
            "def main():",
            "    config = load_config()",
            "    if config['TLS_DISABLED'] == 'False':",
            "        create_dirs()",
            "        config = get_user_token(config)",
            "        write_ca_cert(config)",
            "        write_server_key()",
            "        csr_req = create_server_csr(config)",
            "        write_server_cert(config, csr_req)",
            "",
            "",
            "if __name__ == '__main__':",
            "    sys.exit(main())"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2015 Rackspace, Inc.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import json",
            "import os",
            "import subprocess",
            "import sys",
            "",
            "import requests",
            "",
            "HEAT_PARAMS_PATH = '/etc/sysconfig/heat-params'",
            "PUBLIC_IP_URL = 'http://169.254.169.254/latest/meta-data/public-ipv4'",
            "CERT_DIR = '/etc/docker'",
            "CERT_CONF_DIR = '%s/conf' % CERT_DIR",
            "CA_CERT_PATH = '%s/ca.crt' % CERT_DIR",
            "SERVER_CONF_PATH = '%s/server.conf' % CERT_CONF_DIR",
            "SERVER_KEY_PATH = '%s/server.key' % CERT_DIR",
            "SERVER_CSR_PATH = '%s/server.csr' % CERT_DIR",
            "SERVER_CERT_PATH = '%s/server.crt' % CERT_DIR",
            "",
            "CSR_CONFIG_TEMPLATE = \"\"\"",
            "[req]",
            "distinguished_name = req_distinguished_name",
            "req_extensions     = req_ext",
            "x509_extensions    = req_ext",
            "prompt = no",
            "copy_extensions = copyall",
            "[req_distinguished_name]",
            "CN = swarm.invalid",
            "[req_ext]",
            "subjectAltName = %(subject_alt_names)s",
            "extendedKeyUsage = clientAuth,serverAuth",
            "\"\"\"",
            "",
            "",
            "def _parse_config_value(value):",
            "    parsed_value = value",
            "    if parsed_value[-1] == '\\n':",
            "        parsed_value = parsed_value[:-1]",
            "    return parsed_value[1:-1]",
            "",
            "",
            "def load_config():",
            "    config = dict()",
            "    with open(HEAT_PARAMS_PATH, 'r') as fp:",
            "        for line in fp.readlines():",
            "            key, value = line.split('=', 1)",
            "            config[key] = _parse_config_value(value)",
            "    return config",
            "",
            "",
            "def create_dirs():",
            "    os.makedirs(CERT_CONF_DIR)",
            "",
            "",
            "def _get_public_ip():",
            "    return requests.get(PUBLIC_IP_URL).text",
            "",
            "",
            "def _build_subject_alt_names(config):",
            "    subject_alt_names = [",
            "        'IP:%s' % _get_public_ip(),",
            "        'IP:%s' % config['API_IP_ADDRESS'],",
            "        'IP:%s' % config['SWARM_NODE_IP'],",
            "        'IP:%s' % config['SWARM_API_IP'],",
            "        'IP:127.0.0.1'",
            "    ]",
            "    return ','.join(subject_alt_names)",
            "",
            "",
            "def write_ca_cert(config):",
            "    cluster_cert_url = '%s/certificates/%s' % (config['MAGNUM_URL'],",
            "                                               config['CLUSTER_UUID'])",
            "    headers = {'X-Auth-Token': config['USER_TOKEN'],",
            "               'OpenStack-API-Version': 'container-infra latest'}",
            "    ca_cert_resp = requests.get(cluster_cert_url,",
            "                                headers=headers)",
            "",
            "    with open(CA_CERT_PATH, 'w') as fp:",
            "        fp.write(ca_cert_resp.json()['pem'])",
            "",
            "",
            "def write_server_key():",
            "    subprocess.call(['openssl', 'genrsa',",
            "                     '-out', SERVER_KEY_PATH,",
            "                     '4096'])",
            "",
            "",
            "def _write_csr_config(config):",
            "    with open(SERVER_CONF_PATH, 'w') as fp:",
            "        params = {",
            "            'subject_alt_names': _build_subject_alt_names(config)",
            "        }",
            "        fp.write(CSR_CONFIG_TEMPLATE % params)",
            "",
            "",
            "def create_server_csr(config):",
            "    _write_csr_config(config)",
            "    subprocess.call(['openssl', 'req', '-new',",
            "                     '-days', '1000',",
            "                     '-key', SERVER_KEY_PATH,",
            "                     '-out', SERVER_CSR_PATH,",
            "                     '-reqexts', 'req_ext',",
            "                     '-extensions', 'req_ext',",
            "                     '-config', SERVER_CONF_PATH])",
            "",
            "    with open(SERVER_CSR_PATH, 'r') as fp:",
            "        return {'cluster_uuid': config['CLUSTER_UUID'], 'csr': fp.read()}",
            "",
            "",
            "def write_server_cert(config, csr_req):",
            "    cert_url = '%s/certificates' % config['MAGNUM_URL']",
            "    headers = {",
            "        'Content-Type': 'application/json',",
            "        'X-Auth-Token': config['USER_TOKEN'],",
            "        'OpenStack-API-Version': 'container-infra latest'",
            "    }",
            "    csr_resp = requests.post(cert_url,",
            "                             data=json.dumps(csr_req),",
            "                             headers=headers)",
            "",
            "    with open(SERVER_CERT_PATH, 'w') as fp:",
            "        fp.write(csr_resp.json()['pem'])",
            "",
            "",
            "def get_user_token(config):",
            "    creds_str = '''",
            "{",
            "    \"auth\": {",
            "        \"identity\": {",
            "            \"methods\": [",
            "                \"password\"",
            "            ],",
            "            \"password\": {",
            "                \"user\": {",
            "                    \"id\": \"%(trustee_user_id)s\",",
            "                    \"password\": \"%(trustee_password)s\"",
            "                }",
            "            }",
            "        }",
            "    }",
            "}",
            "'''",
            "    params = {",
            "        'trustee_user_id': config['TRUSTEE_USER_ID'],",
            "        'trustee_password': config['TRUSTEE_PASSWORD'],",
            "    }",
            "    creds = creds_str % params",
            "    headers = {'Content-Type': 'application/json'}",
            "    url = config['AUTH_URL'].replace('v2.0', 'v3') + '/auth/tokens'",
            "    r = requests.post(url, headers=headers, data=creds)",
            "    config['USER_TOKEN'] = r.headers['X-Subject-Token']",
            "    return config",
            "",
            "",
            "def main():",
            "    config = load_config()",
            "    if config['TLS_DISABLED'] == 'False':",
            "        create_dirs()",
            "        config = get_user_token(config)",
            "        write_ca_cert(config)",
            "        write_server_key()",
            "        csr_req = create_server_csr(config)",
            "        write_server_cert(config, csr_req)",
            "",
            "",
            "if __name__ == '__main__':",
            "    sys.exit(main())"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "153": [
                "get_user_token"
            ],
            "154": [
                "get_user_token"
            ],
            "155": [
                "get_user_token"
            ],
            "156": [
                "get_user_token"
            ],
            "157": [
                "get_user_token"
            ],
            "165": [
                "get_user_token"
            ]
        },
        "addLocation": []
    },
    "magnum/drivers/heat/template_def.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from magnum.common import clients"
            },
            "1": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from magnum.common import exception"
            },
            "2": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import magnum.conf"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from magnum.i18n import _LE"
            },
            "4": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from magnum.i18n import _LW"
            },
            "5": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from requests import exceptions as req_exceptions"
            },
            "7": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 246,
                "PatchRowcode": "         extra_params['trustee_user_id'] = cluster.trustee_user_id"
            },
            "8": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "         extra_params['trustee_username'] = cluster.trustee_username"
            },
            "9": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": 248,
                "PatchRowcode": "         extra_params['trustee_password'] = cluster.trustee_password"
            },
            "10": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        extra_params['trust_id'] = cluster.trust_id"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+        # Only pass trust ID into the template when it is needed."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+        if (cluster_template.volume_driver == 'rexray' or"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+                cluster_template.registry_enabled):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+            if CONF.trust.cluster_user_trust:"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+                extra_params['trust_id'] = cluster.trust_id"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+            else:"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+                missing_setting = ('trust/cluster_user_trust = True')"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+                msg = _LE('This cluster can only be created with %s in '"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+                          'magnum.conf')"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+                raise exception.ConfigInvalid(msg % missing_setting)"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+        else:"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+            extra_params['trust_id'] = \"\""
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": 263,
                "PatchRowcode": "         extra_params['auth_url'] = context.auth_url"
            },
            "26": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": 264,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "         return super(BaseTemplateDefinition,"
            }
        },
        "frontPatchFile": [
            "# Copyright 2016 Rackspace Inc. All rights reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "import abc",
            "import ast",
            "",
            "from oslo_log import log as logging",
            "import requests",
            "import six",
            "",
            "from magnum.common import clients",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.i18n import _LW",
            "",
            "from requests import exceptions as req_exceptions",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "COMMON_TEMPLATES_PATH = \"../../common/templates/\"",
            "COMMON_ENV_PATH = COMMON_TEMPLATES_PATH + \"environments/\"",
            "",
            "CONF = magnum.conf.CONF",
            "",
            "",
            "class ParameterMapping(object):",
            "    \"\"\"A mapping associating heat param and cluster_template attr.",
            "",
            "    A ParameterMapping is an association of a Heat parameter name with",
            "    an attribute on a Cluster, ClusterTemplate, or both.",
            "",
            "    In the case of both cluster_template_attr and cluster_attr being set, the",
            "    ClusterTemplate will be checked first and then Cluster if the attribute",
            "    isn't set on the ClusterTemplate.",
            "",
            "    Parameters can also be set as 'required'. If a required parameter",
            "    isn't set, a RequiredArgumentNotProvided exception will be raised.",
            "    \"\"\"",
            "    def __init__(self, heat_param, cluster_template_attr=None,",
            "                 cluster_attr=None, required=False,",
            "                 param_type=lambda x: x):",
            "        self.heat_param = heat_param",
            "        self.cluster_template_attr = cluster_template_attr",
            "        self.cluster_attr = cluster_attr",
            "        self.required = required",
            "        self.param_type = param_type",
            "",
            "    def set_param(self, params, cluster_template, cluster):",
            "        value = None",
            "",
            "        if (self.cluster_template_attr and",
            "                getattr(cluster_template, self.cluster_template_attr, None)",
            "                is not None):",
            "            value = getattr(cluster_template, self.cluster_template_attr)",
            "        elif (self.cluster_attr and",
            "                getattr(cluster, self.cluster_attr, None) is not None):",
            "            value = getattr(cluster, self.cluster_attr)",
            "        elif self.required:",
            "            kwargs = dict(heat_param=self.heat_param)",
            "            raise exception.RequiredParameterNotProvided(**kwargs)",
            "",
            "        if value is not None:",
            "            value = self.param_type(value)",
            "            params[self.heat_param] = value",
            "",
            "",
            "class OutputMapping(object):",
            "    \"\"\"A mapping associating heat outputs and cluster attr.",
            "",
            "    An OutputMapping is an association of a Heat output with a key",
            "    Magnum understands.",
            "    \"\"\"",
            "",
            "    def __init__(self, heat_output, cluster_attr=None):",
            "        self.cluster_attr = cluster_attr",
            "        self.heat_output = heat_output",
            "",
            "    def set_output(self, stack, cluster_template, cluster):",
            "        if self.cluster_attr is None:",
            "            return",
            "",
            "        output_value = self.get_output_value(stack)",
            "        if output_value is not None:",
            "            setattr(cluster, self.cluster_attr, output_value)",
            "",
            "    def matched(self, output_key):",
            "        return self.heat_output == output_key",
            "",
            "    def get_output_value(self, stack):",
            "        for output in stack.to_dict().get('outputs', []):",
            "            if output['output_key'] == self.heat_output:",
            "                return output['output_value']",
            "",
            "        LOG.warning(_LW('stack does not have output_key %s'), self.heat_output)",
            "        return None",
            "",
            "",
            "@six.add_metaclass(abc.ABCMeta)",
            "class TemplateDefinition(object):",
            "    '''A mapping between Magnum objects and Heat templates.",
            "",
            "    A TemplateDefinition is essentially a mapping between Magnum objects",
            "    and Heat templates. Each TemplateDefinition has a mapping of Heat",
            "    parameters.",
            "    '''",
            "",
            "    def __init__(self):",
            "        self.param_mappings = list()",
            "        self.output_mappings = list()",
            "",
            "    def add_parameter(self, *args, **kwargs):",
            "        param = ParameterMapping(*args, **kwargs)",
            "        self.param_mappings.append(param)",
            "",
            "    def add_output(self, *args, **kwargs):",
            "        mapping_type = kwargs.pop('mapping_type', OutputMapping)",
            "        output = mapping_type(*args, **kwargs)",
            "        self.output_mappings.append(output)",
            "",
            "    def get_output(self, *args, **kwargs):",
            "        for output in self.output_mappings:",
            "            if output.matched(*args, **kwargs):",
            "                return output",
            "",
            "        return None",
            "",
            "    def get_params(self, context, cluster_template, cluster, **kwargs):",
            "        \"\"\"Pulls template parameters from ClusterTemplate.",
            "",
            "        :param context: Context to pull template parameters for",
            "        :param cluster_template: ClusterTemplate to pull template parameters",
            "         from",
            "        :param cluster: Cluster to pull template parameters from",
            "        :param extra_params: Any extra params to be provided to the template",
            "",
            "        :return: dict of template parameters",
            "        \"\"\"",
            "        template_params = dict()",
            "",
            "        for mapping in self.param_mappings:",
            "            mapping.set_param(template_params, cluster_template, cluster)",
            "",
            "        if 'extra_params' in kwargs:",
            "            template_params.update(kwargs.get('extra_params'))",
            "",
            "        return template_params",
            "",
            "    def get_env_files(self, cluster_template):",
            "        \"\"\"Gets stack environment files based upon ClusterTemplate attributes.",
            "",
            "        Base implementation returns no files (empty list). Meant to be",
            "        overridden by subclasses.",
            "",
            "        :param cluster_template: ClusterTemplate to grab environment files for",
            "",
            "        :return: list of relative paths to environment files",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_heat_param(self, cluster_attr=None, cluster_template_attr=None):",
            "        \"\"\"Returns stack param name.",
            "",
            "        Return stack param name using cluster and cluster_template attributes",
            "        :param cluster_attr cluster attribute from which it maps to stack",
            "         attribute",
            "        :param cluster_template_attr cluster_template attribute from which it",
            "         maps to stack attribute",
            "",
            "        :return stack parameter name or None",
            "        \"\"\"",
            "        for mapping in self.param_mappings:",
            "            if (mapping.cluster_attr == cluster_attr and",
            "                    mapping.cluster_template_attr == cluster_template_attr):",
            "                return mapping.heat_param",
            "",
            "        return None",
            "",
            "    def update_outputs(self, stack, cluster_template, cluster):",
            "        for output in self.output_mappings:",
            "            output.set_output(stack, cluster_template, cluster)",
            "",
            "    @abc.abstractproperty",
            "    def driver_module_path(self):",
            "        pass",
            "",
            "    @abc.abstractproperty",
            "    def template_path(self):",
            "        pass",
            "",
            "    def extract_definition(self, context, cluster_template, cluster, **kwargs):",
            "        return (self.template_path,",
            "                self.get_params(context, cluster_template, cluster, **kwargs),",
            "                self.get_env_files(cluster_template))",
            "",
            "",
            "class BaseTemplateDefinition(TemplateDefinition):",
            "    def __init__(self):",
            "        super(BaseTemplateDefinition, self).__init__()",
            "        self._osc = None",
            "",
            "        self.add_parameter('ssh_key_name',",
            "                           cluster_attr='keypair',",
            "                           required=True)",
            "        self.add_parameter('server_image',",
            "                           cluster_template_attr='image_id')",
            "        self.add_parameter('dns_nameserver',",
            "                           cluster_template_attr='dns_nameserver')",
            "        self.add_parameter('http_proxy',",
            "                           cluster_template_attr='http_proxy')",
            "        self.add_parameter('https_proxy',",
            "                           cluster_template_attr='https_proxy')",
            "        self.add_parameter('no_proxy',",
            "                           cluster_template_attr='no_proxy')",
            "        self.add_parameter('number_of_masters',",
            "                           cluster_attr='master_count')",
            "",
            "    @property",
            "    def driver_module_path(self):",
            "        pass",
            "",
            "    @abc.abstractproperty",
            "    def template_path(self):",
            "        pass",
            "",
            "    def get_osc(self, context):",
            "        if not self._osc:",
            "            self._osc = clients.OpenStackClients(context)",
            "        return self._osc",
            "",
            "    def get_params(self, context, cluster_template, cluster, **kwargs):",
            "        osc = self.get_osc(context)",
            "",
            "        extra_params = kwargs.pop('extra_params', {})",
            "        extra_params['trustee_domain_id'] = osc.keystone().trustee_domain_id",
            "        extra_params['trustee_user_id'] = cluster.trustee_user_id",
            "        extra_params['trustee_username'] = cluster.trustee_username",
            "        extra_params['trustee_password'] = cluster.trustee_password",
            "        extra_params['trust_id'] = cluster.trust_id",
            "        extra_params['auth_url'] = context.auth_url",
            "",
            "        return super(BaseTemplateDefinition,",
            "                     self).get_params(context, cluster_template, cluster,",
            "                                      extra_params=extra_params,",
            "                                      **kwargs)",
            "",
            "    def validate_discovery_url(self, discovery_url, expect_size):",
            "        url = str(discovery_url)",
            "        if url[len(url)-1] == '/':",
            "            url += '_config/size'",
            "        else:",
            "            url += '/_config/size'",
            "",
            "        try:",
            "            result = requests.get(url).text",
            "        except req_exceptions.RequestException as err:",
            "            LOG.error(six.text_type(err))",
            "            raise exception.GetClusterSizeFailed(",
            "                discovery_url=discovery_url)",
            "",
            "        try:",
            "            result = ast.literal_eval(result)",
            "        except (ValueError, SyntaxError):",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "",
            "        node_value = result.get('node', None)",
            "        if node_value is None:",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "",
            "        value = node_value.get('value', None)",
            "        if value is None:",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "        elif int(value) != expect_size:",
            "            raise exception.InvalidClusterSize(",
            "                expect_size=expect_size,",
            "                size=int(value),",
            "                discovery_url=discovery_url)",
            "",
            "    def get_discovery_url(self, cluster):",
            "        if hasattr(cluster, 'discovery_url') and cluster.discovery_url:",
            "            if getattr(cluster, 'master_count', None) is not None:",
            "                self.validate_discovery_url(cluster.discovery_url,",
            "                                            cluster.master_count)",
            "            else:",
            "                self.validate_discovery_url(cluster.discovery_url, 1)",
            "            discovery_url = cluster.discovery_url",
            "        else:",
            "            discovery_endpoint = (",
            "                CONF.cluster.etcd_discovery_service_endpoint_format %",
            "                {'size': cluster.master_count})",
            "            try:",
            "                discovery_url = requests.get(discovery_endpoint).text",
            "            except req_exceptions.RequestException as err:",
            "                LOG.error(six.text_type(err))",
            "                raise exception.GetDiscoveryUrlFailed(",
            "                    discovery_endpoint=discovery_endpoint)",
            "            if not discovery_url:",
            "                raise exception.InvalidDiscoveryURL(",
            "                    discovery_url=discovery_url,",
            "                    discovery_endpoint=discovery_endpoint)",
            "            else:",
            "                cluster.discovery_url = discovery_url",
            "        return discovery_url",
            "",
            "",
            "def add_lb_env_file(env_files, cluster_template):",
            "    if cluster_template.master_lb_enabled:",
            "        env_files.append(COMMON_ENV_PATH + 'with_master_lb.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'no_master_lb.yaml')",
            "",
            "",
            "def add_volume_env_file(env_files, cluster_template):",
            "    if cluster_template.docker_volume_size is None:",
            "        env_files.append(COMMON_ENV_PATH + 'no_volume.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'with_volume.yaml')",
            "",
            "",
            "def add_fip_env_file(env_files, cluster_template):",
            "    if cluster_template.floating_ip_enabled:",
            "        env_files.append(COMMON_ENV_PATH + 'enable_floating_ip.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'disable_floating_ip.yaml')",
            "",
            "",
            "def add_priv_net_env_file(env_files, cluster_template):",
            "    if cluster_template.fixed_network:",
            "        env_files.append(COMMON_ENV_PATH + 'no_private_network.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'with_private_network.yaml')"
        ],
        "afterPatchFile": [
            "# Copyright 2016 Rackspace Inc. All rights reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "import abc",
            "import ast",
            "",
            "from oslo_log import log as logging",
            "import requests",
            "import six",
            "",
            "from magnum.common import clients",
            "from magnum.common import exception",
            "import magnum.conf",
            "from magnum.i18n import _LE",
            "from magnum.i18n import _LW",
            "",
            "from requests import exceptions as req_exceptions",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "COMMON_TEMPLATES_PATH = \"../../common/templates/\"",
            "COMMON_ENV_PATH = COMMON_TEMPLATES_PATH + \"environments/\"",
            "",
            "CONF = magnum.conf.CONF",
            "",
            "",
            "class ParameterMapping(object):",
            "    \"\"\"A mapping associating heat param and cluster_template attr.",
            "",
            "    A ParameterMapping is an association of a Heat parameter name with",
            "    an attribute on a Cluster, ClusterTemplate, or both.",
            "",
            "    In the case of both cluster_template_attr and cluster_attr being set, the",
            "    ClusterTemplate will be checked first and then Cluster if the attribute",
            "    isn't set on the ClusterTemplate.",
            "",
            "    Parameters can also be set as 'required'. If a required parameter",
            "    isn't set, a RequiredArgumentNotProvided exception will be raised.",
            "    \"\"\"",
            "    def __init__(self, heat_param, cluster_template_attr=None,",
            "                 cluster_attr=None, required=False,",
            "                 param_type=lambda x: x):",
            "        self.heat_param = heat_param",
            "        self.cluster_template_attr = cluster_template_attr",
            "        self.cluster_attr = cluster_attr",
            "        self.required = required",
            "        self.param_type = param_type",
            "",
            "    def set_param(self, params, cluster_template, cluster):",
            "        value = None",
            "",
            "        if (self.cluster_template_attr and",
            "                getattr(cluster_template, self.cluster_template_attr, None)",
            "                is not None):",
            "            value = getattr(cluster_template, self.cluster_template_attr)",
            "        elif (self.cluster_attr and",
            "                getattr(cluster, self.cluster_attr, None) is not None):",
            "            value = getattr(cluster, self.cluster_attr)",
            "        elif self.required:",
            "            kwargs = dict(heat_param=self.heat_param)",
            "            raise exception.RequiredParameterNotProvided(**kwargs)",
            "",
            "        if value is not None:",
            "            value = self.param_type(value)",
            "            params[self.heat_param] = value",
            "",
            "",
            "class OutputMapping(object):",
            "    \"\"\"A mapping associating heat outputs and cluster attr.",
            "",
            "    An OutputMapping is an association of a Heat output with a key",
            "    Magnum understands.",
            "    \"\"\"",
            "",
            "    def __init__(self, heat_output, cluster_attr=None):",
            "        self.cluster_attr = cluster_attr",
            "        self.heat_output = heat_output",
            "",
            "    def set_output(self, stack, cluster_template, cluster):",
            "        if self.cluster_attr is None:",
            "            return",
            "",
            "        output_value = self.get_output_value(stack)",
            "        if output_value is not None:",
            "            setattr(cluster, self.cluster_attr, output_value)",
            "",
            "    def matched(self, output_key):",
            "        return self.heat_output == output_key",
            "",
            "    def get_output_value(self, stack):",
            "        for output in stack.to_dict().get('outputs', []):",
            "            if output['output_key'] == self.heat_output:",
            "                return output['output_value']",
            "",
            "        LOG.warning(_LW('stack does not have output_key %s'), self.heat_output)",
            "        return None",
            "",
            "",
            "@six.add_metaclass(abc.ABCMeta)",
            "class TemplateDefinition(object):",
            "    '''A mapping between Magnum objects and Heat templates.",
            "",
            "    A TemplateDefinition is essentially a mapping between Magnum objects",
            "    and Heat templates. Each TemplateDefinition has a mapping of Heat",
            "    parameters.",
            "    '''",
            "",
            "    def __init__(self):",
            "        self.param_mappings = list()",
            "        self.output_mappings = list()",
            "",
            "    def add_parameter(self, *args, **kwargs):",
            "        param = ParameterMapping(*args, **kwargs)",
            "        self.param_mappings.append(param)",
            "",
            "    def add_output(self, *args, **kwargs):",
            "        mapping_type = kwargs.pop('mapping_type', OutputMapping)",
            "        output = mapping_type(*args, **kwargs)",
            "        self.output_mappings.append(output)",
            "",
            "    def get_output(self, *args, **kwargs):",
            "        for output in self.output_mappings:",
            "            if output.matched(*args, **kwargs):",
            "                return output",
            "",
            "        return None",
            "",
            "    def get_params(self, context, cluster_template, cluster, **kwargs):",
            "        \"\"\"Pulls template parameters from ClusterTemplate.",
            "",
            "        :param context: Context to pull template parameters for",
            "        :param cluster_template: ClusterTemplate to pull template parameters",
            "         from",
            "        :param cluster: Cluster to pull template parameters from",
            "        :param extra_params: Any extra params to be provided to the template",
            "",
            "        :return: dict of template parameters",
            "        \"\"\"",
            "        template_params = dict()",
            "",
            "        for mapping in self.param_mappings:",
            "            mapping.set_param(template_params, cluster_template, cluster)",
            "",
            "        if 'extra_params' in kwargs:",
            "            template_params.update(kwargs.get('extra_params'))",
            "",
            "        return template_params",
            "",
            "    def get_env_files(self, cluster_template):",
            "        \"\"\"Gets stack environment files based upon ClusterTemplate attributes.",
            "",
            "        Base implementation returns no files (empty list). Meant to be",
            "        overridden by subclasses.",
            "",
            "        :param cluster_template: ClusterTemplate to grab environment files for",
            "",
            "        :return: list of relative paths to environment files",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_heat_param(self, cluster_attr=None, cluster_template_attr=None):",
            "        \"\"\"Returns stack param name.",
            "",
            "        Return stack param name using cluster and cluster_template attributes",
            "        :param cluster_attr cluster attribute from which it maps to stack",
            "         attribute",
            "        :param cluster_template_attr cluster_template attribute from which it",
            "         maps to stack attribute",
            "",
            "        :return stack parameter name or None",
            "        \"\"\"",
            "        for mapping in self.param_mappings:",
            "            if (mapping.cluster_attr == cluster_attr and",
            "                    mapping.cluster_template_attr == cluster_template_attr):",
            "                return mapping.heat_param",
            "",
            "        return None",
            "",
            "    def update_outputs(self, stack, cluster_template, cluster):",
            "        for output in self.output_mappings:",
            "            output.set_output(stack, cluster_template, cluster)",
            "",
            "    @abc.abstractproperty",
            "    def driver_module_path(self):",
            "        pass",
            "",
            "    @abc.abstractproperty",
            "    def template_path(self):",
            "        pass",
            "",
            "    def extract_definition(self, context, cluster_template, cluster, **kwargs):",
            "        return (self.template_path,",
            "                self.get_params(context, cluster_template, cluster, **kwargs),",
            "                self.get_env_files(cluster_template))",
            "",
            "",
            "class BaseTemplateDefinition(TemplateDefinition):",
            "    def __init__(self):",
            "        super(BaseTemplateDefinition, self).__init__()",
            "        self._osc = None",
            "",
            "        self.add_parameter('ssh_key_name',",
            "                           cluster_attr='keypair',",
            "                           required=True)",
            "        self.add_parameter('server_image',",
            "                           cluster_template_attr='image_id')",
            "        self.add_parameter('dns_nameserver',",
            "                           cluster_template_attr='dns_nameserver')",
            "        self.add_parameter('http_proxy',",
            "                           cluster_template_attr='http_proxy')",
            "        self.add_parameter('https_proxy',",
            "                           cluster_template_attr='https_proxy')",
            "        self.add_parameter('no_proxy',",
            "                           cluster_template_attr='no_proxy')",
            "        self.add_parameter('number_of_masters',",
            "                           cluster_attr='master_count')",
            "",
            "    @property",
            "    def driver_module_path(self):",
            "        pass",
            "",
            "    @abc.abstractproperty",
            "    def template_path(self):",
            "        pass",
            "",
            "    def get_osc(self, context):",
            "        if not self._osc:",
            "            self._osc = clients.OpenStackClients(context)",
            "        return self._osc",
            "",
            "    def get_params(self, context, cluster_template, cluster, **kwargs):",
            "        osc = self.get_osc(context)",
            "",
            "        extra_params = kwargs.pop('extra_params', {})",
            "        extra_params['trustee_domain_id'] = osc.keystone().trustee_domain_id",
            "        extra_params['trustee_user_id'] = cluster.trustee_user_id",
            "        extra_params['trustee_username'] = cluster.trustee_username",
            "        extra_params['trustee_password'] = cluster.trustee_password",
            "",
            "        # Only pass trust ID into the template when it is needed.",
            "        if (cluster_template.volume_driver == 'rexray' or",
            "                cluster_template.registry_enabled):",
            "            if CONF.trust.cluster_user_trust:",
            "                extra_params['trust_id'] = cluster.trust_id",
            "            else:",
            "                missing_setting = ('trust/cluster_user_trust = True')",
            "                msg = _LE('This cluster can only be created with %s in '",
            "                          'magnum.conf')",
            "                raise exception.ConfigInvalid(msg % missing_setting)",
            "        else:",
            "            extra_params['trust_id'] = \"\"",
            "",
            "        extra_params['auth_url'] = context.auth_url",
            "",
            "        return super(BaseTemplateDefinition,",
            "                     self).get_params(context, cluster_template, cluster,",
            "                                      extra_params=extra_params,",
            "                                      **kwargs)",
            "",
            "    def validate_discovery_url(self, discovery_url, expect_size):",
            "        url = str(discovery_url)",
            "        if url[len(url)-1] == '/':",
            "            url += '_config/size'",
            "        else:",
            "            url += '/_config/size'",
            "",
            "        try:",
            "            result = requests.get(url).text",
            "        except req_exceptions.RequestException as err:",
            "            LOG.error(six.text_type(err))",
            "            raise exception.GetClusterSizeFailed(",
            "                discovery_url=discovery_url)",
            "",
            "        try:",
            "            result = ast.literal_eval(result)",
            "        except (ValueError, SyntaxError):",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "",
            "        node_value = result.get('node', None)",
            "        if node_value is None:",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "",
            "        value = node_value.get('value', None)",
            "        if value is None:",
            "            raise exception.InvalidClusterDiscoveryURL(",
            "                discovery_url=discovery_url)",
            "        elif int(value) != expect_size:",
            "            raise exception.InvalidClusterSize(",
            "                expect_size=expect_size,",
            "                size=int(value),",
            "                discovery_url=discovery_url)",
            "",
            "    def get_discovery_url(self, cluster):",
            "        if hasattr(cluster, 'discovery_url') and cluster.discovery_url:",
            "            if getattr(cluster, 'master_count', None) is not None:",
            "                self.validate_discovery_url(cluster.discovery_url,",
            "                                            cluster.master_count)",
            "            else:",
            "                self.validate_discovery_url(cluster.discovery_url, 1)",
            "            discovery_url = cluster.discovery_url",
            "        else:",
            "            discovery_endpoint = (",
            "                CONF.cluster.etcd_discovery_service_endpoint_format %",
            "                {'size': cluster.master_count})",
            "            try:",
            "                discovery_url = requests.get(discovery_endpoint).text",
            "            except req_exceptions.RequestException as err:",
            "                LOG.error(six.text_type(err))",
            "                raise exception.GetDiscoveryUrlFailed(",
            "                    discovery_endpoint=discovery_endpoint)",
            "            if not discovery_url:",
            "                raise exception.InvalidDiscoveryURL(",
            "                    discovery_url=discovery_url,",
            "                    discovery_endpoint=discovery_endpoint)",
            "            else:",
            "                cluster.discovery_url = discovery_url",
            "        return discovery_url",
            "",
            "",
            "def add_lb_env_file(env_files, cluster_template):",
            "    if cluster_template.master_lb_enabled:",
            "        env_files.append(COMMON_ENV_PATH + 'with_master_lb.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'no_master_lb.yaml')",
            "",
            "",
            "def add_volume_env_file(env_files, cluster_template):",
            "    if cluster_template.docker_volume_size is None:",
            "        env_files.append(COMMON_ENV_PATH + 'no_volume.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'with_volume.yaml')",
            "",
            "",
            "def add_fip_env_file(env_files, cluster_template):",
            "    if cluster_template.floating_ip_enabled:",
            "        env_files.append(COMMON_ENV_PATH + 'enable_floating_ip.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'disable_floating_ip.yaml')",
            "",
            "",
            "def add_priv_net_env_file(env_files, cluster_template):",
            "    if cluster_template.fixed_network:",
            "        env_files.append(COMMON_ENV_PATH + 'no_private_network.yaml')",
            "    else:",
            "        env_files.append(COMMON_ENV_PATH + 'with_private_network.yaml')"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "248": [
                "BaseTemplateDefinition",
                "get_params"
            ]
        },
        "addLocation": []
    }
}