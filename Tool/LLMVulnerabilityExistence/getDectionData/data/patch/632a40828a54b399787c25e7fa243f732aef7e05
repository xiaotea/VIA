{
    "diffoscope/comparators/utils/libarchive.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import ctypes"
            },
            "1": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " import logging"
            },
            "2": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " import libarchive"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+import collections"
            },
            "4": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from diffoscope.tempfiles import get_temporary_directory"
            },
            "6": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 169,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "     def get_member_names(self):"
            },
            "9": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "         self.ensure_unpacked()"
            },
            "10": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return self._member_names"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+        return self._members.keys()"
            },
            "12": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 173,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "     def extract(self, member_name, dest_dir):"
            },
            "14": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "         self.ensure_unpacked()"
            },
            "15": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return os.path.join(self._unpacked, member_name)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+        return self._members[member_name]"
            },
            "17": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 177,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "     def get_member(self, member_name):"
            },
            "19": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "         with libarchive.file_reader(self.source.path) as archive:"
            },
            "20": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "         return LibarchiveMember(self, entry)"
            },
            "21": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": 199,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "     def ensure_unpacked(self):"
            },
            "23": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if hasattr(self, '_unpacked'):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+        if hasattr(self, '_members'):"
            },
            "25": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "             return"
            },
            "26": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 203,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self._unpacked = get_temporary_directory().name"
            },
            "28": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self._member_names = []"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 204,
                "PatchRowcode": "+        tmpdir = get_temporary_directory().name"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+        self._members = collections.OrderedDict()"
            },
            "31": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 206,
                "PatchRowcode": " "
            },
            "32": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)"
            },
            "34": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 208,
                "PatchRowcode": " "
            },
            "35": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "         with libarchive.file_reader(self.source.path) as archive:"
            },
            "36": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            for entry in archive:"
            },
            "37": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self._member_names.append(entry.pathname)"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+            for idx, entry in enumerate(archive):"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+                # Maintain a mapping of archive path to the extracted path,"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+                # avoiding the need to sanitise filenames."
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+                dst = os.path.join(tmpdir, '{}'.format(idx))"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+                self._members[entry.pathname] = dst"
            },
            "43": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 215,
                "PatchRowcode": " "
            },
            "44": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "                 if entry.isdir:"
            },
            "45": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "                     continue"
            },
            "46": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": 218,
                "PatchRowcode": " "
            },
            "47": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # All extracted locations must be underneath self._unpacked"
            },
            "48": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                force_prefix = os.path.join(self._unpacked, \"\")"
            },
            "49": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "50": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # Try to pick a safe and reasonable candidate name"
            },
            "51": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))"
            },
            "52": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if os.path.isabs(candidate_name):"
            },
            "53": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))"
            },
            "54": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "55": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))"
            },
            "56": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if not dst.startswith(force_prefix):"
            },
            "57": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\","
            },
            "58": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                entry.pathname)"
            },
            "59": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    continue"
            },
            "60": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "61": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # TODO: need to fix reading these cleaned members. currently"
            },
            "62": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # reading will still try to use the uncleaned name."
            },
            "63": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)"
            },
            "64": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                os.makedirs(os.path.dirname(dst), exist_ok=True)"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)"
            },
            "66": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 220,
                "PatchRowcode": " "
            },
            "67": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 221,
                "PatchRowcode": "                 with open(dst, 'wb') as f:"
            },
            "68": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 222,
                "PatchRowcode": "                     for block in entry.get_blocks():"
            },
            "69": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 223,
                "PatchRowcode": "                         f.write(block)"
            },
            "70": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 224,
                "PatchRowcode": " "
            },
            "71": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "         logger.debug("
            },
            "72": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 226,
                "PatchRowcode": "             \"Extracted %d entries from %s to %s\","
            },
            "73": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            len(self._member_names), self.source.path, self._unpacked,"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 227,
                "PatchRowcode": "+            len(self._members), self.source.path, tmpdir,"
            },
            "75": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 228,
                "PatchRowcode": "         )"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# diffoscope: in-depth comparison of files, archives, and directories",
            "#",
            "# Copyright \u00a9 2015 J\u00e9r\u00e9my Bobbio <lunar@debian.org>",
            "#",
            "# diffoscope is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# diffoscope is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with diffoscope.  If not, see <https://www.gnu.org/licenses/>.",
            "",
            "",
            "import time",
            "import os.path",
            "import ctypes",
            "import logging",
            "import libarchive",
            "",
            "from diffoscope.tempfiles import get_temporary_directory",
            "",
            "from ..device import Device",
            "from ..symlink import Symlink",
            "from ..directory import Directory",
            "",
            "from .archive import Archive, ArchiveMember",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "# Monkeypatch libarchive-c (<< 2.2)",
            "if not hasattr(libarchive.ffi, 'entry_rdevmajor'):",
            "    libarchive.ffi.ffi('entry_rdevmajor', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.rdevmajor = property(lambda self: libarchive.ffi.entry_rdevmajor(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_rdevminor'):",
            "    libarchive.ffi.ffi('entry_rdevminor', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.rdevminor = property(lambda self: libarchive.ffi.entry_rdevminor(self._entry_p))",
            "# Monkeypatch libarchive-c (<< 2.3)",
            "if not hasattr(libarchive.ffi, 'entry_nlink'):",
            "    libarchive.ffi.ffi('entry_nlink', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.nlink = property(lambda self: libarchive.ffi.entry_nlink(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_uid'):",
            "    libarchive.ffi.ffi('entry_uid', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint32)",
            "    libarchive.ArchiveEntry.uid = property(lambda self: libarchive.ffi.entry_uid(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_gid'):",
            "    libarchive.ffi.ffi('entry_gid', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint32)",
            "    libarchive.ArchiveEntry.gid = property(lambda self: libarchive.ffi.entry_uid(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_mtime_nsec'):",
            "    libarchive.ffi.ffi('entry_mtime_nsec', [libarchive.ffi.c_archive_entry_p], ctypes.c_long)",
            "    libarchive.ArchiveEntry.mtime_nsec = property(lambda self: libarchive.ffi.entry_mtime_nsec(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_uname'):",
            "    libarchive.ffi.ffi('entry_uname', [libarchive.ffi.c_archive_entry_p], ctypes.c_char_p)",
            "    libarchive.ArchiveEntry.uname = property(lambda self: libarchive.ffi.entry_uname(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_gname'):",
            "    libarchive.ffi.ffi('entry_gname', [libarchive.ffi.c_archive_entry_p], ctypes.c_char_p)",
            "    libarchive.ArchiveEntry.gname = property(lambda self: libarchive.ffi.entry_gname(self._entry_p))",
            "",
            "# Monkeypatch libarchive-c so we always get pathname as (Unicode) str",
            "# Otherwise, we'll get sometimes str and sometimes bytes and always pain.",
            "libarchive.ArchiveEntry.pathname = property(lambda self: libarchive.ffi.entry_pathname(self._entry_p).decode('utf-8', errors='surrogateescape'))",
            "",
            "",
            "def list_libarchive(path):",
            "    with libarchive.file_reader(path) as archive:",
            "        for entry in archive:",
            "            if entry.isblk or entry.ischr:",
            "                size_or_dev = '{major:>3},{minor:>3}'.format(major=entry.rdevmajor, minor=entry.rdevminor)",
            "            else:",
            "                size_or_dev = entry.size",
            "            mtime = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(entry.mtime)) + '.{:06d}'.format(entry.mtime_nsec // 1000)",
            "            if entry.issym:",
            "                name_and_link = '{entry.name} -> {entry.linkname}'.format(entry=entry)",
            "            else:",
            "                name_and_link = entry.name",
            "            if entry.uname:",
            "                user = '{user:<8} {uid:>7}'.format(user=entry.uname.decode('utf-8', errors='surrogateescape'), uid='({})'.format(entry.uid))",
            "            else:",
            "                user = entry.uid",
            "            if entry.gname:",
            "                group = '{group:<8} {gid:>7}'.format(group=entry.gname.decode('utf-8', errors='surrogateescape'), gid='({})'.format(entry.gid))",
            "            else:",
            "                group = entry.gid",
            "            yield '{strmode} {entry.nlink:>3} {user:>8} {group:>8} {size_or_dev:>8} {mtime:>8} {name_and_link}\\n'.format(strmode=entry.strmode.decode('us-ascii'), entry=entry, user=user, group=group, size_or_dev=size_or_dev, mtime=mtime, name_and_link=name_and_link)",
            "",
            "",
            "class LibarchiveMember(ArchiveMember):",
            "    def __init__(self, archive, entry):",
            "        super().__init__(archive, entry.pathname)",
            "",
            "    def is_directory(self):",
            "        return False",
            "",
            "    def is_symlink(self):",
            "        return False",
            "",
            "    def is_device(self):",
            "        return False",
            "",
            "",
            "",
            "class LibarchiveDirectory(Directory, LibarchiveMember):",
            "    def __init__(self, archive, entry):",
            "        LibarchiveMember.__init__(self, archive, entry)",
            "",
            "    def compare(self, other, source=None):",
            "        return None",
            "",
            "    def has_same_content_as(self, other):",
            "        return False",
            "",
            "    @property",
            "    def path(self):",
            "        raise NotImplementedError('LibarchiveDirectory is not meant to be extracted.')",
            "",
            "    def is_directory(self):",
            "        return True",
            "",
            "    def get_member_names(self):",
            "        raise ValueError(\"archives are compared as a whole.\")  # noqa",
            "",
            "    def get_member(self, member_name):",
            "        raise ValueError(\"archives are compared as a whole.\")  # noqa",
            "",
            "",
            "class LibarchiveSymlink(Symlink, LibarchiveMember):",
            "    def __init__(self, archive, entry):",
            "        LibarchiveMember.__init__(self, archive, entry)",
            "        self._destination = entry.linkpath",
            "",
            "    @property",
            "    def symlink_destination(self):",
            "        return self._destination",
            "",
            "    def is_symlink(self):",
            "        return True",
            "",
            "",
            "class LibarchiveDevice(Device, LibarchiveMember):",
            "    def __init__(self, container, entry):",
            "        LibarchiveMember.__init__(self, container, entry)",
            "        self._mode = entry.mode",
            "        self._major = entry.rdevmajor",
            "        self._minor = entry.rdevminor",
            "",
            "    def get_device(self):",
            "        return (self._mode, self._major, self._minor)",
            "",
            "    def is_device(self):",
            "        return True",
            "",
            "",
            "class LibarchiveContainer(Archive):",
            "    def open_archive(self):",
            "        # libarchive is very very stream oriented an not for random access",
            "        # so we are going to reopen the archive everytime",
            "        # not nice, but it'll work",
            "        return True",
            "",
            "    def close_archive(self):",
            "        pass",
            "",
            "    def get_member_names(self):",
            "        self.ensure_unpacked()",
            "        return self._member_names",
            "",
            "    def extract(self, member_name, dest_dir):",
            "        self.ensure_unpacked()",
            "        return os.path.join(self._unpacked, member_name)",
            "",
            "    def get_member(self, member_name):",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for entry in archive:",
            "                if entry.pathname == member_name:",
            "                    return self.get_subclass(entry)",
            "        raise KeyError('%s not found in archive', member_name)",
            "",
            "    def get_all_members(self):",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for entry in archive:",
            "                yield entry.pathname, self.get_subclass(entry)",
            "",
            "    def get_subclass(self, entry):",
            "        if entry.isdir:",
            "            return LibarchiveDirectory(self, entry)",
            "        elif entry.issym:",
            "            return LibarchiveSymlink(self, entry)",
            "        elif entry.isblk or entry.ischr:",
            "            return LibarchiveDevice(self, entry)",
            "",
            "        return LibarchiveMember(self, entry)",
            "",
            "    def ensure_unpacked(self):",
            "        if hasattr(self, '_unpacked'):",
            "            return",
            "",
            "        self._unpacked = get_temporary_directory().name",
            "        self._member_names = []",
            "",
            "        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)",
            "",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for entry in archive:",
            "                self._member_names.append(entry.pathname)",
            "",
            "                if entry.isdir:",
            "                    continue",
            "",
            "                # All extracted locations must be underneath self._unpacked",
            "                force_prefix = os.path.join(self._unpacked, \"\")",
            "",
            "                # Try to pick a safe and reasonable candidate name",
            "                candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))",
            "                if os.path.isabs(candidate_name):",
            "                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))",
            "",
            "                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))",
            "                if not dst.startswith(force_prefix):",
            "                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",",
            "                                entry.pathname)",
            "                    continue",
            "",
            "                # TODO: need to fix reading these cleaned members. currently",
            "                # reading will still try to use the uncleaned name.",
            "                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)",
            "                os.makedirs(os.path.dirname(dst), exist_ok=True)",
            "",
            "                with open(dst, 'wb') as f:",
            "                    for block in entry.get_blocks():",
            "                        f.write(block)",
            "",
            "        logger.debug(",
            "            \"Extracted %d entries from %s to %s\",",
            "            len(self._member_names), self.source.path, self._unpacked,",
            "        )"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "#",
            "# diffoscope: in-depth comparison of files, archives, and directories",
            "#",
            "# Copyright \u00a9 2015 J\u00e9r\u00e9my Bobbio <lunar@debian.org>",
            "#",
            "# diffoscope is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# diffoscope is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with diffoscope.  If not, see <https://www.gnu.org/licenses/>.",
            "",
            "",
            "import time",
            "import os.path",
            "import ctypes",
            "import logging",
            "import libarchive",
            "import collections",
            "",
            "from diffoscope.tempfiles import get_temporary_directory",
            "",
            "from ..device import Device",
            "from ..symlink import Symlink",
            "from ..directory import Directory",
            "",
            "from .archive import Archive, ArchiveMember",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "# Monkeypatch libarchive-c (<< 2.2)",
            "if not hasattr(libarchive.ffi, 'entry_rdevmajor'):",
            "    libarchive.ffi.ffi('entry_rdevmajor', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.rdevmajor = property(lambda self: libarchive.ffi.entry_rdevmajor(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_rdevminor'):",
            "    libarchive.ffi.ffi('entry_rdevminor', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.rdevminor = property(lambda self: libarchive.ffi.entry_rdevminor(self._entry_p))",
            "# Monkeypatch libarchive-c (<< 2.3)",
            "if not hasattr(libarchive.ffi, 'entry_nlink'):",
            "    libarchive.ffi.ffi('entry_nlink', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint)",
            "    libarchive.ArchiveEntry.nlink = property(lambda self: libarchive.ffi.entry_nlink(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_uid'):",
            "    libarchive.ffi.ffi('entry_uid', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint32)",
            "    libarchive.ArchiveEntry.uid = property(lambda self: libarchive.ffi.entry_uid(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_gid'):",
            "    libarchive.ffi.ffi('entry_gid', [libarchive.ffi.c_archive_entry_p], ctypes.c_uint32)",
            "    libarchive.ArchiveEntry.gid = property(lambda self: libarchive.ffi.entry_uid(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_mtime_nsec'):",
            "    libarchive.ffi.ffi('entry_mtime_nsec', [libarchive.ffi.c_archive_entry_p], ctypes.c_long)",
            "    libarchive.ArchiveEntry.mtime_nsec = property(lambda self: libarchive.ffi.entry_mtime_nsec(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_uname'):",
            "    libarchive.ffi.ffi('entry_uname', [libarchive.ffi.c_archive_entry_p], ctypes.c_char_p)",
            "    libarchive.ArchiveEntry.uname = property(lambda self: libarchive.ffi.entry_uname(self._entry_p))",
            "if not hasattr(libarchive.ffi, 'entry_gname'):",
            "    libarchive.ffi.ffi('entry_gname', [libarchive.ffi.c_archive_entry_p], ctypes.c_char_p)",
            "    libarchive.ArchiveEntry.gname = property(lambda self: libarchive.ffi.entry_gname(self._entry_p))",
            "",
            "# Monkeypatch libarchive-c so we always get pathname as (Unicode) str",
            "# Otherwise, we'll get sometimes str and sometimes bytes and always pain.",
            "libarchive.ArchiveEntry.pathname = property(lambda self: libarchive.ffi.entry_pathname(self._entry_p).decode('utf-8', errors='surrogateescape'))",
            "",
            "",
            "def list_libarchive(path):",
            "    with libarchive.file_reader(path) as archive:",
            "        for entry in archive:",
            "            if entry.isblk or entry.ischr:",
            "                size_or_dev = '{major:>3},{minor:>3}'.format(major=entry.rdevmajor, minor=entry.rdevminor)",
            "            else:",
            "                size_or_dev = entry.size",
            "            mtime = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(entry.mtime)) + '.{:06d}'.format(entry.mtime_nsec // 1000)",
            "            if entry.issym:",
            "                name_and_link = '{entry.name} -> {entry.linkname}'.format(entry=entry)",
            "            else:",
            "                name_and_link = entry.name",
            "            if entry.uname:",
            "                user = '{user:<8} {uid:>7}'.format(user=entry.uname.decode('utf-8', errors='surrogateescape'), uid='({})'.format(entry.uid))",
            "            else:",
            "                user = entry.uid",
            "            if entry.gname:",
            "                group = '{group:<8} {gid:>7}'.format(group=entry.gname.decode('utf-8', errors='surrogateescape'), gid='({})'.format(entry.gid))",
            "            else:",
            "                group = entry.gid",
            "            yield '{strmode} {entry.nlink:>3} {user:>8} {group:>8} {size_or_dev:>8} {mtime:>8} {name_and_link}\\n'.format(strmode=entry.strmode.decode('us-ascii'), entry=entry, user=user, group=group, size_or_dev=size_or_dev, mtime=mtime, name_and_link=name_and_link)",
            "",
            "",
            "class LibarchiveMember(ArchiveMember):",
            "    def __init__(self, archive, entry):",
            "        super().__init__(archive, entry.pathname)",
            "",
            "    def is_directory(self):",
            "        return False",
            "",
            "    def is_symlink(self):",
            "        return False",
            "",
            "    def is_device(self):",
            "        return False",
            "",
            "",
            "",
            "class LibarchiveDirectory(Directory, LibarchiveMember):",
            "    def __init__(self, archive, entry):",
            "        LibarchiveMember.__init__(self, archive, entry)",
            "",
            "    def compare(self, other, source=None):",
            "        return None",
            "",
            "    def has_same_content_as(self, other):",
            "        return False",
            "",
            "    @property",
            "    def path(self):",
            "        raise NotImplementedError('LibarchiveDirectory is not meant to be extracted.')",
            "",
            "    def is_directory(self):",
            "        return True",
            "",
            "    def get_member_names(self):",
            "        raise ValueError(\"archives are compared as a whole.\")  # noqa",
            "",
            "    def get_member(self, member_name):",
            "        raise ValueError(\"archives are compared as a whole.\")  # noqa",
            "",
            "",
            "class LibarchiveSymlink(Symlink, LibarchiveMember):",
            "    def __init__(self, archive, entry):",
            "        LibarchiveMember.__init__(self, archive, entry)",
            "        self._destination = entry.linkpath",
            "",
            "    @property",
            "    def symlink_destination(self):",
            "        return self._destination",
            "",
            "    def is_symlink(self):",
            "        return True",
            "",
            "",
            "class LibarchiveDevice(Device, LibarchiveMember):",
            "    def __init__(self, container, entry):",
            "        LibarchiveMember.__init__(self, container, entry)",
            "        self._mode = entry.mode",
            "        self._major = entry.rdevmajor",
            "        self._minor = entry.rdevminor",
            "",
            "    def get_device(self):",
            "        return (self._mode, self._major, self._minor)",
            "",
            "    def is_device(self):",
            "        return True",
            "",
            "",
            "class LibarchiveContainer(Archive):",
            "    def open_archive(self):",
            "        # libarchive is very very stream oriented an not for random access",
            "        # so we are going to reopen the archive everytime",
            "        # not nice, but it'll work",
            "        return True",
            "",
            "    def close_archive(self):",
            "        pass",
            "",
            "    def get_member_names(self):",
            "        self.ensure_unpacked()",
            "        return self._members.keys()",
            "",
            "    def extract(self, member_name, dest_dir):",
            "        self.ensure_unpacked()",
            "        return self._members[member_name]",
            "",
            "    def get_member(self, member_name):",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for entry in archive:",
            "                if entry.pathname == member_name:",
            "                    return self.get_subclass(entry)",
            "        raise KeyError('%s not found in archive', member_name)",
            "",
            "    def get_all_members(self):",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for entry in archive:",
            "                yield entry.pathname, self.get_subclass(entry)",
            "",
            "    def get_subclass(self, entry):",
            "        if entry.isdir:",
            "            return LibarchiveDirectory(self, entry)",
            "        elif entry.issym:",
            "            return LibarchiveSymlink(self, entry)",
            "        elif entry.isblk or entry.ischr:",
            "            return LibarchiveDevice(self, entry)",
            "",
            "        return LibarchiveMember(self, entry)",
            "",
            "    def ensure_unpacked(self):",
            "        if hasattr(self, '_members'):",
            "            return",
            "",
            "        tmpdir = get_temporary_directory().name",
            "        self._members = collections.OrderedDict()",
            "",
            "        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)",
            "",
            "        with libarchive.file_reader(self.source.path) as archive:",
            "            for idx, entry in enumerate(archive):",
            "                # Maintain a mapping of archive path to the extracted path,",
            "                # avoiding the need to sanitise filenames.",
            "                dst = os.path.join(tmpdir, '{}'.format(idx))",
            "                self._members[entry.pathname] = dst",
            "",
            "                if entry.isdir:",
            "                    continue",
            "",
            "                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)",
            "",
            "                with open(dst, 'wb') as f:",
            "                    for block in entry.get_blocks():",
            "                        f.write(block)",
            "",
            "        logger.debug(",
            "            \"Extracted %d entries from %s to %s\",",
            "            len(self._members), self.source.path, tmpdir,",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0"
        ],
        "dele_reviseLocation": {
            "171": [
                "LibarchiveContainer",
                "get_member_names"
            ],
            "175": [
                "LibarchiveContainer",
                "extract"
            ],
            "200": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "203": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "204": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "206": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "209": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "210": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "215": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "216": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "217": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "218": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "219": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "220": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "221": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "222": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "223": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "224": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "225": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "226": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "227": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "228": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "229": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "230": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "231": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "232": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ],
            "240": [
                "LibarchiveContainer",
                "ensure_unpacked"
            ]
        },
        "addLocation": []
    }
}