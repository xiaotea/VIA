{
    "airflow/providers/apache/hive/transfers/hive_to_mysql.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         import, typically used to move data from staging to"
            },
            "1": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "         production and issue cleanup commands. (templated)"
            },
            "2": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     :param bulk_load: flag to use bulk_load option.  This loads mysql directly"
            },
            "3": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command."
            },
            "4": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        This option requires an extra connection parameter for the"
            },
            "5": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        destination MySQL connection: {'local_infile': true}."
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command. The MySQL"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+        server must support loading local files via this command (it is disabled by default)."
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+"
            },
            "9": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "     :param hive_conf:"
            },
            "10": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "     \"\"\""
            },
            "11": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "                     output_header=False,"
            },
            "13": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "                     hive_conf=hive_conf,"
            },
            "14": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 107,
                "PatchRowcode": "                 )"
            },
            "15": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                mysql = self._call_preoperator()"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+                mysql = self._call_preoperator(local_infile=self.bulk_load)"
            },
            "17": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "                 mysql.bulk_load(table=self.mysql_table, tmp_file=tmp_file.name)"
            },
            "18": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "         else:"
            },
            "19": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 111,
                "PatchRowcode": "             hive_results = hive.get_records(self.sql, parameters=hive_conf)"
            },
            "20": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 118,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "         self.log.info(\"Done.\")"
            },
            "22": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 120,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def _call_preoperator(self):"
            },
            "24": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+    def _call_preoperator(self, local_infile: bool = False) -> MySqlHook:"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id, local_infile=local_infile)"
            },
            "27": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         if self.mysql_preoperator:"
            },
            "28": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "             self.log.info(\"Running MySQL preoperator\")"
            },
            "29": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "             mysql.run(self.mysql_preoperator)"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"This module contains an operator to move data from Hive to MySQL.\"\"\"",
            "from __future__ import annotations",
            "",
            "from tempfile import NamedTemporaryFile",
            "from typing import TYPE_CHECKING, Sequence",
            "",
            "from airflow.models import BaseOperator",
            "from airflow.providers.apache.hive.hooks.hive import HiveServer2Hook",
            "from airflow.providers.mysql.hooks.mysql import MySqlHook",
            "from airflow.utils.operator_helpers import context_to_airflow_vars",
            "",
            "if TYPE_CHECKING:",
            "    from airflow.utils.context import Context",
            "",
            "",
            "class HiveToMySqlOperator(BaseOperator):",
            "    \"\"\"",
            "    Moves data from Hive to MySQL, note that for now the data is loaded",
            "    into memory before being pushed to MySQL, so this operator should",
            "    be used for smallish amount of data.",
            "",
            "    :param sql: SQL query to execute against Hive server. (templated)",
            "    :param mysql_table: target MySQL table, use dot notation to target a",
            "        specific database. (templated)",
            "    :param mysql_conn_id: source mysql connection",
            "    :param hiveserver2_conn_id: Reference to the",
            "        :ref:`Hive Server2 thrift service connection id <howto/connection:hiveserver2>`.",
            "    :param mysql_preoperator: sql statement to run against mysql prior to",
            "        import, typically use to truncate of delete in place",
            "        of the data coming in, allowing the task to be idempotent (running",
            "        the task twice won't double load data). (templated)",
            "    :param mysql_postoperator: sql statement to run against mysql after the",
            "        import, typically used to move data from staging to",
            "        production and issue cleanup commands. (templated)",
            "    :param bulk_load: flag to use bulk_load option.  This loads mysql directly",
            "        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command.",
            "        This option requires an extra connection parameter for the",
            "        destination MySQL connection: {'local_infile': true}.",
            "    :param hive_conf:",
            "    \"\"\"",
            "",
            "    template_fields: Sequence[str] = (\"sql\", \"mysql_table\", \"mysql_preoperator\", \"mysql_postoperator\")",
            "    template_ext: Sequence[str] = (\".sql\",)",
            "    template_fields_renderers = {",
            "        \"sql\": \"hql\",",
            "        \"mysql_preoperator\": \"mysql\",",
            "        \"mysql_postoperator\": \"mysql\",",
            "    }",
            "    ui_color = \"#a0e08c\"",
            "",
            "    def __init__(",
            "        self,",
            "        *,",
            "        sql: str,",
            "        mysql_table: str,",
            "        hiveserver2_conn_id: str = \"hiveserver2_default\",",
            "        mysql_conn_id: str = \"mysql_default\",",
            "        mysql_preoperator: str | None = None,",
            "        mysql_postoperator: str | None = None,",
            "        bulk_load: bool = False,",
            "        hive_conf: dict | None = None,",
            "        **kwargs,",
            "    ) -> None:",
            "        super().__init__(**kwargs)",
            "        self.sql = sql",
            "        self.mysql_table = mysql_table",
            "        self.mysql_conn_id = mysql_conn_id",
            "        self.mysql_preoperator = mysql_preoperator",
            "        self.mysql_postoperator = mysql_postoperator",
            "        self.hiveserver2_conn_id = hiveserver2_conn_id",
            "        self.bulk_load = bulk_load",
            "        self.hive_conf = hive_conf",
            "",
            "    def execute(self, context: Context):",
            "        hive = HiveServer2Hook(hiveserver2_conn_id=self.hiveserver2_conn_id)",
            "",
            "        self.log.info(\"Extracting data from Hive: %s\", self.sql)",
            "        hive_conf = context_to_airflow_vars(context)",
            "        if self.hive_conf:",
            "            hive_conf.update(self.hive_conf)",
            "        if self.bulk_load:",
            "            with NamedTemporaryFile() as tmp_file:",
            "                hive.to_csv(",
            "                    self.sql,",
            "                    tmp_file.name,",
            "                    delimiter=\"\\t\",",
            "                    lineterminator=\"\\n\",",
            "                    output_header=False,",
            "                    hive_conf=hive_conf,",
            "                )",
            "                mysql = self._call_preoperator()",
            "                mysql.bulk_load(table=self.mysql_table, tmp_file=tmp_file.name)",
            "        else:",
            "            hive_results = hive.get_records(self.sql, parameters=hive_conf)",
            "            mysql = self._call_preoperator()",
            "            mysql.insert_rows(table=self.mysql_table, rows=hive_results)",
            "",
            "        if self.mysql_postoperator:",
            "            self.log.info(\"Running MySQL postoperator\")",
            "            mysql.run(self.mysql_postoperator)",
            "",
            "        self.log.info(\"Done.\")",
            "",
            "    def _call_preoperator(self):",
            "        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)",
            "        if self.mysql_preoperator:",
            "            self.log.info(\"Running MySQL preoperator\")",
            "            mysql.run(self.mysql_preoperator)",
            "        self.log.info(\"Inserting rows into MySQL\")",
            "        return mysql"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"This module contains an operator to move data from Hive to MySQL.\"\"\"",
            "from __future__ import annotations",
            "",
            "from tempfile import NamedTemporaryFile",
            "from typing import TYPE_CHECKING, Sequence",
            "",
            "from airflow.models import BaseOperator",
            "from airflow.providers.apache.hive.hooks.hive import HiveServer2Hook",
            "from airflow.providers.mysql.hooks.mysql import MySqlHook",
            "from airflow.utils.operator_helpers import context_to_airflow_vars",
            "",
            "if TYPE_CHECKING:",
            "    from airflow.utils.context import Context",
            "",
            "",
            "class HiveToMySqlOperator(BaseOperator):",
            "    \"\"\"",
            "    Moves data from Hive to MySQL, note that for now the data is loaded",
            "    into memory before being pushed to MySQL, so this operator should",
            "    be used for smallish amount of data.",
            "",
            "    :param sql: SQL query to execute against Hive server. (templated)",
            "    :param mysql_table: target MySQL table, use dot notation to target a",
            "        specific database. (templated)",
            "    :param mysql_conn_id: source mysql connection",
            "    :param hiveserver2_conn_id: Reference to the",
            "        :ref:`Hive Server2 thrift service connection id <howto/connection:hiveserver2>`.",
            "    :param mysql_preoperator: sql statement to run against mysql prior to",
            "        import, typically use to truncate of delete in place",
            "        of the data coming in, allowing the task to be idempotent (running",
            "        the task twice won't double load data). (templated)",
            "    :param mysql_postoperator: sql statement to run against mysql after the",
            "        import, typically used to move data from staging to",
            "        production and issue cleanup commands. (templated)",
            "    :param bulk_load: flag to use bulk_load option.  This loads mysql directly",
            "        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command. The MySQL",
            "        server must support loading local files via this command (it is disabled by default).",
            "",
            "    :param hive_conf:",
            "    \"\"\"",
            "",
            "    template_fields: Sequence[str] = (\"sql\", \"mysql_table\", \"mysql_preoperator\", \"mysql_postoperator\")",
            "    template_ext: Sequence[str] = (\".sql\",)",
            "    template_fields_renderers = {",
            "        \"sql\": \"hql\",",
            "        \"mysql_preoperator\": \"mysql\",",
            "        \"mysql_postoperator\": \"mysql\",",
            "    }",
            "    ui_color = \"#a0e08c\"",
            "",
            "    def __init__(",
            "        self,",
            "        *,",
            "        sql: str,",
            "        mysql_table: str,",
            "        hiveserver2_conn_id: str = \"hiveserver2_default\",",
            "        mysql_conn_id: str = \"mysql_default\",",
            "        mysql_preoperator: str | None = None,",
            "        mysql_postoperator: str | None = None,",
            "        bulk_load: bool = False,",
            "        hive_conf: dict | None = None,",
            "        **kwargs,",
            "    ) -> None:",
            "        super().__init__(**kwargs)",
            "        self.sql = sql",
            "        self.mysql_table = mysql_table",
            "        self.mysql_conn_id = mysql_conn_id",
            "        self.mysql_preoperator = mysql_preoperator",
            "        self.mysql_postoperator = mysql_postoperator",
            "        self.hiveserver2_conn_id = hiveserver2_conn_id",
            "        self.bulk_load = bulk_load",
            "        self.hive_conf = hive_conf",
            "",
            "    def execute(self, context: Context):",
            "        hive = HiveServer2Hook(hiveserver2_conn_id=self.hiveserver2_conn_id)",
            "",
            "        self.log.info(\"Extracting data from Hive: %s\", self.sql)",
            "        hive_conf = context_to_airflow_vars(context)",
            "        if self.hive_conf:",
            "            hive_conf.update(self.hive_conf)",
            "        if self.bulk_load:",
            "            with NamedTemporaryFile() as tmp_file:",
            "                hive.to_csv(",
            "                    self.sql,",
            "                    tmp_file.name,",
            "                    delimiter=\"\\t\",",
            "                    lineterminator=\"\\n\",",
            "                    output_header=False,",
            "                    hive_conf=hive_conf,",
            "                )",
            "                mysql = self._call_preoperator(local_infile=self.bulk_load)",
            "                mysql.bulk_load(table=self.mysql_table, tmp_file=tmp_file.name)",
            "        else:",
            "            hive_results = hive.get_records(self.sql, parameters=hive_conf)",
            "            mysql = self._call_preoperator()",
            "            mysql.insert_rows(table=self.mysql_table, rows=hive_results)",
            "",
            "        if self.mysql_postoperator:",
            "            self.log.info(\"Running MySQL postoperator\")",
            "            mysql.run(self.mysql_postoperator)",
            "",
            "        self.log.info(\"Done.\")",
            "",
            "    def _call_preoperator(self, local_infile: bool = False) -> MySqlHook:",
            "        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id, local_infile=local_infile)",
            "        if self.mysql_preoperator:",
            "            self.log.info(\"Running MySQL preoperator\")",
            "            mysql.run(self.mysql_preoperator)",
            "        self.log.info(\"Inserting rows into MySQL\")",
            "        return mysql"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "53": [
                "HiveToMySqlOperator"
            ],
            "54": [
                "HiveToMySqlOperator"
            ],
            "55": [
                "HiveToMySqlOperator"
            ],
            "108": [
                "HiveToMySqlOperator",
                "execute"
            ],
            "121": [
                "HiveToMySqlOperator",
                "_call_preoperator"
            ],
            "122": [
                "HiveToMySqlOperator",
                "_call_preoperator"
            ]
        },
        "addLocation": []
    },
    "airflow/providers/mysql/hooks/mysql.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "     in extras."
            },
            "1": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "     extras example: ``{\"iam\":true, \"aws_conn_id\":\"my_aws_conn\"}``"
            },
            "2": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+    You can also add \"local_infile\" parameter to determine whether local_infile feature of MySQL client is"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+    going to be enabled (it is disabled by default)."
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "     :param schema: The MySQL database schema to connect to."
            },
            "7": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     :param connection: The :ref:`MySQL connection id <howto/connection:mysql>` used for MySQL credentials."
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+    :param local_infile: Boolean flag determining if local_infile should be used"
            },
            "9": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "     \"\"\""
            },
            "10": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "     conn_name_attr = \"mysql_conn_id\""
            },
            "12": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "         super().__init__(*args, **kwargs)"
            },
            "13": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         self.schema = kwargs.pop(\"schema\", None)"
            },
            "14": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "         self.connection = kwargs.pop(\"connection\", None)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+        self.local_infile = kwargs.pop(\"local_infile\", False)"
            },
            "16": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     def set_autocommit(self, conn: MySQLConnectionTypes, autocommit: bool) -> None:"
            },
            "18": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "         \"\"\""
            },
            "19": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "                 conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor"
            },
            "20": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "             elif (conn.extra_dejson[\"cursor\"]).lower() == \"ssdictcursor\":"
            },
            "21": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "                 conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor"
            },
            "22": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        local_infile = conn.extra_dejson.get(\"local_infile\", False)"
            },
            "23": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "         if conn.extra_dejson.get(\"ssl\", False):"
            },
            "24": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "             # SSL parameter for MySQL has to be a dictionary and in case"
            },
            "25": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "             # of extra/dejson we can get string if extra is passed via"
            },
            "26": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "             conn_config[\"ssl_mode\"] = conn.extra_dejson[\"ssl_mode\"]"
            },
            "27": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "         if conn.extra_dejson.get(\"unix_socket\"):"
            },
            "28": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "             conn_config[\"unix_socket\"] = conn.extra_dejson[\"unix_socket\"]"
            },
            "29": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if local_infile:"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+        if self.local_infile:"
            },
            "31": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "             conn_config[\"local_infile\"] = 1"
            },
            "32": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         return conn_config"
            },
            "33": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 141,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "             \"port\": int(conn.port) if conn.port else 3306,"
            },
            "35": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "         }"
            },
            "36": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if conn.extra_dejson.get(\"allow_local_infile\", False):"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+        if self.local_infile:"
            },
            "39": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "             conn_config[\"allow_local_infile\"] = True"
            },
            "40": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "         # Ref: https://dev.mysql.com/doc/connector-python/en/connector-python-connectargs.html"
            },
            "41": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "         for key, value in conn.extra_dejson.items():"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"This module allows to connect to a MySQL database.\"\"\"",
            "from __future__ import annotations",
            "",
            "import json",
            "from typing import TYPE_CHECKING, Any, Union",
            "",
            "from airflow.models import Connection",
            "from airflow.providers.common.sql.hooks.sql import DbApiHook",
            "",
            "if TYPE_CHECKING:",
            "    from mysql.connector.abstracts import MySQLConnectionAbstract",
            "    from MySQLdb.connections import Connection as MySQLdbConnection",
            "",
            "MySQLConnectionTypes = Union[\"MySQLdbConnection\", \"MySQLConnectionAbstract\"]",
            "",
            "",
            "class MySqlHook(DbApiHook):",
            "    \"\"\"",
            "    Interact with MySQL.",
            "",
            "    You can specify charset in the extra field of your connection",
            "    as ``{\"charset\": \"utf8\"}``. Also you can choose cursor as",
            "    ``{\"cursor\": \"SSCursor\"}``. Refer to the MySQLdb.cursors for more details.",
            "",
            "    Note: For AWS IAM authentication, use iam in the extra connection parameters",
            "    and set it to true. Leave the password field empty. This will use the",
            "    \"aws_default\" connection to get the temporary token unless you override",
            "    in extras.",
            "    extras example: ``{\"iam\":true, \"aws_conn_id\":\"my_aws_conn\"}``",
            "",
            "    :param schema: The MySQL database schema to connect to.",
            "    :param connection: The :ref:`MySQL connection id <howto/connection:mysql>` used for MySQL credentials.",
            "    \"\"\"",
            "",
            "    conn_name_attr = \"mysql_conn_id\"",
            "    default_conn_name = \"mysql_default\"",
            "    conn_type = \"mysql\"",
            "    hook_name = \"MySQL\"",
            "    supports_autocommit = True",
            "",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.schema = kwargs.pop(\"schema\", None)",
            "        self.connection = kwargs.pop(\"connection\", None)",
            "",
            "    def set_autocommit(self, conn: MySQLConnectionTypes, autocommit: bool) -> None:",
            "        \"\"\"",
            "        Set *autocommit*.",
            "",
            "        *mysqlclient* uses an *autocommit* method rather than an *autocommit*",
            "        property, so we need to override this to support it.",
            "",
            "        :param conn: connection to set autocommit setting",
            "        :param autocommit: autocommit setting",
            "        \"\"\"",
            "        if hasattr(conn.__class__, \"autocommit\") and isinstance(conn.__class__.autocommit, property):",
            "            conn.autocommit = autocommit",
            "        else:",
            "            conn.autocommit(autocommit)",
            "",
            "    def get_autocommit(self, conn: MySQLConnectionTypes) -> bool:",
            "        \"\"\"",
            "        Whether *autocommit* is active.",
            "",
            "        *mysqlclient* uses an *get_autocommit* method rather than an *autocommit*",
            "        property, so we need to override this to support it.",
            "",
            "        :param conn: connection to get autocommit setting from.",
            "        :return: connection autocommit setting",
            "        \"\"\"",
            "        if hasattr(conn.__class__, \"autocommit\") and isinstance(conn.__class__.autocommit, property):",
            "            return conn.autocommit",
            "        else:",
            "            return conn.get_autocommit()",
            "",
            "    def _get_conn_config_mysql_client(self, conn: Connection) -> dict:",
            "        conn_config = {",
            "            \"user\": conn.login,",
            "            \"passwd\": conn.password or \"\",",
            "            \"host\": conn.host or \"localhost\",",
            "            \"db\": self.schema or conn.schema or \"\",",
            "        }",
            "",
            "        # check for authentication via AWS IAM",
            "        if conn.extra_dejson.get(\"iam\", False):",
            "            conn_config[\"passwd\"], conn.port = self.get_iam_token(conn)",
            "            conn_config[\"read_default_group\"] = \"enable-cleartext-plugin\"",
            "",
            "        conn_config[\"port\"] = int(conn.port) if conn.port else 3306",
            "",
            "        if conn.extra_dejson.get(\"charset\", False):",
            "            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]",
            "            if conn_config[\"charset\"].lower() in (\"utf8\", \"utf-8\"):",
            "                conn_config[\"use_unicode\"] = True",
            "        if conn.extra_dejson.get(\"cursor\", False):",
            "            import MySQLdb.cursors",
            "",
            "            if (conn.extra_dejson[\"cursor\"]).lower() == \"sscursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor",
            "            elif (conn.extra_dejson[\"cursor\"]).lower() == \"dictcursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor",
            "            elif (conn.extra_dejson[\"cursor\"]).lower() == \"ssdictcursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor",
            "        local_infile = conn.extra_dejson.get(\"local_infile\", False)",
            "        if conn.extra_dejson.get(\"ssl\", False):",
            "            # SSL parameter for MySQL has to be a dictionary and in case",
            "            # of extra/dejson we can get string if extra is passed via",
            "            # URL parameters",
            "            dejson_ssl = conn.extra_dejson[\"ssl\"]",
            "            if isinstance(dejson_ssl, str):",
            "                dejson_ssl = json.loads(dejson_ssl)",
            "            conn_config[\"ssl\"] = dejson_ssl",
            "        if conn.extra_dejson.get(\"ssl_mode\", False):",
            "            conn_config[\"ssl_mode\"] = conn.extra_dejson[\"ssl_mode\"]",
            "        if conn.extra_dejson.get(\"unix_socket\"):",
            "            conn_config[\"unix_socket\"] = conn.extra_dejson[\"unix_socket\"]",
            "        if local_infile:",
            "            conn_config[\"local_infile\"] = 1",
            "        return conn_config",
            "",
            "    def _get_conn_config_mysql_connector_python(self, conn: Connection) -> dict:",
            "        conn_config = {",
            "            \"user\": conn.login,",
            "            \"password\": conn.password or \"\",",
            "            \"host\": conn.host or \"localhost\",",
            "            \"database\": self.schema or conn.schema or \"\",",
            "            \"port\": int(conn.port) if conn.port else 3306,",
            "        }",
            "",
            "        if conn.extra_dejson.get(\"allow_local_infile\", False):",
            "            conn_config[\"allow_local_infile\"] = True",
            "        # Ref: https://dev.mysql.com/doc/connector-python/en/connector-python-connectargs.html",
            "        for key, value in conn.extra_dejson.items():",
            "            if key.startswith(\"ssl_\"):",
            "                conn_config[key] = value",
            "",
            "        return conn_config",
            "",
            "    def get_conn(self) -> MySQLConnectionTypes:",
            "        \"\"\"",
            "        Connection to a MySQL database.",
            "",
            "        Establishes a connection to a mysql database",
            "        by extracting the connection configuration from the Airflow connection.",
            "",
            "        .. note:: By default it connects to the database via the mysqlclient library.",
            "            But you can also choose the mysql-connector-python library which lets you connect through ssl",
            "            without any further ssl parameters required.",
            "",
            "        :return: a mysql connection object",
            "        \"\"\"",
            "        conn = self.connection or self.get_connection(getattr(self, self.conn_name_attr))",
            "",
            "        client_name = conn.extra_dejson.get(\"client\", \"mysqlclient\")",
            "",
            "        if client_name == \"mysqlclient\":",
            "            import MySQLdb",
            "",
            "            conn_config = self._get_conn_config_mysql_client(conn)",
            "            return MySQLdb.connect(**conn_config)",
            "",
            "        if client_name == \"mysql-connector-python\":",
            "            import mysql.connector",
            "",
            "            conn_config = self._get_conn_config_mysql_connector_python(conn)",
            "            return mysql.connector.connect(**conn_config)",
            "",
            "        raise ValueError(\"Unknown MySQL client name provided!\")",
            "",
            "    def bulk_load(self, table: str, tmp_file: str) -> None:",
            "        \"\"\"Load a tab-delimited file into a database table.\"\"\"",
            "        conn = self.get_conn()",
            "        cur = conn.cursor()",
            "        cur.execute(",
            "            f\"\"\"",
            "            LOAD DATA LOCAL INFILE '{tmp_file}'",
            "            INTO TABLE {table}",
            "            \"\"\"",
            "        )",
            "        conn.commit()",
            "        conn.close()",
            "",
            "    def bulk_dump(self, table: str, tmp_file: str) -> None:",
            "        \"\"\"Dump a database table into a tab-delimited file.\"\"\"",
            "        conn = self.get_conn()",
            "        cur = conn.cursor()",
            "        cur.execute(",
            "            f\"\"\"",
            "            SELECT * INTO OUTFILE '{tmp_file}'",
            "            FROM {table}",
            "            \"\"\"",
            "        )",
            "        conn.commit()",
            "        conn.close()",
            "",
            "    @staticmethod",
            "    def _serialize_cell(cell: object, conn: Connection | None = None) -> Any:",
            "        \"\"\"",
            "        Convert argument to a literal.",
            "",
            "        The package MySQLdb converts an argument to a literal",
            "        when passing those separately to execute. Hence, this method does nothing.",
            "",
            "        :param cell: The cell to insert into the table",
            "        :param conn: The database connection",
            "        :return: The same cell",
            "        \"\"\"",
            "        return cell",
            "",
            "    def get_iam_token(self, conn: Connection) -> tuple[str, int]:",
            "        \"\"\"",
            "        Retrieve a temporary password to connect to MySQL.",
            "",
            "        Uses AWSHook to retrieve a temporary password to connect to MySQL",
            "        Port is required. If none is provided, default 3306 is used",
            "        \"\"\"",
            "        from airflow.providers.amazon.aws.hooks.base_aws import AwsBaseHook",
            "",
            "        aws_conn_id = conn.extra_dejson.get(\"aws_conn_id\", \"aws_default\")",
            "        aws_hook = AwsBaseHook(aws_conn_id, client_type=\"rds\")",
            "        if conn.port is None:",
            "            port = 3306",
            "        else:",
            "            port = conn.port",
            "        client = aws_hook.get_conn()",
            "        token = client.generate_db_auth_token(conn.host, port, conn.login)",
            "        return token, port",
            "",
            "    def bulk_load_custom(",
            "        self, table: str, tmp_file: str, duplicate_key_handling: str = \"IGNORE\", extra_options: str = \"\"",
            "    ) -> None:",
            "        \"\"\"",
            "        A more configurable way to load local data from a file into the database.",
            "",
            "        .. warning:: According to the mysql docs using this function is a",
            "            `security risk <https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html>`_.",
            "            If you want to use it anyway you can do so by setting a client-side + server-side option.",
            "            This depends on the mysql client library used.",
            "",
            "        :param table: The table were the file will be loaded into.",
            "        :param tmp_file: The file (name) that contains the data.",
            "        :param duplicate_key_handling: Specify what should happen to duplicate data.",
            "            You can choose either `IGNORE` or `REPLACE`.",
            "",
            "            .. seealso::",
            "                https://dev.mysql.com/doc/refman/8.0/en/load-data.html#load-data-duplicate-key-handling",
            "        :param extra_options: More sql options to specify exactly how to load the data.",
            "",
            "            .. seealso:: https://dev.mysql.com/doc/refman/8.0/en/load-data.html",
            "        \"\"\"",
            "        conn = self.get_conn()",
            "        cursor = conn.cursor()",
            "",
            "        cursor.execute(",
            "            f\"\"\"",
            "            LOAD DATA LOCAL INFILE '{tmp_file}'",
            "            {duplicate_key_handling}",
            "            INTO TABLE {table}",
            "            {extra_options}",
            "            \"\"\"",
            "        )",
            "",
            "        cursor.close()",
            "        conn.commit()",
            "        conn.close()"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"This module allows to connect to a MySQL database.\"\"\"",
            "from __future__ import annotations",
            "",
            "import json",
            "from typing import TYPE_CHECKING, Any, Union",
            "",
            "from airflow.models import Connection",
            "from airflow.providers.common.sql.hooks.sql import DbApiHook",
            "",
            "if TYPE_CHECKING:",
            "    from mysql.connector.abstracts import MySQLConnectionAbstract",
            "    from MySQLdb.connections import Connection as MySQLdbConnection",
            "",
            "MySQLConnectionTypes = Union[\"MySQLdbConnection\", \"MySQLConnectionAbstract\"]",
            "",
            "",
            "class MySqlHook(DbApiHook):",
            "    \"\"\"",
            "    Interact with MySQL.",
            "",
            "    You can specify charset in the extra field of your connection",
            "    as ``{\"charset\": \"utf8\"}``. Also you can choose cursor as",
            "    ``{\"cursor\": \"SSCursor\"}``. Refer to the MySQLdb.cursors for more details.",
            "",
            "    Note: For AWS IAM authentication, use iam in the extra connection parameters",
            "    and set it to true. Leave the password field empty. This will use the",
            "    \"aws_default\" connection to get the temporary token unless you override",
            "    in extras.",
            "    extras example: ``{\"iam\":true, \"aws_conn_id\":\"my_aws_conn\"}``",
            "",
            "    You can also add \"local_infile\" parameter to determine whether local_infile feature of MySQL client is",
            "    going to be enabled (it is disabled by default).",
            "",
            "    :param schema: The MySQL database schema to connect to.",
            "    :param connection: The :ref:`MySQL connection id <howto/connection:mysql>` used for MySQL credentials.",
            "    :param local_infile: Boolean flag determining if local_infile should be used",
            "    \"\"\"",
            "",
            "    conn_name_attr = \"mysql_conn_id\"",
            "    default_conn_name = \"mysql_default\"",
            "    conn_type = \"mysql\"",
            "    hook_name = \"MySQL\"",
            "    supports_autocommit = True",
            "",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.schema = kwargs.pop(\"schema\", None)",
            "        self.connection = kwargs.pop(\"connection\", None)",
            "        self.local_infile = kwargs.pop(\"local_infile\", False)",
            "",
            "    def set_autocommit(self, conn: MySQLConnectionTypes, autocommit: bool) -> None:",
            "        \"\"\"",
            "        Set *autocommit*.",
            "",
            "        *mysqlclient* uses an *autocommit* method rather than an *autocommit*",
            "        property, so we need to override this to support it.",
            "",
            "        :param conn: connection to set autocommit setting",
            "        :param autocommit: autocommit setting",
            "        \"\"\"",
            "        if hasattr(conn.__class__, \"autocommit\") and isinstance(conn.__class__.autocommit, property):",
            "            conn.autocommit = autocommit",
            "        else:",
            "            conn.autocommit(autocommit)",
            "",
            "    def get_autocommit(self, conn: MySQLConnectionTypes) -> bool:",
            "        \"\"\"",
            "        Whether *autocommit* is active.",
            "",
            "        *mysqlclient* uses an *get_autocommit* method rather than an *autocommit*",
            "        property, so we need to override this to support it.",
            "",
            "        :param conn: connection to get autocommit setting from.",
            "        :return: connection autocommit setting",
            "        \"\"\"",
            "        if hasattr(conn.__class__, \"autocommit\") and isinstance(conn.__class__.autocommit, property):",
            "            return conn.autocommit",
            "        else:",
            "            return conn.get_autocommit()",
            "",
            "    def _get_conn_config_mysql_client(self, conn: Connection) -> dict:",
            "        conn_config = {",
            "            \"user\": conn.login,",
            "            \"passwd\": conn.password or \"\",",
            "            \"host\": conn.host or \"localhost\",",
            "            \"db\": self.schema or conn.schema or \"\",",
            "        }",
            "",
            "        # check for authentication via AWS IAM",
            "        if conn.extra_dejson.get(\"iam\", False):",
            "            conn_config[\"passwd\"], conn.port = self.get_iam_token(conn)",
            "            conn_config[\"read_default_group\"] = \"enable-cleartext-plugin\"",
            "",
            "        conn_config[\"port\"] = int(conn.port) if conn.port else 3306",
            "",
            "        if conn.extra_dejson.get(\"charset\", False):",
            "            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]",
            "            if conn_config[\"charset\"].lower() in (\"utf8\", \"utf-8\"):",
            "                conn_config[\"use_unicode\"] = True",
            "        if conn.extra_dejson.get(\"cursor\", False):",
            "            import MySQLdb.cursors",
            "",
            "            if (conn.extra_dejson[\"cursor\"]).lower() == \"sscursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor",
            "            elif (conn.extra_dejson[\"cursor\"]).lower() == \"dictcursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor",
            "            elif (conn.extra_dejson[\"cursor\"]).lower() == \"ssdictcursor\":",
            "                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor",
            "        if conn.extra_dejson.get(\"ssl\", False):",
            "            # SSL parameter for MySQL has to be a dictionary and in case",
            "            # of extra/dejson we can get string if extra is passed via",
            "            # URL parameters",
            "            dejson_ssl = conn.extra_dejson[\"ssl\"]",
            "            if isinstance(dejson_ssl, str):",
            "                dejson_ssl = json.loads(dejson_ssl)",
            "            conn_config[\"ssl\"] = dejson_ssl",
            "        if conn.extra_dejson.get(\"ssl_mode\", False):",
            "            conn_config[\"ssl_mode\"] = conn.extra_dejson[\"ssl_mode\"]",
            "        if conn.extra_dejson.get(\"unix_socket\"):",
            "            conn_config[\"unix_socket\"] = conn.extra_dejson[\"unix_socket\"]",
            "        if self.local_infile:",
            "            conn_config[\"local_infile\"] = 1",
            "        return conn_config",
            "",
            "    def _get_conn_config_mysql_connector_python(self, conn: Connection) -> dict:",
            "        conn_config = {",
            "            \"user\": conn.login,",
            "            \"password\": conn.password or \"\",",
            "            \"host\": conn.host or \"localhost\",",
            "            \"database\": self.schema or conn.schema or \"\",",
            "            \"port\": int(conn.port) if conn.port else 3306,",
            "        }",
            "",
            "        if self.local_infile:",
            "            conn_config[\"allow_local_infile\"] = True",
            "        # Ref: https://dev.mysql.com/doc/connector-python/en/connector-python-connectargs.html",
            "        for key, value in conn.extra_dejson.items():",
            "            if key.startswith(\"ssl_\"):",
            "                conn_config[key] = value",
            "",
            "        return conn_config",
            "",
            "    def get_conn(self) -> MySQLConnectionTypes:",
            "        \"\"\"",
            "        Connection to a MySQL database.",
            "",
            "        Establishes a connection to a mysql database",
            "        by extracting the connection configuration from the Airflow connection.",
            "",
            "        .. note:: By default it connects to the database via the mysqlclient library.",
            "            But you can also choose the mysql-connector-python library which lets you connect through ssl",
            "            without any further ssl parameters required.",
            "",
            "        :return: a mysql connection object",
            "        \"\"\"",
            "        conn = self.connection or self.get_connection(getattr(self, self.conn_name_attr))",
            "",
            "        client_name = conn.extra_dejson.get(\"client\", \"mysqlclient\")",
            "",
            "        if client_name == \"mysqlclient\":",
            "            import MySQLdb",
            "",
            "            conn_config = self._get_conn_config_mysql_client(conn)",
            "            return MySQLdb.connect(**conn_config)",
            "",
            "        if client_name == \"mysql-connector-python\":",
            "            import mysql.connector",
            "",
            "            conn_config = self._get_conn_config_mysql_connector_python(conn)",
            "            return mysql.connector.connect(**conn_config)",
            "",
            "        raise ValueError(\"Unknown MySQL client name provided!\")",
            "",
            "    def bulk_load(self, table: str, tmp_file: str) -> None:",
            "        \"\"\"Load a tab-delimited file into a database table.\"\"\"",
            "        conn = self.get_conn()",
            "        cur = conn.cursor()",
            "        cur.execute(",
            "            f\"\"\"",
            "            LOAD DATA LOCAL INFILE '{tmp_file}'",
            "            INTO TABLE {table}",
            "            \"\"\"",
            "        )",
            "        conn.commit()",
            "        conn.close()",
            "",
            "    def bulk_dump(self, table: str, tmp_file: str) -> None:",
            "        \"\"\"Dump a database table into a tab-delimited file.\"\"\"",
            "        conn = self.get_conn()",
            "        cur = conn.cursor()",
            "        cur.execute(",
            "            f\"\"\"",
            "            SELECT * INTO OUTFILE '{tmp_file}'",
            "            FROM {table}",
            "            \"\"\"",
            "        )",
            "        conn.commit()",
            "        conn.close()",
            "",
            "    @staticmethod",
            "    def _serialize_cell(cell: object, conn: Connection | None = None) -> Any:",
            "        \"\"\"",
            "        Convert argument to a literal.",
            "",
            "        The package MySQLdb converts an argument to a literal",
            "        when passing those separately to execute. Hence, this method does nothing.",
            "",
            "        :param cell: The cell to insert into the table",
            "        :param conn: The database connection",
            "        :return: The same cell",
            "        \"\"\"",
            "        return cell",
            "",
            "    def get_iam_token(self, conn: Connection) -> tuple[str, int]:",
            "        \"\"\"",
            "        Retrieve a temporary password to connect to MySQL.",
            "",
            "        Uses AWSHook to retrieve a temporary password to connect to MySQL",
            "        Port is required. If none is provided, default 3306 is used",
            "        \"\"\"",
            "        from airflow.providers.amazon.aws.hooks.base_aws import AwsBaseHook",
            "",
            "        aws_conn_id = conn.extra_dejson.get(\"aws_conn_id\", \"aws_default\")",
            "        aws_hook = AwsBaseHook(aws_conn_id, client_type=\"rds\")",
            "        if conn.port is None:",
            "            port = 3306",
            "        else:",
            "            port = conn.port",
            "        client = aws_hook.get_conn()",
            "        token = client.generate_db_auth_token(conn.host, port, conn.login)",
            "        return token, port",
            "",
            "    def bulk_load_custom(",
            "        self, table: str, tmp_file: str, duplicate_key_handling: str = \"IGNORE\", extra_options: str = \"\"",
            "    ) -> None:",
            "        \"\"\"",
            "        A more configurable way to load local data from a file into the database.",
            "",
            "        .. warning:: According to the mysql docs using this function is a",
            "            `security risk <https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html>`_.",
            "            If you want to use it anyway you can do so by setting a client-side + server-side option.",
            "            This depends on the mysql client library used.",
            "",
            "        :param table: The table were the file will be loaded into.",
            "        :param tmp_file: The file (name) that contains the data.",
            "        :param duplicate_key_handling: Specify what should happen to duplicate data.",
            "            You can choose either `IGNORE` or `REPLACE`.",
            "",
            "            .. seealso::",
            "                https://dev.mysql.com/doc/refman/8.0/en/load-data.html#load-data-duplicate-key-handling",
            "        :param extra_options: More sql options to specify exactly how to load the data.",
            "",
            "            .. seealso:: https://dev.mysql.com/doc/refman/8.0/en/load-data.html",
            "        \"\"\"",
            "        conn = self.get_conn()",
            "        cursor = conn.cursor()",
            "",
            "        cursor.execute(",
            "            f\"\"\"",
            "            LOAD DATA LOCAL INFILE '{tmp_file}'",
            "            {duplicate_key_handling}",
            "            INTO TABLE {table}",
            "            {extra_options}",
            "            \"\"\"",
            "        )",
            "",
            "        cursor.close()",
            "        conn.commit()",
            "        conn.close()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "121": [
                "MySqlHook",
                "_get_conn_config_mysql_client"
            ],
            "134": [
                "MySqlHook",
                "_get_conn_config_mysql_client"
            ],
            "147": [
                "MySqlHook",
                "_get_conn_config_mysql_connector_python"
            ]
        },
        "addLocation": [
            "airflow.providers.mysql.hooks.mysql.MySqlHook.self",
            "rdiffweb.controller.page_pref_sshkeys.ApiSshKeys.post",
            "airflow.providers.mysql.hooks.mysql.MySqlHook"
        ]
    },
    "airflow/providers/mysql/transfers/vertica_to_mysql.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         import, typically used to move data from staging to production"
            },
            "1": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         and issue cleanup commands. (templated)"
            },
            "2": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "     :param bulk_load: flag to use bulk_load option.  This loads MySQL directly"
            },
            "3": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command."
            },
            "4": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        This option requires an extra connection parameter for the"
            },
            "5": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        destination MySQL connection: {'local_infile': true}."
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command. The MySQL"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+        server must support loading local files via this command (it is disabled by default)."
            },
            "8": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "     \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "     template_fields: Sequence[str] = (\"sql\", \"mysql_table\", \"mysql_preoperator\", \"mysql_postoperator\")"
            },
            "11": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 85,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "     def execute(self, context: Context):"
            },
            "13": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "         vertica = VerticaHook(vertica_conn_id=self.vertica_conn_id)"
            },
            "14": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id, local_infile=self.bulk_load)"
            },
            "16": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 89,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "         if self.bulk_load:"
            },
            "18": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "             self._bulk_load_transfer(mysql, vertica)"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "from contextlib import closing",
            "from tempfile import NamedTemporaryFile",
            "from typing import TYPE_CHECKING, Sequence",
            "",
            "import MySQLdb",
            "import unicodecsv as csv",
            "",
            "from airflow.models import BaseOperator",
            "from airflow.providers.mysql.hooks.mysql import MySqlHook",
            "from airflow.providers.vertica.hooks.vertica import VerticaHook",
            "",
            "if TYPE_CHECKING:",
            "    from airflow.utils.context import Context",
            "",
            "",
            "class VerticaToMySqlOperator(BaseOperator):",
            "    \"\"\"",
            "    Moves data from Vertica to MySQL.",
            "",
            "    :param sql: SQL query to execute against the Vertica database. (templated)",
            "    :param vertica_conn_id: source Vertica connection",
            "    :param mysql_table: target MySQL table, use dot notation to target a",
            "        specific database. (templated)",
            "    :param mysql_conn_id: Reference to :ref:`mysql connection id <howto/connection:mysql>`.",
            "    :param mysql_preoperator: sql statement to run against MySQL prior to",
            "        import, typically use to truncate of delete in place of the data",
            "        coming in, allowing the task to be idempotent (running the task",
            "        twice won't double load data). (templated)",
            "    :param mysql_postoperator: sql statement to run against MySQL after the",
            "        import, typically used to move data from staging to production",
            "        and issue cleanup commands. (templated)",
            "    :param bulk_load: flag to use bulk_load option.  This loads MySQL directly",
            "        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command.",
            "        This option requires an extra connection parameter for the",
            "        destination MySQL connection: {'local_infile': true}.",
            "    \"\"\"",
            "",
            "    template_fields: Sequence[str] = (\"sql\", \"mysql_table\", \"mysql_preoperator\", \"mysql_postoperator\")",
            "    template_ext: Sequence[str] = (\".sql\",)",
            "    template_fields_renderers = {",
            "        \"sql\": \"sql\",",
            "        \"mysql_preoperator\": \"mysql\",",
            "        \"mysql_postoperator\": \"mysql\",",
            "    }",
            "    ui_color = \"#a0e08c\"",
            "",
            "    def __init__(",
            "        self,",
            "        sql: str,",
            "        mysql_table: str,",
            "        vertica_conn_id: str = \"vertica_default\",",
            "        mysql_conn_id: str = \"mysql_default\",",
            "        mysql_preoperator: str | None = None,",
            "        mysql_postoperator: str | None = None,",
            "        bulk_load: bool = False,",
            "        *args,",
            "        **kwargs,",
            "    ) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.sql = sql",
            "        self.mysql_table = mysql_table",
            "        self.mysql_conn_id = mysql_conn_id",
            "        self.mysql_preoperator = mysql_preoperator",
            "        self.mysql_postoperator = mysql_postoperator",
            "        self.vertica_conn_id = vertica_conn_id",
            "        self.bulk_load = bulk_load",
            "",
            "    def execute(self, context: Context):",
            "        vertica = VerticaHook(vertica_conn_id=self.vertica_conn_id)",
            "        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)",
            "",
            "        if self.bulk_load:",
            "            self._bulk_load_transfer(mysql, vertica)",
            "        else:",
            "            self._non_bulk_load_transfer(mysql, vertica)",
            "",
            "        if self.mysql_postoperator:",
            "            self.log.info(\"Running MySQL postoperator...\")",
            "            mysql.run(self.mysql_postoperator)",
            "",
            "        self.log.info(\"Done\")",
            "",
            "    def _non_bulk_load_transfer(self, mysql, vertica):",
            "        with closing(vertica.get_conn()) as conn:",
            "            with closing(conn.cursor()) as cursor:",
            "                cursor.execute(self.sql)",
            "                selected_columns = [d.name for d in cursor.description]",
            "                self.log.info(\"Selecting rows from Vertica...\")",
            "                self.log.info(self.sql)",
            "",
            "                result = cursor.fetchall()",
            "                count = len(result)",
            "",
            "                self.log.info(\"Selected rows from Vertica %s\", count)",
            "        self._run_preoperator(mysql)",
            "        try:",
            "            self.log.info(\"Inserting rows into MySQL...\")",
            "            mysql.insert_rows(table=self.mysql_table, rows=result, target_fields=selected_columns)",
            "            self.log.info(\"Inserted rows into MySQL %s\", count)",
            "        except (MySQLdb.Error, MySQLdb.Warning):",
            "            self.log.info(\"Inserted rows into MySQL 0\")",
            "            raise",
            "",
            "    def _bulk_load_transfer(self, mysql, vertica):",
            "        count = 0",
            "        with closing(vertica.get_conn()) as conn:",
            "            with closing(conn.cursor()) as cursor:",
            "                cursor.execute(self.sql)",
            "                selected_columns = [d.name for d in cursor.description]",
            "                with NamedTemporaryFile(\"w\") as tmpfile:",
            "                    self.log.info(\"Selecting rows from Vertica to local file %s...\", tmpfile.name)",
            "                    self.log.info(self.sql)",
            "",
            "                    csv_writer = csv.writer(tmpfile, delimiter=\"\\t\", encoding=\"utf-8\")",
            "                    for row in cursor.iterate():",
            "                        csv_writer.writerow(row)",
            "                        count += 1",
            "",
            "                    tmpfile.flush()",
            "        self._run_preoperator(mysql)",
            "        try:",
            "            self.log.info(\"Bulk inserting rows into MySQL...\")",
            "            with closing(mysql.get_conn()) as conn:",
            "                with closing(conn.cursor()) as cursor:",
            "                    cursor.execute(",
            "                        f\"LOAD DATA LOCAL INFILE '{tmpfile.name}' \"",
            "                        f\"INTO TABLE {self.mysql_table} \"",
            "                        f\"LINES TERMINATED BY '\\r\\n' ({', '.join(selected_columns)})\"",
            "                    )",
            "                    conn.commit()",
            "            tmpfile.close()",
            "            self.log.info(\"Inserted rows into MySQL %s\", count)",
            "        except (MySQLdb.Error, MySQLdb.Warning):",
            "            self.log.info(\"Inserted rows into MySQL 0\")",
            "            raise",
            "",
            "    def _run_preoperator(self, mysql):",
            "        if self.mysql_preoperator:",
            "            self.log.info(\"Running MySQL preoperator...\")",
            "            mysql.run(self.mysql_preoperator)"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "from contextlib import closing",
            "from tempfile import NamedTemporaryFile",
            "from typing import TYPE_CHECKING, Sequence",
            "",
            "import MySQLdb",
            "import unicodecsv as csv",
            "",
            "from airflow.models import BaseOperator",
            "from airflow.providers.mysql.hooks.mysql import MySqlHook",
            "from airflow.providers.vertica.hooks.vertica import VerticaHook",
            "",
            "if TYPE_CHECKING:",
            "    from airflow.utils.context import Context",
            "",
            "",
            "class VerticaToMySqlOperator(BaseOperator):",
            "    \"\"\"",
            "    Moves data from Vertica to MySQL.",
            "",
            "    :param sql: SQL query to execute against the Vertica database. (templated)",
            "    :param vertica_conn_id: source Vertica connection",
            "    :param mysql_table: target MySQL table, use dot notation to target a",
            "        specific database. (templated)",
            "    :param mysql_conn_id: Reference to :ref:`mysql connection id <howto/connection:mysql>`.",
            "    :param mysql_preoperator: sql statement to run against MySQL prior to",
            "        import, typically use to truncate of delete in place of the data",
            "        coming in, allowing the task to be idempotent (running the task",
            "        twice won't double load data). (templated)",
            "    :param mysql_postoperator: sql statement to run against MySQL after the",
            "        import, typically used to move data from staging to production",
            "        and issue cleanup commands. (templated)",
            "    :param bulk_load: flag to use bulk_load option.  This loads MySQL directly",
            "        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command. The MySQL",
            "        server must support loading local files via this command (it is disabled by default).",
            "    \"\"\"",
            "",
            "    template_fields: Sequence[str] = (\"sql\", \"mysql_table\", \"mysql_preoperator\", \"mysql_postoperator\")",
            "    template_ext: Sequence[str] = (\".sql\",)",
            "    template_fields_renderers = {",
            "        \"sql\": \"sql\",",
            "        \"mysql_preoperator\": \"mysql\",",
            "        \"mysql_postoperator\": \"mysql\",",
            "    }",
            "    ui_color = \"#a0e08c\"",
            "",
            "    def __init__(",
            "        self,",
            "        sql: str,",
            "        mysql_table: str,",
            "        vertica_conn_id: str = \"vertica_default\",",
            "        mysql_conn_id: str = \"mysql_default\",",
            "        mysql_preoperator: str | None = None,",
            "        mysql_postoperator: str | None = None,",
            "        bulk_load: bool = False,",
            "        *args,",
            "        **kwargs,",
            "    ) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.sql = sql",
            "        self.mysql_table = mysql_table",
            "        self.mysql_conn_id = mysql_conn_id",
            "        self.mysql_preoperator = mysql_preoperator",
            "        self.mysql_postoperator = mysql_postoperator",
            "        self.vertica_conn_id = vertica_conn_id",
            "        self.bulk_load = bulk_load",
            "",
            "    def execute(self, context: Context):",
            "        vertica = VerticaHook(vertica_conn_id=self.vertica_conn_id)",
            "        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id, local_infile=self.bulk_load)",
            "",
            "        if self.bulk_load:",
            "            self._bulk_load_transfer(mysql, vertica)",
            "        else:",
            "            self._non_bulk_load_transfer(mysql, vertica)",
            "",
            "        if self.mysql_postoperator:",
            "            self.log.info(\"Running MySQL postoperator...\")",
            "            mysql.run(self.mysql_postoperator)",
            "",
            "        self.log.info(\"Done\")",
            "",
            "    def _non_bulk_load_transfer(self, mysql, vertica):",
            "        with closing(vertica.get_conn()) as conn:",
            "            with closing(conn.cursor()) as cursor:",
            "                cursor.execute(self.sql)",
            "                selected_columns = [d.name for d in cursor.description]",
            "                self.log.info(\"Selecting rows from Vertica...\")",
            "                self.log.info(self.sql)",
            "",
            "                result = cursor.fetchall()",
            "                count = len(result)",
            "",
            "                self.log.info(\"Selected rows from Vertica %s\", count)",
            "        self._run_preoperator(mysql)",
            "        try:",
            "            self.log.info(\"Inserting rows into MySQL...\")",
            "            mysql.insert_rows(table=self.mysql_table, rows=result, target_fields=selected_columns)",
            "            self.log.info(\"Inserted rows into MySQL %s\", count)",
            "        except (MySQLdb.Error, MySQLdb.Warning):",
            "            self.log.info(\"Inserted rows into MySQL 0\")",
            "            raise",
            "",
            "    def _bulk_load_transfer(self, mysql, vertica):",
            "        count = 0",
            "        with closing(vertica.get_conn()) as conn:",
            "            with closing(conn.cursor()) as cursor:",
            "                cursor.execute(self.sql)",
            "                selected_columns = [d.name for d in cursor.description]",
            "                with NamedTemporaryFile(\"w\") as tmpfile:",
            "                    self.log.info(\"Selecting rows from Vertica to local file %s...\", tmpfile.name)",
            "                    self.log.info(self.sql)",
            "",
            "                    csv_writer = csv.writer(tmpfile, delimiter=\"\\t\", encoding=\"utf-8\")",
            "                    for row in cursor.iterate():",
            "                        csv_writer.writerow(row)",
            "                        count += 1",
            "",
            "                    tmpfile.flush()",
            "        self._run_preoperator(mysql)",
            "        try:",
            "            self.log.info(\"Bulk inserting rows into MySQL...\")",
            "            with closing(mysql.get_conn()) as conn:",
            "                with closing(conn.cursor()) as cursor:",
            "                    cursor.execute(",
            "                        f\"LOAD DATA LOCAL INFILE '{tmpfile.name}' \"",
            "                        f\"INTO TABLE {self.mysql_table} \"",
            "                        f\"LINES TERMINATED BY '\\r\\n' ({', '.join(selected_columns)})\"",
            "                    )",
            "                    conn.commit()",
            "            tmpfile.close()",
            "            self.log.info(\"Inserted rows into MySQL %s\", count)",
            "        except (MySQLdb.Error, MySQLdb.Warning):",
            "            self.log.info(\"Inserted rows into MySQL 0\")",
            "            raise",
            "",
            "    def _run_preoperator(self, mysql):",
            "        if self.mysql_preoperator:",
            "            self.log.info(\"Running MySQL preoperator...\")",
            "            mysql.run(self.mysql_preoperator)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "52": [
                "VerticaToMySqlOperator"
            ],
            "53": [
                "VerticaToMySqlOperator"
            ],
            "54": [
                "VerticaToMySqlOperator"
            ],
            "89": [
                "VerticaToMySqlOperator",
                "execute"
            ]
        },
        "addLocation": []
    }
}