{
    "src/DIRAC/Core/Security/ProxyFile.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from DIRAC import S_OK, S_ERROR"
            },
            "2": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from DIRAC.Core.Utilities import DErrno"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+from DIRAC.Core.Utilities.File import secureOpenForWrite"
            },
            "4": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from DIRAC.Core.Security.X509Chain import X509Chain  # pylint: disable=import-error"
            },
            "5": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from DIRAC.Core.Security.Locations import getProxyLocation"
            },
            "6": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": "       - proxyContents : string object to dump to file"
            },
            "8": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": "       - fileName : filename to dump to"
            },
            "9": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": "     \"\"\""
            },
            "10": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if not fileName:"
            },
            "11": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "12": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            fd, proxyLocation = tempfile.mkstemp()"
            },
            "13": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            os.close(fd)"
            },
            "14": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except OSError:"
            },
            "15": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return S_ERROR(DErrno.ECTMPF)"
            },
            "16": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        fileName = proxyLocation"
            },
            "17": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     try:"
            },
            "18": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        with open(fileName, \"w\") as fd:"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+        with secureOpenForWrite(fileName) as fd:"
            },
            "20": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "             fd.write(proxyContents)"
            },
            "21": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 24,
                "PatchRowcode": "     except Exception as e:"
            },
            "22": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 25,
                "PatchRowcode": "         return S_ERROR(DErrno.EWF, f\" {fileName}: {repr(e).replace(',)', ')')}\")"
            },
            "23": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    try:"
            },
            "24": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        os.chmod(fileName, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "25": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    except Exception as e:"
            },
            "26": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return S_ERROR(DErrno.ESPF, f\"{fileName}: {repr(e).replace(',)', ')')}\")"
            },
            "27": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 26,
                "PatchRowcode": "     return S_OK(fileName)"
            },
            "28": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "\"\"\" Collection of utilities for dealing with security files (i.e. proxy files)",
            "\"\"\"",
            "import os",
            "import stat",
            "import tempfile",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Security.X509Chain import X509Chain  # pylint: disable=import-error",
            "from DIRAC.Core.Security.Locations import getProxyLocation",
            "",
            "",
            "def writeToProxyFile(proxyContents, fileName=False):",
            "    \"\"\"Write a proxy string to file",
            "",
            "    arguments:",
            "      - proxyContents : string object to dump to file",
            "      - fileName : filename to dump to",
            "    \"\"\"",
            "    if not fileName:",
            "        try:",
            "            fd, proxyLocation = tempfile.mkstemp()",
            "            os.close(fd)",
            "        except OSError:",
            "            return S_ERROR(DErrno.ECTMPF)",
            "        fileName = proxyLocation",
            "    try:",
            "        with open(fileName, \"w\") as fd:",
            "            fd.write(proxyContents)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.EWF, f\" {fileName}: {repr(e).replace(',)', ')')}\")",
            "    try:",
            "        os.chmod(fileName, stat.S_IRUSR | stat.S_IWUSR)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.ESPF, f\"{fileName}: {repr(e).replace(',)', ')')}\")",
            "    return S_OK(fileName)",
            "",
            "",
            "def writeChainToProxyFile(proxyChain, fileName):",
            "    \"\"\"",
            "    Write an X509Chain to file",
            "",
            "    arguments:",
            "      - proxyChain : X509Chain object to dump to file",
            "      - fileName : filename to dump to",
            "    \"\"\"",
            "    retVal = proxyChain.dumpAllToString()",
            "    if not retVal[\"OK\"]:",
            "        return retVal",
            "    return writeToProxyFile(retVal[\"Value\"], fileName)",
            "",
            "",
            "def writeChainToTemporaryFile(proxyChain):",
            "    \"\"\"",
            "    Write a proxy chain to a temporary file",
            "    return S_OK( string with name of file )/ S_ERROR",
            "    \"\"\"",
            "    try:",
            "        fd, proxyLocation = tempfile.mkstemp()",
            "        os.close(fd)",
            "    except OSError:",
            "        return S_ERROR(DErrno.ECTMPF)",
            "    retVal = writeChainToProxyFile(proxyChain, proxyLocation)",
            "    if not retVal[\"OK\"]:",
            "        try:",
            "            os.unlink(proxyLocation)",
            "        except Exception:",
            "            pass",
            "        return retVal",
            "    return S_OK(proxyLocation)",
            "",
            "",
            "def deleteMultiProxy(multiProxyDict):",
            "    \"\"\"",
            "    Delete a file from a multiProxyArgument if needed",
            "    \"\"\"",
            "    if multiProxyDict[\"tempFile\"]:",
            "        try:",
            "            os.unlink(multiProxyDict[\"file\"])",
            "        except Exception:",
            "            pass",
            "",
            "",
            "def multiProxyArgument(proxy=False):",
            "    \"\"\"",
            "    Load a proxy:",
            "",
            "",
            "    :param proxy: param can be:",
            "",
            "        * Default -> use current proxy",
            "        * string -> upload file specified as proxy",
            "        * X509Chain -> use chain",
            "",
            "    :returns:  S_OK/S_ERROR",
            "",
            "      .. code-block:: python",
            "",
            "          S_OK( { 'file' : <string with file location>,",
            "                  'chain' : X509Chain object,",
            "                  'tempFile' : <True if file is temporal>",
            "                } )",
            "          S_ERROR",
            "",
            "    \"\"\"",
            "    tempFile = False",
            "    # Set env",
            "    if isinstance(proxy, X509Chain):",
            "        tempFile = True",
            "        retVal = writeChainToTemporaryFile(proxy)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        proxyLoc = retVal[\"Value\"]",
            "    else:",
            "        if not proxy:",
            "            proxyLoc = getProxyLocation()",
            "            if not proxyLoc:",
            "                return S_ERROR(DErrno.EPROXYFIND)",
            "        if isinstance(proxy, str):",
            "            proxyLoc = proxy",
            "        # Load proxy",
            "        proxy = X509Chain()",
            "        retVal = proxy.loadProxyFromFile(proxyLoc)",
            "        if not retVal[\"OK\"]:",
            "            return S_ERROR(DErrno.EPROXYREAD, f\"ProxyLocation: {proxyLoc}\")",
            "    return S_OK({\"file\": proxyLoc, \"chain\": proxy, \"tempFile\": tempFile})"
        ],
        "afterPatchFile": [
            "\"\"\" Collection of utilities for dealing with security files (i.e. proxy files)",
            "\"\"\"",
            "import os",
            "import stat",
            "import tempfile",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Utilities.File import secureOpenForWrite",
            "from DIRAC.Core.Security.X509Chain import X509Chain  # pylint: disable=import-error",
            "from DIRAC.Core.Security.Locations import getProxyLocation",
            "",
            "",
            "def writeToProxyFile(proxyContents, fileName=False):",
            "    \"\"\"Write a proxy string to file",
            "",
            "    arguments:",
            "      - proxyContents : string object to dump to file",
            "      - fileName : filename to dump to",
            "    \"\"\"",
            "    try:",
            "        with secureOpenForWrite(fileName) as fd:",
            "            fd.write(proxyContents)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.EWF, f\" {fileName}: {repr(e).replace(',)', ')')}\")",
            "    return S_OK(fileName)",
            "",
            "",
            "def writeChainToProxyFile(proxyChain, fileName):",
            "    \"\"\"",
            "    Write an X509Chain to file",
            "",
            "    arguments:",
            "      - proxyChain : X509Chain object to dump to file",
            "      - fileName : filename to dump to",
            "    \"\"\"",
            "    retVal = proxyChain.dumpAllToString()",
            "    if not retVal[\"OK\"]:",
            "        return retVal",
            "    return writeToProxyFile(retVal[\"Value\"], fileName)",
            "",
            "",
            "def writeChainToTemporaryFile(proxyChain):",
            "    \"\"\"",
            "    Write a proxy chain to a temporary file",
            "    return S_OK( string with name of file )/ S_ERROR",
            "    \"\"\"",
            "    try:",
            "        fd, proxyLocation = tempfile.mkstemp()",
            "        os.close(fd)",
            "    except OSError:",
            "        return S_ERROR(DErrno.ECTMPF)",
            "    retVal = writeChainToProxyFile(proxyChain, proxyLocation)",
            "    if not retVal[\"OK\"]:",
            "        try:",
            "            os.unlink(proxyLocation)",
            "        except Exception:",
            "            pass",
            "        return retVal",
            "    return S_OK(proxyLocation)",
            "",
            "",
            "def deleteMultiProxy(multiProxyDict):",
            "    \"\"\"",
            "    Delete a file from a multiProxyArgument if needed",
            "    \"\"\"",
            "    if multiProxyDict[\"tempFile\"]:",
            "        try:",
            "            os.unlink(multiProxyDict[\"file\"])",
            "        except Exception:",
            "            pass",
            "",
            "",
            "def multiProxyArgument(proxy=False):",
            "    \"\"\"",
            "    Load a proxy:",
            "",
            "",
            "    :param proxy: param can be:",
            "",
            "        * Default -> use current proxy",
            "        * string -> upload file specified as proxy",
            "        * X509Chain -> use chain",
            "",
            "    :returns:  S_OK/S_ERROR",
            "",
            "      .. code-block:: python",
            "",
            "          S_OK( { 'file' : <string with file location>,",
            "                  'chain' : X509Chain object,",
            "                  'tempFile' : <True if file is temporal>",
            "                } )",
            "          S_ERROR",
            "",
            "    \"\"\"",
            "    tempFile = False",
            "    # Set env",
            "    if isinstance(proxy, X509Chain):",
            "        tempFile = True",
            "        retVal = writeChainToTemporaryFile(proxy)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        proxyLoc = retVal[\"Value\"]",
            "    else:",
            "        if not proxy:",
            "            proxyLoc = getProxyLocation()",
            "            if not proxyLoc:",
            "                return S_ERROR(DErrno.EPROXYFIND)",
            "        if isinstance(proxy, str):",
            "            proxyLoc = proxy",
            "        # Load proxy",
            "        proxy = X509Chain()",
            "        retVal = proxy.loadProxyFromFile(proxyLoc)",
            "        if not retVal[\"OK\"]:",
            "            return S_ERROR(DErrno.EPROXYREAD, f\"ProxyLocation: {proxyLoc}\")",
            "    return S_OK({\"file\": proxyLoc, \"chain\": proxy, \"tempFile\": tempFile})"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "20": [
                "writeToProxyFile"
            ],
            "21": [
                "writeToProxyFile"
            ],
            "22": [
                "writeToProxyFile"
            ],
            "23": [
                "writeToProxyFile"
            ],
            "24": [
                "writeToProxyFile"
            ],
            "25": [
                "writeToProxyFile"
            ],
            "26": [
                "writeToProxyFile"
            ],
            "28": [
                "writeToProxyFile"
            ],
            "32": [
                "writeToProxyFile"
            ],
            "33": [
                "writeToProxyFile"
            ],
            "34": [
                "writeToProxyFile"
            ],
            "35": [
                "writeToProxyFile"
            ]
        },
        "addLocation": []
    },
    "src/DIRAC/Core/Security/m2crypto/X509CRL.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " \"\"\" X509CRL is a class for managing X509CRL"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " This class is used to manage the revoked certificates...."
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " \"\"\""
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import stat"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import os"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import tempfile"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import re"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import datetime"
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " import M2Crypto"
            },
            "10": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from DIRAC import S_OK, S_ERROR"
            },
            "11": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from DIRAC.Core.Utilities import DErrno"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from DIRAC.Core.Utilities.File import secureOpenForWrite"
            },
            "13": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " # pylint: disable=broad-except"
            },
            "15": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "         if not self.__loadedCert:"
            },
            "17": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "             return S_ERROR(\"No certificate loaded\")"
            },
            "18": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "         try:"
            },
            "19": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if not filename:"
            },
            "20": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                fd, filename = tempfile.mkstemp()"
            },
            "21": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                os.close(fd)"
            },
            "22": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with open(filename, \"w\", encoding=\"ascii\") as fd:"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+            with secureOpenForWrite(filename) as fd:"
            },
            "24": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "                 fd.write(self.__pemData)"
            },
            "25": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         except Exception as e:"
            },
            "26": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "             return S_ERROR(DErrno.EWF, f\"{filename}: {repr(e).replace(',)', ')')}\")"
            },
            "27": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "28": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            os.chmod(filename, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "29": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception as e:"
            },
            "30": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return S_ERROR(DErrno.ESPF, f\"{filename}: {repr(e).replace(',)', ')')}\")"
            },
            "31": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "         return S_OK(filename)"
            },
            "32": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 78,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 79,
                "PatchRowcode": "     def hasExpired(self):"
            }
        },
        "frontPatchFile": [
            "\"\"\" X509CRL is a class for managing X509CRL",
            "This class is used to manage the revoked certificates....",
            "\"\"\"",
            "import stat",
            "import os",
            "import tempfile",
            "import re",
            "import datetime",
            "",
            "import M2Crypto",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "",
            "# pylint: disable=broad-except",
            "",
            "",
            "class X509CRL:",
            "    def __init__(self, cert=None):",
            "        self.__pemData = \"\"",
            "",
            "        if cert:",
            "            self.__loadedCert = True",
            "            self.__revokedCert = cert",
            "        else:",
            "            self.__loadedCert = False",
            "",
            "    @classmethod",
            "    def instanceFromFile(cls, crlLocation):",
            "        \"\"\"Instance a X509CRL from a file\"\"\"",
            "        crl = cls()",
            "        result = crl.loadCRLFromFile(crlLocation)",
            "        if not result[\"OK\"]:",
            "            return result",
            "        return S_OK(crl)",
            "",
            "    def loadCRLFromFile(self, crlLocation):",
            "        \"\"\"",
            "        Load a x509CRL certificate from a pem file",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        self.__loadedCert = False",
            "        try:",
            "            self.__revokedCert = M2Crypto.X509.load_crl(crlLocation)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')}\")",
            "        self.__loadedCert = True",
            "        with open(crlLocation) as crlFile:",
            "            pemData = crlFile.read()",
            "        self.__pemData = pemData",
            "        return S_OK()",
            "",
            "    def __bytes__(self):",
            "        if not self.__loadedCert:",
            "            return b\"No certificate loaded\"",
            "        return self.__pemData.encode(\"ascii\")",
            "",
            "    def __str__(self):",
            "        return self.__pemData",
            "",
            "    def dumpAllToString(self):",
            "        \"\"\"",
            "        Dump all to string",
            "        \"\"\"",
            "        if not self.__loadedCert:",
            "            return S_ERROR(DErrno.ECERTREAD, \"No certificate loaded\")",
            "        return S_OK(self.__pemData)",
            "",
            "    def dumpAllToFile(self, filename=False):",
            "        \"\"\"",
            "        Dump all to file. If no filename specified a temporal one will be created",
            "        \"\"\"",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        try:",
            "            if not filename:",
            "                fd, filename = tempfile.mkstemp()",
            "                os.close(fd)",
            "            with open(filename, \"w\", encoding=\"ascii\") as fd:",
            "                fd.write(self.__pemData)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filename}: {repr(e).replace(',)', ')')}\")",
            "        try:",
            "            os.chmod(filename, stat.S_IRUSR | stat.S_IWUSR)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ESPF, f\"{filename}: {repr(e).replace(',)', ')')}\")",
            "        return S_OK(filename)",
            "",
            "    def hasExpired(self):",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        # XXX It should be done better, for now M2Crypto doesn't offer access to fields like Next Update",
            "        txt = self.__revokedCert.as_text()",
            "        pattern = r\"Next Update: (?P<nextUpdate>.*)\\n\"",
            "        dateStr = re.search(pattern, txt).group(\"nextUpdate\")",
            "        nextUpdate = datetime.datetime.strptime(dateStr, \"%b %d %H:%M:%S %Y GMT\")",
            "        return S_OK(datetime.datetime.now() > nextUpdate)",
            "",
            "    def getIssuer(self):",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        # XXX It should be done better, for now M2Crypto doesn't offer access to fields like Issuer",
            "        txt = self.__revokedCert.as_text()",
            "        pattern = r\"Issuer: (?P<issuer>.*)\\n\"",
            "        return S_OK(re.search(pattern, txt).group(\"issuer\"))",
            "",
            "    def __repr__(self):",
            "        repStr = \"<X509CRL\"",
            "        if self.__loadedCert:",
            "            repStr += \"\"  # self.__revokedCert.get_issuer().one_line()  # Why issuer?! XXX",
            "        repStr += \">\"",
            "        return repStr"
        ],
        "afterPatchFile": [
            "\"\"\" X509CRL is a class for managing X509CRL",
            "This class is used to manage the revoked certificates....",
            "\"\"\"",
            "import re",
            "import datetime",
            "",
            "import M2Crypto",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Utilities.File import secureOpenForWrite",
            "",
            "# pylint: disable=broad-except",
            "",
            "",
            "class X509CRL:",
            "    def __init__(self, cert=None):",
            "        self.__pemData = \"\"",
            "",
            "        if cert:",
            "            self.__loadedCert = True",
            "            self.__revokedCert = cert",
            "        else:",
            "            self.__loadedCert = False",
            "",
            "    @classmethod",
            "    def instanceFromFile(cls, crlLocation):",
            "        \"\"\"Instance a X509CRL from a file\"\"\"",
            "        crl = cls()",
            "        result = crl.loadCRLFromFile(crlLocation)",
            "        if not result[\"OK\"]:",
            "            return result",
            "        return S_OK(crl)",
            "",
            "    def loadCRLFromFile(self, crlLocation):",
            "        \"\"\"",
            "        Load a x509CRL certificate from a pem file",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        self.__loadedCert = False",
            "        try:",
            "            self.__revokedCert = M2Crypto.X509.load_crl(crlLocation)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')}\")",
            "        self.__loadedCert = True",
            "        with open(crlLocation) as crlFile:",
            "            pemData = crlFile.read()",
            "        self.__pemData = pemData",
            "        return S_OK()",
            "",
            "    def __bytes__(self):",
            "        if not self.__loadedCert:",
            "            return b\"No certificate loaded\"",
            "        return self.__pemData.encode(\"ascii\")",
            "",
            "    def __str__(self):",
            "        return self.__pemData",
            "",
            "    def dumpAllToString(self):",
            "        \"\"\"",
            "        Dump all to string",
            "        \"\"\"",
            "        if not self.__loadedCert:",
            "            return S_ERROR(DErrno.ECERTREAD, \"No certificate loaded\")",
            "        return S_OK(self.__pemData)",
            "",
            "    def dumpAllToFile(self, filename=False):",
            "        \"\"\"",
            "        Dump all to file. If no filename specified a temporal one will be created",
            "        \"\"\"",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        try:",
            "            with secureOpenForWrite(filename) as fd:",
            "                fd.write(self.__pemData)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filename}: {repr(e).replace(',)', ')')}\")",
            "        return S_OK(filename)",
            "",
            "    def hasExpired(self):",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        # XXX It should be done better, for now M2Crypto doesn't offer access to fields like Next Update",
            "        txt = self.__revokedCert.as_text()",
            "        pattern = r\"Next Update: (?P<nextUpdate>.*)\\n\"",
            "        dateStr = re.search(pattern, txt).group(\"nextUpdate\")",
            "        nextUpdate = datetime.datetime.strptime(dateStr, \"%b %d %H:%M:%S %Y GMT\")",
            "        return S_OK(datetime.datetime.now() > nextUpdate)",
            "",
            "    def getIssuer(self):",
            "        if not self.__loadedCert:",
            "            return S_ERROR(\"No certificate loaded\")",
            "        # XXX It should be done better, for now M2Crypto doesn't offer access to fields like Issuer",
            "        txt = self.__revokedCert.as_text()",
            "        pattern = r\"Issuer: (?P<issuer>.*)\\n\"",
            "        return S_OK(re.search(pattern, txt).group(\"issuer\"))",
            "",
            "    def __repr__(self):",
            "        repStr = \"<X509CRL\"",
            "        if self.__loadedCert:",
            "            repStr += \"\"  # self.__revokedCert.get_issuer().one_line()  # Why issuer?! XXX",
            "        repStr += \">\"",
            "        return repStr"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "4": [],
            "5": [],
            "6": [],
            "75": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "76": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "77": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "78": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "82": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "83": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "84": [
                "X509CRL",
                "dumpAllToFile"
            ],
            "85": [
                "X509CRL",
                "dumpAllToFile"
            ]
        },
        "addLocation": []
    },
    "src/DIRAC/Core/Security/m2crypto/X509Chain.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " import copy"
            },
            "3": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import os"
            },
            "4": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import stat"
            },
            "5": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import tempfile"
            },
            "6": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " import hashlib"
            },
            "7": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import re"
            },
            "9": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from DIRAC import S_OK, S_ERROR"
            },
            "10": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from DIRAC.Core.Utilities import DErrno"
            },
            "11": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from DIRAC.Core.Utilities.Decorators import executeOnlyIf, deprecated"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+from DIRAC.Core.Utilities.File import secureOpenForWrite"
            },
            "13": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from DIRAC.ConfigurationSystem.Client.Helpers import Registry"
            },
            "14": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from DIRAC.Core.Security.m2crypto import PROXY_OID, LIMITED_PROXY_OID, DIRAC_GROUP_OID, DEFAULT_PROXY_STRENGTH"
            },
            "15": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from DIRAC.Core.Security.m2crypto.X509Certificate import X509Certificate"
            },
            "16": {
                "beforePatchRowNumber": 492,
                "afterPatchRowNumber": 490,
                "PatchRowcode": "         if not retVal[\"OK\"]:"
            },
            "17": {
                "beforePatchRowNumber": 493,
                "afterPatchRowNumber": 491,
                "PatchRowcode": "             return retVal"
            },
            "18": {
                "beforePatchRowNumber": 494,
                "afterPatchRowNumber": 492,
                "PatchRowcode": "         try:"
            },
            "19": {
                "beforePatchRowNumber": 495,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with open(filePath, \"w\") as fd:"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 493,
                "PatchRowcode": "+            with secureOpenForWrite(filePath) as fd:"
            },
            "21": {
                "beforePatchRowNumber": 496,
                "afterPatchRowNumber": 494,
                "PatchRowcode": "                 fd.write(retVal[\"Value\"])"
            },
            "22": {
                "beforePatchRowNumber": 497,
                "afterPatchRowNumber": 495,
                "PatchRowcode": "         except Exception as e:"
            },
            "23": {
                "beforePatchRowNumber": 498,
                "afterPatchRowNumber": 496,
                "PatchRowcode": "             return S_ERROR(DErrno.EWF, f\"{filePath} :{repr(e).replace(',)', ')')}\")"
            },
            "24": {
                "beforePatchRowNumber": 499,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "25": {
                "beforePatchRowNumber": 500,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            os.chmod(filePath, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "26": {
                "beforePatchRowNumber": 501,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception as e:"
            },
            "27": {
                "beforePatchRowNumber": 502,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return S_ERROR(DErrno.ESPF, f\"{filePath} :{repr(e).replace(',)', ')')}\")"
            },
            "28": {
                "beforePatchRowNumber": 503,
                "afterPatchRowNumber": 497,
                "PatchRowcode": "         return S_OK()"
            },
            "29": {
                "beforePatchRowNumber": 504,
                "afterPatchRowNumber": 498,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 505,
                "afterPatchRowNumber": 499,
                "PatchRowcode": "     @needCertList"
            },
            "31": {
                "beforePatchRowNumber": 880,
                "afterPatchRowNumber": 874,
                "PatchRowcode": "             return retVal"
            },
            "32": {
                "beforePatchRowNumber": 881,
                "afterPatchRowNumber": 875,
                "PatchRowcode": "         pemData = retVal[\"Value\"]"
            },
            "33": {
                "beforePatchRowNumber": 882,
                "afterPatchRowNumber": 876,
                "PatchRowcode": "         try:"
            },
            "34": {
                "beforePatchRowNumber": 883,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if not filename:"
            },
            "35": {
                "beforePatchRowNumber": 884,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                fd, filename = tempfile.mkstemp()"
            },
            "36": {
                "beforePatchRowNumber": 885,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                os.close(fd)"
            },
            "37": {
                "beforePatchRowNumber": 886,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with open(filename, \"w\") as fp:"
            },
            "38": {
                "beforePatchRowNumber": 887,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                fp.write(pemData)"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 877,
                "PatchRowcode": "+            with secureOpenForWrite(filename) as fh:"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 878,
                "PatchRowcode": "+                fh.write(pemData)"
            },
            "41": {
                "beforePatchRowNumber": 888,
                "afterPatchRowNumber": 879,
                "PatchRowcode": "         except Exception as e:"
            },
            "42": {
                "beforePatchRowNumber": 889,
                "afterPatchRowNumber": 880,
                "PatchRowcode": "             return S_ERROR(DErrno.EWF, f\"{filename} :{repr(e).replace(',)', ')')}\")"
            },
            "43": {
                "beforePatchRowNumber": 890,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "44": {
                "beforePatchRowNumber": 891,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            os.chmod(filename, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "45": {
                "beforePatchRowNumber": 892,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception as e:"
            },
            "46": {
                "beforePatchRowNumber": 893,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return S_ERROR(DErrno.ESPF, f\"{filename} :{repr(e).replace(',)', ')')}\")"
            },
            "47": {
                "beforePatchRowNumber": 894,
                "afterPatchRowNumber": 881,
                "PatchRowcode": "         return S_OK(filename)"
            },
            "48": {
                "beforePatchRowNumber": 895,
                "afterPatchRowNumber": 882,
                "PatchRowcode": " "
            },
            "49": {
                "beforePatchRowNumber": 896,
                "afterPatchRowNumber": 883,
                "PatchRowcode": "     @needCertList"
            }
        },
        "frontPatchFile": [
            "\"\"\" X509Chain is a class for managing X509 chains with their Pkeys",
            "",
            "Link to the RFC 3820: https://tools.ietf.org/html/rfc3820",
            "In particular, limited proxy: https://tools.ietf.org/html/rfc3820#section-3.8",
            "",
            "There are also details available about Per-User Sub-Proxies (PUSP)",
            "here: https://wiki.egi.eu/wiki/Usage_of_the_per_user_sub_proxy_in_EGI",
            "",
            "\"\"\"",
            "import copy",
            "import os",
            "import stat",
            "import tempfile",
            "import hashlib",
            "",
            "import re",
            "",
            "import M2Crypto",
            "",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Utilities.Decorators import executeOnlyIf, deprecated",
            "from DIRAC.ConfigurationSystem.Client.Helpers import Registry",
            "from DIRAC.Core.Security.m2crypto import PROXY_OID, LIMITED_PROXY_OID, DIRAC_GROUP_OID, DEFAULT_PROXY_STRENGTH",
            "from DIRAC.Core.Security.m2crypto.X509Certificate import X509Certificate",
            "",
            "",
            "# Decorator to check that _certList is not empty",
            "needCertList = executeOnlyIf(\"_certList\", S_ERROR(DErrno.ENOCHAIN))",
            "# Decorator to check that the PKey has been loaded",
            "needPKey = executeOnlyIf(\"_keyObj\", S_ERROR(DErrno.ENOPKEY))",
            "",
            "",
            "class X509Chain:",
            "    \"\"\"",
            "    An X509Chain is basically a list of X509Certificate object, as well as a PKey object,",
            "    which is associated to the X509Certificate the lowest in the chain.",
            "",
            "    This is what you will want to use for user certificate (because they will turn into proxy....), and for",
            "    proxy.",
            "",
            "    A priori, once we get rid of pyGSI, we could even meld the X509Certificate into this one, and use the X509Chain",
            "    for host certificates. After all, a certificate is nothing but a chain of length 1...",
            "",
            "    There are normally 4 ways you would instanciate an X509Chain object:",
            "",
            "    * You are loading a proxy from a file",
            "    * Loading the chain from a file",
            "    * You are getting information about your peer during an SSL connection",
            "    * You are delegating",
            "",
            "    Typical usages of X509Chain are illustrated below",
            "",
            "    Loading a proxy from a file (this will load the chain and the key, assuming the key is in the same file)::",
            "",
            "      proxy = X509Chain()",
            "      res = proxy.loadProxyFromFile(myFile)",
            "      if not res['OK']:",
            "        return res",
            "",
            "",
            "    Generating a proxy from a Certificate::",
            "",
            "      cert = X509Chain()",
            "      # Load user cert",
            "      retVal = cert.loadChainFromFile('/home/chaen/.globus/userkey.pem')",
            "      if not retVal['OK']:",
            "        return retVal",
            "      # Load the key from a different place, with a password",
            "      retVal = cert.loadKeyFromFile('/home/chaen/.globus/userkey.pem', password='MySecretKey')",
            "      if not retVal['OK']:",
            "        return res",
            "",
            "      # Generate a limited proxy, valid one hour",
            "      retVal = cert.generateProxyToFile('/tmp/proxy.pem',",
            "                                     3600, # only 1 h",
            "                                     diracGroup = 'lhcb_user',",
            "                                     strength= 2048,",
            "                                     limited=True)",
            "",
            "",
            "    Getting information from a peer in an SSL Connection::",
            "",
            "      # conn is an M2Crypto.SSL.Connection instance",
            "      chain = X509Chain.generateX509ChainFromSSLConnection(conn)",
            "      creds = chain.getCredentials()",
            "",
            "",
            "    Delegating a proxy to a service::",
            "",
            "      # The server side generates a request",
            "      # Equivalent to ProxyManager.requestDelegationUpload",
            "",
            "      x509Req = X509Request()",
            "      x509Req.generateProxyRequest()",
            "",
            "      # This reqStr object is sent to the client",
            "      reqStr = x509Req.dumpRequest()['Value']",
            "",
            "      # This object contains both the public and private key",
            "      pkeyReq = x509Req.getPKey()",
            "",
            "      #######################################################",
            "",
            "      # The client side signs the request, with its proxy",
            "      # Assume the proxy chain was already loaded one way or the otjer",
            "",
            "      # The proxy will not contain a private key",
            "      res = proxyChain.generateChainFromRequestString(reqStr, lifetime=lifetime)",
            "",
            "      # This is sent back to the server",
            "      delegatedProxyString = res['Value']",
            "",
            "      ######################################################",
            "      # Equivalent to ProxyManager.completeDelegationUpload",
            "",
            "      # Create the new chain",
            "      # the pkey was generated together with the Request",
            "      delegatedProxy = X509Chain(keyObj=pkeyReq)",
            "      delegatedProxy.loadChainFromString(delegatedProxyString)",
            "",
            "      # make sure the public key match between Request and the new Chain",
            "      # (Stupid, of course it will ! But it is done in the ProxyManager...)",
            "      res = x509Req.checkChain(delegatedProxy)",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, certList=False, keyObj=False):",
            "        \"\"\"",
            "        C'tor",
            "",
            "        :param certList: list of X509Certificate to constitute the chain",
            "        :param keyObj: ~M2Crypto.EVP.PKey object. The public or public/private key associated to",
            "                       the last certificate of the chain",
            "",
            "        \"\"\"",
            "",
            "        # __isProxy is True if this chain represents a proxy",
            "        self.__isProxy = False",
            "        # Whether the proxy is limited or not",
            "        self.__isLimitedProxy = False",
            "",
            "        # This is the position of the first proxy in the chain",
            "        self.__firstProxyStep = 0",
            "",
            "        # Cache for sha1 hash of the object",
            "        # This is just used as a unique identifier for",
            "        # indexing in the ProxyCache",
            "        self.__hash = False",
            "",
            "        # List of X509Certificate constituing the chain",
            "        # The certificate in position N has been generated from the (N+1)",
            "        self._certList = []",
            "",
            "        # Place holder for the EVP.PKey object",
            "        self._keyObj = None",
            "",
            "        if certList:",
            "            # copy the content of the list, without copying the objects themselves",
            "            self._certList = copy.copy(certList)",
            "            # Immediately check if it is a proxy",
            "            self.__checkProxyness()",
            "",
            "        if keyObj:",
            "            self._keyObj = keyObj",
            "",
            "    @classmethod",
            "    @deprecated(\"Use loadChainFromFile instead\", onlyOnce=True)",
            "    def instanceFromFile(cls, chainLocation):",
            "        \"\"\"Class method to generate a X509Chain from a file",
            "",
            "        :param chainLocation: path to the file",
            "",
            "        :returns: S_OK(X509Chain)",
            "        \"\"\"",
            "        chain = cls()",
            "        result = chain.loadChainFromFile(chainLocation)",
            "        if not result[\"OK\"]:",
            "            return result",
            "",
            "        return S_OK(chain)",
            "",
            "    @staticmethod",
            "    def generateX509ChainFromSSLConnection(sslConnection):",
            "        \"\"\"Returns an instance of X509Chain from the SSL connection",
            "",
            "        :param sslConnection: ~M2Crypto.SSl.Connection instance",
            "",
            "        :returns: a X509Chain instance",
            "        \"\"\"",
            "        certList = []",
            "",
            "        certStack = sslConnection.get_peer_cert_chain()",
            "        for cert in certStack:",
            "            certList.append(X509Certificate(x509Obj=cert))",
            "",
            "        # Servers don't receive the whole chain, the last cert comes alone",
            "        # if not self.infoDict['clientMode']:",
            "        certList.insert(0, X509Certificate(x509Obj=sslConnection.get_peer_cert()))",
            "        peerChain = X509Chain(certList=certList)",
            "",
            "        return peerChain",
            "",
            "    def loadChainFromFile(self, chainLocation):",
            "        \"\"\"",
            "        Load a x509 chain from a pem file",
            "",
            "        :param chainLocation: path to the file",
            "",
            "        :returns: S_OK/S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except OSError as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadChainFromString(pemData)",
            "",
            "    def loadChainFromString(self, data):",
            "        \"\"\"",
            "        Load a x509 cert from a string containing the pem data",
            "",
            "        :param data: data representing the chain of certificate in the",
            "",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            self._certList = self.__certListFromPemString(data)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')}\")",
            "",
            "        if not self._certList:",
            "            return S_ERROR(DErrno.EX509)",
            "",
            "        # Update internals",
            "        self.__checkProxyness()",
            "        return S_OK()",
            "",
            "    @staticmethod",
            "    def __certListFromPemString(certString):",
            "        \"\"\"",
            "        Create certificates list from string. String should contain certificates, just like plain text proxy file.",
            "        \"\"\"",
            "        # To get list of X509 certificates (not X509 Certificate Chain) from string it has to be parsed like that",
            "        # (constructors are not able to deal with big string)",
            "        certList = []",
            "        pattern = r\"(-----BEGIN CERTIFICATE-----((.|\\n)*?)-----END CERTIFICATE-----)\"",
            "        for cert in re.findall(pattern, certString):",
            "            certList.append(X509Certificate(certString=cert[0]))",
            "        return certList",
            "",
            "    # Not used in m2crypto version",
            "    # def setChain(self, certList):",
            "    #   \"\"\"",
            "    #   Set the chain",
            "    #   Return : S_OK / S_ERROR",
            "    #   \"\"\"",
            "    #   self._certList = certList",
            "    #   self.__loadedChain = True",
            "    #   return S_OK()",
            "",
            "    def loadKeyFromFile(self, chainLocation, password=False):",
            "        \"\"\"",
            "        Load a PKey from a pem file",
            "",
            "        :param chainLocation: path to the file",
            "        :param password: password to decode the file.",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadKeyFromString(pemData, password)",
            "",
            "    def loadKeyFromString(self, pemData, password=False):",
            "        \"\"\"",
            "        Load a PKey from a string containing the pem data",
            "",
            "        :param pemData: pem data of the key, potentially encoded with the password",
            "        :param password: password to decode the file.",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        self._keyObj = None",
            "        if not isinstance(pemData, bytes):",
            "            pemData = pemData.encode(\"ascii\")",
            "        if password:",
            "            password = password.encode()",
            "        try:",
            "            self._keyObj = M2Crypto.EVP.load_key_string(pemData, lambda x: password)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')} (Probably bad pass phrase?)\")",
            "",
            "        return S_OK()",
            "",
            "    def setPKey(self, pkeyObj):",
            "        \"\"\"",
            "        Set the chain",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        self._keyObj = pkeyObj",
            "        return S_OK()",
            "",
            "    def loadProxyFromFile(self, chainLocation):",
            "        \"\"\"",
            "        Load a Proxy from a pem file, that is both the Cert chain and the PKey",
            "",
            "        :param chainLocation: path to the proxy file",
            "",
            "        :returns: S_OK  / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadProxyFromString(pemData)",
            "",
            "    def loadProxyFromString(self, pemData):",
            "        \"\"\"",
            "        Load a Proxy from a pem buffer, that is both the Cert chain and the PKey",
            "",
            "        :param pemData: PEM encoded cert chain and pkey",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        retVal = self.loadChainFromString(pemData)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "",
            "        return self.loadKeyFromString(pemData)",
            "",
            "    @staticmethod",
            "    def __getProxyExtensionList(diracGroup=False, rfcLimited=False):",
            "        \"\"\"",
            "        Get an extension stack containing the necessary extension for a proxy.",
            "        Basically the keyUsage, the proxyCertInfo, and eventually the diracGroup",
            "",
            "        :param diracGroup: name of the dirac group for the proxy",
            "        :param rfcLimited: boolean to generate for a limited proxy",
            "",
            "        :returns: M2Crypto.X509.X509_Extension_Stack object.",
            "        \"\"\"",
            "",
            "        extStack = M2Crypto.X509.X509_Extension_Stack()",
            "",
            "        # Standard certificate extensions",
            "        kUext = M2Crypto.X509.new_extension(",
            "            \"keyUsage\", \"digitalSignature, keyEncipherment, dataEncipherment\", critical=1",
            "        )",
            "        extStack.push(kUext)",
            "",
            "        # Mandatory extension to be a proxy",
            "        policyOID = LIMITED_PROXY_OID if rfcLimited else PROXY_OID",
            "        ext = M2Crypto.X509.new_extension(\"proxyCertInfo\", f\"critical, language:{policyOID}\", critical=1)",
            "        extStack.push(ext)",
            "",
            "        # Add a dirac group",
            "        if diracGroup and isinstance(diracGroup, str):",
            "            # the str cast is needed because M2Crypto does not play it cool with unicode here it seems",
            "            # Also one needs to specify the ASN1 type. That's what it is...",
            "            dGext = M2Crypto.X509.new_extension(DIRAC_GROUP_OID, str(f\"ASN1:IA5:{diracGroup}\"))",
            "            extStack.push(dGext)",
            "",
            "        return extStack",
            "",
            "    @needCertList",
            "    def getCertInChain(self, certPos=0):",
            "        \"\"\"",
            "        Get then a certificate in the chain",
            "",
            "        :warning: Contrary to the pygsi version, this is not a copy!",
            "",
            "        :param certPos: position of the certificate in the chain. Default: 0",
            "",
            "        :returns: S_OK(X509Certificate)/S_ERROR",
            "        \"\"\"",
            "        return S_OK(self._certList[certPos])",
            "",
            "    @needCertList",
            "    def getIssuerCert(self):",
            "        \"\"\"",
            "        Returns the issuer certificate of the last one if it is a proxy, otherwise",
            "        the last one in the chain",
            "",
            "        :returns: S_OK(X509Certificate)/S_ERROR",
            "        \"\"\"",
            "        if self.__isProxy:",
            "            return S_OK(self._certList[self.__firstProxyStep + 1])",
            "        return S_OK(self._certList[-1])",
            "",
            "    @deprecated(\"Only here for compatibility reason\", onlyOnce=True)",
            "    @needPKey",
            "    def getPKeyObj(self):",
            "        \"\"\"",
            "        Get the pkey obj",
            "",
            "        :returns: ~M2Crypto.EVP.PKey object",
            "        \"\"\"",
            "        return S_OK(self._keyObj)",
            "",
            "    @deprecated(\"Only here for compatibility reason\")",
            "    @needCertList",
            "    def getCertList(self):",
            "        \"\"\"",
            "        Get the cert list",
            "        \"\"\"",
            "        return S_OK(self._certList)",
            "",
            "    @needCertList",
            "    def getNumCertsInChain(self):",
            "        \"\"\"",
            "        length of the certificate chain",
            "",
            "        :returns: length of the certificate chain",
            "",
            "",
            "        \"\"\"",
            "        return S_OK(len(self._certList))",
            "",
            "    # pylint: disable=unused-argument",
            "    @needCertList",
            "    @needPKey",
            "    def generateProxyToString(",
            "        self, lifetime, diracGroup=False, strength=DEFAULT_PROXY_STRENGTH, limited=False, proxyKey=False",
            "    ):",
            "        \"\"\"",
            "        Generate a proxy and get it as a string.",
            "",
            "        Check here: https://github.com/eventbrite/m2crypto/blob/master/demo/x509/ca.py#L45",
            "",
            "        Args:",
            "            lifetime (int): expected lifetime in seconds of proxy",
            "            diracGroup (str): diracGroup to add to the certificate",
            "            strength (int): length in bits of the pair if proxyKey not given (default 2048)",
            "            limited (bool): Create a limited proxy (default False)",
            "            proxyKey: M2Crypto.EVP.PKey instance with private and public key. If not given, generate one",
            "            rfc: placeholder for backward compatibility and ignored",
            "",
            "        :returns: S_OK(PEM encoded string), S_ERROR. The PEM string contains all the certificates in the chain",
            "                  and the private key associated to the last X509Certificate just generated.",
            "        \"\"\"",
            "",
            "        issuerCert = self._certList[0]",
            "",
            "        # If this is a certificate signing request then the private key will be",
            "        # appended by the server and we don't need to include it in the proxy",
            "        include_private_key = not proxyKey",
            "        if not proxyKey:",
            "            # Generating key is a two step process: create key object and then assign RSA key.",
            "            # This contains both the private and public key",
            "            proxyKey = M2Crypto.EVP.PKey()",
            "            proxyKey.assign_rsa(M2Crypto.RSA.gen_key(strength, 65537, callback=M2Crypto.util.quiet_genparam_callback))",
            "",
            "        # Generate a new X509Certificate object",
            "        proxyExtensions = self.__getProxyExtensionList(diracGroup, limited)",
            "        res = X509Certificate.generateProxyCertFromIssuer(issuerCert, proxyExtensions, proxyKey, lifetime=lifetime)",
            "        if not res[\"OK\"]:",
            "            return res",
            "        proxyCert = res[\"Value\"]",
            "",
            "        # Sign it with one owns key",
            "        proxyCert.sign(self._keyObj, \"sha256\")",
            "",
            "        # Generate the proxy string",
            "        proxyString = proxyCert.asPem()",
            "        if include_private_key:",
            "            proxyString += proxyKey.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\")",
            "        for i in range(len(self._certList)):",
            "            crt = self._certList[i]",
            "            proxyString += crt.asPem()",
            "        return S_OK(proxyString)",
            "",
            "    # pylint: disable=unused-argument",
            "    def generateProxyToFile(self, filePath, lifetime, diracGroup=False, strength=DEFAULT_PROXY_STRENGTH, limited=False):",
            "        \"\"\"",
            "        Generate a proxy and put it into a file",
            "",
            "        Args:",
            "            filePath: file to write",
            "            lifetime: expected lifetime in seconds of proxy",
            "            diracGroup: diracGroup to add to the certificate",
            "            strength: length in bits of the pair",
            "            limited: Create a limited proxy",
            "            rfc: placeholder and ignored",
            "        \"\"\"",
            "        retVal = self.generateProxyToString(lifetime, diracGroup, strength, limited)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        try:",
            "            with open(filePath, \"w\") as fd:",
            "                fd.write(retVal[\"Value\"])",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filePath} :{repr(e).replace(',)', ')')}\")",
            "        try:",
            "            os.chmod(filePath, stat.S_IRUSR | stat.S_IWUSR)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ESPF, f\"{filePath} :{repr(e).replace(',)', ')')}\")",
            "        return S_OK()",
            "",
            "    @needCertList",
            "    def isProxy(self):",
            "        \"\"\"",
            "         Check whether this chain is a proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        return S_OK(self.__isProxy)",
            "",
            "    @needCertList",
            "    def isLimitedProxy(self):",
            "        \"\"\"",
            "        Check whether this chain is a limited proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        return S_OK(self.__isProxy and self.__isLimitedProxy)",
            "",
            "    @needCertList",
            "    def isValidProxy(self, ignoreDefault=False):",
            "        \"\"\"",
            "        Check whether this chain is a valid proxy, that is:",
            "          * a proxy",
            "          * still valid",
            "          * with a valid group",
            "",
            "        :param ignoreDefault: (what a stupid name) if True, do not lookup the CS",
            "",
            "        :returns: S_OK(True) if the proxy is valid, S_ERROR otherwise",
            "",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_ERROR(DErrno.ENOCHAIN, \"Chain is not a proxy\")",
            "",
            "        if self.hasExpired()[\"Value\"]:",
            "            return S_ERROR(DErrno.ENOCHAIN)",
            "",
            "        if ignoreDefault:",
            "            groupRes = self.getDIRACGroup(ignoreDefault=True)",
            "            if not groupRes[\"OK\"]:",
            "                return groupRes",
            "            if not groupRes[\"Value\"]:",
            "                return S_ERROR(DErrno.ENOGROUP)",
            "",
            "        return S_OK(True)",
            "",
            "    def isVOMS(self):",
            "        \"\"\"",
            "        Check whether this proxy contains VOMS extensions.",
            "        It is enough for one of the certificate of the chain to have VOMS extension",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "",
            "        if not self.__isProxy:",
            "            return S_OK(False)",
            "",
            "        for cert in self._certList:",
            "            if cert.hasVOMSExtensions()[\"Value\"]:",
            "                return S_OK(True)",
            "        return S_OK(False)",
            "",
            "    def isRFC(self):",
            "        \"\"\"Check whether this is an RFC proxy. It can only be true, providing it is a proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "",
            "        return self.isProxy()",
            "",
            "    def getVOMSData(self):",
            "        \"\"\"",
            "        Returns the voms data.",
            "",
            "        :returns: See :py:func:`~DIRAC.Core.Security.m2crypto.X509Certificate.getVOMSData`",
            "                  If no VOMS data is available, return DErrno.EVOMS",
            "        :warning: In case the chain is not a proxy, this method will return False.",
            "                  Yes, it's stupid, but it is for compatibility...",
            "",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_OK(False)",
            "",
            "        for cert in self._certList:",
            "            res = cert.getVOMSData()",
            "            if res[\"OK\"]:",
            "                return res",
            "        return S_ERROR(DErrno.EVOMS)",
            "",
            "    def __checkProxyness(self):",
            "        \"\"\"This method is called upon initialization of a chain and fill in some internal attributes.",
            "",
            "        Pure madness...",
            "",
            "        To me, this method just seems to work by pure luck..",
            "        \"\"\"",
            "",
            "        self.__hash = False",
            "        self.__firstProxyStep = len(self._certList) - 2  # -1 is user cert by default, -2 is first proxy step",
            "        self.__isProxy = True",
            "        self.__isLimitedProxy = False",
            "        prevDNMatch = 2",
            "        # If less than 2 steps in the chain is no proxy",
            "        if len(self._certList) < 2:",
            "            self.__isProxy = False",
            "            return",
            "",
            "        # Here we make sure that each certificate in the chain was",
            "        # signed by the previous one",
            "        for step in range(len(self._certList) - 1):",
            "            # this is a cryptographic check with the keys",
            "            issuerMatch = self.__checkIssuer(step, step + 1)",
            "            if not issuerMatch:",
            "                self.__isProxy = False",
            "                return",
            "",
            "            # Do we need to check the proxy DN?",
            "            if prevDNMatch:",
            "                dnMatch = self.__checkProxyDN(step, step + 1)",
            "                if dnMatch == 0:",
            "                    # If we are not in the first step we've found the entity cert",
            "                    if step > 0:",
            "                        self.__firstProxyStep = step - 1",
            "                    # If we are in the first step this is not a proxy",
            "                    else:",
            "                        self.__isProxy = False",
            "                        return",
            "                # Limited proxy DN match",
            "                elif dnMatch == 2:",
            "                    self.__isLimitedProxy = True",
            "                    if prevDNMatch != 2:",
            "                        self.__isProxy = False",
            "                        self.__isLimitedProxy = False",
            "                        return",
            "                prevDNMatch = dnMatch",
            "",
            "    def __checkProxyDN(self, certStep, issuerStep):",
            "        \"\"\"",
            "        Checks that the subject of the proxy is properly derived from the issuer subject.",
            "",
            "        Args:",
            "            certStep: position of the certificate to check in self.__certList",
            "            issuerStep: position of the issuer certificate to check in self.__certList",
            "",
            "        :returns: an int based on the match:",
            "                  0 = no match",
            "                  1 = proxy match",
            "                  2 = limited proxy match",
            "        \"\"\"",
            "",
            "        issuerSubject = self._certList[issuerStep].getSubjectNameObject()",
            "        if not issuerSubject[\"OK\"]:",
            "            return 0",
            "        issuerSubject = issuerSubject[\"Value\"]",
            "",
            "        proxySubject = self._certList[certStep].getSubjectNameObject()",
            "        if not proxySubject[\"OK\"]:",
            "            return 0",
            "        proxySubject = proxySubject[\"Value\"]",
            "",
            "        lastEntry = str(proxySubject).split(\"/\")[-1].split(\"=\")",
            "        limited = False",
            "        if lastEntry[0] != \"CN\":",
            "            return 0",
            "",
            "        # For non-RFC proxy, the proxy always had these two strings in the CN",
            "        if lastEntry[1] not in (\"proxy\", \"limited proxy\"):",
            "            # for RFC proxy, one has to check the extension.",
            "            ext = self._certList[certStep].getExtension(\"proxyCertInfo\")",
            "            if not ext[\"OK\"]:",
            "                return 0",
            "",
            "            ext = ext[\"Value\"]",
            "",
            "            # Check the RFC",
            "            contraint = [",
            "                line.split(\":\")[1].strip()",
            "                for line in ext.get_value().split(\"\\n\")",
            "                if line.split(\":\")[0] == \"Policy Language\"",
            "            ]",
            "            if not contraint:",
            "                return 0",
            "            if contraint[0] == LIMITED_PROXY_OID:",
            "                limited = True",
            "        else:",
            "            if lastEntry[1] == \"limited proxy\":",
            "                limited = True",
            "        if not str(issuerSubject) == str(proxySubject)[: str(proxySubject).rfind(\"/\")]:",
            "            return 0",
            "        return 1 if not limited else 2",
            "",
            "    def __checkIssuer(self, certStep, issuerStep):",
            "        \"\"\"",
            "        Check that the issuer has signed the certificate with his private key",
            "",
            "        :param certStep: position of the certificate in self.__certList",
            "        :param issuerStep: position of the issuer certificate",
            "",
            "        :returns: S_OK(boolean)",
            "",
            "        \"\"\"",
            "        issuerCert = self._certList[issuerStep]",
            "        cert = self._certList[certStep]",
            "        pubKey = issuerCert.getPublicKey()[\"Value\"]",
            "",
            "        return cert.verify(pubKey)[\"Value\"]",
            "",
            "    @needCertList",
            "    def getDIRACGroup(self, ignoreDefault=False):",
            "        \"\"\"",
            "        Retrieve the dirac group of the chain",
            "",
            "        :param ignoreDefault: (default False) if True, do not lookup the CS for a group if it is not in the proxy",
            "",
            "        :returns: S_OK(dirac group)/S_ERROR",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_ERROR(DErrno.EX509, \"Chain does not contain a valid proxy\")",
            "",
            "        # If it is a PUSP, we do a lookup based on the certificate",
            "        # (you can't do a PUSP out of a proxy)",
            "        if self.isPUSP()[\"Value\"]:",
            "            return self._certList[self.__firstProxyStep - 2].getDIRACGroup(ignoreDefault=ignoreDefault)",
            "",
            "        # The code below will find the first match of the DIRAC group",
            "        for cert in reversed(self._certList):",
            "            # We specifically say we do not want the default to first check inside the proxy",
            "            retVal = cert.getDIRACGroup(ignoreDefault=True)",
            "            if retVal[\"OK\"] and \"Value\" in retVal and retVal[\"Value\"]:",
            "                return retVal",
            "",
            "        # No DIRAC group found, try to get the default one",
            "        return self.getCertInChain(self.__firstProxyStep)[\"Value\"].getDIRACGroup(ignoreDefault=ignoreDefault)",
            "",
            "    @needCertList",
            "    def hasExpired(self):",
            "        \"\"\"",
            "        Check whether any element of the chain has expired",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        for cert in reversed(self._certList):",
            "            res = cert.hasExpired()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            # If True, it means the cert has expired",
            "            if res[\"Value\"]:",
            "                return S_OK(True)",
            "",
            "        return S_OK(False)",
            "",
            "    @needCertList",
            "    def getNotAfterDate(self):",
            "        \"\"\"",
            "        Get the smallest not after date",
            "",
            "        :returns: S_OK(datetime.datetime)",
            "        \"\"\"",
            "        notAfter = self._certList[0].getNotAfterDate()",
            "        if not notAfter[\"OK\"]:",
            "            return notAfter",
            "        notAfter = notAfter[\"Value\"]",
            "",
            "        for cert in reversed(self._certList):",
            "            res = cert.getNotAfterDate()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            stepNotAfter = res[\"Value\"]",
            "",
            "            # If the current cert has already expired",
            "            # we return this as notAfter date",
            "            res = cert.hasExpired()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            if res[\"Value\"]:",
            "                return S_OK(stepNotAfter)",
            "",
            "            # if the current cert has a shorter lifetime",
            "            # as the current reference, take it as new reference",
            "            notAfter = min(notAfter, stepNotAfter)",
            "",
            "        return S_OK(notAfter)",
            "",
            "    @needCertList",
            "    def generateProxyRequest(self, bitStrength=DEFAULT_PROXY_STRENGTH, limited=False):",
            "        \"\"\"",
            "        Generate a proxy request.",
            "        See :py:meth:`DIRAC.Core.Security.m2crypto.X509Certificate.X509Certificate.generateProxyRequest`",
            "",
            "        Return S_OK( X509Request ) / S_ERROR",
            "        \"\"\"",
            "",
            "        # We use the first certificate of the chain to do the proxy request",
            "        x509 = self._certList[0]",
            "        return x509.generateProxyRequest(bitStrength, limited)",
            "",
            "    @needCertList",
            "    def getStrength(self):",
            "        \"\"\"",
            "        Returns the strength in bit of the key of the first certificate in the chain",
            "        \"\"\"",
            "        x509 = self._certList[0]",
            "        return x509.getStrength()",
            "",
            "    @needCertList",
            "    @needPKey",
            "    def generateChainFromRequestString(self, pemData, lifetime=86400, requireLimited=False, diracGroup=False):",
            "        \"\"\"",
            "        Generate a x509 chain from a request.",
            "",
            "        :param pemData: PEM encoded request",
            "        :param lifetime: lifetime of the delegated proxy in seconds (default 1 day)",
            "        :param requireLimited: if True, requires a limited proxy",
            "        :param diracGroup: DIRAC group to put in the proxy",
            "        :param rfc: placeholder for compatibility, ignored",
            "",
            "        :returns: S_OK( X509 chain pem encoded string ) / S_ERROR. The new chain will have been signed",
            "                  with the public key included in the request",
            "",
            "        \"\"\"",
            "        try:",
            "            req = M2Crypto.X509.load_request_string(pemData, format=M2Crypto.X509.FORMAT_PEM)",
            "",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"Can't load request data: {repr(e).replace(',)', ')')}\")",
            "",
            "        # I am not sure this test makes sense.",
            "        # You can't request a limit proxy if you are yourself not limited ?!",
            "        # I think it should be a \"or\" instead of \"and\"",
            "        limited = requireLimited and self.isLimitedProxy().get(\"Value\", False)",
            "        return self.generateProxyToString(lifetime, diracGroup, DEFAULT_PROXY_STRENGTH, limited, req.get_pubkey())",
            "",
            "    @needCertList",
            "    def getRemainingSecs(self):",
            "        \"\"\"",
            "        Get remaining time (minimum of all cert in the chain)",
            "",
            "        :returns: S_OK(time left in seconds)",
            "        \"\"\"",
            "        remainingSecs = self.getCertInChain(0)[\"Value\"].getRemainingSecs()[\"Value\"]",
            "        for cert in self._certList[1:]:",
            "            stepRS = cert.getRemainingSecs()[\"Value\"]",
            "            remainingSecs = min(remainingSecs, stepRS)",
            "",
            "        return S_OK(remainingSecs)",
            "",
            "    @needCertList",
            "    def dumpAllToString(self):",
            "        \"\"\"",
            "        Dump the current chain as a PEM encoded string",
            "        The order would be:",
            "",
            "          * first certificate",
            "          * private key (without passphrase)",
            "          * other certificates",
            "",
            "        :returns: S_OK(PEM encoded chain with private key)",
            "        \"\"\"",
            "        data = self._certList[0].asPem()",
            "        if self._keyObj:",
            "            data += self._keyObj.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\")",
            "        for cert in self._certList[1:]:",
            "            data += cert.asPem()",
            "        return S_OK(data)",
            "",
            "    def dumpAllToFile(self, filename=False):",
            "        \"\"\"",
            "        Dump all to file.",
            "",
            "        :param filename: If not specified, a temporary one will be created",
            "",
            "        :returns: S_OK(filename)/S_ERROR",
            "        \"\"\"",
            "        retVal = self.dumpAllToString()",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        pemData = retVal[\"Value\"]",
            "        try:",
            "            if not filename:",
            "                fd, filename = tempfile.mkstemp()",
            "                os.close(fd)",
            "            with open(filename, \"w\") as fp:",
            "                fp.write(pemData)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filename} :{repr(e).replace(',)', ')')}\")",
            "        try:",
            "            os.chmod(filename, stat.S_IRUSR | stat.S_IWUSR)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ESPF, f\"{filename} :{repr(e).replace(',)', ')')}\")",
            "        return S_OK(filename)",
            "",
            "    @needCertList",
            "    def dumpChainToString(self):",
            "        \"\"\"",
            "        Dump only cert chain to string, without the PKey",
            "",
            "        :returns: S_OK(pem chain)",
            "        \"\"\"",
            "        return S_OK(\"\".join(cert.asPem() for cert in self._certList))",
            "",
            "    @needPKey",
            "    def dumpPKeyToString(self):",
            "        \"\"\"",
            "        Dump only the key to string, not encoded",
            "",
            "        :returns: S_OK(PEM encoded key)",
            "",
            "        \"\"\"",
            "        return S_OK(self._keyObj.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\"))",
            "",
            "    def __str__(self):",
            "        \"\"\"String representation\"\"\"",
            "        repStr = \"<X509Chain\"",
            "        if self._certList:",
            "            repStr += f\" {len(self._certList)} certs \"",
            "            for cert in self._certList:",
            "                repStr += f\"[{str(cert.getSubjectDN()['Value'])}]\"",
            "        if self._keyObj:",
            "            repStr += \" with key\"",
            "        repStr += \">\"",
            "        return repStr",
            "",
            "    def __repr__(self):",
            "        \"\"\"Object representation\"\"\"",
            "        return self.__str__()",
            "",
            "    def isPUSP(self):",
            "        \"\"\"Checks whether the current chain is a PUSP",
            "",
            "        :returns: S_OK(boolean).",
            "                  If True, the S_OK structure is enriched with:",
            "                  * Indentity: the DN",
            "                  * SubProxyUser: name of the user",
            "        \"\"\"",
            "        if self.__isProxy:",
            "            # Check if we have a subproxy",
            "            dn = self._certList[self.__firstProxyStep].getSubjectDN()",
            "            if not dn[\"OK\"]:",
            "                return dn",
            "            dn = dn[\"Value\"]",
            "",
            "            subproxyUser = isPUSPdn(dn)",
            "            if subproxyUser:",
            "                result = S_OK(True)",
            "                result[\"Identity\"] = dn",
            "                result[\"SubproxyUser\"] = subproxyUser",
            "                return result",
            "",
            "        return S_OK(False)",
            "",
            "    @needCertList",
            "    def getCredentials(self, ignoreDefault=False, withRegistryInfo=True):",
            "        \"\"\"Returns a summary of the credentials contained in the current chain",
            "",
            "        :params ignoreDefault: (default False) If True and if no DIRAC group is found in the proxy, lookup the CS",
            "        :params withRegistryInfo: (default True) if set to True, will enhance the returned dict with info",
            "                                  from the registry",
            "",
            "",
            "        :returns: S_OK with the credential dict. Some parameters of the dict are always there, other depends",
            "                on the nature of the Chain",
            "",
            "                Always present:",
            "                  * subject: str. The last DN in the chain",
            "                  * issuer: str. The issuer of the last cert in the chain",
            "                  * secondsLeft: validity of the chain in seconds (see :py:meth:`.getRemainingSecs`)",
            "                  * isProxy: boolean (see :py:meth:`.isProxy`)",
            "                  * isLimitedProxy: boolean (see :py:meth:`.isLimitedProxy`)",
            "                  * validDN: boolean if the DN is known to DIRAC",
            "                  * validGroup: False (see further definition)",
            "                  * DN: either the DN of the host, or the DN of the user corresponding to the proxy",
            "",
            "",
            "                Only for proxy:",
            "                  * identity: If it is a normal proxy, it is the DN of the certificate.",
            "                              If it is a PUSP, it contains the identity as in :py:meth:`.isPUSP`",
            "                  * username: DIRAC username associated to the DN (needs withRegistryInfo)",
            "                              (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getUsernameForDN`)",
            "                  * group: DIRAC group, depending on ignoreDefault param(see :py:meth:`.getDIRACGroup`)",
            "                  * validGroup: True if the group found is in the list of groups the user belongs to",
            "                  * groupProperty: (only if validGroup) get the properties of the group",
            "",
            "                For Host certificate (needs withRegistryInfo):",
            "                  * group: always `hosts`",
            "                  * hostname: name of the host as registered in the CS",
            "                             (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getHostnameForDN`)",
            "                  * validGroup: True",
            "                  * groupProperties: host options",
            "                                    (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getHostOption`)",
            "",
            "                If it is a user certificate (needs withRegistryInfo):",
            "                  * username: like for proxy",
            "                  * validDN: like proxy",
            "        \"\"\"",
            "        credDict = {",
            "            \"subject\": str(self._certList[0].getSubjectDN()[\"Value\"]),  # ['Value'] :(",
            "            \"issuer\": self._certList[0].getIssuerDN()[\"Value\"],  # ['Value'] :(",
            "            \"secondsLeft\": self.getRemainingSecs()[\"Value\"],",
            "            \"isProxy\": self.__isProxy,",
            "            \"isLimitedProxy\": self.__isProxy and self.__isLimitedProxy,",
            "            \"validDN\": False,",
            "            \"validGroup\": False,",
            "        }",
            "",
            "        # Add the DN entry as the subject.",
            "        credDict[\"DN\"] = credDict[\"subject\"]",
            "        if self.__isProxy:",
            "            credDict[\"identity\"] = str(",
            "                self._certList[self.__firstProxyStep + 1].getSubjectDN()[\"Value\"]",
            "            )  # ['Value'] :(",
            "            # if the chain is a proxy, then the DN we want to work with is the real one of the",
            "            # user, not the one of his proxy",
            "            credDict[\"DN\"] = credDict[\"identity\"]",
            "",
            "            # Check if we have the PUSP case",
            "            result = self.isPUSP()",
            "            if result[\"OK\"] and result[\"Value\"]:",
            "                credDict[\"identity\"] = result[\"Identity\"]",
            "                credDict[\"subproxyUser\"] = result[\"SubproxyUser\"]",
            "",
            "            if withRegistryInfo:",
            "                retVal = Registry.getUsernameForDN(credDict[\"identity\"])",
            "                if not retVal[\"OK\"]:",
            "                    return S_OK(credDict)",
            "                credDict[\"username\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "            retVal = self.getDIRACGroup(ignoreDefault=ignoreDefault)",
            "            if retVal[\"OK\"]:",
            "                diracGroup = retVal[\"Value\"]",
            "                credDict[\"group\"] = diracGroup",
            "                if withRegistryInfo:",
            "                    retVal = Registry.getGroupsForUser(credDict[\"username\"])",
            "                    if retVal[\"OK\"] and diracGroup in retVal[\"Value\"]:",
            "                        credDict[\"validGroup\"] = True",
            "                        credDict[\"groupProperties\"] = Registry.getPropertiesForGroup(diracGroup)",
            "        elif withRegistryInfo:",
            "            retVal = Registry.getHostnameForDN(credDict[\"subject\"])",
            "            if retVal[\"OK\"]:",
            "                credDict[\"group\"] = \"hosts\"",
            "                credDict[\"hostname\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "                credDict[\"validGroup\"] = True",
            "                credDict[\"groupProperties\"] = Registry.getHostOption(credDict[\"hostname\"], \"Properties\")",
            "",
            "            retVal = Registry.getUsernameForDN(credDict[\"subject\"])",
            "            if retVal[\"OK\"]:",
            "                credDict[\"username\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "        return S_OK(credDict)",
            "",
            "    @needCertList",
            "    def hash(self):",
            "        \"\"\"Get a hash of the chain",
            "        In practice, this is only used to index the chain in a DictCache",
            "",
            "        :returns: S_OK(string hash)",
            "        \"\"\"",
            "        if self.__hash:",
            "            return S_OK(self.__hash)",
            "        sha1 = hashlib.sha1()",
            "        for cert in self._certList:",
            "            sha1.update(str(cert.getSubjectNameObject()[\"Value\"]).encode())",
            "        sha1.update(str(self.getRemainingSecs()[\"Value\"] / 3600).encode())",
            "        sha1.update(self.getDIRACGroup()[\"Value\"].encode())",
            "        if self.isVOMS():",
            "            sha1.update(b\"VOMS\")",
            "            from DIRAC.Core.Security.VOMS import VOMS",
            "",
            "            result = VOMS().getVOMSAttributes(self)",
            "            if result[\"OK\"]:",
            "                for attribute in result[\"Value\"]:",
            "                    sha1.update(attribute.encode())",
            "        self.__hash = sha1.hexdigest()",
            "        return S_OK(self.__hash)",
            "",
            "",
            "def isPUSPdn(userDN):",
            "    \"\"\"Evaluate if the DN is of the PUSP type or not",
            "",
            "    :param str userDN: user DN string",
            "",
            "    :returns: the subproxy user name or None",
            "    \"\"\"",
            "    lastEntry = userDN.split(\"/\")[-1].split(\"=\")",
            "    if lastEntry[0] == \"CN\" and lastEntry[1].startswith(\"user:\"):",
            "        return userDN.split(\"/\")[-1].split(\":\")[1]",
            "    return None"
        ],
        "afterPatchFile": [
            "\"\"\" X509Chain is a class for managing X509 chains with their Pkeys",
            "",
            "Link to the RFC 3820: https://tools.ietf.org/html/rfc3820",
            "In particular, limited proxy: https://tools.ietf.org/html/rfc3820#section-3.8",
            "",
            "There are also details available about Per-User Sub-Proxies (PUSP)",
            "here: https://wiki.egi.eu/wiki/Usage_of_the_per_user_sub_proxy_in_EGI",
            "",
            "\"\"\"",
            "import copy",
            "import hashlib",
            "",
            "import re",
            "",
            "import M2Crypto",
            "",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Utilities.Decorators import executeOnlyIf, deprecated",
            "from DIRAC.Core.Utilities.File import secureOpenForWrite",
            "from DIRAC.ConfigurationSystem.Client.Helpers import Registry",
            "from DIRAC.Core.Security.m2crypto import PROXY_OID, LIMITED_PROXY_OID, DIRAC_GROUP_OID, DEFAULT_PROXY_STRENGTH",
            "from DIRAC.Core.Security.m2crypto.X509Certificate import X509Certificate",
            "",
            "",
            "# Decorator to check that _certList is not empty",
            "needCertList = executeOnlyIf(\"_certList\", S_ERROR(DErrno.ENOCHAIN))",
            "# Decorator to check that the PKey has been loaded",
            "needPKey = executeOnlyIf(\"_keyObj\", S_ERROR(DErrno.ENOPKEY))",
            "",
            "",
            "class X509Chain:",
            "    \"\"\"",
            "    An X509Chain is basically a list of X509Certificate object, as well as a PKey object,",
            "    which is associated to the X509Certificate the lowest in the chain.",
            "",
            "    This is what you will want to use for user certificate (because they will turn into proxy....), and for",
            "    proxy.",
            "",
            "    A priori, once we get rid of pyGSI, we could even meld the X509Certificate into this one, and use the X509Chain",
            "    for host certificates. After all, a certificate is nothing but a chain of length 1...",
            "",
            "    There are normally 4 ways you would instanciate an X509Chain object:",
            "",
            "    * You are loading a proxy from a file",
            "    * Loading the chain from a file",
            "    * You are getting information about your peer during an SSL connection",
            "    * You are delegating",
            "",
            "    Typical usages of X509Chain are illustrated below",
            "",
            "    Loading a proxy from a file (this will load the chain and the key, assuming the key is in the same file)::",
            "",
            "      proxy = X509Chain()",
            "      res = proxy.loadProxyFromFile(myFile)",
            "      if not res['OK']:",
            "        return res",
            "",
            "",
            "    Generating a proxy from a Certificate::",
            "",
            "      cert = X509Chain()",
            "      # Load user cert",
            "      retVal = cert.loadChainFromFile('/home/chaen/.globus/userkey.pem')",
            "      if not retVal['OK']:",
            "        return retVal",
            "      # Load the key from a different place, with a password",
            "      retVal = cert.loadKeyFromFile('/home/chaen/.globus/userkey.pem', password='MySecretKey')",
            "      if not retVal['OK']:",
            "        return res",
            "",
            "      # Generate a limited proxy, valid one hour",
            "      retVal = cert.generateProxyToFile('/tmp/proxy.pem',",
            "                                     3600, # only 1 h",
            "                                     diracGroup = 'lhcb_user',",
            "                                     strength= 2048,",
            "                                     limited=True)",
            "",
            "",
            "    Getting information from a peer in an SSL Connection::",
            "",
            "      # conn is an M2Crypto.SSL.Connection instance",
            "      chain = X509Chain.generateX509ChainFromSSLConnection(conn)",
            "      creds = chain.getCredentials()",
            "",
            "",
            "    Delegating a proxy to a service::",
            "",
            "      # The server side generates a request",
            "      # Equivalent to ProxyManager.requestDelegationUpload",
            "",
            "      x509Req = X509Request()",
            "      x509Req.generateProxyRequest()",
            "",
            "      # This reqStr object is sent to the client",
            "      reqStr = x509Req.dumpRequest()['Value']",
            "",
            "      # This object contains both the public and private key",
            "      pkeyReq = x509Req.getPKey()",
            "",
            "      #######################################################",
            "",
            "      # The client side signs the request, with its proxy",
            "      # Assume the proxy chain was already loaded one way or the otjer",
            "",
            "      # The proxy will not contain a private key",
            "      res = proxyChain.generateChainFromRequestString(reqStr, lifetime=lifetime)",
            "",
            "      # This is sent back to the server",
            "      delegatedProxyString = res['Value']",
            "",
            "      ######################################################",
            "      # Equivalent to ProxyManager.completeDelegationUpload",
            "",
            "      # Create the new chain",
            "      # the pkey was generated together with the Request",
            "      delegatedProxy = X509Chain(keyObj=pkeyReq)",
            "      delegatedProxy.loadChainFromString(delegatedProxyString)",
            "",
            "      # make sure the public key match between Request and the new Chain",
            "      # (Stupid, of course it will ! But it is done in the ProxyManager...)",
            "      res = x509Req.checkChain(delegatedProxy)",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, certList=False, keyObj=False):",
            "        \"\"\"",
            "        C'tor",
            "",
            "        :param certList: list of X509Certificate to constitute the chain",
            "        :param keyObj: ~M2Crypto.EVP.PKey object. The public or public/private key associated to",
            "                       the last certificate of the chain",
            "",
            "        \"\"\"",
            "",
            "        # __isProxy is True if this chain represents a proxy",
            "        self.__isProxy = False",
            "        # Whether the proxy is limited or not",
            "        self.__isLimitedProxy = False",
            "",
            "        # This is the position of the first proxy in the chain",
            "        self.__firstProxyStep = 0",
            "",
            "        # Cache for sha1 hash of the object",
            "        # This is just used as a unique identifier for",
            "        # indexing in the ProxyCache",
            "        self.__hash = False",
            "",
            "        # List of X509Certificate constituing the chain",
            "        # The certificate in position N has been generated from the (N+1)",
            "        self._certList = []",
            "",
            "        # Place holder for the EVP.PKey object",
            "        self._keyObj = None",
            "",
            "        if certList:",
            "            # copy the content of the list, without copying the objects themselves",
            "            self._certList = copy.copy(certList)",
            "            # Immediately check if it is a proxy",
            "            self.__checkProxyness()",
            "",
            "        if keyObj:",
            "            self._keyObj = keyObj",
            "",
            "    @classmethod",
            "    @deprecated(\"Use loadChainFromFile instead\", onlyOnce=True)",
            "    def instanceFromFile(cls, chainLocation):",
            "        \"\"\"Class method to generate a X509Chain from a file",
            "",
            "        :param chainLocation: path to the file",
            "",
            "        :returns: S_OK(X509Chain)",
            "        \"\"\"",
            "        chain = cls()",
            "        result = chain.loadChainFromFile(chainLocation)",
            "        if not result[\"OK\"]:",
            "            return result",
            "",
            "        return S_OK(chain)",
            "",
            "    @staticmethod",
            "    def generateX509ChainFromSSLConnection(sslConnection):",
            "        \"\"\"Returns an instance of X509Chain from the SSL connection",
            "",
            "        :param sslConnection: ~M2Crypto.SSl.Connection instance",
            "",
            "        :returns: a X509Chain instance",
            "        \"\"\"",
            "        certList = []",
            "",
            "        certStack = sslConnection.get_peer_cert_chain()",
            "        for cert in certStack:",
            "            certList.append(X509Certificate(x509Obj=cert))",
            "",
            "        # Servers don't receive the whole chain, the last cert comes alone",
            "        # if not self.infoDict['clientMode']:",
            "        certList.insert(0, X509Certificate(x509Obj=sslConnection.get_peer_cert()))",
            "        peerChain = X509Chain(certList=certList)",
            "",
            "        return peerChain",
            "",
            "    def loadChainFromFile(self, chainLocation):",
            "        \"\"\"",
            "        Load a x509 chain from a pem file",
            "",
            "        :param chainLocation: path to the file",
            "",
            "        :returns: S_OK/S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except OSError as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadChainFromString(pemData)",
            "",
            "    def loadChainFromString(self, data):",
            "        \"\"\"",
            "        Load a x509 cert from a string containing the pem data",
            "",
            "        :param data: data representing the chain of certificate in the",
            "",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            self._certList = self.__certListFromPemString(data)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')}\")",
            "",
            "        if not self._certList:",
            "            return S_ERROR(DErrno.EX509)",
            "",
            "        # Update internals",
            "        self.__checkProxyness()",
            "        return S_OK()",
            "",
            "    @staticmethod",
            "    def __certListFromPemString(certString):",
            "        \"\"\"",
            "        Create certificates list from string. String should contain certificates, just like plain text proxy file.",
            "        \"\"\"",
            "        # To get list of X509 certificates (not X509 Certificate Chain) from string it has to be parsed like that",
            "        # (constructors are not able to deal with big string)",
            "        certList = []",
            "        pattern = r\"(-----BEGIN CERTIFICATE-----((.|\\n)*?)-----END CERTIFICATE-----)\"",
            "        for cert in re.findall(pattern, certString):",
            "            certList.append(X509Certificate(certString=cert[0]))",
            "        return certList",
            "",
            "    # Not used in m2crypto version",
            "    # def setChain(self, certList):",
            "    #   \"\"\"",
            "    #   Set the chain",
            "    #   Return : S_OK / S_ERROR",
            "    #   \"\"\"",
            "    #   self._certList = certList",
            "    #   self.__loadedChain = True",
            "    #   return S_OK()",
            "",
            "    def loadKeyFromFile(self, chainLocation, password=False):",
            "        \"\"\"",
            "        Load a PKey from a pem file",
            "",
            "        :param chainLocation: path to the file",
            "        :param password: password to decode the file.",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadKeyFromString(pemData, password)",
            "",
            "    def loadKeyFromString(self, pemData, password=False):",
            "        \"\"\"",
            "        Load a PKey from a string containing the pem data",
            "",
            "        :param pemData: pem data of the key, potentially encoded with the password",
            "        :param password: password to decode the file.",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        self._keyObj = None",
            "        if not isinstance(pemData, bytes):",
            "            pemData = pemData.encode(\"ascii\")",
            "        if password:",
            "            password = password.encode()",
            "        try:",
            "            self._keyObj = M2Crypto.EVP.load_key_string(pemData, lambda x: password)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"{repr(e).replace(',)', ')')} (Probably bad pass phrase?)\")",
            "",
            "        return S_OK()",
            "",
            "    def setPKey(self, pkeyObj):",
            "        \"\"\"",
            "        Set the chain",
            "        Return : S_OK / S_ERROR",
            "        \"\"\"",
            "        self._keyObj = pkeyObj",
            "        return S_OK()",
            "",
            "    def loadProxyFromFile(self, chainLocation):",
            "        \"\"\"",
            "        Load a Proxy from a pem file, that is both the Cert chain and the PKey",
            "",
            "        :param chainLocation: path to the proxy file",
            "",
            "        :returns: S_OK  / S_ERROR",
            "        \"\"\"",
            "        try:",
            "            with open(chainLocation) as fd:",
            "                pemData = fd.read()",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EOF, f\"{chainLocation}: {repr(e).replace(',)', ')')}\")",
            "        return self.loadProxyFromString(pemData)",
            "",
            "    def loadProxyFromString(self, pemData):",
            "        \"\"\"",
            "        Load a Proxy from a pem buffer, that is both the Cert chain and the PKey",
            "",
            "        :param pemData: PEM encoded cert chain and pkey",
            "",
            "        :returns: S_OK / S_ERROR",
            "        \"\"\"",
            "        retVal = self.loadChainFromString(pemData)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "",
            "        return self.loadKeyFromString(pemData)",
            "",
            "    @staticmethod",
            "    def __getProxyExtensionList(diracGroup=False, rfcLimited=False):",
            "        \"\"\"",
            "        Get an extension stack containing the necessary extension for a proxy.",
            "        Basically the keyUsage, the proxyCertInfo, and eventually the diracGroup",
            "",
            "        :param diracGroup: name of the dirac group for the proxy",
            "        :param rfcLimited: boolean to generate for a limited proxy",
            "",
            "        :returns: M2Crypto.X509.X509_Extension_Stack object.",
            "        \"\"\"",
            "",
            "        extStack = M2Crypto.X509.X509_Extension_Stack()",
            "",
            "        # Standard certificate extensions",
            "        kUext = M2Crypto.X509.new_extension(",
            "            \"keyUsage\", \"digitalSignature, keyEncipherment, dataEncipherment\", critical=1",
            "        )",
            "        extStack.push(kUext)",
            "",
            "        # Mandatory extension to be a proxy",
            "        policyOID = LIMITED_PROXY_OID if rfcLimited else PROXY_OID",
            "        ext = M2Crypto.X509.new_extension(\"proxyCertInfo\", f\"critical, language:{policyOID}\", critical=1)",
            "        extStack.push(ext)",
            "",
            "        # Add a dirac group",
            "        if diracGroup and isinstance(diracGroup, str):",
            "            # the str cast is needed because M2Crypto does not play it cool with unicode here it seems",
            "            # Also one needs to specify the ASN1 type. That's what it is...",
            "            dGext = M2Crypto.X509.new_extension(DIRAC_GROUP_OID, str(f\"ASN1:IA5:{diracGroup}\"))",
            "            extStack.push(dGext)",
            "",
            "        return extStack",
            "",
            "    @needCertList",
            "    def getCertInChain(self, certPos=0):",
            "        \"\"\"",
            "        Get then a certificate in the chain",
            "",
            "        :warning: Contrary to the pygsi version, this is not a copy!",
            "",
            "        :param certPos: position of the certificate in the chain. Default: 0",
            "",
            "        :returns: S_OK(X509Certificate)/S_ERROR",
            "        \"\"\"",
            "        return S_OK(self._certList[certPos])",
            "",
            "    @needCertList",
            "    def getIssuerCert(self):",
            "        \"\"\"",
            "        Returns the issuer certificate of the last one if it is a proxy, otherwise",
            "        the last one in the chain",
            "",
            "        :returns: S_OK(X509Certificate)/S_ERROR",
            "        \"\"\"",
            "        if self.__isProxy:",
            "            return S_OK(self._certList[self.__firstProxyStep + 1])",
            "        return S_OK(self._certList[-1])",
            "",
            "    @deprecated(\"Only here for compatibility reason\", onlyOnce=True)",
            "    @needPKey",
            "    def getPKeyObj(self):",
            "        \"\"\"",
            "        Get the pkey obj",
            "",
            "        :returns: ~M2Crypto.EVP.PKey object",
            "        \"\"\"",
            "        return S_OK(self._keyObj)",
            "",
            "    @deprecated(\"Only here for compatibility reason\")",
            "    @needCertList",
            "    def getCertList(self):",
            "        \"\"\"",
            "        Get the cert list",
            "        \"\"\"",
            "        return S_OK(self._certList)",
            "",
            "    @needCertList",
            "    def getNumCertsInChain(self):",
            "        \"\"\"",
            "        length of the certificate chain",
            "",
            "        :returns: length of the certificate chain",
            "",
            "",
            "        \"\"\"",
            "        return S_OK(len(self._certList))",
            "",
            "    # pylint: disable=unused-argument",
            "    @needCertList",
            "    @needPKey",
            "    def generateProxyToString(",
            "        self, lifetime, diracGroup=False, strength=DEFAULT_PROXY_STRENGTH, limited=False, proxyKey=False",
            "    ):",
            "        \"\"\"",
            "        Generate a proxy and get it as a string.",
            "",
            "        Check here: https://github.com/eventbrite/m2crypto/blob/master/demo/x509/ca.py#L45",
            "",
            "        Args:",
            "            lifetime (int): expected lifetime in seconds of proxy",
            "            diracGroup (str): diracGroup to add to the certificate",
            "            strength (int): length in bits of the pair if proxyKey not given (default 2048)",
            "            limited (bool): Create a limited proxy (default False)",
            "            proxyKey: M2Crypto.EVP.PKey instance with private and public key. If not given, generate one",
            "            rfc: placeholder for backward compatibility and ignored",
            "",
            "        :returns: S_OK(PEM encoded string), S_ERROR. The PEM string contains all the certificates in the chain",
            "                  and the private key associated to the last X509Certificate just generated.",
            "        \"\"\"",
            "",
            "        issuerCert = self._certList[0]",
            "",
            "        # If this is a certificate signing request then the private key will be",
            "        # appended by the server and we don't need to include it in the proxy",
            "        include_private_key = not proxyKey",
            "        if not proxyKey:",
            "            # Generating key is a two step process: create key object and then assign RSA key.",
            "            # This contains both the private and public key",
            "            proxyKey = M2Crypto.EVP.PKey()",
            "            proxyKey.assign_rsa(M2Crypto.RSA.gen_key(strength, 65537, callback=M2Crypto.util.quiet_genparam_callback))",
            "",
            "        # Generate a new X509Certificate object",
            "        proxyExtensions = self.__getProxyExtensionList(diracGroup, limited)",
            "        res = X509Certificate.generateProxyCertFromIssuer(issuerCert, proxyExtensions, proxyKey, lifetime=lifetime)",
            "        if not res[\"OK\"]:",
            "            return res",
            "        proxyCert = res[\"Value\"]",
            "",
            "        # Sign it with one owns key",
            "        proxyCert.sign(self._keyObj, \"sha256\")",
            "",
            "        # Generate the proxy string",
            "        proxyString = proxyCert.asPem()",
            "        if include_private_key:",
            "            proxyString += proxyKey.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\")",
            "        for i in range(len(self._certList)):",
            "            crt = self._certList[i]",
            "            proxyString += crt.asPem()",
            "        return S_OK(proxyString)",
            "",
            "    # pylint: disable=unused-argument",
            "    def generateProxyToFile(self, filePath, lifetime, diracGroup=False, strength=DEFAULT_PROXY_STRENGTH, limited=False):",
            "        \"\"\"",
            "        Generate a proxy and put it into a file",
            "",
            "        Args:",
            "            filePath: file to write",
            "            lifetime: expected lifetime in seconds of proxy",
            "            diracGroup: diracGroup to add to the certificate",
            "            strength: length in bits of the pair",
            "            limited: Create a limited proxy",
            "            rfc: placeholder and ignored",
            "        \"\"\"",
            "        retVal = self.generateProxyToString(lifetime, diracGroup, strength, limited)",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        try:",
            "            with secureOpenForWrite(filePath) as fd:",
            "                fd.write(retVal[\"Value\"])",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filePath} :{repr(e).replace(',)', ')')}\")",
            "        return S_OK()",
            "",
            "    @needCertList",
            "    def isProxy(self):",
            "        \"\"\"",
            "         Check whether this chain is a proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        return S_OK(self.__isProxy)",
            "",
            "    @needCertList",
            "    def isLimitedProxy(self):",
            "        \"\"\"",
            "        Check whether this chain is a limited proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        return S_OK(self.__isProxy and self.__isLimitedProxy)",
            "",
            "    @needCertList",
            "    def isValidProxy(self, ignoreDefault=False):",
            "        \"\"\"",
            "        Check whether this chain is a valid proxy, that is:",
            "          * a proxy",
            "          * still valid",
            "          * with a valid group",
            "",
            "        :param ignoreDefault: (what a stupid name) if True, do not lookup the CS",
            "",
            "        :returns: S_OK(True) if the proxy is valid, S_ERROR otherwise",
            "",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_ERROR(DErrno.ENOCHAIN, \"Chain is not a proxy\")",
            "",
            "        if self.hasExpired()[\"Value\"]:",
            "            return S_ERROR(DErrno.ENOCHAIN)",
            "",
            "        if ignoreDefault:",
            "            groupRes = self.getDIRACGroup(ignoreDefault=True)",
            "            if not groupRes[\"OK\"]:",
            "                return groupRes",
            "            if not groupRes[\"Value\"]:",
            "                return S_ERROR(DErrno.ENOGROUP)",
            "",
            "        return S_OK(True)",
            "",
            "    def isVOMS(self):",
            "        \"\"\"",
            "        Check whether this proxy contains VOMS extensions.",
            "        It is enough for one of the certificate of the chain to have VOMS extension",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "",
            "        if not self.__isProxy:",
            "            return S_OK(False)",
            "",
            "        for cert in self._certList:",
            "            if cert.hasVOMSExtensions()[\"Value\"]:",
            "                return S_OK(True)",
            "        return S_OK(False)",
            "",
            "    def isRFC(self):",
            "        \"\"\"Check whether this is an RFC proxy. It can only be true, providing it is a proxy",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "",
            "        return self.isProxy()",
            "",
            "    def getVOMSData(self):",
            "        \"\"\"",
            "        Returns the voms data.",
            "",
            "        :returns: See :py:func:`~DIRAC.Core.Security.m2crypto.X509Certificate.getVOMSData`",
            "                  If no VOMS data is available, return DErrno.EVOMS",
            "        :warning: In case the chain is not a proxy, this method will return False.",
            "                  Yes, it's stupid, but it is for compatibility...",
            "",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_OK(False)",
            "",
            "        for cert in self._certList:",
            "            res = cert.getVOMSData()",
            "            if res[\"OK\"]:",
            "                return res",
            "        return S_ERROR(DErrno.EVOMS)",
            "",
            "    def __checkProxyness(self):",
            "        \"\"\"This method is called upon initialization of a chain and fill in some internal attributes.",
            "",
            "        Pure madness...",
            "",
            "        To me, this method just seems to work by pure luck..",
            "        \"\"\"",
            "",
            "        self.__hash = False",
            "        self.__firstProxyStep = len(self._certList) - 2  # -1 is user cert by default, -2 is first proxy step",
            "        self.__isProxy = True",
            "        self.__isLimitedProxy = False",
            "        prevDNMatch = 2",
            "        # If less than 2 steps in the chain is no proxy",
            "        if len(self._certList) < 2:",
            "            self.__isProxy = False",
            "            return",
            "",
            "        # Here we make sure that each certificate in the chain was",
            "        # signed by the previous one",
            "        for step in range(len(self._certList) - 1):",
            "            # this is a cryptographic check with the keys",
            "            issuerMatch = self.__checkIssuer(step, step + 1)",
            "            if not issuerMatch:",
            "                self.__isProxy = False",
            "                return",
            "",
            "            # Do we need to check the proxy DN?",
            "            if prevDNMatch:",
            "                dnMatch = self.__checkProxyDN(step, step + 1)",
            "                if dnMatch == 0:",
            "                    # If we are not in the first step we've found the entity cert",
            "                    if step > 0:",
            "                        self.__firstProxyStep = step - 1",
            "                    # If we are in the first step this is not a proxy",
            "                    else:",
            "                        self.__isProxy = False",
            "                        return",
            "                # Limited proxy DN match",
            "                elif dnMatch == 2:",
            "                    self.__isLimitedProxy = True",
            "                    if prevDNMatch != 2:",
            "                        self.__isProxy = False",
            "                        self.__isLimitedProxy = False",
            "                        return",
            "                prevDNMatch = dnMatch",
            "",
            "    def __checkProxyDN(self, certStep, issuerStep):",
            "        \"\"\"",
            "        Checks that the subject of the proxy is properly derived from the issuer subject.",
            "",
            "        Args:",
            "            certStep: position of the certificate to check in self.__certList",
            "            issuerStep: position of the issuer certificate to check in self.__certList",
            "",
            "        :returns: an int based on the match:",
            "                  0 = no match",
            "                  1 = proxy match",
            "                  2 = limited proxy match",
            "        \"\"\"",
            "",
            "        issuerSubject = self._certList[issuerStep].getSubjectNameObject()",
            "        if not issuerSubject[\"OK\"]:",
            "            return 0",
            "        issuerSubject = issuerSubject[\"Value\"]",
            "",
            "        proxySubject = self._certList[certStep].getSubjectNameObject()",
            "        if not proxySubject[\"OK\"]:",
            "            return 0",
            "        proxySubject = proxySubject[\"Value\"]",
            "",
            "        lastEntry = str(proxySubject).split(\"/\")[-1].split(\"=\")",
            "        limited = False",
            "        if lastEntry[0] != \"CN\":",
            "            return 0",
            "",
            "        # For non-RFC proxy, the proxy always had these two strings in the CN",
            "        if lastEntry[1] not in (\"proxy\", \"limited proxy\"):",
            "            # for RFC proxy, one has to check the extension.",
            "            ext = self._certList[certStep].getExtension(\"proxyCertInfo\")",
            "            if not ext[\"OK\"]:",
            "                return 0",
            "",
            "            ext = ext[\"Value\"]",
            "",
            "            # Check the RFC",
            "            contraint = [",
            "                line.split(\":\")[1].strip()",
            "                for line in ext.get_value().split(\"\\n\")",
            "                if line.split(\":\")[0] == \"Policy Language\"",
            "            ]",
            "            if not contraint:",
            "                return 0",
            "            if contraint[0] == LIMITED_PROXY_OID:",
            "                limited = True",
            "        else:",
            "            if lastEntry[1] == \"limited proxy\":",
            "                limited = True",
            "        if not str(issuerSubject) == str(proxySubject)[: str(proxySubject).rfind(\"/\")]:",
            "            return 0",
            "        return 1 if not limited else 2",
            "",
            "    def __checkIssuer(self, certStep, issuerStep):",
            "        \"\"\"",
            "        Check that the issuer has signed the certificate with his private key",
            "",
            "        :param certStep: position of the certificate in self.__certList",
            "        :param issuerStep: position of the issuer certificate",
            "",
            "        :returns: S_OK(boolean)",
            "",
            "        \"\"\"",
            "        issuerCert = self._certList[issuerStep]",
            "        cert = self._certList[certStep]",
            "        pubKey = issuerCert.getPublicKey()[\"Value\"]",
            "",
            "        return cert.verify(pubKey)[\"Value\"]",
            "",
            "    @needCertList",
            "    def getDIRACGroup(self, ignoreDefault=False):",
            "        \"\"\"",
            "        Retrieve the dirac group of the chain",
            "",
            "        :param ignoreDefault: (default False) if True, do not lookup the CS for a group if it is not in the proxy",
            "",
            "        :returns: S_OK(dirac group)/S_ERROR",
            "        \"\"\"",
            "        if not self.__isProxy:",
            "            return S_ERROR(DErrno.EX509, \"Chain does not contain a valid proxy\")",
            "",
            "        # If it is a PUSP, we do a lookup based on the certificate",
            "        # (you can't do a PUSP out of a proxy)",
            "        if self.isPUSP()[\"Value\"]:",
            "            return self._certList[self.__firstProxyStep - 2].getDIRACGroup(ignoreDefault=ignoreDefault)",
            "",
            "        # The code below will find the first match of the DIRAC group",
            "        for cert in reversed(self._certList):",
            "            # We specifically say we do not want the default to first check inside the proxy",
            "            retVal = cert.getDIRACGroup(ignoreDefault=True)",
            "            if retVal[\"OK\"] and \"Value\" in retVal and retVal[\"Value\"]:",
            "                return retVal",
            "",
            "        # No DIRAC group found, try to get the default one",
            "        return self.getCertInChain(self.__firstProxyStep)[\"Value\"].getDIRACGroup(ignoreDefault=ignoreDefault)",
            "",
            "    @needCertList",
            "    def hasExpired(self):",
            "        \"\"\"",
            "        Check whether any element of the chain has expired",
            "",
            "        :returns: S_OK(boolean)",
            "        \"\"\"",
            "        for cert in reversed(self._certList):",
            "            res = cert.hasExpired()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            # If True, it means the cert has expired",
            "            if res[\"Value\"]:",
            "                return S_OK(True)",
            "",
            "        return S_OK(False)",
            "",
            "    @needCertList",
            "    def getNotAfterDate(self):",
            "        \"\"\"",
            "        Get the smallest not after date",
            "",
            "        :returns: S_OK(datetime.datetime)",
            "        \"\"\"",
            "        notAfter = self._certList[0].getNotAfterDate()",
            "        if not notAfter[\"OK\"]:",
            "            return notAfter",
            "        notAfter = notAfter[\"Value\"]",
            "",
            "        for cert in reversed(self._certList):",
            "            res = cert.getNotAfterDate()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            stepNotAfter = res[\"Value\"]",
            "",
            "            # If the current cert has already expired",
            "            # we return this as notAfter date",
            "            res = cert.hasExpired()",
            "            if not res[\"OK\"]:",
            "                return res",
            "            if res[\"Value\"]:",
            "                return S_OK(stepNotAfter)",
            "",
            "            # if the current cert has a shorter lifetime",
            "            # as the current reference, take it as new reference",
            "            notAfter = min(notAfter, stepNotAfter)",
            "",
            "        return S_OK(notAfter)",
            "",
            "    @needCertList",
            "    def generateProxyRequest(self, bitStrength=DEFAULT_PROXY_STRENGTH, limited=False):",
            "        \"\"\"",
            "        Generate a proxy request.",
            "        See :py:meth:`DIRAC.Core.Security.m2crypto.X509Certificate.X509Certificate.generateProxyRequest`",
            "",
            "        Return S_OK( X509Request ) / S_ERROR",
            "        \"\"\"",
            "",
            "        # We use the first certificate of the chain to do the proxy request",
            "        x509 = self._certList[0]",
            "        return x509.generateProxyRequest(bitStrength, limited)",
            "",
            "    @needCertList",
            "    def getStrength(self):",
            "        \"\"\"",
            "        Returns the strength in bit of the key of the first certificate in the chain",
            "        \"\"\"",
            "        x509 = self._certList[0]",
            "        return x509.getStrength()",
            "",
            "    @needCertList",
            "    @needPKey",
            "    def generateChainFromRequestString(self, pemData, lifetime=86400, requireLimited=False, diracGroup=False):",
            "        \"\"\"",
            "        Generate a x509 chain from a request.",
            "",
            "        :param pemData: PEM encoded request",
            "        :param lifetime: lifetime of the delegated proxy in seconds (default 1 day)",
            "        :param requireLimited: if True, requires a limited proxy",
            "        :param diracGroup: DIRAC group to put in the proxy",
            "        :param rfc: placeholder for compatibility, ignored",
            "",
            "        :returns: S_OK( X509 chain pem encoded string ) / S_ERROR. The new chain will have been signed",
            "                  with the public key included in the request",
            "",
            "        \"\"\"",
            "        try:",
            "            req = M2Crypto.X509.load_request_string(pemData, format=M2Crypto.X509.FORMAT_PEM)",
            "",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.ECERTREAD, f\"Can't load request data: {repr(e).replace(',)', ')')}\")",
            "",
            "        # I am not sure this test makes sense.",
            "        # You can't request a limit proxy if you are yourself not limited ?!",
            "        # I think it should be a \"or\" instead of \"and\"",
            "        limited = requireLimited and self.isLimitedProxy().get(\"Value\", False)",
            "        return self.generateProxyToString(lifetime, diracGroup, DEFAULT_PROXY_STRENGTH, limited, req.get_pubkey())",
            "",
            "    @needCertList",
            "    def getRemainingSecs(self):",
            "        \"\"\"",
            "        Get remaining time (minimum of all cert in the chain)",
            "",
            "        :returns: S_OK(time left in seconds)",
            "        \"\"\"",
            "        remainingSecs = self.getCertInChain(0)[\"Value\"].getRemainingSecs()[\"Value\"]",
            "        for cert in self._certList[1:]:",
            "            stepRS = cert.getRemainingSecs()[\"Value\"]",
            "            remainingSecs = min(remainingSecs, stepRS)",
            "",
            "        return S_OK(remainingSecs)",
            "",
            "    @needCertList",
            "    def dumpAllToString(self):",
            "        \"\"\"",
            "        Dump the current chain as a PEM encoded string",
            "        The order would be:",
            "",
            "          * first certificate",
            "          * private key (without passphrase)",
            "          * other certificates",
            "",
            "        :returns: S_OK(PEM encoded chain with private key)",
            "        \"\"\"",
            "        data = self._certList[0].asPem()",
            "        if self._keyObj:",
            "            data += self._keyObj.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\")",
            "        for cert in self._certList[1:]:",
            "            data += cert.asPem()",
            "        return S_OK(data)",
            "",
            "    def dumpAllToFile(self, filename=False):",
            "        \"\"\"",
            "        Dump all to file.",
            "",
            "        :param filename: If not specified, a temporary one will be created",
            "",
            "        :returns: S_OK(filename)/S_ERROR",
            "        \"\"\"",
            "        retVal = self.dumpAllToString()",
            "        if not retVal[\"OK\"]:",
            "            return retVal",
            "        pemData = retVal[\"Value\"]",
            "        try:",
            "            with secureOpenForWrite(filename) as fh:",
            "                fh.write(pemData)",
            "        except Exception as e:",
            "            return S_ERROR(DErrno.EWF, f\"{filename} :{repr(e).replace(',)', ')')}\")",
            "        return S_OK(filename)",
            "",
            "    @needCertList",
            "    def dumpChainToString(self):",
            "        \"\"\"",
            "        Dump only cert chain to string, without the PKey",
            "",
            "        :returns: S_OK(pem chain)",
            "        \"\"\"",
            "        return S_OK(\"\".join(cert.asPem() for cert in self._certList))",
            "",
            "    @needPKey",
            "    def dumpPKeyToString(self):",
            "        \"\"\"",
            "        Dump only the key to string, not encoded",
            "",
            "        :returns: S_OK(PEM encoded key)",
            "",
            "        \"\"\"",
            "        return S_OK(self._keyObj.as_pem(cipher=None, callback=M2Crypto.util.no_passphrase_callback).decode(\"ascii\"))",
            "",
            "    def __str__(self):",
            "        \"\"\"String representation\"\"\"",
            "        repStr = \"<X509Chain\"",
            "        if self._certList:",
            "            repStr += f\" {len(self._certList)} certs \"",
            "            for cert in self._certList:",
            "                repStr += f\"[{str(cert.getSubjectDN()['Value'])}]\"",
            "        if self._keyObj:",
            "            repStr += \" with key\"",
            "        repStr += \">\"",
            "        return repStr",
            "",
            "    def __repr__(self):",
            "        \"\"\"Object representation\"\"\"",
            "        return self.__str__()",
            "",
            "    def isPUSP(self):",
            "        \"\"\"Checks whether the current chain is a PUSP",
            "",
            "        :returns: S_OK(boolean).",
            "                  If True, the S_OK structure is enriched with:",
            "                  * Indentity: the DN",
            "                  * SubProxyUser: name of the user",
            "        \"\"\"",
            "        if self.__isProxy:",
            "            # Check if we have a subproxy",
            "            dn = self._certList[self.__firstProxyStep].getSubjectDN()",
            "            if not dn[\"OK\"]:",
            "                return dn",
            "            dn = dn[\"Value\"]",
            "",
            "            subproxyUser = isPUSPdn(dn)",
            "            if subproxyUser:",
            "                result = S_OK(True)",
            "                result[\"Identity\"] = dn",
            "                result[\"SubproxyUser\"] = subproxyUser",
            "                return result",
            "",
            "        return S_OK(False)",
            "",
            "    @needCertList",
            "    def getCredentials(self, ignoreDefault=False, withRegistryInfo=True):",
            "        \"\"\"Returns a summary of the credentials contained in the current chain",
            "",
            "        :params ignoreDefault: (default False) If True and if no DIRAC group is found in the proxy, lookup the CS",
            "        :params withRegistryInfo: (default True) if set to True, will enhance the returned dict with info",
            "                                  from the registry",
            "",
            "",
            "        :returns: S_OK with the credential dict. Some parameters of the dict are always there, other depends",
            "                on the nature of the Chain",
            "",
            "                Always present:",
            "                  * subject: str. The last DN in the chain",
            "                  * issuer: str. The issuer of the last cert in the chain",
            "                  * secondsLeft: validity of the chain in seconds (see :py:meth:`.getRemainingSecs`)",
            "                  * isProxy: boolean (see :py:meth:`.isProxy`)",
            "                  * isLimitedProxy: boolean (see :py:meth:`.isLimitedProxy`)",
            "                  * validDN: boolean if the DN is known to DIRAC",
            "                  * validGroup: False (see further definition)",
            "                  * DN: either the DN of the host, or the DN of the user corresponding to the proxy",
            "",
            "",
            "                Only for proxy:",
            "                  * identity: If it is a normal proxy, it is the DN of the certificate.",
            "                              If it is a PUSP, it contains the identity as in :py:meth:`.isPUSP`",
            "                  * username: DIRAC username associated to the DN (needs withRegistryInfo)",
            "                              (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getUsernameForDN`)",
            "                  * group: DIRAC group, depending on ignoreDefault param(see :py:meth:`.getDIRACGroup`)",
            "                  * validGroup: True if the group found is in the list of groups the user belongs to",
            "                  * groupProperty: (only if validGroup) get the properties of the group",
            "",
            "                For Host certificate (needs withRegistryInfo):",
            "                  * group: always `hosts`",
            "                  * hostname: name of the host as registered in the CS",
            "                             (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getHostnameForDN`)",
            "                  * validGroup: True",
            "                  * groupProperties: host options",
            "                                    (see :py:func:`DIRAC.ConfigurationSystem.Client.Helpers.Registry.getHostOption`)",
            "",
            "                If it is a user certificate (needs withRegistryInfo):",
            "                  * username: like for proxy",
            "                  * validDN: like proxy",
            "        \"\"\"",
            "        credDict = {",
            "            \"subject\": str(self._certList[0].getSubjectDN()[\"Value\"]),  # ['Value'] :(",
            "            \"issuer\": self._certList[0].getIssuerDN()[\"Value\"],  # ['Value'] :(",
            "            \"secondsLeft\": self.getRemainingSecs()[\"Value\"],",
            "            \"isProxy\": self.__isProxy,",
            "            \"isLimitedProxy\": self.__isProxy and self.__isLimitedProxy,",
            "            \"validDN\": False,",
            "            \"validGroup\": False,",
            "        }",
            "",
            "        # Add the DN entry as the subject.",
            "        credDict[\"DN\"] = credDict[\"subject\"]",
            "        if self.__isProxy:",
            "            credDict[\"identity\"] = str(",
            "                self._certList[self.__firstProxyStep + 1].getSubjectDN()[\"Value\"]",
            "            )  # ['Value'] :(",
            "            # if the chain is a proxy, then the DN we want to work with is the real one of the",
            "            # user, not the one of his proxy",
            "            credDict[\"DN\"] = credDict[\"identity\"]",
            "",
            "            # Check if we have the PUSP case",
            "            result = self.isPUSP()",
            "            if result[\"OK\"] and result[\"Value\"]:",
            "                credDict[\"identity\"] = result[\"Identity\"]",
            "                credDict[\"subproxyUser\"] = result[\"SubproxyUser\"]",
            "",
            "            if withRegistryInfo:",
            "                retVal = Registry.getUsernameForDN(credDict[\"identity\"])",
            "                if not retVal[\"OK\"]:",
            "                    return S_OK(credDict)",
            "                credDict[\"username\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "            retVal = self.getDIRACGroup(ignoreDefault=ignoreDefault)",
            "            if retVal[\"OK\"]:",
            "                diracGroup = retVal[\"Value\"]",
            "                credDict[\"group\"] = diracGroup",
            "                if withRegistryInfo:",
            "                    retVal = Registry.getGroupsForUser(credDict[\"username\"])",
            "                    if retVal[\"OK\"] and diracGroup in retVal[\"Value\"]:",
            "                        credDict[\"validGroup\"] = True",
            "                        credDict[\"groupProperties\"] = Registry.getPropertiesForGroup(diracGroup)",
            "        elif withRegistryInfo:",
            "            retVal = Registry.getHostnameForDN(credDict[\"subject\"])",
            "            if retVal[\"OK\"]:",
            "                credDict[\"group\"] = \"hosts\"",
            "                credDict[\"hostname\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "                credDict[\"validGroup\"] = True",
            "                credDict[\"groupProperties\"] = Registry.getHostOption(credDict[\"hostname\"], \"Properties\")",
            "",
            "            retVal = Registry.getUsernameForDN(credDict[\"subject\"])",
            "            if retVal[\"OK\"]:",
            "                credDict[\"username\"] = retVal[\"Value\"]",
            "                credDict[\"validDN\"] = True",
            "        return S_OK(credDict)",
            "",
            "    @needCertList",
            "    def hash(self):",
            "        \"\"\"Get a hash of the chain",
            "        In practice, this is only used to index the chain in a DictCache",
            "",
            "        :returns: S_OK(string hash)",
            "        \"\"\"",
            "        if self.__hash:",
            "            return S_OK(self.__hash)",
            "        sha1 = hashlib.sha1()",
            "        for cert in self._certList:",
            "            sha1.update(str(cert.getSubjectNameObject()[\"Value\"]).encode())",
            "        sha1.update(str(self.getRemainingSecs()[\"Value\"] / 3600).encode())",
            "        sha1.update(self.getDIRACGroup()[\"Value\"].encode())",
            "        if self.isVOMS():",
            "            sha1.update(b\"VOMS\")",
            "            from DIRAC.Core.Security.VOMS import VOMS",
            "",
            "            result = VOMS().getVOMSAttributes(self)",
            "            if result[\"OK\"]:",
            "                for attribute in result[\"Value\"]:",
            "                    sha1.update(attribute.encode())",
            "        self.__hash = sha1.hexdigest()",
            "        return S_OK(self.__hash)",
            "",
            "",
            "def isPUSPdn(userDN):",
            "    \"\"\"Evaluate if the DN is of the PUSP type or not",
            "",
            "    :param str userDN: user DN string",
            "",
            "    :returns: the subproxy user name or None",
            "    \"\"\"",
            "    lastEntry = userDN.split(\"/\")[-1].split(\"=\")",
            "    if lastEntry[0] == \"CN\" and lastEntry[1].startswith(\"user:\"):",
            "        return userDN.split(\"/\")[-1].split(\":\")[1]",
            "    return None"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "11": [],
            "12": [],
            "13": [],
            "495": [
                "X509Chain",
                "generateProxyToFile"
            ],
            "499": [
                "X509Chain",
                "generateProxyToFile"
            ],
            "500": [
                "X509Chain",
                "generateProxyToFile"
            ],
            "501": [
                "X509Chain",
                "generateProxyToFile"
            ],
            "502": [
                "X509Chain",
                "generateProxyToFile"
            ],
            "883": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "884": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "885": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "886": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "887": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "890": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "891": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "892": [
                "X509Chain",
                "dumpAllToFile"
            ],
            "893": [
                "X509Chain",
                "dumpAllToFile"
            ]
        },
        "addLocation": []
    },
    "src/DIRAC/Core/Utilities/File.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " import sys"
            },
            "1": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " import re"
            },
            "2": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import errno"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+import stat"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+import tempfile"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+from contextlib import contextmanager"
            },
            "6": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " # Translation table of a given unit to Bytes"
            },
            "8": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " # I know, it should be kB..."
            },
            "9": {
                "beforePatchRowNumber": 253,
                "afterPatchRowNumber": 256,
                "PatchRowcode": "         return -sys.maxsize"
            },
            "10": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": 257,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": 258,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+@contextmanager"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+def secureOpenForWrite(filename=None, *, text=True):"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+    \"\"\"Securely open a file for writing."
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+    If filename is not provided, a file is created in tempfile.gettempdir()."
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+    The file always created with mode 600."
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+    :param string filename: name of file to be opened"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 267,
                "PatchRowcode": "+    \"\"\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+    if filename:"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 269,
                "PatchRowcode": "+        fd = os.open("
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 270,
                "PatchRowcode": "+            path=filename,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 271,
                "PatchRowcode": "+            flags=os.O_WRONLY | os.O_CREAT | os.O_TRUNC,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+            mode=stat.S_IRUSR | stat.S_IWUSR,"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+        )"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 274,
                "PatchRowcode": "+    else:"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+        fd, filename = tempfile.mkstemp(text=text)"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+    with open(fd, \"w\" if text else \"wb\", encoding=\"ascii\") as fd:"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+        yield fd"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": 280,
                "PatchRowcode": " if __name__ == \"__main__\":"
            },
            "34": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 281,
                "PatchRowcode": "     for p in sys.argv[1:]:"
            },
            "35": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": 282,
                "PatchRowcode": "         print(f\"{p} : {getGlobbedTotalSize(p)} bytes\")"
            }
        },
        "frontPatchFile": [
            "\"\"\"Collection of DIRAC useful file related modules.",
            "",
            ".. warning::",
            "   By default on Error they return None.",
            "\"\"\"",
            "",
            "import os",
            "import hashlib",
            "import random",
            "import glob",
            "import sys",
            "import re",
            "import errno",
            "",
            "# Translation table of a given unit to Bytes",
            "# I know, it should be kB...",
            "SIZE_UNIT_CONVERSION = {",
            "    \"B\": 1,",
            "    \"KB\": 1024,",
            "    \"MB\": 1024 * 1024,",
            "    \"GB\": 1024 * 1024 * 1024,",
            "    \"TB\": 1024 * 1024 * 1024 * 1024,",
            "    \"PB\": 1024 * 1024 * 1024 * 1024 * 1024,",
            "}",
            "",
            "",
            "def mkDir(path, mode=None):",
            "    \"\"\"Emulate 'mkdir -p path' (if path exists already, don't raise an exception)",
            "",
            "    :param str path: directory hierarchy to create",
            "    :param int mode: Use this mode as the mode for new directories, use python default if None.",
            "    \"\"\"",
            "    try:",
            "        if os.path.isdir(path):",
            "            return",
            "        if mode is None:",
            "            os.makedirs(path)",
            "        else:",
            "            os.makedirs(path, mode)",
            "    except OSError as osError:",
            "        if osError.errno == errno.EEXIST and os.path.isdir(path):",
            "            pass",
            "        else:",
            "            raise",
            "",
            "",
            "def mkLink(src, dst):",
            "    \"\"\"Protected creation of symbolic link\"\"\"",
            "    try:",
            "        os.symlink(src, dst)",
            "    except OSError as osError:",
            "        if osError.errno == errno.EEXIST and os.path.islink(dst) and os.path.realpath(dst) == src:",
            "            pass",
            "        else:",
            "            raise",
            "",
            "",
            "def makeGuid(fileName=None):",
            "    \"\"\"Utility to create GUID. If a filename is provided the",
            "    GUID will correspond to its content's hexadecimal md5 checksum.",
            "    Otherwise a random seed is used to create the GUID.",
            "    The format is capitalized 8-4-4-4-12.",
            "",
            "    .. warning::",
            "       Could return None in case of OSError or IOError.",
            "",
            "    :param string fileName: name of file",
            "    \"\"\"",
            "    myMd5 = hashlib.md5()",
            "    if fileName:",
            "        try:",
            "            with open(fileName, \"rb\") as fd:",
            "                data = fd.read(10 * 1024 * 1024)",
            "                myMd5.update(data)",
            "        except Exception:",
            "            return None",
            "    else:",
            "        myMd5.update(str(random.getrandbits(128)).encode())",
            "",
            "    md5HexString = myMd5.hexdigest().upper()",
            "    return generateGuid(md5HexString, \"MD5\")",
            "",
            "",
            "def generateGuid(checksum, checksumtype):",
            "    \"\"\"Generate a GUID based on the file checksum\"\"\"",
            "",
            "    if checksum:",
            "        if checksumtype == \"MD5\":",
            "            checksumString = checksum",
            "        elif checksumtype == \"Adler32\":",
            "            checksumString = str(checksum).zfill(32)",
            "        else:",
            "            checksumString = \"\"",
            "        if checksumString:",
            "            guid = \"{}-{}-{}-{}-{}\".format(",
            "                checksumString[0:8],",
            "                checksumString[8:12],",
            "                checksumString[12:16],",
            "                checksumString[16:20],",
            "                checksumString[20:32],",
            "            )",
            "            guid = guid.upper()",
            "            return guid",
            "",
            "    # Failed to use the check sum, generate a new guid",
            "    myMd5 = hashlib.md5()",
            "    myMd5.update(str(random.getrandbits(128)).encode())",
            "    md5HexString = myMd5.hexdigest()",
            "    guid = \"{}-{}-{}-{}-{}\".format(",
            "        md5HexString[0:8],",
            "        md5HexString[8:12],",
            "        md5HexString[12:16],",
            "        md5HexString[16:20],",
            "        md5HexString[20:32],",
            "    )",
            "    guid = guid.upper()",
            "    return guid",
            "",
            "",
            "def checkGuid(guid):",
            "    \"\"\"Checks whether a supplied GUID is of the correct format.",
            "    The guid is a string of 36 characters [0-9A-F] long split into 5 parts of length 8-4-4-4-12.",
            "",
            "    .. warning::",
            "       As we are using GUID produced by various services and some of them could not follow",
            "       convention, this function is passing by a guid which can be made of lower case chars or even just",
            "       have 5 parts of proper length with whatever chars.",
            "",
            "    :param string guid: string to be checked",
            "    :return: True (False) if supplied string is (not) a valid GUID.",
            "    \"\"\"",
            "    reGUID = re.compile(\"^[0-9A-F]{8}(-[0-9A-F]{4}){3}-[0-9A-F]{12}$\")",
            "    if reGUID.match(guid.upper()):",
            "        return True",
            "    else:",
            "        guid = [len(x) for x in guid.split(\"-\")]",
            "        if guid == [8, 4, 4, 4, 12]:",
            "            return True",
            "    return False",
            "",
            "",
            "def getSize(fileName: os.PathLike) -> int:",
            "    \"\"\"Get size of a file.",
            "",
            "    :param string fileName: name of file to be checked",
            "",
            "    The os module claims only OSError can be thrown,",
            "    but just for curiosity it's catching all possible exceptions.",
            "",
            "    .. warning::",
            "       On any exception it returns -1.",
            "",
            "    \"\"\"",
            "    try:",
            "        return os.stat(fileName)[6]",
            "    except OSError:",
            "        return -1",
            "",
            "",
            "def getGlobbedTotalSize(files):",
            "    \"\"\"Get total size of a list of files or a single file.",
            "    Globs the parameter to allow regular expressions.",
            "",
            "    :params list files: list or tuple of strings of files",
            "    \"\"\"",
            "    totalSize = 0",
            "    if isinstance(files, (list, tuple)):",
            "        for entry in files:",
            "            size = getGlobbedTotalSize(entry)",
            "            if size == -1:",
            "                size = 0",
            "            totalSize += size",
            "    else:",
            "        for path in glob.glob(files):",
            "            if os.path.isdir(path) and not os.path.islink(path):",
            "                for content in os.listdir(path):",
            "                    totalSize += getGlobbedTotalSize(os.path.join(path, content))",
            "            if os.path.isfile(path):",
            "                size = getSize(path)",
            "                if size == -1:",
            "                    size = 0",
            "                totalSize += size",
            "    return totalSize",
            "",
            "",
            "def getGlobbedFiles(files):",
            "    \"\"\"Get list of files or a single file.",
            "    Globs the parameter to allow regular expressions.",
            "",
            "    :params list files: list or tuple of strings of files",
            "    \"\"\"",
            "    globbedFiles = []",
            "    if isinstance(files, (list, tuple)):",
            "        for entry in files:",
            "            globbedFiles += getGlobbedFiles(entry)",
            "    else:",
            "        for path in glob.glob(files):",
            "            if os.path.isdir(path) and not os.path.islink(path):",
            "                for content in os.listdir(path):",
            "                    globbedFiles += getGlobbedFiles(os.path.join(path, content))",
            "            if os.path.isfile(path):",
            "                globbedFiles.append(path)",
            "    return globbedFiles",
            "",
            "",
            "def getMD5ForFiles(fileList):",
            "    \"\"\"Calculate md5 for the content of all the files.",
            "",
            "    :param fileList: list of paths",
            "    :type fileList: python:list",
            "    \"\"\"",
            "    fileList.sort()",
            "    hashMD5 = hashlib.md5()",
            "    for filePath in fileList:",
            "        if os.path.isdir(filePath):",
            "            continue",
            "        with open(filePath, \"rb\") as fd:",
            "            buf = fd.read(4096)",
            "            while buf:",
            "                hashMD5.update(buf)",
            "                buf = fd.read(4096)",
            "    return hashMD5.hexdigest()",
            "",
            "",
            "def convertSizeUnits(size, srcUnit, dstUnit):",
            "    \"\"\"Converts a number from a given source unit to a destination unit.",
            "",
            "    Example:",
            "      In [1]: convertSizeUnits(1024, 'B', 'kB')",
            "      Out[1]: 1",
            "",
            "      In [2]: convertSizeUnits(1024, 'MB', 'kB')",
            "      Out[2]: 1048576",
            "",
            "",
            "    :param size: number to convert",
            "    :param srcUnit: unit of the number. Any of ( 'B', 'kB', 'MB', 'GB', 'TB', 'PB')",
            "    :param dstUnit: unit expected for the return. Any of ( 'B', 'kB', 'MB', 'GB', 'TB', 'PB')",
            "",
            "    :returns: the size number converted in the dstUnit. In case of problem -sys.maxint is returned (negative)",
            "    \"\"\"",
            "",
            "    srcUnit = srcUnit.upper()",
            "    dstUnit = dstUnit.upper()",
            "",
            "    try:",
            "        convertedValue = float(size) * SIZE_UNIT_CONVERSION[srcUnit] / SIZE_UNIT_CONVERSION[dstUnit]",
            "        return convertedValue",
            "",
            "    # TypeError, ValueError: size is not a number",
            "    # KeyError: srcUnit or dstUnit are not in the conversion list",
            "    except (TypeError, ValueError, KeyError):",
            "        return -sys.maxsize",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    for p in sys.argv[1:]:",
            "        print(f\"{p} : {getGlobbedTotalSize(p)} bytes\")"
        ],
        "afterPatchFile": [
            "\"\"\"Collection of DIRAC useful file related modules.",
            "",
            ".. warning::",
            "   By default on Error they return None.",
            "\"\"\"",
            "",
            "import os",
            "import hashlib",
            "import random",
            "import glob",
            "import sys",
            "import re",
            "import errno",
            "import stat",
            "import tempfile",
            "from contextlib import contextmanager",
            "",
            "# Translation table of a given unit to Bytes",
            "# I know, it should be kB...",
            "SIZE_UNIT_CONVERSION = {",
            "    \"B\": 1,",
            "    \"KB\": 1024,",
            "    \"MB\": 1024 * 1024,",
            "    \"GB\": 1024 * 1024 * 1024,",
            "    \"TB\": 1024 * 1024 * 1024 * 1024,",
            "    \"PB\": 1024 * 1024 * 1024 * 1024 * 1024,",
            "}",
            "",
            "",
            "def mkDir(path, mode=None):",
            "    \"\"\"Emulate 'mkdir -p path' (if path exists already, don't raise an exception)",
            "",
            "    :param str path: directory hierarchy to create",
            "    :param int mode: Use this mode as the mode for new directories, use python default if None.",
            "    \"\"\"",
            "    try:",
            "        if os.path.isdir(path):",
            "            return",
            "        if mode is None:",
            "            os.makedirs(path)",
            "        else:",
            "            os.makedirs(path, mode)",
            "    except OSError as osError:",
            "        if osError.errno == errno.EEXIST and os.path.isdir(path):",
            "            pass",
            "        else:",
            "            raise",
            "",
            "",
            "def mkLink(src, dst):",
            "    \"\"\"Protected creation of symbolic link\"\"\"",
            "    try:",
            "        os.symlink(src, dst)",
            "    except OSError as osError:",
            "        if osError.errno == errno.EEXIST and os.path.islink(dst) and os.path.realpath(dst) == src:",
            "            pass",
            "        else:",
            "            raise",
            "",
            "",
            "def makeGuid(fileName=None):",
            "    \"\"\"Utility to create GUID. If a filename is provided the",
            "    GUID will correspond to its content's hexadecimal md5 checksum.",
            "    Otherwise a random seed is used to create the GUID.",
            "    The format is capitalized 8-4-4-4-12.",
            "",
            "    .. warning::",
            "       Could return None in case of OSError or IOError.",
            "",
            "    :param string fileName: name of file",
            "    \"\"\"",
            "    myMd5 = hashlib.md5()",
            "    if fileName:",
            "        try:",
            "            with open(fileName, \"rb\") as fd:",
            "                data = fd.read(10 * 1024 * 1024)",
            "                myMd5.update(data)",
            "        except Exception:",
            "            return None",
            "    else:",
            "        myMd5.update(str(random.getrandbits(128)).encode())",
            "",
            "    md5HexString = myMd5.hexdigest().upper()",
            "    return generateGuid(md5HexString, \"MD5\")",
            "",
            "",
            "def generateGuid(checksum, checksumtype):",
            "    \"\"\"Generate a GUID based on the file checksum\"\"\"",
            "",
            "    if checksum:",
            "        if checksumtype == \"MD5\":",
            "            checksumString = checksum",
            "        elif checksumtype == \"Adler32\":",
            "            checksumString = str(checksum).zfill(32)",
            "        else:",
            "            checksumString = \"\"",
            "        if checksumString:",
            "            guid = \"{}-{}-{}-{}-{}\".format(",
            "                checksumString[0:8],",
            "                checksumString[8:12],",
            "                checksumString[12:16],",
            "                checksumString[16:20],",
            "                checksumString[20:32],",
            "            )",
            "            guid = guid.upper()",
            "            return guid",
            "",
            "    # Failed to use the check sum, generate a new guid",
            "    myMd5 = hashlib.md5()",
            "    myMd5.update(str(random.getrandbits(128)).encode())",
            "    md5HexString = myMd5.hexdigest()",
            "    guid = \"{}-{}-{}-{}-{}\".format(",
            "        md5HexString[0:8],",
            "        md5HexString[8:12],",
            "        md5HexString[12:16],",
            "        md5HexString[16:20],",
            "        md5HexString[20:32],",
            "    )",
            "    guid = guid.upper()",
            "    return guid",
            "",
            "",
            "def checkGuid(guid):",
            "    \"\"\"Checks whether a supplied GUID is of the correct format.",
            "    The guid is a string of 36 characters [0-9A-F] long split into 5 parts of length 8-4-4-4-12.",
            "",
            "    .. warning::",
            "       As we are using GUID produced by various services and some of them could not follow",
            "       convention, this function is passing by a guid which can be made of lower case chars or even just",
            "       have 5 parts of proper length with whatever chars.",
            "",
            "    :param string guid: string to be checked",
            "    :return: True (False) if supplied string is (not) a valid GUID.",
            "    \"\"\"",
            "    reGUID = re.compile(\"^[0-9A-F]{8}(-[0-9A-F]{4}){3}-[0-9A-F]{12}$\")",
            "    if reGUID.match(guid.upper()):",
            "        return True",
            "    else:",
            "        guid = [len(x) for x in guid.split(\"-\")]",
            "        if guid == [8, 4, 4, 4, 12]:",
            "            return True",
            "    return False",
            "",
            "",
            "def getSize(fileName: os.PathLike) -> int:",
            "    \"\"\"Get size of a file.",
            "",
            "    :param string fileName: name of file to be checked",
            "",
            "    The os module claims only OSError can be thrown,",
            "    but just for curiosity it's catching all possible exceptions.",
            "",
            "    .. warning::",
            "       On any exception it returns -1.",
            "",
            "    \"\"\"",
            "    try:",
            "        return os.stat(fileName)[6]",
            "    except OSError:",
            "        return -1",
            "",
            "",
            "def getGlobbedTotalSize(files):",
            "    \"\"\"Get total size of a list of files or a single file.",
            "    Globs the parameter to allow regular expressions.",
            "",
            "    :params list files: list or tuple of strings of files",
            "    \"\"\"",
            "    totalSize = 0",
            "    if isinstance(files, (list, tuple)):",
            "        for entry in files:",
            "            size = getGlobbedTotalSize(entry)",
            "            if size == -1:",
            "                size = 0",
            "            totalSize += size",
            "    else:",
            "        for path in glob.glob(files):",
            "            if os.path.isdir(path) and not os.path.islink(path):",
            "                for content in os.listdir(path):",
            "                    totalSize += getGlobbedTotalSize(os.path.join(path, content))",
            "            if os.path.isfile(path):",
            "                size = getSize(path)",
            "                if size == -1:",
            "                    size = 0",
            "                totalSize += size",
            "    return totalSize",
            "",
            "",
            "def getGlobbedFiles(files):",
            "    \"\"\"Get list of files or a single file.",
            "    Globs the parameter to allow regular expressions.",
            "",
            "    :params list files: list or tuple of strings of files",
            "    \"\"\"",
            "    globbedFiles = []",
            "    if isinstance(files, (list, tuple)):",
            "        for entry in files:",
            "            globbedFiles += getGlobbedFiles(entry)",
            "    else:",
            "        for path in glob.glob(files):",
            "            if os.path.isdir(path) and not os.path.islink(path):",
            "                for content in os.listdir(path):",
            "                    globbedFiles += getGlobbedFiles(os.path.join(path, content))",
            "            if os.path.isfile(path):",
            "                globbedFiles.append(path)",
            "    return globbedFiles",
            "",
            "",
            "def getMD5ForFiles(fileList):",
            "    \"\"\"Calculate md5 for the content of all the files.",
            "",
            "    :param fileList: list of paths",
            "    :type fileList: python:list",
            "    \"\"\"",
            "    fileList.sort()",
            "    hashMD5 = hashlib.md5()",
            "    for filePath in fileList:",
            "        if os.path.isdir(filePath):",
            "            continue",
            "        with open(filePath, \"rb\") as fd:",
            "            buf = fd.read(4096)",
            "            while buf:",
            "                hashMD5.update(buf)",
            "                buf = fd.read(4096)",
            "    return hashMD5.hexdigest()",
            "",
            "",
            "def convertSizeUnits(size, srcUnit, dstUnit):",
            "    \"\"\"Converts a number from a given source unit to a destination unit.",
            "",
            "    Example:",
            "      In [1]: convertSizeUnits(1024, 'B', 'kB')",
            "      Out[1]: 1",
            "",
            "      In [2]: convertSizeUnits(1024, 'MB', 'kB')",
            "      Out[2]: 1048576",
            "",
            "",
            "    :param size: number to convert",
            "    :param srcUnit: unit of the number. Any of ( 'B', 'kB', 'MB', 'GB', 'TB', 'PB')",
            "    :param dstUnit: unit expected for the return. Any of ( 'B', 'kB', 'MB', 'GB', 'TB', 'PB')",
            "",
            "    :returns: the size number converted in the dstUnit. In case of problem -sys.maxint is returned (negative)",
            "    \"\"\"",
            "",
            "    srcUnit = srcUnit.upper()",
            "    dstUnit = dstUnit.upper()",
            "",
            "    try:",
            "        convertedValue = float(size) * SIZE_UNIT_CONVERSION[srcUnit] / SIZE_UNIT_CONVERSION[dstUnit]",
            "        return convertedValue",
            "",
            "    # TypeError, ValueError: size is not a number",
            "    # KeyError: srcUnit or dstUnit are not in the conversion list",
            "    except (TypeError, ValueError, KeyError):",
            "        return -sys.maxsize",
            "",
            "",
            "@contextmanager",
            "def secureOpenForWrite(filename=None, *, text=True):",
            "    \"\"\"Securely open a file for writing.",
            "",
            "    If filename is not provided, a file is created in tempfile.gettempdir().",
            "    The file always created with mode 600.",
            "",
            "    :param string filename: name of file to be opened",
            "    \"\"\"",
            "    if filename:",
            "        fd = os.open(",
            "            path=filename,",
            "            flags=os.O_WRONLY | os.O_CREAT | os.O_TRUNC,",
            "            mode=stat.S_IRUSR | stat.S_IWUSR,",
            "        )",
            "    else:",
            "        fd, filename = tempfile.mkstemp(text=text)",
            "    with open(fd, \"w\" if text else \"wb\", encoding=\"ascii\") as fd:",
            "        yield fd",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    for p in sys.argv[1:]:",
            "        print(f\"{p} : {getGlobbedTotalSize(p)} bytes\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "src/DIRAC/FrameworkSystem/private/authorization/utils/Tokens.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import os"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import re"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import jwt"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import stat"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import time"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import json"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " import datetime"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from DIRAC import S_OK, S_ERROR"
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from DIRAC.Core.Utilities import DErrno"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from DIRAC.Core.Utilities.File import secureOpenForWrite"
            },
            "11": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from DIRAC.ConfigurationSystem.Client.Helpers import Registry"
            },
            "12": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from DIRAC.Resources.IdProvider.IdProviderFactory import IdProviderFactory"
            },
            "13": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "     \"\"\""
            },
            "15": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "     location = getTokenFileLocation(fileName)"
            },
            "16": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "     try:"
            },
            "17": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        with open(location, \"w\") as fd:"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+        with secureOpenForWrite(location) as fd:"
            },
            "19": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "             fd.write(tokenContents)"
            },
            "20": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "     except Exception as e:"
            },
            "21": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "         return S_ERROR(DErrno.EWF, f\" {location}: {repr(e)}\")"
            },
            "22": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    try:"
            },
            "23": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        os.chmod(location, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "24": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    except Exception as e:"
            },
            "25": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return S_ERROR(DErrno.ESPF, f\"{location}: {repr(e)}\")"
            },
            "26": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "     return S_OK(location)"
            },
            "27": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 91,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 92,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "import os",
            "import re",
            "import jwt",
            "import stat",
            "import time",
            "import json",
            "import datetime",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.ConfigurationSystem.Client.Helpers import Registry",
            "from DIRAC.Resources.IdProvider.IdProviderFactory import IdProviderFactory",
            "",
            "from authlib.oauth2.rfc6749.util import scope_to_list",
            "from authlib.oauth2.rfc6749.wrappers import OAuth2Token as _OAuth2Token",
            "",
            "BEARER_TOKEN_ENV = \"BEARER_TOKEN\"",
            "BEARER_TOKEN_FILE_ENV = \"BEARER_TOKEN_FILE\"",
            "",
            "",
            "def getTokenFileLocation(fileName=None):",
            "    \"\"\"Research token file location. Use the bearer token discovery protocol",
            "    defined by the WLCG (https://doi.org/10.5281/zenodo.3937438) to find one.",
            "",
            "    :param str fileName: file name to dump to",
            "",
            "    :return: str",
            "    \"\"\"",
            "    if fileName:",
            "        return fileName",
            "    if os.environ.get(BEARER_TOKEN_FILE_ENV):",
            "        return os.environ[BEARER_TOKEN_FILE_ENV]",
            "    elif os.environ.get(\"XDG_RUNTIME_DIR\"):",
            "        return f\"{os.environ['XDG_RUNTIME_DIR']}/bt_u{os.getuid()}\"",
            "    else:",
            "        return f\"/tmp/bt_u{os.getuid()}\"",
            "",
            "",
            "def getLocalTokenDict(location=None):",
            "    \"\"\"Search local token. Use the bearer token discovery protocol",
            "    defined by the WLCG (https://doi.org/10.5281/zenodo.3937438) to find one.",
            "",
            "    :param str location: token file path",
            "",
            "    :return: S_OK(dict)/S_ERROR()",
            "    \"\"\"",
            "    result = readTokenFromEnv()",
            "    return result if result[\"OK\"] and result[\"Value\"] else readTokenFromFile(location)",
            "",
            "",
            "def readTokenFromEnv():",
            "    \"\"\"Read token from an environ variable",
            "",
            "    :return: S_OK(dict or None)",
            "    \"\"\"",
            "    token = os.environ.get(BEARER_TOKEN_ENV, \"\").strip()",
            "    return S_OK(OAuth2Token(token) if token else None)",
            "",
            "",
            "def readTokenFromFile(fileName=None):",
            "    \"\"\"Read token from a file",
            "",
            "    :param str fileName: filename to read",
            "",
            "    :return: S_OK(dict or None)/S_ERROR()",
            "    \"\"\"",
            "    location = getTokenFileLocation(fileName)",
            "    try:",
            "        with open(location) as f:",
            "            token = f.read().strip()",
            "    except OSError as e:",
            "        return S_ERROR(DErrno.EOF, f\"Can't open {location} token file.\\n{repr(e)}\")",
            "    return S_OK(OAuth2Token(token) if token else None)",
            "",
            "",
            "def writeToTokenFile(tokenContents, fileName):",
            "    \"\"\"Write a token string to file",
            "",
            "    :param str tokenContents: token as string",
            "    :param str fileName: filename to dump to",
            "",
            "    :return: S_OK(str)/S_ERROR()",
            "    \"\"\"",
            "    location = getTokenFileLocation(fileName)",
            "    try:",
            "        with open(location, \"w\") as fd:",
            "            fd.write(tokenContents)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.EWF, f\" {location}: {repr(e)}\")",
            "    try:",
            "        os.chmod(location, stat.S_IRUSR | stat.S_IWUSR)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.ESPF, f\"{location}: {repr(e)}\")",
            "    return S_OK(location)",
            "",
            "",
            "def writeTokenDictToTokenFile(tokenDict, fileName=None):",
            "    \"\"\"Write a token dict to file",
            "",
            "    :param dict tokenDict: dict object to dump to file",
            "    :param str fileName: filename to dump to",
            "",
            "    :return: S_OK(str)/S_ERROR()",
            "    \"\"\"",
            "    fileName = getTokenFileLocation(fileName)",
            "    if not isinstance(tokenDict, dict):",
            "        return S_ERROR(\"Token is not a dictionary\")",
            "    return writeToTokenFile(json.dumps(tokenDict), fileName)",
            "",
            "",
            "class OAuth2Token(_OAuth2Token):",
            "    \"\"\"Implementation of a Token object\"\"\"",
            "",
            "    def __init__(self, params=None, **kwargs):",
            "        \"\"\"Constructor\"\"\"",
            "        if isinstance(params, bytes):",
            "            params = params.decode()",
            "        if isinstance(params, str):",
            "            # Is params a JWT?",
            "            params = params.strip()",
            "            if re.match(r\"^[A-Za-z0-9-_=]+\\.[A-Za-z0-9-_=]+\\.?[A-Za-z0-9-_.+/=]*$\", params):",
            "                params = dict(access_token=params)",
            "            else:",
            "                params = json.loads(params)",
            "",
            "        kwargs.update(params or {})",
            "        kwargs[\"issued_at\"] = kwargs.get(\"issued_at\", kwargs.get(\"iat\"))",
            "        kwargs[\"expires_at\"] = kwargs.get(\"expires_at\", kwargs.get(\"exp\"))",
            "        if not kwargs.get(\"expires_at\") and kwargs.get(\"access_token\"):",
            "            # Get access token expires_at claim",
            "            kwargs[\"expires_at\"] = self.get_claim(\"exp\")",
            "        super().__init__(kwargs)",
            "",
            "    def check_client(self, client):",
            "        \"\"\"A method to check if this token is issued to the given client.",
            "",
            "        :param client: client object",
            "",
            "        :return: bool",
            "        \"\"\"",
            "        return self.get(\"client_id\", self.get(\"azp\")) == client.client_id",
            "",
            "    def get_scope(self):",
            "        \"\"\"A method to get scope of the authorization code.",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return self.get(\"scope\")",
            "",
            "    def get_expires_in(self) -> int:",
            "        \"\"\"A method to get the ``expires_in`` value of the token.",
            "",
            "        :return: seconds",
            "        \"\"\"",
            "        return int(self.get(\"expires_in\"))",
            "",
            "    def is_expired(self, timeLeft: int = 0):",
            "        \"\"\"A method to define if this token is expired.",
            "",
            "        :param timeLeft: extra time in seconds",
            "",
            "        :return: bool",
            "        \"\"\"",
            "        time_point = time.time() + timeLeft",
            "        if self.get(\"expires_at\"):",
            "            return int(self.get(\"expires_at\")) < time_point",
            "        elif self.get(\"issued_at\") and self.get(\"expires_in\"):",
            "            return int(self.get(\"issued_at\")) + int(self.get(\"expires_in\")) < time_point",
            "        else:",
            "            exp = self.get_payload().get(\"exp\")",
            "            return int(exp) < time_point if exp else True",
            "",
            "    @property",
            "    def scopes(self):",
            "        \"\"\"Get tokens scopes",
            "",
            "        :return: list",
            "        \"\"\"",
            "        return scope_to_list(self.get(\"scope\", \"\"))",
            "",
            "    @property",
            "    def groups(self):",
            "        \"\"\"Get tokens groups",
            "",
            "        :return: list",
            "        \"\"\"",
            "        return [s.split(\":\")[1] for s in self.scopes if s.startswith(\"g:\") and s.split(\":\")[1]]",
            "",
            "    def get_payload(self, token_type=\"access_token\"):",
            "        \"\"\"Decode token",
            "",
            "        :param str token_type: token type",
            "",
            "        :return: dict",
            "        \"\"\"",
            "        if not self.get(token_type):",
            "            return {}",
            "        return jwt.decode(",
            "            self.get(token_type),",
            "            options=dict(verify_signature=False, verify_exp=False, verify_aud=False, verify_nbf=False),",
            "        )",
            "",
            "    def get_claim(self, claim, token_type=\"access_token\"):",
            "        \"\"\"Get token claim without verification",
            "",
            "        :param str attr: attribute",
            "        :param str token_type: token type",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return self.get_payload(token_type).get(claim)",
            "",
            "    def dump_to_string(self):",
            "        \"\"\"Dump token dictionary to sting",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return json.dumps(dict(self))",
            "",
            "    def getInfoAsString(self):",
            "        \"\"\"Return information about token as string",
            "",
            "        :return: str",
            "        \"\"\"",
            "        result = IdProviderFactory().getIdProviderFromToken(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return f\"Cannot load provider: {result['Message']}\"",
            "        cli = result[\"Value\"]",
            "        result = cli.verifyToken(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        payload = result[\"Value\"]",
            "        result = cli.getUserGroups(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        credDict = result[\"Value\"]",
            "        result = Registry.getUsernameForDN(credDict[\"DN\"])",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        credDict[\"username\"] = result[\"Value\"]",
            "        if credDict.get(\"group\"):",
            "            credDict[\"properties\"] = Registry.getPropertiesForGroup(credDict[\"group\"])",
            "        payload.update(credDict)",
            "        return self.__formatTokenInfoAsString(payload)",
            "",
            "    def __formatTokenInfoAsString(self, infoDict):",
            "        \"\"\"Convert a token infoDict into a string",
            "",
            "        :param dict infoDict: info",
            "",
            "        :return: str",
            "        \"\"\"",
            "        secsLeft = int(infoDict[\"exp\"]) - time.time()",
            "        strTimeleft = datetime.datetime.fromtimestamp(secsLeft).strftime(\"%I:%M:%S\")",
            "        leftAlign = 13",
            "        contentList = []",
            "        contentList.append(f\"{'subject'.ljust(leftAlign)}: {infoDict['sub']}\")",
            "        contentList.append(f\"{'issuer'.ljust(leftAlign)}: {infoDict['iss']}\")",
            "        contentList.append(f\"{'timeleft'.ljust(leftAlign)}: {strTimeleft}\")",
            "        contentList.append(f\"{'username'.ljust(leftAlign)}: {infoDict['username']}\")",
            "        if infoDict.get(\"group\"):",
            "            contentList.append(f\"{'DIRAC group'.ljust(leftAlign)}: {infoDict['group']}\")",
            "        if infoDict.get(\"properties\"):",
            "            contentList.append(f\"{'properties'.ljust(leftAlign)}: {', '.join(infoDict['properties'])}\")",
            "        return \"\\n\".join(contentList)"
        ],
        "afterPatchFile": [
            "import os",
            "import re",
            "import jwt",
            "import time",
            "import json",
            "import datetime",
            "",
            "from DIRAC import S_OK, S_ERROR",
            "from DIRAC.Core.Utilities import DErrno",
            "from DIRAC.Core.Utilities.File import secureOpenForWrite",
            "from DIRAC.ConfigurationSystem.Client.Helpers import Registry",
            "from DIRAC.Resources.IdProvider.IdProviderFactory import IdProviderFactory",
            "",
            "from authlib.oauth2.rfc6749.util import scope_to_list",
            "from authlib.oauth2.rfc6749.wrappers import OAuth2Token as _OAuth2Token",
            "",
            "BEARER_TOKEN_ENV = \"BEARER_TOKEN\"",
            "BEARER_TOKEN_FILE_ENV = \"BEARER_TOKEN_FILE\"",
            "",
            "",
            "def getTokenFileLocation(fileName=None):",
            "    \"\"\"Research token file location. Use the bearer token discovery protocol",
            "    defined by the WLCG (https://doi.org/10.5281/zenodo.3937438) to find one.",
            "",
            "    :param str fileName: file name to dump to",
            "",
            "    :return: str",
            "    \"\"\"",
            "    if fileName:",
            "        return fileName",
            "    if os.environ.get(BEARER_TOKEN_FILE_ENV):",
            "        return os.environ[BEARER_TOKEN_FILE_ENV]",
            "    elif os.environ.get(\"XDG_RUNTIME_DIR\"):",
            "        return f\"{os.environ['XDG_RUNTIME_DIR']}/bt_u{os.getuid()}\"",
            "    else:",
            "        return f\"/tmp/bt_u{os.getuid()}\"",
            "",
            "",
            "def getLocalTokenDict(location=None):",
            "    \"\"\"Search local token. Use the bearer token discovery protocol",
            "    defined by the WLCG (https://doi.org/10.5281/zenodo.3937438) to find one.",
            "",
            "    :param str location: token file path",
            "",
            "    :return: S_OK(dict)/S_ERROR()",
            "    \"\"\"",
            "    result = readTokenFromEnv()",
            "    return result if result[\"OK\"] and result[\"Value\"] else readTokenFromFile(location)",
            "",
            "",
            "def readTokenFromEnv():",
            "    \"\"\"Read token from an environ variable",
            "",
            "    :return: S_OK(dict or None)",
            "    \"\"\"",
            "    token = os.environ.get(BEARER_TOKEN_ENV, \"\").strip()",
            "    return S_OK(OAuth2Token(token) if token else None)",
            "",
            "",
            "def readTokenFromFile(fileName=None):",
            "    \"\"\"Read token from a file",
            "",
            "    :param str fileName: filename to read",
            "",
            "    :return: S_OK(dict or None)/S_ERROR()",
            "    \"\"\"",
            "    location = getTokenFileLocation(fileName)",
            "    try:",
            "        with open(location) as f:",
            "            token = f.read().strip()",
            "    except OSError as e:",
            "        return S_ERROR(DErrno.EOF, f\"Can't open {location} token file.\\n{repr(e)}\")",
            "    return S_OK(OAuth2Token(token) if token else None)",
            "",
            "",
            "def writeToTokenFile(tokenContents, fileName):",
            "    \"\"\"Write a token string to file",
            "",
            "    :param str tokenContents: token as string",
            "    :param str fileName: filename to dump to",
            "",
            "    :return: S_OK(str)/S_ERROR()",
            "    \"\"\"",
            "    location = getTokenFileLocation(fileName)",
            "    try:",
            "        with secureOpenForWrite(location) as fd:",
            "            fd.write(tokenContents)",
            "    except Exception as e:",
            "        return S_ERROR(DErrno.EWF, f\" {location}: {repr(e)}\")",
            "    return S_OK(location)",
            "",
            "",
            "def writeTokenDictToTokenFile(tokenDict, fileName=None):",
            "    \"\"\"Write a token dict to file",
            "",
            "    :param dict tokenDict: dict object to dump to file",
            "    :param str fileName: filename to dump to",
            "",
            "    :return: S_OK(str)/S_ERROR()",
            "    \"\"\"",
            "    fileName = getTokenFileLocation(fileName)",
            "    if not isinstance(tokenDict, dict):",
            "        return S_ERROR(\"Token is not a dictionary\")",
            "    return writeToTokenFile(json.dumps(tokenDict), fileName)",
            "",
            "",
            "class OAuth2Token(_OAuth2Token):",
            "    \"\"\"Implementation of a Token object\"\"\"",
            "",
            "    def __init__(self, params=None, **kwargs):",
            "        \"\"\"Constructor\"\"\"",
            "        if isinstance(params, bytes):",
            "            params = params.decode()",
            "        if isinstance(params, str):",
            "            # Is params a JWT?",
            "            params = params.strip()",
            "            if re.match(r\"^[A-Za-z0-9-_=]+\\.[A-Za-z0-9-_=]+\\.?[A-Za-z0-9-_.+/=]*$\", params):",
            "                params = dict(access_token=params)",
            "            else:",
            "                params = json.loads(params)",
            "",
            "        kwargs.update(params or {})",
            "        kwargs[\"issued_at\"] = kwargs.get(\"issued_at\", kwargs.get(\"iat\"))",
            "        kwargs[\"expires_at\"] = kwargs.get(\"expires_at\", kwargs.get(\"exp\"))",
            "        if not kwargs.get(\"expires_at\") and kwargs.get(\"access_token\"):",
            "            # Get access token expires_at claim",
            "            kwargs[\"expires_at\"] = self.get_claim(\"exp\")",
            "        super().__init__(kwargs)",
            "",
            "    def check_client(self, client):",
            "        \"\"\"A method to check if this token is issued to the given client.",
            "",
            "        :param client: client object",
            "",
            "        :return: bool",
            "        \"\"\"",
            "        return self.get(\"client_id\", self.get(\"azp\")) == client.client_id",
            "",
            "    def get_scope(self):",
            "        \"\"\"A method to get scope of the authorization code.",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return self.get(\"scope\")",
            "",
            "    def get_expires_in(self) -> int:",
            "        \"\"\"A method to get the ``expires_in`` value of the token.",
            "",
            "        :return: seconds",
            "        \"\"\"",
            "        return int(self.get(\"expires_in\"))",
            "",
            "    def is_expired(self, timeLeft: int = 0):",
            "        \"\"\"A method to define if this token is expired.",
            "",
            "        :param timeLeft: extra time in seconds",
            "",
            "        :return: bool",
            "        \"\"\"",
            "        time_point = time.time() + timeLeft",
            "        if self.get(\"expires_at\"):",
            "            return int(self.get(\"expires_at\")) < time_point",
            "        elif self.get(\"issued_at\") and self.get(\"expires_in\"):",
            "            return int(self.get(\"issued_at\")) + int(self.get(\"expires_in\")) < time_point",
            "        else:",
            "            exp = self.get_payload().get(\"exp\")",
            "            return int(exp) < time_point if exp else True",
            "",
            "    @property",
            "    def scopes(self):",
            "        \"\"\"Get tokens scopes",
            "",
            "        :return: list",
            "        \"\"\"",
            "        return scope_to_list(self.get(\"scope\", \"\"))",
            "",
            "    @property",
            "    def groups(self):",
            "        \"\"\"Get tokens groups",
            "",
            "        :return: list",
            "        \"\"\"",
            "        return [s.split(\":\")[1] for s in self.scopes if s.startswith(\"g:\") and s.split(\":\")[1]]",
            "",
            "    def get_payload(self, token_type=\"access_token\"):",
            "        \"\"\"Decode token",
            "",
            "        :param str token_type: token type",
            "",
            "        :return: dict",
            "        \"\"\"",
            "        if not self.get(token_type):",
            "            return {}",
            "        return jwt.decode(",
            "            self.get(token_type),",
            "            options=dict(verify_signature=False, verify_exp=False, verify_aud=False, verify_nbf=False),",
            "        )",
            "",
            "    def get_claim(self, claim, token_type=\"access_token\"):",
            "        \"\"\"Get token claim without verification",
            "",
            "        :param str attr: attribute",
            "        :param str token_type: token type",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return self.get_payload(token_type).get(claim)",
            "",
            "    def dump_to_string(self):",
            "        \"\"\"Dump token dictionary to sting",
            "",
            "        :return: str",
            "        \"\"\"",
            "        return json.dumps(dict(self))",
            "",
            "    def getInfoAsString(self):",
            "        \"\"\"Return information about token as string",
            "",
            "        :return: str",
            "        \"\"\"",
            "        result = IdProviderFactory().getIdProviderFromToken(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return f\"Cannot load provider: {result['Message']}\"",
            "        cli = result[\"Value\"]",
            "        result = cli.verifyToken(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        payload = result[\"Value\"]",
            "        result = cli.getUserGroups(self.get(\"access_token\"))",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        credDict = result[\"Value\"]",
            "        result = Registry.getUsernameForDN(credDict[\"DN\"])",
            "        if not result[\"OK\"]:",
            "            return result[\"Message\"]",
            "        credDict[\"username\"] = result[\"Value\"]",
            "        if credDict.get(\"group\"):",
            "            credDict[\"properties\"] = Registry.getPropertiesForGroup(credDict[\"group\"])",
            "        payload.update(credDict)",
            "        return self.__formatTokenInfoAsString(payload)",
            "",
            "    def __formatTokenInfoAsString(self, infoDict):",
            "        \"\"\"Convert a token infoDict into a string",
            "",
            "        :param dict infoDict: info",
            "",
            "        :return: str",
            "        \"\"\"",
            "        secsLeft = int(infoDict[\"exp\"]) - time.time()",
            "        strTimeleft = datetime.datetime.fromtimestamp(secsLeft).strftime(\"%I:%M:%S\")",
            "        leftAlign = 13",
            "        contentList = []",
            "        contentList.append(f\"{'subject'.ljust(leftAlign)}: {infoDict['sub']}\")",
            "        contentList.append(f\"{'issuer'.ljust(leftAlign)}: {infoDict['iss']}\")",
            "        contentList.append(f\"{'timeleft'.ljust(leftAlign)}: {strTimeleft}\")",
            "        contentList.append(f\"{'username'.ljust(leftAlign)}: {infoDict['username']}\")",
            "        if infoDict.get(\"group\"):",
            "            contentList.append(f\"{'DIRAC group'.ljust(leftAlign)}: {infoDict['group']}\")",
            "        if infoDict.get(\"properties\"):",
            "            contentList.append(f\"{'properties'.ljust(leftAlign)}: {', '.join(infoDict['properties'])}\")",
            "        return \"\\n\".join(contentList)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "4": [],
            "86": [
                "writeToTokenFile"
            ],
            "90": [
                "writeToTokenFile"
            ],
            "91": [
                "writeToTokenFile"
            ],
            "92": [
                "writeToTokenFile"
            ],
            "93": [
                "writeToTokenFile"
            ]
        },
        "addLocation": []
    },
    "src/DIRAC/Interfaces/Utilities/DConfigCache.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " #!/usr/bin/env python"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import os"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import re"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import stat"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import time"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import pickle"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " import tempfile"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from DIRAC.Core.Base.Script import Script"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+from DIRAC.Core.Utilities.File import secureOpenForWrite"
            },
            "10": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from DIRAC.ConfigurationSystem.Client.ConfigurationData import gConfigurationData"
            },
            "11": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "         if self.newConfig:"
            },
            "14": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "             self.__cleanCacheDirectory()"
            },
            "15": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with open(self.configCacheName, \"wb\") as fcache:"
            },
            "17": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                os.chmod(self.configCacheName, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+            with secureOpenForWrite(self.configCacheName, text=False) as fcache:"
            },
            "19": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "                 pickle.dump(gConfigurationData.mergedCFG, fcache)"
            },
            "20": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "         else:"
            },
            "21": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 73,
                "PatchRowcode": "             try:"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/env python",
            "import os",
            "import re",
            "import stat",
            "import time",
            "import pickle",
            "import tempfile",
            "",
            "from DIRAC.Core.Base.Script import Script",
            "from DIRAC.ConfigurationSystem.Client.ConfigurationData import gConfigurationData",
            "",
            "",
            "class ConfigCache:",
            "    @classmethod",
            "    def cacheFilePrefix(cls):",
            "        return \"DSession.configCache\"",
            "",
            "    cacheDir = tempfile.gettempdir()",
            "",
            "    def __init__(self, forceRefresh=False):",
            "        self.newConfig = True",
            "        self.configCacheLifetime = 600.0  # ten minutes",
            "",
            "        if \"DCOMMANDS_PPID\" in os.environ:",
            "            self.pid = int(os.environ[\"DCOMMANDS_PPID\"])",
            "        else:",
            "            self.pid = os.getppid()",
            "",
            "        self.configCacheName = os.path.join(self.cacheDir, self.cacheFilePrefix() + \".%d.%d\" % (os.getuid(), self.pid))",
            "",
            "        if not forceRefresh:",
            "            self.loadConfig()",
            "",
            "    def __cleanCacheDirectory(self):",
            "        def pid_exists(pid):",
            "            try:",
            "                os.kill(pid, 0)",
            "            except OSError as _err:",
            "                return False",
            "            return True",
            "",
            "        cachePat = \"^\" + self.cacheFilePrefix() + r\"\\.%s\\.(?P<pid>[0-9]+)$\" % os.getuid()",
            "        cacheRe = re.compile(cachePat)",
            "        for fname in os.listdir(self.cacheDir):",
            "            match = cacheRe.match(fname)",
            "            if match is not None:",
            "                pid = int(match.group(\"pid\"))",
            "",
            "                path = os.path.join(self.cacheDir, fname)",
            "                # delete session files for non running processes",
            "                if not pid_exists(pid) and os.access(path, os.W_OK):",
            "                    # print(\"remove old session file\", path)",
            "                    os.unlink(path)",
            "",
            "    def loadConfig(self):",
            "        self.newConfig = True",
            "",
            "        if os.path.isfile(self.configCacheName):",
            "            cacheStamp = os.stat(self.configCacheName).st_mtime",
            "            # print(time.time() - cacheStamp, self.configCacheLifetime, time.time() - cacheStamp <= self.configCacheLifetime)",
            "            if time.time() - cacheStamp <= self.configCacheLifetime:",
            "                Script.disableCS()",
            "                self.newConfig = False",
            "                # print('use cached config')",
            "",
            "    def cacheConfig(self):",
            "        if self.newConfig:",
            "            self.__cleanCacheDirectory()",
            "",
            "            with open(self.configCacheName, \"wb\") as fcache:",
            "                os.chmod(self.configCacheName, stat.S_IRUSR | stat.S_IWUSR)",
            "                pickle.dump(gConfigurationData.mergedCFG, fcache)",
            "        else:",
            "            try:",
            "                with open(self.configCacheName, \"rb\") as fh:",
            "                    gConfigurationData.mergedCFG = pickle.load(fh)",
            "            except:",
            "                print(\"Warning: Cache corrupt or unreadable\")"
        ],
        "afterPatchFile": [
            "#!/usr/bin/env python",
            "import os",
            "import re",
            "import time",
            "import pickle",
            "import tempfile",
            "",
            "from DIRAC.Core.Base.Script import Script",
            "from DIRAC.Core.Utilities.File import secureOpenForWrite",
            "from DIRAC.ConfigurationSystem.Client.ConfigurationData import gConfigurationData",
            "",
            "",
            "class ConfigCache:",
            "    @classmethod",
            "    def cacheFilePrefix(cls):",
            "        return \"DSession.configCache\"",
            "",
            "    cacheDir = tempfile.gettempdir()",
            "",
            "    def __init__(self, forceRefresh=False):",
            "        self.newConfig = True",
            "        self.configCacheLifetime = 600.0  # ten minutes",
            "",
            "        if \"DCOMMANDS_PPID\" in os.environ:",
            "            self.pid = int(os.environ[\"DCOMMANDS_PPID\"])",
            "        else:",
            "            self.pid = os.getppid()",
            "",
            "        self.configCacheName = os.path.join(self.cacheDir, self.cacheFilePrefix() + \".%d.%d\" % (os.getuid(), self.pid))",
            "",
            "        if not forceRefresh:",
            "            self.loadConfig()",
            "",
            "    def __cleanCacheDirectory(self):",
            "        def pid_exists(pid):",
            "            try:",
            "                os.kill(pid, 0)",
            "            except OSError as _err:",
            "                return False",
            "            return True",
            "",
            "        cachePat = \"^\" + self.cacheFilePrefix() + r\"\\.%s\\.(?P<pid>[0-9]+)$\" % os.getuid()",
            "        cacheRe = re.compile(cachePat)",
            "        for fname in os.listdir(self.cacheDir):",
            "            match = cacheRe.match(fname)",
            "            if match is not None:",
            "                pid = int(match.group(\"pid\"))",
            "",
            "                path = os.path.join(self.cacheDir, fname)",
            "                # delete session files for non running processes",
            "                if not pid_exists(pid) and os.access(path, os.W_OK):",
            "                    # print(\"remove old session file\", path)",
            "                    os.unlink(path)",
            "",
            "    def loadConfig(self):",
            "        self.newConfig = True",
            "",
            "        if os.path.isfile(self.configCacheName):",
            "            cacheStamp = os.stat(self.configCacheName).st_mtime",
            "            # print(time.time() - cacheStamp, self.configCacheLifetime, time.time() - cacheStamp <= self.configCacheLifetime)",
            "            if time.time() - cacheStamp <= self.configCacheLifetime:",
            "                Script.disableCS()",
            "                self.newConfig = False",
            "                # print('use cached config')",
            "",
            "    def cacheConfig(self):",
            "        if self.newConfig:",
            "            self.__cleanCacheDirectory()",
            "",
            "            with secureOpenForWrite(self.configCacheName, text=False) as fcache:",
            "                pickle.dump(gConfigurationData.mergedCFG, fcache)",
            "        else:",
            "            try:",
            "                with open(self.configCacheName, \"rb\") as fh:",
            "                    gConfigurationData.mergedCFG = pickle.load(fh)",
            "            except:",
            "                print(\"Warning: Cache corrupt or unreadable\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "4": [],
            "70": [
                "ConfigCache",
                "cacheConfig"
            ],
            "71": [
                "ConfigCache",
                "cacheConfig"
            ]
        },
        "addLocation": []
    },
    "src/DIRAC/WorkloadManagementSystem/Utilities/PilotWrapper.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " from __future__ import print_function"
            },
            "1": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " import os"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+import io"
            },
            "4": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " import stat"
            },
            "5": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " import tempfile"
            },
            "6": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " import sys"
            },
            "7": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "     for pfName, encodedPf in pilotFilesCompressedEncodedDict.items():"
            },
            "8": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "         compressedString += \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 133,
                "PatchRowcode": " try:"
            },
            "10": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-  with open('%(pfName)s', 'wb') as fd:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+  fd = os.open('%(pfName)s', os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+  with io.open(fd, 'wb') as fd:"
            },
            "13": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "     if sys.version_info < (3,):"
            },
            "14": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "       fd.write(bz2.decompress(base64.b64decode(\\\"\\\"\\\"%(encodedPf)s\\\"\\\"\\\")))"
            },
            "15": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "     else:"
            }
        },
        "frontPatchFile": [
            "\"\"\" Module holding function(s) creating the pilot wrapper.",
            "",
            "    This is a DIRAC-free module, so it could possibly be used also outside of DIRAC installations.",
            "",
            "    The main client of this module is the SiteDirector, that invokes the functions here more or less like this::",
            "",
            "        pilotFilesCompressedEncodedDict = getPilotFilesCompressedEncodedDict(pilotFiles)",
            "        localPilot = pilotWrapperScript(pilotFilesCompressedEncodedDict,",
            "                                        pilotOptions,",
            "                                        pilotExecDir)",
            "       _writePilotWrapperFile(localPilot=localPilot)",
            "",
            "\"\"\"",
            "from __future__ import absolute_import, division, print_function",
            "",
            "import base64",
            "import bz2",
            "import os",
            "import tempfile",
            "",
            "pilotWrapperContent = \"\"\"#!/bin/bash",
            "if command -v python &> /dev/null; then",
            "  py='python'",
            "elif command -v python3 &> /dev/null; then",
            "  py='python3'",
            "elif command -v python2 &> /dev/null; then",
            "  py='python2'",
            "fi",
            "/usr/bin/env $py << EOF",
            "",
            "# imports",
            "from __future__ import absolute_import",
            "from __future__ import division",
            "from __future__ import print_function",
            "",
            "import os",
            "import stat",
            "import tempfile",
            "import sys",
            "import shutil",
            "import base64",
            "import bz2",
            "import logging",
            "import time",
            "import tarfile",
            "import hashlib",
            "",
            "# setting up the logging",
            "formatter = logging.Formatter(fmt='%%(asctime)s UTC %%(levelname)-8s %%(message)s', datefmt='%%Y-%%m-%%d %%H:%%M:%%S')",
            "logging.Formatter.converter = time.gmtime",
            "try:",
            "  screen_handler = logging.StreamHandler(stream=sys.stdout)",
            "except TypeError:  # python2.6",
            "  screen_handler = logging.StreamHandler(strm=sys.stdout)",
            "screen_handler.setFormatter(formatter)",
            "logger = logging.getLogger('pilotLogger')",
            "logger.setLevel(logging.DEBUG)",
            "logger.addHandler(screen_handler)",
            "",
            "# just logging the environment as first thing",
            "logger.debug('===========================================================')",
            "logger.debug('Environment of execution host\\\\n')",
            "for key, val in os.environ.items():",
            "  logger.debug(key + '=' + val)",
            "logger.debug('===========================================================\\\\n')",
            "",
            "# putting ourselves in the right directory",
            "pilotExecDir = '%(pilotExecDir)s'",
            "if not pilotExecDir:",
            "  pilotExecDir = os.getcwd()",
            "pilotWorkingDirectory = tempfile.mkdtemp(suffix='pilot', prefix='DIRAC_', dir=pilotExecDir)",
            "pilotWorkingDirectory = os.path.realpath(pilotWorkingDirectory)",
            "os.chdir(pilotWorkingDirectory)",
            "logger.info(\"Launching dirac-pilot script from %%s\" %%os.getcwd())",
            "\"\"\"",
            "",
            "",
            "def pilotWrapperScript(",
            "    pilotFilesCompressedEncodedDict=None,",
            "    pilotOptions=\"\",",
            "    pilotExecDir=\"\",",
            "    envVariables=None,",
            "    location=\"\",",
            "    CVMFS_locations=None,",
            "):",
            "    \"\"\"Returns the content of the pilot wrapper script.",
            "",
            "     The pilot wrapper script is a bash script that invokes the system python. Linux only.",
            "",
            "    :param pilotFilesCompressedEncodedDict: this is a possible dict of name:compressed+encoded content files.",
            "                       the proxy can be part of this, and of course the pilot files",
            "    :type pilotFilesCompressedEncodedDict: dict",
            "    :param pilotOptions: options with which to start the pilot",
            "    :type pilotOptions: string",
            "    :param pilotExecDir: pilot execution directory",
            "    :type pilotExecDir: string",
            "    :param envVariables: dictionary of environment variables",
            "    :type envVariables: dict",
            "    :param location: location where to get the pilot files",
            "    :type location: string",
            "    :param CVMFS_locations: optional CVMFS locations of where to get the pilot files",
            "    :type CVMFS_locations: list",
            "",
            "    :returns: content of the pilot wrapper",
            "    :rtype: string",
            "    \"\"\"",
            "",
            "    if pilotFilesCompressedEncodedDict is None:",
            "        pilotFilesCompressedEncodedDict = {}",
            "",
            "    if envVariables is None:",
            "        envVariables = {}",
            "",
            "    if CVMFS_locations is None:",
            "        # What is in this location is almost certainly incorrect, especially the pilot.json",
            "        CVMFS_locs = '[\"file:/cvmfs/dirac.egi.eu/pilot\"]'",
            "    else:",
            "        # Here we are making the assumption that, if CVMFS_locations is, e.g., ['/cvmfs/somewhere', '/cvmfs/elsewhere']",
            "        # and the project is 'LHCb',",
            "        # then the pilot can maybe be found at locations",
            "        # - file:/cvmfs/somewhere/lhcbdirac/pilot",
            "        # - file:/cvmfs/elsewhere/lhcbdirac/pilot",
            "        project = \"dirac\"",
            "        if \"-l\" in pilotOptions:",
            "            project = pilotOptions.split(\" \")[pilotOptions.split(\" \").index(\"-l\") + 1].lower() + \"dirac\"",
            "        CVMFS_locs = \"[\" + \",\".join('\"file:' + os.path.join(loc, project, 'pilot\"') for loc in CVMFS_locations) + \"]\"",
            "",
            "    compressedString = \"\"",
            "    # are there some pilot files to unpack? Then we create the unpacking string",
            "    for pfName, encodedPf in pilotFilesCompressedEncodedDict.items():",
            "        compressedString += \"\"\"",
            "try:",
            "  with open('%(pfName)s', 'wb') as fd:",
            "    if sys.version_info < (3,):",
            "      fd.write(bz2.decompress(base64.b64decode(\\\"\\\"\\\"%(encodedPf)s\\\"\\\"\\\")))",
            "    else:",
            "      fd.write(bz2.decompress(base64.b64decode(b'%(encodedPf)s')))",
            "  os.chmod('%(pfName)s', stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR)",
            "except Exception as x:",
            "  print(x, file=sys.stderr)",
            "  logger.error(x)",
            "  shutil.rmtree(pilotWorkingDirectory)",
            "  sys.exit(3)",
            "\"\"\" % {",
            "            \"encodedPf\": encodedPf.decode() if hasattr(encodedPf, \"decode\") else encodedPf,",
            "            \"pfName\": pfName,",
            "        }",
            "",
            "    envVariablesString = \"\"",
            "    for name, value in envVariables.items():  # are there some environment variables to add?",
            "        envVariablesString += \"\"\"",
            "os.environ[\\\"%(name)s\\\"]=\\\"%(value)s\\\"",
            "\"\"\" % {",
            "            \"name\": name,",
            "            \"value\": value,",
            "        }",
            "",
            "    # add X509_USER_PROXY to establish pilot env in Cluster WNs",
            "    if \"proxy\" in pilotFilesCompressedEncodedDict:",
            "        envVariablesString += \"\"\"",
            "os.environ['X509_USER_PROXY'] = os.path.join(pilotWorkingDirectory, 'proxy')",
            "\"\"\"",
            "",
            "    # now building the actual pilot wrapper",
            "",
            "    localPilot = pilotWrapperContent % {\"pilotExecDir\": pilotExecDir}",
            "",
            "    if compressedString:",
            "        localPilot += (",
            "            \"\"\"",
            "# unpacking lines",
            "logger.info(\"But first unpacking pilot files\")",
            "%s",
            "\"\"\"",
            "            % compressedString",
            "        )",
            "",
            "    if envVariablesString:",
            "        localPilot += (",
            "            \"\"\"",
            "# Modifying the environment",
            "%s",
            "\"\"\"",
            "            % envVariablesString",
            "        )",
            "",
            "    if location:",
            "        localPilot += \"\"\"",
            "# Getting the pilot files",
            "logger.info(\"Getting the pilot files from %(location)s\")",
            "",
            "location = '%(location)s'.replace(' ', '').split(',')",
            "",
            "import random",
            "random.shuffle(location)",
            "",
            "# we try from the available locations",
            "locs = [os.path.join('https://', loc) for loc in location]",
            "locations = locs + [os.path.join(loc, 'pilot') for loc in locs]",
            "# adding also the cvmfs locations",
            "locations += %(CVMFS_locs)s",
            "",
            "for loc in locations:",
            "  print('Trying %%s' %% loc)",
            "",
            "  # Getting the json, tar, and checksum file",
            "  try:",
            "",
            "    # urllib is different between python 2 and 3",
            "    if sys.version_info < (3,):",
            "      from urllib2 import urlopen as url_library_urlopen",
            "      from urllib2 import URLError as url_library_URLError",
            "    else:",
            "      from urllib.request import urlopen as url_library_urlopen",
            "      from urllib.error import URLError as url_library_URLError",
            "",
            "    for fileName in ['checksums.sha512', 'pilot.json', 'pilot.tar']:",
            "      # needs to distinguish whether urlopen method contains the 'context' param",
            "      # in theory, it should be available from python 2.7.9",
            "      # in practice, some prior versions may be composed of recent urllib version containing the param",
            "      if 'context' in url_library_urlopen.__code__.co_varnames:",
            "        import ssl",
            "        context = ssl._create_unverified_context()",
            "        remoteFile = url_library_urlopen(os.path.join(loc, fileName),",
            "                                         timeout=10,",
            "                                         context=context)",
            "",
            "      else:",
            "        remoteFile = url_library_urlopen(os.path.join(loc, fileName),",
            "                                         timeout=10)",
            "",
            "      localFile = open(fileName, 'wb')",
            "      localFile.write(remoteFile.read())",
            "      localFile.close()",
            "",
            "      if fileName != 'pilot.tar':",
            "        continue",
            "      try:",
            "        pt = tarfile.open('pilot.tar', 'r')",
            "        pt.extractall()",
            "        pt.close()",
            "      except Exception as x:",
            "        print(\"tarfile failed with message (this is normal!) %%s\" %% repr(x), file=sys.stderr)",
            "        logger.error(\"tarfile failed with message (this is normal!) %%s\" %% repr(x))",
            "        logger.warn(\"Trying tar command (tar -xvf pilot.tar)\")",
            "        res = os.system(\"tar -xvf pilot.tar\")",
            "        if res:",
            "          logger.error(\"tar failed with exit code %%d, giving up (this is normal!)\" %% int(res))",
            "          print(\"tar failed with exit code %%d, giving up (this is normal!)\" %% int(res), file=sys.stderr)",
            "          raise",
            "    # if we get here we break out of the loop of locations",
            "    break",
            "  except (url_library_URLError, Exception) as e:",
            "    print('%%s unreacheable (this is normal!)' %% loc, file=sys.stderr)",
            "    logger.error('%%s unreacheable (this is normal!)' %% loc)",
            "    logger.exception(e)",
            "",
            "else:",
            "  print(\"None of the locations of the pilot files is reachable\", file=sys.stderr)",
            "  logger.error(\"None of the locations of the pilot files is reachable\")",
            "  sys.exit(-1)",
            "",
            "# download was successful, now we check checksums",
            "if os.path.exists('checksums.sha512'):",
            "  checksumDict = {}",
            "  chkSumFile = open('checksums.sha512', 'rt')",
            "  for line in chkSumFile.read().split('\\\\n'):",
            "    if not line.strip():  ## empty lines are ignored",
            "      continue",
            "    expectedHash, fileName = line.split('  ', 1)",
            "    if not os.path.exists(fileName):",
            "      continue",
            "    logger.info('Checking %%r for checksum', fileName)",
            "    fileHash = hashlib.sha512(open(fileName, 'rb').read()).hexdigest()",
            "    if fileHash != expectedHash:",
            "      print('Checksum mismatch for file %%r' %% fileName, file=sys.stderr)",
            "      print('Expected %%r, found %%r' %%(expectedHash, fileHash), file=sys.stderr)",
            "      logger.error('Checksum mismatch for file %%r', fileName)",
            "      logger.error('Expected %%r, found %%r', expectedHash, fileHash)",
            "      sys.exit(-1)",
            "    logger.debug('Checksum matched')",
            "",
            "\"\"\" % {",
            "            \"location\": location,",
            "            \"CVMFS_locs\": CVMFS_locs,",
            "        }",
            "",
            "    localPilot += (",
            "        \"\"\"",
            "# now finally launching the pilot script (which should be called dirac-pilot.py)",
            "cmd = \"$py dirac-pilot.py %s\"",
            "logger.info('Executing: %%s' %% cmd)",
            "sys.stdout.flush()",
            "ret = os.system(cmd)",
            "",
            "# and cleaning up",
            "shutil.rmtree(pilotWorkingDirectory)",
            "",
            "# did it fail?",
            "if ret:",
            "  sys.exit(1)",
            "",
            "EOF",
            "\"\"\"",
            "        % pilotOptions",
            "    )",
            "",
            "    return localPilot",
            "",
            "",
            "def getPilotFilesCompressedEncodedDict(pilotFiles, proxy=None):",
            "    \"\"\"this function will return the dictionary of pilot files names : encodedCompressedContent",
            "     that we are going to send",
            "",
            "    :param pilotFiles: list of pilot files (list of location on the disk)",
            "    :type pilotFiles: list",
            "    :param proxy: the proxy to send",
            "    :type proxy: X509Chain",
            "    \"\"\"",
            "    pilotFilesCompressedEncodedDict = {}",
            "",
            "    for pf in pilotFiles:",
            "        with open(pf, \"r\") as fd:",
            "            pfContent = fd.read()",
            "        pfContentEncoded = base64.b64encode(bz2.compress(pfContent.encode(), 9))",
            "        pilotFilesCompressedEncodedDict[os.path.basename(pf)] = pfContentEncoded",
            "",
            "    if proxy is not None:",
            "        compressedAndEncodedProxy = base64.b64encode(bz2.compress(proxy.dumpAllToString()[\"Value\"].encode()))",
            "        pilotFilesCompressedEncodedDict[\"proxy\"] = compressedAndEncodedProxy",
            "",
            "    return pilotFilesCompressedEncodedDict",
            "",
            "",
            "def _writePilotWrapperFile(workingDirectory=None, localPilot=\"\"):",
            "    \"\"\"write the localPilot string to a file, rurn the file name",
            "",
            "    :param workingDirectory: the directory where to store the pilot wrapper file",
            "    :type workingDirectory: string",
            "    :param localPilot: content of the pilot wrapper",
            "    :type localPilot: string",
            "",
            "    :returns: file name of the pilot wrapper",
            "    :rtype: string",
            "    \"\"\"",
            "",
            "    fd, name = tempfile.mkstemp(suffix=\"_pilotwrapper.py\", prefix=\"DIRAC_\", dir=workingDirectory)",
            "    with os.fdopen(fd, \"w\") as pilotWrapper:",
            "        pilotWrapper.write(localPilot)",
            "    return name"
        ],
        "afterPatchFile": [
            "\"\"\" Module holding function(s) creating the pilot wrapper.",
            "",
            "    This is a DIRAC-free module, so it could possibly be used also outside of DIRAC installations.",
            "",
            "    The main client of this module is the SiteDirector, that invokes the functions here more or less like this::",
            "",
            "        pilotFilesCompressedEncodedDict = getPilotFilesCompressedEncodedDict(pilotFiles)",
            "        localPilot = pilotWrapperScript(pilotFilesCompressedEncodedDict,",
            "                                        pilotOptions,",
            "                                        pilotExecDir)",
            "       _writePilotWrapperFile(localPilot=localPilot)",
            "",
            "\"\"\"",
            "from __future__ import absolute_import, division, print_function",
            "",
            "import base64",
            "import bz2",
            "import os",
            "import tempfile",
            "",
            "pilotWrapperContent = \"\"\"#!/bin/bash",
            "if command -v python &> /dev/null; then",
            "  py='python'",
            "elif command -v python3 &> /dev/null; then",
            "  py='python3'",
            "elif command -v python2 &> /dev/null; then",
            "  py='python2'",
            "fi",
            "/usr/bin/env $py << EOF",
            "",
            "# imports",
            "from __future__ import absolute_import",
            "from __future__ import division",
            "from __future__ import print_function",
            "",
            "import os",
            "import io",
            "import stat",
            "import tempfile",
            "import sys",
            "import shutil",
            "import base64",
            "import bz2",
            "import logging",
            "import time",
            "import tarfile",
            "import hashlib",
            "",
            "# setting up the logging",
            "formatter = logging.Formatter(fmt='%%(asctime)s UTC %%(levelname)-8s %%(message)s', datefmt='%%Y-%%m-%%d %%H:%%M:%%S')",
            "logging.Formatter.converter = time.gmtime",
            "try:",
            "  screen_handler = logging.StreamHandler(stream=sys.stdout)",
            "except TypeError:  # python2.6",
            "  screen_handler = logging.StreamHandler(strm=sys.stdout)",
            "screen_handler.setFormatter(formatter)",
            "logger = logging.getLogger('pilotLogger')",
            "logger.setLevel(logging.DEBUG)",
            "logger.addHandler(screen_handler)",
            "",
            "# just logging the environment as first thing",
            "logger.debug('===========================================================')",
            "logger.debug('Environment of execution host\\\\n')",
            "for key, val in os.environ.items():",
            "  logger.debug(key + '=' + val)",
            "logger.debug('===========================================================\\\\n')",
            "",
            "# putting ourselves in the right directory",
            "pilotExecDir = '%(pilotExecDir)s'",
            "if not pilotExecDir:",
            "  pilotExecDir = os.getcwd()",
            "pilotWorkingDirectory = tempfile.mkdtemp(suffix='pilot', prefix='DIRAC_', dir=pilotExecDir)",
            "pilotWorkingDirectory = os.path.realpath(pilotWorkingDirectory)",
            "os.chdir(pilotWorkingDirectory)",
            "logger.info(\"Launching dirac-pilot script from %%s\" %%os.getcwd())",
            "\"\"\"",
            "",
            "",
            "def pilotWrapperScript(",
            "    pilotFilesCompressedEncodedDict=None,",
            "    pilotOptions=\"\",",
            "    pilotExecDir=\"\",",
            "    envVariables=None,",
            "    location=\"\",",
            "    CVMFS_locations=None,",
            "):",
            "    \"\"\"Returns the content of the pilot wrapper script.",
            "",
            "     The pilot wrapper script is a bash script that invokes the system python. Linux only.",
            "",
            "    :param pilotFilesCompressedEncodedDict: this is a possible dict of name:compressed+encoded content files.",
            "                       the proxy can be part of this, and of course the pilot files",
            "    :type pilotFilesCompressedEncodedDict: dict",
            "    :param pilotOptions: options with which to start the pilot",
            "    :type pilotOptions: string",
            "    :param pilotExecDir: pilot execution directory",
            "    :type pilotExecDir: string",
            "    :param envVariables: dictionary of environment variables",
            "    :type envVariables: dict",
            "    :param location: location where to get the pilot files",
            "    :type location: string",
            "    :param CVMFS_locations: optional CVMFS locations of where to get the pilot files",
            "    :type CVMFS_locations: list",
            "",
            "    :returns: content of the pilot wrapper",
            "    :rtype: string",
            "    \"\"\"",
            "",
            "    if pilotFilesCompressedEncodedDict is None:",
            "        pilotFilesCompressedEncodedDict = {}",
            "",
            "    if envVariables is None:",
            "        envVariables = {}",
            "",
            "    if CVMFS_locations is None:",
            "        # What is in this location is almost certainly incorrect, especially the pilot.json",
            "        CVMFS_locs = '[\"file:/cvmfs/dirac.egi.eu/pilot\"]'",
            "    else:",
            "        # Here we are making the assumption that, if CVMFS_locations is, e.g., ['/cvmfs/somewhere', '/cvmfs/elsewhere']",
            "        # and the project is 'LHCb',",
            "        # then the pilot can maybe be found at locations",
            "        # - file:/cvmfs/somewhere/lhcbdirac/pilot",
            "        # - file:/cvmfs/elsewhere/lhcbdirac/pilot",
            "        project = \"dirac\"",
            "        if \"-l\" in pilotOptions:",
            "            project = pilotOptions.split(\" \")[pilotOptions.split(\" \").index(\"-l\") + 1].lower() + \"dirac\"",
            "        CVMFS_locs = \"[\" + \",\".join('\"file:' + os.path.join(loc, project, 'pilot\"') for loc in CVMFS_locations) + \"]\"",
            "",
            "    compressedString = \"\"",
            "    # are there some pilot files to unpack? Then we create the unpacking string",
            "    for pfName, encodedPf in pilotFilesCompressedEncodedDict.items():",
            "        compressedString += \"\"\"",
            "try:",
            "  fd = os.open('%(pfName)s', os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR)",
            "  with io.open(fd, 'wb') as fd:",
            "    if sys.version_info < (3,):",
            "      fd.write(bz2.decompress(base64.b64decode(\\\"\\\"\\\"%(encodedPf)s\\\"\\\"\\\")))",
            "    else:",
            "      fd.write(bz2.decompress(base64.b64decode(b'%(encodedPf)s')))",
            "  os.chmod('%(pfName)s', stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR)",
            "except Exception as x:",
            "  print(x, file=sys.stderr)",
            "  logger.error(x)",
            "  shutil.rmtree(pilotWorkingDirectory)",
            "  sys.exit(3)",
            "\"\"\" % {",
            "            \"encodedPf\": encodedPf.decode() if hasattr(encodedPf, \"decode\") else encodedPf,",
            "            \"pfName\": pfName,",
            "        }",
            "",
            "    envVariablesString = \"\"",
            "    for name, value in envVariables.items():  # are there some environment variables to add?",
            "        envVariablesString += \"\"\"",
            "os.environ[\\\"%(name)s\\\"]=\\\"%(value)s\\\"",
            "\"\"\" % {",
            "            \"name\": name,",
            "            \"value\": value,",
            "        }",
            "",
            "    # add X509_USER_PROXY to establish pilot env in Cluster WNs",
            "    if \"proxy\" in pilotFilesCompressedEncodedDict:",
            "        envVariablesString += \"\"\"",
            "os.environ['X509_USER_PROXY'] = os.path.join(pilotWorkingDirectory, 'proxy')",
            "\"\"\"",
            "",
            "    # now building the actual pilot wrapper",
            "",
            "    localPilot = pilotWrapperContent % {\"pilotExecDir\": pilotExecDir}",
            "",
            "    if compressedString:",
            "        localPilot += (",
            "            \"\"\"",
            "# unpacking lines",
            "logger.info(\"But first unpacking pilot files\")",
            "%s",
            "\"\"\"",
            "            % compressedString",
            "        )",
            "",
            "    if envVariablesString:",
            "        localPilot += (",
            "            \"\"\"",
            "# Modifying the environment",
            "%s",
            "\"\"\"",
            "            % envVariablesString",
            "        )",
            "",
            "    if location:",
            "        localPilot += \"\"\"",
            "# Getting the pilot files",
            "logger.info(\"Getting the pilot files from %(location)s\")",
            "",
            "location = '%(location)s'.replace(' ', '').split(',')",
            "",
            "import random",
            "random.shuffle(location)",
            "",
            "# we try from the available locations",
            "locs = [os.path.join('https://', loc) for loc in location]",
            "locations = locs + [os.path.join(loc, 'pilot') for loc in locs]",
            "# adding also the cvmfs locations",
            "locations += %(CVMFS_locs)s",
            "",
            "for loc in locations:",
            "  print('Trying %%s' %% loc)",
            "",
            "  # Getting the json, tar, and checksum file",
            "  try:",
            "",
            "    # urllib is different between python 2 and 3",
            "    if sys.version_info < (3,):",
            "      from urllib2 import urlopen as url_library_urlopen",
            "      from urllib2 import URLError as url_library_URLError",
            "    else:",
            "      from urllib.request import urlopen as url_library_urlopen",
            "      from urllib.error import URLError as url_library_URLError",
            "",
            "    for fileName in ['checksums.sha512', 'pilot.json', 'pilot.tar']:",
            "      # needs to distinguish whether urlopen method contains the 'context' param",
            "      # in theory, it should be available from python 2.7.9",
            "      # in practice, some prior versions may be composed of recent urllib version containing the param",
            "      if 'context' in url_library_urlopen.__code__.co_varnames:",
            "        import ssl",
            "        context = ssl._create_unverified_context()",
            "        remoteFile = url_library_urlopen(os.path.join(loc, fileName),",
            "                                         timeout=10,",
            "                                         context=context)",
            "",
            "      else:",
            "        remoteFile = url_library_urlopen(os.path.join(loc, fileName),",
            "                                         timeout=10)",
            "",
            "      localFile = open(fileName, 'wb')",
            "      localFile.write(remoteFile.read())",
            "      localFile.close()",
            "",
            "      if fileName != 'pilot.tar':",
            "        continue",
            "      try:",
            "        pt = tarfile.open('pilot.tar', 'r')",
            "        pt.extractall()",
            "        pt.close()",
            "      except Exception as x:",
            "        print(\"tarfile failed with message (this is normal!) %%s\" %% repr(x), file=sys.stderr)",
            "        logger.error(\"tarfile failed with message (this is normal!) %%s\" %% repr(x))",
            "        logger.warn(\"Trying tar command (tar -xvf pilot.tar)\")",
            "        res = os.system(\"tar -xvf pilot.tar\")",
            "        if res:",
            "          logger.error(\"tar failed with exit code %%d, giving up (this is normal!)\" %% int(res))",
            "          print(\"tar failed with exit code %%d, giving up (this is normal!)\" %% int(res), file=sys.stderr)",
            "          raise",
            "    # if we get here we break out of the loop of locations",
            "    break",
            "  except (url_library_URLError, Exception) as e:",
            "    print('%%s unreacheable (this is normal!)' %% loc, file=sys.stderr)",
            "    logger.error('%%s unreacheable (this is normal!)' %% loc)",
            "    logger.exception(e)",
            "",
            "else:",
            "  print(\"None of the locations of the pilot files is reachable\", file=sys.stderr)",
            "  logger.error(\"None of the locations of the pilot files is reachable\")",
            "  sys.exit(-1)",
            "",
            "# download was successful, now we check checksums",
            "if os.path.exists('checksums.sha512'):",
            "  checksumDict = {}",
            "  chkSumFile = open('checksums.sha512', 'rt')",
            "  for line in chkSumFile.read().split('\\\\n'):",
            "    if not line.strip():  ## empty lines are ignored",
            "      continue",
            "    expectedHash, fileName = line.split('  ', 1)",
            "    if not os.path.exists(fileName):",
            "      continue",
            "    logger.info('Checking %%r for checksum', fileName)",
            "    fileHash = hashlib.sha512(open(fileName, 'rb').read()).hexdigest()",
            "    if fileHash != expectedHash:",
            "      print('Checksum mismatch for file %%r' %% fileName, file=sys.stderr)",
            "      print('Expected %%r, found %%r' %%(expectedHash, fileHash), file=sys.stderr)",
            "      logger.error('Checksum mismatch for file %%r', fileName)",
            "      logger.error('Expected %%r, found %%r', expectedHash, fileHash)",
            "      sys.exit(-1)",
            "    logger.debug('Checksum matched')",
            "",
            "\"\"\" % {",
            "            \"location\": location,",
            "            \"CVMFS_locs\": CVMFS_locs,",
            "        }",
            "",
            "    localPilot += (",
            "        \"\"\"",
            "# now finally launching the pilot script (which should be called dirac-pilot.py)",
            "cmd = \"$py dirac-pilot.py %s\"",
            "logger.info('Executing: %%s' %% cmd)",
            "sys.stdout.flush()",
            "ret = os.system(cmd)",
            "",
            "# and cleaning up",
            "shutil.rmtree(pilotWorkingDirectory)",
            "",
            "# did it fail?",
            "if ret:",
            "  sys.exit(1)",
            "",
            "EOF",
            "\"\"\"",
            "        % pilotOptions",
            "    )",
            "",
            "    return localPilot",
            "",
            "",
            "def getPilotFilesCompressedEncodedDict(pilotFiles, proxy=None):",
            "    \"\"\"this function will return the dictionary of pilot files names : encodedCompressedContent",
            "     that we are going to send",
            "",
            "    :param pilotFiles: list of pilot files (list of location on the disk)",
            "    :type pilotFiles: list",
            "    :param proxy: the proxy to send",
            "    :type proxy: X509Chain",
            "    \"\"\"",
            "    pilotFilesCompressedEncodedDict = {}",
            "",
            "    for pf in pilotFiles:",
            "        with open(pf, \"r\") as fd:",
            "            pfContent = fd.read()",
            "        pfContentEncoded = base64.b64encode(bz2.compress(pfContent.encode(), 9))",
            "        pilotFilesCompressedEncodedDict[os.path.basename(pf)] = pfContentEncoded",
            "",
            "    if proxy is not None:",
            "        compressedAndEncodedProxy = base64.b64encode(bz2.compress(proxy.dumpAllToString()[\"Value\"].encode()))",
            "        pilotFilesCompressedEncodedDict[\"proxy\"] = compressedAndEncodedProxy",
            "",
            "    return pilotFilesCompressedEncodedDict",
            "",
            "",
            "def _writePilotWrapperFile(workingDirectory=None, localPilot=\"\"):",
            "    \"\"\"write the localPilot string to a file, rurn the file name",
            "",
            "    :param workingDirectory: the directory where to store the pilot wrapper file",
            "    :type workingDirectory: string",
            "    :param localPilot: content of the pilot wrapper",
            "    :type localPilot: string",
            "",
            "    :returns: file name of the pilot wrapper",
            "    :rtype: string",
            "    \"\"\"",
            "",
            "    fd, name = tempfile.mkstemp(suffix=\"_pilotwrapper.py\", prefix=\"DIRAC_\", dir=workingDirectory)",
            "    with os.fdopen(fd, \"w\") as pilotWrapper:",
            "        pilotWrapper.write(localPilot)",
            "    return name"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "133": [
                "pilotWrapperScript"
            ]
        },
        "addLocation": []
    }
}