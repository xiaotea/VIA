{
    "vantage6-client/tests/test_client.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import base64"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import json"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import pickle"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from unittest import TestCase"
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from unittest.mock import patch, MagicMock"
            },
            "6": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " class TestClient(TestCase):"
            },
            "9": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_post_task_legacy_method(self):"
            },
            "11": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'legacy')"
            },
            "12": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        decoded_input = base64.b64decode(post_input)"
            },
            "13": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        decoded_input = pickle.loads(decoded_input)"
            },
            "14": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert {'method': 'test-task'} == decoded_input"
            },
            "15": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "16": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_post_json_task(self):"
            },
            "17": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'json')"
            },
            "18": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        decoded_input = base64.b64decode(post_input)"
            },
            "19": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert b'json.{\"method\": \"test-task\"}' == decoded_input"
            },
            "20": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "21": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_post_pickle_task(self):"
            },
            "22": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'pickle')"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+    def test_post_task(self):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT)"
            },
            "25": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "         decoded_input = base64.b64decode(post_input)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        assert b'{\"method\": \"test-task\"}' == decoded_input"
            },
            "27": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert b'pickle.' == decoded_input[0:7]"
            },
            "29": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "30": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert {'method': 'test-task'} == pickle.loads(decoded_input[7:])"
            },
            "31": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "32": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_get_legacy_results(self):"
            },
            "33": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mock_result = pickle.dumps(1)"
            },
            "34": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "35": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        results = TestClient._receive_results_on_mock_client(mock_result)"
            },
            "36": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "37": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert results == [{'result': 1}]"
            },
            "38": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "39": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_get_json_results(self):"
            },
            "40": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mock_result = b'json.' + json.dumps({'some_key': 'some_value'}).encode()"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+    def test_get_results(self):"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+        mock_result = json.dumps({'some_key': 'some_value'}).encode()"
            },
            "43": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " "
            },
            "44": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         results = TestClient._receive_results_on_mock_client(mock_result)"
            },
            "45": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "46": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "         assert results == [{'result': {'some_key': 'some_value'}}]"
            },
            "47": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_get_pickle_results(self):"
            },
            "49": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mock_result = b'pickle.' + pickle.dumps([1, 2, 3, 4, 5])"
            },
            "50": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "51": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        results = TestClient._receive_results_on_mock_client(mock_result)"
            },
            "52": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "53": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert results == [{'result': [1, 2, 3, 4, 5]}]"
            },
            "54": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "55": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "     @staticmethod"
            },
            "56": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def post_task_on_mock_client(input_, serialization: str) -> dict[str, any]:"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    def post_task_on_mock_client(input_) -> dict[str, any]:"
            },
            "58": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "         mock_requests = MagicMock()"
            },
            "59": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         mock_requests.get.return_value.status_code = 200"
            },
            "60": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "         mock_requests.post.return_value.status_code = 200"
            },
            "61": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "         with patch.multiple('vantage6.client', requests=mock_requests, jwt=mock_jwt):"
            },
            "62": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "             client = TestClient.setup_client()"
            },
            "63": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 50,
                "PatchRowcode": " "
            },
            "64": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            client.post_task(name=TASK_NAME, image=TASK_IMAGE, collaboration_id=COLLABORATION_ID,"
            },
            "65": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                             organization_ids=ORGANIZATION_IDS, input_=input_, data_format=serialization)"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+            client.post_task("
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+                name=TASK_NAME, image=TASK_IMAGE,"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+                collaboration_id=COLLABORATION_ID,"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+                organization_ids=ORGANIZATION_IDS, input_=input_"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+            )"
            },
            "71": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 56,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "             # In a request.post call, json is provided with the keyword argument 'json'"
            },
            "73": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "             # call_args provides a tuple with positional arguments followed by a dict with positional arguments"
            }
        },
        "frontPatchFile": [
            "import base64",
            "import json",
            "import pickle",
            "from unittest import TestCase",
            "from unittest.mock import patch, MagicMock",
            "",
            "from vantage6.client import Client",
            "from vantage6.common.globals import STRING_ENCODING",
            "",
            "# Mock server",
            "HOST = 'mock_server'",
            "PORT = 1234",
            "",
            "# Mock credentials",
            "FAKE_USERNAME = 'vantage6_test'",
            "FAKE_PASSWORD = 'secretpassword'",
            "FAKE_ID = 1",
            "",
            "TASK_NAME = 'test-task'",
            "TASK_IMAGE = 'mock-image'",
            "COLLABORATION_ID = 1",
            "ORGANIZATION_IDS = [1]",
            "SAMPLE_INPUT = {'method': 'test-task'}",
            "FAKE_NAME = 'john doe'",
            "",
            "",
            "class TestClient(TestCase):",
            "",
            "    def test_post_task_legacy_method(self):",
            "        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'legacy')",
            "        decoded_input = base64.b64decode(post_input)",
            "        decoded_input = pickle.loads(decoded_input)",
            "        assert {'method': 'test-task'} == decoded_input",
            "",
            "    def test_post_json_task(self):",
            "        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'json')",
            "        decoded_input = base64.b64decode(post_input)",
            "        assert b'json.{\"method\": \"test-task\"}' == decoded_input",
            "",
            "    def test_post_pickle_task(self):",
            "        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT, 'pickle')",
            "        decoded_input = base64.b64decode(post_input)",
            "",
            "        assert b'pickle.' == decoded_input[0:7]",
            "",
            "        assert {'method': 'test-task'} == pickle.loads(decoded_input[7:])",
            "",
            "    def test_get_legacy_results(self):",
            "        mock_result = pickle.dumps(1)",
            "",
            "        results = TestClient._receive_results_on_mock_client(mock_result)",
            "",
            "        assert results == [{'result': 1}]",
            "",
            "    def test_get_json_results(self):",
            "        mock_result = b'json.' + json.dumps({'some_key': 'some_value'}).encode()",
            "",
            "        results = TestClient._receive_results_on_mock_client(mock_result)",
            "",
            "        assert results == [{'result': {'some_key': 'some_value'}}]",
            "",
            "    def test_get_pickle_results(self):",
            "        mock_result = b'pickle.' + pickle.dumps([1, 2, 3, 4, 5])",
            "",
            "        results = TestClient._receive_results_on_mock_client(mock_result)",
            "",
            "        assert results == [{'result': [1, 2, 3, 4, 5]}]",
            "",
            "    @staticmethod",
            "    def post_task_on_mock_client(input_, serialization: str) -> dict[str, any]:",
            "        mock_requests = MagicMock()",
            "        mock_requests.get.return_value.status_code = 200",
            "        mock_requests.post.return_value.status_code = 200",
            "",
            "        mock_jwt = TestClient._create_mock_jwt()",
            "        with patch.multiple('vantage6.client', requests=mock_requests, jwt=mock_jwt):",
            "            client = TestClient.setup_client()",
            "",
            "            client.post_task(name=TASK_NAME, image=TASK_IMAGE, collaboration_id=COLLABORATION_ID,",
            "                             organization_ids=ORGANIZATION_IDS, input_=input_, data_format=serialization)",
            "",
            "            # In a request.post call, json is provided with the keyword argument 'json'",
            "            # call_args provides a tuple with positional arguments followed by a dict with positional arguments",
            "            post_content = mock_requests.post.call_args[1]['json']",
            "",
            "            post_input = post_content['organizations'][0]['input']",
            "",
            "        return post_input",
            "",
            "    @staticmethod",
            "    def _receive_results_on_mock_client(mock_result):",
            "        mock_result = base64.b64encode(mock_result).decode(STRING_ENCODING)",
            "        mock_result_response = [{'result': mock_result}]",
            "        mock_jwt = TestClient._create_mock_jwt()",
            "",
            "        mock_requests = MagicMock()",
            "        mock_requests.get.return_value.status_code = 200",
            "        mock_requests.post.return_value.status_code = 200",
            "",
            "        user = {'id': FAKE_ID, 'firstname': 'naam', 'organization': {'id': FAKE_ID}}",
            "        organization = {'id': FAKE_ID, 'name': FAKE_NAME}",
            "",
            "        # The client will first send a post request for authentication, then for retrieving results.",
            "        mock_requests.get.return_value.json.side_effect = [user, organization, mock_result_response]",
            "",
            "        with patch.multiple('vantage6.client', requests=mock_requests, jwt=mock_jwt):",
            "            client = TestClient.setup_client()",
            "",
            "            results = client.result.from_task(task_id=FAKE_ID)",
            "",
            "            return results",
            "",
            "    @staticmethod",
            "    def setup_client() -> Client:",
            "        client = Client(HOST, PORT)",
            "        client.authenticate(FAKE_USERNAME, FAKE_PASSWORD)",
            "        client.setup_encryption(None)",
            "        return client",
            "",
            "    @staticmethod",
            "    def _create_mock_jwt() -> MagicMock:",
            "        mock_jwt = MagicMock()",
            "        mock_jwt.decode.return_value = {'sub': FAKE_ID}",
            "        return mock_jwt"
        ],
        "afterPatchFile": [
            "import base64",
            "import json",
            "",
            "from unittest import TestCase",
            "from unittest.mock import patch, MagicMock",
            "",
            "from vantage6.client import Client",
            "from vantage6.common.globals import STRING_ENCODING",
            "",
            "# Mock server",
            "HOST = 'mock_server'",
            "PORT = 1234",
            "",
            "# Mock credentials",
            "FAKE_USERNAME = 'vantage6_test'",
            "FAKE_PASSWORD = 'secretpassword'",
            "FAKE_ID = 1",
            "",
            "TASK_NAME = 'test-task'",
            "TASK_IMAGE = 'mock-image'",
            "COLLABORATION_ID = 1",
            "ORGANIZATION_IDS = [1]",
            "SAMPLE_INPUT = {'method': 'test-task'}",
            "FAKE_NAME = 'john doe'",
            "",
            "",
            "class TestClient(TestCase):",
            "",
            "    def test_post_task(self):",
            "        post_input = TestClient.post_task_on_mock_client(SAMPLE_INPUT)",
            "        decoded_input = base64.b64decode(post_input)",
            "        assert b'{\"method\": \"test-task\"}' == decoded_input",
            "",
            "    def test_get_results(self):",
            "        mock_result = json.dumps({'some_key': 'some_value'}).encode()",
            "",
            "        results = TestClient._receive_results_on_mock_client(mock_result)",
            "",
            "        assert results == [{'result': {'some_key': 'some_value'}}]",
            "",
            "    @staticmethod",
            "    def post_task_on_mock_client(input_) -> dict[str, any]:",
            "        mock_requests = MagicMock()",
            "        mock_requests.get.return_value.status_code = 200",
            "        mock_requests.post.return_value.status_code = 200",
            "",
            "        mock_jwt = TestClient._create_mock_jwt()",
            "        with patch.multiple('vantage6.client', requests=mock_requests, jwt=mock_jwt):",
            "            client = TestClient.setup_client()",
            "",
            "            client.post_task(",
            "                name=TASK_NAME, image=TASK_IMAGE,",
            "                collaboration_id=COLLABORATION_ID,",
            "                organization_ids=ORGANIZATION_IDS, input_=input_",
            "            )",
            "",
            "            # In a request.post call, json is provided with the keyword argument 'json'",
            "            # call_args provides a tuple with positional arguments followed by a dict with positional arguments",
            "            post_content = mock_requests.post.call_args[1]['json']",
            "",
            "            post_input = post_content['organizations'][0]['input']",
            "",
            "        return post_input",
            "",
            "    @staticmethod",
            "    def _receive_results_on_mock_client(mock_result):",
            "        mock_result = base64.b64encode(mock_result).decode(STRING_ENCODING)",
            "        mock_result_response = [{'result': mock_result}]",
            "        mock_jwt = TestClient._create_mock_jwt()",
            "",
            "        mock_requests = MagicMock()",
            "        mock_requests.get.return_value.status_code = 200",
            "        mock_requests.post.return_value.status_code = 200",
            "",
            "        user = {'id': FAKE_ID, 'firstname': 'naam', 'organization': {'id': FAKE_ID}}",
            "        organization = {'id': FAKE_ID, 'name': FAKE_NAME}",
            "",
            "        # The client will first send a post request for authentication, then for retrieving results.",
            "        mock_requests.get.return_value.json.side_effect = [user, organization, mock_result_response]",
            "",
            "        with patch.multiple('vantage6.client', requests=mock_requests, jwt=mock_jwt):",
            "            client = TestClient.setup_client()",
            "",
            "            results = client.result.from_task(task_id=FAKE_ID)",
            "",
            "            return results",
            "",
            "    @staticmethod",
            "    def setup_client() -> Client:",
            "        client = Client(HOST, PORT)",
            "        client.authenticate(FAKE_USERNAME, FAKE_PASSWORD)",
            "        client.setup_encryption(None)",
            "        return client",
            "",
            "    @staticmethod",
            "    def _create_mock_jwt() -> MagicMock:",
            "        mock_jwt = MagicMock()",
            "        mock_jwt.decode.return_value = {'sub': FAKE_ID}",
            "        return mock_jwt"
        ],
        "action": [
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "3": [],
            "29": [
                "TestClient",
                "test_post_task_legacy_method"
            ],
            "30": [
                "TestClient",
                "test_post_task_legacy_method"
            ],
            "31": [
                "TestClient",
                "test_post_task_legacy_method"
            ],
            "32": [
                "TestClient",
                "test_post_task_legacy_method"
            ],
            "33": [
                "TestClient",
                "test_post_task_legacy_method"
            ],
            "34": [
                "TestClient"
            ],
            "35": [
                "TestClient",
                "test_post_json_task"
            ],
            "36": [
                "TestClient",
                "test_post_json_task"
            ],
            "37": [
                "TestClient",
                "test_post_json_task"
            ],
            "38": [
                "TestClient",
                "test_post_json_task"
            ],
            "39": [
                "TestClient"
            ],
            "40": [
                "TestClient",
                "test_post_pickle_task"
            ],
            "41": [
                "TestClient",
                "test_post_pickle_task"
            ],
            "44": [
                "TestClient",
                "test_post_pickle_task"
            ],
            "45": [
                "TestClient",
                "test_post_pickle_task"
            ],
            "46": [
                "TestClient",
                "test_post_pickle_task"
            ],
            "47": [
                "TestClient"
            ],
            "48": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "49": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "50": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "51": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "52": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "53": [
                "TestClient",
                "test_get_legacy_results"
            ],
            "54": [
                "TestClient"
            ],
            "55": [
                "TestClient",
                "test_get_json_results"
            ],
            "56": [
                "TestClient",
                "test_get_json_results"
            ],
            "62": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "63": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "64": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "65": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "66": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "67": [
                "TestClient",
                "test_get_pickle_results"
            ],
            "68": [
                "TestClient"
            ],
            "70": [
                "TestClient",
                "post_task_on_mock_client"
            ],
            "79": [
                "TestClient",
                "post_task_on_mock_client"
            ],
            "80": [
                "TestClient",
                "post_task_on_mock_client"
            ]
        },
        "addLocation": []
    },
    "vantage6-client/tests/test_deserialization.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import pickle"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from pathlib import Path"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " from vantage6.tools import deserialization"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from vantage6.tools.data_format import DataFormat"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " SIMPLE_TARGET_DATA = {'key': 'value'}"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 10,
                "PatchRowcode": "     json_path.write_text(data)"
            },
            "8": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 12,
                "PatchRowcode": "     with json_path.open('r') as f:"
            },
            "10": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        result = deserialization.deserialize(f, DataFormat.JSON)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 13,
                "PatchRowcode": "+        result = deserialization.deserialize(f)"
            },
            "12": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "         assert SIMPLE_TARGET_DATA == result"
            },
            "14": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "15": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "16": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_deserialize_pickle(tmp_path: Path):"
            },
            "17": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    data = {'key': 'value'}"
            },
            "18": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "19": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    pickle_path = tmp_path / 'picklefile.pkl'"
            },
            "20": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "21": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with pickle_path.open('wb') as f:"
            },
            "22": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pickle.dump(data, f)"
            },
            "23": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "24": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with pickle_path.open('rb') as f:"
            },
            "25": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        result = deserialization.deserialize(f, DataFormat.PICKLE)"
            },
            "26": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert SIMPLE_TARGET_DATA == result"
            }
        },
        "frontPatchFile": [
            "import pickle",
            "from pathlib import Path",
            "from vantage6.tools import deserialization",
            "from vantage6.tools.data_format import DataFormat",
            "",
            "SIMPLE_TARGET_DATA = {'key': 'value'}",
            "",
            "",
            "def test_deserialize_json(tmp_path: Path):",
            "    data = '{\"key\": \"value\"}'",
            "    json_path = tmp_path / 'jsonfile.json'",
            "    json_path.write_text(data)",
            "",
            "    with json_path.open('r') as f:",
            "        result = deserialization.deserialize(f, DataFormat.JSON)",
            "",
            "        assert SIMPLE_TARGET_DATA == result",
            "",
            "",
            "def test_deserialize_pickle(tmp_path: Path):",
            "    data = {'key': 'value'}",
            "",
            "    pickle_path = tmp_path / 'picklefile.pkl'",
            "",
            "    with pickle_path.open('wb') as f:",
            "        pickle.dump(data, f)",
            "",
            "    with pickle_path.open('rb') as f:",
            "        result = deserialization.deserialize(f, DataFormat.PICKLE)",
            "        assert SIMPLE_TARGET_DATA == result"
        ],
        "afterPatchFile": [
            "from pathlib import Path",
            "from vantage6.tools import deserialization",
            "",
            "SIMPLE_TARGET_DATA = {'key': 'value'}",
            "",
            "",
            "def test_deserialize_json(tmp_path: Path):",
            "    data = '{\"key\": \"value\"}'",
            "    json_path = tmp_path / 'jsonfile.json'",
            "    json_path.write_text(data)",
            "",
            "    with json_path.open('r') as f:",
            "        result = deserialization.deserialize(f)",
            "",
            "        assert SIMPLE_TARGET_DATA == result"
        ],
        "action": [
            "1",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "1": [],
            "4": [],
            "15": [
                "test_deserialize_json"
            ],
            "18": [],
            "19": [],
            "20": [
                "test_deserialize_pickle"
            ],
            "21": [
                "test_deserialize_pickle"
            ],
            "22": [
                "test_deserialize_pickle"
            ],
            "23": [
                "test_deserialize_pickle"
            ],
            "24": [
                "test_deserialize_pickle"
            ],
            "25": [
                "test_deserialize_pickle"
            ],
            "26": [
                "test_deserialize_pickle"
            ],
            "27": [
                "test_deserialize_pickle"
            ],
            "28": [
                "test_deserialize_pickle"
            ],
            "29": [
                "test_deserialize_pickle"
            ],
            "30": [
                "test_deserialize_pickle"
            ]
        },
        "addLocation": []
    },
    "vantage6-client/tests/test_docker_wrapper.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import json"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import pickle"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " from pathlib import Path"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from unittest.mock import patch, MagicMock"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import pandas as pd"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from pytest import raises"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from vantage6.tools import wrapper"
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from vantage6.tools.exceptions import DeserializationException"
            },
            "10": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " MODULE_NAME = 'algorithm_module'"
            },
            "12": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " DATA = 'column1,column2\\n1,2'"
            },
            "13": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " JSON_FORMAT = 'json'"
            },
            "14": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " SEPARATOR = '.'"
            },
            "15": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " SAMPLE_DB = pd.DataFrame([[1, 2]], columns=['column1', 'column2'])"
            },
            "16": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-PICKLE_FORMAT = 'pickle'"
            },
            "17": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " MOCK_SPARQL_ENDPOINT = 'sparql://some_triplestore'"
            },
            "19": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_old_pickle_input_wrapper(tmp_path):"
            },
            "22": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "23": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Testing if wrapper still parses legacy input."
            },
            "24": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "25": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = tmp_path / 'input.pkl'"
            },
            "26": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "27": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with input_file.open('wb') as f:"
            },
            "28": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pickle.dump(INPUT_PARAMETERS, f)"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+# def test_json_input_without_format_raises_deserializationexception(tmp_path):"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+#     \"\"\""
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+#     It should only be possible to provide json input if it is preceded by the"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+#     string \"json.\" in unicode. Otherwise a `DeserializationException` should"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+#     be thrown."
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+#     \"\"\""
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+#     input_file = tmp_path / 'input.json'"
            },
            "36": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "38": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    assert file_echoes_db(output_file)"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+#     with input_file.open('wb') as f:"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+#         f.write(json.dumps(INPUT_PARAMETERS).encode())"
            },
            "41": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+#     with raises(DeserializationException):"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+#         run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "44": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " "
            },
            "45": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_json_input_without_format_raises_deserializationexception(tmp_path):"
            },
            "46": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "47": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    It should only be possible to provide json input if it is preceded by the"
            },
            "48": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    string \"json.\" in unicode. Otherwise a `DeserializationException` should"
            },
            "49": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    be thrown."
            },
            "50": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "51": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = tmp_path / 'input.json'"
            },
            "52": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "53": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with input_file.open('wb') as f:"
            },
            "54": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(json.dumps(INPUT_PARAMETERS).encode())"
            },
            "55": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "56": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with raises(DeserializationException):"
            },
            "57": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "58": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "59": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "60": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_json_input_with_format_succeeds(tmp_path):"
            },
            "61": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = tmp_path / 'input.txt'"
            },
            "62": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "63": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with input_file.open('wb') as f:"
            },
            "64": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(f'JSON{SEPARATOR}'.encode())"
            },
            "65": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(json.dumps(INPUT_PARAMETERS).encode())"
            },
            "66": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " "
            },
            "67": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "68": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    assert file_echoes_db(output_file)"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+# def test_json_input_with_format_succeeds(tmp_path):"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+#     input_file = tmp_path / 'input.txt'"
            },
            "71": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+#     with input_file.open('wb') as f:"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+#         f.write(json.dumps(INPUT_PARAMETERS).encode())"
            },
            "74": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " "
            },
            "75": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_pickle_input_with_format_succeeds(tmp_path):"
            },
            "76": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = create_pickle_input(tmp_path)"
            },
            "77": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "78": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    assert file_echoes_db(output_file)"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+#     output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+#     assert file_echoes_db(output_file)"
            },
            "81": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " "
            },
            "82": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " "
            },
            "83": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_wrapper_serializes_pickle_output(tmp_path):"
            },
            "84": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_parameters = {"
            },
            "85": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'method': 'hello_world',"
            },
            "86": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'output_format': PICKLE_FORMAT"
            },
            "87": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    }"
            },
            "88": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = create_pickle_input(tmp_path, input_parameters)"
            },
            "89": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "90": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "91": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "92": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with output_file.open('rb') as f:"
            },
            "93": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Check whether the output starts with `pickle.` to indicate the pickle"
            },
            "94": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # data format"
            },
            "95": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert f.read(len(PICKLE_FORMAT) + 1).decode() == f'{PICKLE_FORMAT}.'"
            },
            "96": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "97": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        result = pickle.loads(f.read())"
            },
            "98": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pd.testing.assert_frame_equal(SAMPLE_DB, result)"
            },
            "99": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "100": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "101": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_wrapper_serializes_json_output(tmp_path):"
            },
            "102": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_parameters = {'method': 'hello_world', 'output_format': JSON_FORMAT}"
            },
            "103": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = create_pickle_input(tmp_path, input_parameters)"
            },
            "104": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "105": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "106": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "107": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with output_file.open('rb') as f:"
            },
            "108": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Check whether the data is preceded by json format string"
            },
            "109": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert f.read(len(JSON_FORMAT) + 1).decode() == f'{JSON_FORMAT}.'"
            },
            "110": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "111": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Since the echo_db algorithm was triggered, output will be table that"
            },
            "112": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # can be read by pandas."
            },
            "113": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        result = pd.read_json(f.read())"
            },
            "114": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pd.testing.assert_frame_equal(SAMPLE_DB, result)"
            },
            "115": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "116": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "117": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def create_pickle_input(tmp_path, input_parameters=None):"
            },
            "118": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if input_parameters is None:"
            },
            "119": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        input_parameters = INPUT_PARAMETERS"
            },
            "120": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "121": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    input_file = tmp_path / 'input.pkl'"
            },
            "122": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with input_file.open('wb') as f:"
            },
            "123": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(f'PICKLE{SEPARATOR}'.encode())"
            },
            "124": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(pickle.dumps(input_parameters))"
            },
            "125": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return input_file"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+# def test_wrapper_serializes_json_output(tmp_path):"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+#     input_parameters = {'method': 'hello_world', 'output_format': JSON_FORMAT}"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+#     input_file = create_pickle_input(tmp_path, input_parameters)"
            },
            "129": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " "
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+#     output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)"
            },
            "131": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 50,
                "PatchRowcode": " "
            },
            "132": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def file_echoes_db(output_file):"
            },
            "133": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with output_file.open('rb') as f:"
            },
            "134": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        result = pickle.load(f)"
            },
            "135": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        target = SAMPLE_DB"
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+#     with output_file.open('rb') as f:"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+#         # Check whether the data is preceded by json format string"
            },
            "138": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+#         assert f.read(len(JSON_FORMAT) + 1).decode() == f'{JSON_FORMAT}.'"
            },
            "139": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " "
            },
            "140": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return target.equals(result)"
            },
            "141": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+#         # Since the echo_db algorithm was triggered, output will be table that"
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+#         # can be read by pandas."
            },
            "143": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+#         result = pd.read_json(f.read())"
            },
            "144": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+#         pd.testing.assert_frame_equal(SAMPLE_DB, result)"
            },
            "145": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 59,
                "PatchRowcode": " "
            },
            "146": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " "
            },
            "147": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " def run_docker_wrapper_with_echo_db(input_file, tmp_path):"
            },
            "148": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "     input_args = {'query': 'select *'}"
            },
            "149": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 109,
                "PatchRowcode": " "
            },
            "150": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "     with input_file.open('wb') as f:"
            },
            "151": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pickle.dump(input_args, f)"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        json.dumps(input_args, f)"
            },
            "153": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 112,
                "PatchRowcode": " "
            },
            "154": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 113,
                "PatchRowcode": "     with token_file.open('w') as f:"
            },
            "155": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "         f.write(TOKEN)"
            }
        },
        "frontPatchFile": [
            "import json",
            "import pickle",
            "from pathlib import Path",
            "from unittest.mock import patch, MagicMock",
            "",
            "import pandas as pd",
            "from pytest import raises",
            "",
            "from vantage6.tools import wrapper",
            "from vantage6.tools.exceptions import DeserializationException",
            "",
            "MODULE_NAME = 'algorithm_module'",
            "DATA = 'column1,column2\\n1,2'",
            "TOKEN = 'This is a fake token'",
            "INPUT_PARAMETERS = {'method': 'hello_world'}",
            "JSON_FORMAT = 'json'",
            "SEPARATOR = '.'",
            "SAMPLE_DB = pd.DataFrame([[1, 2]], columns=['column1', 'column2'])",
            "PICKLE_FORMAT = 'pickle'",
            "",
            "MOCK_SPARQL_ENDPOINT = 'sparql://some_triplestore'",
            "",
            "",
            "def test_old_pickle_input_wrapper(tmp_path):",
            "    \"\"\"",
            "    Testing if wrapper still parses legacy input.",
            "    \"\"\"",
            "    input_file = tmp_path / 'input.pkl'",
            "",
            "    with input_file.open('wb') as f:",
            "        pickle.dump(INPUT_PARAMETERS, f)",
            "",
            "    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "    assert file_echoes_db(output_file)",
            "",
            "",
            "def test_json_input_without_format_raises_deserializationexception(tmp_path):",
            "    \"\"\"",
            "    It should only be possible to provide json input if it is preceded by the",
            "    string \"json.\" in unicode. Otherwise a `DeserializationException` should",
            "    be thrown.",
            "    \"\"\"",
            "    input_file = tmp_path / 'input.json'",
            "",
            "    with input_file.open('wb') as f:",
            "        f.write(json.dumps(INPUT_PARAMETERS).encode())",
            "",
            "    with raises(DeserializationException):",
            "        run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "",
            "",
            "def test_json_input_with_format_succeeds(tmp_path):",
            "    input_file = tmp_path / 'input.txt'",
            "",
            "    with input_file.open('wb') as f:",
            "        f.write(f'JSON{SEPARATOR}'.encode())",
            "        f.write(json.dumps(INPUT_PARAMETERS).encode())",
            "",
            "    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "    assert file_echoes_db(output_file)",
            "",
            "",
            "def test_pickle_input_with_format_succeeds(tmp_path):",
            "    input_file = create_pickle_input(tmp_path)",
            "    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "    assert file_echoes_db(output_file)",
            "",
            "",
            "def test_wrapper_serializes_pickle_output(tmp_path):",
            "    input_parameters = {",
            "        'method': 'hello_world',",
            "        'output_format': PICKLE_FORMAT",
            "    }",
            "    input_file = create_pickle_input(tmp_path, input_parameters)",
            "",
            "    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "",
            "    with output_file.open('rb') as f:",
            "        # Check whether the output starts with `pickle.` to indicate the pickle",
            "        # data format",
            "        assert f.read(len(PICKLE_FORMAT) + 1).decode() == f'{PICKLE_FORMAT}.'",
            "",
            "        result = pickle.loads(f.read())",
            "        pd.testing.assert_frame_equal(SAMPLE_DB, result)",
            "",
            "",
            "def test_wrapper_serializes_json_output(tmp_path):",
            "    input_parameters = {'method': 'hello_world', 'output_format': JSON_FORMAT}",
            "    input_file = create_pickle_input(tmp_path, input_parameters)",
            "",
            "    output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "",
            "    with output_file.open('rb') as f:",
            "        # Check whether the data is preceded by json format string",
            "        assert f.read(len(JSON_FORMAT) + 1).decode() == f'{JSON_FORMAT}.'",
            "",
            "        # Since the echo_db algorithm was triggered, output will be table that",
            "        # can be read by pandas.",
            "        result = pd.read_json(f.read())",
            "        pd.testing.assert_frame_equal(SAMPLE_DB, result)",
            "",
            "",
            "def create_pickle_input(tmp_path, input_parameters=None):",
            "    if input_parameters is None:",
            "        input_parameters = INPUT_PARAMETERS",
            "",
            "    input_file = tmp_path / 'input.pkl'",
            "    with input_file.open('wb') as f:",
            "        f.write(f'PICKLE{SEPARATOR}'.encode())",
            "        f.write(pickle.dumps(input_parameters))",
            "    return input_file",
            "",
            "",
            "def file_echoes_db(output_file):",
            "    with output_file.open('rb') as f:",
            "        result = pickle.load(f)",
            "        target = SAMPLE_DB",
            "",
            "        return target.equals(result)",
            "",
            "",
            "def run_docker_wrapper_with_echo_db(input_file, tmp_path):",
            "    \"\"\"",
            "    Run the `echo_db` testing algorithm through the wrapper code. The wrapper",
            "    communicates through files whose locations are stored in the `INPUT_FILE`,",
            "    `TOKEN_FILE` and `DATABASE_URI` environment variables. The output of the",
            "    algorithm is stored in the location specified in environment variable",
            "    `OUTPUT_FILE`.",
            "",
            "    :param input_file: input arguments to the wrapper and algorithm",
            "    :param tmp_path: temporary path to store additional files.",
            "    :return:",
            "    \"\"\"",
            "    db_file = tmp_path / 'db_file.csv'",
            "    token_file = tmp_path / 'token.txt'",
            "    output_file = tmp_path / 'output_file.pkl'",
            "    db_file.write_text(DATA)",
            "    token_file.write_text(TOKEN)",
            "    with patch('vantage6.tools.docker_wrapper.os') as mock_os:",
            "        mock_os.environ = {",
            "            'INPUT_FILE': input_file,",
            "            'TOKEN_FILE': token_file,",
            "            'OUTPUT_FILE': output_file,",
            "            'DATABASE_URI': db_file",
            "        }",
            "",
            "        wrapper.docker_wrapper(MODULE_NAME)",
            "    return output_file",
            "",
            "",
            "@patch('vantage6.tools.docker_wrapper.dispatch_rpc')",
            "@patch('vantage6.tools.docker_wrapper.os')",
            "@patch('vantage6.tools.docker_wrapper.SPARQLWrapper')",
            "def test_sparql_docker_wrapper_passes_dataframe(",
            "    SPARQLWrapper: MagicMock, os: MagicMock, dispatch_rpc: MagicMock,",
            "    tmp_path: Path",
            "):",
            "    input_file = tmp_path / 'input_file.pkl'",
            "    token_file = tmp_path / 'token.txt'",
            "    output_file = tmp_path / 'output.pkl'",
            "",
            "    environ = {'INPUT_FILE': str(input_file),",
            "               'TOKEN_FILE': str(token_file),",
            "               'DATABASE_URI': MOCK_SPARQL_ENDPOINT,",
            "               'OUTPUT_FILE': str(output_file)}",
            "",
            "    os.environ = environ",
            "",
            "    input_args = {'query': 'select *'}",
            "",
            "    with input_file.open('wb') as f:",
            "        pickle.dump(input_args, f)",
            "",
            "    with token_file.open('w') as f:",
            "        f.write(TOKEN)",
            "",
            "    dispatch_rpc.return_value = pd.DataFrame()",
            "    SPARQLWrapper.return_value.query.return_value.convert.return_value = \\",
            "        DATA.encode()",
            "",
            "    wrapper.sparql_wrapper(MODULE_NAME)",
            "",
            "    dispatch_rpc.assert_called_once()",
            "",
            "    target_df = pd.DataFrame([[1, 2]], columns=['column1', 'column2'])",
            "    pd.testing.assert_frame_equal(target_df, dispatch_rpc.call_args[0][0])"
        ],
        "afterPatchFile": [
            "import json",
            "from pathlib import Path",
            "from unittest.mock import patch, MagicMock",
            "",
            "import pandas as pd",
            "",
            "from vantage6.tools import wrapper",
            "",
            "MODULE_NAME = 'algorithm_module'",
            "DATA = 'column1,column2\\n1,2'",
            "TOKEN = 'This is a fake token'",
            "INPUT_PARAMETERS = {'method': 'hello_world'}",
            "JSON_FORMAT = 'json'",
            "SEPARATOR = '.'",
            "SAMPLE_DB = pd.DataFrame([[1, 2]], columns=['column1', 'column2'])",
            "",
            "MOCK_SPARQL_ENDPOINT = 'sparql://some_triplestore'",
            "",
            "",
            "# def test_json_input_without_format_raises_deserializationexception(tmp_path):",
            "#     \"\"\"",
            "#     It should only be possible to provide json input if it is preceded by the",
            "#     string \"json.\" in unicode. Otherwise a `DeserializationException` should",
            "#     be thrown.",
            "#     \"\"\"",
            "#     input_file = tmp_path / 'input.json'",
            "",
            "#     with input_file.open('wb') as f:",
            "#         f.write(json.dumps(INPUT_PARAMETERS).encode())",
            "",
            "#     with raises(DeserializationException):",
            "#         run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "",
            "",
            "# def test_json_input_with_format_succeeds(tmp_path):",
            "#     input_file = tmp_path / 'input.txt'",
            "",
            "#     with input_file.open('wb') as f:",
            "#         f.write(json.dumps(INPUT_PARAMETERS).encode())",
            "",
            "#     output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "#     assert file_echoes_db(output_file)",
            "",
            "",
            "# def test_wrapper_serializes_json_output(tmp_path):",
            "#     input_parameters = {'method': 'hello_world', 'output_format': JSON_FORMAT}",
            "#     input_file = create_pickle_input(tmp_path, input_parameters)",
            "",
            "#     output_file = run_docker_wrapper_with_echo_db(input_file, tmp_path)",
            "",
            "#     with output_file.open('rb') as f:",
            "#         # Check whether the data is preceded by json format string",
            "#         assert f.read(len(JSON_FORMAT) + 1).decode() == f'{JSON_FORMAT}.'",
            "",
            "#         # Since the echo_db algorithm was triggered, output will be table that",
            "#         # can be read by pandas.",
            "#         result = pd.read_json(f.read())",
            "#         pd.testing.assert_frame_equal(SAMPLE_DB, result)",
            "",
            "",
            "def run_docker_wrapper_with_echo_db(input_file, tmp_path):",
            "    \"\"\"",
            "    Run the `echo_db` testing algorithm through the wrapper code. The wrapper",
            "    communicates through files whose locations are stored in the `INPUT_FILE`,",
            "    `TOKEN_FILE` and `DATABASE_URI` environment variables. The output of the",
            "    algorithm is stored in the location specified in environment variable",
            "    `OUTPUT_FILE`.",
            "",
            "    :param input_file: input arguments to the wrapper and algorithm",
            "    :param tmp_path: temporary path to store additional files.",
            "    :return:",
            "    \"\"\"",
            "    db_file = tmp_path / 'db_file.csv'",
            "    token_file = tmp_path / 'token.txt'",
            "    output_file = tmp_path / 'output_file.pkl'",
            "    db_file.write_text(DATA)",
            "    token_file.write_text(TOKEN)",
            "    with patch('vantage6.tools.docker_wrapper.os') as mock_os:",
            "        mock_os.environ = {",
            "            'INPUT_FILE': input_file,",
            "            'TOKEN_FILE': token_file,",
            "            'OUTPUT_FILE': output_file,",
            "            'DATABASE_URI': db_file",
            "        }",
            "",
            "        wrapper.docker_wrapper(MODULE_NAME)",
            "    return output_file",
            "",
            "",
            "@patch('vantage6.tools.docker_wrapper.dispatch_rpc')",
            "@patch('vantage6.tools.docker_wrapper.os')",
            "@patch('vantage6.tools.docker_wrapper.SPARQLWrapper')",
            "def test_sparql_docker_wrapper_passes_dataframe(",
            "    SPARQLWrapper: MagicMock, os: MagicMock, dispatch_rpc: MagicMock,",
            "    tmp_path: Path",
            "):",
            "    input_file = tmp_path / 'input_file.pkl'",
            "    token_file = tmp_path / 'token.txt'",
            "    output_file = tmp_path / 'output.pkl'",
            "",
            "    environ = {'INPUT_FILE': str(input_file),",
            "               'TOKEN_FILE': str(token_file),",
            "               'DATABASE_URI': MOCK_SPARQL_ENDPOINT,",
            "               'OUTPUT_FILE': str(output_file)}",
            "",
            "    os.environ = environ",
            "",
            "    input_args = {'query': 'select *'}",
            "",
            "    with input_file.open('wb') as f:",
            "        json.dumps(input_args, f)",
            "",
            "    with token_file.open('w') as f:",
            "        f.write(TOKEN)",
            "",
            "    dispatch_rpc.return_value = pd.DataFrame()",
            "    SPARQLWrapper.return_value.query.return_value.convert.return_value = \\",
            "        DATA.encode()",
            "",
            "    wrapper.sparql_wrapper(MODULE_NAME)",
            "",
            "    dispatch_rpc.assert_called_once()",
            "",
            "    target_df = pd.DataFrame([[1, 2]], columns=['column1', 'column2'])",
            "    pd.testing.assert_frame_equal(target_df, dispatch_rpc.call_args[0][0])"
        ],
        "action": [
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "2": [],
            "7": [],
            "10": [],
            "19": [
                "PICKLE_FORMAT"
            ],
            "24": [
                "test_old_pickle_input_wrapper"
            ],
            "25": [
                "test_old_pickle_input_wrapper"
            ],
            "26": [
                "test_old_pickle_input_wrapper"
            ],
            "27": [
                "test_old_pickle_input_wrapper"
            ],
            "28": [
                "test_old_pickle_input_wrapper"
            ],
            "29": [
                "test_old_pickle_input_wrapper"
            ],
            "30": [
                "test_old_pickle_input_wrapper"
            ],
            "31": [
                "test_old_pickle_input_wrapper"
            ],
            "33": [
                "test_old_pickle_input_wrapper"
            ],
            "34": [
                "test_old_pickle_input_wrapper"
            ],
            "37": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "38": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "39": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "40": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "41": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "42": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "43": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "44": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "45": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "46": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "47": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "48": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "49": [
                "test_json_input_without_format_raises_deserializationexception"
            ],
            "50": [],
            "51": [],
            "52": [
                "test_json_input_with_format_succeeds"
            ],
            "53": [
                "test_json_input_with_format_succeeds"
            ],
            "54": [
                "test_json_input_with_format_succeeds"
            ],
            "55": [
                "test_json_input_with_format_succeeds"
            ],
            "56": [
                "test_json_input_with_format_succeeds"
            ],
            "57": [
                "test_json_input_with_format_succeeds"
            ],
            "59": [
                "test_json_input_with_format_succeeds"
            ],
            "60": [
                "test_json_input_with_format_succeeds"
            ],
            "63": [
                "test_pickle_input_with_format_succeeds"
            ],
            "64": [
                "test_pickle_input_with_format_succeeds"
            ],
            "65": [
                "test_pickle_input_with_format_succeeds"
            ],
            "66": [
                "test_pickle_input_with_format_succeeds"
            ],
            "69": [
                "test_wrapper_serializes_pickle_output"
            ],
            "70": [
                "test_wrapper_serializes_pickle_output"
            ],
            "71": [
                "test_wrapper_serializes_pickle_output"
            ],
            "72": [
                "test_wrapper_serializes_pickle_output"
            ],
            "73": [
                "test_wrapper_serializes_pickle_output"
            ],
            "74": [
                "test_wrapper_serializes_pickle_output"
            ],
            "75": [
                "test_wrapper_serializes_pickle_output"
            ],
            "76": [
                "test_wrapper_serializes_pickle_output"
            ],
            "77": [
                "test_wrapper_serializes_pickle_output"
            ],
            "78": [
                "test_wrapper_serializes_pickle_output"
            ],
            "79": [
                "test_wrapper_serializes_pickle_output"
            ],
            "80": [
                "test_wrapper_serializes_pickle_output"
            ],
            "81": [
                "test_wrapper_serializes_pickle_output"
            ],
            "82": [
                "test_wrapper_serializes_pickle_output"
            ],
            "83": [
                "test_wrapper_serializes_pickle_output"
            ],
            "84": [
                "test_wrapper_serializes_pickle_output"
            ],
            "85": [],
            "86": [],
            "87": [
                "test_wrapper_serializes_json_output"
            ],
            "88": [
                "test_wrapper_serializes_json_output"
            ],
            "89": [
                "test_wrapper_serializes_json_output"
            ],
            "90": [
                "test_wrapper_serializes_json_output"
            ],
            "91": [
                "test_wrapper_serializes_json_output"
            ],
            "92": [
                "test_wrapper_serializes_json_output"
            ],
            "93": [
                "test_wrapper_serializes_json_output"
            ],
            "94": [
                "test_wrapper_serializes_json_output"
            ],
            "95": [
                "test_wrapper_serializes_json_output"
            ],
            "96": [
                "test_wrapper_serializes_json_output"
            ],
            "97": [
                "test_wrapper_serializes_json_output"
            ],
            "98": [
                "test_wrapper_serializes_json_output"
            ],
            "99": [
                "test_wrapper_serializes_json_output"
            ],
            "100": [
                "test_wrapper_serializes_json_output"
            ],
            "101": [],
            "102": [],
            "103": [
                "create_pickle_input"
            ],
            "104": [
                "create_pickle_input"
            ],
            "105": [
                "create_pickle_input"
            ],
            "106": [
                "create_pickle_input"
            ],
            "107": [
                "create_pickle_input"
            ],
            "108": [
                "create_pickle_input"
            ],
            "109": [
                "create_pickle_input"
            ],
            "110": [
                "create_pickle_input"
            ],
            "111": [
                "create_pickle_input"
            ],
            "114": [
                "file_echoes_db"
            ],
            "115": [
                "file_echoes_db"
            ],
            "116": [
                "file_echoes_db"
            ],
            "117": [
                "file_echoes_db"
            ],
            "119": [
                "file_echoes_db"
            ],
            "172": [
                "test_sparql_docker_wrapper_passes_dataframe"
            ]
        },
        "addLocation": []
    },
    "vantage6-client/tests/test_serialization.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import pickle"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from pytest import mark"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from vantage6.tools import serialization"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import pandas as pd"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from vantage6.tools.data_format import DataFormat"
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-JSON = 'json'"
            },
            "10": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "11": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " @mark.parametrize(\"data,target\", ["
            },
            "13": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     # Default serialization"
            },
            "14": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 11,
                "PatchRowcode": "     ({'hello': 'goodbye'}, '{\"hello\": \"goodbye\"}'),"
            },
            "15": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 13,
                "PatchRowcode": "     # Pandas serialization"
            },
            "17": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    (pd.DataFrame([[1, 2, 3]], columns=['one', 'two', 'three']), '{\"one\":{\"0\":1},\"two\":{\"0\":2},\"three\":{\"0\":3}}'),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+    (pd.DataFrame([[1, 2, 3]], columns=['one', 'two', 'three']),"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+     '{\"one\":{\"0\":1},\"two\":{\"0\":2},\"three\":{\"0\":3}}'),"
            },
            "20": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 16,
                "PatchRowcode": "     (pd.Series([1, 2, 3]), '{\"0\":1,\"1\":2,\"2\":3}')"
            },
            "21": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " ])"
            },
            "22": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " def test_json_serialization(data, target):"
            },
            "23": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    result = serialization.serialize(data, DataFormat.JSON)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+    result = serialization.serialize(data)"
            },
            "25": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     assert target == result.decode()"
            },
            "27": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "28": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "29": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-@mark.parametrize(\"data\", ["
            },
            "30": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ({'key': 'value'}),"
            },
            "31": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    (123),"
            },
            "32": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ([1, 2, 3]),"
            },
            "33": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-])"
            },
            "34": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_pickle_serialization(data):"
            },
            "35": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    pickled = serialization.serialize(data, DataFormat.PICKLE)"
            },
            "36": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "37": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    assert data == pickle.loads(pickled)"
            },
            "38": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "39": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "40": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def test_pickle_serialization_pandas():"
            },
            "41": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    data = pd.DataFrame([1, 2, 3])"
            },
            "42": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    pickled = serialization.serialize(data, DataFormat.PICKLE)"
            },
            "43": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "44": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    pd.testing.assert_frame_equal(data, pickle.loads(pickled))"
            }
        },
        "frontPatchFile": [
            "import pickle",
            "",
            "from pytest import mark",
            "",
            "from vantage6.tools import serialization",
            "import pandas as pd",
            "",
            "from vantage6.tools.data_format import DataFormat",
            "",
            "JSON = 'json'",
            "",
            "",
            "@mark.parametrize(\"data,target\", [",
            "    # Default serialization",
            "    ([1, 2, 3], '[1, 2, 3]'),",
            "    ('hello', '\"hello\"'),",
            "    ({'hello': 'goodbye'}, '{\"hello\": \"goodbye\"}'),",
            "",
            "    # Pandas serialization",
            "    (pd.DataFrame([[1, 2, 3]], columns=['one', 'two', 'three']), '{\"one\":{\"0\":1},\"two\":{\"0\":2},\"three\":{\"0\":3}}'),",
            "    (pd.Series([1, 2, 3]), '{\"0\":1,\"1\":2,\"2\":3}')",
            "])",
            "def test_json_serialization(data, target):",
            "    result = serialization.serialize(data, DataFormat.JSON)",
            "",
            "    assert target == result.decode()",
            "",
            "",
            "@mark.parametrize(\"data\", [",
            "    ({'key': 'value'}),",
            "    (123),",
            "    ([1, 2, 3]),",
            "])",
            "def test_pickle_serialization(data):",
            "    pickled = serialization.serialize(data, DataFormat.PICKLE)",
            "",
            "    assert data == pickle.loads(pickled)",
            "",
            "",
            "def test_pickle_serialization_pandas():",
            "    data = pd.DataFrame([1, 2, 3])",
            "    pickled = serialization.serialize(data, DataFormat.PICKLE)",
            "",
            "    pd.testing.assert_frame_equal(data, pickle.loads(pickled))"
        ],
        "afterPatchFile": [
            "from pytest import mark",
            "",
            "from vantage6.tools import serialization",
            "import pandas as pd",
            "",
            "",
            "@mark.parametrize(\"data,target\", [",
            "    # Default serialization",
            "    ([1, 2, 3], '[1, 2, 3]'),",
            "    ('hello', '\"hello\"'),",
            "    ({'hello': 'goodbye'}, '{\"hello\": \"goodbye\"}'),",
            "",
            "    # Pandas serialization",
            "    (pd.DataFrame([[1, 2, 3]], columns=['one', 'two', 'three']),",
            "     '{\"one\":{\"0\":1},\"two\":{\"0\":2},\"three\":{\"0\":3}}'),",
            "    (pd.Series([1, 2, 3]), '{\"0\":1,\"1\":2,\"2\":3}')",
            "])",
            "def test_json_serialization(data, target):",
            "    result = serialization.serialize(data)",
            "",
            "    assert target == result.decode()"
        ],
        "action": [
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "1": [],
            "2": [],
            "8": [],
            "9": [],
            "10": [
                "JSON"
            ],
            "11": [],
            "20": [],
            "24": [
                "test_json_serialization"
            ],
            "27": [],
            "28": [],
            "29": [],
            "30": [],
            "31": [],
            "32": [],
            "33": [],
            "34": [
                "test_pickle_serialization"
            ],
            "35": [
                "test_pickle_serialization"
            ],
            "36": [
                "test_pickle_serialization"
            ],
            "37": [
                "test_pickle_serialization"
            ],
            "38": [],
            "39": [],
            "40": [
                "test_pickle_serialization_pandas"
            ],
            "41": [
                "test_pickle_serialization_pandas"
            ],
            "42": [
                "test_pickle_serialization_pandas"
            ],
            "43": [
                "test_pickle_serialization_pandas"
            ],
            "44": [
                "test_pickle_serialization_pandas"
            ]
        },
        "addLocation": []
    }
}