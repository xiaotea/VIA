{
    ".github/scripts/check_diff.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import json"
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import os"
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import sys"
            },
            "3": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import tomllib"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from collections import defaultdict"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from typing import Dict, List, Set"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from pathlib import Path"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+import tomllib"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from get_min_versions import get_min_version_from_toml"
            },
            "10": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " LANGCHAIN_DIRS = ["
            },
            "13": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 18,
                "PatchRowcode": "     \"libs/experimental\","
            },
            "14": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " ]"
            },
            "15": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+# when set to True, we are ignoring core dependents"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+# in order to be able to get CI to pass for each individual"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+# package that depends on core"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+# e.g. if you touch core, we don't then add textsplitters/etc to CI"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+IGNORE_CORE_DEPENDENTS = False"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " # ignored partners are removed from dependents"
            },
            "23": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " # but still run if directly edited"
            },
            "24": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " IGNORED_PARTNERS = ["
            },
            "25": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 107,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 109,
                "PatchRowcode": " def _get_configs_for_single_dir(job: str, dir_: str) -> List[Dict[str, str]]:"
            },
            "28": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dir_ == \"libs/core\":"
            },
            "29": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return ["
            },
            "30": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {\"working-directory\": dir_, \"python-version\": f\"3.{v}\"}"
            },
            "31": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            for v in range(8, 13)"
            },
            "32": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ]"
            },
            "33": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    min_python = \"3.8\""
            },
            "34": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    max_python = \"3.12\""
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+    if job == \"test-pydantic\":"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        return _get_pydantic_test_configs(dir_)"
            },
            "37": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 112,
                "PatchRowcode": " "
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+    if dir_ == \"libs/core\":"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+        py_versions = [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]"
            },
            "40": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     # custom logic for specific directories"
            },
            "41": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dir_ == \"libs/partners/milvus\":"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+    elif dir_ == \"libs/partners/milvus\":"
            },
            "43": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 117,
                "PatchRowcode": "         # milvus poetry doesn't allow 3.12 because they"
            },
            "44": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "         # declare deps in funny way"
            },
            "45": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        max_python = \"3.11\""
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+        py_versions = [\"3.9\", \"3.11\"]"
            },
            "47": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 120,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+    elif dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":"
            },
            "50": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "         # community extended test resolution in 3.12 is slow"
            },
            "51": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         # even in uv"
            },
            "52": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        max_python = \"3.11\""
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+        py_versions = [\"3.9\", \"3.11\"]"
            },
            "54": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 125,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dir_ == \"libs/community\" and job == \"compile-integration-tests\":"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+    elif dir_ == \"libs/community\" and job == \"compile-integration-tests\":"
            },
            "57": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         # community integration deps are slow in 3.12"
            },
            "58": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        max_python = \"3.11\""
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+        py_versions = [\"3.9\", \"3.11\"]"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+    else:"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+        py_versions = [\"3.9\", \"3.12\"]"
            },
            "62": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 131,
                "PatchRowcode": " "
            },
            "63": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return ["
            },
            "64": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        {\"working-directory\": dir_, \"python-version\": min_python},"
            },
            "65": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        {\"working-directory\": dir_, \"python-version\": max_python},"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+    return [{\"working-directory\": dir_, \"python-version\": py_v} for py_v in py_versions]"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 134,
                "PatchRowcode": "+"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+def _get_pydantic_test_configs("
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+    dir_: str, *, python_version: str = \"3.11\""
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+) -> List[Dict[str, str]]:"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+    with open(\"./libs/core/poetry.lock\", \"rb\") as f:"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+        core_poetry_lock_data = tomllib.load(f)"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+    for package in core_poetry_lock_data[\"package\"]:"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+        if package[\"name\"] == \"pydantic\":"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+            core_max_pydantic_minor = package[\"version\"].split(\".\")[1]"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+            break"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+    with open(f\"./{dir_}/poetry.lock\", \"rb\") as f:"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+        dir_poetry_lock_data = tomllib.load(f)"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+    for package in dir_poetry_lock_data[\"package\"]:"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+        if package[\"name\"] == \"pydantic\":"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+            dir_max_pydantic_minor = package[\"version\"].split(\".\")[1]"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+            break"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+    core_min_pydantic_version = get_min_version_from_toml("
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+        \"./libs/core/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+    )[\"pydantic\"]"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+    core_min_pydantic_minor = core_min_pydantic_version.split(\".\")[1] if \".\" in core_min_pydantic_version else \"0\""
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+    dir_min_pydantic_version = ("
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+        get_min_version_from_toml("
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+            f\"./{dir_}/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+        )"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+        .get(\"pydantic\", \"0.0.0\")"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 162,
                "PatchRowcode": "+    )"
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+    dir_min_pydantic_minor = dir_min_pydantic_version.split(\".\")[1] if \".\" in dir_min_pydantic_version else \"0\""
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 164,
                "PatchRowcode": "+"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+    custom_mins = {"
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+        # depends on pydantic-settings 2.4 which requires pydantic 2.7"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+        \"libs/community\": 7,"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+    }"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+    max_pydantic_minor = min("
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+        int(dir_max_pydantic_minor),"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+        int(core_max_pydantic_minor),"
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+    )"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+    min_pydantic_minor = max("
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+        int(dir_min_pydantic_minor),"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+        int(core_min_pydantic_minor),"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+        custom_mins.get(dir_, 0),"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 178,
                "PatchRowcode": "+    )"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 179,
                "PatchRowcode": "+"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+    configs = ["
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+        {"
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+            \"working-directory\": dir_,"
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+            \"pydantic-version\": f\"2.{v}.0\","
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+            \"python-version\": python_version,"
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+        }"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 186,
                "PatchRowcode": "+        for v in range(min_pydantic_minor, max_pydantic_minor + 1)"
            },
            "121": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "     ]"
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+    return configs"
            },
            "123": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 189,
                "PatchRowcode": " "
            },
            "124": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 190,
                "PatchRowcode": " "
            },
            "125": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 191,
                "PatchRowcode": " def _get_configs_for_multi_dirs("
            },
            "126": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    job: str, dirs_to_run: List[str], dependents: dict"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 192,
                "PatchRowcode": "+    job: str, dirs_to_run: Dict[str, Set[str]], dependents: dict"
            },
            "128": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 193,
                "PatchRowcode": " ) -> List[Dict[str, str]]:"
            },
            "129": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 194,
                "PatchRowcode": "     if job == \"lint\":"
            },
            "130": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "         dirs = add_dependents("
            },
            "131": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 196,
                "PatchRowcode": "             dirs_to_run[\"lint\"] | dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"],"
            },
            "132": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "             dependents,"
            },
            "133": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "         )"
            },
            "134": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\"]:"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\", \"test-pydantic\"]:"
            },
            "136": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "         dirs = add_dependents("
            },
            "137": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "             dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"], dependents"
            },
            "138": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "         )"
            },
            "139": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "         dirs_to_run[\"lint\"] = all_package_dirs()"
            },
            "140": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 226,
                "PatchRowcode": "         dirs_to_run[\"test\"] = all_package_dirs()"
            },
            "141": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 227,
                "PatchRowcode": "         dirs_to_run[\"extended-test\"] = set(LANGCHAIN_DIRS)"
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+"
            },
            "143": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "     for file in files:"
            },
            "144": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 230,
                "PatchRowcode": "         if any("
            },
            "145": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 231,
                "PatchRowcode": "             file.startswith(dir_)"
            },
            "146": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "         if any(file.startswith(dir_) for dir_ in LANGCHAIN_DIRS):"
            },
            "147": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "             # add that dir and all dirs after in LANGCHAIN_DIRS"
            },
            "148": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 245,
                "PatchRowcode": "             # for extended testing"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+"
            },
            "150": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "             found = False"
            },
            "151": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 248,
                "PatchRowcode": "             for dir_ in LANGCHAIN_DIRS:"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+                if dir_ == \"libs/core\" and IGNORE_CORE_DEPENDENTS:"
            },
            "153": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+                    dirs_to_run[\"extended-test\"].add(dir_)"
            },
            "154": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+                    continue"
            },
            "155": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 252,
                "PatchRowcode": "                 if file.startswith(dir_):"
            },
            "156": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 253,
                "PatchRowcode": "                     found = True"
            },
            "157": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 254,
                "PatchRowcode": "                 if found:"
            },
            "158": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": 289,
                "PatchRowcode": " "
            },
            "159": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 290,
                "PatchRowcode": "     # we now have dirs_by_job"
            },
            "160": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "     # todo: clean this up"
            },
            "161": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "162": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 292,
                "PatchRowcode": "     map_job_to_configs = {"
            },
            "163": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 293,
                "PatchRowcode": "         job: _get_configs_for_multi_dirs(job, dirs_to_run, dependents)"
            },
            "164": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 294,
                "PatchRowcode": "         for job in ["
            },
            "165": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 297,
                "PatchRowcode": "             \"extended-tests\","
            },
            "166": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 298,
                "PatchRowcode": "             \"compile-integration-tests\","
            },
            "167": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 299,
                "PatchRowcode": "             \"dependencies\","
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 300,
                "PatchRowcode": "+            \"test-pydantic\","
            },
            "169": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 301,
                "PatchRowcode": "         ]"
            },
            "170": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 302,
                "PatchRowcode": "     }"
            },
            "171": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 303,
                "PatchRowcode": "     map_job_to_configs[\"test-doc-imports\"] = ("
            }
        },
        "frontPatchFile": [
            "import glob",
            "import json",
            "import os",
            "import sys",
            "import tomllib",
            "from collections import defaultdict",
            "from typing import Dict, List, Set",
            "from pathlib import Path",
            "",
            "",
            "LANGCHAIN_DIRS = [",
            "    \"libs/core\",",
            "    \"libs/text-splitters\",",
            "    \"libs/langchain\",",
            "    \"libs/community\",",
            "    \"libs/experimental\",",
            "]",
            "",
            "# ignored partners are removed from dependents",
            "# but still run if directly edited",
            "IGNORED_PARTNERS = [",
            "    # remove huggingface from dependents because of CI instability",
            "    # specifically in huggingface jobs",
            "    # https://github.com/langchain-ai/langchain/issues/25558",
            "    \"huggingface\",",
            "]",
            "",
            "",
            "def all_package_dirs() -> Set[str]:",
            "    return {",
            "        \"/\".join(path.split(\"/\")[:-1]).lstrip(\"./\")",
            "        for path in glob.glob(\"./libs/**/pyproject.toml\", recursive=True)",
            "        if \"libs/cli\" not in path and \"libs/standard-tests\" not in path",
            "    }",
            "",
            "",
            "def dependents_graph() -> dict:",
            "    \"\"\"",
            "    Construct a mapping of package -> dependents, such that we can",
            "    run tests on all dependents of a package when a change is made.",
            "    \"\"\"",
            "    dependents = defaultdict(set)",
            "",
            "    for path in glob.glob(\"./libs/**/pyproject.toml\", recursive=True):",
            "        if \"template\" in path:",
            "            continue",
            "",
            "        # load regular and test deps from pyproject.toml",
            "        with open(path, \"rb\") as f:",
            "            pyproject = tomllib.load(f)[\"tool\"][\"poetry\"]",
            "",
            "        pkg_dir = \"libs\" + \"/\".join(path.split(\"libs\")[1].split(\"/\")[:-1])",
            "        for dep in [",
            "            *pyproject[\"dependencies\"].keys(),",
            "            *pyproject[\"group\"][\"test\"][\"dependencies\"].keys(),",
            "        ]:",
            "            if \"langchain\" in dep:",
            "                dependents[dep].add(pkg_dir)",
            "                continue",
            "",
            "        # load extended deps from extended_testing_deps.txt",
            "        package_path = Path(path).parent",
            "        extended_requirement_path = package_path / \"extended_testing_deps.txt\"",
            "        if extended_requirement_path.exists():",
            "            with open(extended_requirement_path, \"r\") as f:",
            "                extended_deps = f.read().splitlines()",
            "                for depline in extended_deps:",
            "                    if depline.startswith(\"-e \"):",
            "                        # editable dependency",
            "                        assert depline.startswith(",
            "                            \"-e ../partners/\"",
            "                        ), \"Extended test deps should only editable install partner packages\"",
            "                        partner = depline.split(\"partners/\")[1]",
            "                        dep = f\"langchain-{partner}\"",
            "                    else:",
            "                        dep = depline.split(\"==\")[0]",
            "",
            "                    if \"langchain\" in dep:",
            "                        dependents[dep].add(pkg_dir)",
            "",
            "    for k in dependents:",
            "        for partner in IGNORED_PARTNERS:",
            "            if f\"libs/partners/{partner}\" in dependents[k]:",
            "                dependents[k].remove(f\"libs/partners/{partner}\")",
            "    return dependents",
            "",
            "",
            "def add_dependents(dirs_to_eval: Set[str], dependents: dict) -> List[str]:",
            "    updated = set()",
            "    for dir_ in dirs_to_eval:",
            "        # handle core manually because it has so many dependents",
            "        if \"core\" in dir_:",
            "            updated.add(dir_)",
            "            continue",
            "        pkg = \"langchain-\" + dir_.split(\"/\")[-1]",
            "        updated.update(dependents[pkg])",
            "        updated.add(dir_)",
            "    return list(updated)",
            "",
            "",
            "def _get_configs_for_single_dir(job: str, dir_: str) -> List[Dict[str, str]]:",
            "    if dir_ == \"libs/core\":",
            "        return [",
            "            {\"working-directory\": dir_, \"python-version\": f\"3.{v}\"}",
            "            for v in range(8, 13)",
            "        ]",
            "    min_python = \"3.8\"",
            "    max_python = \"3.12\"",
            "",
            "    # custom logic for specific directories",
            "    if dir_ == \"libs/partners/milvus\":",
            "        # milvus poetry doesn't allow 3.12 because they",
            "        # declare deps in funny way",
            "        max_python = \"3.11\"",
            "",
            "    if dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":",
            "        # community extended test resolution in 3.12 is slow",
            "        # even in uv",
            "        max_python = \"3.11\"",
            "",
            "    if dir_ == \"libs/community\" and job == \"compile-integration-tests\":",
            "        # community integration deps are slow in 3.12",
            "        max_python = \"3.11\"",
            "",
            "    return [",
            "        {\"working-directory\": dir_, \"python-version\": min_python},",
            "        {\"working-directory\": dir_, \"python-version\": max_python},",
            "    ]",
            "",
            "",
            "def _get_configs_for_multi_dirs(",
            "    job: str, dirs_to_run: List[str], dependents: dict",
            ") -> List[Dict[str, str]]:",
            "    if job == \"lint\":",
            "        dirs = add_dependents(",
            "            dirs_to_run[\"lint\"] | dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"],",
            "            dependents,",
            "        )",
            "    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\"]:",
            "        dirs = add_dependents(",
            "            dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"], dependents",
            "        )",
            "    elif job == \"extended-tests\":",
            "        dirs = list(dirs_to_run[\"extended-test\"])",
            "    else:",
            "        raise ValueError(f\"Unknown job: {job}\")",
            "",
            "    return [",
            "        config for dir_ in dirs for config in _get_configs_for_single_dir(job, dir_)",
            "    ]",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    files = sys.argv[1:]",
            "",
            "    dirs_to_run: Dict[str, set] = {",
            "        \"lint\": set(),",
            "        \"test\": set(),",
            "        \"extended-test\": set(),",
            "    }",
            "    docs_edited = False",
            "",
            "    if len(files) >= 300:",
            "        # max diff length is 300 files - there are likely files missing",
            "        dirs_to_run[\"lint\"] = all_package_dirs()",
            "        dirs_to_run[\"test\"] = all_package_dirs()",
            "        dirs_to_run[\"extended-test\"] = set(LANGCHAIN_DIRS)",
            "    for file in files:",
            "        if any(",
            "            file.startswith(dir_)",
            "            for dir_ in (",
            "                \".github/workflows\",",
            "                \".github/tools\",",
            "                \".github/actions\",",
            "                \".github/scripts/check_diff.py\",",
            "            )",
            "        ):",
            "            # add all LANGCHAIN_DIRS for infra changes",
            "            dirs_to_run[\"extended-test\"].update(LANGCHAIN_DIRS)",
            "            dirs_to_run[\"lint\"].add(\".\")",
            "",
            "        if any(file.startswith(dir_) for dir_ in LANGCHAIN_DIRS):",
            "            # add that dir and all dirs after in LANGCHAIN_DIRS",
            "            # for extended testing",
            "            found = False",
            "            for dir_ in LANGCHAIN_DIRS:",
            "                if file.startswith(dir_):",
            "                    found = True",
            "                if found:",
            "                    dirs_to_run[\"extended-test\"].add(dir_)",
            "        elif file.startswith(\"libs/standard-tests\"):",
            "            # TODO: update to include all packages that rely on standard-tests (all partner packages)",
            "            # note: won't run on external repo partners",
            "            dirs_to_run[\"lint\"].add(\"libs/standard-tests\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/mistralai\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/openai\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/anthropic\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/fireworks\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/groq\")",
            "",
            "        elif file.startswith(\"libs/cli\"):",
            "            # todo: add cli makefile",
            "            pass",
            "        elif file.startswith(\"libs/partners\"):",
            "            partner_dir = file.split(\"/\")[2]",
            "            if os.path.isdir(f\"libs/partners/{partner_dir}\") and [",
            "                filename",
            "                for filename in os.listdir(f\"libs/partners/{partner_dir}\")",
            "                if not filename.startswith(\".\")",
            "            ] != [\"README.md\"]:",
            "                dirs_to_run[\"test\"].add(f\"libs/partners/{partner_dir}\")",
            "            # Skip if the directory was deleted or is just a tombstone readme",
            "        elif file.startswith(\"libs/\"):",
            "            raise ValueError(",
            "                f\"Unknown lib: {file}. check_diff.py likely needs \"",
            "                \"an update for this new library!\"",
            "            )",
            "        elif any(file.startswith(p) for p in [\"docs/\", \"templates/\", \"cookbook/\"]):",
            "            if file.startswith(\"docs/\"):",
            "                docs_edited = True",
            "            dirs_to_run[\"lint\"].add(\".\")",
            "",
            "    dependents = dependents_graph()",
            "",
            "    # we now have dirs_by_job",
            "    # todo: clean this up",
            "",
            "    map_job_to_configs = {",
            "        job: _get_configs_for_multi_dirs(job, dirs_to_run, dependents)",
            "        for job in [",
            "            \"lint\",",
            "            \"test\",",
            "            \"extended-tests\",",
            "            \"compile-integration-tests\",",
            "            \"dependencies\",",
            "        ]",
            "    }",
            "    map_job_to_configs[\"test-doc-imports\"] = (",
            "        [{\"python-version\": \"3.12\"}] if docs_edited else []",
            "    )",
            "",
            "    for key, value in map_job_to_configs.items():",
            "        json_output = json.dumps(value)",
            "        print(f\"{key}={json_output}\")"
        ],
        "afterPatchFile": [
            "import glob",
            "import json",
            "import os",
            "import sys",
            "from collections import defaultdict",
            "from typing import Dict, List, Set",
            "from pathlib import Path",
            "import tomllib",
            "",
            "from get_min_versions import get_min_version_from_toml",
            "",
            "",
            "LANGCHAIN_DIRS = [",
            "    \"libs/core\",",
            "    \"libs/text-splitters\",",
            "    \"libs/langchain\",",
            "    \"libs/community\",",
            "    \"libs/experimental\",",
            "]",
            "",
            "# when set to True, we are ignoring core dependents",
            "# in order to be able to get CI to pass for each individual",
            "# package that depends on core",
            "# e.g. if you touch core, we don't then add textsplitters/etc to CI",
            "IGNORE_CORE_DEPENDENTS = False",
            "",
            "# ignored partners are removed from dependents",
            "# but still run if directly edited",
            "IGNORED_PARTNERS = [",
            "    # remove huggingface from dependents because of CI instability",
            "    # specifically in huggingface jobs",
            "    # https://github.com/langchain-ai/langchain/issues/25558",
            "    \"huggingface\",",
            "]",
            "",
            "",
            "def all_package_dirs() -> Set[str]:",
            "    return {",
            "        \"/\".join(path.split(\"/\")[:-1]).lstrip(\"./\")",
            "        for path in glob.glob(\"./libs/**/pyproject.toml\", recursive=True)",
            "        if \"libs/cli\" not in path and \"libs/standard-tests\" not in path",
            "    }",
            "",
            "",
            "def dependents_graph() -> dict:",
            "    \"\"\"",
            "    Construct a mapping of package -> dependents, such that we can",
            "    run tests on all dependents of a package when a change is made.",
            "    \"\"\"",
            "    dependents = defaultdict(set)",
            "",
            "    for path in glob.glob(\"./libs/**/pyproject.toml\", recursive=True):",
            "        if \"template\" in path:",
            "            continue",
            "",
            "        # load regular and test deps from pyproject.toml",
            "        with open(path, \"rb\") as f:",
            "            pyproject = tomllib.load(f)[\"tool\"][\"poetry\"]",
            "",
            "        pkg_dir = \"libs\" + \"/\".join(path.split(\"libs\")[1].split(\"/\")[:-1])",
            "        for dep in [",
            "            *pyproject[\"dependencies\"].keys(),",
            "            *pyproject[\"group\"][\"test\"][\"dependencies\"].keys(),",
            "        ]:",
            "            if \"langchain\" in dep:",
            "                dependents[dep].add(pkg_dir)",
            "                continue",
            "",
            "        # load extended deps from extended_testing_deps.txt",
            "        package_path = Path(path).parent",
            "        extended_requirement_path = package_path / \"extended_testing_deps.txt\"",
            "        if extended_requirement_path.exists():",
            "            with open(extended_requirement_path, \"r\") as f:",
            "                extended_deps = f.read().splitlines()",
            "                for depline in extended_deps:",
            "                    if depline.startswith(\"-e \"):",
            "                        # editable dependency",
            "                        assert depline.startswith(",
            "                            \"-e ../partners/\"",
            "                        ), \"Extended test deps should only editable install partner packages\"",
            "                        partner = depline.split(\"partners/\")[1]",
            "                        dep = f\"langchain-{partner}\"",
            "                    else:",
            "                        dep = depline.split(\"==\")[0]",
            "",
            "                    if \"langchain\" in dep:",
            "                        dependents[dep].add(pkg_dir)",
            "",
            "    for k in dependents:",
            "        for partner in IGNORED_PARTNERS:",
            "            if f\"libs/partners/{partner}\" in dependents[k]:",
            "                dependents[k].remove(f\"libs/partners/{partner}\")",
            "    return dependents",
            "",
            "",
            "def add_dependents(dirs_to_eval: Set[str], dependents: dict) -> List[str]:",
            "    updated = set()",
            "    for dir_ in dirs_to_eval:",
            "        # handle core manually because it has so many dependents",
            "        if \"core\" in dir_:",
            "            updated.add(dir_)",
            "            continue",
            "        pkg = \"langchain-\" + dir_.split(\"/\")[-1]",
            "        updated.update(dependents[pkg])",
            "        updated.add(dir_)",
            "    return list(updated)",
            "",
            "",
            "def _get_configs_for_single_dir(job: str, dir_: str) -> List[Dict[str, str]]:",
            "    if job == \"test-pydantic\":",
            "        return _get_pydantic_test_configs(dir_)",
            "",
            "    if dir_ == \"libs/core\":",
            "        py_versions = [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]",
            "    # custom logic for specific directories",
            "    elif dir_ == \"libs/partners/milvus\":",
            "        # milvus poetry doesn't allow 3.12 because they",
            "        # declare deps in funny way",
            "        py_versions = [\"3.9\", \"3.11\"]",
            "",
            "    elif dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":",
            "        # community extended test resolution in 3.12 is slow",
            "        # even in uv",
            "        py_versions = [\"3.9\", \"3.11\"]",
            "",
            "    elif dir_ == \"libs/community\" and job == \"compile-integration-tests\":",
            "        # community integration deps are slow in 3.12",
            "        py_versions = [\"3.9\", \"3.11\"]",
            "    else:",
            "        py_versions = [\"3.9\", \"3.12\"]",
            "",
            "    return [{\"working-directory\": dir_, \"python-version\": py_v} for py_v in py_versions]",
            "",
            "",
            "def _get_pydantic_test_configs(",
            "    dir_: str, *, python_version: str = \"3.11\"",
            ") -> List[Dict[str, str]]:",
            "    with open(\"./libs/core/poetry.lock\", \"rb\") as f:",
            "        core_poetry_lock_data = tomllib.load(f)",
            "    for package in core_poetry_lock_data[\"package\"]:",
            "        if package[\"name\"] == \"pydantic\":",
            "            core_max_pydantic_minor = package[\"version\"].split(\".\")[1]",
            "            break",
            "",
            "    with open(f\"./{dir_}/poetry.lock\", \"rb\") as f:",
            "        dir_poetry_lock_data = tomllib.load(f)",
            "",
            "    for package in dir_poetry_lock_data[\"package\"]:",
            "        if package[\"name\"] == \"pydantic\":",
            "            dir_max_pydantic_minor = package[\"version\"].split(\".\")[1]",
            "            break",
            "",
            "    core_min_pydantic_version = get_min_version_from_toml(",
            "        \"./libs/core/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]",
            "    )[\"pydantic\"]",
            "    core_min_pydantic_minor = core_min_pydantic_version.split(\".\")[1] if \".\" in core_min_pydantic_version else \"0\"",
            "    dir_min_pydantic_version = (",
            "        get_min_version_from_toml(",
            "            f\"./{dir_}/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]",
            "        )",
            "        .get(\"pydantic\", \"0.0.0\")",
            "    )",
            "    dir_min_pydantic_minor = dir_min_pydantic_version.split(\".\")[1] if \".\" in dir_min_pydantic_version else \"0\"",
            "",
            "    custom_mins = {",
            "        # depends on pydantic-settings 2.4 which requires pydantic 2.7",
            "        \"libs/community\": 7,",
            "    }",
            "",
            "    max_pydantic_minor = min(",
            "        int(dir_max_pydantic_minor),",
            "        int(core_max_pydantic_minor),",
            "    )",
            "    min_pydantic_minor = max(",
            "        int(dir_min_pydantic_minor),",
            "        int(core_min_pydantic_minor),",
            "        custom_mins.get(dir_, 0),",
            "    )",
            "",
            "    configs = [",
            "        {",
            "            \"working-directory\": dir_,",
            "            \"pydantic-version\": f\"2.{v}.0\",",
            "            \"python-version\": python_version,",
            "        }",
            "        for v in range(min_pydantic_minor, max_pydantic_minor + 1)",
            "    ]",
            "    return configs",
            "",
            "",
            "def _get_configs_for_multi_dirs(",
            "    job: str, dirs_to_run: Dict[str, Set[str]], dependents: dict",
            ") -> List[Dict[str, str]]:",
            "    if job == \"lint\":",
            "        dirs = add_dependents(",
            "            dirs_to_run[\"lint\"] | dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"],",
            "            dependents,",
            "        )",
            "    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\", \"test-pydantic\"]:",
            "        dirs = add_dependents(",
            "            dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"], dependents",
            "        )",
            "    elif job == \"extended-tests\":",
            "        dirs = list(dirs_to_run[\"extended-test\"])",
            "    else:",
            "        raise ValueError(f\"Unknown job: {job}\")",
            "",
            "    return [",
            "        config for dir_ in dirs for config in _get_configs_for_single_dir(job, dir_)",
            "    ]",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    files = sys.argv[1:]",
            "",
            "    dirs_to_run: Dict[str, set] = {",
            "        \"lint\": set(),",
            "        \"test\": set(),",
            "        \"extended-test\": set(),",
            "    }",
            "    docs_edited = False",
            "",
            "    if len(files) >= 300:",
            "        # max diff length is 300 files - there are likely files missing",
            "        dirs_to_run[\"lint\"] = all_package_dirs()",
            "        dirs_to_run[\"test\"] = all_package_dirs()",
            "        dirs_to_run[\"extended-test\"] = set(LANGCHAIN_DIRS)",
            "",
            "    for file in files:",
            "        if any(",
            "            file.startswith(dir_)",
            "            for dir_ in (",
            "                \".github/workflows\",",
            "                \".github/tools\",",
            "                \".github/actions\",",
            "                \".github/scripts/check_diff.py\",",
            "            )",
            "        ):",
            "            # add all LANGCHAIN_DIRS for infra changes",
            "            dirs_to_run[\"extended-test\"].update(LANGCHAIN_DIRS)",
            "            dirs_to_run[\"lint\"].add(\".\")",
            "",
            "        if any(file.startswith(dir_) for dir_ in LANGCHAIN_DIRS):",
            "            # add that dir and all dirs after in LANGCHAIN_DIRS",
            "            # for extended testing",
            "",
            "            found = False",
            "            for dir_ in LANGCHAIN_DIRS:",
            "                if dir_ == \"libs/core\" and IGNORE_CORE_DEPENDENTS:",
            "                    dirs_to_run[\"extended-test\"].add(dir_)",
            "                    continue",
            "                if file.startswith(dir_):",
            "                    found = True",
            "                if found:",
            "                    dirs_to_run[\"extended-test\"].add(dir_)",
            "        elif file.startswith(\"libs/standard-tests\"):",
            "            # TODO: update to include all packages that rely on standard-tests (all partner packages)",
            "            # note: won't run on external repo partners",
            "            dirs_to_run[\"lint\"].add(\"libs/standard-tests\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/mistralai\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/openai\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/anthropic\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/fireworks\")",
            "            dirs_to_run[\"test\"].add(\"libs/partners/groq\")",
            "",
            "        elif file.startswith(\"libs/cli\"):",
            "            # todo: add cli makefile",
            "            pass",
            "        elif file.startswith(\"libs/partners\"):",
            "            partner_dir = file.split(\"/\")[2]",
            "            if os.path.isdir(f\"libs/partners/{partner_dir}\") and [",
            "                filename",
            "                for filename in os.listdir(f\"libs/partners/{partner_dir}\")",
            "                if not filename.startswith(\".\")",
            "            ] != [\"README.md\"]:",
            "                dirs_to_run[\"test\"].add(f\"libs/partners/{partner_dir}\")",
            "            # Skip if the directory was deleted or is just a tombstone readme",
            "        elif file.startswith(\"libs/\"):",
            "            raise ValueError(",
            "                f\"Unknown lib: {file}. check_diff.py likely needs \"",
            "                \"an update for this new library!\"",
            "            )",
            "        elif any(file.startswith(p) for p in [\"docs/\", \"templates/\", \"cookbook/\"]):",
            "            if file.startswith(\"docs/\"):",
            "                docs_edited = True",
            "            dirs_to_run[\"lint\"].add(\".\")",
            "",
            "    dependents = dependents_graph()",
            "",
            "    # we now have dirs_by_job",
            "    # todo: clean this up",
            "    map_job_to_configs = {",
            "        job: _get_configs_for_multi_dirs(job, dirs_to_run, dependents)",
            "        for job in [",
            "            \"lint\",",
            "            \"test\",",
            "            \"extended-tests\",",
            "            \"compile-integration-tests\",",
            "            \"dependencies\",",
            "            \"test-pydantic\",",
            "        ]",
            "    }",
            "    map_job_to_configs[\"test-doc-imports\"] = (",
            "        [{\"python-version\": \"3.12\"}] if docs_edited else []",
            "    )",
            "",
            "    for key, value in map_job_to_configs.items():",
            "        json_output = json.dumps(value)",
            "        print(f\"{key}={json_output}\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "5": [],
            "102": [
                "_get_configs_for_single_dir"
            ],
            "103": [
                "_get_configs_for_single_dir"
            ],
            "104": [
                "_get_configs_for_single_dir"
            ],
            "105": [
                "_get_configs_for_single_dir"
            ],
            "106": [
                "_get_configs_for_single_dir"
            ],
            "107": [
                "_get_configs_for_single_dir"
            ],
            "108": [
                "_get_configs_for_single_dir"
            ],
            "111": [
                "_get_configs_for_single_dir"
            ],
            "114": [
                "_get_configs_for_single_dir"
            ],
            "116": [
                "_get_configs_for_single_dir"
            ],
            "119": [
                "_get_configs_for_single_dir"
            ],
            "121": [
                "_get_configs_for_single_dir"
            ],
            "123": [
                "_get_configs_for_single_dir"
            ],
            "125": [
                "_get_configs_for_single_dir"
            ],
            "126": [
                "_get_configs_for_single_dir"
            ],
            "127": [
                "_get_configs_for_single_dir"
            ],
            "132": [
                "_get_configs_for_multi_dirs"
            ],
            "139": [
                "_get_configs_for_multi_dirs"
            ],
            "227": []
        },
        "addLocation": []
    },
    ".github/scripts/check_prerelease_dependencies.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": "     # see if we're releasing an rc"
            },
            "2": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": "     version = toml_data[\"tool\"][\"poetry\"][\"version\"]"
            },
            "3": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    releasing_rc = \"rc\" in version"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+    releasing_rc = \"rc\" in version or \"dev\" in version"
            },
            "5": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": "     # if not, iterate through dependencies and make sure none allow prereleases"
            },
            "7": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": "     if not releasing_rc:"
            }
        },
        "frontPatchFile": [
            "import sys",
            "import tomllib",
            "",
            "if __name__ == \"__main__\":",
            "    # Get the TOML file path from the command line argument",
            "    toml_file = sys.argv[1]",
            "",
            "    # read toml file",
            "    with open(toml_file, \"rb\") as file:",
            "        toml_data = tomllib.load(file)",
            "",
            "    # see if we're releasing an rc",
            "    version = toml_data[\"tool\"][\"poetry\"][\"version\"]",
            "    releasing_rc = \"rc\" in version",
            "",
            "    # if not, iterate through dependencies and make sure none allow prereleases",
            "    if not releasing_rc:",
            "        dependencies = toml_data[\"tool\"][\"poetry\"][\"dependencies\"]",
            "        for lib in dependencies:",
            "            dep_version = dependencies[lib]",
            "            dep_version_string = (",
            "                dep_version[\"version\"] if isinstance(dep_version, dict) else dep_version",
            "            )",
            "",
            "            if \"rc\" in dep_version_string:",
            "                raise ValueError(",
            "                    f\"Dependency {lib} has a prerelease version. Please remove this.\"",
            "                )",
            "",
            "            if isinstance(dep_version, dict) and dep_version.get(",
            "                \"allow-prereleases\", False",
            "            ):",
            "                raise ValueError(",
            "                    f\"Dependency {lib} has allow-prereleases set to true. Please remove this.\"",
            "                )"
        ],
        "afterPatchFile": [
            "import sys",
            "import tomllib",
            "",
            "if __name__ == \"__main__\":",
            "    # Get the TOML file path from the command line argument",
            "    toml_file = sys.argv[1]",
            "",
            "    # read toml file",
            "    with open(toml_file, \"rb\") as file:",
            "        toml_data = tomllib.load(file)",
            "",
            "    # see if we're releasing an rc",
            "    version = toml_data[\"tool\"][\"poetry\"][\"version\"]",
            "    releasing_rc = \"rc\" in version or \"dev\" in version",
            "",
            "    # if not, iterate through dependencies and make sure none allow prereleases",
            "    if not releasing_rc:",
            "        dependencies = toml_data[\"tool\"][\"poetry\"][\"dependencies\"]",
            "        for lib in dependencies:",
            "            dep_version = dependencies[lib]",
            "            dep_version_string = (",
            "                dep_version[\"version\"] if isinstance(dep_version, dict) else dep_version",
            "            )",
            "",
            "            if \"rc\" in dep_version_string:",
            "                raise ValueError(",
            "                    f\"Dependency {lib} has a prerelease version. Please remove this.\"",
            "                )",
            "",
            "            if isinstance(dep_version, dict) and dep_version.get(",
            "                \"allow-prereleases\", False",
            "            ):",
            "                raise ValueError(",
            "                    f\"Dependency {lib} has allow-prereleases set to true. Please remove this.\"",
            "                )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "14": [
                "releasing_rc"
            ]
        },
        "addLocation": []
    },
    ".github/scripts/get_min_versions.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import sys"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+from typing import Optional"
            },
            "2": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " if sys.version_info >= (3, 11):"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": "     import tomllib"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     import tomli as tomllib"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from packaging.version import parse as parse_version"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 11,
                "PatchRowcode": "+from packaging.specifiers import SpecifierSet"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+from packaging.version import Version"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 13,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " import re"
            },
            "12": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " MIN_VERSION_LIBS = ["
            },
            "14": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 19,
                "PatchRowcode": "     \"langchain\","
            },
            "15": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 20,
                "PatchRowcode": "     \"langchain-text-splitters\","
            },
            "16": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     \"SQLAlchemy\","
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+    \"pydantic\","
            },
            "18": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " ]"
            },
            "19": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " SKIP_IF_PULL_REQUEST = [\"langchain-core\"]"
            },
            "21": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "     raise ValueError(f\"Unrecognized version format: {version}\")"
            },
            "22": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 52,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def get_min_version_from_toml(toml_path: str, versions_for: str):"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+def get_min_version_from_toml("
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+    toml_path: str,"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+    versions_for: str,"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+    python_version: str,"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+    *,"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+    include: Optional[list] = None,"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+):"
            },
            "32": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "     # Parse the TOML file"
            },
            "33": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "     with open(toml_path, \"rb\") as file:"
            },
            "34": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         toml_data = tomllib.load(file)"
            },
            "35": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "             continue"
            },
            "36": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "         # Check if the lib is present in the dependencies"
            },
            "37": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "         if lib in dependencies:"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+            if include and lib not in include:"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+                continue"
            },
            "40": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 80,
                "PatchRowcode": "             # Get the version string"
            },
            "41": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "             version_string = dependencies[lib]"
            },
            "42": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 82,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "             if isinstance(version_string, dict):"
            },
            "44": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "                 version_string = version_string[\"version\"]"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+            if isinstance(version_string, list):"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+                version_string = ["
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+                    vs"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+                    for vs in version_string"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+                    if check_python_version(python_version, vs[\"python\"])"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+                ][0][\"version\"]"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+"
            },
            "52": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 92,
                "PatchRowcode": " "
            },
            "53": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "             # Use parse_version to get the minimum supported version from version_string"
            },
            "54": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "             min_version = get_min_version(version_string)"
            },
            "55": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 99,
                "PatchRowcode": "     return min_versions"
            },
            "56": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 100,
                "PatchRowcode": " "
            },
            "57": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 101,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+def check_python_version(version_string, constraint_string):"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    \"\"\""
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+    Check if the given Python version matches the given constraints."
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+    :param version_string: A string representing the Python version (e.g. \"3.8.5\")."
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+    :param constraint_string: A string representing the package's Python version constraints (e.g. \">=3.6, <4.0\")."
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+    :return: True if the version matches the constraints, False otherwise."
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+    \"\"\""
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+    try:"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        version = Version(version_string)"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+        constraints = SpecifierSet(constraint_string)"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+        return version in constraints"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+    except Exception as e:"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 115,
                "PatchRowcode": "+        print(f\"Error: {e}\")"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+        return False"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+"
            },
            "75": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 119,
                "PatchRowcode": " if __name__ == \"__main__\":"
            },
            "76": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 120,
                "PatchRowcode": "     # Get the TOML file path from the command line argument"
            },
            "77": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 121,
                "PatchRowcode": "     toml_file = sys.argv[1]"
            },
            "78": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "     versions_for = sys.argv[2]"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+    python_version = sys.argv[3]"
            },
            "80": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "     assert versions_for in [\"release\", \"pull_request\"]"
            },
            "81": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 125,
                "PatchRowcode": " "
            },
            "82": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "     # Call the function to get the minimum versions"
            },
            "83": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    min_versions = get_min_version_from_toml(toml_file, versions_for)"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+    min_versions = get_min_version_from_toml(toml_file, versions_for, python_version)"
            },
            "85": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " "
            },
            "86": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "     print(\" \".join([f\"{lib}=={version}\" for lib, version in min_versions.items()]))"
            }
        },
        "frontPatchFile": [
            "import sys",
            "",
            "if sys.version_info >= (3, 11):",
            "    import tomllib",
            "else:",
            "    # for python 3.10 and below, which doesnt have stdlib tomllib",
            "    import tomli as tomllib",
            "",
            "from packaging.version import parse as parse_version",
            "import re",
            "",
            "MIN_VERSION_LIBS = [",
            "    \"langchain-core\",",
            "    \"langchain-community\",",
            "    \"langchain\",",
            "    \"langchain-text-splitters\",",
            "    \"SQLAlchemy\",",
            "]",
            "",
            "SKIP_IF_PULL_REQUEST = [\"langchain-core\"]",
            "",
            "",
            "def get_min_version(version: str) -> str:",
            "    # base regex for x.x.x with cases for rc/post/etc",
            "    # valid strings: https://peps.python.org/pep-0440/#public-version-identifiers",
            "    vstring = r\"\\d+(?:\\.\\d+){0,2}(?:(?:a|b|rc|\\.post|\\.dev)\\d+)?\"",
            "    # case ^x.x.x",
            "    _match = re.match(f\"^\\\\^({vstring})$\", version)",
            "    if _match:",
            "        return _match.group(1)",
            "",
            "    # case >=x.x.x,<y.y.y",
            "    _match = re.match(f\"^>=({vstring}),<({vstring})$\", version)",
            "    if _match:",
            "        _min = _match.group(1)",
            "        _max = _match.group(2)",
            "        assert parse_version(_min) < parse_version(_max)",
            "        return _min",
            "",
            "    # case x.x.x",
            "    _match = re.match(f\"^({vstring})$\", version)",
            "    if _match:",
            "        return _match.group(1)",
            "",
            "    raise ValueError(f\"Unrecognized version format: {version}\")",
            "",
            "",
            "def get_min_version_from_toml(toml_path: str, versions_for: str):",
            "    # Parse the TOML file",
            "    with open(toml_path, \"rb\") as file:",
            "        toml_data = tomllib.load(file)",
            "",
            "    # Get the dependencies from tool.poetry.dependencies",
            "    dependencies = toml_data[\"tool\"][\"poetry\"][\"dependencies\"]",
            "",
            "    # Initialize a dictionary to store the minimum versions",
            "    min_versions = {}",
            "",
            "    # Iterate over the libs in MIN_VERSION_LIBS",
            "    for lib in MIN_VERSION_LIBS:",
            "        if versions_for == \"pull_request\" and lib in SKIP_IF_PULL_REQUEST:",
            "            # some libs only get checked on release because of simultaneous",
            "            # changes",
            "            continue",
            "        # Check if the lib is present in the dependencies",
            "        if lib in dependencies:",
            "            # Get the version string",
            "            version_string = dependencies[lib]",
            "",
            "            if isinstance(version_string, dict):",
            "                version_string = version_string[\"version\"]",
            "",
            "            # Use parse_version to get the minimum supported version from version_string",
            "            min_version = get_min_version(version_string)",
            "",
            "            # Store the minimum version in the min_versions dictionary",
            "            min_versions[lib] = min_version",
            "",
            "    return min_versions",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    # Get the TOML file path from the command line argument",
            "    toml_file = sys.argv[1]",
            "    versions_for = sys.argv[2]",
            "    assert versions_for in [\"release\", \"pull_request\"]",
            "",
            "    # Call the function to get the minimum versions",
            "    min_versions = get_min_version_from_toml(toml_file, versions_for)",
            "",
            "    print(\" \".join([f\"{lib}=={version}\" for lib, version in min_versions.items()]))"
        ],
        "afterPatchFile": [
            "import sys",
            "from typing import Optional",
            "",
            "if sys.version_info >= (3, 11):",
            "    import tomllib",
            "else:",
            "    # for python 3.10 and below, which doesnt have stdlib tomllib",
            "    import tomli as tomllib",
            "",
            "from packaging.version import parse as parse_version",
            "from packaging.specifiers import SpecifierSet",
            "from packaging.version import Version",
            "",
            "import re",
            "",
            "MIN_VERSION_LIBS = [",
            "    \"langchain-core\",",
            "    \"langchain-community\",",
            "    \"langchain\",",
            "    \"langchain-text-splitters\",",
            "    \"SQLAlchemy\",",
            "    \"pydantic\",",
            "]",
            "",
            "SKIP_IF_PULL_REQUEST = [\"langchain-core\"]",
            "",
            "",
            "def get_min_version(version: str) -> str:",
            "    # base regex for x.x.x with cases for rc/post/etc",
            "    # valid strings: https://peps.python.org/pep-0440/#public-version-identifiers",
            "    vstring = r\"\\d+(?:\\.\\d+){0,2}(?:(?:a|b|rc|\\.post|\\.dev)\\d+)?\"",
            "    # case ^x.x.x",
            "    _match = re.match(f\"^\\\\^({vstring})$\", version)",
            "    if _match:",
            "        return _match.group(1)",
            "",
            "    # case >=x.x.x,<y.y.y",
            "    _match = re.match(f\"^>=({vstring}),<({vstring})$\", version)",
            "    if _match:",
            "        _min = _match.group(1)",
            "        _max = _match.group(2)",
            "        assert parse_version(_min) < parse_version(_max)",
            "        return _min",
            "",
            "    # case x.x.x",
            "    _match = re.match(f\"^({vstring})$\", version)",
            "    if _match:",
            "        return _match.group(1)",
            "",
            "    raise ValueError(f\"Unrecognized version format: {version}\")",
            "",
            "",
            "def get_min_version_from_toml(",
            "    toml_path: str,",
            "    versions_for: str,",
            "    python_version: str,",
            "    *,",
            "    include: Optional[list] = None,",
            "):",
            "    # Parse the TOML file",
            "    with open(toml_path, \"rb\") as file:",
            "        toml_data = tomllib.load(file)",
            "",
            "    # Get the dependencies from tool.poetry.dependencies",
            "    dependencies = toml_data[\"tool\"][\"poetry\"][\"dependencies\"]",
            "",
            "    # Initialize a dictionary to store the minimum versions",
            "    min_versions = {}",
            "",
            "    # Iterate over the libs in MIN_VERSION_LIBS",
            "    for lib in MIN_VERSION_LIBS:",
            "        if versions_for == \"pull_request\" and lib in SKIP_IF_PULL_REQUEST:",
            "            # some libs only get checked on release because of simultaneous",
            "            # changes",
            "            continue",
            "        # Check if the lib is present in the dependencies",
            "        if lib in dependencies:",
            "            if include and lib not in include:",
            "                continue",
            "            # Get the version string",
            "            version_string = dependencies[lib]",
            "",
            "            if isinstance(version_string, dict):",
            "                version_string = version_string[\"version\"]",
            "            if isinstance(version_string, list):",
            "                version_string = [",
            "                    vs",
            "                    for vs in version_string",
            "                    if check_python_version(python_version, vs[\"python\"])",
            "                ][0][\"version\"]",
            "",
            "",
            "            # Use parse_version to get the minimum supported version from version_string",
            "            min_version = get_min_version(version_string)",
            "",
            "            # Store the minimum version in the min_versions dictionary",
            "            min_versions[lib] = min_version",
            "",
            "    return min_versions",
            "",
            "",
            "def check_python_version(version_string, constraint_string):",
            "    \"\"\"",
            "    Check if the given Python version matches the given constraints.",
            "",
            "    :param version_string: A string representing the Python version (e.g. \"3.8.5\").",
            "    :param constraint_string: A string representing the package's Python version constraints (e.g. \">=3.6, <4.0\").",
            "    :return: True if the version matches the constraints, False otherwise.",
            "    \"\"\"",
            "    try:",
            "        version = Version(version_string)",
            "        constraints = SpecifierSet(constraint_string)",
            "        return version in constraints",
            "    except Exception as e:",
            "        print(f\"Error: {e}\")",
            "        return False",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    # Get the TOML file path from the command line argument",
            "    toml_file = sys.argv[1]",
            "    versions_for = sys.argv[2]",
            "    python_version = sys.argv[3]",
            "    assert versions_for in [\"release\", \"pull_request\"]",
            "",
            "    # Call the function to get the minimum versions",
            "    min_versions = get_min_version_from_toml(toml_file, versions_for, python_version)",
            "",
            "    print(\" \".join([f\"{lib}=={version}\" for lib, version in min_versions.items()]))"
        ],
        "action": [
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "48": [
                "get_min_version_from_toml"
            ],
            "89": [
                "min_versions"
            ]
        },
        "addLocation": []
    }
}