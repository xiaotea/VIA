{
    "src/quart/formparser.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from urllib.parse import parse_qsl"
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from werkzeug.datastructures import Headers, MultiDict"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+from werkzeug.exceptions import RequestEntityTooLarge"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from werkzeug.formparser import default_stream_factory"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from werkzeug.http import parse_options_header"
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from werkzeug.sansio.multipart import Data, Epilogue, Field, File, MultipartDecoder, NeedData"
            },
            "7": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "         files = []"
            },
            "8": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 175,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "         current_part: Field | File"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+        field_size: int | None = None"
            },
            "11": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "         async for data in body:"
            },
            "12": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "             parser.receive_data(data)"
            },
            "13": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "             event = parser.next_event()"
            },
            "14": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "             while not isinstance(event, (Epilogue, NeedData)):"
            },
            "15": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "                 if isinstance(event, Field):"
            },
            "16": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 183,
                "PatchRowcode": "                     current_part = event"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+                    field_size = 0"
            },
            "18": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "                     container = []"
            },
            "19": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "                     _write = container.append"
            },
            "20": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "                 elif isinstance(event, File):"
            },
            "21": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "                     current_part = event"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+                    field_size = None"
            },
            "23": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "                     container = self.start_file_streaming(event, content_length)"
            },
            "24": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "                     _write = container.write"
            },
            "25": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "                 elif isinstance(event, Data):"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+                    if field_size is not None:"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+                        field_size += len(event.data)"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+                        if field_size > self.max_form_memory_size:"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+                            raise RequestEntityTooLarge()"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 199,
                "PatchRowcode": "                     _write(event.data)"
            },
            "33": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "                     if not event.more_data:"
            },
            "34": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "                         if isinstance(current_part, Field):"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "from typing import (",
            "    Any,",
            "    Awaitable,",
            "    Callable,",
            "    cast,",
            "    Dict,",
            "    IO,",
            "    NoReturn,",
            "    Optional,",
            "    Tuple,",
            "    TYPE_CHECKING,",
            ")",
            "from urllib.parse import parse_qsl",
            "",
            "from werkzeug.datastructures import Headers, MultiDict",
            "from werkzeug.formparser import default_stream_factory",
            "from werkzeug.http import parse_options_header",
            "from werkzeug.sansio.multipart import Data, Epilogue, Field, File, MultipartDecoder, NeedData",
            "",
            "from .datastructures import FileStorage",
            "",
            "if TYPE_CHECKING:",
            "    from .wrappers.request import Body",
            "",
            "StreamFactory = Callable[",
            "    [Optional[int], Optional[str], Optional[str], Optional[int]],",
            "    IO[bytes],",
            "]",
            "",
            "ParserFunc = Callable[",
            "    [\"FormDataParser\", \"Body\", str, Optional[int], Dict[str, str]],",
            "    Awaitable[Tuple[MultiDict, MultiDict]],",
            "]",
            "",
            "",
            "class FormDataParser:",
            "    file_storage_class = FileStorage",
            "",
            "    def __init__(",
            "        self,",
            "        stream_factory: StreamFactory = default_stream_factory,",
            "        max_form_memory_size: int | None = None,",
            "        max_content_length: int | None = None,",
            "        cls: type[MultiDict] | None = MultiDict,",
            "        silent: bool = True,",
            "    ) -> None:",
            "        self.stream_factory = stream_factory",
            "        self.cls = cls",
            "        self.silent = silent",
            "",
            "    def get_parse_func(self, mimetype: str, options: dict[str, str]) -> ParserFunc | None:",
            "        return self.parse_functions.get(mimetype)",
            "",
            "    async def parse(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str] | None = None,",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        if options is None:",
            "            options = {}",
            "",
            "        parse_func = self.get_parse_func(mimetype, options)",
            "",
            "        if parse_func is not None:",
            "            try:",
            "                return await parse_func(self, body, mimetype, content_length, options)",
            "            except ValueError:",
            "                if not self.silent:",
            "                    raise",
            "",
            "        return self.cls(), self.cls()",
            "",
            "    async def _parse_multipart(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str],",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        parser = MultiPartParser(",
            "            self.stream_factory,",
            "            cls=self.cls,",
            "            file_storage_cls=self.file_storage_class,",
            "        )",
            "        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")",
            "",
            "        if not boundary:",
            "            raise ValueError(\"Missing boundary\")",
            "",
            "        return await parser.parse(body, boundary, content_length)",
            "",
            "    async def _parse_urlencoded(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str],",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        form = parse_qsl(",
            "            (await body).decode(),",
            "            keep_blank_values=True,",
            "        )",
            "        return self.cls(form), self.cls()",
            "",
            "    parse_functions: dict[str, ParserFunc] = {",
            "        \"multipart/form-data\": _parse_multipart,",
            "        \"application/x-www-form-urlencoded\": _parse_urlencoded,",
            "        \"application/x-url-encoded\": _parse_urlencoded,",
            "    }",
            "",
            "",
            "class MultiPartParser:",
            "    def __init__(",
            "        self,",
            "        stream_factory: StreamFactory = default_stream_factory,",
            "        max_form_memory_size: int | None = None,",
            "        cls: type[MultiDict] = MultiDict,",
            "        buffer_size: int = 64 * 1024,",
            "        file_storage_cls: type[FileStorage] = FileStorage,",
            "    ) -> None:",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.stream_factory = stream_factory",
            "        self.cls = cls",
            "        self.buffer_size = buffer_size",
            "        self.file_storage_cls = file_storage_cls",
            "",
            "    def fail(self, message: str) -> NoReturn:",
            "        raise ValueError(message)",
            "",
            "    def get_part_charset(self, headers: Headers) -> str:",
            "        content_type = headers.get(\"content-type\")",
            "",
            "        if content_type:",
            "            parameters = parse_options_header(content_type)[1]",
            "            ct_charset = parameters.get(\"charset\", \"\").lower()",
            "",
            "            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.",
            "            # This list will not be extended further.",
            "            if ct_charset in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:",
            "                return ct_charset",
            "",
            "        return \"utf-8\"",
            "",
            "    def start_file_streaming(self, event: File, total_content_length: int) -> IO[bytes]:",
            "        content_type = event.headers.get(\"content-type\")",
            "",
            "        try:",
            "            content_length = int(event.headers[\"content-length\"])",
            "        except (KeyError, ValueError):",
            "            content_length = 0",
            "",
            "        container = self.stream_factory(",
            "            total_content_length,",
            "            content_type,",
            "            event.filename,",
            "            content_length,",
            "        )",
            "        return container",
            "",
            "    async def parse(",
            "        self, body: Body, boundary: bytes, content_length: int",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        container: IO[bytes] | list[bytes]",
            "        _write: Callable[[bytes], Any]",
            "",
            "        parser = MultipartDecoder(boundary, self.max_form_memory_size)",
            "",
            "        fields = []",
            "        files = []",
            "",
            "        current_part: Field | File",
            "        async for data in body:",
            "            parser.receive_data(data)",
            "            event = parser.next_event()",
            "            while not isinstance(event, (Epilogue, NeedData)):",
            "                if isinstance(event, Field):",
            "                    current_part = event",
            "                    container = []",
            "                    _write = container.append",
            "                elif isinstance(event, File):",
            "                    current_part = event",
            "                    container = self.start_file_streaming(event, content_length)",
            "                    _write = container.write",
            "                elif isinstance(event, Data):",
            "                    _write(event.data)",
            "                    if not event.more_data:",
            "                        if isinstance(current_part, Field):",
            "                            value = b\"\".join(container).decode(",
            "                                self.get_part_charset(current_part.headers), \"replace\"",
            "                            )",
            "                            fields.append((current_part.name, value))",
            "                        else:",
            "                            container = cast(IO[bytes], container)",
            "                            container.seek(0)",
            "                            files.append(",
            "                                (",
            "                                    current_part.name,",
            "                                    self.file_storage_cls(",
            "                                        container,",
            "                                        current_part.filename,",
            "                                        current_part.name,",
            "                                        headers=current_part.headers,",
            "                                    ),",
            "                                )",
            "                            )",
            "",
            "                event = parser.next_event()",
            "",
            "        return self.cls(fields), self.cls(files)"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "from typing import (",
            "    Any,",
            "    Awaitable,",
            "    Callable,",
            "    cast,",
            "    Dict,",
            "    IO,",
            "    NoReturn,",
            "    Optional,",
            "    Tuple,",
            "    TYPE_CHECKING,",
            ")",
            "from urllib.parse import parse_qsl",
            "",
            "from werkzeug.datastructures import Headers, MultiDict",
            "from werkzeug.exceptions import RequestEntityTooLarge",
            "from werkzeug.formparser import default_stream_factory",
            "from werkzeug.http import parse_options_header",
            "from werkzeug.sansio.multipart import Data, Epilogue, Field, File, MultipartDecoder, NeedData",
            "",
            "from .datastructures import FileStorage",
            "",
            "if TYPE_CHECKING:",
            "    from .wrappers.request import Body",
            "",
            "StreamFactory = Callable[",
            "    [Optional[int], Optional[str], Optional[str], Optional[int]],",
            "    IO[bytes],",
            "]",
            "",
            "ParserFunc = Callable[",
            "    [\"FormDataParser\", \"Body\", str, Optional[int], Dict[str, str]],",
            "    Awaitable[Tuple[MultiDict, MultiDict]],",
            "]",
            "",
            "",
            "class FormDataParser:",
            "    file_storage_class = FileStorage",
            "",
            "    def __init__(",
            "        self,",
            "        stream_factory: StreamFactory = default_stream_factory,",
            "        max_form_memory_size: int | None = None,",
            "        max_content_length: int | None = None,",
            "        cls: type[MultiDict] | None = MultiDict,",
            "        silent: bool = True,",
            "    ) -> None:",
            "        self.stream_factory = stream_factory",
            "        self.cls = cls",
            "        self.silent = silent",
            "",
            "    def get_parse_func(self, mimetype: str, options: dict[str, str]) -> ParserFunc | None:",
            "        return self.parse_functions.get(mimetype)",
            "",
            "    async def parse(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str] | None = None,",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        if options is None:",
            "            options = {}",
            "",
            "        parse_func = self.get_parse_func(mimetype, options)",
            "",
            "        if parse_func is not None:",
            "            try:",
            "                return await parse_func(self, body, mimetype, content_length, options)",
            "            except ValueError:",
            "                if not self.silent:",
            "                    raise",
            "",
            "        return self.cls(), self.cls()",
            "",
            "    async def _parse_multipart(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str],",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        parser = MultiPartParser(",
            "            self.stream_factory,",
            "            cls=self.cls,",
            "            file_storage_cls=self.file_storage_class,",
            "        )",
            "        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")",
            "",
            "        if not boundary:",
            "            raise ValueError(\"Missing boundary\")",
            "",
            "        return await parser.parse(body, boundary, content_length)",
            "",
            "    async def _parse_urlencoded(",
            "        self,",
            "        body: Body,",
            "        mimetype: str,",
            "        content_length: int | None,",
            "        options: dict[str, str],",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        form = parse_qsl(",
            "            (await body).decode(),",
            "            keep_blank_values=True,",
            "        )",
            "        return self.cls(form), self.cls()",
            "",
            "    parse_functions: dict[str, ParserFunc] = {",
            "        \"multipart/form-data\": _parse_multipart,",
            "        \"application/x-www-form-urlencoded\": _parse_urlencoded,",
            "        \"application/x-url-encoded\": _parse_urlencoded,",
            "    }",
            "",
            "",
            "class MultiPartParser:",
            "    def __init__(",
            "        self,",
            "        stream_factory: StreamFactory = default_stream_factory,",
            "        max_form_memory_size: int | None = None,",
            "        cls: type[MultiDict] = MultiDict,",
            "        buffer_size: int = 64 * 1024,",
            "        file_storage_cls: type[FileStorage] = FileStorage,",
            "    ) -> None:",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.stream_factory = stream_factory",
            "        self.cls = cls",
            "        self.buffer_size = buffer_size",
            "        self.file_storage_cls = file_storage_cls",
            "",
            "    def fail(self, message: str) -> NoReturn:",
            "        raise ValueError(message)",
            "",
            "    def get_part_charset(self, headers: Headers) -> str:",
            "        content_type = headers.get(\"content-type\")",
            "",
            "        if content_type:",
            "            parameters = parse_options_header(content_type)[1]",
            "            ct_charset = parameters.get(\"charset\", \"\").lower()",
            "",
            "            # A safe list of encodings. Modern clients should only send ASCII or UTF-8.",
            "            # This list will not be extended further.",
            "            if ct_charset in {\"ascii\", \"us-ascii\", \"utf-8\", \"iso-8859-1\"}:",
            "                return ct_charset",
            "",
            "        return \"utf-8\"",
            "",
            "    def start_file_streaming(self, event: File, total_content_length: int) -> IO[bytes]:",
            "        content_type = event.headers.get(\"content-type\")",
            "",
            "        try:",
            "            content_length = int(event.headers[\"content-length\"])",
            "        except (KeyError, ValueError):",
            "            content_length = 0",
            "",
            "        container = self.stream_factory(",
            "            total_content_length,",
            "            content_type,",
            "            event.filename,",
            "            content_length,",
            "        )",
            "        return container",
            "",
            "    async def parse(",
            "        self, body: Body, boundary: bytes, content_length: int",
            "    ) -> tuple[MultiDict, MultiDict]:",
            "        container: IO[bytes] | list[bytes]",
            "        _write: Callable[[bytes], Any]",
            "",
            "        parser = MultipartDecoder(boundary, self.max_form_memory_size)",
            "",
            "        fields = []",
            "        files = []",
            "",
            "        current_part: Field | File",
            "        field_size: int | None = None",
            "        async for data in body:",
            "            parser.receive_data(data)",
            "            event = parser.next_event()",
            "            while not isinstance(event, (Epilogue, NeedData)):",
            "                if isinstance(event, Field):",
            "                    current_part = event",
            "                    field_size = 0",
            "                    container = []",
            "                    _write = container.append",
            "                elif isinstance(event, File):",
            "                    current_part = event",
            "                    field_size = None",
            "                    container = self.start_file_streaming(event, content_length)",
            "                    _write = container.write",
            "                elif isinstance(event, Data):",
            "                    if field_size is not None:",
            "                        field_size += len(event.data)",
            "",
            "                        if field_size > self.max_form_memory_size:",
            "                            raise RequestEntityTooLarge()",
            "",
            "                    _write(event.data)",
            "                    if not event.more_data:",
            "                        if isinstance(current_part, Field):",
            "                            value = b\"\".join(container).decode(",
            "                                self.get_part_charset(current_part.headers), \"replace\"",
            "                            )",
            "                            fields.append((current_part.name, value))",
            "                        else:",
            "                            container = cast(IO[bytes], container)",
            "                            container.seek(0)",
            "                            files.append(",
            "                                (",
            "                                    current_part.name,",
            "                                    self.file_storage_cls(",
            "                                        container,",
            "                                        current_part.filename,",
            "                                        current_part.name,",
            "                                        headers=current_part.headers,",
            "                                    ),",
            "                                )",
            "                            )",
            "",
            "                event = parser.next_event()",
            "",
            "        return self.cls(fields), self.cls(files)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.quart.formparser.MultiPartParser.self",
            "src.quart.formparser.FormDataParser._parse_multipart.parser"
        ]
    }
}