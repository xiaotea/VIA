{
    "synapse/federation/federation_base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " # See the License for the specific language governing permissions and"
            },
            "1": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " # limitations under the License."
            },
            "2": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import logging"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+from collections import namedtuple"
            },
            "4": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import six"
            },
            "6": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from twisted.internet import defer"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+from twisted.internet.defer import DeferredList"
            },
            "9": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from synapse.api.constants import MAX_DEPTH"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from synapse.api.constants import MAX_DEPTH, EventTypes, Membership"
            },
            "12": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from synapse.api.errors import Codes, SynapseError"
            },
            "13": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from synapse.crypto.event_signing import check_event_content_hash"
            },
            "14": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from synapse.events import FrozenEvent"
            },
            "15": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from synapse.events.utils import prune_event"
            },
            "16": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from synapse.http.servlet import assert_params_in_dict"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+from synapse.types import get_domain_from_id"
            },
            "18": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from synapse.util import logcontext, unwrapFirstError"
            },
            "19": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "21": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "               * throws a SynapseError if the signature check failed."
            },
            "22": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "             The deferreds run their callbacks in the sentinel logcontext."
            },
            "23": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "         \"\"\""
            },
            "24": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "25": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        redacted_pdus = ["
            },
            "26": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            prune_event(pdu)"
            },
            "27": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            for pdu in pdus"
            },
            "28": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ]"
            },
            "29": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "30": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        deferreds = self.keyring.verify_json_objects_for_server(["
            },
            "31": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            (p.origin, p.get_pdu_json())"
            },
            "32": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            for p in redacted_pdus"
            },
            "33": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ])"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+        deferreds = _check_sigs_on_pdus(self.keyring, pdus)"
            },
            "35": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 140,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         ctx = logcontext.LoggingContext.current_context()"
            },
            "37": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 142,
                "PatchRowcode": " "
            },
            "38": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def callback(_, pdu, redacted):"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+        def callback(_, pdu):"
            },
            "40": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "             with logcontext.PreserveLoggingContext(ctx):"
            },
            "41": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "                 if not check_event_content_hash(pdu):"
            },
            "42": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "                     logger.warn("
            },
            "43": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "                         \"Event content has been tampered, redacting %s: %s\","
            },
            "44": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "                         pdu.event_id, pdu.get_pdu_json()"
            },
            "45": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "                     )"
            },
            "46": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return redacted"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+                    return prune_event(pdu)"
            },
            "48": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 151,
                "PatchRowcode": " "
            },
            "49": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "                 if self.spam_checker.check_event_for_spam(pdu):"
            },
            "50": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "                     logger.warn("
            },
            "51": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "                         \"Event contains spam, redacting %s: %s\","
            },
            "52": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "                         pdu.event_id, pdu.get_pdu_json()"
            },
            "53": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "                     )"
            },
            "54": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return redacted"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+                    return prune_event(pdu)"
            },
            "56": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 158,
                "PatchRowcode": " "
            },
            "57": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "                 return pdu"
            },
            "58": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 160,
                "PatchRowcode": " "
            },
            "59": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "                 )"
            },
            "60": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "             return failure"
            },
            "61": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 169,
                "PatchRowcode": " "
            },
            "62": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for deferred, pdu, redacted in zip(deferreds, pdus, redacted_pdus):"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+        for deferred, pdu in zip(deferreds, pdus):"
            },
            "64": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "             deferred.addCallbacks("
            },
            "65": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "                 callback, errback,"
            },
            "66": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                callbackArgs=[pdu, redacted],"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+                callbackArgs=[pdu],"
            },
            "68": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "                 errbackArgs=[pdu],"
            },
            "69": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "             )"
            },
            "70": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 176,
                "PatchRowcode": " "
            },
            "71": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "         return deferreds"
            },
            "72": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 178,
                "PatchRowcode": " "
            },
            "73": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 179,
                "PatchRowcode": " "
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+class PduToCheckSig(namedtuple(\"PduToCheckSig\", ["
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+    \"pdu\", \"redacted_pdu_json\", \"event_id_domain\", \"sender_domain\", \"deferreds\","
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+])):"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+    pass"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 186,
                "PatchRowcode": "+def _check_sigs_on_pdus(keyring, pdus):"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 187,
                "PatchRowcode": "+    \"\"\"Check that the given events are correctly signed"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+    Args:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 190,
                "PatchRowcode": "+        keyring (synapse.crypto.Keyring): keyring object to do the checks"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 191,
                "PatchRowcode": "+        pdus (Collection[EventBase]): the events to be checked"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 192,
                "PatchRowcode": "+"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+    Returns:"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+        List[Deferred]: a Deferred for each event in pdus, which will either succeed if"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+           the signatures are valid, or fail (with a SynapseError) if not."
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+    \"\"\""
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+    # (currently this is written assuming the v1 room structure; we'll probably want a"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+    # separate function for checking v2 rooms)"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+    # we want to check that the event is signed by:"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 202,
                "PatchRowcode": "+    #"
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 203,
                "PatchRowcode": "+    # (a) the server which created the event_id"
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 204,
                "PatchRowcode": "+    #"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+    # (b) the sender's server."
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+    #"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+    #     - except in the case of invites created from a 3pid invite, which are exempt"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+    #     from this check, because the sender has to match that of the original 3pid"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+    #     invite, but the event may come from a different HS, for reasons that I don't"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+    #     entirely grok (why do the senders have to match? and if they do, why doesn't the"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+    #     joining server ask the inviting server to do the switcheroo with"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+    #     exchange_third_party_invite?)."
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+    #"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+    #     That's pretty awful, since redacting such an invite will render it invalid"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+    #     (because it will then look like a regular invite without a valid signature),"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+    #     and signatures are *supposed* to be valid whether or not an event has been"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 217,
                "PatchRowcode": "+    #     redacted. But this isn't the worst of the ways that 3pid invites are broken."
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+    #"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+    # let's start by getting the domain for each pdu, and flattening the event back"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+    # to JSON."
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+    pdus_to_check = ["
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+        PduToCheckSig("
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+            pdu=p,"
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 224,
                "PatchRowcode": "+            redacted_pdu_json=prune_event(p).get_pdu_json(),"
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 225,
                "PatchRowcode": "+            event_id_domain=get_domain_from_id(p.event_id),"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+            sender_domain=get_domain_from_id(p.sender),"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 227,
                "PatchRowcode": "+            deferreds=[],"
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+        )"
            },
            "123": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 229,
                "PatchRowcode": "+        for p in pdus"
            },
            "124": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+    ]"
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+    # first make sure that the event is signed by the event_id's domain"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+    deferreds = keyring.verify_json_objects_for_server(["
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+        (p.event_id_domain, p.redacted_pdu_json)"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+        for p in pdus_to_check"
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 236,
                "PatchRowcode": "+    ])"
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+    for p, d in zip(pdus_to_check, deferreds):"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+        p.deferreds.append(d)"
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+    # now let's look for events where the sender's domain is different to the"
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+    # event id's domain (normally only the case for joins/leaves), and add additional"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+    # checks."
            },
            "138": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+    pdus_to_check_sender = ["
            },
            "139": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+        p for p in pdus_to_check"
            },
            "140": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+        if p.sender_domain != p.event_id_domain and not _is_invite_via_3pid(p.pdu)"
            },
            "141": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+    ]"
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+"
            },
            "143": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+    more_deferreds = keyring.verify_json_objects_for_server(["
            },
            "144": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+        (p.sender_domain, p.redacted_pdu_json)"
            },
            "145": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+        for p in pdus_to_check_sender"
            },
            "146": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+    ])"
            },
            "147": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+"
            },
            "148": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+    for p, d in zip(pdus_to_check_sender, more_deferreds):"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+        p.deferreds.append(d)"
            },
            "150": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+"
            },
            "151": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+    # replace lists of deferreds with single Deferreds"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]"
            },
            "153": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+"
            },
            "154": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+"
            },
            "155": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+def _flatten_deferred_list(deferreds):"
            },
            "156": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+    \"\"\"Given a list of one or more deferreds, either return the single deferred, or"
            },
            "157": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+    combine into a DeferredList."
            },
            "158": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+    \"\"\""
            },
            "159": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+    if len(deferreds) > 1:"
            },
            "160": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+        return DeferredList(deferreds, fireOnOneErrback=True, consumeErrors=True)"
            },
            "161": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 267,
                "PatchRowcode": "+    else:"
            },
            "162": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+        assert len(deferreds) == 1"
            },
            "163": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 269,
                "PatchRowcode": "+        return deferreds[0]"
            },
            "164": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 270,
                "PatchRowcode": "+"
            },
            "165": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 271,
                "PatchRowcode": "+"
            },
            "166": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+def _is_invite_via_3pid(event):"
            },
            "167": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+    return ("
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 274,
                "PatchRowcode": "+        event.type == EventTypes.Member"
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+        and event.membership == Membership.INVITE"
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+        and \"third_party_invite\" in event.content"
            },
            "171": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+    )"
            },
            "172": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+"
            },
            "173": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+"
            },
            "174": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 280,
                "PatchRowcode": " def event_from_pdu_json(pdu_json, outlier=False):"
            },
            "175": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 281,
                "PatchRowcode": "     \"\"\"Construct a FrozenEvent from an event json received over federation"
            },
            "176": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 282,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "",
            "import six",
            "",
            "from twisted.internet import defer",
            "",
            "from synapse.api.constants import MAX_DEPTH",
            "from synapse.api.errors import Codes, SynapseError",
            "from synapse.crypto.event_signing import check_event_content_hash",
            "from synapse.events import FrozenEvent",
            "from synapse.events.utils import prune_event",
            "from synapse.http.servlet import assert_params_in_dict",
            "from synapse.util import logcontext, unwrapFirstError",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class FederationBase(object):",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.store = hs.get_datastore()",
            "        self._clock = hs.get_clock()",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_sigs_and_hash_and_fetch(self, origin, pdus, outlier=False,",
            "                                       include_none=False):",
            "        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each",
            "        one. If a PDU fails its signature check then we check if we have it in",
            "        the database and if not then request if from the originating server of",
            "        that PDU.",
            "",
            "        If a PDU fails its content hash check then it is redacted.",
            "",
            "        The given list of PDUs are not modified, instead the function returns",
            "        a new list.",
            "",
            "        Args:",
            "            pdu (list)",
            "            outlier (bool)",
            "",
            "        Returns:",
            "            Deferred : A list of PDUs that have valid signatures and hashes.",
            "        \"\"\"",
            "        deferreds = self._check_sigs_and_hashes(pdus)",
            "",
            "        @defer.inlineCallbacks",
            "        def handle_check_result(pdu, deferred):",
            "            try:",
            "                res = yield logcontext.make_deferred_yieldable(deferred)",
            "            except SynapseError:",
            "                res = None",
            "",
            "            if not res:",
            "                # Check local db.",
            "                res = yield self.store.get_event(",
            "                    pdu.event_id,",
            "                    allow_rejected=True,",
            "                    allow_none=True,",
            "                )",
            "",
            "            if not res and pdu.origin != origin:",
            "                try:",
            "                    res = yield self.get_pdu(",
            "                        destinations=[pdu.origin],",
            "                        event_id=pdu.event_id,",
            "                        outlier=outlier,",
            "                        timeout=10000,",
            "                    )",
            "                except SynapseError:",
            "                    pass",
            "",
            "            if not res:",
            "                logger.warn(",
            "                    \"Failed to find copy of %s with valid signature\",",
            "                    pdu.event_id,",
            "                )",
            "",
            "            defer.returnValue(res)",
            "",
            "        handle = logcontext.preserve_fn(handle_check_result)",
            "        deferreds2 = [",
            "            handle(pdu, deferred)",
            "            for pdu, deferred in zip(pdus, deferreds)",
            "        ]",
            "",
            "        valid_pdus = yield logcontext.make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                deferreds2,",
            "                consumeErrors=True,",
            "            )",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if include_none:",
            "            defer.returnValue(valid_pdus)",
            "        else:",
            "            defer.returnValue([p for p in valid_pdus if p])",
            "",
            "    def _check_sigs_and_hash(self, pdu):",
            "        return logcontext.make_deferred_yieldable(",
            "            self._check_sigs_and_hashes([pdu])[0],",
            "        )",
            "",
            "    def _check_sigs_and_hashes(self, pdus):",
            "        \"\"\"Checks that each of the received events is correctly signed by the",
            "        sending server.",
            "",
            "        Args:",
            "            pdus (list[FrozenEvent]): the events to be checked",
            "",
            "        Returns:",
            "            list[Deferred]: for each input event, a deferred which:",
            "              * returns the original event if the checks pass",
            "              * returns a redacted version of the event (if the signature",
            "                matched but the hash did not)",
            "              * throws a SynapseError if the signature check failed.",
            "            The deferreds run their callbacks in the sentinel logcontext.",
            "        \"\"\"",
            "",
            "        redacted_pdus = [",
            "            prune_event(pdu)",
            "            for pdu in pdus",
            "        ]",
            "",
            "        deferreds = self.keyring.verify_json_objects_for_server([",
            "            (p.origin, p.get_pdu_json())",
            "            for p in redacted_pdus",
            "        ])",
            "",
            "        ctx = logcontext.LoggingContext.current_context()",
            "",
            "        def callback(_, pdu, redacted):",
            "            with logcontext.PreserveLoggingContext(ctx):",
            "                if not check_event_content_hash(pdu):",
            "                    logger.warn(",
            "                        \"Event content has been tampered, redacting %s: %s\",",
            "                        pdu.event_id, pdu.get_pdu_json()",
            "                    )",
            "                    return redacted",
            "",
            "                if self.spam_checker.check_event_for_spam(pdu):",
            "                    logger.warn(",
            "                        \"Event contains spam, redacting %s: %s\",",
            "                        pdu.event_id, pdu.get_pdu_json()",
            "                    )",
            "                    return redacted",
            "",
            "                return pdu",
            "",
            "        def errback(failure, pdu):",
            "            failure.trap(SynapseError)",
            "            with logcontext.PreserveLoggingContext(ctx):",
            "                logger.warn(",
            "                    \"Signature check failed for %s\",",
            "                    pdu.event_id,",
            "                )",
            "            return failure",
            "",
            "        for deferred, pdu, redacted in zip(deferreds, pdus, redacted_pdus):",
            "            deferred.addCallbacks(",
            "                callback, errback,",
            "                callbackArgs=[pdu, redacted],",
            "                errbackArgs=[pdu],",
            "            )",
            "",
            "        return deferreds",
            "",
            "",
            "def event_from_pdu_json(pdu_json, outlier=False):",
            "    \"\"\"Construct a FrozenEvent from an event json received over federation",
            "",
            "    Args:",
            "        pdu_json (object): pdu as received over federation",
            "        outlier (bool): True to mark this event as an outlier",
            "",
            "    Returns:",
            "        FrozenEvent",
            "",
            "    Raises:",
            "        SynapseError: if the pdu is missing required fields or is otherwise",
            "            not a valid matrix event",
            "    \"\"\"",
            "    # we could probably enforce a bunch of other fields here (room_id, sender,",
            "    # origin, etc etc)",
            "    assert_params_in_dict(pdu_json, ('event_id', 'type', 'depth'))",
            "",
            "    depth = pdu_json['depth']",
            "    if not isinstance(depth, six.integer_types):",
            "        raise SynapseError(400, \"Depth %r not an intger\" % (depth, ),",
            "                           Codes.BAD_JSON)",
            "",
            "    if depth < 0:",
            "        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)",
            "    elif depth > MAX_DEPTH:",
            "        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)",
            "",
            "    event = FrozenEvent(",
            "        pdu_json",
            "    )",
            "",
            "    event.internal_metadata.outlier = outlier",
            "",
            "    return event"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "from collections import namedtuple",
            "",
            "import six",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.defer import DeferredList",
            "",
            "from synapse.api.constants import MAX_DEPTH, EventTypes, Membership",
            "from synapse.api.errors import Codes, SynapseError",
            "from synapse.crypto.event_signing import check_event_content_hash",
            "from synapse.events import FrozenEvent",
            "from synapse.events.utils import prune_event",
            "from synapse.http.servlet import assert_params_in_dict",
            "from synapse.types import get_domain_from_id",
            "from synapse.util import logcontext, unwrapFirstError",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class FederationBase(object):",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.store = hs.get_datastore()",
            "        self._clock = hs.get_clock()",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_sigs_and_hash_and_fetch(self, origin, pdus, outlier=False,",
            "                                       include_none=False):",
            "        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each",
            "        one. If a PDU fails its signature check then we check if we have it in",
            "        the database and if not then request if from the originating server of",
            "        that PDU.",
            "",
            "        If a PDU fails its content hash check then it is redacted.",
            "",
            "        The given list of PDUs are not modified, instead the function returns",
            "        a new list.",
            "",
            "        Args:",
            "            pdu (list)",
            "            outlier (bool)",
            "",
            "        Returns:",
            "            Deferred : A list of PDUs that have valid signatures and hashes.",
            "        \"\"\"",
            "        deferreds = self._check_sigs_and_hashes(pdus)",
            "",
            "        @defer.inlineCallbacks",
            "        def handle_check_result(pdu, deferred):",
            "            try:",
            "                res = yield logcontext.make_deferred_yieldable(deferred)",
            "            except SynapseError:",
            "                res = None",
            "",
            "            if not res:",
            "                # Check local db.",
            "                res = yield self.store.get_event(",
            "                    pdu.event_id,",
            "                    allow_rejected=True,",
            "                    allow_none=True,",
            "                )",
            "",
            "            if not res and pdu.origin != origin:",
            "                try:",
            "                    res = yield self.get_pdu(",
            "                        destinations=[pdu.origin],",
            "                        event_id=pdu.event_id,",
            "                        outlier=outlier,",
            "                        timeout=10000,",
            "                    )",
            "                except SynapseError:",
            "                    pass",
            "",
            "            if not res:",
            "                logger.warn(",
            "                    \"Failed to find copy of %s with valid signature\",",
            "                    pdu.event_id,",
            "                )",
            "",
            "            defer.returnValue(res)",
            "",
            "        handle = logcontext.preserve_fn(handle_check_result)",
            "        deferreds2 = [",
            "            handle(pdu, deferred)",
            "            for pdu, deferred in zip(pdus, deferreds)",
            "        ]",
            "",
            "        valid_pdus = yield logcontext.make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                deferreds2,",
            "                consumeErrors=True,",
            "            )",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if include_none:",
            "            defer.returnValue(valid_pdus)",
            "        else:",
            "            defer.returnValue([p for p in valid_pdus if p])",
            "",
            "    def _check_sigs_and_hash(self, pdu):",
            "        return logcontext.make_deferred_yieldable(",
            "            self._check_sigs_and_hashes([pdu])[0],",
            "        )",
            "",
            "    def _check_sigs_and_hashes(self, pdus):",
            "        \"\"\"Checks that each of the received events is correctly signed by the",
            "        sending server.",
            "",
            "        Args:",
            "            pdus (list[FrozenEvent]): the events to be checked",
            "",
            "        Returns:",
            "            list[Deferred]: for each input event, a deferred which:",
            "              * returns the original event if the checks pass",
            "              * returns a redacted version of the event (if the signature",
            "                matched but the hash did not)",
            "              * throws a SynapseError if the signature check failed.",
            "            The deferreds run their callbacks in the sentinel logcontext.",
            "        \"\"\"",
            "        deferreds = _check_sigs_on_pdus(self.keyring, pdus)",
            "",
            "        ctx = logcontext.LoggingContext.current_context()",
            "",
            "        def callback(_, pdu):",
            "            with logcontext.PreserveLoggingContext(ctx):",
            "                if not check_event_content_hash(pdu):",
            "                    logger.warn(",
            "                        \"Event content has been tampered, redacting %s: %s\",",
            "                        pdu.event_id, pdu.get_pdu_json()",
            "                    )",
            "                    return prune_event(pdu)",
            "",
            "                if self.spam_checker.check_event_for_spam(pdu):",
            "                    logger.warn(",
            "                        \"Event contains spam, redacting %s: %s\",",
            "                        pdu.event_id, pdu.get_pdu_json()",
            "                    )",
            "                    return prune_event(pdu)",
            "",
            "                return pdu",
            "",
            "        def errback(failure, pdu):",
            "            failure.trap(SynapseError)",
            "            with logcontext.PreserveLoggingContext(ctx):",
            "                logger.warn(",
            "                    \"Signature check failed for %s\",",
            "                    pdu.event_id,",
            "                )",
            "            return failure",
            "",
            "        for deferred, pdu in zip(deferreds, pdus):",
            "            deferred.addCallbacks(",
            "                callback, errback,",
            "                callbackArgs=[pdu],",
            "                errbackArgs=[pdu],",
            "            )",
            "",
            "        return deferreds",
            "",
            "",
            "class PduToCheckSig(namedtuple(\"PduToCheckSig\", [",
            "    \"pdu\", \"redacted_pdu_json\", \"event_id_domain\", \"sender_domain\", \"deferreds\",",
            "])):",
            "    pass",
            "",
            "",
            "def _check_sigs_on_pdus(keyring, pdus):",
            "    \"\"\"Check that the given events are correctly signed",
            "",
            "    Args:",
            "        keyring (synapse.crypto.Keyring): keyring object to do the checks",
            "        pdus (Collection[EventBase]): the events to be checked",
            "",
            "    Returns:",
            "        List[Deferred]: a Deferred for each event in pdus, which will either succeed if",
            "           the signatures are valid, or fail (with a SynapseError) if not.",
            "    \"\"\"",
            "",
            "    # (currently this is written assuming the v1 room structure; we'll probably want a",
            "    # separate function for checking v2 rooms)",
            "",
            "    # we want to check that the event is signed by:",
            "    #",
            "    # (a) the server which created the event_id",
            "    #",
            "    # (b) the sender's server.",
            "    #",
            "    #     - except in the case of invites created from a 3pid invite, which are exempt",
            "    #     from this check, because the sender has to match that of the original 3pid",
            "    #     invite, but the event may come from a different HS, for reasons that I don't",
            "    #     entirely grok (why do the senders have to match? and if they do, why doesn't the",
            "    #     joining server ask the inviting server to do the switcheroo with",
            "    #     exchange_third_party_invite?).",
            "    #",
            "    #     That's pretty awful, since redacting such an invite will render it invalid",
            "    #     (because it will then look like a regular invite without a valid signature),",
            "    #     and signatures are *supposed* to be valid whether or not an event has been",
            "    #     redacted. But this isn't the worst of the ways that 3pid invites are broken.",
            "    #",
            "    # let's start by getting the domain for each pdu, and flattening the event back",
            "    # to JSON.",
            "    pdus_to_check = [",
            "        PduToCheckSig(",
            "            pdu=p,",
            "            redacted_pdu_json=prune_event(p).get_pdu_json(),",
            "            event_id_domain=get_domain_from_id(p.event_id),",
            "            sender_domain=get_domain_from_id(p.sender),",
            "            deferreds=[],",
            "        )",
            "        for p in pdus",
            "    ]",
            "",
            "    # first make sure that the event is signed by the event_id's domain",
            "    deferreds = keyring.verify_json_objects_for_server([",
            "        (p.event_id_domain, p.redacted_pdu_json)",
            "        for p in pdus_to_check",
            "    ])",
            "",
            "    for p, d in zip(pdus_to_check, deferreds):",
            "        p.deferreds.append(d)",
            "",
            "    # now let's look for events where the sender's domain is different to the",
            "    # event id's domain (normally only the case for joins/leaves), and add additional",
            "    # checks.",
            "    pdus_to_check_sender = [",
            "        p for p in pdus_to_check",
            "        if p.sender_domain != p.event_id_domain and not _is_invite_via_3pid(p.pdu)",
            "    ]",
            "",
            "    more_deferreds = keyring.verify_json_objects_for_server([",
            "        (p.sender_domain, p.redacted_pdu_json)",
            "        for p in pdus_to_check_sender",
            "    ])",
            "",
            "    for p, d in zip(pdus_to_check_sender, more_deferreds):",
            "        p.deferreds.append(d)",
            "",
            "    # replace lists of deferreds with single Deferreds",
            "    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]",
            "",
            "",
            "def _flatten_deferred_list(deferreds):",
            "    \"\"\"Given a list of one or more deferreds, either return the single deferred, or",
            "    combine into a DeferredList.",
            "    \"\"\"",
            "    if len(deferreds) > 1:",
            "        return DeferredList(deferreds, fireOnOneErrback=True, consumeErrors=True)",
            "    else:",
            "        assert len(deferreds) == 1",
            "        return deferreds[0]",
            "",
            "",
            "def _is_invite_via_3pid(event):",
            "    return (",
            "        event.type == EventTypes.Member",
            "        and event.membership == Membership.INVITE",
            "        and \"third_party_invite\" in event.content",
            "    )",
            "",
            "",
            "def event_from_pdu_json(pdu_json, outlier=False):",
            "    \"\"\"Construct a FrozenEvent from an event json received over federation",
            "",
            "    Args:",
            "        pdu_json (object): pdu as received over federation",
            "        outlier (bool): True to mark this event as an outlier",
            "",
            "    Returns:",
            "        FrozenEvent",
            "",
            "    Raises:",
            "        SynapseError: if the pdu is missing required fields or is otherwise",
            "            not a valid matrix event",
            "    \"\"\"",
            "    # we could probably enforce a bunch of other fields here (room_id, sender,",
            "    # origin, etc etc)",
            "    assert_params_in_dict(pdu_json, ('event_id', 'type', 'depth'))",
            "",
            "    depth = pdu_json['depth']",
            "    if not isinstance(depth, six.integer_types):",
            "        raise SynapseError(400, \"Depth %r not an intger\" % (depth, ),",
            "                           Codes.BAD_JSON)",
            "",
            "    if depth < 0:",
            "        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)",
            "    elif depth > MAX_DEPTH:",
            "        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)",
            "",
            "    event = FrozenEvent(",
            "        pdu_json",
            "    )",
            "",
            "    event.internal_metadata.outlier = outlier",
            "",
            "    return event"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "21": [],
            "136": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "137": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "138": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "139": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "140": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "141": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "142": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "143": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "144": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "145": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "149": [
                "FederationBase",
                "_check_sigs_and_hashes",
                "callback"
            ],
            "156": [
                "FederationBase",
                "_check_sigs_and_hashes",
                "callback"
            ],
            "163": [
                "FederationBase",
                "_check_sigs_and_hashes",
                "callback"
            ],
            "176": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ],
            "179": [
                "FederationBase",
                "_check_sigs_and_hashes"
            ]
        },
        "addLocation": []
    },
    "synapse/federation/federation_server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 99,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "     @defer.inlineCallbacks"
            },
            "2": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "     @log_function"
            },
            "3": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def on_incoming_transaction(self, transaction_data):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+    def on_incoming_transaction(self, origin, transaction_data):"
            },
            "5": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "         # keep this as early as possible to make the calculated origin ts as"
            },
            "6": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "         # accurate as possible."
            },
            "7": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "         request_time = self._clock.time_msec()"
            },
            "8": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "         if not transaction.transaction_id:"
            },
            "10": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "             raise Exception(\"Transaction missing transaction_id\")"
            },
            "11": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if not transaction.origin:"
            },
            "12": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise Exception(\"Transaction missing origin\")"
            },
            "13": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 111,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 112,
                "PatchRowcode": "         logger.debug(\"[%s] Got transaction\", transaction.transaction_id)"
            },
            "15": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 113,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "         # use a linearizer to ensure that we don't process the same transaction"
            },
            "17": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         # multiple times in parallel."
            },
            "18": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "         with (yield self._transaction_linearizer.queue("
            },
            "19": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                (transaction.origin, transaction.transaction_id),"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+                (origin, transaction.transaction_id),"
            },
            "21": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "         )):"
            },
            "22": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "             result = yield self._handle_incoming_transaction("
            },
            "23": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                transaction, request_time,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+                origin, transaction, request_time,"
            },
            "25": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 121,
                "PatchRowcode": "             )"
            },
            "26": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 122,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         defer.returnValue(result)"
            },
            "28": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 124,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "     @defer.inlineCallbacks"
            },
            "30": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def _handle_incoming_transaction(self, transaction, request_time):"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+    def _handle_incoming_transaction(self, origin, transaction, request_time):"
            },
            "32": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         \"\"\" Process an incoming transaction and return the HTTP response"
            },
            "33": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "         Args:"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+            origin (unicode): the server making the request"
            },
            "36": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "             transaction (Transaction): incoming transaction"
            },
            "37": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "             request_time (int): timestamp that the HTTP request arrived at"
            },
            "38": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 133,
                "PatchRowcode": " "
            },
            "39": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "         Returns:"
            },
            "40": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "             Deferred[(int, object)]: http response code and body"
            },
            "41": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "         \"\"\""
            },
            "42": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        response = yield self.transaction_actions.have_responded(transaction)"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+        response = yield self.transaction_actions.have_responded(origin, transaction)"
            },
            "44": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 138,
                "PatchRowcode": " "
            },
            "45": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "         if response:"
            },
            "46": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "             logger.debug("
            },
            "47": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 148,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "         received_pdus_counter.inc(len(transaction.pdus))"
            },
            "49": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        origin_host, _ = parse_server_name(transaction.origin)"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+        origin_host, _ = parse_server_name(origin)"
            },
            "52": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 152,
                "PatchRowcode": " "
            },
            "53": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "         pdus_by_room = {}"
            },
            "54": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 189,
                "PatchRowcode": "                 event_id = pdu.event_id"
            },
            "56": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "                 try:"
            },
            "57": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "                     yield self._handle_received_pdu("
            },
            "58": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        transaction.origin, pdu"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 192,
                "PatchRowcode": "+                        origin, pdu"
            },
            "60": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "                     )"
            },
            "61": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": 194,
                "PatchRowcode": "                     pdu_results[event_id] = {}"
            },
            "62": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "                 except FederationError as e:"
            },
            "63": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 211,
                "PatchRowcode": "         if hasattr(transaction, \"edus\"):"
            },
            "64": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 212,
                "PatchRowcode": "             for edu in (Edu(**x) for x in transaction.edus):"
            },
            "65": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": 213,
                "PatchRowcode": "                 yield self.received_edu("
            },
            "66": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    transaction.origin,"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+                    origin,"
            },
            "68": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "                     edu.edu_type,"
            },
            "69": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "                     edu.content"
            },
            "70": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "                 )"
            },
            "71": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": 223,
                "PatchRowcode": "         logger.debug(\"Returning: %s\", str(response))"
            },
            "72": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 224,
                "PatchRowcode": " "
            },
            "73": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "         yield self.transaction_actions.set_response("
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+            origin,"
            },
            "75": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 227,
                "PatchRowcode": "             transaction,"
            },
            "76": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 228,
                "PatchRowcode": "             200, response"
            },
            "77": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "         )"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "import re",
            "",
            "import six",
            "from six import iteritems",
            "",
            "from canonicaljson import json",
            "from prometheus_client import Counter",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.abstract import isIPAddress",
            "from twisted.python import failure",
            "",
            "from synapse.api.constants import EventTypes",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    FederationError,",
            "    IncompatibleRoomVersionError,",
            "    NotFoundError,",
            "    SynapseError,",
            ")",
            "from synapse.crypto.event_signing import compute_event_signature",
            "from synapse.federation.federation_base import FederationBase, event_from_pdu_json",
            "from synapse.federation.persistence import TransactionActions",
            "from synapse.federation.units import Edu, Transaction",
            "from synapse.http.endpoint import parse_server_name",
            "from synapse.replication.http.federation import (",
            "    ReplicationFederationSendEduRestServlet,",
            "    ReplicationGetQueryRestServlet,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util.async_helpers import Linearizer, concurrently_execute",
            "from synapse.util.caches.response_cache import ResponseCache",
            "from synapse.util.logutils import log_function",
            "",
            "# when processing incoming transactions, we try to handle multiple rooms in",
            "# parallel, up to this limit.",
            "TRANSACTION_CONCURRENCY_LIMIT = 10",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "received_pdus_counter = Counter(\"synapse_federation_server_received_pdus\", \"\")",
            "",
            "received_edus_counter = Counter(\"synapse_federation_server_received_edus\", \"\")",
            "",
            "received_queries_counter = Counter(",
            "    \"synapse_federation_server_received_queries\", \"\", [\"type\"]",
            ")",
            "",
            "",
            "class FederationServer(FederationBase):",
            "",
            "    def __init__(self, hs):",
            "        super(FederationServer, self).__init__(hs)",
            "",
            "        self.auth = hs.get_auth()",
            "        self.handler = hs.get_handlers().federation_handler",
            "",
            "        self._server_linearizer = Linearizer(\"fed_server\")",
            "        self._transaction_linearizer = Linearizer(\"fed_txn_handler\")",
            "",
            "        self.transaction_actions = TransactionActions(self.store)",
            "",
            "        self.registry = hs.get_federation_registry()",
            "",
            "        # We cache responses to state queries, as they take a while and often",
            "        # come in waves.",
            "        self._state_resp_cache = ResponseCache(hs, \"state_resp\", timeout_ms=30000)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, versions, limit):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            pdus = yield self.handler.on_backfill_request(",
            "                origin, room_id, versions, limit",
            "            )",
            "",
            "            res = self._transaction_from_pdus(pdus).get_dict()",
            "",
            "        defer.returnValue((200, res))",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_incoming_transaction(self, transaction_data):",
            "        # keep this as early as possible to make the calculated origin ts as",
            "        # accurate as possible.",
            "        request_time = self._clock.time_msec()",
            "",
            "        transaction = Transaction(**transaction_data)",
            "",
            "        if not transaction.transaction_id:",
            "            raise Exception(\"Transaction missing transaction_id\")",
            "        if not transaction.origin:",
            "            raise Exception(\"Transaction missing origin\")",
            "",
            "        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)",
            "",
            "        # use a linearizer to ensure that we don't process the same transaction",
            "        # multiple times in parallel.",
            "        with (yield self._transaction_linearizer.queue(",
            "                (transaction.origin, transaction.transaction_id),",
            "        )):",
            "            result = yield self._handle_incoming_transaction(",
            "                transaction, request_time,",
            "            )",
            "",
            "        defer.returnValue(result)",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_incoming_transaction(self, transaction, request_time):",
            "        \"\"\" Process an incoming transaction and return the HTTP response",
            "",
            "        Args:",
            "            transaction (Transaction): incoming transaction",
            "            request_time (int): timestamp that the HTTP request arrived at",
            "",
            "        Returns:",
            "            Deferred[(int, object)]: http response code and body",
            "        \"\"\"",
            "        response = yield self.transaction_actions.have_responded(transaction)",
            "",
            "        if response:",
            "            logger.debug(",
            "                \"[%s] We've already responded to this request\",",
            "                transaction.transaction_id",
            "            )",
            "            defer.returnValue(response)",
            "            return",
            "",
            "        logger.debug(\"[%s] Transaction is new\", transaction.transaction_id)",
            "",
            "        received_pdus_counter.inc(len(transaction.pdus))",
            "",
            "        origin_host, _ = parse_server_name(transaction.origin)",
            "",
            "        pdus_by_room = {}",
            "",
            "        for p in transaction.pdus:",
            "            if \"unsigned\" in p:",
            "                unsigned = p[\"unsigned\"]",
            "                if \"age\" in unsigned:",
            "                    p[\"age\"] = unsigned[\"age\"]",
            "            if \"age\" in p:",
            "                p[\"age_ts\"] = request_time - int(p[\"age\"])",
            "                del p[\"age\"]",
            "",
            "            event = event_from_pdu_json(p)",
            "            room_id = event.room_id",
            "            pdus_by_room.setdefault(room_id, []).append(event)",
            "",
            "        pdu_results = {}",
            "",
            "        # we can process different rooms in parallel (which is useful if they",
            "        # require callouts to other servers to fetch missing events), but",
            "        # impose a limit to avoid going too crazy with ram/cpu.",
            "",
            "        @defer.inlineCallbacks",
            "        def process_pdus_for_room(room_id):",
            "            logger.debug(\"Processing PDUs for %s\", room_id)",
            "            try:",
            "                yield self.check_server_matches_acl(origin_host, room_id)",
            "            except AuthError as e:",
            "                logger.warn(",
            "                    \"Ignoring PDUs for room %s from banned server\", room_id,",
            "                )",
            "                for pdu in pdus_by_room[room_id]:",
            "                    event_id = pdu.event_id",
            "                    pdu_results[event_id] = e.error_dict()",
            "                return",
            "",
            "            for pdu in pdus_by_room[room_id]:",
            "                event_id = pdu.event_id",
            "                try:",
            "                    yield self._handle_received_pdu(",
            "                        transaction.origin, pdu",
            "                    )",
            "                    pdu_results[event_id] = {}",
            "                except FederationError as e:",
            "                    logger.warn(\"Error handling PDU %s: %s\", event_id, e)",
            "                    pdu_results[event_id] = {\"error\": str(e)}",
            "                except Exception as e:",
            "                    f = failure.Failure()",
            "                    pdu_results[event_id] = {\"error\": str(e)}",
            "                    logger.error(",
            "                        \"Failed to handle PDU %s: %s\",",
            "                        event_id, f.getTraceback().rstrip(),",
            "                    )",
            "",
            "        yield concurrently_execute(",
            "            process_pdus_for_room, pdus_by_room.keys(),",
            "            TRANSACTION_CONCURRENCY_LIMIT,",
            "        )",
            "",
            "        if hasattr(transaction, \"edus\"):",
            "            for edu in (Edu(**x) for x in transaction.edus):",
            "                yield self.received_edu(",
            "                    transaction.origin,",
            "                    edu.edu_type,",
            "                    edu.content",
            "                )",
            "",
            "        response = {",
            "            \"pdus\": pdu_results,",
            "        }",
            "",
            "        logger.debug(\"Returning: %s\", str(response))",
            "",
            "        yield self.transaction_actions.set_response(",
            "            transaction,",
            "            200, response",
            "        )",
            "        defer.returnValue((200, response))",
            "",
            "    @defer.inlineCallbacks",
            "    def received_edu(self, origin, edu_type, content):",
            "        received_edus_counter.inc()",
            "        yield self.registry.on_edu(edu_type, origin, content)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_context_state_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        # we grab the linearizer to protect ourselves from servers which hammer",
            "        # us. In theory we might already have the response to this query",
            "        # in the cache so we could return it without waiting for the linearizer",
            "        # - but that's non-trivial to get right, and anyway somewhat defeats",
            "        # the point of the linearizer.",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            resp = yield self._state_resp_cache.wrap(",
            "                (room_id, event_id),",
            "                self._on_context_state_request_compute,",
            "                room_id, event_id,",
            "            )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_state_ids_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        state_ids = yield self.handler.get_state_ids_for_pdu(",
            "            room_id, event_id,",
            "        )",
            "        auth_chain_ids = yield self.store.get_auth_chain_ids(state_ids)",
            "",
            "        defer.returnValue((200, {",
            "            \"pdu_ids\": state_ids,",
            "            \"auth_chain_ids\": auth_chain_ids,",
            "        }))",
            "",
            "    @defer.inlineCallbacks",
            "    def _on_context_state_request_compute(self, room_id, event_id):",
            "        pdus = yield self.handler.get_state_for_pdu(",
            "            room_id, event_id,",
            "        )",
            "        auth_chain = yield self.store.get_auth_chain(",
            "            [pdu.event_id for pdu in pdus]",
            "        )",
            "",
            "        for event in auth_chain:",
            "            # We sign these again because there was a bug where we",
            "            # incorrectly signed things the first time round",
            "            if self.hs.is_mine_id(event.event_id):",
            "                event.signatures.update(",
            "                    compute_event_signature(",
            "                        event,",
            "                        self.hs.hostname,",
            "                        self.hs.config.signing_key[0]",
            "                    )",
            "                )",
            "",
            "        defer.returnValue({",
            "            \"pdus\": [pdu.get_pdu_json() for pdu in pdus],",
            "            \"auth_chain\": [pdu.get_pdu_json() for pdu in auth_chain],",
            "        })",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pdu_request(self, origin, event_id):",
            "        pdu = yield self.handler.get_persisted_pdu(origin, event_id)",
            "",
            "        if pdu:",
            "            defer.returnValue(",
            "                (200, self._transaction_from_pdus([pdu]).get_dict())",
            "            )",
            "        else:",
            "            defer.returnValue((404, \"\"))",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pull_request(self, origin, versions):",
            "        raise NotImplementedError(\"Pull transactions not implemented\")",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_request(self, query_type, args):",
            "        received_queries_counter.labels(query_type).inc()",
            "        resp = yield self.registry.on_query(query_type, args)",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_join_request(self, origin, room_id, user_id, supported_versions):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        if room_version not in supported_versions:",
            "            logger.warn(\"Room version %s not in %s\", room_version, supported_versions)",
            "            raise IncompatibleRoomVersionError(room_version=room_version)",
            "",
            "        pdu = yield self.handler.on_make_join_request(room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue({",
            "            \"event\": pdu.get_pdu_json(time_now),",
            "            \"room_version\": room_version,",
            "        })",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, content):",
            "        pdu = event_from_pdu_json(content)",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "        ret_pdu = yield self.handler.on_invite_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue((200, {\"event\": ret_pdu.get_pdu_json(time_now)}))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_join_request(self, origin, content):",
            "        logger.debug(\"on_send_join_request: content: %s\", content)",
            "        pdu = event_from_pdu_json(content)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_join_request: pdu sigs: %s\", pdu.signatures)",
            "        res_pdus = yield self.handler.on_send_join_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue((200, {",
            "            \"state\": [p.get_pdu_json(time_now) for p in res_pdus[\"state\"]],",
            "            \"auth_chain\": [",
            "                p.get_pdu_json(time_now) for p in res_pdus[\"auth_chain\"]",
            "            ],",
            "        }))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "        pdu = yield self.handler.on_make_leave_request(room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue({\"event\": pdu.get_pdu_json(time_now)})",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_leave_request(self, origin, content):",
            "        logger.debug(\"on_send_leave_request: content: %s\", content)",
            "        pdu = event_from_pdu_json(content)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_leave_request: pdu sigs: %s\", pdu.signatures)",
            "        yield self.handler.on_send_leave_request(origin, pdu)",
            "        defer.returnValue((200, {}))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, origin, room_id, event_id):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            time_now = self._clock.time_msec()",
            "            auth_pdus = yield self.handler.on_event_auth(event_id)",
            "            res = {",
            "                \"auth_chain\": [a.get_pdu_json(time_now) for a in auth_pdus],",
            "            }",
            "        defer.returnValue((200, res))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth_request(self, origin, content, room_id, event_id):",
            "        \"\"\"",
            "        Content is a dict with keys::",
            "            auth_chain (list): A list of events that give the auth chain.",
            "            missing (list): A list of event_ids indicating what the other",
            "              side (`origin`) think we're missing.",
            "            rejects (dict): A mapping from event_id to a 2-tuple of reason",
            "              string and a proof (or None) of why the event was rejected.",
            "              The keys of this dict give the list of events the `origin` has",
            "              rejected.",
            "",
            "        Args:",
            "            origin (str)",
            "            content (dict)",
            "            event_id (str)",
            "",
            "        Returns:",
            "            Deferred: Results in `dict` with the same format as `content`",
            "        \"\"\"",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            auth_chain = [",
            "                event_from_pdu_json(e)",
            "                for e in content[\"auth_chain\"]",
            "            ]",
            "",
            "            signed_auth = yield self._check_sigs_and_hash_and_fetch(",
            "                origin, auth_chain, outlier=True",
            "            )",
            "",
            "            ret = yield self.handler.on_query_auth(",
            "                origin,",
            "                event_id,",
            "                room_id,",
            "                signed_auth,",
            "                content.get(\"rejects\", []),",
            "                content.get(\"missing\", []),",
            "            )",
            "",
            "            time_now = self._clock.time_msec()",
            "            send_content = {",
            "                \"auth_chain\": [",
            "                    e.get_pdu_json(time_now)",
            "                    for e in ret[\"auth_chain\"]",
            "                ],",
            "                \"rejects\": ret.get(\"rejects\", []),",
            "                \"missing\": ret.get(\"missing\", []),",
            "            }",
            "",
            "        defer.returnValue(",
            "            (200, send_content)",
            "        )",
            "",
            "    @log_function",
            "    def on_query_client_keys(self, origin, content):",
            "        return self.on_query_request(\"client_keys\", content)",
            "",
            "    def on_query_user_devices(self, origin, user_id):",
            "        return self.on_query_request(\"user_devices\", user_id)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_claim_client_keys(self, origin, content):",
            "        query = []",
            "        for user_id, device_keys in content.get(\"one_time_keys\", {}).items():",
            "            for device_id, algorithm in device_keys.items():",
            "                query.append((user_id, device_id, algorithm))",
            "",
            "        results = yield self.store.claim_e2e_one_time_keys(query)",
            "",
            "        json_result = {}",
            "        for user_id, device_keys in results.items():",
            "            for device_id, keys in device_keys.items():",
            "                for key_id, json_bytes in keys.items():",
            "                    json_result.setdefault(user_id, {})[device_id] = {",
            "                        key_id: json.loads(json_bytes)",
            "                    }",
            "",
            "        logger.info(",
            "            \"Claimed one-time-keys: %s\",",
            "            \",\".join((",
            "                \"%s for %s:%s\" % (key_id, user_id, device_id)",
            "                for user_id, user_keys in iteritems(json_result)",
            "                for device_id, device_keys in iteritems(user_keys)",
            "                for key_id, _ in iteritems(device_keys)",
            "            )),",
            "        )",
            "",
            "        defer.returnValue({\"one_time_keys\": json_result})",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_get_missing_events(self, origin, room_id, earliest_events,",
            "                              latest_events, limit, min_depth):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            logger.info(",
            "                \"on_get_missing_events: earliest_events: %r, latest_events: %r,\"",
            "                \" limit: %d, min_depth: %d\",",
            "                earliest_events, latest_events, limit, min_depth",
            "            )",
            "",
            "            missing_events = yield self.handler.on_get_missing_events(",
            "                origin, room_id, earliest_events, latest_events, limit, min_depth",
            "            )",
            "",
            "            if len(missing_events) < 5:",
            "                logger.info(",
            "                    \"Returning %d events: %r\", len(missing_events), missing_events",
            "                )",
            "            else:",
            "                logger.info(\"Returning %d events\", len(missing_events))",
            "",
            "            time_now = self._clock.time_msec()",
            "",
            "        defer.returnValue({",
            "            \"events\": [ev.get_pdu_json(time_now) for ev in missing_events],",
            "        })",
            "",
            "    @log_function",
            "    def on_openid_userinfo(self, token):",
            "        ts_now_ms = self._clock.time_msec()",
            "        return self.store.get_user_id_for_open_id_token(token, ts_now_ms)",
            "",
            "    def _transaction_from_pdus(self, pdu_list):",
            "        \"\"\"Returns a new Transaction containing the given PDUs suitable for",
            "        transmission.",
            "        \"\"\"",
            "        time_now = self._clock.time_msec()",
            "        pdus = [p.get_pdu_json(time_now) for p in pdu_list]",
            "        return Transaction(",
            "            origin=self.server_name,",
            "            pdus=pdus,",
            "            origin_server_ts=int(time_now),",
            "            destination=None,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_received_pdu(self, origin, pdu):",
            "        \"\"\" Process a PDU received in a federation /send/ transaction.",
            "",
            "        If the event is invalid, then this method throws a FederationError.",
            "        (The error will then be logged and sent back to the sender (which",
            "        probably won't do anything with it), and other events in the",
            "        transaction will be processed as normal).",
            "",
            "        It is likely that we'll then receive other events which refer to",
            "        this rejected_event in their prev_events, etc.  When that happens,",
            "        we'll attempt to fetch the rejected event again, which will presumably",
            "        fail, so those second-generation events will also get rejected.",
            "",
            "        Eventually, we get to the point where there are more than 10 events",
            "        between any new events and the original rejected event. Since we",
            "        only try to backfill 10 events deep on received pdu, we then accept the",
            "        new event, possibly introducing a discontinuity in the DAG, with new",
            "        forward extremities, so normal service is approximately returned,",
            "        until we try to backfill across the discontinuity.",
            "",
            "        Args:",
            "            origin (str): server which sent the pdu",
            "            pdu (FrozenEvent): received pdu",
            "",
            "        Returns (Deferred): completes with None",
            "",
            "        Raises: FederationError if the signatures / hash do not match, or",
            "            if the event was unacceptable for any other reason (eg, too large,",
            "            too many prev_events, couldn't find the prev_events)",
            "        \"\"\"",
            "        # check that it's actually being sent from a valid destination to",
            "        # workaround bug #1753 in 0.18.5 and 0.18.6",
            "        if origin != get_domain_from_id(pdu.event_id):",
            "            # We continue to accept join events from any server; this is",
            "            # necessary for the federation join dance to work correctly.",
            "            # (When we join over federation, the \"helper\" server is",
            "            # responsible for sending out the join event, rather than the",
            "            # origin. See bug #1893).",
            "            if not (",
            "                pdu.type == 'm.room.member' and",
            "                pdu.content and",
            "                pdu.content.get(\"membership\", None) == 'join'",
            "            ):",
            "                logger.info(",
            "                    \"Discarding PDU %s from invalid origin %s\",",
            "                    pdu.event_id, origin",
            "                )",
            "                return",
            "            else:",
            "                logger.info(",
            "                    \"Accepting join PDU %s from %s\",",
            "                    pdu.event_id, origin",
            "                )",
            "",
            "        # Check signature.",
            "        try:",
            "            pdu = yield self._check_sigs_and_hash(pdu)",
            "        except SynapseError as e:",
            "            raise FederationError(",
            "                \"ERROR\",",
            "                e.code,",
            "                e.msg,",
            "                affected=pdu.event_id,",
            "            )",
            "",
            "        yield self.handler.on_receive_pdu(",
            "            origin, pdu, get_missing=True, sent_to_us_directly=True,",
            "        )",
            "",
            "    def __str__(self):",
            "        return \"<ReplicationLayer(%s)>\" % self.server_name",
            "",
            "    @defer.inlineCallbacks",
            "    def exchange_third_party_invite(",
            "            self,",
            "            sender_user_id,",
            "            target_user_id,",
            "            room_id,",
            "            signed,",
            "    ):",
            "        ret = yield self.handler.exchange_third_party_invite(",
            "            sender_user_id,",
            "            target_user_id,",
            "            room_id,",
            "            signed,",
            "        )",
            "        defer.returnValue(ret)",
            "",
            "    @defer.inlineCallbacks",
            "    def on_exchange_third_party_invite_request(self, origin, room_id, event_dict):",
            "        ret = yield self.handler.on_exchange_third_party_invite_request(",
            "            origin, room_id, event_dict",
            "        )",
            "        defer.returnValue(ret)",
            "",
            "    @defer.inlineCallbacks",
            "    def check_server_matches_acl(self, server_name, room_id):",
            "        \"\"\"Check if the given server is allowed by the server ACLs in the room",
            "",
            "        Args:",
            "            server_name (str): name of server, *without any port part*",
            "            room_id (str): ID of the room to check",
            "",
            "        Raises:",
            "            AuthError if the server does not match the ACL",
            "        \"\"\"",
            "        state_ids = yield self.store.get_current_state_ids(room_id)",
            "        acl_event_id = state_ids.get((EventTypes.ServerACL, \"\"))",
            "",
            "        if not acl_event_id:",
            "            return",
            "",
            "        acl_event = yield self.store.get_event(acl_event_id)",
            "        if server_matches_acl_event(server_name, acl_event):",
            "            return",
            "",
            "        raise AuthError(code=403, msg=\"Server is banned from room\")",
            "",
            "",
            "def server_matches_acl_event(server_name, acl_event):",
            "    \"\"\"Check if the given server is allowed by the ACL event",
            "",
            "    Args:",
            "        server_name (str): name of server, without any port part",
            "        acl_event (EventBase): m.room.server_acl event",
            "",
            "    Returns:",
            "        bool: True if this server is allowed by the ACLs",
            "    \"\"\"",
            "    logger.debug(\"Checking %s against acl %s\", server_name, acl_event.content)",
            "",
            "    # first of all, check if literal IPs are blocked, and if so, whether the",
            "    # server name is a literal IP",
            "    allow_ip_literals = acl_event.content.get(\"allow_ip_literals\", True)",
            "    if not isinstance(allow_ip_literals, bool):",
            "        logger.warn(\"Ignorning non-bool allow_ip_literals flag\")",
            "        allow_ip_literals = True",
            "    if not allow_ip_literals:",
            "        # check for ipv6 literals. These start with '['.",
            "        if server_name[0] == '[':",
            "            return False",
            "",
            "        # check for ipv4 literals. We can just lift the routine from twisted.",
            "        if isIPAddress(server_name):",
            "            return False",
            "",
            "    # next,  check the deny list",
            "    deny = acl_event.content.get(\"deny\", [])",
            "    if not isinstance(deny, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list deny ACL %s\", deny)",
            "        deny = []",
            "    for e in deny:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched deny rule %s\", server_name, e)",
            "            return False",
            "",
            "    # then the allow list.",
            "    allow = acl_event.content.get(\"allow\", [])",
            "    if not isinstance(allow, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list allow ACL %s\", allow)",
            "        allow = []",
            "    for e in allow:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched allow rule %s\", server_name, e)",
            "            return True",
            "",
            "    # everything else should be rejected.",
            "    # logger.info(\"%s fell through\", server_name)",
            "    return False",
            "",
            "",
            "def _acl_entry_matches(server_name, acl_entry):",
            "    if not isinstance(acl_entry, six.string_types):",
            "        logger.warn(\"Ignoring non-str ACL entry '%s' (is %s)\", acl_entry, type(acl_entry))",
            "        return False",
            "    regex = _glob_to_regex(acl_entry)",
            "    return regex.match(server_name)",
            "",
            "",
            "def _glob_to_regex(glob):",
            "    res = ''",
            "    for c in glob:",
            "        if c == '*':",
            "            res = res + '.*'",
            "        elif c == '?':",
            "            res = res + '.'",
            "        else:",
            "            res = res + re.escape(c)",
            "    return re.compile(res + \"\\\\Z\", re.IGNORECASE)",
            "",
            "",
            "class FederationHandlerRegistry(object):",
            "    \"\"\"Allows classes to register themselves as handlers for a given EDU or",
            "    query type for incoming federation traffic.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self.edu_handlers = {}",
            "        self.query_handlers = {}",
            "",
            "    def register_edu_handler(self, edu_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation EDU of the given type.",
            "",
            "        Args:",
            "            edu_type (str): The type of the incoming EDU to register handler for",
            "            handler (Callable[[str, dict]]): A callable invoked on incoming EDU",
            "                of the given type. The arguments are the origin server name and",
            "                the EDU contents.",
            "        \"\"\"",
            "        if edu_type in self.edu_handlers:",
            "            raise KeyError(\"Already have an EDU handler for %s\" % (edu_type,))",
            "",
            "        logger.info(\"Registering federation EDU handler for %r\", edu_type)",
            "",
            "        self.edu_handlers[edu_type] = handler",
            "",
            "    def register_query_handler(self, query_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation query of the given type.",
            "",
            "        Args:",
            "            query_type (str): Category name of the query, which should match",
            "                the string used by make_query.",
            "            handler (Callable[[dict], Deferred[dict]]): Invoked to handle",
            "                incoming queries of this type. The return will be yielded",
            "                on and the result used as the response to the query request.",
            "        \"\"\"",
            "        if query_type in self.query_handlers:",
            "            raise KeyError(",
            "                \"Already have a Query handler for %s\" % (query_type,)",
            "            )",
            "",
            "        logger.info(\"Registering federation query handler for %r\", query_type)",
            "",
            "        self.query_handlers[query_type] = handler",
            "",
            "    @defer.inlineCallbacks",
            "    def on_edu(self, edu_type, origin, content):",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for EDU type %s\", edu_type)",
            "",
            "        try:",
            "            yield handler(origin, content)",
            "        except SynapseError as e:",
            "            logger.info(\"Failed to handle edu %r: %r\", edu_type, e)",
            "        except Exception as e:",
            "            logger.exception(\"Failed to handle edu %r\", edu_type)",
            "",
            "    def on_query(self, query_type, args):",
            "        handler = self.query_handlers.get(query_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for query type %s\", query_type)",
            "            raise NotFoundError(\"No handler for Query type '%s'\" % (query_type,))",
            "",
            "        return handler(args)",
            "",
            "",
            "class ReplicationFederationHandlerRegistry(FederationHandlerRegistry):",
            "    \"\"\"A FederationHandlerRegistry for worker processes.",
            "",
            "    When receiving EDU or queries it will check if an appropriate handler has",
            "    been registered on the worker, if there isn't one then it calls off to the",
            "    master process.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "        self.clock = hs.get_clock()",
            "",
            "        self._get_query_client = ReplicationGetQueryRestServlet.make_client(hs)",
            "        self._send_edu = ReplicationFederationSendEduRestServlet.make_client(hs)",
            "",
            "        super(ReplicationFederationHandlerRegistry, self).__init__()",
            "",
            "    def on_edu(self, edu_type, origin, content):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if handler:",
            "            return super(ReplicationFederationHandlerRegistry, self).on_edu(",
            "                edu_type, origin, content,",
            "            )",
            "",
            "        return self._send_edu(",
            "                edu_type=edu_type,",
            "                origin=origin,",
            "                content=content,",
            "        )",
            "",
            "    def on_query(self, query_type, args):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.query_handlers.get(query_type)",
            "        if handler:",
            "            return handler(args)",
            "",
            "        return self._get_query_client(",
            "                query_type=query_type,",
            "                args=args,",
            "        )"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "import re",
            "",
            "import six",
            "from six import iteritems",
            "",
            "from canonicaljson import json",
            "from prometheus_client import Counter",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.abstract import isIPAddress",
            "from twisted.python import failure",
            "",
            "from synapse.api.constants import EventTypes",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    FederationError,",
            "    IncompatibleRoomVersionError,",
            "    NotFoundError,",
            "    SynapseError,",
            ")",
            "from synapse.crypto.event_signing import compute_event_signature",
            "from synapse.federation.federation_base import FederationBase, event_from_pdu_json",
            "from synapse.federation.persistence import TransactionActions",
            "from synapse.federation.units import Edu, Transaction",
            "from synapse.http.endpoint import parse_server_name",
            "from synapse.replication.http.federation import (",
            "    ReplicationFederationSendEduRestServlet,",
            "    ReplicationGetQueryRestServlet,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util.async_helpers import Linearizer, concurrently_execute",
            "from synapse.util.caches.response_cache import ResponseCache",
            "from synapse.util.logutils import log_function",
            "",
            "# when processing incoming transactions, we try to handle multiple rooms in",
            "# parallel, up to this limit.",
            "TRANSACTION_CONCURRENCY_LIMIT = 10",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "received_pdus_counter = Counter(\"synapse_federation_server_received_pdus\", \"\")",
            "",
            "received_edus_counter = Counter(\"synapse_federation_server_received_edus\", \"\")",
            "",
            "received_queries_counter = Counter(",
            "    \"synapse_federation_server_received_queries\", \"\", [\"type\"]",
            ")",
            "",
            "",
            "class FederationServer(FederationBase):",
            "",
            "    def __init__(self, hs):",
            "        super(FederationServer, self).__init__(hs)",
            "",
            "        self.auth = hs.get_auth()",
            "        self.handler = hs.get_handlers().federation_handler",
            "",
            "        self._server_linearizer = Linearizer(\"fed_server\")",
            "        self._transaction_linearizer = Linearizer(\"fed_txn_handler\")",
            "",
            "        self.transaction_actions = TransactionActions(self.store)",
            "",
            "        self.registry = hs.get_federation_registry()",
            "",
            "        # We cache responses to state queries, as they take a while and often",
            "        # come in waves.",
            "        self._state_resp_cache = ResponseCache(hs, \"state_resp\", timeout_ms=30000)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, versions, limit):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            pdus = yield self.handler.on_backfill_request(",
            "                origin, room_id, versions, limit",
            "            )",
            "",
            "            res = self._transaction_from_pdus(pdus).get_dict()",
            "",
            "        defer.returnValue((200, res))",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_incoming_transaction(self, origin, transaction_data):",
            "        # keep this as early as possible to make the calculated origin ts as",
            "        # accurate as possible.",
            "        request_time = self._clock.time_msec()",
            "",
            "        transaction = Transaction(**transaction_data)",
            "",
            "        if not transaction.transaction_id:",
            "            raise Exception(\"Transaction missing transaction_id\")",
            "",
            "        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)",
            "",
            "        # use a linearizer to ensure that we don't process the same transaction",
            "        # multiple times in parallel.",
            "        with (yield self._transaction_linearizer.queue(",
            "                (origin, transaction.transaction_id),",
            "        )):",
            "            result = yield self._handle_incoming_transaction(",
            "                origin, transaction, request_time,",
            "            )",
            "",
            "        defer.returnValue(result)",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_incoming_transaction(self, origin, transaction, request_time):",
            "        \"\"\" Process an incoming transaction and return the HTTP response",
            "",
            "        Args:",
            "            origin (unicode): the server making the request",
            "            transaction (Transaction): incoming transaction",
            "            request_time (int): timestamp that the HTTP request arrived at",
            "",
            "        Returns:",
            "            Deferred[(int, object)]: http response code and body",
            "        \"\"\"",
            "        response = yield self.transaction_actions.have_responded(origin, transaction)",
            "",
            "        if response:",
            "            logger.debug(",
            "                \"[%s] We've already responded to this request\",",
            "                transaction.transaction_id",
            "            )",
            "            defer.returnValue(response)",
            "            return",
            "",
            "        logger.debug(\"[%s] Transaction is new\", transaction.transaction_id)",
            "",
            "        received_pdus_counter.inc(len(transaction.pdus))",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "",
            "        pdus_by_room = {}",
            "",
            "        for p in transaction.pdus:",
            "            if \"unsigned\" in p:",
            "                unsigned = p[\"unsigned\"]",
            "                if \"age\" in unsigned:",
            "                    p[\"age\"] = unsigned[\"age\"]",
            "            if \"age\" in p:",
            "                p[\"age_ts\"] = request_time - int(p[\"age\"])",
            "                del p[\"age\"]",
            "",
            "            event = event_from_pdu_json(p)",
            "            room_id = event.room_id",
            "            pdus_by_room.setdefault(room_id, []).append(event)",
            "",
            "        pdu_results = {}",
            "",
            "        # we can process different rooms in parallel (which is useful if they",
            "        # require callouts to other servers to fetch missing events), but",
            "        # impose a limit to avoid going too crazy with ram/cpu.",
            "",
            "        @defer.inlineCallbacks",
            "        def process_pdus_for_room(room_id):",
            "            logger.debug(\"Processing PDUs for %s\", room_id)",
            "            try:",
            "                yield self.check_server_matches_acl(origin_host, room_id)",
            "            except AuthError as e:",
            "                logger.warn(",
            "                    \"Ignoring PDUs for room %s from banned server\", room_id,",
            "                )",
            "                for pdu in pdus_by_room[room_id]:",
            "                    event_id = pdu.event_id",
            "                    pdu_results[event_id] = e.error_dict()",
            "                return",
            "",
            "            for pdu in pdus_by_room[room_id]:",
            "                event_id = pdu.event_id",
            "                try:",
            "                    yield self._handle_received_pdu(",
            "                        origin, pdu",
            "                    )",
            "                    pdu_results[event_id] = {}",
            "                except FederationError as e:",
            "                    logger.warn(\"Error handling PDU %s: %s\", event_id, e)",
            "                    pdu_results[event_id] = {\"error\": str(e)}",
            "                except Exception as e:",
            "                    f = failure.Failure()",
            "                    pdu_results[event_id] = {\"error\": str(e)}",
            "                    logger.error(",
            "                        \"Failed to handle PDU %s: %s\",",
            "                        event_id, f.getTraceback().rstrip(),",
            "                    )",
            "",
            "        yield concurrently_execute(",
            "            process_pdus_for_room, pdus_by_room.keys(),",
            "            TRANSACTION_CONCURRENCY_LIMIT,",
            "        )",
            "",
            "        if hasattr(transaction, \"edus\"):",
            "            for edu in (Edu(**x) for x in transaction.edus):",
            "                yield self.received_edu(",
            "                    origin,",
            "                    edu.edu_type,",
            "                    edu.content",
            "                )",
            "",
            "        response = {",
            "            \"pdus\": pdu_results,",
            "        }",
            "",
            "        logger.debug(\"Returning: %s\", str(response))",
            "",
            "        yield self.transaction_actions.set_response(",
            "            origin,",
            "            transaction,",
            "            200, response",
            "        )",
            "        defer.returnValue((200, response))",
            "",
            "    @defer.inlineCallbacks",
            "    def received_edu(self, origin, edu_type, content):",
            "        received_edus_counter.inc()",
            "        yield self.registry.on_edu(edu_type, origin, content)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_context_state_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        # we grab the linearizer to protect ourselves from servers which hammer",
            "        # us. In theory we might already have the response to this query",
            "        # in the cache so we could return it without waiting for the linearizer",
            "        # - but that's non-trivial to get right, and anyway somewhat defeats",
            "        # the point of the linearizer.",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            resp = yield self._state_resp_cache.wrap(",
            "                (room_id, event_id),",
            "                self._on_context_state_request_compute,",
            "                room_id, event_id,",
            "            )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_state_ids_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        state_ids = yield self.handler.get_state_ids_for_pdu(",
            "            room_id, event_id,",
            "        )",
            "        auth_chain_ids = yield self.store.get_auth_chain_ids(state_ids)",
            "",
            "        defer.returnValue((200, {",
            "            \"pdu_ids\": state_ids,",
            "            \"auth_chain_ids\": auth_chain_ids,",
            "        }))",
            "",
            "    @defer.inlineCallbacks",
            "    def _on_context_state_request_compute(self, room_id, event_id):",
            "        pdus = yield self.handler.get_state_for_pdu(",
            "            room_id, event_id,",
            "        )",
            "        auth_chain = yield self.store.get_auth_chain(",
            "            [pdu.event_id for pdu in pdus]",
            "        )",
            "",
            "        for event in auth_chain:",
            "            # We sign these again because there was a bug where we",
            "            # incorrectly signed things the first time round",
            "            if self.hs.is_mine_id(event.event_id):",
            "                event.signatures.update(",
            "                    compute_event_signature(",
            "                        event,",
            "                        self.hs.hostname,",
            "                        self.hs.config.signing_key[0]",
            "                    )",
            "                )",
            "",
            "        defer.returnValue({",
            "            \"pdus\": [pdu.get_pdu_json() for pdu in pdus],",
            "            \"auth_chain\": [pdu.get_pdu_json() for pdu in auth_chain],",
            "        })",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pdu_request(self, origin, event_id):",
            "        pdu = yield self.handler.get_persisted_pdu(origin, event_id)",
            "",
            "        if pdu:",
            "            defer.returnValue(",
            "                (200, self._transaction_from_pdus([pdu]).get_dict())",
            "            )",
            "        else:",
            "            defer.returnValue((404, \"\"))",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pull_request(self, origin, versions):",
            "        raise NotImplementedError(\"Pull transactions not implemented\")",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_request(self, query_type, args):",
            "        received_queries_counter.labels(query_type).inc()",
            "        resp = yield self.registry.on_query(query_type, args)",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_join_request(self, origin, room_id, user_id, supported_versions):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        if room_version not in supported_versions:",
            "            logger.warn(\"Room version %s not in %s\", room_version, supported_versions)",
            "            raise IncompatibleRoomVersionError(room_version=room_version)",
            "",
            "        pdu = yield self.handler.on_make_join_request(room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue({",
            "            \"event\": pdu.get_pdu_json(time_now),",
            "            \"room_version\": room_version,",
            "        })",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, content):",
            "        pdu = event_from_pdu_json(content)",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "        ret_pdu = yield self.handler.on_invite_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue((200, {\"event\": ret_pdu.get_pdu_json(time_now)}))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_join_request(self, origin, content):",
            "        logger.debug(\"on_send_join_request: content: %s\", content)",
            "        pdu = event_from_pdu_json(content)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_join_request: pdu sigs: %s\", pdu.signatures)",
            "        res_pdus = yield self.handler.on_send_join_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue((200, {",
            "            \"state\": [p.get_pdu_json(time_now) for p in res_pdus[\"state\"]],",
            "            \"auth_chain\": [",
            "                p.get_pdu_json(time_now) for p in res_pdus[\"auth_chain\"]",
            "            ],",
            "        }))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "        pdu = yield self.handler.on_make_leave_request(room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        defer.returnValue({\"event\": pdu.get_pdu_json(time_now)})",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_leave_request(self, origin, content):",
            "        logger.debug(\"on_send_leave_request: content: %s\", content)",
            "        pdu = event_from_pdu_json(content)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_leave_request: pdu sigs: %s\", pdu.signatures)",
            "        yield self.handler.on_send_leave_request(origin, pdu)",
            "        defer.returnValue((200, {}))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, origin, room_id, event_id):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            time_now = self._clock.time_msec()",
            "            auth_pdus = yield self.handler.on_event_auth(event_id)",
            "            res = {",
            "                \"auth_chain\": [a.get_pdu_json(time_now) for a in auth_pdus],",
            "            }",
            "        defer.returnValue((200, res))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth_request(self, origin, content, room_id, event_id):",
            "        \"\"\"",
            "        Content is a dict with keys::",
            "            auth_chain (list): A list of events that give the auth chain.",
            "            missing (list): A list of event_ids indicating what the other",
            "              side (`origin`) think we're missing.",
            "            rejects (dict): A mapping from event_id to a 2-tuple of reason",
            "              string and a proof (or None) of why the event was rejected.",
            "              The keys of this dict give the list of events the `origin` has",
            "              rejected.",
            "",
            "        Args:",
            "            origin (str)",
            "            content (dict)",
            "            event_id (str)",
            "",
            "        Returns:",
            "            Deferred: Results in `dict` with the same format as `content`",
            "        \"\"\"",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            auth_chain = [",
            "                event_from_pdu_json(e)",
            "                for e in content[\"auth_chain\"]",
            "            ]",
            "",
            "            signed_auth = yield self._check_sigs_and_hash_and_fetch(",
            "                origin, auth_chain, outlier=True",
            "            )",
            "",
            "            ret = yield self.handler.on_query_auth(",
            "                origin,",
            "                event_id,",
            "                room_id,",
            "                signed_auth,",
            "                content.get(\"rejects\", []),",
            "                content.get(\"missing\", []),",
            "            )",
            "",
            "            time_now = self._clock.time_msec()",
            "            send_content = {",
            "                \"auth_chain\": [",
            "                    e.get_pdu_json(time_now)",
            "                    for e in ret[\"auth_chain\"]",
            "                ],",
            "                \"rejects\": ret.get(\"rejects\", []),",
            "                \"missing\": ret.get(\"missing\", []),",
            "            }",
            "",
            "        defer.returnValue(",
            "            (200, send_content)",
            "        )",
            "",
            "    @log_function",
            "    def on_query_client_keys(self, origin, content):",
            "        return self.on_query_request(\"client_keys\", content)",
            "",
            "    def on_query_user_devices(self, origin, user_id):",
            "        return self.on_query_request(\"user_devices\", user_id)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_claim_client_keys(self, origin, content):",
            "        query = []",
            "        for user_id, device_keys in content.get(\"one_time_keys\", {}).items():",
            "            for device_id, algorithm in device_keys.items():",
            "                query.append((user_id, device_id, algorithm))",
            "",
            "        results = yield self.store.claim_e2e_one_time_keys(query)",
            "",
            "        json_result = {}",
            "        for user_id, device_keys in results.items():",
            "            for device_id, keys in device_keys.items():",
            "                for key_id, json_bytes in keys.items():",
            "                    json_result.setdefault(user_id, {})[device_id] = {",
            "                        key_id: json.loads(json_bytes)",
            "                    }",
            "",
            "        logger.info(",
            "            \"Claimed one-time-keys: %s\",",
            "            \",\".join((",
            "                \"%s for %s:%s\" % (key_id, user_id, device_id)",
            "                for user_id, user_keys in iteritems(json_result)",
            "                for device_id, device_keys in iteritems(user_keys)",
            "                for key_id, _ in iteritems(device_keys)",
            "            )),",
            "        )",
            "",
            "        defer.returnValue({\"one_time_keys\": json_result})",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_get_missing_events(self, origin, room_id, earliest_events,",
            "                              latest_events, limit, min_depth):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            logger.info(",
            "                \"on_get_missing_events: earliest_events: %r, latest_events: %r,\"",
            "                \" limit: %d, min_depth: %d\",",
            "                earliest_events, latest_events, limit, min_depth",
            "            )",
            "",
            "            missing_events = yield self.handler.on_get_missing_events(",
            "                origin, room_id, earliest_events, latest_events, limit, min_depth",
            "            )",
            "",
            "            if len(missing_events) < 5:",
            "                logger.info(",
            "                    \"Returning %d events: %r\", len(missing_events), missing_events",
            "                )",
            "            else:",
            "                logger.info(\"Returning %d events\", len(missing_events))",
            "",
            "            time_now = self._clock.time_msec()",
            "",
            "        defer.returnValue({",
            "            \"events\": [ev.get_pdu_json(time_now) for ev in missing_events],",
            "        })",
            "",
            "    @log_function",
            "    def on_openid_userinfo(self, token):",
            "        ts_now_ms = self._clock.time_msec()",
            "        return self.store.get_user_id_for_open_id_token(token, ts_now_ms)",
            "",
            "    def _transaction_from_pdus(self, pdu_list):",
            "        \"\"\"Returns a new Transaction containing the given PDUs suitable for",
            "        transmission.",
            "        \"\"\"",
            "        time_now = self._clock.time_msec()",
            "        pdus = [p.get_pdu_json(time_now) for p in pdu_list]",
            "        return Transaction(",
            "            origin=self.server_name,",
            "            pdus=pdus,",
            "            origin_server_ts=int(time_now),",
            "            destination=None,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_received_pdu(self, origin, pdu):",
            "        \"\"\" Process a PDU received in a federation /send/ transaction.",
            "",
            "        If the event is invalid, then this method throws a FederationError.",
            "        (The error will then be logged and sent back to the sender (which",
            "        probably won't do anything with it), and other events in the",
            "        transaction will be processed as normal).",
            "",
            "        It is likely that we'll then receive other events which refer to",
            "        this rejected_event in their prev_events, etc.  When that happens,",
            "        we'll attempt to fetch the rejected event again, which will presumably",
            "        fail, so those second-generation events will also get rejected.",
            "",
            "        Eventually, we get to the point where there are more than 10 events",
            "        between any new events and the original rejected event. Since we",
            "        only try to backfill 10 events deep on received pdu, we then accept the",
            "        new event, possibly introducing a discontinuity in the DAG, with new",
            "        forward extremities, so normal service is approximately returned,",
            "        until we try to backfill across the discontinuity.",
            "",
            "        Args:",
            "            origin (str): server which sent the pdu",
            "            pdu (FrozenEvent): received pdu",
            "",
            "        Returns (Deferred): completes with None",
            "",
            "        Raises: FederationError if the signatures / hash do not match, or",
            "            if the event was unacceptable for any other reason (eg, too large,",
            "            too many prev_events, couldn't find the prev_events)",
            "        \"\"\"",
            "        # check that it's actually being sent from a valid destination to",
            "        # workaround bug #1753 in 0.18.5 and 0.18.6",
            "        if origin != get_domain_from_id(pdu.event_id):",
            "            # We continue to accept join events from any server; this is",
            "            # necessary for the federation join dance to work correctly.",
            "            # (When we join over federation, the \"helper\" server is",
            "            # responsible for sending out the join event, rather than the",
            "            # origin. See bug #1893).",
            "            if not (",
            "                pdu.type == 'm.room.member' and",
            "                pdu.content and",
            "                pdu.content.get(\"membership\", None) == 'join'",
            "            ):",
            "                logger.info(",
            "                    \"Discarding PDU %s from invalid origin %s\",",
            "                    pdu.event_id, origin",
            "                )",
            "                return",
            "            else:",
            "                logger.info(",
            "                    \"Accepting join PDU %s from %s\",",
            "                    pdu.event_id, origin",
            "                )",
            "",
            "        # Check signature.",
            "        try:",
            "            pdu = yield self._check_sigs_and_hash(pdu)",
            "        except SynapseError as e:",
            "            raise FederationError(",
            "                \"ERROR\",",
            "                e.code,",
            "                e.msg,",
            "                affected=pdu.event_id,",
            "            )",
            "",
            "        yield self.handler.on_receive_pdu(",
            "            origin, pdu, get_missing=True, sent_to_us_directly=True,",
            "        )",
            "",
            "    def __str__(self):",
            "        return \"<ReplicationLayer(%s)>\" % self.server_name",
            "",
            "    @defer.inlineCallbacks",
            "    def exchange_third_party_invite(",
            "            self,",
            "            sender_user_id,",
            "            target_user_id,",
            "            room_id,",
            "            signed,",
            "    ):",
            "        ret = yield self.handler.exchange_third_party_invite(",
            "            sender_user_id,",
            "            target_user_id,",
            "            room_id,",
            "            signed,",
            "        )",
            "        defer.returnValue(ret)",
            "",
            "    @defer.inlineCallbacks",
            "    def on_exchange_third_party_invite_request(self, origin, room_id, event_dict):",
            "        ret = yield self.handler.on_exchange_third_party_invite_request(",
            "            origin, room_id, event_dict",
            "        )",
            "        defer.returnValue(ret)",
            "",
            "    @defer.inlineCallbacks",
            "    def check_server_matches_acl(self, server_name, room_id):",
            "        \"\"\"Check if the given server is allowed by the server ACLs in the room",
            "",
            "        Args:",
            "            server_name (str): name of server, *without any port part*",
            "            room_id (str): ID of the room to check",
            "",
            "        Raises:",
            "            AuthError if the server does not match the ACL",
            "        \"\"\"",
            "        state_ids = yield self.store.get_current_state_ids(room_id)",
            "        acl_event_id = state_ids.get((EventTypes.ServerACL, \"\"))",
            "",
            "        if not acl_event_id:",
            "            return",
            "",
            "        acl_event = yield self.store.get_event(acl_event_id)",
            "        if server_matches_acl_event(server_name, acl_event):",
            "            return",
            "",
            "        raise AuthError(code=403, msg=\"Server is banned from room\")",
            "",
            "",
            "def server_matches_acl_event(server_name, acl_event):",
            "    \"\"\"Check if the given server is allowed by the ACL event",
            "",
            "    Args:",
            "        server_name (str): name of server, without any port part",
            "        acl_event (EventBase): m.room.server_acl event",
            "",
            "    Returns:",
            "        bool: True if this server is allowed by the ACLs",
            "    \"\"\"",
            "    logger.debug(\"Checking %s against acl %s\", server_name, acl_event.content)",
            "",
            "    # first of all, check if literal IPs are blocked, and if so, whether the",
            "    # server name is a literal IP",
            "    allow_ip_literals = acl_event.content.get(\"allow_ip_literals\", True)",
            "    if not isinstance(allow_ip_literals, bool):",
            "        logger.warn(\"Ignorning non-bool allow_ip_literals flag\")",
            "        allow_ip_literals = True",
            "    if not allow_ip_literals:",
            "        # check for ipv6 literals. These start with '['.",
            "        if server_name[0] == '[':",
            "            return False",
            "",
            "        # check for ipv4 literals. We can just lift the routine from twisted.",
            "        if isIPAddress(server_name):",
            "            return False",
            "",
            "    # next,  check the deny list",
            "    deny = acl_event.content.get(\"deny\", [])",
            "    if not isinstance(deny, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list deny ACL %s\", deny)",
            "        deny = []",
            "    for e in deny:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched deny rule %s\", server_name, e)",
            "            return False",
            "",
            "    # then the allow list.",
            "    allow = acl_event.content.get(\"allow\", [])",
            "    if not isinstance(allow, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list allow ACL %s\", allow)",
            "        allow = []",
            "    for e in allow:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched allow rule %s\", server_name, e)",
            "            return True",
            "",
            "    # everything else should be rejected.",
            "    # logger.info(\"%s fell through\", server_name)",
            "    return False",
            "",
            "",
            "def _acl_entry_matches(server_name, acl_entry):",
            "    if not isinstance(acl_entry, six.string_types):",
            "        logger.warn(\"Ignoring non-str ACL entry '%s' (is %s)\", acl_entry, type(acl_entry))",
            "        return False",
            "    regex = _glob_to_regex(acl_entry)",
            "    return regex.match(server_name)",
            "",
            "",
            "def _glob_to_regex(glob):",
            "    res = ''",
            "    for c in glob:",
            "        if c == '*':",
            "            res = res + '.*'",
            "        elif c == '?':",
            "            res = res + '.'",
            "        else:",
            "            res = res + re.escape(c)",
            "    return re.compile(res + \"\\\\Z\", re.IGNORECASE)",
            "",
            "",
            "class FederationHandlerRegistry(object):",
            "    \"\"\"Allows classes to register themselves as handlers for a given EDU or",
            "    query type for incoming federation traffic.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self.edu_handlers = {}",
            "        self.query_handlers = {}",
            "",
            "    def register_edu_handler(self, edu_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation EDU of the given type.",
            "",
            "        Args:",
            "            edu_type (str): The type of the incoming EDU to register handler for",
            "            handler (Callable[[str, dict]]): A callable invoked on incoming EDU",
            "                of the given type. The arguments are the origin server name and",
            "                the EDU contents.",
            "        \"\"\"",
            "        if edu_type in self.edu_handlers:",
            "            raise KeyError(\"Already have an EDU handler for %s\" % (edu_type,))",
            "",
            "        logger.info(\"Registering federation EDU handler for %r\", edu_type)",
            "",
            "        self.edu_handlers[edu_type] = handler",
            "",
            "    def register_query_handler(self, query_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation query of the given type.",
            "",
            "        Args:",
            "            query_type (str): Category name of the query, which should match",
            "                the string used by make_query.",
            "            handler (Callable[[dict], Deferred[dict]]): Invoked to handle",
            "                incoming queries of this type. The return will be yielded",
            "                on and the result used as the response to the query request.",
            "        \"\"\"",
            "        if query_type in self.query_handlers:",
            "            raise KeyError(",
            "                \"Already have a Query handler for %s\" % (query_type,)",
            "            )",
            "",
            "        logger.info(\"Registering federation query handler for %r\", query_type)",
            "",
            "        self.query_handlers[query_type] = handler",
            "",
            "    @defer.inlineCallbacks",
            "    def on_edu(self, edu_type, origin, content):",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for EDU type %s\", edu_type)",
            "",
            "        try:",
            "            yield handler(origin, content)",
            "        except SynapseError as e:",
            "            logger.info(\"Failed to handle edu %r: %r\", edu_type, e)",
            "        except Exception as e:",
            "            logger.exception(\"Failed to handle edu %r\", edu_type)",
            "",
            "    def on_query(self, query_type, args):",
            "        handler = self.query_handlers.get(query_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for query type %s\", query_type)",
            "            raise NotFoundError(\"No handler for Query type '%s'\" % (query_type,))",
            "",
            "        return handler(args)",
            "",
            "",
            "class ReplicationFederationHandlerRegistry(FederationHandlerRegistry):",
            "    \"\"\"A FederationHandlerRegistry for worker processes.",
            "",
            "    When receiving EDU or queries it will check if an appropriate handler has",
            "    been registered on the worker, if there isn't one then it calls off to the",
            "    master process.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "        self.clock = hs.get_clock()",
            "",
            "        self._get_query_client = ReplicationGetQueryRestServlet.make_client(hs)",
            "        self._send_edu = ReplicationFederationSendEduRestServlet.make_client(hs)",
            "",
            "        super(ReplicationFederationHandlerRegistry, self).__init__()",
            "",
            "    def on_edu(self, edu_type, origin, content):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if handler:",
            "            return super(ReplicationFederationHandlerRegistry, self).on_edu(",
            "                edu_type, origin, content,",
            "            )",
            "",
            "        return self._send_edu(",
            "                edu_type=edu_type,",
            "                origin=origin,",
            "                content=content,",
            "        )",
            "",
            "    def on_query(self, query_type, args):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.query_handlers.get(query_type)",
            "        if handler:",
            "            return handler(args)",
            "",
            "        return self._get_query_client(",
            "                query_type=query_type,",
            "                args=args,",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "102": [
                "FederationServer",
                "on_incoming_transaction"
            ],
            "111": [
                "FederationServer",
                "on_incoming_transaction"
            ],
            "112": [
                "FederationServer",
                "on_incoming_transaction"
            ],
            "119": [
                "FederationServer",
                "on_incoming_transaction"
            ],
            "122": [
                "FederationServer",
                "on_incoming_transaction"
            ],
            "128": [
                "FederationServer",
                "_handle_incoming_transaction"
            ],
            "138": [
                "FederationServer",
                "_handle_incoming_transaction"
            ],
            "152": [
                "FederationServer",
                "_handle_incoming_transaction"
            ],
            "193": [
                "FederationServer",
                "_handle_incoming_transaction",
                "process_pdus_for_room"
            ],
            "215": [
                "FederationServer",
                "_handle_incoming_transaction"
            ]
        },
        "addLocation": []
    },
    "synapse/federation/persistence.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "         self.store = datastore"
            },
            "1": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "     @log_function"
            },
            "3": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def have_responded(self, transaction):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+    def have_responded(self, origin, transaction):"
            },
            "5": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "         \"\"\" Have we already responded to a transaction with the same id and"
            },
            "6": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         origin?"
            },
            "7": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "                                \"transaction_id\")"
            },
            "9": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "         return self.store.get_received_txn_response("
            },
            "11": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            transaction.transaction_id, transaction.origin"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+            transaction.transaction_id, origin"
            },
            "13": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "         )"
            },
            "14": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "     @log_function"
            },
            "16": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def set_response(self, transaction, code, response):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+    def set_response(self, origin, transaction, code, response):"
            },
            "18": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         \"\"\" Persist how we responded to a transaction."
            },
            "19": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "         Returns:"
            },
            "21": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "         return self.store.set_received_txn_response("
            },
            "23": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "             transaction.transaction_id,"
            },
            "24": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            transaction.origin,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+            origin,"
            },
            "26": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "             code,"
            },
            "27": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "             response,"
            },
            "28": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "         )"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\" This module contains all the persistence actions done by the federation",
            "package.",
            "",
            "These actions are mostly only used by the :py:mod:`.replication` module.",
            "\"\"\"",
            "",
            "import logging",
            "",
            "from twisted.internet import defer",
            "",
            "from synapse.util.logutils import log_function",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class TransactionActions(object):",
            "    \"\"\" Defines persistence actions that relate to handling Transactions.",
            "    \"\"\"",
            "",
            "    def __init__(self, datastore):",
            "        self.store = datastore",
            "",
            "    @log_function",
            "    def have_responded(self, transaction):",
            "        \"\"\" Have we already responded to a transaction with the same id and",
            "        origin?",
            "",
            "        Returns:",
            "            Deferred: Results in `None` if we have not previously responded to",
            "            this transaction or a 2-tuple of `(int, dict)` representing the",
            "            response code and response body.",
            "        \"\"\"",
            "        if not transaction.transaction_id:",
            "            raise RuntimeError(\"Cannot persist a transaction with no \"",
            "                               \"transaction_id\")",
            "",
            "        return self.store.get_received_txn_response(",
            "            transaction.transaction_id, transaction.origin",
            "        )",
            "",
            "    @log_function",
            "    def set_response(self, transaction, code, response):",
            "        \"\"\" Persist how we responded to a transaction.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        if not transaction.transaction_id:",
            "            raise RuntimeError(\"Cannot persist a transaction with no \"",
            "                               \"transaction_id\")",
            "",
            "        return self.store.set_received_txn_response(",
            "            transaction.transaction_id,",
            "            transaction.origin,",
            "            code,",
            "            response,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def prepare_to_send(self, transaction):",
            "        \"\"\" Persists the `Transaction` we are about to send and works out the",
            "        correct value for the `prev_ids` key.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        transaction.prev_ids = yield self.store.prep_send_transaction(",
            "            transaction.transaction_id,",
            "            transaction.destination,",
            "            transaction.origin_server_ts,",
            "        )",
            "",
            "    @log_function",
            "    def delivered(self, transaction, response_code, response_dict):",
            "        \"\"\" Marks the given `Transaction` as having been successfully",
            "        delivered to the remote homeserver, and what the response was.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        return self.store.delivered_txn(",
            "            transaction.transaction_id,",
            "            transaction.destination,",
            "            response_code,",
            "            response_dict,",
            "        )"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\" This module contains all the persistence actions done by the federation",
            "package.",
            "",
            "These actions are mostly only used by the :py:mod:`.replication` module.",
            "\"\"\"",
            "",
            "import logging",
            "",
            "from twisted.internet import defer",
            "",
            "from synapse.util.logutils import log_function",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class TransactionActions(object):",
            "    \"\"\" Defines persistence actions that relate to handling Transactions.",
            "    \"\"\"",
            "",
            "    def __init__(self, datastore):",
            "        self.store = datastore",
            "",
            "    @log_function",
            "    def have_responded(self, origin, transaction):",
            "        \"\"\" Have we already responded to a transaction with the same id and",
            "        origin?",
            "",
            "        Returns:",
            "            Deferred: Results in `None` if we have not previously responded to",
            "            this transaction or a 2-tuple of `(int, dict)` representing the",
            "            response code and response body.",
            "        \"\"\"",
            "        if not transaction.transaction_id:",
            "            raise RuntimeError(\"Cannot persist a transaction with no \"",
            "                               \"transaction_id\")",
            "",
            "        return self.store.get_received_txn_response(",
            "            transaction.transaction_id, origin",
            "        )",
            "",
            "    @log_function",
            "    def set_response(self, origin, transaction, code, response):",
            "        \"\"\" Persist how we responded to a transaction.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        if not transaction.transaction_id:",
            "            raise RuntimeError(\"Cannot persist a transaction with no \"",
            "                               \"transaction_id\")",
            "",
            "        return self.store.set_received_txn_response(",
            "            transaction.transaction_id,",
            "            origin,",
            "            code,",
            "            response,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def prepare_to_send(self, transaction):",
            "        \"\"\" Persists the `Transaction` we are about to send and works out the",
            "        correct value for the `prev_ids` key.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        transaction.prev_ids = yield self.store.prep_send_transaction(",
            "            transaction.transaction_id,",
            "            transaction.destination,",
            "            transaction.origin_server_ts,",
            "        )",
            "",
            "    @log_function",
            "    def delivered(self, transaction, response_code, response_dict):",
            "        \"\"\" Marks the given `Transaction` as having been successfully",
            "        delivered to the remote homeserver, and what the response was.",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        return self.store.delivered_txn(",
            "            transaction.transaction_id,",
            "            transaction.destination,",
            "            response_code,",
            "            response_dict,",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "39": [
                "TransactionActions",
                "have_responded"
            ],
            "53": [
                "TransactionActions",
                "have_responded"
            ],
            "57": [
                "TransactionActions",
                "set_response"
            ],
            "69": [
                "TransactionActions",
                "set_response"
            ]
        },
        "addLocation": []
    },
    "synapse/federation/transport/server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 353,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 354,
                "PatchRowcode": "         try:"
            },
            "2": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 355,
                "PatchRowcode": "             code, response = yield self.handler.on_incoming_transaction("
            },
            "3": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                transaction_data"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+                origin, transaction_data,"
            },
            "5": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "             )"
            },
            "6": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 358,
                "PatchRowcode": "         except Exception:"
            },
            "7": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": 359,
                "PatchRowcode": "             logger.exception(\"on_incoming_transaction failed\")"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import functools",
            "import logging",
            "import re",
            "",
            "from twisted.internet import defer",
            "",
            "import synapse",
            "from synapse.api.errors import Codes, FederationDeniedError, SynapseError",
            "from synapse.api.urls import FEDERATION_PREFIX as PREFIX",
            "from synapse.http.endpoint import parse_and_validate_server_name",
            "from synapse.http.server import JsonResource",
            "from synapse.http.servlet import (",
            "    parse_boolean_from_args,",
            "    parse_integer_from_args,",
            "    parse_json_object_from_request,",
            "    parse_string_from_args,",
            ")",
            "from synapse.types import ThirdPartyInstanceID, get_domain_from_id",
            "from synapse.util.logcontext import run_in_background",
            "from synapse.util.ratelimitutils import FederationRateLimiter",
            "from synapse.util.versionstring import get_version_string",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class TransportLayerServer(JsonResource):",
            "    \"\"\"Handles incoming federation HTTP requests\"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "        self.clock = hs.get_clock()",
            "",
            "        super(TransportLayerServer, self).__init__(hs, canonical_json=False)",
            "",
            "        self.authenticator = Authenticator(hs)",
            "        self.ratelimiter = FederationRateLimiter(",
            "            self.clock,",
            "            window_size=hs.config.federation_rc_window_size,",
            "            sleep_limit=hs.config.federation_rc_sleep_limit,",
            "            sleep_msec=hs.config.federation_rc_sleep_delay,",
            "            reject_limit=hs.config.federation_rc_reject_limit,",
            "            concurrent_requests=hs.config.federation_rc_concurrent,",
            "        )",
            "",
            "        self.register_servlets()",
            "",
            "    def register_servlets(self):",
            "        register_servlets(",
            "            self.hs,",
            "            resource=self,",
            "            ratelimiter=self.ratelimiter,",
            "            authenticator=self.authenticator,",
            "        )",
            "",
            "",
            "class AuthenticationError(SynapseError):",
            "    \"\"\"There was a problem authenticating the request\"\"\"",
            "    pass",
            "",
            "",
            "class NoAuthenticationError(AuthenticationError):",
            "    \"\"\"The request had no authentication information\"\"\"",
            "    pass",
            "",
            "",
            "class Authenticator(object):",
            "    def __init__(self, hs):",
            "        self.keyring = hs.get_keyring()",
            "        self.server_name = hs.hostname",
            "        self.store = hs.get_datastore()",
            "        self.federation_domain_whitelist = hs.config.federation_domain_whitelist",
            "",
            "    # A method just so we can pass 'self' as the authenticator to the Servlets",
            "    @defer.inlineCallbacks",
            "    def authenticate_request(self, request, content):",
            "        json_request = {",
            "            \"method\": request.method,",
            "            \"uri\": request.uri,",
            "            \"destination\": self.server_name,",
            "            \"signatures\": {},",
            "        }",
            "",
            "        if content is not None:",
            "            json_request[\"content\"] = content",
            "",
            "        origin = None",
            "",
            "        auth_headers = request.requestHeaders.getRawHeaders(b\"Authorization\")",
            "",
            "        if not auth_headers:",
            "            raise NoAuthenticationError(",
            "                401, \"Missing Authorization headers\", Codes.UNAUTHORIZED,",
            "            )",
            "",
            "        for auth in auth_headers:",
            "            if auth.startswith(b\"X-Matrix\"):",
            "                (origin, key, sig) = _parse_auth_header(auth)",
            "                json_request[\"origin\"] = origin",
            "                json_request[\"signatures\"].setdefault(origin, {})[key] = sig",
            "",
            "        if (",
            "            self.federation_domain_whitelist is not None and",
            "            origin not in self.federation_domain_whitelist",
            "        ):",
            "            raise FederationDeniedError(origin)",
            "",
            "        if not json_request[\"signatures\"]:",
            "            raise NoAuthenticationError(",
            "                401, \"Missing Authorization headers\", Codes.UNAUTHORIZED,",
            "            )",
            "",
            "        yield self.keyring.verify_json_for_server(origin, json_request)",
            "",
            "        logger.info(\"Request from %s\", origin)",
            "        request.authenticated_entity = origin",
            "",
            "        # If we get a valid signed request from the other side, its probably",
            "        # alive",
            "        retry_timings = yield self.store.get_destination_retry_timings(origin)",
            "        if retry_timings and retry_timings[\"retry_last_ts\"]:",
            "            run_in_background(self._reset_retry_timings, origin)",
            "",
            "        defer.returnValue(origin)",
            "",
            "    @defer.inlineCallbacks",
            "    def _reset_retry_timings(self, origin):",
            "        try:",
            "            logger.info(\"Marking origin %r as up\", origin)",
            "            yield self.store.set_destination_retry_timings(origin, 0, 0)",
            "        except Exception:",
            "            logger.exception(\"Error resetting retry timings on %s\", origin)",
            "",
            "",
            "def _parse_auth_header(header_bytes):",
            "    \"\"\"Parse an X-Matrix auth header",
            "",
            "    Args:",
            "        header_bytes (bytes): header value",
            "",
            "    Returns:",
            "        Tuple[str, str, str]: origin, key id, signature.",
            "",
            "    Raises:",
            "        AuthenticationError if the header could not be parsed",
            "    \"\"\"",
            "    try:",
            "        header_str = header_bytes.decode('utf-8')",
            "        params = header_str.split(\" \")[1].split(\",\")",
            "        param_dict = dict(kv.split(\"=\") for kv in params)",
            "",
            "        def strip_quotes(value):",
            "            if value.startswith(\"\\\"\"):",
            "                return value[1:-1]",
            "            else:",
            "                return value",
            "",
            "        origin = strip_quotes(param_dict[\"origin\"])",
            "",
            "        # ensure that the origin is a valid server name",
            "        parse_and_validate_server_name(origin)",
            "",
            "        key = strip_quotes(param_dict[\"key\"])",
            "        sig = strip_quotes(param_dict[\"sig\"])",
            "        return origin, key, sig",
            "    except Exception as e:",
            "        logger.warn(",
            "            \"Error parsing auth header '%s': %s\",",
            "            header_bytes.decode('ascii', 'replace'),",
            "            e,",
            "        )",
            "        raise AuthenticationError(",
            "            400, \"Malformed Authorization header\", Codes.UNAUTHORIZED,",
            "        )",
            "",
            "",
            "class BaseFederationServlet(object):",
            "    \"\"\"Abstract base class for federation servlet classes.",
            "",
            "    The servlet object should have a PATH attribute which takes the form of a regexp to",
            "    match against the request path (excluding the /federation/v1 prefix).",
            "",
            "    The servlet should also implement one or more of on_GET, on_POST, on_PUT, to match",
            "    the appropriate HTTP method. These methods have the signature:",
            "",
            "        on_<METHOD>(self, origin, content, query, **kwargs)",
            "",
            "        With arguments:",
            "",
            "            origin (unicode|None): The authenticated server_name of the calling server,",
            "                unless REQUIRE_AUTH is set to False and authentication failed.",
            "",
            "            content (unicode|None): decoded json body of the request. None if the",
            "                request was a GET.",
            "",
            "            query (dict[bytes, list[bytes]]): Query params from the request. url-decoded",
            "                (ie, '+' and '%xx' are decoded) but note that it is *not* utf8-decoded",
            "                yet.",
            "",
            "            **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                components as specified in the path match regexp.",
            "",
            "        Returns:",
            "            Deferred[(int, object)|None]: either (response code, response object) to",
            "                 return a JSON response, or None if the request has already been handled.",
            "",
            "        Raises:",
            "            SynapseError: to return an error code",
            "",
            "            Exception: other exceptions will be caught, logged, and a 500 will be",
            "                returned.",
            "    \"\"\"",
            "    REQUIRE_AUTH = True",
            "",
            "    def __init__(self, handler, authenticator, ratelimiter, server_name):",
            "        self.handler = handler",
            "        self.authenticator = authenticator",
            "        self.ratelimiter = ratelimiter",
            "",
            "    def _wrap(self, func):",
            "        authenticator = self.authenticator",
            "        ratelimiter = self.ratelimiter",
            "",
            "        @defer.inlineCallbacks",
            "        @functools.wraps(func)",
            "        def new_func(request, *args, **kwargs):",
            "            \"\"\" A callback which can be passed to HttpServer.RegisterPaths",
            "",
            "            Args:",
            "                request (twisted.web.http.Request):",
            "                *args: unused?",
            "                **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                    components as specified in the path match regexp.",
            "",
            "            Returns:",
            "                Deferred[(int, object)|None]: (response code, response object) as returned",
            "                    by the callback method. None if the request has already been handled.",
            "            \"\"\"",
            "            content = None",
            "            if request.method in [\"PUT\", \"POST\"]:",
            "                # TODO: Handle other method types? other content types?",
            "                content = parse_json_object_from_request(request)",
            "",
            "            try:",
            "                origin = yield authenticator.authenticate_request(request, content)",
            "            except NoAuthenticationError:",
            "                origin = None",
            "                if self.REQUIRE_AUTH:",
            "                    logger.warn(\"authenticate_request failed: missing authentication\")",
            "                    raise",
            "            except Exception as e:",
            "                logger.warn(\"authenticate_request failed: %s\", e)",
            "                raise",
            "",
            "            if origin:",
            "                with ratelimiter.ratelimit(origin) as d:",
            "                    yield d",
            "                    response = yield func(",
            "                        origin, content, request.args, *args, **kwargs",
            "                    )",
            "            else:",
            "                response = yield func(",
            "                    origin, content, request.args, *args, **kwargs",
            "                )",
            "",
            "            defer.returnValue(response)",
            "",
            "        # Extra logic that functools.wraps() doesn't finish",
            "        new_func.__self__ = func.__self__",
            "",
            "        return new_func",
            "",
            "    def register(self, server):",
            "        pattern = re.compile(\"^\" + PREFIX + self.PATH + \"$\")",
            "",
            "        for method in (\"GET\", \"PUT\", \"POST\"):",
            "            code = getattr(self, \"on_%s\" % (method), None)",
            "            if code is None:",
            "                continue",
            "",
            "            server.register_paths(method, (pattern,), self._wrap(code))",
            "",
            "",
            "class FederationSendServlet(BaseFederationServlet):",
            "    PATH = \"/send/(?P<transaction_id>[^/]*)/\"",
            "",
            "    def __init__(self, handler, server_name, **kwargs):",
            "        super(FederationSendServlet, self).__init__(",
            "            handler, server_name=server_name, **kwargs",
            "        )",
            "        self.server_name = server_name",
            "",
            "    # This is when someone is trying to send us a bunch of data.",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, transaction_id):",
            "        \"\"\" Called on PUT /send/<transaction_id>/",
            "",
            "        Args:",
            "            request (twisted.web.http.Request): The HTTP request.",
            "            transaction_id (str): The transaction_id associated with this",
            "                request. This is *not* None.",
            "",
            "        Returns:",
            "            Deferred: Results in a tuple of `(code, response)`, where",
            "            `response` is a python dict to be converted into JSON that is",
            "            used as the response body.",
            "        \"\"\"",
            "        # Parse the request",
            "        try:",
            "            transaction_data = content",
            "",
            "            logger.debug(",
            "                \"Decoded %s: %s\",",
            "                transaction_id, str(transaction_data)",
            "            )",
            "",
            "            logger.info(",
            "                \"Received txn %s from %s. (PDUs: %d, EDUs: %d)\",",
            "                transaction_id, origin,",
            "                len(transaction_data.get(\"pdus\", [])),",
            "                len(transaction_data.get(\"edus\", [])),",
            "            )",
            "",
            "            # We should ideally be getting this from the security layer.",
            "            # origin = body[\"origin\"]",
            "",
            "            # Add some extra data to the transaction dict that isn't included",
            "            # in the request body.",
            "            transaction_data.update(",
            "                transaction_id=transaction_id,",
            "                destination=self.server_name",
            "            )",
            "",
            "        except Exception as e:",
            "            logger.exception(e)",
            "            defer.returnValue((400, {\"error\": \"Invalid transaction\"}))",
            "            return",
            "",
            "        try:",
            "            code, response = yield self.handler.on_incoming_transaction(",
            "                transaction_data",
            "            )",
            "        except Exception:",
            "            logger.exception(\"on_incoming_transaction failed\")",
            "            raise",
            "",
            "        defer.returnValue((code, response))",
            "",
            "",
            "class FederationPullServlet(BaseFederationServlet):",
            "    PATH = \"/pull/\"",
            "",
            "    # This is for when someone asks us for everything since version X",
            "    def on_GET(self, origin, content, query):",
            "        return self.handler.on_pull_request(query[\"origin\"][0], query[\"v\"])",
            "",
            "",
            "class FederationEventServlet(BaseFederationServlet):",
            "    PATH = \"/event/(?P<event_id>[^/]*)/\"",
            "",
            "    # This is when someone asks for a data item for a given server data_id pair.",
            "    def on_GET(self, origin, content, query, event_id):",
            "        return self.handler.on_pdu_request(origin, event_id)",
            "",
            "",
            "class FederationStateServlet(BaseFederationServlet):",
            "    PATH = \"/state/(?P<context>[^/]*)/\"",
            "",
            "    # This is when someone asks for all data for a given context.",
            "    def on_GET(self, origin, content, query, context):",
            "        return self.handler.on_context_state_request(",
            "            origin,",
            "            context,",
            "            query.get(\"event_id\", [None])[0],",
            "        )",
            "",
            "",
            "class FederationStateIdsServlet(BaseFederationServlet):",
            "    PATH = \"/state_ids/(?P<room_id>[^/]*)/\"",
            "",
            "    def on_GET(self, origin, content, query, room_id):",
            "        return self.handler.on_state_ids_request(",
            "            origin,",
            "            room_id,",
            "            query.get(\"event_id\", [None])[0],",
            "        )",
            "",
            "",
            "class FederationBackfillServlet(BaseFederationServlet):",
            "    PATH = \"/backfill/(?P<context>[^/]*)/\"",
            "",
            "    def on_GET(self, origin, content, query, context):",
            "        versions = query[\"v\"]",
            "        limits = query[\"limit\"]",
            "",
            "        if not limits:",
            "            return defer.succeed((400, {\"error\": \"Did not include limit param\"}))",
            "",
            "        limit = int(limits[-1])",
            "",
            "        return self.handler.on_backfill_request(origin, context, versions, limit)",
            "",
            "",
            "class FederationQueryServlet(BaseFederationServlet):",
            "    PATH = \"/query/(?P<query_type>[^/]*)\"",
            "",
            "    # This is when we receive a server-server Query",
            "    def on_GET(self, origin, content, query, query_type):",
            "        return self.handler.on_query_request(",
            "            query_type,",
            "            {k: v[0].decode(\"utf-8\") for k, v in query.items()}",
            "        )",
            "",
            "",
            "class FederationMakeJoinServlet(BaseFederationServlet):",
            "    PATH = \"/make_join/(?P<context>[^/]*)/(?P<user_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, _content, query, context, user_id):",
            "        \"\"\"",
            "        Args:",
            "            origin (unicode): The authenticated server_name of the calling server",
            "",
            "            _content (None): (GETs don't have bodies)",
            "",
            "            query (dict[bytes, list[bytes]]): Query params from the request.",
            "",
            "            **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                components as specified in the path match regexp.",
            "",
            "        Returns:",
            "            Deferred[(int, object)|None]: either (response code, response object) to",
            "                 return a JSON response, or None if the request has already been handled.",
            "        \"\"\"",
            "        versions = query.get(b'ver')",
            "        if versions is not None:",
            "            supported_versions = [v.decode(\"utf-8\") for v in versions]",
            "        else:",
            "            supported_versions = [\"1\"]",
            "",
            "        content = yield self.handler.on_make_join_request(",
            "            origin, context, user_id,",
            "            supported_versions=supported_versions,",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationMakeLeaveServlet(BaseFederationServlet):",
            "    PATH = \"/make_leave/(?P<context>[^/]*)/(?P<user_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, context, user_id):",
            "        content = yield self.handler.on_make_leave_request(",
            "            origin, context, user_id,",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationSendLeaveServlet(BaseFederationServlet):",
            "    PATH = \"/send_leave/(?P<room_id>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, room_id, event_id):",
            "        content = yield self.handler.on_send_leave_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationEventAuthServlet(BaseFederationServlet):",
            "    PATH = \"/event_auth/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    def on_GET(self, origin, content, query, context, event_id):",
            "        return self.handler.on_event_auth(origin, context, event_id)",
            "",
            "",
            "class FederationSendJoinServlet(BaseFederationServlet):",
            "    PATH = \"/send_join/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, context, event_id):",
            "        # TODO(paul): assert that context/event_id parsed from path actually",
            "        #   match those given in content",
            "        content = yield self.handler.on_send_join_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationInviteServlet(BaseFederationServlet):",
            "    PATH = \"/invite/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, context, event_id):",
            "        # TODO(paul): assert that context/event_id parsed from path actually",
            "        #   match those given in content",
            "        content = yield self.handler.on_invite_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationThirdPartyInviteExchangeServlet(BaseFederationServlet):",
            "    PATH = \"/exchange_third_party_invite/(?P<room_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, room_id):",
            "        content = yield self.handler.on_exchange_third_party_invite_request(",
            "            origin, room_id, content",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationClientKeysQueryServlet(BaseFederationServlet):",
            "    PATH = \"/user/keys/query\"",
            "",
            "    def on_POST(self, origin, content, query):",
            "        return self.handler.on_query_client_keys(origin, content)",
            "",
            "",
            "class FederationUserDevicesQueryServlet(BaseFederationServlet):",
            "    PATH = \"/user/devices/(?P<user_id>[^/]*)\"",
            "",
            "    def on_GET(self, origin, content, query, user_id):",
            "        return self.handler.on_query_user_devices(origin, user_id)",
            "",
            "",
            "class FederationClientKeysClaimServlet(BaseFederationServlet):",
            "    PATH = \"/user/keys/claim\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        response = yield self.handler.on_claim_client_keys(origin, content)",
            "        defer.returnValue((200, response))",
            "",
            "",
            "class FederationQueryAuthServlet(BaseFederationServlet):",
            "    PATH = \"/query_auth/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, context, event_id):",
            "        new_content = yield self.handler.on_query_auth_request(",
            "            origin, content, context, event_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGetMissingEventsServlet(BaseFederationServlet):",
            "    # TODO(paul): Why does this path alone end with \"/?\" optional?",
            "    PATH = \"/get_missing_events/(?P<room_id>[^/]*)/?\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, room_id):",
            "        limit = int(content.get(\"limit\", 10))",
            "        min_depth = int(content.get(\"min_depth\", 0))",
            "        earliest_events = content.get(\"earliest_events\", [])",
            "        latest_events = content.get(\"latest_events\", [])",
            "",
            "        content = yield self.handler.on_get_missing_events(",
            "            origin,",
            "            room_id=room_id,",
            "            earliest_events=earliest_events,",
            "            latest_events=latest_events,",
            "            min_depth=min_depth,",
            "            limit=limit,",
            "        )",
            "",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class On3pidBindServlet(BaseFederationServlet):",
            "    PATH = \"/3pid/onbind\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        if \"invites\" in content:",
            "            last_exception = None",
            "            for invite in content[\"invites\"]:",
            "                try:",
            "                    if \"signed\" not in invite or \"token\" not in invite[\"signed\"]:",
            "                        message = (\"Rejecting received notification of third-\"",
            "                                   \"party invite without signed: %s\" % (invite,))",
            "                        logger.info(message)",
            "                        raise SynapseError(400, message)",
            "                    yield self.handler.exchange_third_party_invite(",
            "                        invite[\"sender\"],",
            "                        invite[\"mxid\"],",
            "                        invite[\"room_id\"],",
            "                        invite[\"signed\"],",
            "                    )",
            "                except Exception as e:",
            "                    last_exception = e",
            "            if last_exception:",
            "                raise last_exception",
            "        defer.returnValue((200, {}))",
            "",
            "",
            "class OpenIdUserInfo(BaseFederationServlet):",
            "    \"\"\"",
            "    Exchange a bearer token for information about a user.",
            "",
            "    The response format should be compatible with:",
            "        http://openid.net/specs/openid-connect-core-1_0.html#UserInfoResponse",
            "",
            "    GET /openid/userinfo?access_token=ABDEFGH HTTP/1.1",
            "",
            "    HTTP/1.1 200 OK",
            "    Content-Type: application/json",
            "",
            "    {",
            "        \"sub\": \"@userpart:example.org\",",
            "    }",
            "    \"\"\"",
            "",
            "    PATH = \"/openid/userinfo\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query):",
            "        token = query.get(\"access_token\", [None])[0]",
            "        if token is None:",
            "            defer.returnValue((401, {",
            "                \"errcode\": \"M_MISSING_TOKEN\", \"error\": \"Access Token required\"",
            "            }))",
            "            return",
            "",
            "        user_id = yield self.handler.on_openid_userinfo(token)",
            "",
            "        if user_id is None:",
            "            defer.returnValue((401, {",
            "                \"errcode\": \"M_UNKNOWN_TOKEN\",",
            "                \"error\": \"Access Token unknown or expired\"",
            "            }))",
            "",
            "        defer.returnValue((200, {\"sub\": user_id}))",
            "",
            "",
            "class PublicRoomList(BaseFederationServlet):",
            "    \"\"\"",
            "    Fetch the public room list for this server.",
            "",
            "    This API returns information in the same format as /publicRooms on the",
            "    client API, but will only ever include local public rooms and hence is",
            "    intended for consumption by other home servers.",
            "",
            "    GET /publicRooms HTTP/1.1",
            "",
            "    HTTP/1.1 200 OK",
            "    Content-Type: application/json",
            "",
            "    {",
            "        \"chunk\": [",
            "            {",
            "                \"aliases\": [",
            "                    \"#test:localhost\"",
            "                ],",
            "                \"guest_can_join\": false,",
            "                \"name\": \"test room\",",
            "                \"num_joined_members\": 3,",
            "                \"room_id\": \"!whkydVegtvatLfXmPN:localhost\",",
            "                \"world_readable\": false",
            "            }",
            "        ],",
            "        \"end\": \"END\",",
            "        \"start\": \"START\"",
            "    }",
            "    \"\"\"",
            "",
            "    PATH = \"/publicRooms\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query):",
            "        limit = parse_integer_from_args(query, \"limit\", 0)",
            "        since_token = parse_string_from_args(query, \"since\", None)",
            "        include_all_networks = parse_boolean_from_args(",
            "            query, \"include_all_networks\", False",
            "        )",
            "        third_party_instance_id = parse_string_from_args(",
            "            query, \"third_party_instance_id\", None",
            "        )",
            "",
            "        if include_all_networks:",
            "            network_tuple = None",
            "        elif third_party_instance_id:",
            "            network_tuple = ThirdPartyInstanceID.from_string(third_party_instance_id)",
            "        else:",
            "            network_tuple = ThirdPartyInstanceID(None, None)",
            "",
            "        data = yield self.handler.get_local_public_room_list(",
            "            limit, since_token,",
            "            network_tuple=network_tuple",
            "        )",
            "        defer.returnValue((200, data))",
            "",
            "",
            "class FederationVersionServlet(BaseFederationServlet):",
            "    PATH = \"/version\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    def on_GET(self, origin, content, query):",
            "        return defer.succeed((200, {",
            "            \"server\": {",
            "                \"name\": \"Synapse\",",
            "                \"version\": get_version_string(synapse)",
            "            },",
            "        }))",
            "",
            "",
            "class FederationGroupsProfileServlet(BaseFederationServlet):",
            "    \"\"\"Get/set the basic profile of a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/profile$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_group_profile(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.update_group_profile(",
            "            group_id, requester_user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsSummaryServlet(BaseFederationServlet):",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/summary$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_group_summary(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Get the rooms in a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/rooms$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_rooms_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAddRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove room from group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/room/(?P<room_id>[^/]*)$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.add_room_to_group(",
            "            group_id, requester_user_id, room_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.remove_room_from_group(",
            "            group_id, requester_user_id, room_id,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAddRoomsConfigServlet(BaseFederationServlet):",
            "    \"\"\"Update room config in group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/room/(?P<room_id>[^/]*)\"",
            "        \"/config/(?P<config_key>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, room_id, config_key):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        result = yield self.groups_handler.update_room_in_group(",
            "            group_id, requester_user_id, room_id, config_key, content,",
            "        )",
            "",
            "        defer.returnValue((200, result))",
            "",
            "",
            "class FederationGroupsUsersServlet(BaseFederationServlet):",
            "    \"\"\"Get the users in a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_users_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsInvitedUsersServlet(BaseFederationServlet):",
            "    \"\"\"Get the users that have been invited to a group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/invited_users$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_invited_users_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsInviteServlet(BaseFederationServlet):",
            "    \"\"\"Ask a group server to invite someone to the group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.invite_to_group(",
            "            group_id, user_id, requester_user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAcceptInviteServlet(BaseFederationServlet):",
            "    \"\"\"Accept an invitation from the group server",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/accept_invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(user_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.accept_invite(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsJoinServlet(BaseFederationServlet):",
            "    \"\"\"Attempt to join a group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/join$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(user_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.join_group(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRemoveUserServlet(BaseFederationServlet):",
            "    \"\"\"Leave or kick a user from the group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/remove$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.remove_user_from_group(",
            "            group_id, user_id, requester_user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsLocalInviteServlet(BaseFederationServlet):",
            "    \"\"\"A group server has invited a local user",
            "    \"\"\"",
            "    PATH = \"/groups/local/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(group_id) != origin:",
            "            raise SynapseError(403, \"group_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.on_invite(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRemoveLocalUserServlet(BaseFederationServlet):",
            "    \"\"\"A group server has removed a local user",
            "    \"\"\"",
            "    PATH = \"/groups/local/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/remove$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(group_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.user_removed_from_group(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRenewAttestaionServlet(BaseFederationServlet):",
            "    \"\"\"A group or user's server renews their attestation",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/renew_attestation/(?P<user_id>[^/]*)$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        # We don't need to check auth here as we check the attestation signatures",
            "",
            "        new_content = yield self.handler.on_renew_attestation(",
            "            group_id, user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsSummaryRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove a room from the group summary, with optional category.",
            "",
            "    Matches both:",
            "        - /groups/:group/summary/rooms/:room_id",
            "        - /groups/:group/summary/categories/:category/rooms/:room_id",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/summary\"",
            "        \"(/categories/(?P<category_id>[^/]+))?\"",
            "        \"/rooms/(?P<room_id>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, category_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_summary_room(",
            "            group_id, requester_user_id,",
            "            room_id=room_id,",
            "            category_id=category_id,",
            "            content=content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, category_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_summary_room(",
            "            group_id, requester_user_id,",
            "            room_id=room_id,",
            "            category_id=category_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsCategoriesServlet(BaseFederationServlet):",
            "    \"\"\"Get all categories for a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/categories/$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_categories(",
            "            group_id, requester_user_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsCategoryServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove/get a category in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/categories/(?P<category_id>[^/]+)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_category(",
            "            group_id, requester_user_id, category_id",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.upsert_group_category(",
            "            group_id, requester_user_id, category_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_category(",
            "            group_id, requester_user_id, category_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsRolesServlet(BaseFederationServlet):",
            "    \"\"\"Get roles in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/roles/$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_roles(",
            "            group_id, requester_user_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsRoleServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove/get a role in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/roles/(?P<role_id>[^/]+)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_role(",
            "            group_id, requester_user_id, role_id",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_role(",
            "            group_id, requester_user_id, role_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_role(",
            "            group_id, requester_user_id, role_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsSummaryUsersServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove a user from the group summary, with optional role.",
            "",
            "    Matches both:",
            "        - /groups/:group/summary/users/:user_id",
            "        - /groups/:group/summary/roles/:role/users/:user_id",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/summary\"",
            "        \"(/roles/(?P<role_id>[^/]+))?\"",
            "        \"/users/(?P<user_id>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, role_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_summary_user(",
            "            group_id, requester_user_id,",
            "            user_id=user_id,",
            "            role_id=role_id,",
            "            content=content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, role_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_summary_user(",
            "            group_id, requester_user_id,",
            "            user_id=user_id,",
            "            role_id=role_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsBulkPublicisedServlet(BaseFederationServlet):",
            "    \"\"\"Get roles in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/get_groups_publicised$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        resp = yield self.handler.bulk_get_publicised_groups(",
            "            content[\"user_ids\"], proxy=False,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsSettingJoinPolicyServlet(BaseFederationServlet):",
            "    \"\"\"Sets whether a group is joinable without an invite or knock",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/settings/m.join_policy$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.set_group_join_policy(",
            "            group_id, requester_user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "FEDERATION_SERVLET_CLASSES = (",
            "    FederationSendServlet,",
            "    FederationPullServlet,",
            "    FederationEventServlet,",
            "    FederationStateServlet,",
            "    FederationStateIdsServlet,",
            "    FederationBackfillServlet,",
            "    FederationQueryServlet,",
            "    FederationMakeJoinServlet,",
            "    FederationMakeLeaveServlet,",
            "    FederationEventServlet,",
            "    FederationSendJoinServlet,",
            "    FederationSendLeaveServlet,",
            "    FederationInviteServlet,",
            "    FederationQueryAuthServlet,",
            "    FederationGetMissingEventsServlet,",
            "    FederationEventAuthServlet,",
            "    FederationClientKeysQueryServlet,",
            "    FederationUserDevicesQueryServlet,",
            "    FederationClientKeysClaimServlet,",
            "    FederationThirdPartyInviteExchangeServlet,",
            "    On3pidBindServlet,",
            "    OpenIdUserInfo,",
            "    FederationVersionServlet,",
            ")",
            "",
            "",
            "ROOM_LIST_CLASSES = (",
            "    PublicRoomList,",
            ")",
            "",
            "GROUP_SERVER_SERVLET_CLASSES = (",
            "    FederationGroupsProfileServlet,",
            "    FederationGroupsSummaryServlet,",
            "    FederationGroupsRoomsServlet,",
            "    FederationGroupsUsersServlet,",
            "    FederationGroupsInvitedUsersServlet,",
            "    FederationGroupsInviteServlet,",
            "    FederationGroupsAcceptInviteServlet,",
            "    FederationGroupsJoinServlet,",
            "    FederationGroupsRemoveUserServlet,",
            "    FederationGroupsSummaryRoomsServlet,",
            "    FederationGroupsCategoriesServlet,",
            "    FederationGroupsCategoryServlet,",
            "    FederationGroupsRolesServlet,",
            "    FederationGroupsRoleServlet,",
            "    FederationGroupsSummaryUsersServlet,",
            "    FederationGroupsAddRoomsServlet,",
            "    FederationGroupsAddRoomsConfigServlet,",
            "    FederationGroupsSettingJoinPolicyServlet,",
            ")",
            "",
            "",
            "GROUP_LOCAL_SERVLET_CLASSES = (",
            "    FederationGroupsLocalInviteServlet,",
            "    FederationGroupsRemoveLocalUserServlet,",
            "    FederationGroupsBulkPublicisedServlet,",
            ")",
            "",
            "",
            "GROUP_ATTESTATION_SERVLET_CLASSES = (",
            "    FederationGroupsRenewAttestaionServlet,",
            ")",
            "",
            "",
            "def register_servlets(hs, resource, authenticator, ratelimiter):",
            "    for servletclass in FEDERATION_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_federation_server(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in ROOM_LIST_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_room_list_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_SERVER_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_server_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_LOCAL_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_local_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_ATTESTATION_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_attestation_renewer(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import functools",
            "import logging",
            "import re",
            "",
            "from twisted.internet import defer",
            "",
            "import synapse",
            "from synapse.api.errors import Codes, FederationDeniedError, SynapseError",
            "from synapse.api.urls import FEDERATION_PREFIX as PREFIX",
            "from synapse.http.endpoint import parse_and_validate_server_name",
            "from synapse.http.server import JsonResource",
            "from synapse.http.servlet import (",
            "    parse_boolean_from_args,",
            "    parse_integer_from_args,",
            "    parse_json_object_from_request,",
            "    parse_string_from_args,",
            ")",
            "from synapse.types import ThirdPartyInstanceID, get_domain_from_id",
            "from synapse.util.logcontext import run_in_background",
            "from synapse.util.ratelimitutils import FederationRateLimiter",
            "from synapse.util.versionstring import get_version_string",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class TransportLayerServer(JsonResource):",
            "    \"\"\"Handles incoming federation HTTP requests\"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "        self.clock = hs.get_clock()",
            "",
            "        super(TransportLayerServer, self).__init__(hs, canonical_json=False)",
            "",
            "        self.authenticator = Authenticator(hs)",
            "        self.ratelimiter = FederationRateLimiter(",
            "            self.clock,",
            "            window_size=hs.config.federation_rc_window_size,",
            "            sleep_limit=hs.config.federation_rc_sleep_limit,",
            "            sleep_msec=hs.config.federation_rc_sleep_delay,",
            "            reject_limit=hs.config.federation_rc_reject_limit,",
            "            concurrent_requests=hs.config.federation_rc_concurrent,",
            "        )",
            "",
            "        self.register_servlets()",
            "",
            "    def register_servlets(self):",
            "        register_servlets(",
            "            self.hs,",
            "            resource=self,",
            "            ratelimiter=self.ratelimiter,",
            "            authenticator=self.authenticator,",
            "        )",
            "",
            "",
            "class AuthenticationError(SynapseError):",
            "    \"\"\"There was a problem authenticating the request\"\"\"",
            "    pass",
            "",
            "",
            "class NoAuthenticationError(AuthenticationError):",
            "    \"\"\"The request had no authentication information\"\"\"",
            "    pass",
            "",
            "",
            "class Authenticator(object):",
            "    def __init__(self, hs):",
            "        self.keyring = hs.get_keyring()",
            "        self.server_name = hs.hostname",
            "        self.store = hs.get_datastore()",
            "        self.federation_domain_whitelist = hs.config.federation_domain_whitelist",
            "",
            "    # A method just so we can pass 'self' as the authenticator to the Servlets",
            "    @defer.inlineCallbacks",
            "    def authenticate_request(self, request, content):",
            "        json_request = {",
            "            \"method\": request.method,",
            "            \"uri\": request.uri,",
            "            \"destination\": self.server_name,",
            "            \"signatures\": {},",
            "        }",
            "",
            "        if content is not None:",
            "            json_request[\"content\"] = content",
            "",
            "        origin = None",
            "",
            "        auth_headers = request.requestHeaders.getRawHeaders(b\"Authorization\")",
            "",
            "        if not auth_headers:",
            "            raise NoAuthenticationError(",
            "                401, \"Missing Authorization headers\", Codes.UNAUTHORIZED,",
            "            )",
            "",
            "        for auth in auth_headers:",
            "            if auth.startswith(b\"X-Matrix\"):",
            "                (origin, key, sig) = _parse_auth_header(auth)",
            "                json_request[\"origin\"] = origin",
            "                json_request[\"signatures\"].setdefault(origin, {})[key] = sig",
            "",
            "        if (",
            "            self.federation_domain_whitelist is not None and",
            "            origin not in self.federation_domain_whitelist",
            "        ):",
            "            raise FederationDeniedError(origin)",
            "",
            "        if not json_request[\"signatures\"]:",
            "            raise NoAuthenticationError(",
            "                401, \"Missing Authorization headers\", Codes.UNAUTHORIZED,",
            "            )",
            "",
            "        yield self.keyring.verify_json_for_server(origin, json_request)",
            "",
            "        logger.info(\"Request from %s\", origin)",
            "        request.authenticated_entity = origin",
            "",
            "        # If we get a valid signed request from the other side, its probably",
            "        # alive",
            "        retry_timings = yield self.store.get_destination_retry_timings(origin)",
            "        if retry_timings and retry_timings[\"retry_last_ts\"]:",
            "            run_in_background(self._reset_retry_timings, origin)",
            "",
            "        defer.returnValue(origin)",
            "",
            "    @defer.inlineCallbacks",
            "    def _reset_retry_timings(self, origin):",
            "        try:",
            "            logger.info(\"Marking origin %r as up\", origin)",
            "            yield self.store.set_destination_retry_timings(origin, 0, 0)",
            "        except Exception:",
            "            logger.exception(\"Error resetting retry timings on %s\", origin)",
            "",
            "",
            "def _parse_auth_header(header_bytes):",
            "    \"\"\"Parse an X-Matrix auth header",
            "",
            "    Args:",
            "        header_bytes (bytes): header value",
            "",
            "    Returns:",
            "        Tuple[str, str, str]: origin, key id, signature.",
            "",
            "    Raises:",
            "        AuthenticationError if the header could not be parsed",
            "    \"\"\"",
            "    try:",
            "        header_str = header_bytes.decode('utf-8')",
            "        params = header_str.split(\" \")[1].split(\",\")",
            "        param_dict = dict(kv.split(\"=\") for kv in params)",
            "",
            "        def strip_quotes(value):",
            "            if value.startswith(\"\\\"\"):",
            "                return value[1:-1]",
            "            else:",
            "                return value",
            "",
            "        origin = strip_quotes(param_dict[\"origin\"])",
            "",
            "        # ensure that the origin is a valid server name",
            "        parse_and_validate_server_name(origin)",
            "",
            "        key = strip_quotes(param_dict[\"key\"])",
            "        sig = strip_quotes(param_dict[\"sig\"])",
            "        return origin, key, sig",
            "    except Exception as e:",
            "        logger.warn(",
            "            \"Error parsing auth header '%s': %s\",",
            "            header_bytes.decode('ascii', 'replace'),",
            "            e,",
            "        )",
            "        raise AuthenticationError(",
            "            400, \"Malformed Authorization header\", Codes.UNAUTHORIZED,",
            "        )",
            "",
            "",
            "class BaseFederationServlet(object):",
            "    \"\"\"Abstract base class for federation servlet classes.",
            "",
            "    The servlet object should have a PATH attribute which takes the form of a regexp to",
            "    match against the request path (excluding the /federation/v1 prefix).",
            "",
            "    The servlet should also implement one or more of on_GET, on_POST, on_PUT, to match",
            "    the appropriate HTTP method. These methods have the signature:",
            "",
            "        on_<METHOD>(self, origin, content, query, **kwargs)",
            "",
            "        With arguments:",
            "",
            "            origin (unicode|None): The authenticated server_name of the calling server,",
            "                unless REQUIRE_AUTH is set to False and authentication failed.",
            "",
            "            content (unicode|None): decoded json body of the request. None if the",
            "                request was a GET.",
            "",
            "            query (dict[bytes, list[bytes]]): Query params from the request. url-decoded",
            "                (ie, '+' and '%xx' are decoded) but note that it is *not* utf8-decoded",
            "                yet.",
            "",
            "            **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                components as specified in the path match regexp.",
            "",
            "        Returns:",
            "            Deferred[(int, object)|None]: either (response code, response object) to",
            "                 return a JSON response, or None if the request has already been handled.",
            "",
            "        Raises:",
            "            SynapseError: to return an error code",
            "",
            "            Exception: other exceptions will be caught, logged, and a 500 will be",
            "                returned.",
            "    \"\"\"",
            "    REQUIRE_AUTH = True",
            "",
            "    def __init__(self, handler, authenticator, ratelimiter, server_name):",
            "        self.handler = handler",
            "        self.authenticator = authenticator",
            "        self.ratelimiter = ratelimiter",
            "",
            "    def _wrap(self, func):",
            "        authenticator = self.authenticator",
            "        ratelimiter = self.ratelimiter",
            "",
            "        @defer.inlineCallbacks",
            "        @functools.wraps(func)",
            "        def new_func(request, *args, **kwargs):",
            "            \"\"\" A callback which can be passed to HttpServer.RegisterPaths",
            "",
            "            Args:",
            "                request (twisted.web.http.Request):",
            "                *args: unused?",
            "                **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                    components as specified in the path match regexp.",
            "",
            "            Returns:",
            "                Deferred[(int, object)|None]: (response code, response object) as returned",
            "                    by the callback method. None if the request has already been handled.",
            "            \"\"\"",
            "            content = None",
            "            if request.method in [\"PUT\", \"POST\"]:",
            "                # TODO: Handle other method types? other content types?",
            "                content = parse_json_object_from_request(request)",
            "",
            "            try:",
            "                origin = yield authenticator.authenticate_request(request, content)",
            "            except NoAuthenticationError:",
            "                origin = None",
            "                if self.REQUIRE_AUTH:",
            "                    logger.warn(\"authenticate_request failed: missing authentication\")",
            "                    raise",
            "            except Exception as e:",
            "                logger.warn(\"authenticate_request failed: %s\", e)",
            "                raise",
            "",
            "            if origin:",
            "                with ratelimiter.ratelimit(origin) as d:",
            "                    yield d",
            "                    response = yield func(",
            "                        origin, content, request.args, *args, **kwargs",
            "                    )",
            "            else:",
            "                response = yield func(",
            "                    origin, content, request.args, *args, **kwargs",
            "                )",
            "",
            "            defer.returnValue(response)",
            "",
            "        # Extra logic that functools.wraps() doesn't finish",
            "        new_func.__self__ = func.__self__",
            "",
            "        return new_func",
            "",
            "    def register(self, server):",
            "        pattern = re.compile(\"^\" + PREFIX + self.PATH + \"$\")",
            "",
            "        for method in (\"GET\", \"PUT\", \"POST\"):",
            "            code = getattr(self, \"on_%s\" % (method), None)",
            "            if code is None:",
            "                continue",
            "",
            "            server.register_paths(method, (pattern,), self._wrap(code))",
            "",
            "",
            "class FederationSendServlet(BaseFederationServlet):",
            "    PATH = \"/send/(?P<transaction_id>[^/]*)/\"",
            "",
            "    def __init__(self, handler, server_name, **kwargs):",
            "        super(FederationSendServlet, self).__init__(",
            "            handler, server_name=server_name, **kwargs",
            "        )",
            "        self.server_name = server_name",
            "",
            "    # This is when someone is trying to send us a bunch of data.",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, transaction_id):",
            "        \"\"\" Called on PUT /send/<transaction_id>/",
            "",
            "        Args:",
            "            request (twisted.web.http.Request): The HTTP request.",
            "            transaction_id (str): The transaction_id associated with this",
            "                request. This is *not* None.",
            "",
            "        Returns:",
            "            Deferred: Results in a tuple of `(code, response)`, where",
            "            `response` is a python dict to be converted into JSON that is",
            "            used as the response body.",
            "        \"\"\"",
            "        # Parse the request",
            "        try:",
            "            transaction_data = content",
            "",
            "            logger.debug(",
            "                \"Decoded %s: %s\",",
            "                transaction_id, str(transaction_data)",
            "            )",
            "",
            "            logger.info(",
            "                \"Received txn %s from %s. (PDUs: %d, EDUs: %d)\",",
            "                transaction_id, origin,",
            "                len(transaction_data.get(\"pdus\", [])),",
            "                len(transaction_data.get(\"edus\", [])),",
            "            )",
            "",
            "            # We should ideally be getting this from the security layer.",
            "            # origin = body[\"origin\"]",
            "",
            "            # Add some extra data to the transaction dict that isn't included",
            "            # in the request body.",
            "            transaction_data.update(",
            "                transaction_id=transaction_id,",
            "                destination=self.server_name",
            "            )",
            "",
            "        except Exception as e:",
            "            logger.exception(e)",
            "            defer.returnValue((400, {\"error\": \"Invalid transaction\"}))",
            "            return",
            "",
            "        try:",
            "            code, response = yield self.handler.on_incoming_transaction(",
            "                origin, transaction_data,",
            "            )",
            "        except Exception:",
            "            logger.exception(\"on_incoming_transaction failed\")",
            "            raise",
            "",
            "        defer.returnValue((code, response))",
            "",
            "",
            "class FederationPullServlet(BaseFederationServlet):",
            "    PATH = \"/pull/\"",
            "",
            "    # This is for when someone asks us for everything since version X",
            "    def on_GET(self, origin, content, query):",
            "        return self.handler.on_pull_request(query[\"origin\"][0], query[\"v\"])",
            "",
            "",
            "class FederationEventServlet(BaseFederationServlet):",
            "    PATH = \"/event/(?P<event_id>[^/]*)/\"",
            "",
            "    # This is when someone asks for a data item for a given server data_id pair.",
            "    def on_GET(self, origin, content, query, event_id):",
            "        return self.handler.on_pdu_request(origin, event_id)",
            "",
            "",
            "class FederationStateServlet(BaseFederationServlet):",
            "    PATH = \"/state/(?P<context>[^/]*)/\"",
            "",
            "    # This is when someone asks for all data for a given context.",
            "    def on_GET(self, origin, content, query, context):",
            "        return self.handler.on_context_state_request(",
            "            origin,",
            "            context,",
            "            query.get(\"event_id\", [None])[0],",
            "        )",
            "",
            "",
            "class FederationStateIdsServlet(BaseFederationServlet):",
            "    PATH = \"/state_ids/(?P<room_id>[^/]*)/\"",
            "",
            "    def on_GET(self, origin, content, query, room_id):",
            "        return self.handler.on_state_ids_request(",
            "            origin,",
            "            room_id,",
            "            query.get(\"event_id\", [None])[0],",
            "        )",
            "",
            "",
            "class FederationBackfillServlet(BaseFederationServlet):",
            "    PATH = \"/backfill/(?P<context>[^/]*)/\"",
            "",
            "    def on_GET(self, origin, content, query, context):",
            "        versions = query[\"v\"]",
            "        limits = query[\"limit\"]",
            "",
            "        if not limits:",
            "            return defer.succeed((400, {\"error\": \"Did not include limit param\"}))",
            "",
            "        limit = int(limits[-1])",
            "",
            "        return self.handler.on_backfill_request(origin, context, versions, limit)",
            "",
            "",
            "class FederationQueryServlet(BaseFederationServlet):",
            "    PATH = \"/query/(?P<query_type>[^/]*)\"",
            "",
            "    # This is when we receive a server-server Query",
            "    def on_GET(self, origin, content, query, query_type):",
            "        return self.handler.on_query_request(",
            "            query_type,",
            "            {k: v[0].decode(\"utf-8\") for k, v in query.items()}",
            "        )",
            "",
            "",
            "class FederationMakeJoinServlet(BaseFederationServlet):",
            "    PATH = \"/make_join/(?P<context>[^/]*)/(?P<user_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, _content, query, context, user_id):",
            "        \"\"\"",
            "        Args:",
            "            origin (unicode): The authenticated server_name of the calling server",
            "",
            "            _content (None): (GETs don't have bodies)",
            "",
            "            query (dict[bytes, list[bytes]]): Query params from the request.",
            "",
            "            **kwargs (dict[unicode, unicode]): the dict mapping keys to path",
            "                components as specified in the path match regexp.",
            "",
            "        Returns:",
            "            Deferred[(int, object)|None]: either (response code, response object) to",
            "                 return a JSON response, or None if the request has already been handled.",
            "        \"\"\"",
            "        versions = query.get(b'ver')",
            "        if versions is not None:",
            "            supported_versions = [v.decode(\"utf-8\") for v in versions]",
            "        else:",
            "            supported_versions = [\"1\"]",
            "",
            "        content = yield self.handler.on_make_join_request(",
            "            origin, context, user_id,",
            "            supported_versions=supported_versions,",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationMakeLeaveServlet(BaseFederationServlet):",
            "    PATH = \"/make_leave/(?P<context>[^/]*)/(?P<user_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, context, user_id):",
            "        content = yield self.handler.on_make_leave_request(",
            "            origin, context, user_id,",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationSendLeaveServlet(BaseFederationServlet):",
            "    PATH = \"/send_leave/(?P<room_id>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, room_id, event_id):",
            "        content = yield self.handler.on_send_leave_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationEventAuthServlet(BaseFederationServlet):",
            "    PATH = \"/event_auth/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    def on_GET(self, origin, content, query, context, event_id):",
            "        return self.handler.on_event_auth(origin, context, event_id)",
            "",
            "",
            "class FederationSendJoinServlet(BaseFederationServlet):",
            "    PATH = \"/send_join/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, context, event_id):",
            "        # TODO(paul): assert that context/event_id parsed from path actually",
            "        #   match those given in content",
            "        content = yield self.handler.on_send_join_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationInviteServlet(BaseFederationServlet):",
            "    PATH = \"/invite/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, context, event_id):",
            "        # TODO(paul): assert that context/event_id parsed from path actually",
            "        #   match those given in content",
            "        content = yield self.handler.on_invite_request(origin, content)",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationThirdPartyInviteExchangeServlet(BaseFederationServlet):",
            "    PATH = \"/exchange_third_party_invite/(?P<room_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, room_id):",
            "        content = yield self.handler.on_exchange_third_party_invite_request(",
            "            origin, room_id, content",
            "        )",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class FederationClientKeysQueryServlet(BaseFederationServlet):",
            "    PATH = \"/user/keys/query\"",
            "",
            "    def on_POST(self, origin, content, query):",
            "        return self.handler.on_query_client_keys(origin, content)",
            "",
            "",
            "class FederationUserDevicesQueryServlet(BaseFederationServlet):",
            "    PATH = \"/user/devices/(?P<user_id>[^/]*)\"",
            "",
            "    def on_GET(self, origin, content, query, user_id):",
            "        return self.handler.on_query_user_devices(origin, user_id)",
            "",
            "",
            "class FederationClientKeysClaimServlet(BaseFederationServlet):",
            "    PATH = \"/user/keys/claim\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        response = yield self.handler.on_claim_client_keys(origin, content)",
            "        defer.returnValue((200, response))",
            "",
            "",
            "class FederationQueryAuthServlet(BaseFederationServlet):",
            "    PATH = \"/query_auth/(?P<context>[^/]*)/(?P<event_id>[^/]*)\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, context, event_id):",
            "        new_content = yield self.handler.on_query_auth_request(",
            "            origin, content, context, event_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGetMissingEventsServlet(BaseFederationServlet):",
            "    # TODO(paul): Why does this path alone end with \"/?\" optional?",
            "    PATH = \"/get_missing_events/(?P<room_id>[^/]*)/?\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, room_id):",
            "        limit = int(content.get(\"limit\", 10))",
            "        min_depth = int(content.get(\"min_depth\", 0))",
            "        earliest_events = content.get(\"earliest_events\", [])",
            "        latest_events = content.get(\"latest_events\", [])",
            "",
            "        content = yield self.handler.on_get_missing_events(",
            "            origin,",
            "            room_id=room_id,",
            "            earliest_events=earliest_events,",
            "            latest_events=latest_events,",
            "            min_depth=min_depth,",
            "            limit=limit,",
            "        )",
            "",
            "        defer.returnValue((200, content))",
            "",
            "",
            "class On3pidBindServlet(BaseFederationServlet):",
            "    PATH = \"/3pid/onbind\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        if \"invites\" in content:",
            "            last_exception = None",
            "            for invite in content[\"invites\"]:",
            "                try:",
            "                    if \"signed\" not in invite or \"token\" not in invite[\"signed\"]:",
            "                        message = (\"Rejecting received notification of third-\"",
            "                                   \"party invite without signed: %s\" % (invite,))",
            "                        logger.info(message)",
            "                        raise SynapseError(400, message)",
            "                    yield self.handler.exchange_third_party_invite(",
            "                        invite[\"sender\"],",
            "                        invite[\"mxid\"],",
            "                        invite[\"room_id\"],",
            "                        invite[\"signed\"],",
            "                    )",
            "                except Exception as e:",
            "                    last_exception = e",
            "            if last_exception:",
            "                raise last_exception",
            "        defer.returnValue((200, {}))",
            "",
            "",
            "class OpenIdUserInfo(BaseFederationServlet):",
            "    \"\"\"",
            "    Exchange a bearer token for information about a user.",
            "",
            "    The response format should be compatible with:",
            "        http://openid.net/specs/openid-connect-core-1_0.html#UserInfoResponse",
            "",
            "    GET /openid/userinfo?access_token=ABDEFGH HTTP/1.1",
            "",
            "    HTTP/1.1 200 OK",
            "    Content-Type: application/json",
            "",
            "    {",
            "        \"sub\": \"@userpart:example.org\",",
            "    }",
            "    \"\"\"",
            "",
            "    PATH = \"/openid/userinfo\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query):",
            "        token = query.get(\"access_token\", [None])[0]",
            "        if token is None:",
            "            defer.returnValue((401, {",
            "                \"errcode\": \"M_MISSING_TOKEN\", \"error\": \"Access Token required\"",
            "            }))",
            "            return",
            "",
            "        user_id = yield self.handler.on_openid_userinfo(token)",
            "",
            "        if user_id is None:",
            "            defer.returnValue((401, {",
            "                \"errcode\": \"M_UNKNOWN_TOKEN\",",
            "                \"error\": \"Access Token unknown or expired\"",
            "            }))",
            "",
            "        defer.returnValue((200, {\"sub\": user_id}))",
            "",
            "",
            "class PublicRoomList(BaseFederationServlet):",
            "    \"\"\"",
            "    Fetch the public room list for this server.",
            "",
            "    This API returns information in the same format as /publicRooms on the",
            "    client API, but will only ever include local public rooms and hence is",
            "    intended for consumption by other home servers.",
            "",
            "    GET /publicRooms HTTP/1.1",
            "",
            "    HTTP/1.1 200 OK",
            "    Content-Type: application/json",
            "",
            "    {",
            "        \"chunk\": [",
            "            {",
            "                \"aliases\": [",
            "                    \"#test:localhost\"",
            "                ],",
            "                \"guest_can_join\": false,",
            "                \"name\": \"test room\",",
            "                \"num_joined_members\": 3,",
            "                \"room_id\": \"!whkydVegtvatLfXmPN:localhost\",",
            "                \"world_readable\": false",
            "            }",
            "        ],",
            "        \"end\": \"END\",",
            "        \"start\": \"START\"",
            "    }",
            "    \"\"\"",
            "",
            "    PATH = \"/publicRooms\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query):",
            "        limit = parse_integer_from_args(query, \"limit\", 0)",
            "        since_token = parse_string_from_args(query, \"since\", None)",
            "        include_all_networks = parse_boolean_from_args(",
            "            query, \"include_all_networks\", False",
            "        )",
            "        third_party_instance_id = parse_string_from_args(",
            "            query, \"third_party_instance_id\", None",
            "        )",
            "",
            "        if include_all_networks:",
            "            network_tuple = None",
            "        elif third_party_instance_id:",
            "            network_tuple = ThirdPartyInstanceID.from_string(third_party_instance_id)",
            "        else:",
            "            network_tuple = ThirdPartyInstanceID(None, None)",
            "",
            "        data = yield self.handler.get_local_public_room_list(",
            "            limit, since_token,",
            "            network_tuple=network_tuple",
            "        )",
            "        defer.returnValue((200, data))",
            "",
            "",
            "class FederationVersionServlet(BaseFederationServlet):",
            "    PATH = \"/version\"",
            "",
            "    REQUIRE_AUTH = False",
            "",
            "    def on_GET(self, origin, content, query):",
            "        return defer.succeed((200, {",
            "            \"server\": {",
            "                \"name\": \"Synapse\",",
            "                \"version\": get_version_string(synapse)",
            "            },",
            "        }))",
            "",
            "",
            "class FederationGroupsProfileServlet(BaseFederationServlet):",
            "    \"\"\"Get/set the basic profile of a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/profile$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_group_profile(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.update_group_profile(",
            "            group_id, requester_user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsSummaryServlet(BaseFederationServlet):",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/summary$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_group_summary(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Get the rooms in a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/rooms$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_rooms_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAddRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove room from group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/room/(?P<room_id>[^/]*)$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.add_room_to_group(",
            "            group_id, requester_user_id, room_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.remove_room_from_group(",
            "            group_id, requester_user_id, room_id,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAddRoomsConfigServlet(BaseFederationServlet):",
            "    \"\"\"Update room config in group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/room/(?P<room_id>[^/]*)\"",
            "        \"/config/(?P<config_key>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, room_id, config_key):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        result = yield self.groups_handler.update_room_in_group(",
            "            group_id, requester_user_id, room_id, config_key, content,",
            "        )",
            "",
            "        defer.returnValue((200, result))",
            "",
            "",
            "class FederationGroupsUsersServlet(BaseFederationServlet):",
            "    \"\"\"Get the users in a group on behalf of a user",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_users_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsInvitedUsersServlet(BaseFederationServlet):",
            "    \"\"\"Get the users that have been invited to a group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/invited_users$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.get_invited_users_in_group(",
            "            group_id, requester_user_id",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsInviteServlet(BaseFederationServlet):",
            "    \"\"\"Ask a group server to invite someone to the group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.invite_to_group(",
            "            group_id, user_id, requester_user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsAcceptInviteServlet(BaseFederationServlet):",
            "    \"\"\"Accept an invitation from the group server",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/accept_invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(user_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.accept_invite(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsJoinServlet(BaseFederationServlet):",
            "    \"\"\"Attempt to join a group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/join$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(user_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.join_group(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRemoveUserServlet(BaseFederationServlet):",
            "    \"\"\"Leave or kick a user from the group",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/remove$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.remove_user_from_group(",
            "            group_id, user_id, requester_user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsLocalInviteServlet(BaseFederationServlet):",
            "    \"\"\"A group server has invited a local user",
            "    \"\"\"",
            "    PATH = \"/groups/local/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/invite$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(group_id) != origin:",
            "            raise SynapseError(403, \"group_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.on_invite(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRemoveLocalUserServlet(BaseFederationServlet):",
            "    \"\"\"A group server has removed a local user",
            "    \"\"\"",
            "    PATH = \"/groups/local/(?P<group_id>[^/]*)/users/(?P<user_id>[^/]*)/remove$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        if get_domain_from_id(group_id) != origin:",
            "            raise SynapseError(403, \"user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.user_removed_from_group(",
            "            group_id, user_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsRenewAttestaionServlet(BaseFederationServlet):",
            "    \"\"\"A group or user's server renews their attestation",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/renew_attestation/(?P<user_id>[^/]*)$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, user_id):",
            "        # We don't need to check auth here as we check the attestation signatures",
            "",
            "        new_content = yield self.handler.on_renew_attestation(",
            "            group_id, user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "class FederationGroupsSummaryRoomsServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove a room from the group summary, with optional category.",
            "",
            "    Matches both:",
            "        - /groups/:group/summary/rooms/:room_id",
            "        - /groups/:group/summary/categories/:category/rooms/:room_id",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/summary\"",
            "        \"(/categories/(?P<category_id>[^/]+))?\"",
            "        \"/rooms/(?P<room_id>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, category_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_summary_room(",
            "            group_id, requester_user_id,",
            "            room_id=room_id,",
            "            category_id=category_id,",
            "            content=content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, category_id, room_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_summary_room(",
            "            group_id, requester_user_id,",
            "            room_id=room_id,",
            "            category_id=category_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsCategoriesServlet(BaseFederationServlet):",
            "    \"\"\"Get all categories for a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/categories/$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_categories(",
            "            group_id, requester_user_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsCategoryServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove/get a category in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/categories/(?P<category_id>[^/]+)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_category(",
            "            group_id, requester_user_id, category_id",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.upsert_group_category(",
            "            group_id, requester_user_id, category_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, category_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if category_id == \"\":",
            "            raise SynapseError(400, \"category_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_category(",
            "            group_id, requester_user_id, category_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsRolesServlet(BaseFederationServlet):",
            "    \"\"\"Get roles in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/roles/$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_roles(",
            "            group_id, requester_user_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsRoleServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove/get a role in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/roles/(?P<role_id>[^/]+)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_GET(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        resp = yield self.handler.get_group_role(",
            "            group_id, requester_user_id, role_id",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_role(",
            "            group_id, requester_user_id, role_id, content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, role_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_role(",
            "            group_id, requester_user_id, role_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsSummaryUsersServlet(BaseFederationServlet):",
            "    \"\"\"Add/remove a user from the group summary, with optional role.",
            "",
            "    Matches both:",
            "        - /groups/:group/summary/users/:user_id",
            "        - /groups/:group/summary/roles/:role/users/:user_id",
            "    \"\"\"",
            "    PATH = (",
            "        \"/groups/(?P<group_id>[^/]*)/summary\"",
            "        \"(/roles/(?P<role_id>[^/]+))?\"",
            "        \"/users/(?P<user_id>[^/]*)$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query, group_id, role_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.update_group_summary_user(",
            "            group_id, requester_user_id,",
            "            user_id=user_id,",
            "            role_id=role_id,",
            "            content=content,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "    @defer.inlineCallbacks",
            "    def on_DELETE(self, origin, content, query, group_id, role_id, user_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        if role_id == \"\":",
            "            raise SynapseError(400, \"role_id cannot be empty string\")",
            "",
            "        resp = yield self.handler.delete_group_summary_user(",
            "            group_id, requester_user_id,",
            "            user_id=user_id,",
            "            role_id=role_id,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsBulkPublicisedServlet(BaseFederationServlet):",
            "    \"\"\"Get roles in a group",
            "    \"\"\"",
            "    PATH = (",
            "        \"/get_groups_publicised$\"",
            "    )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_POST(self, origin, content, query):",
            "        resp = yield self.handler.bulk_get_publicised_groups(",
            "            content[\"user_ids\"], proxy=False,",
            "        )",
            "",
            "        defer.returnValue((200, resp))",
            "",
            "",
            "class FederationGroupsSettingJoinPolicyServlet(BaseFederationServlet):",
            "    \"\"\"Sets whether a group is joinable without an invite or knock",
            "    \"\"\"",
            "    PATH = \"/groups/(?P<group_id>[^/]*)/settings/m.join_policy$\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_PUT(self, origin, content, query, group_id):",
            "        requester_user_id = parse_string_from_args(query, \"requester_user_id\")",
            "        if get_domain_from_id(requester_user_id) != origin:",
            "            raise SynapseError(403, \"requester_user_id doesn't match origin\")",
            "",
            "        new_content = yield self.handler.set_group_join_policy(",
            "            group_id, requester_user_id, content",
            "        )",
            "",
            "        defer.returnValue((200, new_content))",
            "",
            "",
            "FEDERATION_SERVLET_CLASSES = (",
            "    FederationSendServlet,",
            "    FederationPullServlet,",
            "    FederationEventServlet,",
            "    FederationStateServlet,",
            "    FederationStateIdsServlet,",
            "    FederationBackfillServlet,",
            "    FederationQueryServlet,",
            "    FederationMakeJoinServlet,",
            "    FederationMakeLeaveServlet,",
            "    FederationEventServlet,",
            "    FederationSendJoinServlet,",
            "    FederationSendLeaveServlet,",
            "    FederationInviteServlet,",
            "    FederationQueryAuthServlet,",
            "    FederationGetMissingEventsServlet,",
            "    FederationEventAuthServlet,",
            "    FederationClientKeysQueryServlet,",
            "    FederationUserDevicesQueryServlet,",
            "    FederationClientKeysClaimServlet,",
            "    FederationThirdPartyInviteExchangeServlet,",
            "    On3pidBindServlet,",
            "    OpenIdUserInfo,",
            "    FederationVersionServlet,",
            ")",
            "",
            "",
            "ROOM_LIST_CLASSES = (",
            "    PublicRoomList,",
            ")",
            "",
            "GROUP_SERVER_SERVLET_CLASSES = (",
            "    FederationGroupsProfileServlet,",
            "    FederationGroupsSummaryServlet,",
            "    FederationGroupsRoomsServlet,",
            "    FederationGroupsUsersServlet,",
            "    FederationGroupsInvitedUsersServlet,",
            "    FederationGroupsInviteServlet,",
            "    FederationGroupsAcceptInviteServlet,",
            "    FederationGroupsJoinServlet,",
            "    FederationGroupsRemoveUserServlet,",
            "    FederationGroupsSummaryRoomsServlet,",
            "    FederationGroupsCategoriesServlet,",
            "    FederationGroupsCategoryServlet,",
            "    FederationGroupsRolesServlet,",
            "    FederationGroupsRoleServlet,",
            "    FederationGroupsSummaryUsersServlet,",
            "    FederationGroupsAddRoomsServlet,",
            "    FederationGroupsAddRoomsConfigServlet,",
            "    FederationGroupsSettingJoinPolicyServlet,",
            ")",
            "",
            "",
            "GROUP_LOCAL_SERVLET_CLASSES = (",
            "    FederationGroupsLocalInviteServlet,",
            "    FederationGroupsRemoveLocalUserServlet,",
            "    FederationGroupsBulkPublicisedServlet,",
            ")",
            "",
            "",
            "GROUP_ATTESTATION_SERVLET_CLASSES = (",
            "    FederationGroupsRenewAttestaionServlet,",
            ")",
            "",
            "",
            "def register_servlets(hs, resource, authenticator, ratelimiter):",
            "    for servletclass in FEDERATION_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_federation_server(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in ROOM_LIST_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_room_list_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_SERVER_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_server_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_LOCAL_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_local_handler(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)",
            "",
            "    for servletclass in GROUP_ATTESTATION_SERVLET_CLASSES:",
            "        servletclass(",
            "            handler=hs.get_groups_attestation_renewer(),",
            "            authenticator=authenticator,",
            "            ratelimiter=ratelimiter,",
            "            server_name=hs.hostname,",
            "        ).register(resource)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "356": [
                "FederationSendServlet",
                "on_PUT"
            ]
        },
        "addLocation": []
    }
}