{
    "nova/tests/virt/libvirt/test_imagebackend.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from nova import test"
            },
            "1": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from nova.tests import fake_processutils"
            },
            "2": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from nova.tests.virt.libvirt import fake_libvirt_utils"
            },
            "3": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from nova import utils"
            },
            "4": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from nova.virt.libvirt import imagebackend"
            },
            "5": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " CONF = cfg.CONF"
            },
            "7": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "             'nova.virt.libvirt.imagebackend.libvirt_utils',"
            },
            "8": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "             fake_libvirt_utils))"
            },
            "9": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def fake_chown(path, owner_uid=None):"
            },
            "11": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "12": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.stubs.Set(utils, 'chown', fake_chown)"
            },
            "13": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "14": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "     def tearDown(self):"
            },
            "15": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "         super(_ImageTestCase, self).tearDown()"
            },
            "16": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "         shutil.rmtree(self.INSTANCES_PATH)"
            },
            "17": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "         super(RawTestCase, self).setUp()"
            },
            "18": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         self.stubs.Set(imagebackend.Raw, 'correct_format', lambda _: None)"
            },
            "19": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 124,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def fake_chown(path, owner_uid=None):"
            },
            "21": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "22": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.stubs.Set(utils, 'chown', fake_chown)"
            },
            "23": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "24": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "     def prepare_mocks(self):"
            },
            "25": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "         fn = self.mox.CreateMockAnything()"
            },
            "26": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         self.mox.StubOutWithMock(imagebackend.utils.synchronized,"
            },
            "27": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "         self.mox.StubOutWithMock(os.path, 'exists')"
            },
            "28": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "         self.mox.StubOutWithMock(imagebackend.images, 'qemu_img_info')"
            },
            "29": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 236,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def fake_chown(path, owner_uid=None):"
            },
            "31": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "32": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.stubs.Set(utils, 'chown', fake_chown)"
            },
            "33": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "34": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "         os.path.exists(self.PATH).AndReturn(True)"
            },
            "35": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         os.path.exists(self.DISK_INFO_PATH).AndReturn(False)"
            },
            "36": {
                "beforePatchRowNumber": 252,
                "afterPatchRowNumber": 239,
                "PatchRowcode": "         info = self.mox.CreateMockAnything()"
            },
            "37": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": 262,
                "PatchRowcode": "         self.QCOW2_BASE = (self.TEMPLATE_PATH +"
            },
            "38": {
                "beforePatchRowNumber": 276,
                "afterPatchRowNumber": 263,
                "PatchRowcode": "                            '_%d' % (self.SIZE / units.Gi))"
            },
            "39": {
                "beforePatchRowNumber": 277,
                "afterPatchRowNumber": 264,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def fake_chown(path, owner_uid=None):"
            },
            "41": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "42": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.stubs.Set(utils, 'chown', fake_chown)"
            },
            "43": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "44": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "     def prepare_mocks(self):"
            },
            "45": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 266,
                "PatchRowcode": "         fn = self.mox.CreateMockAnything()"
            },
            "46": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": 267,
                "PatchRowcode": "         self.mox.StubOutWithMock(imagebackend.utils.synchronized,"
            },
            "47": {
                "beforePatchRowNumber": 874,
                "afterPatchRowNumber": 857,
                "PatchRowcode": "     def setUp(self):"
            },
            "48": {
                "beforePatchRowNumber": 875,
                "afterPatchRowNumber": 858,
                "PatchRowcode": "         super(BackendTestCase, self).setUp()"
            },
            "49": {
                "beforePatchRowNumber": 876,
                "afterPatchRowNumber": 859,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 877,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        def fake_chown(path, owner_uid=None):"
            },
            "51": {
                "beforePatchRowNumber": 878,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "52": {
                "beforePatchRowNumber": 879,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.stubs.Set(utils, 'chown', fake_chown)"
            },
            "53": {
                "beforePatchRowNumber": 880,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "54": {
                "beforePatchRowNumber": 881,
                "afterPatchRowNumber": 860,
                "PatchRowcode": "     def get_image(self, use_cow, image_type):"
            },
            "55": {
                "beforePatchRowNumber": 882,
                "afterPatchRowNumber": 861,
                "PatchRowcode": "         return imagebackend.Backend(use_cow).image(self.INSTANCE,"
            },
            "56": {
                "beforePatchRowNumber": 883,
                "afterPatchRowNumber": 862,
                "PatchRowcode": "                                                    self.NAME,"
            }
        },
        "frontPatchFile": [
            "# Copyright 2012 Grid Dynamics",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import os",
            "import shutil",
            "import tempfile",
            "",
            "import fixtures",
            "from oslo.config import cfg",
            "",
            "import inspect",
            "",
            "from nova import exception",
            "from nova.openstack.common import units",
            "from nova.openstack.common import uuidutils",
            "from nova import test",
            "from nova.tests import fake_processutils",
            "from nova.tests.virt.libvirt import fake_libvirt_utils",
            "from nova import utils",
            "from nova.virt.libvirt import imagebackend",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "class _ImageTestCase(object):",
            "",
            "    def mock_create_image(self, image):",
            "        def create_image(fn, base, size, *args, **kwargs):",
            "            fn(target=base, *args, **kwargs)",
            "        image.create_image = create_image",
            "",
            "    def setUp(self):",
            "        super(_ImageTestCase, self).setUp()",
            "        self.INSTANCES_PATH = tempfile.mkdtemp(suffix='instances')",
            "        self.flags(disable_process_locking=True,",
            "                   instances_path=self.INSTANCES_PATH)",
            "        self.INSTANCE = {'name': 'instance',",
            "                         'uuid': uuidutils.generate_uuid()}",
            "        self.DISK_INFO_PATH = os.path.join(self.INSTANCES_PATH,",
            "                                           self.INSTANCE['uuid'], 'disk.info')",
            "        self.NAME = 'fake.vm'",
            "        self.TEMPLATE = 'template'",
            "",
            "        self.OLD_STYLE_INSTANCE_PATH = \\",
            "            fake_libvirt_utils.get_instance_path(self.INSTANCE, forceold=True)",
            "        self.PATH = os.path.join(",
            "            fake_libvirt_utils.get_instance_path(self.INSTANCE), self.NAME)",
            "",
            "        # TODO(mikal): rename template_dir to base_dir and template_path",
            "        # to cached_image_path. This will be less confusing.",
            "        self.TEMPLATE_DIR = os.path.join(CONF.instances_path, '_base')",
            "        self.TEMPLATE_PATH = os.path.join(self.TEMPLATE_DIR, 'template')",
            "",
            "        self.useFixture(fixtures.MonkeyPatch(",
            "            'nova.virt.libvirt.imagebackend.libvirt_utils',",
            "            fake_libvirt_utils))",
            "",
            "        def fake_chown(path, owner_uid=None):",
            "            return None",
            "        self.stubs.Set(utils, 'chown', fake_chown)",
            "",
            "    def tearDown(self):",
            "        super(_ImageTestCase, self).tearDown()",
            "        shutil.rmtree(self.INSTANCES_PATH)",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: True)",
            "",
            "        # Call twice to verify testing fallocate is only called once.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(),",
            "            ['fallocate -n -l 1 %s.fallocate_test' % self.PATH,",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH),",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH)])",
            "",
            "    def test_prealloc_image_without_write_access(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "        self.stubs.Set(image, '_can_fallocate', lambda: True)",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: False)",
            "",
            "        # Testing fallocate is only called when user has write access.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class RawTestCase(_ImageTestCase, test.NoDBTestCase):",
            "",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Raw",
            "        super(RawTestCase, self).setUp()",
            "        self.stubs.Set(imagebackend.Raw, 'correct_format', lambda _: None)",
            "",
            "        def fake_chown(path, owner_uid=None):",
            "            return None",
            "        self.stubs.Set(utils, 'chown', fake_chown)",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend.utils.synchronized,",
            "                                 '__call__')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils, 'copy_image')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'extend')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.TEMPLATE_PATH, max_size=None, image_id=None)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH, self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None, image_id=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_generated(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_extend(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH, image_id=None)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH, self.PATH)",
            "        imagebackend.disk.extend(self.PATH, self.SIZE, use_cow=False)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE, image_id=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_correct_format(self):",
            "        self.stubs.UnsetAll()",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.images, 'qemu_img_info')",
            "",
            "        def fake_chown(path, owner_uid=None):",
            "            return None",
            "        self.stubs.Set(utils, 'chown', fake_chown)",
            "",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        info = self.mox.CreateMockAnything()",
            "        info.file_format = 'foo'",
            "        imagebackend.images.qemu_img_info(self.PATH).AndReturn(info)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME, path=self.PATH)",
            "        self.assertEqual(image.driver_format, 'foo')",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_resolve_driver_format(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        driver_format = image.resolve_driver_format()",
            "        self.assertEqual(driver_format, 'raw')",
            "",
            "",
            "class Qcow2TestCase(_ImageTestCase, test.NoDBTestCase):",
            "    SIZE = units.Gi",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Qcow2",
            "        super(Qcow2TestCase, self).setUp()",
            "        self.QCOW2_BASE = (self.TEMPLATE_PATH +",
            "                           '_%d' % (self.SIZE / units.Gi))",
            "",
            "        def fake_chown(path, owner_uid=None):",
            "            return None",
            "        self.stubs.Set(utils, 'chown', fake_chown)",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend.utils.synchronized,",
            "                                 '__call__')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'create_cow_image')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils, 'copy_image')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'extend')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, target=self.TEMPLATE_PATH)",
            "        imagebackend.libvirt_utils.create_cow_image(self.TEMPLATE_PATH,",
            "                                                    self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_with_size(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        imagebackend.libvirt_utils.create_cow_image(self.TEMPLATE_PATH,",
            "                                                    self.PATH)",
            "        imagebackend.disk.extend(self.PATH, self.SIZE, use_cow=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_too_small(self):",
            "        fn = self.prepare_mocks()",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'get_disk_size')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        imagebackend.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                       ).AndReturn(self.SIZE)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.assertRaises(exception.FlavorDiskTooSmall,",
            "                          image.create_image, fn, self.TEMPLATE_PATH, 1)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_generate_resized_backing_files(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'get_disk_backing_file')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "",
            "        imagebackend.libvirt_utils.get_disk_backing_file(self.PATH)\\",
            "            .AndReturn(self.QCOW2_BASE)",
            "        os.path.exists(self.QCOW2_BASE).AndReturn(False)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH,",
            "                                              self.QCOW2_BASE)",
            "        imagebackend.disk.extend(self.QCOW2_BASE, self.SIZE, use_cow=True)",
            "",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_qcow2_exists_and_has_no_backing_file(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'get_disk_backing_file')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "",
            "        imagebackend.libvirt_utils.get_disk_backing_file(self.PATH)\\",
            "            .AndReturn(None)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_resolve_driver_format(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        driver_format = image.resolve_driver_format()",
            "        self.assertEqual(driver_format, 'qcow2')",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: True)",
            "",
            "        # Call twice to verify testing fallocate is only called once.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(),",
            "            ['fallocate -n -l 1 %s.fallocate_test' % self.PATH,",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH),",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH)])",
            "",
            "    def test_prealloc_image_without_write_access(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "        self.stubs.Set(image, '_can_fallocate', lambda: True)",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: False)",
            "",
            "        # Testing fallocate is only called when user has write access.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class LvmTestCase(_ImageTestCase, test.NoDBTestCase):",
            "    VG = 'FakeVG'",
            "    TEMPLATE_SIZE = 512",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Lvm",
            "        super(LvmTestCase, self).setUp()",
            "        self.flags(images_volume_group=self.VG, group='libvirt')",
            "        self.LV = '%s_%s' % (self.INSTANCE['uuid'], self.NAME)",
            "        self.OLD_STYLE_INSTANCE_PATH = None",
            "        self.PATH = os.path.join('/dev', self.VG, self.LV)",
            "",
            "        self.disk = imagebackend.disk",
            "        self.utils = imagebackend.utils",
            "        self.libvirt_utils = imagebackend.libvirt_utils",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(self.disk, 'resize2fs')",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'create_lvm_image')",
            "        self.mox.StubOutWithMock(self.disk, 'get_disk_size')",
            "        self.mox.StubOutWithMock(self.utils, 'execute')",
            "        return fn",
            "",
            "    def _create_image(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.TEMPLATE_SIZE,",
            "                                            sparse=sparse)",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        cmd = ('qemu-img', 'convert', '-O', 'raw', self.TEMPLATE_PATH,",
            "               self.PATH)",
            "        self.utils.execute(*cmd, run_as_root=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def _create_image_generated(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        self.libvirt_utils.create_lvm_image(self.VG, self.LV,",
            "                                            self.SIZE, sparse=sparse)",
            "        fn(target=self.PATH, ephemeral_size=None)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH,",
            "                self.SIZE, ephemeral_size=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def _create_image_resize(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG, self.LV,",
            "                                            self.SIZE, sparse=sparse)",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        cmd = ('qemu-img', 'convert', '-O', 'raw', self.TEMPLATE_PATH,",
            "               self.PATH)",
            "        self.utils.execute(*cmd, run_as_root=True)",
            "        self.disk.resize2fs(self.PATH, run_as_root=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        self._create_image(False)",
            "",
            "    def test_create_image_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image(True)",
            "",
            "    def test_create_image_generated(self):",
            "        self._create_image_generated(False)",
            "",
            "    def test_create_image_generated_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image_generated(True)",
            "",
            "    def test_create_image_resize(self):",
            "        self._create_image_resize(False)",
            "",
            "    def test_create_image_resize_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image_resize(True)",
            "",
            "    def test_create_image_negative(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.SIZE,",
            "                                            sparse=False",
            "                                            ).AndRaise(RuntimeError())",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'remove_logical_volumes')",
            "        self.libvirt_utils.remove_logical_volumes(self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.assertRaises(RuntimeError, image.create_image, fn,",
            "                          self.TEMPLATE_PATH, self.SIZE)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_generated_negative(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.PATH,",
            "           ephemeral_size=None).AndRaise(RuntimeError())",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.SIZE,",
            "                                            sparse=False)",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'remove_logical_volumes')",
            "        self.libvirt_utils.remove_logical_volumes(self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.assertRaises(RuntimeError, image.create_image, fn,",
            "                          self.TEMPLATE_PATH, self.SIZE,",
            "                          ephemeral_size=None)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class RbdTestCase(_ImageTestCase, test.NoDBTestCase):",
            "    POOL = \"FakePool\"",
            "    USER = \"FakeUser\"",
            "    CONF = \"FakeConf\"",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Rbd",
            "        super(RbdTestCase, self).setUp()",
            "        self.flags(images_rbd_pool=self.POOL,",
            "                   rbd_user=self.USER,",
            "                   images_rbd_ceph_conf=self.CONF,",
            "                   group='libvirt')",
            "        self.libvirt_utils = imagebackend.libvirt_utils",
            "        self.utils = imagebackend.utils",
            "        self.rbd = self.mox.CreateMockAnything()",
            "        self.rados = self.mox.CreateMockAnything()",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend, 'rbd')",
            "        self.mox.StubOutWithMock(imagebackend, 'rados')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, rbd=self.rbd, target=self.TEMPLATE_PATH)",
            "",
            "        self.rbd.RBD_FEATURE_LAYERING = 1",
            "",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'get_disk_size')",
            "        imagebackend.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                       ).AndReturn(self.SIZE)",
            "        rbd_name = \"%s/%s\" % (self.INSTANCE['name'], self.NAME)",
            "        cmd = ('--pool', self.POOL, self.TEMPLATE_PATH,",
            "               rbd_name, '--new-format', '--id', self.USER,",
            "               '--conf', self.CONF)",
            "        self.libvirt_utils.import_rbd_image(self.TEMPLATE_PATH, *cmd)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None, rbd=self.rbd)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        self.mox.StubOutWithMock(imagebackend, 'rbd')",
            "        self.mox.StubOutWithMock(imagebackend, 'rados')",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        def fake_resize(rbd_name, size):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "    def test_parent_compatible(self):",
            "        self.assertEqual(inspect.getargspec(imagebackend.Image.libvirt_info),",
            "                         inspect.getargspec(self.image_class.libvirt_info))",
            "",
            "    def test_image_path(self):",
            "",
            "        conf = \"FakeConf\"",
            "        pool = \"FakePool\"",
            "        user = \"FakeUser\"",
            "",
            "        self.flags(images_rbd_pool=pool, group='libvirt')",
            "        self.flags(images_rbd_ceph_conf=conf, group='libvirt')",
            "        self.flags(rbd_user=user, group='libvirt')",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        rbd_path = \"rbd:%s/%s:id=%s:conf=%s\" % (pool, image.rbd_name,",
            "                                                user, conf)",
            "",
            "        self.assertEqual(image.path, rbd_path)",
            "",
            "",
            "class BackendTestCase(test.NoDBTestCase):",
            "    INSTANCE = {'name': 'fake-instance',",
            "                'uuid': uuidutils.generate_uuid()}",
            "    NAME = 'fake-name.suffix'",
            "",
            "    def setUp(self):",
            "        super(BackendTestCase, self).setUp()",
            "",
            "        def fake_chown(path, owner_uid=None):",
            "            return None",
            "        self.stubs.Set(utils, 'chown', fake_chown)",
            "",
            "    def get_image(self, use_cow, image_type):",
            "        return imagebackend.Backend(use_cow).image(self.INSTANCE,",
            "                                                   self.NAME,",
            "                                                   image_type)",
            "",
            "    def _test_image(self, image_type, image_not_cow, image_cow):",
            "        image1 = self.get_image(False, image_type)",
            "        image2 = self.get_image(True, image_type)",
            "",
            "        def assertIsInstance(instance, class_object):",
            "            failure = ('Expected %s,' +",
            "                       ' but got %s.') % (class_object.__name__,",
            "                                          instance.__class__.__name__)",
            "            self.assertIsInstance(instance, class_object, msg=failure)",
            "",
            "        assertIsInstance(image1, image_not_cow)",
            "        assertIsInstance(image2, image_cow)",
            "",
            "    def test_image_raw(self):",
            "        self._test_image('raw', imagebackend.Raw, imagebackend.Raw)",
            "",
            "    def test_image_qcow2(self):",
            "        self._test_image('qcow2', imagebackend.Qcow2, imagebackend.Qcow2)",
            "",
            "    def test_image_lvm(self):",
            "        self.flags(images_volume_group='FakeVG', group='libvirt')",
            "        self._test_image('lvm', imagebackend.Lvm, imagebackend.Lvm)",
            "",
            "    def test_image_rbd(self):",
            "        conf = \"FakeConf\"",
            "        pool = \"FakePool\"",
            "        self.flags(images_rbd_pool=pool, group='libvirt')",
            "        self.flags(images_rbd_ceph_conf=conf, group='libvirt')",
            "        self._test_image('rbd', imagebackend.Rbd, imagebackend.Rbd)",
            "",
            "    def test_image_default(self):",
            "        self._test_image('default', imagebackend.Raw, imagebackend.Qcow2)"
        ],
        "afterPatchFile": [
            "# Copyright 2012 Grid Dynamics",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import os",
            "import shutil",
            "import tempfile",
            "",
            "import fixtures",
            "from oslo.config import cfg",
            "",
            "import inspect",
            "",
            "from nova import exception",
            "from nova.openstack.common import units",
            "from nova.openstack.common import uuidutils",
            "from nova import test",
            "from nova.tests import fake_processutils",
            "from nova.tests.virt.libvirt import fake_libvirt_utils",
            "from nova.virt.libvirt import imagebackend",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "class _ImageTestCase(object):",
            "",
            "    def mock_create_image(self, image):",
            "        def create_image(fn, base, size, *args, **kwargs):",
            "            fn(target=base, *args, **kwargs)",
            "        image.create_image = create_image",
            "",
            "    def setUp(self):",
            "        super(_ImageTestCase, self).setUp()",
            "        self.INSTANCES_PATH = tempfile.mkdtemp(suffix='instances')",
            "        self.flags(disable_process_locking=True,",
            "                   instances_path=self.INSTANCES_PATH)",
            "        self.INSTANCE = {'name': 'instance',",
            "                         'uuid': uuidutils.generate_uuid()}",
            "        self.DISK_INFO_PATH = os.path.join(self.INSTANCES_PATH,",
            "                                           self.INSTANCE['uuid'], 'disk.info')",
            "        self.NAME = 'fake.vm'",
            "        self.TEMPLATE = 'template'",
            "",
            "        self.OLD_STYLE_INSTANCE_PATH = \\",
            "            fake_libvirt_utils.get_instance_path(self.INSTANCE, forceold=True)",
            "        self.PATH = os.path.join(",
            "            fake_libvirt_utils.get_instance_path(self.INSTANCE), self.NAME)",
            "",
            "        # TODO(mikal): rename template_dir to base_dir and template_path",
            "        # to cached_image_path. This will be less confusing.",
            "        self.TEMPLATE_DIR = os.path.join(CONF.instances_path, '_base')",
            "        self.TEMPLATE_PATH = os.path.join(self.TEMPLATE_DIR, 'template')",
            "",
            "        self.useFixture(fixtures.MonkeyPatch(",
            "            'nova.virt.libvirt.imagebackend.libvirt_utils',",
            "            fake_libvirt_utils))",
            "",
            "    def tearDown(self):",
            "        super(_ImageTestCase, self).tearDown()",
            "        shutil.rmtree(self.INSTANCES_PATH)",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: True)",
            "",
            "        # Call twice to verify testing fallocate is only called once.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(),",
            "            ['fallocate -n -l 1 %s.fallocate_test' % self.PATH,",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH),",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH)])",
            "",
            "    def test_prealloc_image_without_write_access(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "        self.stubs.Set(image, '_can_fallocate', lambda: True)",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: False)",
            "",
            "        # Testing fallocate is only called when user has write access.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class RawTestCase(_ImageTestCase, test.NoDBTestCase):",
            "",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Raw",
            "        super(RawTestCase, self).setUp()",
            "        self.stubs.Set(imagebackend.Raw, 'correct_format', lambda _: None)",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend.utils.synchronized,",
            "                                 '__call__')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils, 'copy_image')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'extend')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.TEMPLATE_PATH, max_size=None, image_id=None)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH, self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None, image_id=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_generated(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_extend(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH, image_id=None)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH, self.PATH)",
            "        imagebackend.disk.extend(self.PATH, self.SIZE, use_cow=False)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE, image_id=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_correct_format(self):",
            "        self.stubs.UnsetAll()",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.images, 'qemu_img_info')",
            "",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        info = self.mox.CreateMockAnything()",
            "        info.file_format = 'foo'",
            "        imagebackend.images.qemu_img_info(self.PATH).AndReturn(info)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME, path=self.PATH)",
            "        self.assertEqual(image.driver_format, 'foo')",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_resolve_driver_format(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        driver_format = image.resolve_driver_format()",
            "        self.assertEqual(driver_format, 'raw')",
            "",
            "",
            "class Qcow2TestCase(_ImageTestCase, test.NoDBTestCase):",
            "    SIZE = units.Gi",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Qcow2",
            "        super(Qcow2TestCase, self).setUp()",
            "        self.QCOW2_BASE = (self.TEMPLATE_PATH +",
            "                           '_%d' % (self.SIZE / units.Gi))",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend.utils.synchronized,",
            "                                 '__call__')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'create_cow_image')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils, 'copy_image')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'extend')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, target=self.TEMPLATE_PATH)",
            "        imagebackend.libvirt_utils.create_cow_image(self.TEMPLATE_PATH,",
            "                                                    self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_with_size(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        imagebackend.libvirt_utils.create_cow_image(self.TEMPLATE_PATH,",
            "                                                    self.PATH)",
            "        imagebackend.disk.extend(self.PATH, self.SIZE, use_cow=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_too_small(self):",
            "        fn = self.prepare_mocks()",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'get_disk_size')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        imagebackend.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                       ).AndReturn(self.SIZE)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.assertRaises(exception.FlavorDiskTooSmall,",
            "                          image.create_image, fn, self.TEMPLATE_PATH, 1)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_generate_resized_backing_files(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'get_disk_backing_file')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(CONF.instances_path).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "",
            "        imagebackend.libvirt_utils.get_disk_backing_file(self.PATH)\\",
            "            .AndReturn(self.QCOW2_BASE)",
            "        os.path.exists(self.QCOW2_BASE).AndReturn(False)",
            "        imagebackend.libvirt_utils.copy_image(self.TEMPLATE_PATH,",
            "                                              self.QCOW2_BASE)",
            "        imagebackend.disk.extend(self.QCOW2_BASE, self.SIZE, use_cow=True)",
            "",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_qcow2_exists_and_has_no_backing_file(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(imagebackend.libvirt_utils,",
            "                                 'get_disk_backing_file')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.DISK_INFO_PATH).AndReturn(False)",
            "        os.path.exists(self.INSTANCES_PATH).AndReturn(True)",
            "",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "",
            "        imagebackend.libvirt_utils.get_disk_backing_file(self.PATH)\\",
            "            .AndReturn(None)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_resolve_driver_format(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        driver_format = image.resolve_driver_format()",
            "        self.assertEqual(driver_format, 'qcow2')",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: True)",
            "",
            "        # Call twice to verify testing fallocate is only called once.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(),",
            "            ['fallocate -n -l 1 %s.fallocate_test' % self.PATH,",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH),",
            "             'fallocate -n -l %s %s' % (self.SIZE, self.PATH)])",
            "",
            "    def test_prealloc_image_without_write_access(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "        self.stubs.Set(image, '_can_fallocate', lambda: True)",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(os, 'access', lambda p, w: False)",
            "",
            "        # Testing fallocate is only called when user has write access.",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class LvmTestCase(_ImageTestCase, test.NoDBTestCase):",
            "    VG = 'FakeVG'",
            "    TEMPLATE_SIZE = 512",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Lvm",
            "        super(LvmTestCase, self).setUp()",
            "        self.flags(images_volume_group=self.VG, group='libvirt')",
            "        self.LV = '%s_%s' % (self.INSTANCE['uuid'], self.NAME)",
            "        self.OLD_STYLE_INSTANCE_PATH = None",
            "        self.PATH = os.path.join('/dev', self.VG, self.LV)",
            "",
            "        self.disk = imagebackend.disk",
            "        self.utils = imagebackend.utils",
            "        self.libvirt_utils = imagebackend.libvirt_utils",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(self.disk, 'resize2fs')",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'create_lvm_image')",
            "        self.mox.StubOutWithMock(self.disk, 'get_disk_size')",
            "        self.mox.StubOutWithMock(self.utils, 'execute')",
            "        return fn",
            "",
            "    def _create_image(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.TEMPLATE_SIZE,",
            "                                            sparse=sparse)",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        cmd = ('qemu-img', 'convert', '-O', 'raw', self.TEMPLATE_PATH,",
            "               self.PATH)",
            "        self.utils.execute(*cmd, run_as_root=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def _create_image_generated(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        self.libvirt_utils.create_lvm_image(self.VG, self.LV,",
            "                                            self.SIZE, sparse=sparse)",
            "        fn(target=self.PATH, ephemeral_size=None)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH,",
            "                self.SIZE, ephemeral_size=None)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def _create_image_resize(self, sparse):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG, self.LV,",
            "                                            self.SIZE, sparse=sparse)",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        cmd = ('qemu-img', 'convert', '-O', 'raw', self.TEMPLATE_PATH,",
            "               self.PATH)",
            "        self.utils.execute(*cmd, run_as_root=True)",
            "        self.disk.resize2fs(self.PATH, run_as_root=True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        if self.OLD_STYLE_INSTANCE_PATH:",
            "            os.path.exists(self.OLD_STYLE_INSTANCE_PATH).AndReturn(False)",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        os.path.exists(self.PATH).AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        self._create_image(False)",
            "",
            "    def test_create_image_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image(True)",
            "",
            "    def test_create_image_generated(self):",
            "        self._create_image_generated(False)",
            "",
            "    def test_create_image_generated_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image_generated(True)",
            "",
            "    def test_create_image_resize(self):",
            "        self._create_image_resize(False)",
            "",
            "    def test_create_image_resize_sparsed(self):",
            "        self.flags(sparse_logical_volumes=True, group='libvirt')",
            "        self._create_image_resize(True)",
            "",
            "    def test_create_image_negative(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=self.SIZE, target=self.TEMPLATE_PATH)",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.SIZE,",
            "                                            sparse=False",
            "                                            ).AndRaise(RuntimeError())",
            "        self.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                         ).AndReturn(self.TEMPLATE_SIZE)",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'remove_logical_volumes')",
            "        self.libvirt_utils.remove_logical_volumes(self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.assertRaises(RuntimeError, image.create_image, fn,",
            "                          self.TEMPLATE_PATH, self.SIZE)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image_generated_negative(self):",
            "        fn = self.prepare_mocks()",
            "        fn(target=self.PATH,",
            "           ephemeral_size=None).AndRaise(RuntimeError())",
            "        self.libvirt_utils.create_lvm_image(self.VG,",
            "                                            self.LV,",
            "                                            self.SIZE,",
            "                                            sparse=False)",
            "        self.mox.StubOutWithMock(self.libvirt_utils, 'remove_logical_volumes')",
            "        self.libvirt_utils.remove_logical_volumes(self.PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.assertRaises(RuntimeError, image.create_image, fn,",
            "                          self.TEMPLATE_PATH, self.SIZE,",
            "                          ephemeral_size=None)",
            "        self.mox.VerifyAll()",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "",
            "class RbdTestCase(_ImageTestCase, test.NoDBTestCase):",
            "    POOL = \"FakePool\"",
            "    USER = \"FakeUser\"",
            "    CONF = \"FakeConf\"",
            "    SIZE = 1024",
            "",
            "    def setUp(self):",
            "        self.image_class = imagebackend.Rbd",
            "        super(RbdTestCase, self).setUp()",
            "        self.flags(images_rbd_pool=self.POOL,",
            "                   rbd_user=self.USER,",
            "                   images_rbd_ceph_conf=self.CONF,",
            "                   group='libvirt')",
            "        self.libvirt_utils = imagebackend.libvirt_utils",
            "        self.utils = imagebackend.utils",
            "        self.rbd = self.mox.CreateMockAnything()",
            "        self.rados = self.mox.CreateMockAnything()",
            "",
            "    def prepare_mocks(self):",
            "        fn = self.mox.CreateMockAnything()",
            "        self.mox.StubOutWithMock(imagebackend, 'rbd')",
            "        self.mox.StubOutWithMock(imagebackend, 'rados')",
            "        return fn",
            "",
            "    def test_cache(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(False)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        imagebackend.fileutils.ensure_tree(self.TEMPLATE_DIR)",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_base_dir_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.StubOutWithMock(imagebackend.fileutils, 'ensure_tree')",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_image_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(True)",
            "        os.path.exists(self.TEMPLATE_PATH).AndReturn(True)",
            "        self.mox.ReplayAll()",
            "",
            "        image.cache(None, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_cache_template_exists(self):",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        self.mox.StubOutWithMock(os.path, 'exists')",
            "        self.mox.StubOutWithMock(image, 'check_image_exists')",
            "        os.path.exists(self.TEMPLATE_DIR).AndReturn(True)",
            "        image.check_image_exists().AndReturn(False)",
            "        fn = self.mox.CreateMockAnything()",
            "        fn(target=self.TEMPLATE_PATH)",
            "        self.mox.ReplayAll()",
            "",
            "        self.mock_create_image(image)",
            "        image.cache(fn, self.TEMPLATE)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_create_image(self):",
            "        fn = self.prepare_mocks()",
            "        fn(max_size=None, rbd=self.rbd, target=self.TEMPLATE_PATH)",
            "",
            "        self.rbd.RBD_FEATURE_LAYERING = 1",
            "",
            "        self.mox.StubOutWithMock(imagebackend.disk, 'get_disk_size')",
            "        imagebackend.disk.get_disk_size(self.TEMPLATE_PATH",
            "                                       ).AndReturn(self.SIZE)",
            "        rbd_name = \"%s/%s\" % (self.INSTANCE['name'], self.NAME)",
            "        cmd = ('--pool', self.POOL, self.TEMPLATE_PATH,",
            "               rbd_name, '--new-format', '--id', self.USER,",
            "               '--conf', self.CONF)",
            "        self.libvirt_utils.import_rbd_image(self.TEMPLATE_PATH, *cmd)",
            "        self.mox.ReplayAll()",
            "",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        image.create_image(fn, self.TEMPLATE_PATH, None, rbd=self.rbd)",
            "",
            "        self.mox.VerifyAll()",
            "",
            "    def test_prealloc_image(self):",
            "        CONF.set_override('preallocate_images', 'space')",
            "",
            "        fake_processutils.fake_execute_clear_log()",
            "        fake_processutils.stub_out_processutils_execute(self.stubs)",
            "        self.mox.StubOutWithMock(imagebackend, 'rbd')",
            "        self.mox.StubOutWithMock(imagebackend, 'rados')",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "",
            "        def fake_fetch(target, *args, **kwargs):",
            "            return",
            "",
            "        def fake_resize(rbd_name, size):",
            "            return",
            "",
            "        self.stubs.Set(os.path, 'exists', lambda _: True)",
            "        self.stubs.Set(image, 'check_image_exists', lambda: True)",
            "",
            "        image.cache(fake_fetch, self.TEMPLATE_PATH, self.SIZE)",
            "",
            "        self.assertEqual(fake_processutils.fake_execute_get_log(), [])",
            "",
            "    def test_parent_compatible(self):",
            "        self.assertEqual(inspect.getargspec(imagebackend.Image.libvirt_info),",
            "                         inspect.getargspec(self.image_class.libvirt_info))",
            "",
            "    def test_image_path(self):",
            "",
            "        conf = \"FakeConf\"",
            "        pool = \"FakePool\"",
            "        user = \"FakeUser\"",
            "",
            "        self.flags(images_rbd_pool=pool, group='libvirt')",
            "        self.flags(images_rbd_ceph_conf=conf, group='libvirt')",
            "        self.flags(rbd_user=user, group='libvirt')",
            "        image = self.image_class(self.INSTANCE, self.NAME)",
            "        rbd_path = \"rbd:%s/%s:id=%s:conf=%s\" % (pool, image.rbd_name,",
            "                                                user, conf)",
            "",
            "        self.assertEqual(image.path, rbd_path)",
            "",
            "",
            "class BackendTestCase(test.NoDBTestCase):",
            "    INSTANCE = {'name': 'fake-instance',",
            "                'uuid': uuidutils.generate_uuid()}",
            "    NAME = 'fake-name.suffix'",
            "",
            "    def setUp(self):",
            "        super(BackendTestCase, self).setUp()",
            "",
            "    def get_image(self, use_cow, image_type):",
            "        return imagebackend.Backend(use_cow).image(self.INSTANCE,",
            "                                                   self.NAME,",
            "                                                   image_type)",
            "",
            "    def _test_image(self, image_type, image_not_cow, image_cow):",
            "        image1 = self.get_image(False, image_type)",
            "        image2 = self.get_image(True, image_type)",
            "",
            "        def assertIsInstance(instance, class_object):",
            "            failure = ('Expected %s,' +",
            "                       ' but got %s.') % (class_object.__name__,",
            "                                          instance.__class__.__name__)",
            "            self.assertIsInstance(instance, class_object, msg=failure)",
            "",
            "        assertIsInstance(image1, image_not_cow)",
            "        assertIsInstance(image2, image_cow)",
            "",
            "    def test_image_raw(self):",
            "        self._test_image('raw', imagebackend.Raw, imagebackend.Raw)",
            "",
            "    def test_image_qcow2(self):",
            "        self._test_image('qcow2', imagebackend.Qcow2, imagebackend.Qcow2)",
            "",
            "    def test_image_lvm(self):",
            "        self.flags(images_volume_group='FakeVG', group='libvirt')",
            "        self._test_image('lvm', imagebackend.Lvm, imagebackend.Lvm)",
            "",
            "    def test_image_rbd(self):",
            "        conf = \"FakeConf\"",
            "        pool = \"FakePool\"",
            "        self.flags(images_rbd_pool=pool, group='libvirt')",
            "        self.flags(images_rbd_ceph_conf=conf, group='libvirt')",
            "        self._test_image('rbd', imagebackend.Rbd, imagebackend.Rbd)",
            "",
            "    def test_image_default(self):",
            "        self._test_image('default', imagebackend.Raw, imagebackend.Qcow2)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "31": [],
            "70": [
                "_ImageTestCase",
                "setUp",
                "fake_chown"
            ],
            "71": [
                "_ImageTestCase",
                "setUp",
                "fake_chown"
            ],
            "72": [
                "_ImageTestCase",
                "setUp"
            ],
            "73": [
                "_ImageTestCase"
            ],
            "130": [
                "RawTestCase",
                "setUp",
                "fake_chown"
            ],
            "131": [
                "RawTestCase",
                "setUp",
                "fake_chown"
            ],
            "132": [
                "RawTestCase",
                "setUp"
            ],
            "133": [
                "RawTestCase"
            ],
            "246": [
                "RawTestCase",
                "test_correct_format",
                "fake_chown"
            ],
            "247": [
                "RawTestCase",
                "test_correct_format",
                "fake_chown"
            ],
            "248": [
                "RawTestCase",
                "test_correct_format"
            ],
            "249": [
                "RawTestCase",
                "test_correct_format"
            ],
            "278": [
                "Qcow2TestCase",
                "setUp",
                "fake_chown"
            ],
            "279": [
                "Qcow2TestCase",
                "setUp",
                "fake_chown"
            ],
            "280": [
                "Qcow2TestCase",
                "setUp"
            ],
            "281": [
                "Qcow2TestCase"
            ],
            "877": [
                "BackendTestCase",
                "setUp",
                "fake_chown"
            ],
            "878": [
                "BackendTestCase",
                "setUp",
                "fake_chown"
            ],
            "879": [
                "BackendTestCase",
                "setUp"
            ],
            "880": [
                "BackendTestCase"
            ]
        },
        "addLocation": []
    },
    "nova/utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 761,
                "afterPatchRowNumber": 761,
                "PatchRowcode": "             execute('chown', orig_uid, path, run_as_root=True)"
            },
            "1": {
                "beforePatchRowNumber": 762,
                "afterPatchRowNumber": 762,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 763,
                "afterPatchRowNumber": 763,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 764,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def chown(path, owner_uid=None):"
            },
            "4": {
                "beforePatchRowNumber": 765,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"chown a path."
            },
            "5": {
                "beforePatchRowNumber": 766,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "6": {
                "beforePatchRowNumber": 767,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    :param owner_uid: UID of owner (defaults to current user)"
            },
            "7": {
                "beforePatchRowNumber": 768,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "8": {
                "beforePatchRowNumber": 769,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if owner_uid is None:"
            },
            "9": {
                "beforePatchRowNumber": 770,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        owner_uid = os.getuid()"
            },
            "10": {
                "beforePatchRowNumber": 771,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "11": {
                "beforePatchRowNumber": 772,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    orig_uid = os.stat(path).st_uid"
            },
            "12": {
                "beforePatchRowNumber": 773,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "13": {
                "beforePatchRowNumber": 774,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if orig_uid != owner_uid:"
            },
            "14": {
                "beforePatchRowNumber": 775,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        execute('chown', owner_uid, path, run_as_root=True)"
            },
            "15": {
                "beforePatchRowNumber": 776,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "16": {
                "beforePatchRowNumber": 777,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "17": {
                "beforePatchRowNumber": 778,
                "afterPatchRowNumber": 764,
                "PatchRowcode": " @contextlib.contextmanager"
            },
            "18": {
                "beforePatchRowNumber": 779,
                "afterPatchRowNumber": 765,
                "PatchRowcode": " def tempdir(**kwargs):"
            },
            "19": {
                "beforePatchRowNumber": 780,
                "afterPatchRowNumber": 766,
                "PatchRowcode": "     argdict = kwargs.copy()"
            }
        },
        "frontPatchFile": [
            "# Copyright 2010 United States Government as represented by the",
            "# Administrator of the National Aeronautics and Space Administration.",
            "# Copyright 2011 Justin Santa Barbara",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"Utilities and helper functions.\"\"\"",
            "",
            "import contextlib",
            "import datetime",
            "import functools",
            "import hashlib",
            "import inspect",
            "import multiprocessing",
            "import os",
            "import pyclbr",
            "import random",
            "import re",
            "import shutil",
            "import socket",
            "import struct",
            "import sys",
            "import tempfile",
            "from xml.sax import saxutils",
            "",
            "import eventlet",
            "import netaddr",
            "from oslo.config import cfg",
            "from oslo import messaging",
            "import six",
            "",
            "from nova import exception",
            "from nova.openstack.common import excutils",
            "from nova.openstack.common import gettextutils",
            "from nova.openstack.common.gettextutils import _",
            "from nova.openstack.common import importutils",
            "from nova.openstack.common import lockutils",
            "from nova.openstack.common import log as logging",
            "from nova.openstack.common import processutils",
            "from nova.openstack.common import timeutils",
            "",
            "notify_decorator = 'nova.notifications.notify_decorator'",
            "",
            "monkey_patch_opts = [",
            "    cfg.BoolOpt('monkey_patch',",
            "                default=False,",
            "                help='Whether to log monkey patching'),",
            "    cfg.ListOpt('monkey_patch_modules',",
            "                default=[",
            "                  'nova.api.ec2.cloud:%s' % (notify_decorator),",
            "                  'nova.compute.api:%s' % (notify_decorator)",
            "                  ],",
            "                help='List of modules/decorators to monkey patch'),",
            "]",
            "utils_opts = [",
            "    cfg.IntOpt('password_length',",
            "               default=12,",
            "               help='Length of generated instance admin passwords'),",
            "    cfg.StrOpt('instance_usage_audit_period',",
            "               default='month',",
            "               help='Time period to generate instance usages for.  '",
            "                    'Time period must be hour, day, month or year'),",
            "    cfg.StrOpt('rootwrap_config',",
            "               default=\"/etc/nova/rootwrap.conf\",",
            "               help='Path to the rootwrap configuration file to use for '",
            "                    'running commands as root'),",
            "    cfg.StrOpt('tempdir',",
            "               help='Explicitly specify the temporary working directory'),",
            "]",
            "CONF = cfg.CONF",
            "CONF.register_opts(monkey_patch_opts)",
            "CONF.register_opts(utils_opts)",
            "CONF.import_opt('network_api_class', 'nova.network')",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "# used in limits",
            "TIME_UNITS = {",
            "    'SECOND': 1,",
            "    'MINUTE': 60,",
            "    'HOUR': 3600,",
            "    'DAY': 84400",
            "}",
            "",
            "",
            "_IS_NEUTRON = None",
            "",
            "synchronized = lockutils.synchronized_with_prefix('nova-')",
            "",
            "SM_IMAGE_PROP_PREFIX = \"image_\"",
            "SM_INHERITABLE_KEYS = (",
            "    'min_ram', 'min_disk', 'disk_format', 'container_format',",
            ")",
            "",
            "",
            "def vpn_ping(address, port, timeout=0.05, session_id=None):",
            "    \"\"\"Sends a vpn negotiation packet and returns the server session.",
            "",
            "    Returns False on a failure. Basic packet structure is below.",
            "",
            "    Client packet (14 bytes)::",
            "",
            "         0 1      8 9  13",
            "        +-+--------+-----+",
            "        |x| cli_id |?????|",
            "        +-+--------+-----+",
            "        x = packet identifier 0x38",
            "        cli_id = 64 bit identifier",
            "        ? = unknown, probably flags/padding",
            "",
            "    Server packet (26 bytes)::",
            "",
            "         0 1      8 9  13 14    21 2225",
            "        +-+--------+-----+--------+----+",
            "        |x| srv_id |?????| cli_id |????|",
            "        +-+--------+-----+--------+----+",
            "        x = packet identifier 0x40",
            "        cli_id = 64 bit identifier",
            "        ? = unknown, probably flags/padding",
            "        bit 9 was 1 and the rest were 0 in testing",
            "",
            "    \"\"\"",
            "    if session_id is None:",
            "        session_id = random.randint(0, 0xffffffffffffffff)",
            "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)",
            "    data = struct.pack('!BQxxxxx', 0x38, session_id)",
            "    sock.sendto(data, (address, port))",
            "    sock.settimeout(timeout)",
            "    try:",
            "        received = sock.recv(2048)",
            "    except socket.timeout:",
            "        return False",
            "    finally:",
            "        sock.close()",
            "    fmt = '!BQxxxxxQxxxx'",
            "    if len(received) != struct.calcsize(fmt):",
            "        LOG.warn(_('Expected to receive %(exp)s bytes, but actually %(act)s') %",
            "                 dict(exp=struct.calcsize(fmt), act=len(received)))",
            "        return False",
            "    (identifier, server_sess, client_sess) = struct.unpack(fmt, received)",
            "    if identifier == 0x40 and client_sess == session_id:",
            "        return server_sess",
            "",
            "",
            "def _get_root_helper():",
            "    return 'sudo nova-rootwrap %s' % CONF.rootwrap_config",
            "",
            "",
            "def execute(*cmd, **kwargs):",
            "    \"\"\"Convenience wrapper around oslo's execute() method.\"\"\"",
            "    if 'run_as_root' in kwargs and not 'root_helper' in kwargs:",
            "        kwargs['root_helper'] = _get_root_helper()",
            "    return processutils.execute(*cmd, **kwargs)",
            "",
            "",
            "def trycmd(*args, **kwargs):",
            "    \"\"\"Convenience wrapper around oslo's trycmd() method.\"\"\"",
            "    if 'run_as_root' in kwargs and not 'root_helper' in kwargs:",
            "        kwargs['root_helper'] = _get_root_helper()",
            "    return processutils.trycmd(*args, **kwargs)",
            "",
            "",
            "def novadir():",
            "    import nova",
            "    return os.path.abspath(nova.__file__).split('nova/__init__.py')[0]",
            "",
            "",
            "def generate_uid(topic, size=8):",
            "    characters = '01234567890abcdefghijklmnopqrstuvwxyz'",
            "    choices = [random.choice(characters) for _x in xrange(size)]",
            "    return '%s-%s' % (topic, ''.join(choices))",
            "",
            "",
            "# Default symbols to use for passwords. Avoids visually confusing characters.",
            "# ~6 bits per symbol",
            "DEFAULT_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0,1",
            "                            'ABCDEFGHJKLMNPQRSTUVWXYZ',   # Removed: I, O",
            "                            'abcdefghijkmnopqrstuvwxyz')  # Removed: l",
            "",
            "",
            "# ~5 bits per symbol",
            "EASIER_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0, 1",
            "                           'ABCDEFGHJKLMNPQRSTUVWXYZ')  # Removed: I, O",
            "",
            "",
            "def last_completed_audit_period(unit=None, before=None):",
            "    \"\"\"This method gives you the most recently *completed* audit period.",
            "",
            "    arguments:",
            "            units: string, one of 'hour', 'day', 'month', 'year'",
            "                    Periods normally begin at the beginning (UTC) of the",
            "                    period unit (So a 'day' period begins at midnight UTC,",
            "                    a 'month' unit on the 1st, a 'year' on Jan, 1)",
            "                    unit string may be appended with an optional offset",
            "                    like so:  'day@18'  This will begin the period at 18:00",
            "                    UTC.  'month@15' starts a monthly period on the 15th,",
            "                    and year@3 begins a yearly one on March 1st.",
            "            before: Give the audit period most recently completed before",
            "                    <timestamp>. Defaults to now.",
            "",
            "",
            "    returns:  2 tuple of datetimes (begin, end)",
            "              The begin timestamp of this audit period is the same as the",
            "              end of the previous.",
            "    \"\"\"",
            "    if not unit:",
            "        unit = CONF.instance_usage_audit_period",
            "",
            "    offset = 0",
            "    if '@' in unit:",
            "        unit, offset = unit.split(\"@\", 1)",
            "        offset = int(offset)",
            "",
            "    if before is not None:",
            "        rightnow = before",
            "    else:",
            "        rightnow = timeutils.utcnow()",
            "    if unit not in ('month', 'day', 'year', 'hour'):",
            "        raise ValueError('Time period must be hour, day, month or year')",
            "    if unit == 'month':",
            "        if offset == 0:",
            "            offset = 1",
            "        end = datetime.datetime(day=offset,",
            "                                month=rightnow.month,",
            "                                year=rightnow.year)",
            "        if end >= rightnow:",
            "            year = rightnow.year",
            "            if 1 >= rightnow.month:",
            "                year -= 1",
            "                month = 12 + (rightnow.month - 1)",
            "            else:",
            "                month = rightnow.month - 1",
            "            end = datetime.datetime(day=offset,",
            "                                    month=month,",
            "                                    year=year)",
            "        year = end.year",
            "        if 1 >= end.month:",
            "            year -= 1",
            "            month = 12 + (end.month - 1)",
            "        else:",
            "            month = end.month - 1",
            "        begin = datetime.datetime(day=offset, month=month, year=year)",
            "",
            "    elif unit == 'year':",
            "        if offset == 0:",
            "            offset = 1",
            "        end = datetime.datetime(day=1, month=offset, year=rightnow.year)",
            "        if end >= rightnow:",
            "            end = datetime.datetime(day=1,",
            "                                    month=offset,",
            "                                    year=rightnow.year - 1)",
            "            begin = datetime.datetime(day=1,",
            "                                      month=offset,",
            "                                      year=rightnow.year - 2)",
            "        else:",
            "            begin = datetime.datetime(day=1,",
            "                                      month=offset,",
            "                                      year=rightnow.year - 1)",
            "",
            "    elif unit == 'day':",
            "        end = datetime.datetime(hour=offset,",
            "                               day=rightnow.day,",
            "                               month=rightnow.month,",
            "                               year=rightnow.year)",
            "        if end >= rightnow:",
            "            end = end - datetime.timedelta(days=1)",
            "        begin = end - datetime.timedelta(days=1)",
            "",
            "    elif unit == 'hour':",
            "        end = rightnow.replace(minute=offset, second=0, microsecond=0)",
            "        if end >= rightnow:",
            "            end = end - datetime.timedelta(hours=1)",
            "        begin = end - datetime.timedelta(hours=1)",
            "",
            "    return (begin, end)",
            "",
            "",
            "def generate_password(length=None, symbolgroups=DEFAULT_PASSWORD_SYMBOLS):",
            "    \"\"\"Generate a random password from the supplied symbol groups.",
            "",
            "    At least one symbol from each group will be included. Unpredictable",
            "    results if length is less than the number of symbol groups.",
            "",
            "    Believed to be reasonably secure (with a reasonable password length!)",
            "",
            "    \"\"\"",
            "    if length is None:",
            "        length = CONF.password_length",
            "",
            "    r = random.SystemRandom()",
            "",
            "    # NOTE(jerdfelt): Some password policies require at least one character",
            "    # from each group of symbols, so start off with one random character",
            "    # from each symbol group",
            "    password = [r.choice(s) for s in symbolgroups]",
            "    # If length < len(symbolgroups), the leading characters will only",
            "    # be from the first length groups. Try our best to not be predictable",
            "    # by shuffling and then truncating.",
            "    r.shuffle(password)",
            "    password = password[:length]",
            "    length -= len(password)",
            "",
            "    # then fill with random characters from all symbol groups",
            "    symbols = ''.join(symbolgroups)",
            "    password.extend([r.choice(symbols) for _i in xrange(length)])",
            "",
            "    # finally shuffle to ensure first x characters aren't from a",
            "    # predictable group",
            "    r.shuffle(password)",
            "",
            "    return ''.join(password)",
            "",
            "",
            "def get_my_ipv4_address():",
            "    \"\"\"Run ip route/addr commands to figure out the best ipv4",
            "    \"\"\"",
            "    LOCALHOST = '127.0.0.1'",
            "    try:",
            "        out = execute('ip', '-f', 'inet', '-o', 'route', 'show')",
            "",
            "        # Find the default route",
            "        regex_default = ('default\\s*via\\s*'",
            "                         '(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'",
            "                         '\\s*dev\\s*(\\w*)\\s*')",
            "        default_routes = re.findall(regex_default, out[0])",
            "        if not default_routes:",
            "            return LOCALHOST",
            "        gateway, iface = default_routes[0]",
            "",
            "        # Find the right subnet for the gateway/interface for",
            "        # the default route",
            "        route = ('(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\/(\\d{1,2})'",
            "              '\\s*dev\\s*(\\w*)\\s*')",
            "        for match in re.finditer(route, out[0]):",
            "            subnet = netaddr.IPNetwork(match.group(1) + \"/\" + match.group(2))",
            "            if (match.group(3) == iface and",
            "                    netaddr.IPAddress(gateway) in subnet):",
            "                try:",
            "                    return _get_ipv4_address_for_interface(iface)",
            "                except exception.NovaException:",
            "                    pass",
            "    except Exception as ex:",
            "        LOG.error(_(\"Couldn't get IPv4 : %(ex)s\") % {'ex': ex})",
            "    return LOCALHOST",
            "",
            "",
            "def _get_ipv4_address_for_interface(iface):",
            "    \"\"\"Run ip addr show for an interface and grab its ipv4 addresses",
            "    \"\"\"",
            "    try:",
            "        out = execute('ip', '-f', 'inet', '-o', 'addr', 'show', iface)",
            "        regexp_address = re.compile('inet\\s*'",
            "                                    '(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})')",
            "        address = [m.group(1) for m in regexp_address.finditer(out[0])",
            "                   if m.group(1) != '127.0.0.1']",
            "        if address:",
            "            return address[0]",
            "        else:",
            "            msg = _('IPv4 address is not found.: %s') % out[0]",
            "            raise exception.NovaException(msg)",
            "    except Exception as ex:",
            "        msg = _(\"Couldn't get IPv4 of %(interface)s\"",
            "                \" : %(ex)s\") % {'interface': iface, 'ex': ex}",
            "        LOG.error(msg)",
            "        raise exception.NovaException(msg)",
            "",
            "",
            "def get_my_linklocal(interface):",
            "    try:",
            "        if_str = execute('ip', '-f', 'inet6', '-o', 'addr', 'show', interface)",
            "        condition = '\\s+inet6\\s+([0-9a-f:]+)/\\d+\\s+scope\\s+link'",
            "        links = [re.search(condition, x) for x in if_str[0].split('\\n')]",
            "        address = [w.group(1) for w in links if w is not None]",
            "        if address[0] is not None:",
            "            return address[0]",
            "        else:",
            "            msg = _('Link Local address is not found.:%s') % if_str",
            "            raise exception.NovaException(msg)",
            "    except Exception as ex:",
            "        msg = _(\"Couldn't get Link Local IP of %(interface)s\"",
            "                \" :%(ex)s\") % {'interface': interface, 'ex': ex}",
            "        raise exception.NovaException(msg)",
            "",
            "",
            "class LazyPluggable(object):",
            "    \"\"\"A pluggable backend loaded lazily based on some value.\"\"\"",
            "",
            "    def __init__(self, pivot, config_group=None, **backends):",
            "        self.__backends = backends",
            "        self.__pivot = pivot",
            "        self.__backend = None",
            "        self.__config_group = config_group",
            "",
            "    def __get_backend(self):",
            "        if not self.__backend:",
            "            if self.__config_group is None:",
            "                backend_name = CONF[self.__pivot]",
            "            else:",
            "                backend_name = CONF[self.__config_group][self.__pivot]",
            "            if backend_name not in self.__backends:",
            "                msg = _('Invalid backend: %s') % backend_name",
            "                raise exception.NovaException(msg)",
            "",
            "            backend = self.__backends[backend_name]",
            "            if isinstance(backend, tuple):",
            "                name = backend[0]",
            "                fromlist = backend[1]",
            "            else:",
            "                name = backend",
            "                fromlist = backend",
            "",
            "            self.__backend = __import__(name, None, None, fromlist)",
            "        return self.__backend",
            "",
            "    def __getattr__(self, key):",
            "        backend = self.__get_backend()",
            "        return getattr(backend, key)",
            "",
            "",
            "def xhtml_escape(value):",
            "    \"\"\"Escapes a string so it is valid within XML or XHTML.",
            "",
            "    \"\"\"",
            "    return saxutils.escape(value, {'\"': '&quot;', \"'\": '&apos;'})",
            "",
            "",
            "def utf8(value):",
            "    \"\"\"Try to turn a string into utf-8 if possible.",
            "",
            "    Code is directly from the utf8 function in",
            "    http://github.com/facebook/tornado/blob/master/tornado/escape.py",
            "",
            "    \"\"\"",
            "    if isinstance(value, unicode):",
            "        return value.encode('utf-8')",
            "    elif isinstance(value, gettextutils.Message):",
            "        return unicode(value).encode('utf-8')",
            "    assert isinstance(value, str)",
            "    return value",
            "",
            "",
            "def check_isinstance(obj, cls):",
            "    \"\"\"Checks that obj is of type cls, and lets PyLint infer types.\"\"\"",
            "    if isinstance(obj, cls):",
            "        return obj",
            "    raise Exception(_('Expected object of type: %s') % (str(cls)))",
            "",
            "",
            "def parse_server_string(server_str):",
            "    \"\"\"Parses the given server_string and returns a list of host and port.",
            "    If it's not a combination of host part and port, the port element",
            "    is a null string. If the input is invalid expression, return a null",
            "    list.",
            "    \"\"\"",
            "    try:",
            "        # First of all, exclude pure IPv6 address (w/o port).",
            "        if netaddr.valid_ipv6(server_str):",
            "            return (server_str, '')",
            "",
            "        # Next, check if this is IPv6 address with a port number combination.",
            "        if server_str.find(\"]:\") != -1:",
            "            (address, port) = server_str.replace('[', '', 1).split(']:')",
            "            return (address, port)",
            "",
            "        # Third, check if this is a combination of an address and a port",
            "        if server_str.find(':') == -1:",
            "            return (server_str, '')",
            "",
            "        # This must be a combination of an address and a port",
            "        (address, port) = server_str.split(':')",
            "        return (address, port)",
            "",
            "    except Exception:",
            "        LOG.error(_('Invalid server_string: %s'), server_str)",
            "        return ('', '')",
            "",
            "",
            "def is_int_like(val):",
            "    \"\"\"Check if a value looks like an int.\"\"\"",
            "    try:",
            "        return str(int(val)) == str(val)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ipv4(address):",
            "    \"\"\"Verify that address represents a valid IPv4 address.\"\"\"",
            "    try:",
            "        return netaddr.valid_ipv4(address)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ipv6(address):",
            "    try:",
            "        return netaddr.valid_ipv6(address)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ip_address(address):",
            "    return is_valid_ipv4(address) or is_valid_ipv6(address)",
            "",
            "",
            "def is_valid_ipv6_cidr(address):",
            "    try:",
            "        str(netaddr.IPNetwork(address, version=6).cidr)",
            "        return True",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def get_shortened_ipv6(address):",
            "    addr = netaddr.IPAddress(address, version=6)",
            "    return str(addr.ipv6())",
            "",
            "",
            "def get_shortened_ipv6_cidr(address):",
            "    net = netaddr.IPNetwork(address, version=6)",
            "    return str(net.cidr)",
            "",
            "",
            "def is_valid_cidr(address):",
            "    \"\"\"Check if address is valid",
            "",
            "    The provided address can be a IPv6 or a IPv4",
            "    CIDR address.",
            "    \"\"\"",
            "    try:",
            "        # Validate the correct CIDR Address",
            "        netaddr.IPNetwork(address)",
            "    except netaddr.core.AddrFormatError:",
            "        return False",
            "    except UnboundLocalError:",
            "        # NOTE(MotoKen): work around bug in netaddr 0.7.5 (see detail in",
            "        # https://github.com/drkjam/netaddr/issues/2)",
            "        return False",
            "",
            "    # Prior validation partially verify /xx part",
            "    # Verify it here",
            "    ip_segment = address.split('/')",
            "",
            "    if (len(ip_segment) <= 1 or",
            "            ip_segment[1] == ''):",
            "        return False",
            "",
            "    return True",
            "",
            "",
            "def get_ip_version(network):",
            "    \"\"\"Returns the IP version of a network (IPv4 or IPv6).",
            "",
            "    Raises AddrFormatError if invalid network.",
            "    \"\"\"",
            "    if netaddr.IPNetwork(network).version == 6:",
            "        return \"IPv6\"",
            "    elif netaddr.IPNetwork(network).version == 4:",
            "        return \"IPv4\"",
            "",
            "",
            "def monkey_patch():",
            "    \"\"\"If the CONF.monkey_patch set as True,",
            "    this function patches a decorator",
            "    for all functions in specified modules.",
            "    You can set decorators for each modules",
            "    using CONF.monkey_patch_modules.",
            "    The format is \"Module path:Decorator function\".",
            "    Example:",
            "      'nova.api.ec2.cloud:nova.notifications.notify_decorator'",
            "",
            "    Parameters of the decorator is as follows.",
            "    (See nova.notifications.notify_decorator)",
            "",
            "    name - name of the function",
            "    function - object of the function",
            "    \"\"\"",
            "    # If CONF.monkey_patch is not True, this function do nothing.",
            "    if not CONF.monkey_patch:",
            "        return",
            "    # Get list of modules and decorators",
            "    for module_and_decorator in CONF.monkey_patch_modules:",
            "        module, decorator_name = module_and_decorator.split(':')",
            "        # import decorator function",
            "        decorator = importutils.import_class(decorator_name)",
            "        __import__(module)",
            "        # Retrieve module information using pyclbr",
            "        module_data = pyclbr.readmodule_ex(module)",
            "        for key in module_data.keys():",
            "            # set the decorator for the class methods",
            "            if isinstance(module_data[key], pyclbr.Class):",
            "                clz = importutils.import_class(\"%s.%s\" % (module, key))",
            "                for method, func in inspect.getmembers(clz, inspect.ismethod):",
            "                    setattr(clz, method,",
            "                        decorator(\"%s.%s.%s\" % (module, key, method), func))",
            "            # set the decorator for the function",
            "            if isinstance(module_data[key], pyclbr.Function):",
            "                func = importutils.import_class(\"%s.%s\" % (module, key))",
            "                setattr(sys.modules[module], key,",
            "                    decorator(\"%s.%s\" % (module, key), func))",
            "",
            "",
            "def convert_to_list_dict(lst, label):",
            "    \"\"\"Convert a value or list into a list of dicts.\"\"\"",
            "    if not lst:",
            "        return None",
            "    if not isinstance(lst, list):",
            "        lst = [lst]",
            "    return [{label: x} for x in lst]",
            "",
            "",
            "def make_dev_path(dev, partition=None, base='/dev'):",
            "    \"\"\"Return a path to a particular device.",
            "",
            "    >>> make_dev_path('xvdc')",
            "    /dev/xvdc",
            "",
            "    >>> make_dev_path('xvdc', 1)",
            "    /dev/xvdc1",
            "    \"\"\"",
            "    path = os.path.join(base, dev)",
            "    if partition:",
            "        path += str(partition)",
            "    return path",
            "",
            "",
            "def sanitize_hostname(hostname):",
            "    \"\"\"Return a hostname which conforms to RFC-952 and RFC-1123 specs.\"\"\"",
            "    if isinstance(hostname, unicode):",
            "        hostname = hostname.encode('latin-1', 'ignore')",
            "",
            "    hostname = re.sub('[ _]', '-', hostname)",
            "    hostname = re.sub('[^\\w.-]+', '', hostname)",
            "    hostname = hostname.lower()",
            "    hostname = hostname.strip('.-')",
            "",
            "    return hostname",
            "",
            "",
            "def read_cached_file(filename, cache_info, reload_func=None):",
            "    \"\"\"Read from a file if it has been modified.",
            "",
            "    :param cache_info: dictionary to hold opaque cache.",
            "    :param reload_func: optional function to be called with data when",
            "                        file is reloaded due to a modification.",
            "",
            "    :returns: data from file",
            "",
            "    \"\"\"",
            "    mtime = os.path.getmtime(filename)",
            "    if not cache_info or mtime != cache_info.get('mtime'):",
            "        LOG.debug(_(\"Reloading cached file %s\") % filename)",
            "        with open(filename) as fap:",
            "            cache_info['data'] = fap.read()",
            "        cache_info['mtime'] = mtime",
            "        if reload_func:",
            "            reload_func(cache_info['data'])",
            "    return cache_info['data']",
            "",
            "",
            "@contextlib.contextmanager",
            "def temporary_mutation(obj, **kwargs):",
            "    \"\"\"Temporarily set the attr on a particular object to a given value then",
            "    revert when finished.",
            "",
            "    One use of this is to temporarily set the read_deleted flag on a context",
            "    object:",
            "",
            "        with temporary_mutation(context, read_deleted=\"yes\"):",
            "            do_something_that_needed_deleted_objects()",
            "    \"\"\"",
            "    def is_dict_like(thing):",
            "        return hasattr(thing, 'has_key')",
            "",
            "    def get(thing, attr, default):",
            "        if is_dict_like(thing):",
            "            return thing.get(attr, default)",
            "        else:",
            "            return getattr(thing, attr, default)",
            "",
            "    def set_value(thing, attr, val):",
            "        if is_dict_like(thing):",
            "            thing[attr] = val",
            "        else:",
            "            setattr(thing, attr, val)",
            "",
            "    def delete(thing, attr):",
            "        if is_dict_like(thing):",
            "            del thing[attr]",
            "        else:",
            "            delattr(thing, attr)",
            "",
            "    NOT_PRESENT = object()",
            "",
            "    old_values = {}",
            "    for attr, new_value in kwargs.items():",
            "        old_values[attr] = get(obj, attr, NOT_PRESENT)",
            "        set_value(obj, attr, new_value)",
            "",
            "    try:",
            "        yield",
            "    finally:",
            "        for attr, old_value in old_values.items():",
            "            if old_value is NOT_PRESENT:",
            "                delete(obj, attr)",
            "            else:",
            "                set_value(obj, attr, old_value)",
            "",
            "",
            "def generate_mac_address():",
            "    \"\"\"Generate an Ethernet MAC address.\"\"\"",
            "    # NOTE(vish): We would prefer to use 0xfe here to ensure that linux",
            "    #             bridge mac addresses don't change, but it appears to",
            "    #             conflict with libvirt, so we use the next highest octet",
            "    #             that has the unicast and locally administered bits set",
            "    #             properly: 0xfa.",
            "    #             Discussion: https://bugs.launchpad.net/nova/+bug/921838",
            "    mac = [0xfa, 0x16, 0x3e,",
            "           random.randint(0x00, 0xff),",
            "           random.randint(0x00, 0xff),",
            "           random.randint(0x00, 0xff)]",
            "    return ':'.join(map(lambda x: \"%02x\" % x, mac))",
            "",
            "",
            "def read_file_as_root(file_path):",
            "    \"\"\"Secure helper to read file as root.\"\"\"",
            "    try:",
            "        out, _err = execute('cat', file_path, run_as_root=True)",
            "        return out",
            "    except processutils.ProcessExecutionError:",
            "        raise exception.FileNotFound(file_path=file_path)",
            "",
            "",
            "@contextlib.contextmanager",
            "def temporary_chown(path, owner_uid=None):",
            "    \"\"\"Temporarily chown a path.",
            "",
            "    :param owner_uid: UID of temporary owner (defaults to current user)",
            "    \"\"\"",
            "    if owner_uid is None:",
            "        owner_uid = os.getuid()",
            "",
            "    orig_uid = os.stat(path).st_uid",
            "",
            "    if orig_uid != owner_uid:",
            "        execute('chown', owner_uid, path, run_as_root=True)",
            "    try:",
            "        yield",
            "    finally:",
            "        if orig_uid != owner_uid:",
            "            execute('chown', orig_uid, path, run_as_root=True)",
            "",
            "",
            "def chown(path, owner_uid=None):",
            "    \"\"\"chown a path.",
            "",
            "    :param owner_uid: UID of owner (defaults to current user)",
            "    \"\"\"",
            "    if owner_uid is None:",
            "        owner_uid = os.getuid()",
            "",
            "    orig_uid = os.stat(path).st_uid",
            "",
            "    if orig_uid != owner_uid:",
            "        execute('chown', owner_uid, path, run_as_root=True)",
            "",
            "",
            "@contextlib.contextmanager",
            "def tempdir(**kwargs):",
            "    argdict = kwargs.copy()",
            "    if 'dir' not in argdict:",
            "        argdict['dir'] = CONF.tempdir",
            "    tmpdir = tempfile.mkdtemp(**argdict)",
            "    try:",
            "        yield tmpdir",
            "    finally:",
            "        try:",
            "            shutil.rmtree(tmpdir)",
            "        except OSError as e:",
            "            LOG.error(_('Could not remove tmpdir: %s'), str(e))",
            "",
            "",
            "def walk_class_hierarchy(clazz, encountered=None):",
            "    \"\"\"Walk class hierarchy, yielding most derived classes first.\"\"\"",
            "    if not encountered:",
            "        encountered = []",
            "    for subclass in clazz.__subclasses__():",
            "        if subclass not in encountered:",
            "            encountered.append(subclass)",
            "            # drill down to leaves first",
            "            for subsubclass in walk_class_hierarchy(subclass, encountered):",
            "                yield subsubclass",
            "            yield subclass",
            "",
            "",
            "class UndoManager(object):",
            "    \"\"\"Provides a mechanism to facilitate rolling back a series of actions",
            "    when an exception is raised.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self.undo_stack = []",
            "",
            "    def undo_with(self, undo_func):",
            "        self.undo_stack.append(undo_func)",
            "",
            "    def _rollback(self):",
            "        for undo_func in reversed(self.undo_stack):",
            "            undo_func()",
            "",
            "    def rollback_and_reraise(self, msg=None, **kwargs):",
            "        \"\"\"Rollback a series of actions then re-raise the exception.",
            "",
            "        .. note:: (sirp) This should only be called within an",
            "                  exception handler.",
            "        \"\"\"",
            "        with excutils.save_and_reraise_exception():",
            "            if msg:",
            "                LOG.exception(msg, **kwargs)",
            "",
            "            self._rollback()",
            "",
            "",
            "def mkfs(fs, path, label=None, run_as_root=False):",
            "    \"\"\"Format a file or block device",
            "",
            "    :param fs: Filesystem type (examples include 'swap', 'ext3', 'ext4'",
            "               'btrfs', etc.)",
            "    :param path: Path to file or block device to format",
            "    :param label: Volume label to use",
            "    \"\"\"",
            "    if fs == 'swap':",
            "        args = ['mkswap']",
            "    else:",
            "        args = ['mkfs', '-t', fs]",
            "    #add -F to force no interactive execute on non-block device.",
            "    if fs in ('ext3', 'ext4', 'ntfs'):",
            "        args.extend(['-F'])",
            "    if label:",
            "        if fs in ('msdos', 'vfat'):",
            "            label_opt = '-n'",
            "        else:",
            "            label_opt = '-L'",
            "        args.extend([label_opt, label])",
            "    args.append(path)",
            "    execute(*args, run_as_root=run_as_root)",
            "",
            "",
            "def last_bytes(file_like_object, num):",
            "    \"\"\"Return num bytes from the end of the file, and remaining byte count.",
            "",
            "    :param file_like_object: The file to read",
            "    :param num: The number of bytes to return",
            "",
            "    :returns (data, remaining)",
            "    \"\"\"",
            "",
            "    try:",
            "        file_like_object.seek(-num, os.SEEK_END)",
            "    except IOError as e:",
            "        if e.errno == 22:",
            "            file_like_object.seek(0, os.SEEK_SET)",
            "        else:",
            "            raise",
            "",
            "    remaining = file_like_object.tell()",
            "    return (file_like_object.read(), remaining)",
            "",
            "",
            "def metadata_to_dict(metadata):",
            "    result = {}",
            "    for item in metadata:",
            "        if not item.get('deleted'):",
            "            result[item['key']] = item['value']",
            "    return result",
            "",
            "",
            "def dict_to_metadata(metadata):",
            "    result = []",
            "    for key, value in metadata.iteritems():",
            "        result.append(dict(key=key, value=value))",
            "    return result",
            "",
            "",
            "def instance_meta(instance):",
            "    if isinstance(instance['metadata'], dict):",
            "        return instance['metadata']",
            "    else:",
            "        return metadata_to_dict(instance['metadata'])",
            "",
            "",
            "def instance_sys_meta(instance):",
            "    if not instance.get('system_metadata'):",
            "        return {}",
            "    if isinstance(instance['system_metadata'], dict):",
            "        return instance['system_metadata']",
            "    else:",
            "        return metadata_to_dict(instance['system_metadata'])",
            "",
            "",
            "def get_wrapped_function(function):",
            "    \"\"\"Get the method at the bottom of a stack of decorators.\"\"\"",
            "    if not hasattr(function, 'func_closure') or not function.func_closure:",
            "        return function",
            "",
            "    def _get_wrapped_function(function):",
            "        if not hasattr(function, 'func_closure') or not function.func_closure:",
            "            return None",
            "",
            "        for closure in function.func_closure:",
            "            func = closure.cell_contents",
            "",
            "            deeper_func = _get_wrapped_function(func)",
            "            if deeper_func:",
            "                return deeper_func",
            "            elif hasattr(closure.cell_contents, '__call__'):",
            "                return closure.cell_contents",
            "",
            "    return _get_wrapped_function(function)",
            "",
            "",
            "def expects_func_args(*args):",
            "    def _decorator_checker(dec):",
            "        @functools.wraps(dec)",
            "        def _decorator(f):",
            "            base_f = get_wrapped_function(f)",
            "            arg_names, a, kw, _default = inspect.getargspec(base_f)",
            "            if a or kw or set(args) <= set(arg_names):",
            "                # NOTE (ndipanov): We can't really tell if correct stuff will",
            "                # be passed if it's a function with *args or **kwargs so",
            "                # we still carry on and hope for the best",
            "                return dec(f)",
            "            else:",
            "                raise TypeError(\"Decorated function %(f_name)s does not \"",
            "                                \"have the arguments expected by the \"",
            "                                \"decorator %(d_name)s\" %",
            "                                {'f_name': base_f.__name__,",
            "                                 'd_name': dec.__name__})",
            "        return _decorator",
            "    return _decorator_checker",
            "",
            "",
            "class ExceptionHelper(object):",
            "    \"\"\"Class to wrap another and translate the ClientExceptions raised by its",
            "    function calls to the actual ones.",
            "    \"\"\"",
            "",
            "    def __init__(self, target):",
            "        self._target = target",
            "",
            "    def __getattr__(self, name):",
            "        func = getattr(self._target, name)",
            "",
            "        @functools.wraps(func)",
            "        def wrapper(*args, **kwargs):",
            "            try:",
            "                return func(*args, **kwargs)",
            "            except messaging.ExpectedException as e:",
            "                raise (e.exc_info[1], None, e.exc_info[2])",
            "        return wrapper",
            "",
            "",
            "def check_string_length(value, name, min_length=0, max_length=None):",
            "    \"\"\"Check the length of specified string",
            "    :param value: the value of the string",
            "    :param name: the name of the string",
            "    :param min_length: the min_length of the string",
            "    :param max_length: the max_length of the string",
            "    \"\"\"",
            "    if not isinstance(value, six.string_types):",
            "        msg = _(\"%s is not a string or unicode\") % name",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "    if len(value) < min_length:",
            "        msg = _(\"%(name)s has a minimum character requirement of \"",
            "                \"%(min_length)s.\") % {'name': name, 'min_length': min_length}",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "    if max_length and len(value) > max_length:",
            "        msg = _(\"%(name)s has more than %(max_length)s \"",
            "                \"characters.\") % {'name': name, 'max_length': max_length}",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "",
            "def validate_integer(value, name, min_value=None, max_value=None):",
            "    \"\"\"Make sure that value is a valid integer, potentially within range.\"\"\"",
            "    try:",
            "        value = int(str(value))",
            "    except (ValueError, UnicodeEncodeError):",
            "        msg = _('%(value_name)s must be an integer')",
            "        raise exception.InvalidInput(reason=(",
            "            msg % {'value_name': name}))",
            "",
            "    if min_value is not None:",
            "        if value < min_value:",
            "            msg = _('%(value_name)s must be >= %(min_value)d')",
            "            raise exception.InvalidInput(",
            "                reason=(msg % {'value_name': name,",
            "                               'min_value': min_value}))",
            "    if max_value is not None:",
            "        if value > max_value:",
            "            msg = _('%(value_name)s must be <= %(max_value)d')",
            "            raise exception.InvalidInput(",
            "                reason=(",
            "                    msg % {'value_name': name,",
            "                           'max_value': max_value})",
            "            )",
            "    return value",
            "",
            "",
            "def spawn_n(func, *args, **kwargs):",
            "    \"\"\"Passthrough method for eventlet.spawn_n.",
            "",
            "    This utility exists so that it can be stubbed for testing without",
            "    interfering with the service spawns.",
            "    \"\"\"",
            "    eventlet.spawn_n(func, *args, **kwargs)",
            "",
            "",
            "def is_none_string(val):",
            "    \"\"\"Check if a string represents a None value.",
            "    \"\"\"",
            "    if not isinstance(val, six.string_types):",
            "        return False",
            "",
            "    return val.lower() == 'none'",
            "",
            "",
            "def convert_version_to_int(version):",
            "    try:",
            "        if isinstance(version, six.string_types):",
            "            version = convert_version_to_tuple(version)",
            "        if isinstance(version, tuple):",
            "            return reduce(lambda x, y: (x * 1000) + y, version)",
            "    except Exception:",
            "        raise exception.NovaException(message=\"Hypervisor version invalid.\")",
            "",
            "",
            "def convert_version_to_str(version_int):",
            "    version_numbers = []",
            "    factor = 1000",
            "    while version_int != 0:",
            "        version_number = version_int - (version_int // factor * factor)",
            "        version_numbers.insert(0, str(version_number))",
            "        version_int = version_int / factor",
            "",
            "    return reduce(lambda x, y: \"%s.%s\" % (x, y), version_numbers)",
            "",
            "",
            "def convert_version_to_tuple(version_str):",
            "    return tuple(int(part) for part in version_str.split('.'))",
            "",
            "",
            "def is_neutron():",
            "    global _IS_NEUTRON",
            "",
            "    if _IS_NEUTRON is not None:",
            "        return _IS_NEUTRON",
            "",
            "    try:",
            "        # compatibility with Folsom/Grizzly configs",
            "        cls_name = CONF.network_api_class",
            "        if cls_name == 'nova.network.quantumv2.api.API':",
            "            cls_name = 'nova.network.neutronv2.api.API'",
            "",
            "        from nova.network.neutronv2 import api as neutron_api",
            "        _IS_NEUTRON = issubclass(importutils.import_class(cls_name),",
            "                                 neutron_api.API)",
            "    except ImportError:",
            "        _IS_NEUTRON = False",
            "",
            "    return _IS_NEUTRON",
            "",
            "",
            "def reset_is_neutron():",
            "    global _IS_NEUTRON",
            "    _IS_NEUTRON = None",
            "",
            "",
            "def is_auto_disk_config_disabled(auto_disk_config_raw):",
            "    auto_disk_config_disabled = False",
            "    if auto_disk_config_raw is not None:",
            "        adc_lowered = auto_disk_config_raw.strip().lower()",
            "        if adc_lowered == \"disabled\":",
            "            auto_disk_config_disabled = True",
            "    return auto_disk_config_disabled",
            "",
            "",
            "def get_auto_disk_config_from_instance(instance=None, sys_meta=None):",
            "    if sys_meta is None:",
            "        sys_meta = instance_sys_meta(instance)",
            "    return sys_meta.get(\"image_auto_disk_config\")",
            "",
            "",
            "def get_auto_disk_config_from_image_props(image_properties):",
            "    return image_properties.get(\"auto_disk_config\")",
            "",
            "",
            "def get_system_metadata_from_image(image_meta, flavor=None):",
            "    system_meta = {}",
            "    prefix_format = SM_IMAGE_PROP_PREFIX + '%s'",
            "",
            "    for key, value in image_meta.get('properties', {}).iteritems():",
            "        new_value = unicode(value)[:255]",
            "        system_meta[prefix_format % key] = new_value",
            "",
            "    for key in SM_INHERITABLE_KEYS:",
            "        value = image_meta.get(key)",
            "",
            "        if key == 'min_disk' and flavor:",
            "            if image_meta.get('disk_format') == 'vhd':",
            "                value = flavor['root_gb']",
            "            else:",
            "                value = max(value, flavor['root_gb'])",
            "",
            "        if value is None:",
            "            continue",
            "",
            "        system_meta[prefix_format % key] = value",
            "",
            "    return system_meta",
            "",
            "",
            "def get_image_from_system_metadata(system_meta):",
            "    image_meta = {}",
            "    properties = {}",
            "",
            "    if not isinstance(system_meta, dict):",
            "        system_meta = metadata_to_dict(system_meta)",
            "",
            "    for key, value in system_meta.iteritems():",
            "        if value is None:",
            "            continue",
            "",
            "        # NOTE(xqueralt): Not sure this has to inherit all the properties or",
            "        # just the ones we need. Leaving it for now to keep the old behaviour.",
            "        if key.startswith(SM_IMAGE_PROP_PREFIX):",
            "            key = key[len(SM_IMAGE_PROP_PREFIX):]",
            "",
            "        if key in SM_INHERITABLE_KEYS:",
            "            image_meta[key] = value",
            "        else:",
            "            # Skip properties that are non-inheritable",
            "            if key in CONF.non_inheritable_image_properties:",
            "                continue",
            "            properties[key] = value",
            "",
            "    if properties:",
            "        image_meta['properties'] = properties",
            "",
            "    return image_meta",
            "",
            "",
            "def get_hash_str(base_str):",
            "    \"\"\"returns string that represents hash of base_str (in hex format).\"\"\"",
            "    return hashlib.md5(base_str).hexdigest()",
            "",
            "",
            "def cpu_count():",
            "    try:",
            "        return multiprocessing.cpu_count()",
            "    except NotImplementedError:",
            "        return 1"
        ],
        "afterPatchFile": [
            "# Copyright 2010 United States Government as represented by the",
            "# Administrator of the National Aeronautics and Space Administration.",
            "# Copyright 2011 Justin Santa Barbara",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"Utilities and helper functions.\"\"\"",
            "",
            "import contextlib",
            "import datetime",
            "import functools",
            "import hashlib",
            "import inspect",
            "import multiprocessing",
            "import os",
            "import pyclbr",
            "import random",
            "import re",
            "import shutil",
            "import socket",
            "import struct",
            "import sys",
            "import tempfile",
            "from xml.sax import saxutils",
            "",
            "import eventlet",
            "import netaddr",
            "from oslo.config import cfg",
            "from oslo import messaging",
            "import six",
            "",
            "from nova import exception",
            "from nova.openstack.common import excutils",
            "from nova.openstack.common import gettextutils",
            "from nova.openstack.common.gettextutils import _",
            "from nova.openstack.common import importutils",
            "from nova.openstack.common import lockutils",
            "from nova.openstack.common import log as logging",
            "from nova.openstack.common import processutils",
            "from nova.openstack.common import timeutils",
            "",
            "notify_decorator = 'nova.notifications.notify_decorator'",
            "",
            "monkey_patch_opts = [",
            "    cfg.BoolOpt('monkey_patch',",
            "                default=False,",
            "                help='Whether to log monkey patching'),",
            "    cfg.ListOpt('monkey_patch_modules',",
            "                default=[",
            "                  'nova.api.ec2.cloud:%s' % (notify_decorator),",
            "                  'nova.compute.api:%s' % (notify_decorator)",
            "                  ],",
            "                help='List of modules/decorators to monkey patch'),",
            "]",
            "utils_opts = [",
            "    cfg.IntOpt('password_length',",
            "               default=12,",
            "               help='Length of generated instance admin passwords'),",
            "    cfg.StrOpt('instance_usage_audit_period',",
            "               default='month',",
            "               help='Time period to generate instance usages for.  '",
            "                    'Time period must be hour, day, month or year'),",
            "    cfg.StrOpt('rootwrap_config',",
            "               default=\"/etc/nova/rootwrap.conf\",",
            "               help='Path to the rootwrap configuration file to use for '",
            "                    'running commands as root'),",
            "    cfg.StrOpt('tempdir',",
            "               help='Explicitly specify the temporary working directory'),",
            "]",
            "CONF = cfg.CONF",
            "CONF.register_opts(monkey_patch_opts)",
            "CONF.register_opts(utils_opts)",
            "CONF.import_opt('network_api_class', 'nova.network')",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "# used in limits",
            "TIME_UNITS = {",
            "    'SECOND': 1,",
            "    'MINUTE': 60,",
            "    'HOUR': 3600,",
            "    'DAY': 84400",
            "}",
            "",
            "",
            "_IS_NEUTRON = None",
            "",
            "synchronized = lockutils.synchronized_with_prefix('nova-')",
            "",
            "SM_IMAGE_PROP_PREFIX = \"image_\"",
            "SM_INHERITABLE_KEYS = (",
            "    'min_ram', 'min_disk', 'disk_format', 'container_format',",
            ")",
            "",
            "",
            "def vpn_ping(address, port, timeout=0.05, session_id=None):",
            "    \"\"\"Sends a vpn negotiation packet and returns the server session.",
            "",
            "    Returns False on a failure. Basic packet structure is below.",
            "",
            "    Client packet (14 bytes)::",
            "",
            "         0 1      8 9  13",
            "        +-+--------+-----+",
            "        |x| cli_id |?????|",
            "        +-+--------+-----+",
            "        x = packet identifier 0x38",
            "        cli_id = 64 bit identifier",
            "        ? = unknown, probably flags/padding",
            "",
            "    Server packet (26 bytes)::",
            "",
            "         0 1      8 9  13 14    21 2225",
            "        +-+--------+-----+--------+----+",
            "        |x| srv_id |?????| cli_id |????|",
            "        +-+--------+-----+--------+----+",
            "        x = packet identifier 0x40",
            "        cli_id = 64 bit identifier",
            "        ? = unknown, probably flags/padding",
            "        bit 9 was 1 and the rest were 0 in testing",
            "",
            "    \"\"\"",
            "    if session_id is None:",
            "        session_id = random.randint(0, 0xffffffffffffffff)",
            "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)",
            "    data = struct.pack('!BQxxxxx', 0x38, session_id)",
            "    sock.sendto(data, (address, port))",
            "    sock.settimeout(timeout)",
            "    try:",
            "        received = sock.recv(2048)",
            "    except socket.timeout:",
            "        return False",
            "    finally:",
            "        sock.close()",
            "    fmt = '!BQxxxxxQxxxx'",
            "    if len(received) != struct.calcsize(fmt):",
            "        LOG.warn(_('Expected to receive %(exp)s bytes, but actually %(act)s') %",
            "                 dict(exp=struct.calcsize(fmt), act=len(received)))",
            "        return False",
            "    (identifier, server_sess, client_sess) = struct.unpack(fmt, received)",
            "    if identifier == 0x40 and client_sess == session_id:",
            "        return server_sess",
            "",
            "",
            "def _get_root_helper():",
            "    return 'sudo nova-rootwrap %s' % CONF.rootwrap_config",
            "",
            "",
            "def execute(*cmd, **kwargs):",
            "    \"\"\"Convenience wrapper around oslo's execute() method.\"\"\"",
            "    if 'run_as_root' in kwargs and not 'root_helper' in kwargs:",
            "        kwargs['root_helper'] = _get_root_helper()",
            "    return processutils.execute(*cmd, **kwargs)",
            "",
            "",
            "def trycmd(*args, **kwargs):",
            "    \"\"\"Convenience wrapper around oslo's trycmd() method.\"\"\"",
            "    if 'run_as_root' in kwargs and not 'root_helper' in kwargs:",
            "        kwargs['root_helper'] = _get_root_helper()",
            "    return processutils.trycmd(*args, **kwargs)",
            "",
            "",
            "def novadir():",
            "    import nova",
            "    return os.path.abspath(nova.__file__).split('nova/__init__.py')[0]",
            "",
            "",
            "def generate_uid(topic, size=8):",
            "    characters = '01234567890abcdefghijklmnopqrstuvwxyz'",
            "    choices = [random.choice(characters) for _x in xrange(size)]",
            "    return '%s-%s' % (topic, ''.join(choices))",
            "",
            "",
            "# Default symbols to use for passwords. Avoids visually confusing characters.",
            "# ~6 bits per symbol",
            "DEFAULT_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0,1",
            "                            'ABCDEFGHJKLMNPQRSTUVWXYZ',   # Removed: I, O",
            "                            'abcdefghijkmnopqrstuvwxyz')  # Removed: l",
            "",
            "",
            "# ~5 bits per symbol",
            "EASIER_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0, 1",
            "                           'ABCDEFGHJKLMNPQRSTUVWXYZ')  # Removed: I, O",
            "",
            "",
            "def last_completed_audit_period(unit=None, before=None):",
            "    \"\"\"This method gives you the most recently *completed* audit period.",
            "",
            "    arguments:",
            "            units: string, one of 'hour', 'day', 'month', 'year'",
            "                    Periods normally begin at the beginning (UTC) of the",
            "                    period unit (So a 'day' period begins at midnight UTC,",
            "                    a 'month' unit on the 1st, a 'year' on Jan, 1)",
            "                    unit string may be appended with an optional offset",
            "                    like so:  'day@18'  This will begin the period at 18:00",
            "                    UTC.  'month@15' starts a monthly period on the 15th,",
            "                    and year@3 begins a yearly one on March 1st.",
            "            before: Give the audit period most recently completed before",
            "                    <timestamp>. Defaults to now.",
            "",
            "",
            "    returns:  2 tuple of datetimes (begin, end)",
            "              The begin timestamp of this audit period is the same as the",
            "              end of the previous.",
            "    \"\"\"",
            "    if not unit:",
            "        unit = CONF.instance_usage_audit_period",
            "",
            "    offset = 0",
            "    if '@' in unit:",
            "        unit, offset = unit.split(\"@\", 1)",
            "        offset = int(offset)",
            "",
            "    if before is not None:",
            "        rightnow = before",
            "    else:",
            "        rightnow = timeutils.utcnow()",
            "    if unit not in ('month', 'day', 'year', 'hour'):",
            "        raise ValueError('Time period must be hour, day, month or year')",
            "    if unit == 'month':",
            "        if offset == 0:",
            "            offset = 1",
            "        end = datetime.datetime(day=offset,",
            "                                month=rightnow.month,",
            "                                year=rightnow.year)",
            "        if end >= rightnow:",
            "            year = rightnow.year",
            "            if 1 >= rightnow.month:",
            "                year -= 1",
            "                month = 12 + (rightnow.month - 1)",
            "            else:",
            "                month = rightnow.month - 1",
            "            end = datetime.datetime(day=offset,",
            "                                    month=month,",
            "                                    year=year)",
            "        year = end.year",
            "        if 1 >= end.month:",
            "            year -= 1",
            "            month = 12 + (end.month - 1)",
            "        else:",
            "            month = end.month - 1",
            "        begin = datetime.datetime(day=offset, month=month, year=year)",
            "",
            "    elif unit == 'year':",
            "        if offset == 0:",
            "            offset = 1",
            "        end = datetime.datetime(day=1, month=offset, year=rightnow.year)",
            "        if end >= rightnow:",
            "            end = datetime.datetime(day=1,",
            "                                    month=offset,",
            "                                    year=rightnow.year - 1)",
            "            begin = datetime.datetime(day=1,",
            "                                      month=offset,",
            "                                      year=rightnow.year - 2)",
            "        else:",
            "            begin = datetime.datetime(day=1,",
            "                                      month=offset,",
            "                                      year=rightnow.year - 1)",
            "",
            "    elif unit == 'day':",
            "        end = datetime.datetime(hour=offset,",
            "                               day=rightnow.day,",
            "                               month=rightnow.month,",
            "                               year=rightnow.year)",
            "        if end >= rightnow:",
            "            end = end - datetime.timedelta(days=1)",
            "        begin = end - datetime.timedelta(days=1)",
            "",
            "    elif unit == 'hour':",
            "        end = rightnow.replace(minute=offset, second=0, microsecond=0)",
            "        if end >= rightnow:",
            "            end = end - datetime.timedelta(hours=1)",
            "        begin = end - datetime.timedelta(hours=1)",
            "",
            "    return (begin, end)",
            "",
            "",
            "def generate_password(length=None, symbolgroups=DEFAULT_PASSWORD_SYMBOLS):",
            "    \"\"\"Generate a random password from the supplied symbol groups.",
            "",
            "    At least one symbol from each group will be included. Unpredictable",
            "    results if length is less than the number of symbol groups.",
            "",
            "    Believed to be reasonably secure (with a reasonable password length!)",
            "",
            "    \"\"\"",
            "    if length is None:",
            "        length = CONF.password_length",
            "",
            "    r = random.SystemRandom()",
            "",
            "    # NOTE(jerdfelt): Some password policies require at least one character",
            "    # from each group of symbols, so start off with one random character",
            "    # from each symbol group",
            "    password = [r.choice(s) for s in symbolgroups]",
            "    # If length < len(symbolgroups), the leading characters will only",
            "    # be from the first length groups. Try our best to not be predictable",
            "    # by shuffling and then truncating.",
            "    r.shuffle(password)",
            "    password = password[:length]",
            "    length -= len(password)",
            "",
            "    # then fill with random characters from all symbol groups",
            "    symbols = ''.join(symbolgroups)",
            "    password.extend([r.choice(symbols) for _i in xrange(length)])",
            "",
            "    # finally shuffle to ensure first x characters aren't from a",
            "    # predictable group",
            "    r.shuffle(password)",
            "",
            "    return ''.join(password)",
            "",
            "",
            "def get_my_ipv4_address():",
            "    \"\"\"Run ip route/addr commands to figure out the best ipv4",
            "    \"\"\"",
            "    LOCALHOST = '127.0.0.1'",
            "    try:",
            "        out = execute('ip', '-f', 'inet', '-o', 'route', 'show')",
            "",
            "        # Find the default route",
            "        regex_default = ('default\\s*via\\s*'",
            "                         '(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'",
            "                         '\\s*dev\\s*(\\w*)\\s*')",
            "        default_routes = re.findall(regex_default, out[0])",
            "        if not default_routes:",
            "            return LOCALHOST",
            "        gateway, iface = default_routes[0]",
            "",
            "        # Find the right subnet for the gateway/interface for",
            "        # the default route",
            "        route = ('(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\/(\\d{1,2})'",
            "              '\\s*dev\\s*(\\w*)\\s*')",
            "        for match in re.finditer(route, out[0]):",
            "            subnet = netaddr.IPNetwork(match.group(1) + \"/\" + match.group(2))",
            "            if (match.group(3) == iface and",
            "                    netaddr.IPAddress(gateway) in subnet):",
            "                try:",
            "                    return _get_ipv4_address_for_interface(iface)",
            "                except exception.NovaException:",
            "                    pass",
            "    except Exception as ex:",
            "        LOG.error(_(\"Couldn't get IPv4 : %(ex)s\") % {'ex': ex})",
            "    return LOCALHOST",
            "",
            "",
            "def _get_ipv4_address_for_interface(iface):",
            "    \"\"\"Run ip addr show for an interface and grab its ipv4 addresses",
            "    \"\"\"",
            "    try:",
            "        out = execute('ip', '-f', 'inet', '-o', 'addr', 'show', iface)",
            "        regexp_address = re.compile('inet\\s*'",
            "                                    '(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})')",
            "        address = [m.group(1) for m in regexp_address.finditer(out[0])",
            "                   if m.group(1) != '127.0.0.1']",
            "        if address:",
            "            return address[0]",
            "        else:",
            "            msg = _('IPv4 address is not found.: %s') % out[0]",
            "            raise exception.NovaException(msg)",
            "    except Exception as ex:",
            "        msg = _(\"Couldn't get IPv4 of %(interface)s\"",
            "                \" : %(ex)s\") % {'interface': iface, 'ex': ex}",
            "        LOG.error(msg)",
            "        raise exception.NovaException(msg)",
            "",
            "",
            "def get_my_linklocal(interface):",
            "    try:",
            "        if_str = execute('ip', '-f', 'inet6', '-o', 'addr', 'show', interface)",
            "        condition = '\\s+inet6\\s+([0-9a-f:]+)/\\d+\\s+scope\\s+link'",
            "        links = [re.search(condition, x) for x in if_str[0].split('\\n')]",
            "        address = [w.group(1) for w in links if w is not None]",
            "        if address[0] is not None:",
            "            return address[0]",
            "        else:",
            "            msg = _('Link Local address is not found.:%s') % if_str",
            "            raise exception.NovaException(msg)",
            "    except Exception as ex:",
            "        msg = _(\"Couldn't get Link Local IP of %(interface)s\"",
            "                \" :%(ex)s\") % {'interface': interface, 'ex': ex}",
            "        raise exception.NovaException(msg)",
            "",
            "",
            "class LazyPluggable(object):",
            "    \"\"\"A pluggable backend loaded lazily based on some value.\"\"\"",
            "",
            "    def __init__(self, pivot, config_group=None, **backends):",
            "        self.__backends = backends",
            "        self.__pivot = pivot",
            "        self.__backend = None",
            "        self.__config_group = config_group",
            "",
            "    def __get_backend(self):",
            "        if not self.__backend:",
            "            if self.__config_group is None:",
            "                backend_name = CONF[self.__pivot]",
            "            else:",
            "                backend_name = CONF[self.__config_group][self.__pivot]",
            "            if backend_name not in self.__backends:",
            "                msg = _('Invalid backend: %s') % backend_name",
            "                raise exception.NovaException(msg)",
            "",
            "            backend = self.__backends[backend_name]",
            "            if isinstance(backend, tuple):",
            "                name = backend[0]",
            "                fromlist = backend[1]",
            "            else:",
            "                name = backend",
            "                fromlist = backend",
            "",
            "            self.__backend = __import__(name, None, None, fromlist)",
            "        return self.__backend",
            "",
            "    def __getattr__(self, key):",
            "        backend = self.__get_backend()",
            "        return getattr(backend, key)",
            "",
            "",
            "def xhtml_escape(value):",
            "    \"\"\"Escapes a string so it is valid within XML or XHTML.",
            "",
            "    \"\"\"",
            "    return saxutils.escape(value, {'\"': '&quot;', \"'\": '&apos;'})",
            "",
            "",
            "def utf8(value):",
            "    \"\"\"Try to turn a string into utf-8 if possible.",
            "",
            "    Code is directly from the utf8 function in",
            "    http://github.com/facebook/tornado/blob/master/tornado/escape.py",
            "",
            "    \"\"\"",
            "    if isinstance(value, unicode):",
            "        return value.encode('utf-8')",
            "    elif isinstance(value, gettextutils.Message):",
            "        return unicode(value).encode('utf-8')",
            "    assert isinstance(value, str)",
            "    return value",
            "",
            "",
            "def check_isinstance(obj, cls):",
            "    \"\"\"Checks that obj is of type cls, and lets PyLint infer types.\"\"\"",
            "    if isinstance(obj, cls):",
            "        return obj",
            "    raise Exception(_('Expected object of type: %s') % (str(cls)))",
            "",
            "",
            "def parse_server_string(server_str):",
            "    \"\"\"Parses the given server_string and returns a list of host and port.",
            "    If it's not a combination of host part and port, the port element",
            "    is a null string. If the input is invalid expression, return a null",
            "    list.",
            "    \"\"\"",
            "    try:",
            "        # First of all, exclude pure IPv6 address (w/o port).",
            "        if netaddr.valid_ipv6(server_str):",
            "            return (server_str, '')",
            "",
            "        # Next, check if this is IPv6 address with a port number combination.",
            "        if server_str.find(\"]:\") != -1:",
            "            (address, port) = server_str.replace('[', '', 1).split(']:')",
            "            return (address, port)",
            "",
            "        # Third, check if this is a combination of an address and a port",
            "        if server_str.find(':') == -1:",
            "            return (server_str, '')",
            "",
            "        # This must be a combination of an address and a port",
            "        (address, port) = server_str.split(':')",
            "        return (address, port)",
            "",
            "    except Exception:",
            "        LOG.error(_('Invalid server_string: %s'), server_str)",
            "        return ('', '')",
            "",
            "",
            "def is_int_like(val):",
            "    \"\"\"Check if a value looks like an int.\"\"\"",
            "    try:",
            "        return str(int(val)) == str(val)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ipv4(address):",
            "    \"\"\"Verify that address represents a valid IPv4 address.\"\"\"",
            "    try:",
            "        return netaddr.valid_ipv4(address)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ipv6(address):",
            "    try:",
            "        return netaddr.valid_ipv6(address)",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_valid_ip_address(address):",
            "    return is_valid_ipv4(address) or is_valid_ipv6(address)",
            "",
            "",
            "def is_valid_ipv6_cidr(address):",
            "    try:",
            "        str(netaddr.IPNetwork(address, version=6).cidr)",
            "        return True",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def get_shortened_ipv6(address):",
            "    addr = netaddr.IPAddress(address, version=6)",
            "    return str(addr.ipv6())",
            "",
            "",
            "def get_shortened_ipv6_cidr(address):",
            "    net = netaddr.IPNetwork(address, version=6)",
            "    return str(net.cidr)",
            "",
            "",
            "def is_valid_cidr(address):",
            "    \"\"\"Check if address is valid",
            "",
            "    The provided address can be a IPv6 or a IPv4",
            "    CIDR address.",
            "    \"\"\"",
            "    try:",
            "        # Validate the correct CIDR Address",
            "        netaddr.IPNetwork(address)",
            "    except netaddr.core.AddrFormatError:",
            "        return False",
            "    except UnboundLocalError:",
            "        # NOTE(MotoKen): work around bug in netaddr 0.7.5 (see detail in",
            "        # https://github.com/drkjam/netaddr/issues/2)",
            "        return False",
            "",
            "    # Prior validation partially verify /xx part",
            "    # Verify it here",
            "    ip_segment = address.split('/')",
            "",
            "    if (len(ip_segment) <= 1 or",
            "            ip_segment[1] == ''):",
            "        return False",
            "",
            "    return True",
            "",
            "",
            "def get_ip_version(network):",
            "    \"\"\"Returns the IP version of a network (IPv4 or IPv6).",
            "",
            "    Raises AddrFormatError if invalid network.",
            "    \"\"\"",
            "    if netaddr.IPNetwork(network).version == 6:",
            "        return \"IPv6\"",
            "    elif netaddr.IPNetwork(network).version == 4:",
            "        return \"IPv4\"",
            "",
            "",
            "def monkey_patch():",
            "    \"\"\"If the CONF.monkey_patch set as True,",
            "    this function patches a decorator",
            "    for all functions in specified modules.",
            "    You can set decorators for each modules",
            "    using CONF.monkey_patch_modules.",
            "    The format is \"Module path:Decorator function\".",
            "    Example:",
            "      'nova.api.ec2.cloud:nova.notifications.notify_decorator'",
            "",
            "    Parameters of the decorator is as follows.",
            "    (See nova.notifications.notify_decorator)",
            "",
            "    name - name of the function",
            "    function - object of the function",
            "    \"\"\"",
            "    # If CONF.monkey_patch is not True, this function do nothing.",
            "    if not CONF.monkey_patch:",
            "        return",
            "    # Get list of modules and decorators",
            "    for module_and_decorator in CONF.monkey_patch_modules:",
            "        module, decorator_name = module_and_decorator.split(':')",
            "        # import decorator function",
            "        decorator = importutils.import_class(decorator_name)",
            "        __import__(module)",
            "        # Retrieve module information using pyclbr",
            "        module_data = pyclbr.readmodule_ex(module)",
            "        for key in module_data.keys():",
            "            # set the decorator for the class methods",
            "            if isinstance(module_data[key], pyclbr.Class):",
            "                clz = importutils.import_class(\"%s.%s\" % (module, key))",
            "                for method, func in inspect.getmembers(clz, inspect.ismethod):",
            "                    setattr(clz, method,",
            "                        decorator(\"%s.%s.%s\" % (module, key, method), func))",
            "            # set the decorator for the function",
            "            if isinstance(module_data[key], pyclbr.Function):",
            "                func = importutils.import_class(\"%s.%s\" % (module, key))",
            "                setattr(sys.modules[module], key,",
            "                    decorator(\"%s.%s\" % (module, key), func))",
            "",
            "",
            "def convert_to_list_dict(lst, label):",
            "    \"\"\"Convert a value or list into a list of dicts.\"\"\"",
            "    if not lst:",
            "        return None",
            "    if not isinstance(lst, list):",
            "        lst = [lst]",
            "    return [{label: x} for x in lst]",
            "",
            "",
            "def make_dev_path(dev, partition=None, base='/dev'):",
            "    \"\"\"Return a path to a particular device.",
            "",
            "    >>> make_dev_path('xvdc')",
            "    /dev/xvdc",
            "",
            "    >>> make_dev_path('xvdc', 1)",
            "    /dev/xvdc1",
            "    \"\"\"",
            "    path = os.path.join(base, dev)",
            "    if partition:",
            "        path += str(partition)",
            "    return path",
            "",
            "",
            "def sanitize_hostname(hostname):",
            "    \"\"\"Return a hostname which conforms to RFC-952 and RFC-1123 specs.\"\"\"",
            "    if isinstance(hostname, unicode):",
            "        hostname = hostname.encode('latin-1', 'ignore')",
            "",
            "    hostname = re.sub('[ _]', '-', hostname)",
            "    hostname = re.sub('[^\\w.-]+', '', hostname)",
            "    hostname = hostname.lower()",
            "    hostname = hostname.strip('.-')",
            "",
            "    return hostname",
            "",
            "",
            "def read_cached_file(filename, cache_info, reload_func=None):",
            "    \"\"\"Read from a file if it has been modified.",
            "",
            "    :param cache_info: dictionary to hold opaque cache.",
            "    :param reload_func: optional function to be called with data when",
            "                        file is reloaded due to a modification.",
            "",
            "    :returns: data from file",
            "",
            "    \"\"\"",
            "    mtime = os.path.getmtime(filename)",
            "    if not cache_info or mtime != cache_info.get('mtime'):",
            "        LOG.debug(_(\"Reloading cached file %s\") % filename)",
            "        with open(filename) as fap:",
            "            cache_info['data'] = fap.read()",
            "        cache_info['mtime'] = mtime",
            "        if reload_func:",
            "            reload_func(cache_info['data'])",
            "    return cache_info['data']",
            "",
            "",
            "@contextlib.contextmanager",
            "def temporary_mutation(obj, **kwargs):",
            "    \"\"\"Temporarily set the attr on a particular object to a given value then",
            "    revert when finished.",
            "",
            "    One use of this is to temporarily set the read_deleted flag on a context",
            "    object:",
            "",
            "        with temporary_mutation(context, read_deleted=\"yes\"):",
            "            do_something_that_needed_deleted_objects()",
            "    \"\"\"",
            "    def is_dict_like(thing):",
            "        return hasattr(thing, 'has_key')",
            "",
            "    def get(thing, attr, default):",
            "        if is_dict_like(thing):",
            "            return thing.get(attr, default)",
            "        else:",
            "            return getattr(thing, attr, default)",
            "",
            "    def set_value(thing, attr, val):",
            "        if is_dict_like(thing):",
            "            thing[attr] = val",
            "        else:",
            "            setattr(thing, attr, val)",
            "",
            "    def delete(thing, attr):",
            "        if is_dict_like(thing):",
            "            del thing[attr]",
            "        else:",
            "            delattr(thing, attr)",
            "",
            "    NOT_PRESENT = object()",
            "",
            "    old_values = {}",
            "    for attr, new_value in kwargs.items():",
            "        old_values[attr] = get(obj, attr, NOT_PRESENT)",
            "        set_value(obj, attr, new_value)",
            "",
            "    try:",
            "        yield",
            "    finally:",
            "        for attr, old_value in old_values.items():",
            "            if old_value is NOT_PRESENT:",
            "                delete(obj, attr)",
            "            else:",
            "                set_value(obj, attr, old_value)",
            "",
            "",
            "def generate_mac_address():",
            "    \"\"\"Generate an Ethernet MAC address.\"\"\"",
            "    # NOTE(vish): We would prefer to use 0xfe here to ensure that linux",
            "    #             bridge mac addresses don't change, but it appears to",
            "    #             conflict with libvirt, so we use the next highest octet",
            "    #             that has the unicast and locally administered bits set",
            "    #             properly: 0xfa.",
            "    #             Discussion: https://bugs.launchpad.net/nova/+bug/921838",
            "    mac = [0xfa, 0x16, 0x3e,",
            "           random.randint(0x00, 0xff),",
            "           random.randint(0x00, 0xff),",
            "           random.randint(0x00, 0xff)]",
            "    return ':'.join(map(lambda x: \"%02x\" % x, mac))",
            "",
            "",
            "def read_file_as_root(file_path):",
            "    \"\"\"Secure helper to read file as root.\"\"\"",
            "    try:",
            "        out, _err = execute('cat', file_path, run_as_root=True)",
            "        return out",
            "    except processutils.ProcessExecutionError:",
            "        raise exception.FileNotFound(file_path=file_path)",
            "",
            "",
            "@contextlib.contextmanager",
            "def temporary_chown(path, owner_uid=None):",
            "    \"\"\"Temporarily chown a path.",
            "",
            "    :param owner_uid: UID of temporary owner (defaults to current user)",
            "    \"\"\"",
            "    if owner_uid is None:",
            "        owner_uid = os.getuid()",
            "",
            "    orig_uid = os.stat(path).st_uid",
            "",
            "    if orig_uid != owner_uid:",
            "        execute('chown', owner_uid, path, run_as_root=True)",
            "    try:",
            "        yield",
            "    finally:",
            "        if orig_uid != owner_uid:",
            "            execute('chown', orig_uid, path, run_as_root=True)",
            "",
            "",
            "@contextlib.contextmanager",
            "def tempdir(**kwargs):",
            "    argdict = kwargs.copy()",
            "    if 'dir' not in argdict:",
            "        argdict['dir'] = CONF.tempdir",
            "    tmpdir = tempfile.mkdtemp(**argdict)",
            "    try:",
            "        yield tmpdir",
            "    finally:",
            "        try:",
            "            shutil.rmtree(tmpdir)",
            "        except OSError as e:",
            "            LOG.error(_('Could not remove tmpdir: %s'), str(e))",
            "",
            "",
            "def walk_class_hierarchy(clazz, encountered=None):",
            "    \"\"\"Walk class hierarchy, yielding most derived classes first.\"\"\"",
            "    if not encountered:",
            "        encountered = []",
            "    for subclass in clazz.__subclasses__():",
            "        if subclass not in encountered:",
            "            encountered.append(subclass)",
            "            # drill down to leaves first",
            "            for subsubclass in walk_class_hierarchy(subclass, encountered):",
            "                yield subsubclass",
            "            yield subclass",
            "",
            "",
            "class UndoManager(object):",
            "    \"\"\"Provides a mechanism to facilitate rolling back a series of actions",
            "    when an exception is raised.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self.undo_stack = []",
            "",
            "    def undo_with(self, undo_func):",
            "        self.undo_stack.append(undo_func)",
            "",
            "    def _rollback(self):",
            "        for undo_func in reversed(self.undo_stack):",
            "            undo_func()",
            "",
            "    def rollback_and_reraise(self, msg=None, **kwargs):",
            "        \"\"\"Rollback a series of actions then re-raise the exception.",
            "",
            "        .. note:: (sirp) This should only be called within an",
            "                  exception handler.",
            "        \"\"\"",
            "        with excutils.save_and_reraise_exception():",
            "            if msg:",
            "                LOG.exception(msg, **kwargs)",
            "",
            "            self._rollback()",
            "",
            "",
            "def mkfs(fs, path, label=None, run_as_root=False):",
            "    \"\"\"Format a file or block device",
            "",
            "    :param fs: Filesystem type (examples include 'swap', 'ext3', 'ext4'",
            "               'btrfs', etc.)",
            "    :param path: Path to file or block device to format",
            "    :param label: Volume label to use",
            "    \"\"\"",
            "    if fs == 'swap':",
            "        args = ['mkswap']",
            "    else:",
            "        args = ['mkfs', '-t', fs]",
            "    #add -F to force no interactive execute on non-block device.",
            "    if fs in ('ext3', 'ext4', 'ntfs'):",
            "        args.extend(['-F'])",
            "    if label:",
            "        if fs in ('msdos', 'vfat'):",
            "            label_opt = '-n'",
            "        else:",
            "            label_opt = '-L'",
            "        args.extend([label_opt, label])",
            "    args.append(path)",
            "    execute(*args, run_as_root=run_as_root)",
            "",
            "",
            "def last_bytes(file_like_object, num):",
            "    \"\"\"Return num bytes from the end of the file, and remaining byte count.",
            "",
            "    :param file_like_object: The file to read",
            "    :param num: The number of bytes to return",
            "",
            "    :returns (data, remaining)",
            "    \"\"\"",
            "",
            "    try:",
            "        file_like_object.seek(-num, os.SEEK_END)",
            "    except IOError as e:",
            "        if e.errno == 22:",
            "            file_like_object.seek(0, os.SEEK_SET)",
            "        else:",
            "            raise",
            "",
            "    remaining = file_like_object.tell()",
            "    return (file_like_object.read(), remaining)",
            "",
            "",
            "def metadata_to_dict(metadata):",
            "    result = {}",
            "    for item in metadata:",
            "        if not item.get('deleted'):",
            "            result[item['key']] = item['value']",
            "    return result",
            "",
            "",
            "def dict_to_metadata(metadata):",
            "    result = []",
            "    for key, value in metadata.iteritems():",
            "        result.append(dict(key=key, value=value))",
            "    return result",
            "",
            "",
            "def instance_meta(instance):",
            "    if isinstance(instance['metadata'], dict):",
            "        return instance['metadata']",
            "    else:",
            "        return metadata_to_dict(instance['metadata'])",
            "",
            "",
            "def instance_sys_meta(instance):",
            "    if not instance.get('system_metadata'):",
            "        return {}",
            "    if isinstance(instance['system_metadata'], dict):",
            "        return instance['system_metadata']",
            "    else:",
            "        return metadata_to_dict(instance['system_metadata'])",
            "",
            "",
            "def get_wrapped_function(function):",
            "    \"\"\"Get the method at the bottom of a stack of decorators.\"\"\"",
            "    if not hasattr(function, 'func_closure') or not function.func_closure:",
            "        return function",
            "",
            "    def _get_wrapped_function(function):",
            "        if not hasattr(function, 'func_closure') or not function.func_closure:",
            "            return None",
            "",
            "        for closure in function.func_closure:",
            "            func = closure.cell_contents",
            "",
            "            deeper_func = _get_wrapped_function(func)",
            "            if deeper_func:",
            "                return deeper_func",
            "            elif hasattr(closure.cell_contents, '__call__'):",
            "                return closure.cell_contents",
            "",
            "    return _get_wrapped_function(function)",
            "",
            "",
            "def expects_func_args(*args):",
            "    def _decorator_checker(dec):",
            "        @functools.wraps(dec)",
            "        def _decorator(f):",
            "            base_f = get_wrapped_function(f)",
            "            arg_names, a, kw, _default = inspect.getargspec(base_f)",
            "            if a or kw or set(args) <= set(arg_names):",
            "                # NOTE (ndipanov): We can't really tell if correct stuff will",
            "                # be passed if it's a function with *args or **kwargs so",
            "                # we still carry on and hope for the best",
            "                return dec(f)",
            "            else:",
            "                raise TypeError(\"Decorated function %(f_name)s does not \"",
            "                                \"have the arguments expected by the \"",
            "                                \"decorator %(d_name)s\" %",
            "                                {'f_name': base_f.__name__,",
            "                                 'd_name': dec.__name__})",
            "        return _decorator",
            "    return _decorator_checker",
            "",
            "",
            "class ExceptionHelper(object):",
            "    \"\"\"Class to wrap another and translate the ClientExceptions raised by its",
            "    function calls to the actual ones.",
            "    \"\"\"",
            "",
            "    def __init__(self, target):",
            "        self._target = target",
            "",
            "    def __getattr__(self, name):",
            "        func = getattr(self._target, name)",
            "",
            "        @functools.wraps(func)",
            "        def wrapper(*args, **kwargs):",
            "            try:",
            "                return func(*args, **kwargs)",
            "            except messaging.ExpectedException as e:",
            "                raise (e.exc_info[1], None, e.exc_info[2])",
            "        return wrapper",
            "",
            "",
            "def check_string_length(value, name, min_length=0, max_length=None):",
            "    \"\"\"Check the length of specified string",
            "    :param value: the value of the string",
            "    :param name: the name of the string",
            "    :param min_length: the min_length of the string",
            "    :param max_length: the max_length of the string",
            "    \"\"\"",
            "    if not isinstance(value, six.string_types):",
            "        msg = _(\"%s is not a string or unicode\") % name",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "    if len(value) < min_length:",
            "        msg = _(\"%(name)s has a minimum character requirement of \"",
            "                \"%(min_length)s.\") % {'name': name, 'min_length': min_length}",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "    if max_length and len(value) > max_length:",
            "        msg = _(\"%(name)s has more than %(max_length)s \"",
            "                \"characters.\") % {'name': name, 'max_length': max_length}",
            "        raise exception.InvalidInput(message=msg)",
            "",
            "",
            "def validate_integer(value, name, min_value=None, max_value=None):",
            "    \"\"\"Make sure that value is a valid integer, potentially within range.\"\"\"",
            "    try:",
            "        value = int(str(value))",
            "    except (ValueError, UnicodeEncodeError):",
            "        msg = _('%(value_name)s must be an integer')",
            "        raise exception.InvalidInput(reason=(",
            "            msg % {'value_name': name}))",
            "",
            "    if min_value is not None:",
            "        if value < min_value:",
            "            msg = _('%(value_name)s must be >= %(min_value)d')",
            "            raise exception.InvalidInput(",
            "                reason=(msg % {'value_name': name,",
            "                               'min_value': min_value}))",
            "    if max_value is not None:",
            "        if value > max_value:",
            "            msg = _('%(value_name)s must be <= %(max_value)d')",
            "            raise exception.InvalidInput(",
            "                reason=(",
            "                    msg % {'value_name': name,",
            "                           'max_value': max_value})",
            "            )",
            "    return value",
            "",
            "",
            "def spawn_n(func, *args, **kwargs):",
            "    \"\"\"Passthrough method for eventlet.spawn_n.",
            "",
            "    This utility exists so that it can be stubbed for testing without",
            "    interfering with the service spawns.",
            "    \"\"\"",
            "    eventlet.spawn_n(func, *args, **kwargs)",
            "",
            "",
            "def is_none_string(val):",
            "    \"\"\"Check if a string represents a None value.",
            "    \"\"\"",
            "    if not isinstance(val, six.string_types):",
            "        return False",
            "",
            "    return val.lower() == 'none'",
            "",
            "",
            "def convert_version_to_int(version):",
            "    try:",
            "        if isinstance(version, six.string_types):",
            "            version = convert_version_to_tuple(version)",
            "        if isinstance(version, tuple):",
            "            return reduce(lambda x, y: (x * 1000) + y, version)",
            "    except Exception:",
            "        raise exception.NovaException(message=\"Hypervisor version invalid.\")",
            "",
            "",
            "def convert_version_to_str(version_int):",
            "    version_numbers = []",
            "    factor = 1000",
            "    while version_int != 0:",
            "        version_number = version_int - (version_int // factor * factor)",
            "        version_numbers.insert(0, str(version_number))",
            "        version_int = version_int / factor",
            "",
            "    return reduce(lambda x, y: \"%s.%s\" % (x, y), version_numbers)",
            "",
            "",
            "def convert_version_to_tuple(version_str):",
            "    return tuple(int(part) for part in version_str.split('.'))",
            "",
            "",
            "def is_neutron():",
            "    global _IS_NEUTRON",
            "",
            "    if _IS_NEUTRON is not None:",
            "        return _IS_NEUTRON",
            "",
            "    try:",
            "        # compatibility with Folsom/Grizzly configs",
            "        cls_name = CONF.network_api_class",
            "        if cls_name == 'nova.network.quantumv2.api.API':",
            "            cls_name = 'nova.network.neutronv2.api.API'",
            "",
            "        from nova.network.neutronv2 import api as neutron_api",
            "        _IS_NEUTRON = issubclass(importutils.import_class(cls_name),",
            "                                 neutron_api.API)",
            "    except ImportError:",
            "        _IS_NEUTRON = False",
            "",
            "    return _IS_NEUTRON",
            "",
            "",
            "def reset_is_neutron():",
            "    global _IS_NEUTRON",
            "    _IS_NEUTRON = None",
            "",
            "",
            "def is_auto_disk_config_disabled(auto_disk_config_raw):",
            "    auto_disk_config_disabled = False",
            "    if auto_disk_config_raw is not None:",
            "        adc_lowered = auto_disk_config_raw.strip().lower()",
            "        if adc_lowered == \"disabled\":",
            "            auto_disk_config_disabled = True",
            "    return auto_disk_config_disabled",
            "",
            "",
            "def get_auto_disk_config_from_instance(instance=None, sys_meta=None):",
            "    if sys_meta is None:",
            "        sys_meta = instance_sys_meta(instance)",
            "    return sys_meta.get(\"image_auto_disk_config\")",
            "",
            "",
            "def get_auto_disk_config_from_image_props(image_properties):",
            "    return image_properties.get(\"auto_disk_config\")",
            "",
            "",
            "def get_system_metadata_from_image(image_meta, flavor=None):",
            "    system_meta = {}",
            "    prefix_format = SM_IMAGE_PROP_PREFIX + '%s'",
            "",
            "    for key, value in image_meta.get('properties', {}).iteritems():",
            "        new_value = unicode(value)[:255]",
            "        system_meta[prefix_format % key] = new_value",
            "",
            "    for key in SM_INHERITABLE_KEYS:",
            "        value = image_meta.get(key)",
            "",
            "        if key == 'min_disk' and flavor:",
            "            if image_meta.get('disk_format') == 'vhd':",
            "                value = flavor['root_gb']",
            "            else:",
            "                value = max(value, flavor['root_gb'])",
            "",
            "        if value is None:",
            "            continue",
            "",
            "        system_meta[prefix_format % key] = value",
            "",
            "    return system_meta",
            "",
            "",
            "def get_image_from_system_metadata(system_meta):",
            "    image_meta = {}",
            "    properties = {}",
            "",
            "    if not isinstance(system_meta, dict):",
            "        system_meta = metadata_to_dict(system_meta)",
            "",
            "    for key, value in system_meta.iteritems():",
            "        if value is None:",
            "            continue",
            "",
            "        # NOTE(xqueralt): Not sure this has to inherit all the properties or",
            "        # just the ones we need. Leaving it for now to keep the old behaviour.",
            "        if key.startswith(SM_IMAGE_PROP_PREFIX):",
            "            key = key[len(SM_IMAGE_PROP_PREFIX):]",
            "",
            "        if key in SM_INHERITABLE_KEYS:",
            "            image_meta[key] = value",
            "        else:",
            "            # Skip properties that are non-inheritable",
            "            if key in CONF.non_inheritable_image_properties:",
            "                continue",
            "            properties[key] = value",
            "",
            "    if properties:",
            "        image_meta['properties'] = properties",
            "",
            "    return image_meta",
            "",
            "",
            "def get_hash_str(base_str):",
            "    \"\"\"returns string that represents hash of base_str (in hex format).\"\"\"",
            "    return hashlib.md5(base_str).hexdigest()",
            "",
            "",
            "def cpu_count():",
            "    try:",
            "        return multiprocessing.cpu_count()",
            "    except NotImplementedError:",
            "        return 1"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "764": [
                "chown"
            ],
            "765": [
                "chown"
            ],
            "766": [
                "chown"
            ],
            "767": [
                "chown"
            ],
            "768": [
                "chown"
            ],
            "769": [
                "chown"
            ],
            "770": [
                "chown"
            ],
            "771": [
                "chown"
            ],
            "772": [
                "chown"
            ],
            "773": [
                "chown"
            ],
            "774": [
                "chown"
            ],
            "775": [
                "chown"
            ],
            "776": [],
            "777": []
        },
        "addLocation": []
    },
    "nova/virt/libvirt/imagebackend.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": 272,
                "PatchRowcode": "                             lock_path=self.lock_path)"
            },
            "1": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": 273,
                "PatchRowcode": "         def write_to_disk_info_file():"
            },
            "2": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": 274,
                "PatchRowcode": "             # Use os.open to create it without group or world write permission."
            },
            "3": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            fd = os.open(self.disk_info_path, os.O_RDWR | os.O_CREAT, 0o644)"
            },
            "4": {
                "beforePatchRowNumber": 276,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with os.fdopen(fd, \"r+\") as disk_info_file:"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+            fd = os.open(self.disk_info_path, os.O_RDONLY | os.O_CREAT, 0o644)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+            with os.fdopen(fd, \"r\") as disk_info_file:"
            },
            "7": {
                "beforePatchRowNumber": 277,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "                 line = disk_info_file.read().rstrip()"
            },
            "8": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": 278,
                "PatchRowcode": "                 dct = _dict_from_line(line)"
            },
            "9": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if self.path in dct:"
            },
            "10": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    msg = _(\"Attempted overwrite of an existing value.\")"
            },
            "11": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    raise exception.InvalidDiskInfo(reason=msg)"
            },
            "12": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                dct.update({self.path: driver_format})"
            },
            "13": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                disk_info_file.seek(0)"
            },
            "14": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                disk_info_file.truncate()"
            },
            "15": {
                "beforePatchRowNumber": 285,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                disk_info_file.write('%s\\n' % jsonutils.dumps(dct))"
            },
            "16": {
                "beforePatchRowNumber": 286,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # Ensure the file is always owned by the nova user so qemu can't"
            },
            "17": {
                "beforePatchRowNumber": 287,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # write it."
            },
            "18": {
                "beforePatchRowNumber": 288,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            utils.chown(self.disk_info_path, owner_uid=os.getuid())"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+            if self.path in dct:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+                msg = _(\"Attempted overwrite of an existing value.\")"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+                raise exception.InvalidDiskInfo(reason=msg)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+            dct.update({self.path: driver_format})"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+            tmp_path = self.disk_info_path + \".tmp\""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 286,
                "PatchRowcode": "+            fd = os.open(tmp_path, os.O_WRONLY | os.O_CREAT, 0o644)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 287,
                "PatchRowcode": "+            with os.fdopen(fd, \"w\") as tmp_file:"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 288,
                "PatchRowcode": "+                tmp_file.write('%s\\n' % jsonutils.dumps(dct))"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 289,
                "PatchRowcode": "+            os.rename(tmp_path, self.disk_info_path)"
            },
            "30": {
                "beforePatchRowNumber": 289,
                "afterPatchRowNumber": 290,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": 290,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "         try:"
            },
            "32": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": 292,
                "PatchRowcode": "             if (self.disk_info_path is not None and"
            }
        },
        "frontPatchFile": [
            "# Copyright 2012 Grid Dynamics",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import abc",
            "import contextlib",
            "import os",
            "",
            "import six",
            "",
            "from oslo.config import cfg",
            "",
            "from nova import exception",
            "from nova.openstack.common import excutils",
            "from nova.openstack.common import fileutils",
            "from nova.openstack.common.gettextutils import _",
            "from nova.openstack.common import jsonutils",
            "from nova.openstack.common import log as logging",
            "from nova.openstack.common import units",
            "from nova import utils",
            "from nova.virt.disk import api as disk",
            "from nova.virt import images",
            "from nova.virt.libvirt import config as vconfig",
            "from nova.virt.libvirt import utils as libvirt_utils",
            "",
            "",
            "try:",
            "    import rados",
            "    import rbd",
            "except ImportError:",
            "    rados = None",
            "    rbd = None",
            "",
            "",
            "__imagebackend_opts = [",
            "    cfg.StrOpt('images_type',",
            "               default='default',",
            "               help='VM Images format. Acceptable values are: raw, qcow2, lvm,'",
            "                    ' rbd, default. If default is specified,'",
            "                    ' then use_cow_images flag is used instead of this one.',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_type'),",
            "    cfg.StrOpt('images_volume_group',",
            "               help='LVM Volume Group that is used for VM images, when you'",
            "                    ' specify images_type=lvm.',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_volume_group'),",
            "    cfg.BoolOpt('sparse_logical_volumes',",
            "                default=False,",
            "                help='Create sparse logical volumes (with virtualsize)'",
            "                     ' if this flag is set to True.',",
            "                deprecated_group='DEFAULT',",
            "                deprecated_name='libvirt_sparse_logical_volumes'),",
            "    cfg.StrOpt('volume_clear',",
            "               default='zero',",
            "               help='Method used to wipe old volumes (valid options are: '",
            "                    'none, zero, shred)'),",
            "    cfg.IntOpt('volume_clear_size',",
            "               default=0,",
            "               help='Size in MiB to wipe at start of old volumes. 0 => all'),",
            "    cfg.StrOpt('images_rbd_pool',",
            "               default='rbd',",
            "               help='The RADOS pool in which rbd volumes are stored',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_rbd_pool'),",
            "    cfg.StrOpt('images_rbd_ceph_conf',",
            "               default='',  # default determined by librados",
            "               help='Path to the ceph configuration file to use',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_rbd_ceph_conf'),",
            "        ]",
            "",
            "CONF = cfg.CONF",
            "CONF.register_opts(__imagebackend_opts, 'libvirt')",
            "CONF.import_opt('image_cache_subdirectory_name', 'nova.virt.imagecache')",
            "CONF.import_opt('preallocate_images', 'nova.virt.driver')",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "@six.add_metaclass(abc.ABCMeta)",
            "class Image(object):",
            "",
            "    def __init__(self, source_type, driver_format, is_block_dev=False):",
            "        \"\"\"Image initialization.",
            "",
            "        :source_type: block or file",
            "        :driver_format: raw or qcow2",
            "        :is_block_dev:",
            "        \"\"\"",
            "        self.source_type = source_type",
            "        self.driver_format = driver_format",
            "        self.is_block_dev = is_block_dev",
            "        self.preallocate = False",
            "",
            "        # NOTE(dripton): We store lines of json (path, disk_format) in this",
            "        # file, for some image types, to prevent attacks based on changing the",
            "        # disk_format.",
            "        self.disk_info_path = None",
            "",
            "        # NOTE(mikal): We need a lock directory which is shared along with",
            "        # instance files, to cover the scenario where multiple compute nodes",
            "        # are trying to create a base file at the same time",
            "        self.lock_path = os.path.join(CONF.instances_path, 'locks')",
            "",
            "    @abc.abstractmethod",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        \"\"\"Create image from template.",
            "",
            "        Contains specific behavior for each image type.",
            "",
            "        :prepare_template: function, that creates template.",
            "        Should accept `target` argument.",
            "        :base: Template name",
            "        :size: Size of created image in bytes",
            "        \"\"\"",
            "        pass",
            "",
            "    def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode,",
            "            extra_specs, hypervisor_version):",
            "        \"\"\"Get `LibvirtConfigGuestDisk` filled for this image.",
            "",
            "        :disk_dev: Disk bus device name",
            "        :disk_bus: Disk bus type",
            "        :device_type: Device type for this image.",
            "        :cache_mode: Caching mode for this image",
            "        :extra_specs: Instance type extra specs dict.",
            "        \"\"\"",
            "        info = vconfig.LibvirtConfigGuestDisk()",
            "        info.source_type = self.source_type",
            "        info.source_device = device_type",
            "        info.target_bus = disk_bus",
            "        info.target_dev = disk_dev",
            "        info.driver_cache = cache_mode",
            "        info.driver_format = self.driver_format",
            "        driver_name = libvirt_utils.pick_disk_driver_name(hypervisor_version,",
            "                                                          self.is_block_dev)",
            "        info.driver_name = driver_name",
            "        info.source_path = self.path",
            "",
            "        tune_items = ['disk_read_bytes_sec', 'disk_read_iops_sec',",
            "            'disk_write_bytes_sec', 'disk_write_iops_sec',",
            "            'disk_total_bytes_sec', 'disk_total_iops_sec']",
            "        # Note(yaguang): Currently, the only tuning available is Block I/O",
            "        # throttling for qemu.",
            "        if self.source_type in ['file', 'block']:",
            "            for key, value in extra_specs.iteritems():",
            "                scope = key.split(':')",
            "                if len(scope) > 1 and scope[0] == 'quota':",
            "                    if scope[1] in tune_items:",
            "                        setattr(info, scope[1], value)",
            "        return info",
            "",
            "    def check_image_exists(self):",
            "        return os.path.exists(self.path)",
            "",
            "    def cache(self, fetch_func, filename, size=None, *args, **kwargs):",
            "        \"\"\"Creates image from template.",
            "",
            "        Ensures that template and image not already exists.",
            "        Ensures that base directory exists.",
            "        Synchronizes on template fetching.",
            "",
            "        :fetch_func: Function that creates the base image",
            "                     Should accept `target` argument.",
            "        :filename: Name of the file in the image directory",
            "        :size: Size of created image in bytes (optional)",
            "        \"\"\"",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def fetch_func_sync(target, *args, **kwargs):",
            "            fetch_func(target=target, *args, **kwargs)",
            "",
            "        base_dir = os.path.join(CONF.instances_path,",
            "                                CONF.image_cache_subdirectory_name)",
            "        if not os.path.exists(base_dir):",
            "            fileutils.ensure_tree(base_dir)",
            "        base = os.path.join(base_dir, filename)",
            "",
            "        if not self.check_image_exists() or not os.path.exists(base):",
            "            self.create_image(fetch_func_sync, base, size,",
            "                              *args, **kwargs)",
            "",
            "        if (size and self.preallocate and self._can_fallocate() and",
            "                os.access(self.path, os.W_OK)):",
            "            utils.execute('fallocate', '-n', '-l', size, self.path)",
            "",
            "    def _can_fallocate(self):",
            "        \"\"\"Check once per class, whether fallocate(1) is available,",
            "           and that the instances directory supports fallocate(2).",
            "        \"\"\"",
            "        can_fallocate = getattr(self.__class__, 'can_fallocate', None)",
            "        if can_fallocate is None:",
            "            _out, err = utils.trycmd('fallocate', '-n', '-l', '1',",
            "                                     self.path + '.fallocate_test')",
            "            fileutils.delete_if_exists(self.path + '.fallocate_test')",
            "            can_fallocate = not err",
            "            self.__class__.can_fallocate = can_fallocate",
            "            if not can_fallocate:",
            "                LOG.error(_('Unable to preallocate_images=%(imgs)s at path: '",
            "                            '%(path)s'), {'imgs': CONF.preallocate_images,",
            "                                           'path': self.path})",
            "        return can_fallocate",
            "",
            "    @staticmethod",
            "    def verify_base_size(base, size, base_size=0):",
            "        \"\"\"Check that the base image is not larger than size.",
            "           Since images can't be generally shrunk, enforce this",
            "           constraint taking account of virtual image size.",
            "        \"\"\"",
            "",
            "        # Note(pbrady): The size and min_disk parameters of a glance",
            "        #  image are checked against the instance size before the image",
            "        #  is even downloaded from glance, but currently min_disk is",
            "        #  adjustable and doesn't currently account for virtual disk size,",
            "        #  so we need this extra check here.",
            "        # NOTE(cfb): Having a flavor that sets the root size to 0 and having",
            "        #  nova effectively ignore that size and use the size of the",
            "        #  image is considered a feature at this time, not a bug.",
            "",
            "        if size is None:",
            "            return",
            "",
            "        if size and not base_size:",
            "            base_size = disk.get_disk_size(base)",
            "",
            "        if size < base_size:",
            "            msg = _('%(base)s virtual size %(base_size)s '",
            "                    'larger than flavor root disk size %(size)s')",
            "            LOG.error(msg % {'base': base,",
            "                              'base_size': base_size,",
            "                              'size': size})",
            "            raise exception.FlavorDiskTooSmall()",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        raise NotImplementedError()",
            "",
            "    def _get_driver_format(self):",
            "        return self.driver_format",
            "",
            "    def resolve_driver_format(self):",
            "        \"\"\"Return the driver format for self.path.",
            "",
            "        First checks self.disk_info_path for an entry.",
            "        If it's not there, calls self._get_driver_format(), and then",
            "        stores the result in self.disk_info_path",
            "",
            "        See https://bugs.launchpad.net/nova/+bug/1221190",
            "        \"\"\"",
            "        def _dict_from_line(line):",
            "            if not line:",
            "                return {}",
            "            try:",
            "                return jsonutils.loads(line)",
            "            except (TypeError, ValueError) as e:",
            "                msg = (_(\"Could not load line %(line)s, got error \"",
            "                        \"%(error)s\") %",
            "                        {'line': line, 'error': unicode(e)})",
            "                raise exception.InvalidDiskInfo(reason=msg)",
            "",
            "        @utils.synchronized(self.disk_info_path, external=False,",
            "                            lock_path=self.lock_path)",
            "        def write_to_disk_info_file():",
            "            # Use os.open to create it without group or world write permission.",
            "            fd = os.open(self.disk_info_path, os.O_RDWR | os.O_CREAT, 0o644)",
            "            with os.fdopen(fd, \"r+\") as disk_info_file:",
            "                line = disk_info_file.read().rstrip()",
            "                dct = _dict_from_line(line)",
            "                if self.path in dct:",
            "                    msg = _(\"Attempted overwrite of an existing value.\")",
            "                    raise exception.InvalidDiskInfo(reason=msg)",
            "                dct.update({self.path: driver_format})",
            "                disk_info_file.seek(0)",
            "                disk_info_file.truncate()",
            "                disk_info_file.write('%s\\n' % jsonutils.dumps(dct))",
            "            # Ensure the file is always owned by the nova user so qemu can't",
            "            # write it.",
            "            utils.chown(self.disk_info_path, owner_uid=os.getuid())",
            "",
            "        try:",
            "            if (self.disk_info_path is not None and",
            "                        os.path.exists(self.disk_info_path)):",
            "                with open(self.disk_info_path) as disk_info_file:",
            "                    line = disk_info_file.read().rstrip()",
            "                    dct = _dict_from_line(line)",
            "                    for path, driver_format in dct.iteritems():",
            "                        if path == self.path:",
            "                            return driver_format",
            "            driver_format = self._get_driver_format()",
            "            if self.disk_info_path is not None:",
            "                fileutils.ensure_tree(os.path.dirname(self.disk_info_path))",
            "                write_to_disk_info_file()",
            "        except OSError as e:",
            "            raise exception.DiskInfoReadWriteFail(reason=unicode(e))",
            "        return driver_format",
            "",
            "",
            "class Raw(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Raw, self).__init__(\"file\", \"raw\", is_block_dev=False)",
            "",
            "        self.path = (path or",
            "                     os.path.join(libvirt_utils.get_instance_path(instance),",
            "                                  disk_name))",
            "        self.preallocate = CONF.preallocate_images != 'none'",
            "        self.disk_info_path = os.path.join(os.path.dirname(self.path),",
            "                                           'disk.info')",
            "        self.correct_format()",
            "",
            "    def _get_driver_format(self):",
            "        data = images.qemu_img_info(self.path)",
            "        return data.file_format or 'raw'",
            "",
            "    def correct_format(self):",
            "        if os.path.exists(self.path):",
            "            self.driver_format = self.resolve_driver_format()",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def copy_raw_image(base, target, size):",
            "            libvirt_utils.copy_image(base, target)",
            "            if size:",
            "                # class Raw is misnamed, format may not be 'raw' in all cases",
            "                use_cow = self.driver_format == 'qcow2'",
            "                disk.extend(target, size, use_cow=use_cow)",
            "",
            "        generating = 'image_id' not in kwargs",
            "        if generating:",
            "            if not self.check_image_exists():",
            "                #Generating image in place",
            "                prepare_template(target=self.path, *args, **kwargs)",
            "        else:",
            "            if not os.path.exists(base):",
            "                prepare_template(target=base, max_size=size, *args, **kwargs)",
            "            self.verify_base_size(base, size)",
            "            if not os.path.exists(self.path):",
            "                with fileutils.remove_path_on_error(self.path):",
            "                    copy_raw_image(base, self.path, size)",
            "        self.correct_format()",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format)",
            "",
            "",
            "class Qcow2(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Qcow2, self).__init__(\"file\", \"qcow2\", is_block_dev=False)",
            "",
            "        self.path = (path or",
            "                     os.path.join(libvirt_utils.get_instance_path(instance),",
            "                                  disk_name))",
            "        self.preallocate = CONF.preallocate_images != 'none'",
            "        self.disk_info_path = os.path.join(os.path.dirname(self.path),",
            "                                           'disk.info')",
            "        self.resolve_driver_format()",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def copy_qcow2_image(base, target, size):",
            "            # TODO(pbrady): Consider copying the cow image here",
            "            # with preallocation=metadata set for performance reasons.",
            "            # This would be keyed on a 'preallocate_images' setting.",
            "            libvirt_utils.create_cow_image(base, target)",
            "            if size:",
            "                disk.extend(target, size, use_cow=True)",
            "",
            "        # Download the unmodified base image unless we already have a copy.",
            "        if not os.path.exists(base):",
            "            prepare_template(target=base, max_size=size, *args, **kwargs)",
            "        else:",
            "            self.verify_base_size(base, size)",
            "",
            "        legacy_backing_size = None",
            "        legacy_base = base",
            "",
            "        # Determine whether an existing qcow2 disk uses a legacy backing by",
            "        # actually looking at the image itself and parsing the output of the",
            "        # backing file it expects to be using.",
            "        if os.path.exists(self.path):",
            "            backing_path = libvirt_utils.get_disk_backing_file(self.path)",
            "            if backing_path is not None:",
            "                backing_file = os.path.basename(backing_path)",
            "                backing_parts = backing_file.rpartition('_')",
            "                if backing_file != backing_parts[-1] and \\",
            "                        backing_parts[-1].isdigit():",
            "                    legacy_backing_size = int(backing_parts[-1])",
            "                    legacy_base += '_%d' % legacy_backing_size",
            "                    legacy_backing_size *= units.Gi",
            "",
            "        # Create the legacy backing file if necessary.",
            "        if legacy_backing_size:",
            "            if not os.path.exists(legacy_base):",
            "                with fileutils.remove_path_on_error(legacy_base):",
            "                    libvirt_utils.copy_image(base, legacy_base)",
            "                    disk.extend(legacy_base, legacy_backing_size, use_cow=True)",
            "",
            "        if not os.path.exists(self.path):",
            "            with fileutils.remove_path_on_error(self.path):",
            "                copy_qcow2_image(base, self.path, size)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        libvirt_utils.extract_snapshot(self.path, 'qcow2',",
            "                                       target,",
            "                                       out_format)",
            "",
            "",
            "class Lvm(Image):",
            "    @staticmethod",
            "    def escape(filename):",
            "        return filename.replace('_', '__')",
            "",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Lvm, self).__init__(\"block\", \"raw\", is_block_dev=True)",
            "",
            "        if path:",
            "            info = libvirt_utils.logical_volume_info(path)",
            "            self.vg = info['VG']",
            "            self.lv = info['LV']",
            "            self.path = path",
            "        else:",
            "            if not CONF.libvirt.images_volume_group:",
            "                raise RuntimeError(_('You should specify'",
            "                                     ' images_volume_group'",
            "                                     ' flag to use LVM images.'))",
            "            self.vg = CONF.libvirt.images_volume_group",
            "            self.lv = '%s_%s' % (instance['uuid'],",
            "                                 self.escape(disk_name))",
            "            self.path = os.path.join('/dev', self.vg, self.lv)",
            "",
            "        # TODO(pbrady): possibly deprecate libvirt.sparse_logical_volumes",
            "        # for the more general preallocate_images",
            "        self.sparse = CONF.libvirt.sparse_logical_volumes",
            "        self.preallocate = not self.sparse",
            "",
            "    def _can_fallocate(self):",
            "        return False",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def create_lvm_image(base, size):",
            "            base_size = disk.get_disk_size(base)",
            "            self.verify_base_size(base, size, base_size=base_size)",
            "            resize = size > base_size",
            "            size = size if resize else base_size",
            "            libvirt_utils.create_lvm_image(self.vg, self.lv,",
            "                                           size, sparse=self.sparse)",
            "            images.convert_image(base, self.path, 'raw', run_as_root=True)",
            "            if resize:",
            "                disk.resize2fs(self.path, run_as_root=True)",
            "",
            "        generated = 'ephemeral_size' in kwargs",
            "",
            "        #Generate images with specified size right on volume",
            "        if generated and size:",
            "            libvirt_utils.create_lvm_image(self.vg, self.lv,",
            "                                           size, sparse=self.sparse)",
            "            with self.remove_volume_on_error(self.path):",
            "                prepare_template(target=self.path, *args, **kwargs)",
            "        else:",
            "            if not os.path.exists(base):",
            "                prepare_template(target=base, max_size=size, *args, **kwargs)",
            "            with self.remove_volume_on_error(self.path):",
            "                create_lvm_image(base, size)",
            "",
            "    @contextlib.contextmanager",
            "    def remove_volume_on_error(self, path):",
            "        try:",
            "            yield",
            "        except Exception:",
            "            with excutils.save_and_reraise_exception():",
            "                libvirt_utils.remove_logical_volumes(path)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format,",
            "                             run_as_root=True)",
            "",
            "",
            "class RBDVolumeProxy(object):",
            "    \"\"\"Context manager for dealing with an existing rbd volume.",
            "",
            "    This handles connecting to rados and opening an ioctx automatically, and",
            "    otherwise acts like a librbd Image object.",
            "",
            "    The underlying librados client and ioctx can be accessed as the attributes",
            "    'client' and 'ioctx'.",
            "    \"\"\"",
            "    def __init__(self, driver, name, pool=None):",
            "        client, ioctx = driver._connect_to_rados(pool)",
            "        try:",
            "            self.volume = driver.rbd.Image(ioctx, str(name), snapshot=None)",
            "        except driver.rbd.Error:",
            "            LOG.exception(_(\"error opening rbd image %s\"), name)",
            "            driver._disconnect_from_rados(client, ioctx)",
            "            raise",
            "        self.driver = driver",
            "        self.client = client",
            "        self.ioctx = ioctx",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, type_, value, traceback):",
            "        try:",
            "            self.volume.close()",
            "        finally:",
            "            self.driver._disconnect_from_rados(self.client, self.ioctx)",
            "",
            "    def __getattr__(self, attrib):",
            "        return getattr(self.volume, attrib)",
            "",
            "",
            "def ascii_str(s):",
            "    \"\"\"Convert a string to ascii, or return None if the input is None.",
            "",
            "    This is useful when a parameter is None by default, or a string. LibRBD",
            "    only accepts ascii, hence the need for conversion.",
            "    \"\"\"",
            "    if s is None:",
            "        return s",
            "    return str(s)",
            "",
            "",
            "class Rbd(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None, **kwargs):",
            "        super(Rbd, self).__init__(\"block\", \"rbd\", is_block_dev=True)",
            "        if path:",
            "            try:",
            "                self.rbd_name = path.split('/')[1]",
            "            except IndexError:",
            "                raise exception.InvalidDevicePath(path=path)",
            "        else:",
            "            self.rbd_name = '%s_%s' % (instance['uuid'], disk_name)",
            "",
            "        if not CONF.libvirt.images_rbd_pool:",
            "            raise RuntimeError(_('You should specify'",
            "                                 ' images_rbd_pool'",
            "                                 ' flag to use rbd images.'))",
            "        self.pool = CONF.libvirt.images_rbd_pool",
            "        self.ceph_conf = ascii_str(CONF.libvirt.images_rbd_ceph_conf)",
            "        self.rbd_user = ascii_str(CONF.libvirt.rbd_user)",
            "        self.rbd = kwargs.get('rbd', rbd)",
            "        self.rados = kwargs.get('rados', rados)",
            "",
            "        self.path = 'rbd:%s/%s' % (self.pool, self.rbd_name)",
            "        if self.rbd_user:",
            "            self.path += ':id=' + self.rbd_user",
            "        if self.ceph_conf:",
            "            self.path += ':conf=' + self.ceph_conf",
            "",
            "    def _connect_to_rados(self, pool=None):",
            "        client = self.rados.Rados(rados_id=self.rbd_user,",
            "                                  conffile=self.ceph_conf)",
            "        try:",
            "            client.connect()",
            "            pool_to_open = str(pool or self.pool)",
            "            ioctx = client.open_ioctx(pool_to_open)",
            "            return client, ioctx",
            "        except self.rados.Error:",
            "            # shutdown cannot raise an exception",
            "            client.shutdown()",
            "            raise",
            "",
            "    def _disconnect_from_rados(self, client, ioctx):",
            "        # closing an ioctx cannot raise an exception",
            "        ioctx.close()",
            "        client.shutdown()",
            "",
            "    def _supports_layering(self):",
            "        return hasattr(self.rbd, 'RBD_FEATURE_LAYERING')",
            "",
            "    def _ceph_args(self):",
            "        args = []",
            "        if self.rbd_user:",
            "            args.extend(['--id', self.rbd_user])",
            "        if self.ceph_conf:",
            "            args.extend(['--conf', self.ceph_conf])",
            "        return args",
            "",
            "    def _get_mon_addrs(self):",
            "        args = ['ceph', 'mon', 'dump', '--format=json'] + self._ceph_args()",
            "        out, _ = utils.execute(*args)",
            "        lines = out.split('\\n')",
            "        if lines[0].startswith('dumped monmap epoch'):",
            "            lines = lines[1:]",
            "        monmap = jsonutils.loads('\\n'.join(lines))",
            "        addrs = [mon['addr'] for mon in monmap['mons']]",
            "        hosts = []",
            "        ports = []",
            "        for addr in addrs:",
            "            host_port = addr[:addr.rindex('/')]",
            "            host, port = host_port.rsplit(':', 1)",
            "            hosts.append(host.strip('[]'))",
            "            ports.append(port)",
            "        return hosts, ports",
            "",
            "    def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode,",
            "            extra_specs, hypervisor_version):",
            "        \"\"\"Get `LibvirtConfigGuestDisk` filled for this image.",
            "",
            "        :disk_dev: Disk bus device name",
            "        :disk_bus: Disk bus type",
            "        :device_type: Device type for this image.",
            "        :cache_mode: Caching mode for this image",
            "        :extra_specs: Instance type extra specs dict.",
            "        \"\"\"",
            "        info = vconfig.LibvirtConfigGuestDisk()",
            "",
            "        hosts, ports = self._get_mon_addrs()",
            "        info.device_type = device_type",
            "        info.driver_format = 'raw'",
            "        info.driver_cache = cache_mode",
            "        info.target_bus = disk_bus",
            "        info.target_dev = disk_dev",
            "        info.source_type = 'network'",
            "        info.source_protocol = 'rbd'",
            "        info.source_name = '%s/%s' % (self.pool, self.rbd_name)",
            "        info.source_hosts = hosts",
            "        info.source_ports = ports",
            "        auth_enabled = (CONF.libvirt.rbd_user is not None)",
            "        if CONF.libvirt.rbd_secret_uuid:",
            "            info.auth_secret_uuid = CONF.libvirt.rbd_secret_uuid",
            "            auth_enabled = True  # Force authentication locally",
            "            if CONF.libvirt.rbd_user:",
            "                info.auth_username = CONF.libvirt.rbd_user",
            "        if auth_enabled:",
            "            info.auth_secret_type = 'ceph'",
            "            info.auth_secret_uuid = CONF.libvirt.rbd_secret_uuid",
            "        return info",
            "",
            "    def _can_fallocate(self):",
            "        return False",
            "",
            "    def check_image_exists(self):",
            "        rbd_volumes = libvirt_utils.list_rbd_volumes(self.pool)",
            "        for vol in rbd_volumes:",
            "            if vol.startswith(self.rbd_name):",
            "                return True",
            "",
            "        return False",
            "",
            "    def _resize(self, volume_name, size):",
            "        size = int(size) * units.Ki",
            "",
            "        with RBDVolumeProxy(self, volume_name) as vol:",
            "            vol.resize(size)",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        if self.rbd is None:",
            "            raise RuntimeError(_('rbd python libraries not found'))",
            "",
            "        if not os.path.exists(base):",
            "            prepare_template(target=base, max_size=size, *args, **kwargs)",
            "        else:",
            "            self.verify_base_size(base, size)",
            "",
            "        # keep using the command line import instead of librbd since it",
            "        # detects zeroes to preserve sparseness in the image",
            "        args = ['--pool', self.pool, base, self.rbd_name]",
            "        if self._supports_layering():",
            "            args += ['--new-format']",
            "        args += self._ceph_args()",
            "        libvirt_utils.import_rbd_image(*args)",
            "",
            "        base_size = disk.get_disk_size(base)",
            "",
            "        if size and size > base_size:",
            "            self._resize(self.rbd_name, size)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format)",
            "",
            "",
            "class Backend(object):",
            "    def __init__(self, use_cow):",
            "        self.BACKEND = {",
            "            'raw': Raw,",
            "            'qcow2': Qcow2,",
            "            'lvm': Lvm,",
            "            'rbd': Rbd,",
            "            'default': Qcow2 if use_cow else Raw",
            "        }",
            "",
            "    def backend(self, image_type=None):",
            "        if not image_type:",
            "            image_type = CONF.libvirt.images_type",
            "        image = self.BACKEND.get(image_type)",
            "        if not image:",
            "            raise RuntimeError(_('Unknown image_type=%s') % image_type)",
            "        return image",
            "",
            "    def image(self, instance, disk_name, image_type=None):",
            "        \"\"\"Constructs image for selected backend",
            "",
            "        :instance: Instance name.",
            "        :name: Image name.",
            "        :image_type: Image type.",
            "        Optional, is CONF.libvirt.images_type by default.",
            "        \"\"\"",
            "        backend = self.backend(image_type)",
            "        return backend(instance=instance, disk_name=disk_name)",
            "",
            "    def snapshot(self, disk_path, image_type=None):",
            "        \"\"\"Returns snapshot for given image",
            "",
            "        :path: path to image",
            "        :image_type: type of image",
            "        \"\"\"",
            "        backend = self.backend(image_type)",
            "        return backend(path=disk_path)"
        ],
        "afterPatchFile": [
            "# Copyright 2012 Grid Dynamics",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import abc",
            "import contextlib",
            "import os",
            "",
            "import six",
            "",
            "from oslo.config import cfg",
            "",
            "from nova import exception",
            "from nova.openstack.common import excutils",
            "from nova.openstack.common import fileutils",
            "from nova.openstack.common.gettextutils import _",
            "from nova.openstack.common import jsonutils",
            "from nova.openstack.common import log as logging",
            "from nova.openstack.common import units",
            "from nova import utils",
            "from nova.virt.disk import api as disk",
            "from nova.virt import images",
            "from nova.virt.libvirt import config as vconfig",
            "from nova.virt.libvirt import utils as libvirt_utils",
            "",
            "",
            "try:",
            "    import rados",
            "    import rbd",
            "except ImportError:",
            "    rados = None",
            "    rbd = None",
            "",
            "",
            "__imagebackend_opts = [",
            "    cfg.StrOpt('images_type',",
            "               default='default',",
            "               help='VM Images format. Acceptable values are: raw, qcow2, lvm,'",
            "                    ' rbd, default. If default is specified,'",
            "                    ' then use_cow_images flag is used instead of this one.',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_type'),",
            "    cfg.StrOpt('images_volume_group',",
            "               help='LVM Volume Group that is used for VM images, when you'",
            "                    ' specify images_type=lvm.',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_volume_group'),",
            "    cfg.BoolOpt('sparse_logical_volumes',",
            "                default=False,",
            "                help='Create sparse logical volumes (with virtualsize)'",
            "                     ' if this flag is set to True.',",
            "                deprecated_group='DEFAULT',",
            "                deprecated_name='libvirt_sparse_logical_volumes'),",
            "    cfg.StrOpt('volume_clear',",
            "               default='zero',",
            "               help='Method used to wipe old volumes (valid options are: '",
            "                    'none, zero, shred)'),",
            "    cfg.IntOpt('volume_clear_size',",
            "               default=0,",
            "               help='Size in MiB to wipe at start of old volumes. 0 => all'),",
            "    cfg.StrOpt('images_rbd_pool',",
            "               default='rbd',",
            "               help='The RADOS pool in which rbd volumes are stored',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_rbd_pool'),",
            "    cfg.StrOpt('images_rbd_ceph_conf',",
            "               default='',  # default determined by librados",
            "               help='Path to the ceph configuration file to use',",
            "               deprecated_group='DEFAULT',",
            "               deprecated_name='libvirt_images_rbd_ceph_conf'),",
            "        ]",
            "",
            "CONF = cfg.CONF",
            "CONF.register_opts(__imagebackend_opts, 'libvirt')",
            "CONF.import_opt('image_cache_subdirectory_name', 'nova.virt.imagecache')",
            "CONF.import_opt('preallocate_images', 'nova.virt.driver')",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "",
            "@six.add_metaclass(abc.ABCMeta)",
            "class Image(object):",
            "",
            "    def __init__(self, source_type, driver_format, is_block_dev=False):",
            "        \"\"\"Image initialization.",
            "",
            "        :source_type: block or file",
            "        :driver_format: raw or qcow2",
            "        :is_block_dev:",
            "        \"\"\"",
            "        self.source_type = source_type",
            "        self.driver_format = driver_format",
            "        self.is_block_dev = is_block_dev",
            "        self.preallocate = False",
            "",
            "        # NOTE(dripton): We store lines of json (path, disk_format) in this",
            "        # file, for some image types, to prevent attacks based on changing the",
            "        # disk_format.",
            "        self.disk_info_path = None",
            "",
            "        # NOTE(mikal): We need a lock directory which is shared along with",
            "        # instance files, to cover the scenario where multiple compute nodes",
            "        # are trying to create a base file at the same time",
            "        self.lock_path = os.path.join(CONF.instances_path, 'locks')",
            "",
            "    @abc.abstractmethod",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        \"\"\"Create image from template.",
            "",
            "        Contains specific behavior for each image type.",
            "",
            "        :prepare_template: function, that creates template.",
            "        Should accept `target` argument.",
            "        :base: Template name",
            "        :size: Size of created image in bytes",
            "        \"\"\"",
            "        pass",
            "",
            "    def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode,",
            "            extra_specs, hypervisor_version):",
            "        \"\"\"Get `LibvirtConfigGuestDisk` filled for this image.",
            "",
            "        :disk_dev: Disk bus device name",
            "        :disk_bus: Disk bus type",
            "        :device_type: Device type for this image.",
            "        :cache_mode: Caching mode for this image",
            "        :extra_specs: Instance type extra specs dict.",
            "        \"\"\"",
            "        info = vconfig.LibvirtConfigGuestDisk()",
            "        info.source_type = self.source_type",
            "        info.source_device = device_type",
            "        info.target_bus = disk_bus",
            "        info.target_dev = disk_dev",
            "        info.driver_cache = cache_mode",
            "        info.driver_format = self.driver_format",
            "        driver_name = libvirt_utils.pick_disk_driver_name(hypervisor_version,",
            "                                                          self.is_block_dev)",
            "        info.driver_name = driver_name",
            "        info.source_path = self.path",
            "",
            "        tune_items = ['disk_read_bytes_sec', 'disk_read_iops_sec',",
            "            'disk_write_bytes_sec', 'disk_write_iops_sec',",
            "            'disk_total_bytes_sec', 'disk_total_iops_sec']",
            "        # Note(yaguang): Currently, the only tuning available is Block I/O",
            "        # throttling for qemu.",
            "        if self.source_type in ['file', 'block']:",
            "            for key, value in extra_specs.iteritems():",
            "                scope = key.split(':')",
            "                if len(scope) > 1 and scope[0] == 'quota':",
            "                    if scope[1] in tune_items:",
            "                        setattr(info, scope[1], value)",
            "        return info",
            "",
            "    def check_image_exists(self):",
            "        return os.path.exists(self.path)",
            "",
            "    def cache(self, fetch_func, filename, size=None, *args, **kwargs):",
            "        \"\"\"Creates image from template.",
            "",
            "        Ensures that template and image not already exists.",
            "        Ensures that base directory exists.",
            "        Synchronizes on template fetching.",
            "",
            "        :fetch_func: Function that creates the base image",
            "                     Should accept `target` argument.",
            "        :filename: Name of the file in the image directory",
            "        :size: Size of created image in bytes (optional)",
            "        \"\"\"",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def fetch_func_sync(target, *args, **kwargs):",
            "            fetch_func(target=target, *args, **kwargs)",
            "",
            "        base_dir = os.path.join(CONF.instances_path,",
            "                                CONF.image_cache_subdirectory_name)",
            "        if not os.path.exists(base_dir):",
            "            fileutils.ensure_tree(base_dir)",
            "        base = os.path.join(base_dir, filename)",
            "",
            "        if not self.check_image_exists() or not os.path.exists(base):",
            "            self.create_image(fetch_func_sync, base, size,",
            "                              *args, **kwargs)",
            "",
            "        if (size and self.preallocate and self._can_fallocate() and",
            "                os.access(self.path, os.W_OK)):",
            "            utils.execute('fallocate', '-n', '-l', size, self.path)",
            "",
            "    def _can_fallocate(self):",
            "        \"\"\"Check once per class, whether fallocate(1) is available,",
            "           and that the instances directory supports fallocate(2).",
            "        \"\"\"",
            "        can_fallocate = getattr(self.__class__, 'can_fallocate', None)",
            "        if can_fallocate is None:",
            "            _out, err = utils.trycmd('fallocate', '-n', '-l', '1',",
            "                                     self.path + '.fallocate_test')",
            "            fileutils.delete_if_exists(self.path + '.fallocate_test')",
            "            can_fallocate = not err",
            "            self.__class__.can_fallocate = can_fallocate",
            "            if not can_fallocate:",
            "                LOG.error(_('Unable to preallocate_images=%(imgs)s at path: '",
            "                            '%(path)s'), {'imgs': CONF.preallocate_images,",
            "                                           'path': self.path})",
            "        return can_fallocate",
            "",
            "    @staticmethod",
            "    def verify_base_size(base, size, base_size=0):",
            "        \"\"\"Check that the base image is not larger than size.",
            "           Since images can't be generally shrunk, enforce this",
            "           constraint taking account of virtual image size.",
            "        \"\"\"",
            "",
            "        # Note(pbrady): The size and min_disk parameters of a glance",
            "        #  image are checked against the instance size before the image",
            "        #  is even downloaded from glance, but currently min_disk is",
            "        #  adjustable and doesn't currently account for virtual disk size,",
            "        #  so we need this extra check here.",
            "        # NOTE(cfb): Having a flavor that sets the root size to 0 and having",
            "        #  nova effectively ignore that size and use the size of the",
            "        #  image is considered a feature at this time, not a bug.",
            "",
            "        if size is None:",
            "            return",
            "",
            "        if size and not base_size:",
            "            base_size = disk.get_disk_size(base)",
            "",
            "        if size < base_size:",
            "            msg = _('%(base)s virtual size %(base_size)s '",
            "                    'larger than flavor root disk size %(size)s')",
            "            LOG.error(msg % {'base': base,",
            "                              'base_size': base_size,",
            "                              'size': size})",
            "            raise exception.FlavorDiskTooSmall()",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        raise NotImplementedError()",
            "",
            "    def _get_driver_format(self):",
            "        return self.driver_format",
            "",
            "    def resolve_driver_format(self):",
            "        \"\"\"Return the driver format for self.path.",
            "",
            "        First checks self.disk_info_path for an entry.",
            "        If it's not there, calls self._get_driver_format(), and then",
            "        stores the result in self.disk_info_path",
            "",
            "        See https://bugs.launchpad.net/nova/+bug/1221190",
            "        \"\"\"",
            "        def _dict_from_line(line):",
            "            if not line:",
            "                return {}",
            "            try:",
            "                return jsonutils.loads(line)",
            "            except (TypeError, ValueError) as e:",
            "                msg = (_(\"Could not load line %(line)s, got error \"",
            "                        \"%(error)s\") %",
            "                        {'line': line, 'error': unicode(e)})",
            "                raise exception.InvalidDiskInfo(reason=msg)",
            "",
            "        @utils.synchronized(self.disk_info_path, external=False,",
            "                            lock_path=self.lock_path)",
            "        def write_to_disk_info_file():",
            "            # Use os.open to create it without group or world write permission.",
            "            fd = os.open(self.disk_info_path, os.O_RDONLY | os.O_CREAT, 0o644)",
            "            with os.fdopen(fd, \"r\") as disk_info_file:",
            "                line = disk_info_file.read().rstrip()",
            "                dct = _dict_from_line(line)",
            "",
            "            if self.path in dct:",
            "                msg = _(\"Attempted overwrite of an existing value.\")",
            "                raise exception.InvalidDiskInfo(reason=msg)",
            "            dct.update({self.path: driver_format})",
            "",
            "            tmp_path = self.disk_info_path + \".tmp\"",
            "            fd = os.open(tmp_path, os.O_WRONLY | os.O_CREAT, 0o644)",
            "            with os.fdopen(fd, \"w\") as tmp_file:",
            "                tmp_file.write('%s\\n' % jsonutils.dumps(dct))",
            "            os.rename(tmp_path, self.disk_info_path)",
            "",
            "        try:",
            "            if (self.disk_info_path is not None and",
            "                        os.path.exists(self.disk_info_path)):",
            "                with open(self.disk_info_path) as disk_info_file:",
            "                    line = disk_info_file.read().rstrip()",
            "                    dct = _dict_from_line(line)",
            "                    for path, driver_format in dct.iteritems():",
            "                        if path == self.path:",
            "                            return driver_format",
            "            driver_format = self._get_driver_format()",
            "            if self.disk_info_path is not None:",
            "                fileutils.ensure_tree(os.path.dirname(self.disk_info_path))",
            "                write_to_disk_info_file()",
            "        except OSError as e:",
            "            raise exception.DiskInfoReadWriteFail(reason=unicode(e))",
            "        return driver_format",
            "",
            "",
            "class Raw(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Raw, self).__init__(\"file\", \"raw\", is_block_dev=False)",
            "",
            "        self.path = (path or",
            "                     os.path.join(libvirt_utils.get_instance_path(instance),",
            "                                  disk_name))",
            "        self.preallocate = CONF.preallocate_images != 'none'",
            "        self.disk_info_path = os.path.join(os.path.dirname(self.path),",
            "                                           'disk.info')",
            "        self.correct_format()",
            "",
            "    def _get_driver_format(self):",
            "        data = images.qemu_img_info(self.path)",
            "        return data.file_format or 'raw'",
            "",
            "    def correct_format(self):",
            "        if os.path.exists(self.path):",
            "            self.driver_format = self.resolve_driver_format()",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def copy_raw_image(base, target, size):",
            "            libvirt_utils.copy_image(base, target)",
            "            if size:",
            "                # class Raw is misnamed, format may not be 'raw' in all cases",
            "                use_cow = self.driver_format == 'qcow2'",
            "                disk.extend(target, size, use_cow=use_cow)",
            "",
            "        generating = 'image_id' not in kwargs",
            "        if generating:",
            "            if not self.check_image_exists():",
            "                #Generating image in place",
            "                prepare_template(target=self.path, *args, **kwargs)",
            "        else:",
            "            if not os.path.exists(base):",
            "                prepare_template(target=base, max_size=size, *args, **kwargs)",
            "            self.verify_base_size(base, size)",
            "            if not os.path.exists(self.path):",
            "                with fileutils.remove_path_on_error(self.path):",
            "                    copy_raw_image(base, self.path, size)",
            "        self.correct_format()",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format)",
            "",
            "",
            "class Qcow2(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Qcow2, self).__init__(\"file\", \"qcow2\", is_block_dev=False)",
            "",
            "        self.path = (path or",
            "                     os.path.join(libvirt_utils.get_instance_path(instance),",
            "                                  disk_name))",
            "        self.preallocate = CONF.preallocate_images != 'none'",
            "        self.disk_info_path = os.path.join(os.path.dirname(self.path),",
            "                                           'disk.info')",
            "        self.resolve_driver_format()",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def copy_qcow2_image(base, target, size):",
            "            # TODO(pbrady): Consider copying the cow image here",
            "            # with preallocation=metadata set for performance reasons.",
            "            # This would be keyed on a 'preallocate_images' setting.",
            "            libvirt_utils.create_cow_image(base, target)",
            "            if size:",
            "                disk.extend(target, size, use_cow=True)",
            "",
            "        # Download the unmodified base image unless we already have a copy.",
            "        if not os.path.exists(base):",
            "            prepare_template(target=base, max_size=size, *args, **kwargs)",
            "        else:",
            "            self.verify_base_size(base, size)",
            "",
            "        legacy_backing_size = None",
            "        legacy_base = base",
            "",
            "        # Determine whether an existing qcow2 disk uses a legacy backing by",
            "        # actually looking at the image itself and parsing the output of the",
            "        # backing file it expects to be using.",
            "        if os.path.exists(self.path):",
            "            backing_path = libvirt_utils.get_disk_backing_file(self.path)",
            "            if backing_path is not None:",
            "                backing_file = os.path.basename(backing_path)",
            "                backing_parts = backing_file.rpartition('_')",
            "                if backing_file != backing_parts[-1] and \\",
            "                        backing_parts[-1].isdigit():",
            "                    legacy_backing_size = int(backing_parts[-1])",
            "                    legacy_base += '_%d' % legacy_backing_size",
            "                    legacy_backing_size *= units.Gi",
            "",
            "        # Create the legacy backing file if necessary.",
            "        if legacy_backing_size:",
            "            if not os.path.exists(legacy_base):",
            "                with fileutils.remove_path_on_error(legacy_base):",
            "                    libvirt_utils.copy_image(base, legacy_base)",
            "                    disk.extend(legacy_base, legacy_backing_size, use_cow=True)",
            "",
            "        if not os.path.exists(self.path):",
            "            with fileutils.remove_path_on_error(self.path):",
            "                copy_qcow2_image(base, self.path, size)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        libvirt_utils.extract_snapshot(self.path, 'qcow2',",
            "                                       target,",
            "                                       out_format)",
            "",
            "",
            "class Lvm(Image):",
            "    @staticmethod",
            "    def escape(filename):",
            "        return filename.replace('_', '__')",
            "",
            "    def __init__(self, instance=None, disk_name=None, path=None):",
            "        super(Lvm, self).__init__(\"block\", \"raw\", is_block_dev=True)",
            "",
            "        if path:",
            "            info = libvirt_utils.logical_volume_info(path)",
            "            self.vg = info['VG']",
            "            self.lv = info['LV']",
            "            self.path = path",
            "        else:",
            "            if not CONF.libvirt.images_volume_group:",
            "                raise RuntimeError(_('You should specify'",
            "                                     ' images_volume_group'",
            "                                     ' flag to use LVM images.'))",
            "            self.vg = CONF.libvirt.images_volume_group",
            "            self.lv = '%s_%s' % (instance['uuid'],",
            "                                 self.escape(disk_name))",
            "            self.path = os.path.join('/dev', self.vg, self.lv)",
            "",
            "        # TODO(pbrady): possibly deprecate libvirt.sparse_logical_volumes",
            "        # for the more general preallocate_images",
            "        self.sparse = CONF.libvirt.sparse_logical_volumes",
            "        self.preallocate = not self.sparse",
            "",
            "    def _can_fallocate(self):",
            "        return False",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        filename = os.path.split(base)[-1]",
            "",
            "        @utils.synchronized(filename, external=True, lock_path=self.lock_path)",
            "        def create_lvm_image(base, size):",
            "            base_size = disk.get_disk_size(base)",
            "            self.verify_base_size(base, size, base_size=base_size)",
            "            resize = size > base_size",
            "            size = size if resize else base_size",
            "            libvirt_utils.create_lvm_image(self.vg, self.lv,",
            "                                           size, sparse=self.sparse)",
            "            images.convert_image(base, self.path, 'raw', run_as_root=True)",
            "            if resize:",
            "                disk.resize2fs(self.path, run_as_root=True)",
            "",
            "        generated = 'ephemeral_size' in kwargs",
            "",
            "        #Generate images with specified size right on volume",
            "        if generated and size:",
            "            libvirt_utils.create_lvm_image(self.vg, self.lv,",
            "                                           size, sparse=self.sparse)",
            "            with self.remove_volume_on_error(self.path):",
            "                prepare_template(target=self.path, *args, **kwargs)",
            "        else:",
            "            if not os.path.exists(base):",
            "                prepare_template(target=base, max_size=size, *args, **kwargs)",
            "            with self.remove_volume_on_error(self.path):",
            "                create_lvm_image(base, size)",
            "",
            "    @contextlib.contextmanager",
            "    def remove_volume_on_error(self, path):",
            "        try:",
            "            yield",
            "        except Exception:",
            "            with excutils.save_and_reraise_exception():",
            "                libvirt_utils.remove_logical_volumes(path)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format,",
            "                             run_as_root=True)",
            "",
            "",
            "class RBDVolumeProxy(object):",
            "    \"\"\"Context manager for dealing with an existing rbd volume.",
            "",
            "    This handles connecting to rados and opening an ioctx automatically, and",
            "    otherwise acts like a librbd Image object.",
            "",
            "    The underlying librados client and ioctx can be accessed as the attributes",
            "    'client' and 'ioctx'.",
            "    \"\"\"",
            "    def __init__(self, driver, name, pool=None):",
            "        client, ioctx = driver._connect_to_rados(pool)",
            "        try:",
            "            self.volume = driver.rbd.Image(ioctx, str(name), snapshot=None)",
            "        except driver.rbd.Error:",
            "            LOG.exception(_(\"error opening rbd image %s\"), name)",
            "            driver._disconnect_from_rados(client, ioctx)",
            "            raise",
            "        self.driver = driver",
            "        self.client = client",
            "        self.ioctx = ioctx",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, type_, value, traceback):",
            "        try:",
            "            self.volume.close()",
            "        finally:",
            "            self.driver._disconnect_from_rados(self.client, self.ioctx)",
            "",
            "    def __getattr__(self, attrib):",
            "        return getattr(self.volume, attrib)",
            "",
            "",
            "def ascii_str(s):",
            "    \"\"\"Convert a string to ascii, or return None if the input is None.",
            "",
            "    This is useful when a parameter is None by default, or a string. LibRBD",
            "    only accepts ascii, hence the need for conversion.",
            "    \"\"\"",
            "    if s is None:",
            "        return s",
            "    return str(s)",
            "",
            "",
            "class Rbd(Image):",
            "    def __init__(self, instance=None, disk_name=None, path=None, **kwargs):",
            "        super(Rbd, self).__init__(\"block\", \"rbd\", is_block_dev=True)",
            "        if path:",
            "            try:",
            "                self.rbd_name = path.split('/')[1]",
            "            except IndexError:",
            "                raise exception.InvalidDevicePath(path=path)",
            "        else:",
            "            self.rbd_name = '%s_%s' % (instance['uuid'], disk_name)",
            "",
            "        if not CONF.libvirt.images_rbd_pool:",
            "            raise RuntimeError(_('You should specify'",
            "                                 ' images_rbd_pool'",
            "                                 ' flag to use rbd images.'))",
            "        self.pool = CONF.libvirt.images_rbd_pool",
            "        self.ceph_conf = ascii_str(CONF.libvirt.images_rbd_ceph_conf)",
            "        self.rbd_user = ascii_str(CONF.libvirt.rbd_user)",
            "        self.rbd = kwargs.get('rbd', rbd)",
            "        self.rados = kwargs.get('rados', rados)",
            "",
            "        self.path = 'rbd:%s/%s' % (self.pool, self.rbd_name)",
            "        if self.rbd_user:",
            "            self.path += ':id=' + self.rbd_user",
            "        if self.ceph_conf:",
            "            self.path += ':conf=' + self.ceph_conf",
            "",
            "    def _connect_to_rados(self, pool=None):",
            "        client = self.rados.Rados(rados_id=self.rbd_user,",
            "                                  conffile=self.ceph_conf)",
            "        try:",
            "            client.connect()",
            "            pool_to_open = str(pool or self.pool)",
            "            ioctx = client.open_ioctx(pool_to_open)",
            "            return client, ioctx",
            "        except self.rados.Error:",
            "            # shutdown cannot raise an exception",
            "            client.shutdown()",
            "            raise",
            "",
            "    def _disconnect_from_rados(self, client, ioctx):",
            "        # closing an ioctx cannot raise an exception",
            "        ioctx.close()",
            "        client.shutdown()",
            "",
            "    def _supports_layering(self):",
            "        return hasattr(self.rbd, 'RBD_FEATURE_LAYERING')",
            "",
            "    def _ceph_args(self):",
            "        args = []",
            "        if self.rbd_user:",
            "            args.extend(['--id', self.rbd_user])",
            "        if self.ceph_conf:",
            "            args.extend(['--conf', self.ceph_conf])",
            "        return args",
            "",
            "    def _get_mon_addrs(self):",
            "        args = ['ceph', 'mon', 'dump', '--format=json'] + self._ceph_args()",
            "        out, _ = utils.execute(*args)",
            "        lines = out.split('\\n')",
            "        if lines[0].startswith('dumped monmap epoch'):",
            "            lines = lines[1:]",
            "        monmap = jsonutils.loads('\\n'.join(lines))",
            "        addrs = [mon['addr'] for mon in monmap['mons']]",
            "        hosts = []",
            "        ports = []",
            "        for addr in addrs:",
            "            host_port = addr[:addr.rindex('/')]",
            "            host, port = host_port.rsplit(':', 1)",
            "            hosts.append(host.strip('[]'))",
            "            ports.append(port)",
            "        return hosts, ports",
            "",
            "    def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode,",
            "            extra_specs, hypervisor_version):",
            "        \"\"\"Get `LibvirtConfigGuestDisk` filled for this image.",
            "",
            "        :disk_dev: Disk bus device name",
            "        :disk_bus: Disk bus type",
            "        :device_type: Device type for this image.",
            "        :cache_mode: Caching mode for this image",
            "        :extra_specs: Instance type extra specs dict.",
            "        \"\"\"",
            "        info = vconfig.LibvirtConfigGuestDisk()",
            "",
            "        hosts, ports = self._get_mon_addrs()",
            "        info.device_type = device_type",
            "        info.driver_format = 'raw'",
            "        info.driver_cache = cache_mode",
            "        info.target_bus = disk_bus",
            "        info.target_dev = disk_dev",
            "        info.source_type = 'network'",
            "        info.source_protocol = 'rbd'",
            "        info.source_name = '%s/%s' % (self.pool, self.rbd_name)",
            "        info.source_hosts = hosts",
            "        info.source_ports = ports",
            "        auth_enabled = (CONF.libvirt.rbd_user is not None)",
            "        if CONF.libvirt.rbd_secret_uuid:",
            "            info.auth_secret_uuid = CONF.libvirt.rbd_secret_uuid",
            "            auth_enabled = True  # Force authentication locally",
            "            if CONF.libvirt.rbd_user:",
            "                info.auth_username = CONF.libvirt.rbd_user",
            "        if auth_enabled:",
            "            info.auth_secret_type = 'ceph'",
            "            info.auth_secret_uuid = CONF.libvirt.rbd_secret_uuid",
            "        return info",
            "",
            "    def _can_fallocate(self):",
            "        return False",
            "",
            "    def check_image_exists(self):",
            "        rbd_volumes = libvirt_utils.list_rbd_volumes(self.pool)",
            "        for vol in rbd_volumes:",
            "            if vol.startswith(self.rbd_name):",
            "                return True",
            "",
            "        return False",
            "",
            "    def _resize(self, volume_name, size):",
            "        size = int(size) * units.Ki",
            "",
            "        with RBDVolumeProxy(self, volume_name) as vol:",
            "            vol.resize(size)",
            "",
            "    def create_image(self, prepare_template, base, size, *args, **kwargs):",
            "        if self.rbd is None:",
            "            raise RuntimeError(_('rbd python libraries not found'))",
            "",
            "        if not os.path.exists(base):",
            "            prepare_template(target=base, max_size=size, *args, **kwargs)",
            "        else:",
            "            self.verify_base_size(base, size)",
            "",
            "        # keep using the command line import instead of librbd since it",
            "        # detects zeroes to preserve sparseness in the image",
            "        args = ['--pool', self.pool, base, self.rbd_name]",
            "        if self._supports_layering():",
            "            args += ['--new-format']",
            "        args += self._ceph_args()",
            "        libvirt_utils.import_rbd_image(*args)",
            "",
            "        base_size = disk.get_disk_size(base)",
            "",
            "        if size and size > base_size:",
            "            self._resize(self.rbd_name, size)",
            "",
            "    def snapshot_extract(self, target, out_format):",
            "        images.convert_image(self.path, target, out_format)",
            "",
            "",
            "class Backend(object):",
            "    def __init__(self, use_cow):",
            "        self.BACKEND = {",
            "            'raw': Raw,",
            "            'qcow2': Qcow2,",
            "            'lvm': Lvm,",
            "            'rbd': Rbd,",
            "            'default': Qcow2 if use_cow else Raw",
            "        }",
            "",
            "    def backend(self, image_type=None):",
            "        if not image_type:",
            "            image_type = CONF.libvirt.images_type",
            "        image = self.BACKEND.get(image_type)",
            "        if not image:",
            "            raise RuntimeError(_('Unknown image_type=%s') % image_type)",
            "        return image",
            "",
            "    def image(self, instance, disk_name, image_type=None):",
            "        \"\"\"Constructs image for selected backend",
            "",
            "        :instance: Instance name.",
            "        :name: Image name.",
            "        :image_type: Image type.",
            "        Optional, is CONF.libvirt.images_type by default.",
            "        \"\"\"",
            "        backend = self.backend(image_type)",
            "        return backend(instance=instance, disk_name=disk_name)",
            "",
            "    def snapshot(self, disk_path, image_type=None):",
            "        \"\"\"Returns snapshot for given image",
            "",
            "        :path: path to image",
            "        :image_type: type of image",
            "        \"\"\"",
            "        backend = self.backend(image_type)",
            "        return backend(path=disk_path)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "275": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "276": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "279": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "280": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "281": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "282": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "283": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "284": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "285": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "286": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "287": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ],
            "288": [
                "Image",
                "resolve_driver_format",
                "write_to_disk_info_file"
            ]
        },
        "addLocation": []
    }
}