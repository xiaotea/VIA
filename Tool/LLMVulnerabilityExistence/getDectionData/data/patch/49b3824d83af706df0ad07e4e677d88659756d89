{
    "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "               out_type=dtypes.qint8))"
            },
            "1": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 207,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 208,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+class QuantizedAddOpTest(test_util.TensorFlowTestCase):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+  @test_util.run_in_graph_and_eager_modes"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+  def test_invalid_inputs(self):"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+    x = constant_op.constant("
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 217,
                "PatchRowcode": "+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+                                \"must be rank 0\"):"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+      self.evaluate("
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+          math_ops.quantized_add("
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+              x=x,"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+              y=y,"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+              min_x=[],"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 224,
                "PatchRowcode": "+              max_x=1.0,"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 225,
                "PatchRowcode": "+              min_y=0.0,"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+              max_y=1.0,"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 227,
                "PatchRowcode": "+              Toutput=dtypes.qint32))"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 229,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+class QuantizedReluOpTest(test_util.TensorFlowTestCase):"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+  @test_util.run_in_graph_and_eager_modes"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+  def test_invalid_inputs(self):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+    inputs = constant_op.constant("
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 236,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+                                \"must be rank 0\"):"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+      self.evaluate("
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+          nn_ops.quantized_relu("
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+              features=inputs,"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+              min_features=[],"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+              max_features=127.0,"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+              out_type=dtypes.quint8))"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+  @test_util.run_in_graph_and_eager_modes"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+  def test_invalid_inputs(self):"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+    inputs = constant_op.constant("
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+                                \"must be rank 0\"):"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+      self.evaluate("
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+          nn_ops.quantized_relu6("
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+              features=inputs,"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+              min_features=[],"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+              max_features=127.0,"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+              out_type=dtypes.quint8))"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+"
            },
            "58": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 264,
                "PatchRowcode": " if __name__ == \"__main__\":"
            },
            "59": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "   googletest.main()"
            }
        },
        "frontPatchFile": [
            "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for tf.quantize ops.\"\"\"",
            "import numpy as np",
            "",
            "from tensorflow.python.framework import constant_op",
            "from tensorflow.python.framework import dtypes",
            "from tensorflow.python.framework import errors",
            "from tensorflow.python.framework import test_util",
            "from tensorflow.python.ops import array_ops",
            "from tensorflow.python.ops import math_ops",
            "from tensorflow.python.ops import nn_ops",
            "from tensorflow.python.platform import googletest",
            "",
            "",
            "class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars(",
            "              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars(",
            "              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
            "",
            "",
            "class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 1\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[[0.0]], max=[1.0]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"Dimensions must be equal|incorrect size\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 1\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[1.0], max=[[1.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"Dimensions must be equal|incorrect size\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
            "",
            "",
            "class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
            "    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=[],",
            "              max_input=1.0,",
            "              min_bias=0.0,",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=[],",
            "              min_bias=0.0,",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=1.0,",
            "              min_bias=[],",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=1.0,",
            "              min_bias=0.0,",
            "              max_bias=[],",
            "              out_type=dtypes.qint32))",
            "",
            "",
            "class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.quantized_instance_norm(",
            "              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.quantized_instance_norm(",
            "              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
            "",
            "",
            "class RequantizeOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=[],",
            "              input_max=1.0,",
            "              requested_output_min=0.0,",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=[],",
            "              requested_output_min=0.0,",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=1.0,",
            "              requested_output_min=[],",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=1.0,",
            "              requested_output_min=0.0,",
            "              requested_output_max=[],",
            "              out_type=dtypes.qint8))",
            "",
            "",
            "if __name__ == \"__main__\":",
            "  googletest.main()"
        ],
        "afterPatchFile": [
            "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for tf.quantize ops.\"\"\"",
            "import numpy as np",
            "",
            "from tensorflow.python.framework import constant_op",
            "from tensorflow.python.framework import dtypes",
            "from tensorflow.python.framework import errors",
            "from tensorflow.python.framework import test_util",
            "from tensorflow.python.ops import array_ops",
            "from tensorflow.python.ops import math_ops",
            "from tensorflow.python.ops import nn_ops",
            "from tensorflow.python.platform import googletest",
            "",
            "",
            "class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars(",
            "              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars(",
            "              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
            "",
            "",
            "class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 1\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[[0.0]], max=[1.0]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"Dimensions must be equal|incorrect size\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 1\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[1.0], max=[[1.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"Dimensions must be equal|incorrect size\"):",
            "      self.evaluate(",
            "          array_ops.fake_quant_with_min_max_vars_per_channel(",
            "              inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
            "",
            "",
            "class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
            "    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=[],",
            "              max_input=1.0,",
            "              min_bias=0.0,",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=[],",
            "              min_bias=0.0,",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=1.0,",
            "              min_bias=[],",
            "              max_bias=1.0,",
            "              out_type=dtypes.qint32))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_bias_add(",
            "              input=inputs,",
            "              bias=bias,",
            "              min_input=0.0,",
            "              max_input=1.0,",
            "              min_bias=0.0,",
            "              max_bias=[],",
            "              out_type=dtypes.qint32))",
            "",
            "",
            "class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.quantized_instance_norm(",
            "              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          array_ops.quantized_instance_norm(",
            "              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
            "",
            "",
            "class RequantizeOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=[],",
            "              input_max=1.0,",
            "              requested_output_min=0.0,",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=[],",
            "              requested_output_min=0.0,",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=1.0,",
            "              requested_output_min=[],",
            "              requested_output_max=1.0,",
            "              out_type=dtypes.qint8))",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.requantize(",
            "              input=inputs,",
            "              input_min=0.0,",
            "              input_max=1.0,",
            "              requested_output_min=0.0,",
            "              requested_output_max=[],",
            "              out_type=dtypes.qint8))",
            "",
            "",
            "class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    x = constant_op.constant(",
            "        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
            "    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          math_ops.quantized_add(",
            "              x=x,",
            "              y=y,",
            "              min_x=[],",
            "              max_x=1.0,",
            "              min_y=0.0,",
            "              max_y=1.0,",
            "              Toutput=dtypes.qint32))",
            "",
            "",
            "class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_relu(",
            "              features=inputs,",
            "              min_features=[],",
            "              max_features=127.0,",
            "              out_type=dtypes.quint8))",
            "",
            "",
            "class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
            "",
            "  @test_util.run_in_graph_and_eager_modes",
            "  def test_invalid_inputs(self):",
            "    inputs = constant_op.constant(",
            "        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
            "",
            "    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
            "                                \"must be rank 0\"):",
            "      self.evaluate(",
            "          nn_ops.quantized_relu6(",
            "              features=inputs,",
            "              min_features=[],",
            "              max_features=127.0,",
            "              out_type=dtypes.quint8))",
            "",
            "",
            "if __name__ == \"__main__\":",
            "  googletest.main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    }
}