{
    "lib/ansible/cli/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 652,
                "afterPatchRowNumber": 652,
                "PatchRowcode": "                 ansible_versions[counter] = 0"
            },
            "1": {
                "beforePatchRowNumber": 653,
                "afterPatchRowNumber": 653,
                "PatchRowcode": "             try:"
            },
            "2": {
                "beforePatchRowNumber": 654,
                "afterPatchRowNumber": 654,
                "PatchRowcode": "                 ansible_versions[counter] = int(ansible_versions[counter])"
            },
            "3": {
                "beforePatchRowNumber": 655,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            except:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 655,
                "PatchRowcode": "+            except Exception:"
            },
            "5": {
                "beforePatchRowNumber": 656,
                "afterPatchRowNumber": 656,
                "PatchRowcode": "                 pass"
            },
            "6": {
                "beforePatchRowNumber": 657,
                "afterPatchRowNumber": 657,
                "PatchRowcode": "         if len(ansible_versions) < 3:"
            },
            "7": {
                "beforePatchRowNumber": 658,
                "afterPatchRowNumber": 658,
                "PatchRowcode": "             for counter in range(len(ansible_versions), 3):"
            },
            "8": {
                "beforePatchRowNumber": 793,
                "afterPatchRowNumber": 793,
                "PatchRowcode": "         # the code, ensuring a consistent view of global variables"
            },
            "9": {
                "beforePatchRowNumber": 794,
                "afterPatchRowNumber": 794,
                "PatchRowcode": "         variable_manager = VariableManager(loader=loader, inventory=inventory)"
            },
            "10": {
                "beforePatchRowNumber": 795,
                "afterPatchRowNumber": 795,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 796,
                "PatchRowcode": "+        if hasattr(options, 'basedir'):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 797,
                "PatchRowcode": "+            if options.basedir:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 798,
                "PatchRowcode": "+                variable_manager.safe_basedir = True"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 799,
                "PatchRowcode": "+        else:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 800,
                "PatchRowcode": "+            variable_manager.safe_basedir = True"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 801,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": 796,
                "afterPatchRowNumber": 802,
                "PatchRowcode": "         # load vars from cli options"
            },
            "18": {
                "beforePatchRowNumber": 797,
                "afterPatchRowNumber": 803,
                "PatchRowcode": "         variable_manager.extra_vars = load_extra_vars(loader=loader, options=options)"
            },
            "19": {
                "beforePatchRowNumber": 798,
                "afterPatchRowNumber": 804,
                "PatchRowcode": "         variable_manager.options_vars = load_options_vars(options, CLI.version_info(gitinfo=False))"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# (c) 2016, Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import getpass",
            "import operator",
            "import optparse",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import time",
            "import yaml",
            "",
            "from abc import ABCMeta, abstractmethod",
            "",
            "import ansible",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleOptionsError, AnsibleError",
            "from ansible.inventory.manager import InventoryManager",
            "from ansible.module_utils.six import with_metaclass, string_types",
            "from ansible.module_utils._text import to_bytes, to_text",
            "from ansible.parsing.dataloader import DataLoader",
            "from ansible.release import __version__",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.vars import load_extra_vars, load_options_vars",
            "from ansible.vars.manager import VariableManager",
            "from ansible.parsing.vault import PromptVaultSecret, get_file_vault_secret",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "class SortedOptParser(optparse.OptionParser):",
            "    '''Optparser which sorts the options by opt before outputting --help'''",
            "",
            "    def format_help(self, formatter=None, epilog=None):",
            "        self.option_list.sort(key=operator.methodcaller('get_opt_string'))",
            "        return optparse.OptionParser.format_help(self, formatter=None)",
            "",
            "",
            "# Note: Inherit from SortedOptParser so that we get our format_help method",
            "class InvalidOptsParser(SortedOptParser):",
            "    '''Ignore invalid options.",
            "",
            "    Meant for the special case where we need to take care of help and version",
            "    but may not know the full range of options yet.  (See it in use in set_action)",
            "    '''",
            "    def __init__(self, parser):",
            "        # Since this is special purposed to just handle help and version, we",
            "        # take a pre-existing option parser here and set our options from",
            "        # that.  This allows us to give accurate help based on the given",
            "        # option parser.",
            "        SortedOptParser.__init__(self, usage=parser.usage,",
            "                                 option_list=parser.option_list,",
            "                                 option_class=parser.option_class,",
            "                                 conflict_handler=parser.conflict_handler,",
            "                                 description=parser.description,",
            "                                 formatter=parser.formatter,",
            "                                 add_help_option=False,",
            "                                 prog=parser.prog,",
            "                                 epilog=parser.epilog)",
            "        self.version = parser.version",
            "",
            "    def _process_long_opt(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_long_opt(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "    def _process_short_opts(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_short_opts(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "",
            "class CLI(with_metaclass(ABCMeta, object)):",
            "    ''' code behind bin/ansible* programs '''",
            "",
            "    VALID_ACTIONS = []",
            "",
            "    _ITALIC = re.compile(r\"I\\(([^)]+)\\)\")",
            "    _BOLD = re.compile(r\"B\\(([^)]+)\\)\")",
            "    _MODULE = re.compile(r\"M\\(([^)]+)\\)\")",
            "    _URL = re.compile(r\"U\\(([^)]+)\\)\")",
            "    _CONST = re.compile(r\"C\\(([^)]+)\\)\")",
            "",
            "    PAGER = 'less'",
            "",
            "    # -F (quit-if-one-screen) -R (allow raw ansi control chars)",
            "    # -S (chop long lines) -X (disable termcap init and de-init)",
            "    LESS_OPTS = 'FRSX'",
            "    SKIP_INVENTORY_DEFAULTS = False",
            "",
            "    def __init__(self, args, callback=None):",
            "        \"\"\"",
            "        Base init method for all command line programs",
            "        \"\"\"",
            "",
            "        self.args = args",
            "        self.options = None",
            "        self.parser = None",
            "        self.action = None",
            "        self.callback = callback",
            "",
            "    def set_action(self):",
            "        \"\"\"",
            "        Get the action the user wants to execute from the sys argv list.",
            "        \"\"\"",
            "        for i in range(0, len(self.args)):",
            "            arg = self.args[i]",
            "            if arg in self.VALID_ACTIONS:",
            "                self.action = arg",
            "                del self.args[i]",
            "                break",
            "",
            "        if not self.action:",
            "            # if we're asked for help or version, we don't need an action.",
            "            # have to use a special purpose Option Parser to figure that out as",
            "            # the standard OptionParser throws an error for unknown options and",
            "            # without knowing action, we only know of a subset of the options",
            "            # that could be legal for this command",
            "            tmp_parser = InvalidOptsParser(self.parser)",
            "            tmp_options, tmp_args = tmp_parser.parse_args(self.args)",
            "            if not(hasattr(tmp_options, 'help') and tmp_options.help) or (hasattr(tmp_options, 'version') and tmp_options.version):",
            "                raise AnsibleOptionsError(\"Missing required action\")",
            "",
            "    def execute(self):",
            "        \"\"\"",
            "        Actually runs a child defined method using the execute_<action> pattern",
            "        \"\"\"",
            "        fn = getattr(self, \"execute_%s\" % self.action)",
            "        fn()",
            "",
            "    @abstractmethod",
            "    def run(self):",
            "        \"\"\"Run the ansible command",
            "",
            "        Subclasses must implement this method.  It does the actual work of",
            "        running an Ansible command.",
            "        \"\"\"",
            "",
            "        display.vv(to_text(self.parser.get_version()))",
            "",
            "        if C.CONFIG_FILE:",
            "            display.v(u\"Using %s as config file\" % to_text(C.CONFIG_FILE))",
            "        else:",
            "            display.v(u\"No config file found; using defaults\")",
            "",
            "        # warn about deprecated config options",
            "        for deprecated in C.config.DEPRECATED:",
            "            name = deprecated[0]",
            "            why = deprecated[1]['why']",
            "            if 'alternative' in deprecated[1]:",
            "                alt = ', use %s instead' % deprecated[1]['alternative']",
            "            else:",
            "                alt = ''",
            "            ver = deprecated[1]['version']",
            "            display.deprecated(\"%s option, %s %s\" % (name, why, alt), version=ver)",
            "",
            "        # warn about typing issues with configuration entries",
            "        for unable in C.config.UNABLE:",
            "            display.warning(\"Unable to set correct type for configuration entry: %s\" % unable)",
            "",
            "    @staticmethod",
            "    def split_vault_id(vault_id):",
            "        # return (before_@, after_@)",
            "        # if no @, return whole string as after_",
            "        if '@' not in vault_id:",
            "            return (None, vault_id)",
            "",
            "        parts = vault_id.split('@', 1)",
            "        ret = tuple(parts)",
            "        return ret",
            "",
            "    @staticmethod",
            "    def build_vault_ids(vault_ids, vault_password_files=None,",
            "                        ask_vault_pass=None, create_new_password=None,",
            "                        auto_prompt=True):",
            "        vault_password_files = vault_password_files or []",
            "        vault_ids = vault_ids or []",
            "",
            "        # convert vault_password_files into vault_ids slugs",
            "        for password_file in vault_password_files:",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, password_file)",
            "",
            "            # note this makes --vault-id higher precendence than --vault-password-file",
            "            # if we want to intertwingle them in order probably need a cli callback to populate vault_ids",
            "            # used by --vault-id and --vault-password-file",
            "            vault_ids.append(id_slug)",
            "",
            "        # if an action needs an encrypt password (create_new_password=True) and we dont",
            "        # have other secrets setup, then automatically add a password prompt as well.",
            "        # prompts cant/shouldnt work without a tty, so dont add prompt secrets",
            "        if ask_vault_pass or (not vault_ids and auto_prompt):",
            "",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, u'prompt_ask_vault_pass')",
            "            vault_ids.append(id_slug)",
            "",
            "        return vault_ids",
            "",
            "    # TODO: remove the now unused args",
            "    @staticmethod",
            "    def setup_vault_secrets(loader, vault_ids, vault_password_files=None,",
            "                            ask_vault_pass=None, create_new_password=False,",
            "                            auto_prompt=True):",
            "        # list of tuples",
            "        vault_secrets = []",
            "",
            "        # Depending on the vault_id value (including how --ask-vault-pass / --vault-password-file create a vault_id)",
            "        # we need to show different prompts. This is for compat with older Towers that expect a",
            "        # certain vault password prompt format, so 'promp_ask_vault_pass' vault_id gets the old format.",
            "        prompt_formats = {}",
            "",
            "        # If there are configured default vault identities, they are considered 'first'",
            "        # so we prepend them to vault_ids (from cli) here",
            "",
            "        vault_password_files = vault_password_files or []",
            "        if C.DEFAULT_VAULT_PASSWORD_FILE:",
            "            vault_password_files.append(C.DEFAULT_VAULT_PASSWORD_FILE)",
            "",
            "        if create_new_password:",
            "            prompt_formats['prompt'] = ['New vault password (%(vault_id)s): ',",
            "                                        'Confirm vew vault password (%(vault_id)s): ']",
            "            # 2.3 format prompts for --ask-vault-pass",
            "            prompt_formats['prompt_ask_vault_pass'] = ['New Vault password: ',",
            "                                                       'Confirm New Vault password: ']",
            "        else:",
            "            prompt_formats['prompt'] = ['Vault password (%(vault_id)s): ']",
            "            # The format when we use just --ask-vault-pass needs to match 'Vault password:\\s*?$'",
            "            prompt_formats['prompt_ask_vault_pass'] = ['Vault password: ']",
            "",
            "        vault_ids = CLI.build_vault_ids(vault_ids,",
            "                                        vault_password_files,",
            "                                        ask_vault_pass,",
            "                                        create_new_password,",
            "                                        auto_prompt=auto_prompt)",
            "",
            "        for vault_id_slug in vault_ids:",
            "            vault_id_name, vault_id_value = CLI.split_vault_id(vault_id_slug)",
            "            if vault_id_value in ['prompt', 'prompt_ask_vault_pass']:",
            "",
            "                # --vault-id some_name@prompt_ask_vault_pass --vault-id other_name@prompt_ask_vault_pass will be a little",
            "                # confusing since it will use the old format without the vault id in the prompt",
            "                built_vault_id = vault_id_name or C.DEFAULT_VAULT_IDENTITY",
            "",
            "                # choose the prompt based on --vault-id=prompt or --ask-vault-pass. --ask-vault-pass",
            "                # always gets the old format for Tower compatibility.",
            "                # ie, we used --ask-vault-pass, so we need to use the old vault password prompt",
            "                # format since Tower needs to match on that format.",
            "                prompted_vault_secret = PromptVaultSecret(prompt_formats=prompt_formats[vault_id_value],",
            "                                                          vault_id=built_vault_id)",
            "",
            "                # a empty or invalid password from the prompt will warn and continue to the next",
            "                # without erroring globablly",
            "                try:",
            "                    prompted_vault_secret.load()",
            "                except AnsibleError as exc:",
            "                    display.warning('Error in vault password prompt (%s): %s' % (vault_id_name, exc))",
            "                    raise",
            "",
            "                vault_secrets.append((built_vault_id, prompted_vault_secret))",
            "",
            "                # update loader with new secrets incrementally, so we can load a vault password",
            "                # that is encrypted with a vault secret provided earlier",
            "                loader.set_vault_secrets(vault_secrets)",
            "                continue",
            "",
            "            # assuming anything else is a password file",
            "            display.vvvvv('Reading vault password file: %s' % vault_id_value)",
            "            # read vault_pass from a file",
            "            file_vault_secret = get_file_vault_secret(filename=vault_id_value,",
            "                                                      vault_id_name=vault_id_name,",
            "                                                      loader=loader)",
            "",
            "            # an invalid password file will error globally",
            "            try:",
            "                file_vault_secret.load()",
            "            except AnsibleError as exc:",
            "                display.warning('Error in vault password file loading (%s): %s' % (vault_id_name, exc))",
            "                raise",
            "",
            "            if vault_id_name:",
            "                vault_secrets.append((vault_id_name, file_vault_secret))",
            "            else:",
            "                vault_secrets.append((C.DEFAULT_VAULT_IDENTITY, file_vault_secret))",
            "",
            "            # update loader with as-yet-known vault secrets",
            "            loader.set_vault_secrets(vault_secrets)",
            "",
            "        return vault_secrets",
            "",
            "    def ask_passwords(self):",
            "        ''' prompt for connection and become passwords if needed '''",
            "",
            "        op = self.options",
            "        sshpass = None",
            "        becomepass = None",
            "        become_prompt = ''",
            "",
            "        try:",
            "            if op.ask_pass:",
            "                sshpass = getpass.getpass(prompt=\"SSH password: \")",
            "                become_prompt = \"%s password[defaults to SSH password]: \" % op.become_method.upper()",
            "                if sshpass:",
            "                    sshpass = to_bytes(sshpass, errors='strict', nonstring='simplerepr')",
            "            else:",
            "                become_prompt = \"%s password: \" % op.become_method.upper()",
            "",
            "            if op.become_ask_pass:",
            "                becomepass = getpass.getpass(prompt=become_prompt)",
            "                if op.ask_pass and becomepass == '':",
            "                    becomepass = sshpass",
            "                if becomepass:",
            "                    becomepass = to_bytes(becomepass)",
            "        except EOFError:",
            "            pass",
            "",
            "        return (sshpass, becomepass)",
            "",
            "    def normalize_become_options(self):",
            "        ''' this keeps backwards compatibility with sudo/su self.options '''",
            "        self.options.become_ask_pass = self.options.become_ask_pass or self.options.ask_sudo_pass or self.options.ask_su_pass or C.DEFAULT_BECOME_ASK_PASS",
            "        self.options.become_user = self.options.become_user or self.options.sudo_user or self.options.su_user or C.DEFAULT_BECOME_USER",
            "",
            "        def _dep(which):",
            "            display.deprecated('The %s command line option has been deprecated in favor of the \"become\" command line arguments' % which, '2.6')",
            "",
            "        if self.options.become:",
            "            pass",
            "        elif self.options.sudo:",
            "            self.options.become = True",
            "            self.options.become_method = 'sudo'",
            "            _dep('sudo')",
            "        elif self.options.su:",
            "            self.options.become = True",
            "            self.options.become_method = 'su'",
            "            _dep('su')",
            "",
            "        # other deprecations:",
            "        if self.options.ask_sudo_pass or self.options.sudo_user:",
            "            _dep('sudo')",
            "        if self.options.ask_su_pass or self.options.su_user:",
            "            _dep('su')",
            "",
            "    def validate_conflicts(self, vault_opts=False, runas_opts=False, fork_opts=False):",
            "        ''' check for conflicting options '''",
            "",
            "        op = self.options",
            "",
            "        if vault_opts:",
            "            # Check for vault related conflicts",
            "            if (op.ask_vault_pass and op.vault_password_files):",
            "                self.parser.error(\"--ask-vault-pass and --vault-password-file are mutually exclusive\")",
            "",
            "        if runas_opts:",
            "            # Check for privilege escalation conflicts",
            "            if ((op.su or op.su_user) and (op.sudo or op.sudo_user) or",
            "                    (op.su or op.su_user) and (op.become or op.become_user) or",
            "                    (op.sudo or op.sudo_user) and (op.become or op.become_user)):",
            "",
            "                self.parser.error(\"Sudo arguments ('--sudo', '--sudo-user', and '--ask-sudo-pass') and su arguments ('--su', '--su-user', and '--ask-su-pass') \"",
            "                                  \"and become arguments ('--become', '--become-user', and '--ask-become-pass') are exclusive of each other\")",
            "",
            "        if fork_opts:",
            "            if op.forks < 1:",
            "                self.parser.error(\"The number of processes (--forks) must be >= 1\")",
            "",
            "    @staticmethod",
            "    def unfrack_paths(option, opt, value, parser):",
            "        paths = getattr(parser.values, option.dest)",
            "        if paths is None:",
            "            paths = []",
            "",
            "        if isinstance(value, string_types):",
            "            paths[:0] = [unfrackpath(x) for x in value.split(os.pathsep) if x]",
            "        elif isinstance(value, list):",
            "            paths[:0] = [unfrackpath(x) for x in value if x]",
            "        else:",
            "            pass  # FIXME: should we raise options error?",
            "",
            "        setattr(parser.values, option.dest, paths)",
            "",
            "    @staticmethod",
            "    def unfrack_path(option, opt, value, parser):",
            "        if value != '-':",
            "            setattr(parser.values, option.dest, unfrackpath(value))",
            "        else:",
            "            setattr(parser.values, option.dest, value)",
            "",
            "    @staticmethod",
            "    def base_parser(usage=\"\", output_opts=False, runas_opts=False, meta_opts=False, runtask_opts=False, vault_opts=False, module_opts=False,",
            "                    async_opts=False, connect_opts=False, subset_opts=False, check_opts=False, inventory_opts=False, epilog=None, fork_opts=False,",
            "                    runas_prompt_opts=False, desc=None, vault_rekey_opts=False):",
            "        ''' create an options parser for most ansible scripts '''",
            "",
            "        # base opts",
            "        parser = SortedOptParser(usage, version=CLI.version(\"%prog\"), description=desc, epilog=epilog)",
            "        parser.add_option('-v', '--verbose', dest='verbosity', default=C.DEFAULT_VERBOSITY, action=\"count\",",
            "                          help=\"verbose mode (-vvv for more, -vvvv to enable connection debugging)\")",
            "",
            "        if inventory_opts:",
            "            parser.add_option('-i', '--inventory', '--inventory-file', dest='inventory', action=\"append\",",
            "                              help=\"specify inventory host path or comma separated host list. --inventory-file is deprecated\")",
            "            parser.add_option('--list-hosts', dest='listhosts', action='store_true',",
            "                              help='outputs a list of matching hosts; does not execute anything else')",
            "            parser.add_option('-l', '--limit', default=C.DEFAULT_SUBSET, dest='subset',",
            "                              help='further limit selected hosts to an additional pattern')",
            "",
            "        if module_opts:",
            "            parser.add_option('-M', '--module-path', dest='module_path', default=None,",
            "                              help=\"prepend colon-separated path(s) to module library (default=%s)\" % C.DEFAULT_MODULE_PATH,",
            "                              action=\"callback\", callback=CLI.unfrack_paths, type='str')",
            "        if runtask_opts:",
            "            parser.add_option('-e', '--extra-vars', dest=\"extra_vars\", action=\"append\",",
            "                              help=\"set additional variables as key=value or YAML/JSON, if filename prepend with @\", default=[])",
            "",
            "        if fork_opts:",
            "            parser.add_option('-f', '--forks', dest='forks', default=C.DEFAULT_FORKS, type='int',",
            "                              help=\"specify number of parallel processes to use (default=%s)\" % C.DEFAULT_FORKS)",
            "",
            "        if vault_opts:",
            "            parser.add_option('--ask-vault-pass', default=C.DEFAULT_ASK_VAULT_PASS, dest='ask_vault_pass', action='store_true',",
            "                              help='ask for vault password')",
            "            parser.add_option('--vault-password-file', default=[], dest='vault_password_files',",
            "                              help=\"vault password file\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--vault-id', default=[], dest='vault_ids', action='append', type='string',",
            "                              help='the vault identity to use')",
            "",
            "        if vault_rekey_opts:",
            "            parser.add_option('--new-vault-password-file', default=[], dest='new_vault_password_files',",
            "                              help=\"new vault password file for rekey\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--new-vault-id', default=None, dest='new_vault_id', type='string',",
            "                              help='the new vault identity to use for rekey')",
            "",
            "        if subset_opts:",
            "            parser.add_option('-t', '--tags', dest='tags', default=[], action='append',",
            "                              help=\"only run plays and tasks tagged with these values\")",
            "            parser.add_option('--skip-tags', dest='skip_tags', default=[], action='append',",
            "                              help=\"only run plays and tasks whose tags do not match these values\")",
            "",
            "        if output_opts:",
            "            parser.add_option('-o', '--one-line', dest='one_line', action='store_true',",
            "                              help='condense output')",
            "            parser.add_option('-t', '--tree', dest='tree', default=None,",
            "                              help='log output to this directory')",
            "",
            "        if connect_opts:",
            "            connect_group = optparse.OptionGroup(parser, \"Connection Options\", \"control as whom and how to connect to hosts\")",
            "            connect_group.add_option('-k', '--ask-pass', default=C.DEFAULT_ASK_PASS, dest='ask_pass', action='store_true',",
            "                                     help='ask for connection password')",
            "            connect_group.add_option('--private-key', '--key-file', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',",
            "                                     help='use this file to authenticate the connection', action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            connect_group.add_option('-u', '--user', default=C.DEFAULT_REMOTE_USER, dest='remote_user',",
            "                                     help='connect as this user (default=%s)' % C.DEFAULT_REMOTE_USER)",
            "            connect_group.add_option('-c', '--connection', dest='connection', default=C.DEFAULT_TRANSPORT,",
            "                                     help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)",
            "            connect_group.add_option('-T', '--timeout', default=C.DEFAULT_TIMEOUT, type='int', dest='timeout',",
            "                                     help=\"override the connection timeout in seconds (default=%s)\" % C.DEFAULT_TIMEOUT)",
            "            connect_group.add_option('--ssh-common-args', default='', dest='ssh_common_args',",
            "                                     help=\"specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand)\")",
            "            connect_group.add_option('--sftp-extra-args', default='', dest='sftp_extra_args',",
            "                                     help=\"specify extra arguments to pass to sftp only (e.g. -f, -l)\")",
            "            connect_group.add_option('--scp-extra-args', default='', dest='scp_extra_args',",
            "                                     help=\"specify extra arguments to pass to scp only (e.g. -l)\")",
            "            connect_group.add_option('--ssh-extra-args', default='', dest='ssh_extra_args',",
            "                                     help=\"specify extra arguments to pass to ssh only (e.g. -R)\")",
            "",
            "            parser.add_option_group(connect_group)",
            "",
            "        runas_group = None",
            "        rg = optparse.OptionGroup(parser, \"Privilege Escalation Options\", \"control how and which user you become as on target hosts\")",
            "        if runas_opts:",
            "            runas_group = rg",
            "            # priv user defaults to root later on to enable detecting when this option was given here",
            "            runas_group.add_option(\"-s\", \"--sudo\", default=C.DEFAULT_SUDO, action=\"store_true\", dest='sudo',",
            "                                   help=\"run operations with sudo (nopasswd) (deprecated, use become)\")",
            "            runas_group.add_option('-U', '--sudo-user', dest='sudo_user', default=None,",
            "                                   help='desired sudo user (default=root) (deprecated, use become)')",
            "            runas_group.add_option('-S', '--su', default=C.DEFAULT_SU, action='store_true',",
            "                                   help='run operations with su (deprecated, use become)')",
            "            runas_group.add_option('-R', '--su-user', default=None,",
            "                                   help='run operations with su as this user (default=%s) (deprecated, use become)' % C.DEFAULT_SU_USER)",
            "",
            "            # consolidated privilege escalation (become)",
            "            runas_group.add_option(\"-b\", \"--become\", default=C.DEFAULT_BECOME, action=\"store_true\", dest='become',",
            "                                   help=\"run operations with become (does not imply password prompting)\")",
            "            runas_group.add_option('--become-method', dest='become_method', default=C.DEFAULT_BECOME_METHOD, type='choice', choices=C.BECOME_METHODS,",
            "                                   help=\"privilege escalation method to use (default=%s), valid choices: [ %s ]\" %",
            "                                   (C.DEFAULT_BECOME_METHOD, ' | '.join(C.BECOME_METHODS)))",
            "            runas_group.add_option('--become-user', default=None, dest='become_user', type='string',",
            "                                   help='run operations as this user (default=%s)' % C.DEFAULT_BECOME_USER)",
            "",
            "        if runas_opts or runas_prompt_opts:",
            "            if not runas_group:",
            "                runas_group = rg",
            "            runas_group.add_option('--ask-sudo-pass', default=C.DEFAULT_ASK_SUDO_PASS, dest='ask_sudo_pass', action='store_true',",
            "                                   help='ask for sudo password (deprecated, use become)')",
            "            runas_group.add_option('--ask-su-pass', default=C.DEFAULT_ASK_SU_PASS, dest='ask_su_pass', action='store_true',",
            "                                   help='ask for su password (deprecated, use become)')",
            "            runas_group.add_option('-K', '--ask-become-pass', default=False, dest='become_ask_pass', action='store_true',",
            "                                   help='ask for privilege escalation password')",
            "",
            "        if runas_group:",
            "            parser.add_option_group(runas_group)",
            "",
            "        if async_opts:",
            "            parser.add_option('-P', '--poll', default=C.DEFAULT_POLL_INTERVAL, type='int', dest='poll_interval',",
            "                              help=\"set the poll interval if using -B (default=%s)\" % C.DEFAULT_POLL_INTERVAL)",
            "            parser.add_option('-B', '--background', dest='seconds', type='int', default=0,",
            "                              help='run asynchronously, failing after X seconds (default=N/A)')",
            "",
            "        if check_opts:",
            "            parser.add_option(\"-C\", \"--check\", default=False, dest='check', action='store_true',",
            "                              help=\"don't make any changes; instead, try to predict some of the changes that may occur\")",
            "            parser.add_option('--syntax-check', dest='syntax', action='store_true',",
            "                              help=\"perform a syntax check on the playbook, but do not execute it\")",
            "            parser.add_option(\"-D\", \"--diff\", default=C.DIFF_ALWAYS, dest='diff', action='store_true',",
            "                              help=\"when changing (small) files and templates, show the differences in those files; works great with --check\")",
            "",
            "        if meta_opts:",
            "            parser.add_option('--force-handlers', default=C.DEFAULT_FORCE_HANDLERS, dest='force_handlers', action='store_true',",
            "                              help=\"run handlers even if a task fails\")",
            "            parser.add_option('--flush-cache', dest='flush_cache', action='store_true',",
            "                              help=\"clear the fact cache\")",
            "",
            "        return parser",
            "",
            "    @abstractmethod",
            "    def parse(self):",
            "        \"\"\"Parse the command line args",
            "",
            "        This method parses the command line arguments.  It uses the parser",
            "        stored in the self.parser attribute and saves the args and options in",
            "        self.args and self.options respectively.",
            "",
            "        Subclasses need to implement this method.  They will usually create",
            "        a base_parser, add their own options to the base_parser, and then call",
            "        this method to do the actual parsing.  An implementation will look",
            "        something like this::",
            "",
            "            def parse(self):",
            "                parser = super(MyCLI, self).base_parser(usage=\"My Ansible CLI\", inventory_opts=True)",
            "                parser.add_option('--my-option', dest='my_option', action='store')",
            "                self.parser = parser",
            "                super(MyCLI, self).parse()",
            "                # If some additional transformations are needed for the",
            "                # arguments and options, do it here.",
            "        \"\"\"",
            "",
            "        self.options, self.args = self.parser.parse_args(self.args[1:])",
            "",
            "        # process tags",
            "        if hasattr(self.options, 'tags') and not self.options.tags:",
            "            # optparse defaults does not do what's expected",
            "            self.options.tags = ['all']",
            "        if hasattr(self.options, 'tags') and self.options.tags:",
            "            if not C.MERGE_MULTIPLE_CLI_TAGS:",
            "                if len(self.options.tags) > 1:",
            "                    display.deprecated('Specifying --tags multiple times on the command line currently uses the last specified value. '",
            "                                       'In 2.4, values will be merged instead.  Set merge_multiple_cli_tags=True in ansible.cfg to get this behavior now.',",
            "                                       version=2.5, removed=False)",
            "                    self.options.tags = [self.options.tags[-1]]",
            "",
            "            tags = set()",
            "            for tag_set in self.options.tags:",
            "                for tag in tag_set.split(u','):",
            "                    tags.add(tag.strip())",
            "            self.options.tags = list(tags)",
            "",
            "        # process skip_tags",
            "        if hasattr(self.options, 'skip_tags') and self.options.skip_tags:",
            "            if not C.MERGE_MULTIPLE_CLI_TAGS:",
            "                if len(self.options.skip_tags) > 1:",
            "                    display.deprecated('Specifying --skip-tags multiple times on the command line currently uses the last specified value. '",
            "                                       'In 2.4, values will be merged instead.  Set merge_multiple_cli_tags=True in ansible.cfg to get this behavior now.',",
            "                                       version=2.5, removed=False)",
            "                    self.options.skip_tags = [self.options.skip_tags[-1]]",
            "",
            "            skip_tags = set()",
            "            for tag_set in self.options.skip_tags:",
            "                for tag in tag_set.split(u','):",
            "                    skip_tags.add(tag.strip())",
            "            self.options.skip_tags = list(skip_tags)",
            "",
            "        # process inventory options except for CLIs that require their own processing",
            "        if hasattr(self.options, 'inventory') and not self.SKIP_INVENTORY_DEFAULTS:",
            "",
            "            if self.options.inventory:",
            "",
            "                # should always be list",
            "                if isinstance(self.options.inventory, string_types):",
            "                    self.options.inventory = [self.options.inventory]",
            "",
            "                # Ensure full paths when needed",
            "                self.options.inventory = [unfrackpath(opt, follow=False) if ',' not in opt else opt for opt in self.options.inventory]",
            "            else:",
            "                self.options.inventory = C.DEFAULT_HOST_LIST",
            "",
            "    @staticmethod",
            "    def version(prog):",
            "        ''' return ansible version '''",
            "        result = \"{0} {1}\".format(prog, __version__)",
            "        gitinfo = CLI._gitinfo()",
            "        if gitinfo:",
            "            result = result + \" {0}\".format(gitinfo)",
            "        result += \"\\n  config file = %s\" % C.CONFIG_FILE",
            "        if C.DEFAULT_MODULE_PATH is None:",
            "            cpath = \"Default w/o overrides\"",
            "        else:",
            "            cpath = C.DEFAULT_MODULE_PATH",
            "        result = result + \"\\n  configured module search path = %s\" % cpath",
            "        result = result + \"\\n  ansible python module location = %s\" % ':'.join(ansible.__path__)",
            "        result = result + \"\\n  executable location = %s\" % sys.argv[0]",
            "        result = result + \"\\n  python version = %s\" % ''.join(sys.version.splitlines())",
            "        return result",
            "",
            "    @staticmethod",
            "    def version_info(gitinfo=False):",
            "        ''' return full ansible version info '''",
            "        if gitinfo:",
            "            # expensive call, user with care",
            "            ansible_version_string = CLI.version('')",
            "        else:",
            "            ansible_version_string = __version__",
            "        ansible_version = ansible_version_string.split()[0]",
            "        ansible_versions = ansible_version.split('.')",
            "        for counter in range(len(ansible_versions)):",
            "            if ansible_versions[counter] == \"\":",
            "                ansible_versions[counter] = 0",
            "            try:",
            "                ansible_versions[counter] = int(ansible_versions[counter])",
            "            except:",
            "                pass",
            "        if len(ansible_versions) < 3:",
            "            for counter in range(len(ansible_versions), 3):",
            "                ansible_versions.append(0)",
            "        return {'string': ansible_version_string.strip(),",
            "                'full': ansible_version,",
            "                'major': ansible_versions[0],",
            "                'minor': ansible_versions[1],",
            "                'revision': ansible_versions[2]}",
            "",
            "    @staticmethod",
            "    def _git_repo_info(repo_path):",
            "        ''' returns a string containing git branch, commit id and commit date '''",
            "        result = None",
            "        if os.path.exists(repo_path):",
            "            # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.",
            "            if os.path.isfile(repo_path):",
            "                try:",
            "                    gitdir = yaml.safe_load(open(repo_path)).get('gitdir')",
            "                    # There is a possibility the .git file to have an absolute path.",
            "                    if os.path.isabs(gitdir):",
            "                        repo_path = gitdir",
            "                    else:",
            "                        repo_path = os.path.join(repo_path[:-4], gitdir)",
            "                except (IOError, AttributeError):",
            "                    return ''",
            "            f = open(os.path.join(repo_path, \"HEAD\"))",
            "            line = f.readline().rstrip(\"\\n\")",
            "            if line.startswith(\"ref:\"):",
            "                branch_path = os.path.join(repo_path, line[5:])",
            "            else:",
            "                branch_path = None",
            "            f.close()",
            "            if branch_path and os.path.exists(branch_path):",
            "                branch = '/'.join(line.split('/')[2:])",
            "                f = open(branch_path)",
            "                commit = f.readline()[:10]",
            "                f.close()",
            "            else:",
            "                # detached HEAD",
            "                commit = line[:10]",
            "                branch = 'detached HEAD'",
            "                branch_path = os.path.join(repo_path, \"HEAD\")",
            "",
            "            date = time.localtime(os.stat(branch_path).st_mtime)",
            "            if time.daylight == 0:",
            "                offset = time.timezone",
            "            else:",
            "                offset = time.altzone",
            "            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit, time.strftime(\"%Y/%m/%d %H:%M:%S\", date), int(offset / -36))",
            "        else:",
            "            result = ''",
            "        return result",
            "",
            "    @staticmethod",
            "    def _gitinfo():",
            "        basedir = os.path.join(os.path.dirname(__file__), '..', '..', '..')",
            "        repo_path = os.path.join(basedir, '.git')",
            "        result = CLI._git_repo_info(repo_path)",
            "        submodules = os.path.join(basedir, '.gitmodules')",
            "        if not os.path.exists(submodules):",
            "            return result",
            "        f = open(submodules)",
            "        for line in f:",
            "            tokens = line.strip().split(' ')",
            "            if tokens[0] == 'path':",
            "                submodule_path = tokens[2]",
            "                submodule_info = CLI._git_repo_info(os.path.join(basedir, submodule_path, '.git'))",
            "                if not submodule_info:",
            "                    submodule_info = ' not found - use git submodule update --init ' + submodule_path",
            "                result += \"\\n  {0}: {1}\".format(submodule_path, submodule_info)",
            "        f.close()",
            "        return result",
            "",
            "    def pager(self, text):",
            "        ''' find reasonable way to display text '''",
            "        # this is a much simpler form of what is in pydoc.py",
            "        if not sys.stdout.isatty():",
            "            display.display(text, screen_only=True)",
            "        elif 'PAGER' in os.environ:",
            "            if sys.platform == 'win32':",
            "                display.display(text, screen_only=True)",
            "            else:",
            "                self.pager_pipe(text, os.environ['PAGER'])",
            "        else:",
            "            p = subprocess.Popen('less --version', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
            "            p.communicate()",
            "            if p.returncode == 0:",
            "                self.pager_pipe(text, 'less')",
            "            else:",
            "                display.display(text, screen_only=True)",
            "",
            "    @staticmethod",
            "    def pager_pipe(text, cmd):",
            "        ''' pipe text through a pager '''",
            "        if 'LESS' not in os.environ:",
            "            os.environ['LESS'] = CLI.LESS_OPTS",
            "        try:",
            "            cmd = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=sys.stdout)",
            "            cmd.communicate(input=to_bytes(text))",
            "        except IOError:",
            "            pass",
            "        except KeyboardInterrupt:",
            "            pass",
            "",
            "    @classmethod",
            "    def tty_ify(cls, text):",
            "",
            "        t = cls._ITALIC.sub(\"`\" + r\"\\1\" + \"'\", text)    # I(word) => `word'",
            "        t = cls._BOLD.sub(\"*\" + r\"\\1\" + \"*\", t)         # B(word) => *word*",
            "        t = cls._MODULE.sub(\"[\" + r\"\\1\" + \"]\", t)       # M(word) => [word]",
            "        t = cls._URL.sub(r\"\\1\", t)                      # U(word) => word",
            "        t = cls._CONST.sub(\"`\" + r\"\\1\" + \"'\", t)        # C(word) => `word'",
            "",
            "        return t",
            "",
            "    @staticmethod",
            "    def _play_prereqs(options):",
            "",
            "        # all needs loader",
            "        loader = DataLoader()",
            "",
            "        vault_ids = options.vault_ids",
            "        default_vault_ids = C.DEFAULT_VAULT_IDENTITY_LIST",
            "        vault_ids = default_vault_ids + vault_ids",
            "",
            "        vault_secrets = CLI.setup_vault_secrets(loader,",
            "                                                vault_ids=vault_ids,",
            "                                                vault_password_files=options.vault_password_files,",
            "                                                ask_vault_pass=options.ask_vault_pass,",
            "                                                auto_prompt=False)",
            "        loader.set_vault_secrets(vault_secrets)",
            "",
            "        # create the inventory, and filter it based on the subset specified (if any)",
            "        inventory = InventoryManager(loader=loader, sources=options.inventory)",
            "",
            "        # create the variable manager, which will be shared throughout",
            "        # the code, ensuring a consistent view of global variables",
            "        variable_manager = VariableManager(loader=loader, inventory=inventory)",
            "",
            "        # load vars from cli options",
            "        variable_manager.extra_vars = load_extra_vars(loader=loader, options=options)",
            "        variable_manager.options_vars = load_options_vars(options, CLI.version_info(gitinfo=False))",
            "",
            "        return loader, inventory, variable_manager",
            "",
            "    @staticmethod",
            "    def get_host_list(inventory, subset, pattern='all'):",
            "",
            "        no_hosts = False",
            "        if len(inventory.list_hosts()) == 0:",
            "            # Empty inventory",
            "            display.warning(\"provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\")",
            "            no_hosts = True",
            "",
            "        inventory.subset(subset)",
            "",
            "        hosts = inventory.list_hosts(pattern)",
            "        if len(hosts) == 0 and no_hosts is False:",
            "            raise AnsibleError(\"Specified hosts and/or --limit does not match any hosts\")",
            "",
            "        return hosts"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# (c) 2016, Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import getpass",
            "import operator",
            "import optparse",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import time",
            "import yaml",
            "",
            "from abc import ABCMeta, abstractmethod",
            "",
            "import ansible",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleOptionsError, AnsibleError",
            "from ansible.inventory.manager import InventoryManager",
            "from ansible.module_utils.six import with_metaclass, string_types",
            "from ansible.module_utils._text import to_bytes, to_text",
            "from ansible.parsing.dataloader import DataLoader",
            "from ansible.release import __version__",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.vars import load_extra_vars, load_options_vars",
            "from ansible.vars.manager import VariableManager",
            "from ansible.parsing.vault import PromptVaultSecret, get_file_vault_secret",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "class SortedOptParser(optparse.OptionParser):",
            "    '''Optparser which sorts the options by opt before outputting --help'''",
            "",
            "    def format_help(self, formatter=None, epilog=None):",
            "        self.option_list.sort(key=operator.methodcaller('get_opt_string'))",
            "        return optparse.OptionParser.format_help(self, formatter=None)",
            "",
            "",
            "# Note: Inherit from SortedOptParser so that we get our format_help method",
            "class InvalidOptsParser(SortedOptParser):",
            "    '''Ignore invalid options.",
            "",
            "    Meant for the special case where we need to take care of help and version",
            "    but may not know the full range of options yet.  (See it in use in set_action)",
            "    '''",
            "    def __init__(self, parser):",
            "        # Since this is special purposed to just handle help and version, we",
            "        # take a pre-existing option parser here and set our options from",
            "        # that.  This allows us to give accurate help based on the given",
            "        # option parser.",
            "        SortedOptParser.__init__(self, usage=parser.usage,",
            "                                 option_list=parser.option_list,",
            "                                 option_class=parser.option_class,",
            "                                 conflict_handler=parser.conflict_handler,",
            "                                 description=parser.description,",
            "                                 formatter=parser.formatter,",
            "                                 add_help_option=False,",
            "                                 prog=parser.prog,",
            "                                 epilog=parser.epilog)",
            "        self.version = parser.version",
            "",
            "    def _process_long_opt(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_long_opt(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "    def _process_short_opts(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_short_opts(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "",
            "class CLI(with_metaclass(ABCMeta, object)):",
            "    ''' code behind bin/ansible* programs '''",
            "",
            "    VALID_ACTIONS = []",
            "",
            "    _ITALIC = re.compile(r\"I\\(([^)]+)\\)\")",
            "    _BOLD = re.compile(r\"B\\(([^)]+)\\)\")",
            "    _MODULE = re.compile(r\"M\\(([^)]+)\\)\")",
            "    _URL = re.compile(r\"U\\(([^)]+)\\)\")",
            "    _CONST = re.compile(r\"C\\(([^)]+)\\)\")",
            "",
            "    PAGER = 'less'",
            "",
            "    # -F (quit-if-one-screen) -R (allow raw ansi control chars)",
            "    # -S (chop long lines) -X (disable termcap init and de-init)",
            "    LESS_OPTS = 'FRSX'",
            "    SKIP_INVENTORY_DEFAULTS = False",
            "",
            "    def __init__(self, args, callback=None):",
            "        \"\"\"",
            "        Base init method for all command line programs",
            "        \"\"\"",
            "",
            "        self.args = args",
            "        self.options = None",
            "        self.parser = None",
            "        self.action = None",
            "        self.callback = callback",
            "",
            "    def set_action(self):",
            "        \"\"\"",
            "        Get the action the user wants to execute from the sys argv list.",
            "        \"\"\"",
            "        for i in range(0, len(self.args)):",
            "            arg = self.args[i]",
            "            if arg in self.VALID_ACTIONS:",
            "                self.action = arg",
            "                del self.args[i]",
            "                break",
            "",
            "        if not self.action:",
            "            # if we're asked for help or version, we don't need an action.",
            "            # have to use a special purpose Option Parser to figure that out as",
            "            # the standard OptionParser throws an error for unknown options and",
            "            # without knowing action, we only know of a subset of the options",
            "            # that could be legal for this command",
            "            tmp_parser = InvalidOptsParser(self.parser)",
            "            tmp_options, tmp_args = tmp_parser.parse_args(self.args)",
            "            if not(hasattr(tmp_options, 'help') and tmp_options.help) or (hasattr(tmp_options, 'version') and tmp_options.version):",
            "                raise AnsibleOptionsError(\"Missing required action\")",
            "",
            "    def execute(self):",
            "        \"\"\"",
            "        Actually runs a child defined method using the execute_<action> pattern",
            "        \"\"\"",
            "        fn = getattr(self, \"execute_%s\" % self.action)",
            "        fn()",
            "",
            "    @abstractmethod",
            "    def run(self):",
            "        \"\"\"Run the ansible command",
            "",
            "        Subclasses must implement this method.  It does the actual work of",
            "        running an Ansible command.",
            "        \"\"\"",
            "",
            "        display.vv(to_text(self.parser.get_version()))",
            "",
            "        if C.CONFIG_FILE:",
            "            display.v(u\"Using %s as config file\" % to_text(C.CONFIG_FILE))",
            "        else:",
            "            display.v(u\"No config file found; using defaults\")",
            "",
            "        # warn about deprecated config options",
            "        for deprecated in C.config.DEPRECATED:",
            "            name = deprecated[0]",
            "            why = deprecated[1]['why']",
            "            if 'alternative' in deprecated[1]:",
            "                alt = ', use %s instead' % deprecated[1]['alternative']",
            "            else:",
            "                alt = ''",
            "            ver = deprecated[1]['version']",
            "            display.deprecated(\"%s option, %s %s\" % (name, why, alt), version=ver)",
            "",
            "        # warn about typing issues with configuration entries",
            "        for unable in C.config.UNABLE:",
            "            display.warning(\"Unable to set correct type for configuration entry: %s\" % unable)",
            "",
            "    @staticmethod",
            "    def split_vault_id(vault_id):",
            "        # return (before_@, after_@)",
            "        # if no @, return whole string as after_",
            "        if '@' not in vault_id:",
            "            return (None, vault_id)",
            "",
            "        parts = vault_id.split('@', 1)",
            "        ret = tuple(parts)",
            "        return ret",
            "",
            "    @staticmethod",
            "    def build_vault_ids(vault_ids, vault_password_files=None,",
            "                        ask_vault_pass=None, create_new_password=None,",
            "                        auto_prompt=True):",
            "        vault_password_files = vault_password_files or []",
            "        vault_ids = vault_ids or []",
            "",
            "        # convert vault_password_files into vault_ids slugs",
            "        for password_file in vault_password_files:",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, password_file)",
            "",
            "            # note this makes --vault-id higher precendence than --vault-password-file",
            "            # if we want to intertwingle them in order probably need a cli callback to populate vault_ids",
            "            # used by --vault-id and --vault-password-file",
            "            vault_ids.append(id_slug)",
            "",
            "        # if an action needs an encrypt password (create_new_password=True) and we dont",
            "        # have other secrets setup, then automatically add a password prompt as well.",
            "        # prompts cant/shouldnt work without a tty, so dont add prompt secrets",
            "        if ask_vault_pass or (not vault_ids and auto_prompt):",
            "",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, u'prompt_ask_vault_pass')",
            "            vault_ids.append(id_slug)",
            "",
            "        return vault_ids",
            "",
            "    # TODO: remove the now unused args",
            "    @staticmethod",
            "    def setup_vault_secrets(loader, vault_ids, vault_password_files=None,",
            "                            ask_vault_pass=None, create_new_password=False,",
            "                            auto_prompt=True):",
            "        # list of tuples",
            "        vault_secrets = []",
            "",
            "        # Depending on the vault_id value (including how --ask-vault-pass / --vault-password-file create a vault_id)",
            "        # we need to show different prompts. This is for compat with older Towers that expect a",
            "        # certain vault password prompt format, so 'promp_ask_vault_pass' vault_id gets the old format.",
            "        prompt_formats = {}",
            "",
            "        # If there are configured default vault identities, they are considered 'first'",
            "        # so we prepend them to vault_ids (from cli) here",
            "",
            "        vault_password_files = vault_password_files or []",
            "        if C.DEFAULT_VAULT_PASSWORD_FILE:",
            "            vault_password_files.append(C.DEFAULT_VAULT_PASSWORD_FILE)",
            "",
            "        if create_new_password:",
            "            prompt_formats['prompt'] = ['New vault password (%(vault_id)s): ',",
            "                                        'Confirm vew vault password (%(vault_id)s): ']",
            "            # 2.3 format prompts for --ask-vault-pass",
            "            prompt_formats['prompt_ask_vault_pass'] = ['New Vault password: ',",
            "                                                       'Confirm New Vault password: ']",
            "        else:",
            "            prompt_formats['prompt'] = ['Vault password (%(vault_id)s): ']",
            "            # The format when we use just --ask-vault-pass needs to match 'Vault password:\\s*?$'",
            "            prompt_formats['prompt_ask_vault_pass'] = ['Vault password: ']",
            "",
            "        vault_ids = CLI.build_vault_ids(vault_ids,",
            "                                        vault_password_files,",
            "                                        ask_vault_pass,",
            "                                        create_new_password,",
            "                                        auto_prompt=auto_prompt)",
            "",
            "        for vault_id_slug in vault_ids:",
            "            vault_id_name, vault_id_value = CLI.split_vault_id(vault_id_slug)",
            "            if vault_id_value in ['prompt', 'prompt_ask_vault_pass']:",
            "",
            "                # --vault-id some_name@prompt_ask_vault_pass --vault-id other_name@prompt_ask_vault_pass will be a little",
            "                # confusing since it will use the old format without the vault id in the prompt",
            "                built_vault_id = vault_id_name or C.DEFAULT_VAULT_IDENTITY",
            "",
            "                # choose the prompt based on --vault-id=prompt or --ask-vault-pass. --ask-vault-pass",
            "                # always gets the old format for Tower compatibility.",
            "                # ie, we used --ask-vault-pass, so we need to use the old vault password prompt",
            "                # format since Tower needs to match on that format.",
            "                prompted_vault_secret = PromptVaultSecret(prompt_formats=prompt_formats[vault_id_value],",
            "                                                          vault_id=built_vault_id)",
            "",
            "                # a empty or invalid password from the prompt will warn and continue to the next",
            "                # without erroring globablly",
            "                try:",
            "                    prompted_vault_secret.load()",
            "                except AnsibleError as exc:",
            "                    display.warning('Error in vault password prompt (%s): %s' % (vault_id_name, exc))",
            "                    raise",
            "",
            "                vault_secrets.append((built_vault_id, prompted_vault_secret))",
            "",
            "                # update loader with new secrets incrementally, so we can load a vault password",
            "                # that is encrypted with a vault secret provided earlier",
            "                loader.set_vault_secrets(vault_secrets)",
            "                continue",
            "",
            "            # assuming anything else is a password file",
            "            display.vvvvv('Reading vault password file: %s' % vault_id_value)",
            "            # read vault_pass from a file",
            "            file_vault_secret = get_file_vault_secret(filename=vault_id_value,",
            "                                                      vault_id_name=vault_id_name,",
            "                                                      loader=loader)",
            "",
            "            # an invalid password file will error globally",
            "            try:",
            "                file_vault_secret.load()",
            "            except AnsibleError as exc:",
            "                display.warning('Error in vault password file loading (%s): %s' % (vault_id_name, exc))",
            "                raise",
            "",
            "            if vault_id_name:",
            "                vault_secrets.append((vault_id_name, file_vault_secret))",
            "            else:",
            "                vault_secrets.append((C.DEFAULT_VAULT_IDENTITY, file_vault_secret))",
            "",
            "            # update loader with as-yet-known vault secrets",
            "            loader.set_vault_secrets(vault_secrets)",
            "",
            "        return vault_secrets",
            "",
            "    def ask_passwords(self):",
            "        ''' prompt for connection and become passwords if needed '''",
            "",
            "        op = self.options",
            "        sshpass = None",
            "        becomepass = None",
            "        become_prompt = ''",
            "",
            "        try:",
            "            if op.ask_pass:",
            "                sshpass = getpass.getpass(prompt=\"SSH password: \")",
            "                become_prompt = \"%s password[defaults to SSH password]: \" % op.become_method.upper()",
            "                if sshpass:",
            "                    sshpass = to_bytes(sshpass, errors='strict', nonstring='simplerepr')",
            "            else:",
            "                become_prompt = \"%s password: \" % op.become_method.upper()",
            "",
            "            if op.become_ask_pass:",
            "                becomepass = getpass.getpass(prompt=become_prompt)",
            "                if op.ask_pass and becomepass == '':",
            "                    becomepass = sshpass",
            "                if becomepass:",
            "                    becomepass = to_bytes(becomepass)",
            "        except EOFError:",
            "            pass",
            "",
            "        return (sshpass, becomepass)",
            "",
            "    def normalize_become_options(self):",
            "        ''' this keeps backwards compatibility with sudo/su self.options '''",
            "        self.options.become_ask_pass = self.options.become_ask_pass or self.options.ask_sudo_pass or self.options.ask_su_pass or C.DEFAULT_BECOME_ASK_PASS",
            "        self.options.become_user = self.options.become_user or self.options.sudo_user or self.options.su_user or C.DEFAULT_BECOME_USER",
            "",
            "        def _dep(which):",
            "            display.deprecated('The %s command line option has been deprecated in favor of the \"become\" command line arguments' % which, '2.6')",
            "",
            "        if self.options.become:",
            "            pass",
            "        elif self.options.sudo:",
            "            self.options.become = True",
            "            self.options.become_method = 'sudo'",
            "            _dep('sudo')",
            "        elif self.options.su:",
            "            self.options.become = True",
            "            self.options.become_method = 'su'",
            "            _dep('su')",
            "",
            "        # other deprecations:",
            "        if self.options.ask_sudo_pass or self.options.sudo_user:",
            "            _dep('sudo')",
            "        if self.options.ask_su_pass or self.options.su_user:",
            "            _dep('su')",
            "",
            "    def validate_conflicts(self, vault_opts=False, runas_opts=False, fork_opts=False):",
            "        ''' check for conflicting options '''",
            "",
            "        op = self.options",
            "",
            "        if vault_opts:",
            "            # Check for vault related conflicts",
            "            if (op.ask_vault_pass and op.vault_password_files):",
            "                self.parser.error(\"--ask-vault-pass and --vault-password-file are mutually exclusive\")",
            "",
            "        if runas_opts:",
            "            # Check for privilege escalation conflicts",
            "            if ((op.su or op.su_user) and (op.sudo or op.sudo_user) or",
            "                    (op.su or op.su_user) and (op.become or op.become_user) or",
            "                    (op.sudo or op.sudo_user) and (op.become or op.become_user)):",
            "",
            "                self.parser.error(\"Sudo arguments ('--sudo', '--sudo-user', and '--ask-sudo-pass') and su arguments ('--su', '--su-user', and '--ask-su-pass') \"",
            "                                  \"and become arguments ('--become', '--become-user', and '--ask-become-pass') are exclusive of each other\")",
            "",
            "        if fork_opts:",
            "            if op.forks < 1:",
            "                self.parser.error(\"The number of processes (--forks) must be >= 1\")",
            "",
            "    @staticmethod",
            "    def unfrack_paths(option, opt, value, parser):",
            "        paths = getattr(parser.values, option.dest)",
            "        if paths is None:",
            "            paths = []",
            "",
            "        if isinstance(value, string_types):",
            "            paths[:0] = [unfrackpath(x) for x in value.split(os.pathsep) if x]",
            "        elif isinstance(value, list):",
            "            paths[:0] = [unfrackpath(x) for x in value if x]",
            "        else:",
            "            pass  # FIXME: should we raise options error?",
            "",
            "        setattr(parser.values, option.dest, paths)",
            "",
            "    @staticmethod",
            "    def unfrack_path(option, opt, value, parser):",
            "        if value != '-':",
            "            setattr(parser.values, option.dest, unfrackpath(value))",
            "        else:",
            "            setattr(parser.values, option.dest, value)",
            "",
            "    @staticmethod",
            "    def base_parser(usage=\"\", output_opts=False, runas_opts=False, meta_opts=False, runtask_opts=False, vault_opts=False, module_opts=False,",
            "                    async_opts=False, connect_opts=False, subset_opts=False, check_opts=False, inventory_opts=False, epilog=None, fork_opts=False,",
            "                    runas_prompt_opts=False, desc=None, vault_rekey_opts=False):",
            "        ''' create an options parser for most ansible scripts '''",
            "",
            "        # base opts",
            "        parser = SortedOptParser(usage, version=CLI.version(\"%prog\"), description=desc, epilog=epilog)",
            "        parser.add_option('-v', '--verbose', dest='verbosity', default=C.DEFAULT_VERBOSITY, action=\"count\",",
            "                          help=\"verbose mode (-vvv for more, -vvvv to enable connection debugging)\")",
            "",
            "        if inventory_opts:",
            "            parser.add_option('-i', '--inventory', '--inventory-file', dest='inventory', action=\"append\",",
            "                              help=\"specify inventory host path or comma separated host list. --inventory-file is deprecated\")",
            "            parser.add_option('--list-hosts', dest='listhosts', action='store_true',",
            "                              help='outputs a list of matching hosts; does not execute anything else')",
            "            parser.add_option('-l', '--limit', default=C.DEFAULT_SUBSET, dest='subset',",
            "                              help='further limit selected hosts to an additional pattern')",
            "",
            "        if module_opts:",
            "            parser.add_option('-M', '--module-path', dest='module_path', default=None,",
            "                              help=\"prepend colon-separated path(s) to module library (default=%s)\" % C.DEFAULT_MODULE_PATH,",
            "                              action=\"callback\", callback=CLI.unfrack_paths, type='str')",
            "        if runtask_opts:",
            "            parser.add_option('-e', '--extra-vars', dest=\"extra_vars\", action=\"append\",",
            "                              help=\"set additional variables as key=value or YAML/JSON, if filename prepend with @\", default=[])",
            "",
            "        if fork_opts:",
            "            parser.add_option('-f', '--forks', dest='forks', default=C.DEFAULT_FORKS, type='int',",
            "                              help=\"specify number of parallel processes to use (default=%s)\" % C.DEFAULT_FORKS)",
            "",
            "        if vault_opts:",
            "            parser.add_option('--ask-vault-pass', default=C.DEFAULT_ASK_VAULT_PASS, dest='ask_vault_pass', action='store_true',",
            "                              help='ask for vault password')",
            "            parser.add_option('--vault-password-file', default=[], dest='vault_password_files',",
            "                              help=\"vault password file\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--vault-id', default=[], dest='vault_ids', action='append', type='string',",
            "                              help='the vault identity to use')",
            "",
            "        if vault_rekey_opts:",
            "            parser.add_option('--new-vault-password-file', default=[], dest='new_vault_password_files',",
            "                              help=\"new vault password file for rekey\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--new-vault-id', default=None, dest='new_vault_id', type='string',",
            "                              help='the new vault identity to use for rekey')",
            "",
            "        if subset_opts:",
            "            parser.add_option('-t', '--tags', dest='tags', default=[], action='append',",
            "                              help=\"only run plays and tasks tagged with these values\")",
            "            parser.add_option('--skip-tags', dest='skip_tags', default=[], action='append',",
            "                              help=\"only run plays and tasks whose tags do not match these values\")",
            "",
            "        if output_opts:",
            "            parser.add_option('-o', '--one-line', dest='one_line', action='store_true',",
            "                              help='condense output')",
            "            parser.add_option('-t', '--tree', dest='tree', default=None,",
            "                              help='log output to this directory')",
            "",
            "        if connect_opts:",
            "            connect_group = optparse.OptionGroup(parser, \"Connection Options\", \"control as whom and how to connect to hosts\")",
            "            connect_group.add_option('-k', '--ask-pass', default=C.DEFAULT_ASK_PASS, dest='ask_pass', action='store_true',",
            "                                     help='ask for connection password')",
            "            connect_group.add_option('--private-key', '--key-file', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',",
            "                                     help='use this file to authenticate the connection', action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            connect_group.add_option('-u', '--user', default=C.DEFAULT_REMOTE_USER, dest='remote_user',",
            "                                     help='connect as this user (default=%s)' % C.DEFAULT_REMOTE_USER)",
            "            connect_group.add_option('-c', '--connection', dest='connection', default=C.DEFAULT_TRANSPORT,",
            "                                     help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)",
            "            connect_group.add_option('-T', '--timeout', default=C.DEFAULT_TIMEOUT, type='int', dest='timeout',",
            "                                     help=\"override the connection timeout in seconds (default=%s)\" % C.DEFAULT_TIMEOUT)",
            "            connect_group.add_option('--ssh-common-args', default='', dest='ssh_common_args',",
            "                                     help=\"specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand)\")",
            "            connect_group.add_option('--sftp-extra-args', default='', dest='sftp_extra_args',",
            "                                     help=\"specify extra arguments to pass to sftp only (e.g. -f, -l)\")",
            "            connect_group.add_option('--scp-extra-args', default='', dest='scp_extra_args',",
            "                                     help=\"specify extra arguments to pass to scp only (e.g. -l)\")",
            "            connect_group.add_option('--ssh-extra-args', default='', dest='ssh_extra_args',",
            "                                     help=\"specify extra arguments to pass to ssh only (e.g. -R)\")",
            "",
            "            parser.add_option_group(connect_group)",
            "",
            "        runas_group = None",
            "        rg = optparse.OptionGroup(parser, \"Privilege Escalation Options\", \"control how and which user you become as on target hosts\")",
            "        if runas_opts:",
            "            runas_group = rg",
            "            # priv user defaults to root later on to enable detecting when this option was given here",
            "            runas_group.add_option(\"-s\", \"--sudo\", default=C.DEFAULT_SUDO, action=\"store_true\", dest='sudo',",
            "                                   help=\"run operations with sudo (nopasswd) (deprecated, use become)\")",
            "            runas_group.add_option('-U', '--sudo-user', dest='sudo_user', default=None,",
            "                                   help='desired sudo user (default=root) (deprecated, use become)')",
            "            runas_group.add_option('-S', '--su', default=C.DEFAULT_SU, action='store_true',",
            "                                   help='run operations with su (deprecated, use become)')",
            "            runas_group.add_option('-R', '--su-user', default=None,",
            "                                   help='run operations with su as this user (default=%s) (deprecated, use become)' % C.DEFAULT_SU_USER)",
            "",
            "            # consolidated privilege escalation (become)",
            "            runas_group.add_option(\"-b\", \"--become\", default=C.DEFAULT_BECOME, action=\"store_true\", dest='become',",
            "                                   help=\"run operations with become (does not imply password prompting)\")",
            "            runas_group.add_option('--become-method', dest='become_method', default=C.DEFAULT_BECOME_METHOD, type='choice', choices=C.BECOME_METHODS,",
            "                                   help=\"privilege escalation method to use (default=%s), valid choices: [ %s ]\" %",
            "                                   (C.DEFAULT_BECOME_METHOD, ' | '.join(C.BECOME_METHODS)))",
            "            runas_group.add_option('--become-user', default=None, dest='become_user', type='string',",
            "                                   help='run operations as this user (default=%s)' % C.DEFAULT_BECOME_USER)",
            "",
            "        if runas_opts or runas_prompt_opts:",
            "            if not runas_group:",
            "                runas_group = rg",
            "            runas_group.add_option('--ask-sudo-pass', default=C.DEFAULT_ASK_SUDO_PASS, dest='ask_sudo_pass', action='store_true',",
            "                                   help='ask for sudo password (deprecated, use become)')",
            "            runas_group.add_option('--ask-su-pass', default=C.DEFAULT_ASK_SU_PASS, dest='ask_su_pass', action='store_true',",
            "                                   help='ask for su password (deprecated, use become)')",
            "            runas_group.add_option('-K', '--ask-become-pass', default=False, dest='become_ask_pass', action='store_true',",
            "                                   help='ask for privilege escalation password')",
            "",
            "        if runas_group:",
            "            parser.add_option_group(runas_group)",
            "",
            "        if async_opts:",
            "            parser.add_option('-P', '--poll', default=C.DEFAULT_POLL_INTERVAL, type='int', dest='poll_interval',",
            "                              help=\"set the poll interval if using -B (default=%s)\" % C.DEFAULT_POLL_INTERVAL)",
            "            parser.add_option('-B', '--background', dest='seconds', type='int', default=0,",
            "                              help='run asynchronously, failing after X seconds (default=N/A)')",
            "",
            "        if check_opts:",
            "            parser.add_option(\"-C\", \"--check\", default=False, dest='check', action='store_true',",
            "                              help=\"don't make any changes; instead, try to predict some of the changes that may occur\")",
            "            parser.add_option('--syntax-check', dest='syntax', action='store_true',",
            "                              help=\"perform a syntax check on the playbook, but do not execute it\")",
            "            parser.add_option(\"-D\", \"--diff\", default=C.DIFF_ALWAYS, dest='diff', action='store_true',",
            "                              help=\"when changing (small) files and templates, show the differences in those files; works great with --check\")",
            "",
            "        if meta_opts:",
            "            parser.add_option('--force-handlers', default=C.DEFAULT_FORCE_HANDLERS, dest='force_handlers', action='store_true',",
            "                              help=\"run handlers even if a task fails\")",
            "            parser.add_option('--flush-cache', dest='flush_cache', action='store_true',",
            "                              help=\"clear the fact cache\")",
            "",
            "        return parser",
            "",
            "    @abstractmethod",
            "    def parse(self):",
            "        \"\"\"Parse the command line args",
            "",
            "        This method parses the command line arguments.  It uses the parser",
            "        stored in the self.parser attribute and saves the args and options in",
            "        self.args and self.options respectively.",
            "",
            "        Subclasses need to implement this method.  They will usually create",
            "        a base_parser, add their own options to the base_parser, and then call",
            "        this method to do the actual parsing.  An implementation will look",
            "        something like this::",
            "",
            "            def parse(self):",
            "                parser = super(MyCLI, self).base_parser(usage=\"My Ansible CLI\", inventory_opts=True)",
            "                parser.add_option('--my-option', dest='my_option', action='store')",
            "                self.parser = parser",
            "                super(MyCLI, self).parse()",
            "                # If some additional transformations are needed for the",
            "                # arguments and options, do it here.",
            "        \"\"\"",
            "",
            "        self.options, self.args = self.parser.parse_args(self.args[1:])",
            "",
            "        # process tags",
            "        if hasattr(self.options, 'tags') and not self.options.tags:",
            "            # optparse defaults does not do what's expected",
            "            self.options.tags = ['all']",
            "        if hasattr(self.options, 'tags') and self.options.tags:",
            "            if not C.MERGE_MULTIPLE_CLI_TAGS:",
            "                if len(self.options.tags) > 1:",
            "                    display.deprecated('Specifying --tags multiple times on the command line currently uses the last specified value. '",
            "                                       'In 2.4, values will be merged instead.  Set merge_multiple_cli_tags=True in ansible.cfg to get this behavior now.',",
            "                                       version=2.5, removed=False)",
            "                    self.options.tags = [self.options.tags[-1]]",
            "",
            "            tags = set()",
            "            for tag_set in self.options.tags:",
            "                for tag in tag_set.split(u','):",
            "                    tags.add(tag.strip())",
            "            self.options.tags = list(tags)",
            "",
            "        # process skip_tags",
            "        if hasattr(self.options, 'skip_tags') and self.options.skip_tags:",
            "            if not C.MERGE_MULTIPLE_CLI_TAGS:",
            "                if len(self.options.skip_tags) > 1:",
            "                    display.deprecated('Specifying --skip-tags multiple times on the command line currently uses the last specified value. '",
            "                                       'In 2.4, values will be merged instead.  Set merge_multiple_cli_tags=True in ansible.cfg to get this behavior now.',",
            "                                       version=2.5, removed=False)",
            "                    self.options.skip_tags = [self.options.skip_tags[-1]]",
            "",
            "            skip_tags = set()",
            "            for tag_set in self.options.skip_tags:",
            "                for tag in tag_set.split(u','):",
            "                    skip_tags.add(tag.strip())",
            "            self.options.skip_tags = list(skip_tags)",
            "",
            "        # process inventory options except for CLIs that require their own processing",
            "        if hasattr(self.options, 'inventory') and not self.SKIP_INVENTORY_DEFAULTS:",
            "",
            "            if self.options.inventory:",
            "",
            "                # should always be list",
            "                if isinstance(self.options.inventory, string_types):",
            "                    self.options.inventory = [self.options.inventory]",
            "",
            "                # Ensure full paths when needed",
            "                self.options.inventory = [unfrackpath(opt, follow=False) if ',' not in opt else opt for opt in self.options.inventory]",
            "            else:",
            "                self.options.inventory = C.DEFAULT_HOST_LIST",
            "",
            "    @staticmethod",
            "    def version(prog):",
            "        ''' return ansible version '''",
            "        result = \"{0} {1}\".format(prog, __version__)",
            "        gitinfo = CLI._gitinfo()",
            "        if gitinfo:",
            "            result = result + \" {0}\".format(gitinfo)",
            "        result += \"\\n  config file = %s\" % C.CONFIG_FILE",
            "        if C.DEFAULT_MODULE_PATH is None:",
            "            cpath = \"Default w/o overrides\"",
            "        else:",
            "            cpath = C.DEFAULT_MODULE_PATH",
            "        result = result + \"\\n  configured module search path = %s\" % cpath",
            "        result = result + \"\\n  ansible python module location = %s\" % ':'.join(ansible.__path__)",
            "        result = result + \"\\n  executable location = %s\" % sys.argv[0]",
            "        result = result + \"\\n  python version = %s\" % ''.join(sys.version.splitlines())",
            "        return result",
            "",
            "    @staticmethod",
            "    def version_info(gitinfo=False):",
            "        ''' return full ansible version info '''",
            "        if gitinfo:",
            "            # expensive call, user with care",
            "            ansible_version_string = CLI.version('')",
            "        else:",
            "            ansible_version_string = __version__",
            "        ansible_version = ansible_version_string.split()[0]",
            "        ansible_versions = ansible_version.split('.')",
            "        for counter in range(len(ansible_versions)):",
            "            if ansible_versions[counter] == \"\":",
            "                ansible_versions[counter] = 0",
            "            try:",
            "                ansible_versions[counter] = int(ansible_versions[counter])",
            "            except Exception:",
            "                pass",
            "        if len(ansible_versions) < 3:",
            "            for counter in range(len(ansible_versions), 3):",
            "                ansible_versions.append(0)",
            "        return {'string': ansible_version_string.strip(),",
            "                'full': ansible_version,",
            "                'major': ansible_versions[0],",
            "                'minor': ansible_versions[1],",
            "                'revision': ansible_versions[2]}",
            "",
            "    @staticmethod",
            "    def _git_repo_info(repo_path):",
            "        ''' returns a string containing git branch, commit id and commit date '''",
            "        result = None",
            "        if os.path.exists(repo_path):",
            "            # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.",
            "            if os.path.isfile(repo_path):",
            "                try:",
            "                    gitdir = yaml.safe_load(open(repo_path)).get('gitdir')",
            "                    # There is a possibility the .git file to have an absolute path.",
            "                    if os.path.isabs(gitdir):",
            "                        repo_path = gitdir",
            "                    else:",
            "                        repo_path = os.path.join(repo_path[:-4], gitdir)",
            "                except (IOError, AttributeError):",
            "                    return ''",
            "            f = open(os.path.join(repo_path, \"HEAD\"))",
            "            line = f.readline().rstrip(\"\\n\")",
            "            if line.startswith(\"ref:\"):",
            "                branch_path = os.path.join(repo_path, line[5:])",
            "            else:",
            "                branch_path = None",
            "            f.close()",
            "            if branch_path and os.path.exists(branch_path):",
            "                branch = '/'.join(line.split('/')[2:])",
            "                f = open(branch_path)",
            "                commit = f.readline()[:10]",
            "                f.close()",
            "            else:",
            "                # detached HEAD",
            "                commit = line[:10]",
            "                branch = 'detached HEAD'",
            "                branch_path = os.path.join(repo_path, \"HEAD\")",
            "",
            "            date = time.localtime(os.stat(branch_path).st_mtime)",
            "            if time.daylight == 0:",
            "                offset = time.timezone",
            "            else:",
            "                offset = time.altzone",
            "            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit, time.strftime(\"%Y/%m/%d %H:%M:%S\", date), int(offset / -36))",
            "        else:",
            "            result = ''",
            "        return result",
            "",
            "    @staticmethod",
            "    def _gitinfo():",
            "        basedir = os.path.join(os.path.dirname(__file__), '..', '..', '..')",
            "        repo_path = os.path.join(basedir, '.git')",
            "        result = CLI._git_repo_info(repo_path)",
            "        submodules = os.path.join(basedir, '.gitmodules')",
            "        if not os.path.exists(submodules):",
            "            return result",
            "        f = open(submodules)",
            "        for line in f:",
            "            tokens = line.strip().split(' ')",
            "            if tokens[0] == 'path':",
            "                submodule_path = tokens[2]",
            "                submodule_info = CLI._git_repo_info(os.path.join(basedir, submodule_path, '.git'))",
            "                if not submodule_info:",
            "                    submodule_info = ' not found - use git submodule update --init ' + submodule_path",
            "                result += \"\\n  {0}: {1}\".format(submodule_path, submodule_info)",
            "        f.close()",
            "        return result",
            "",
            "    def pager(self, text):",
            "        ''' find reasonable way to display text '''",
            "        # this is a much simpler form of what is in pydoc.py",
            "        if not sys.stdout.isatty():",
            "            display.display(text, screen_only=True)",
            "        elif 'PAGER' in os.environ:",
            "            if sys.platform == 'win32':",
            "                display.display(text, screen_only=True)",
            "            else:",
            "                self.pager_pipe(text, os.environ['PAGER'])",
            "        else:",
            "            p = subprocess.Popen('less --version', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
            "            p.communicate()",
            "            if p.returncode == 0:",
            "                self.pager_pipe(text, 'less')",
            "            else:",
            "                display.display(text, screen_only=True)",
            "",
            "    @staticmethod",
            "    def pager_pipe(text, cmd):",
            "        ''' pipe text through a pager '''",
            "        if 'LESS' not in os.environ:",
            "            os.environ['LESS'] = CLI.LESS_OPTS",
            "        try:",
            "            cmd = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=sys.stdout)",
            "            cmd.communicate(input=to_bytes(text))",
            "        except IOError:",
            "            pass",
            "        except KeyboardInterrupt:",
            "            pass",
            "",
            "    @classmethod",
            "    def tty_ify(cls, text):",
            "",
            "        t = cls._ITALIC.sub(\"`\" + r\"\\1\" + \"'\", text)    # I(word) => `word'",
            "        t = cls._BOLD.sub(\"*\" + r\"\\1\" + \"*\", t)         # B(word) => *word*",
            "        t = cls._MODULE.sub(\"[\" + r\"\\1\" + \"]\", t)       # M(word) => [word]",
            "        t = cls._URL.sub(r\"\\1\", t)                      # U(word) => word",
            "        t = cls._CONST.sub(\"`\" + r\"\\1\" + \"'\", t)        # C(word) => `word'",
            "",
            "        return t",
            "",
            "    @staticmethod",
            "    def _play_prereqs(options):",
            "",
            "        # all needs loader",
            "        loader = DataLoader()",
            "",
            "        vault_ids = options.vault_ids",
            "        default_vault_ids = C.DEFAULT_VAULT_IDENTITY_LIST",
            "        vault_ids = default_vault_ids + vault_ids",
            "",
            "        vault_secrets = CLI.setup_vault_secrets(loader,",
            "                                                vault_ids=vault_ids,",
            "                                                vault_password_files=options.vault_password_files,",
            "                                                ask_vault_pass=options.ask_vault_pass,",
            "                                                auto_prompt=False)",
            "        loader.set_vault_secrets(vault_secrets)",
            "",
            "        # create the inventory, and filter it based on the subset specified (if any)",
            "        inventory = InventoryManager(loader=loader, sources=options.inventory)",
            "",
            "        # create the variable manager, which will be shared throughout",
            "        # the code, ensuring a consistent view of global variables",
            "        variable_manager = VariableManager(loader=loader, inventory=inventory)",
            "",
            "        if hasattr(options, 'basedir'):",
            "            if options.basedir:",
            "                variable_manager.safe_basedir = True",
            "        else:",
            "            variable_manager.safe_basedir = True",
            "",
            "        # load vars from cli options",
            "        variable_manager.extra_vars = load_extra_vars(loader=loader, options=options)",
            "        variable_manager.options_vars = load_options_vars(options, CLI.version_info(gitinfo=False))",
            "",
            "        return loader, inventory, variable_manager",
            "",
            "    @staticmethod",
            "    def get_host_list(inventory, subset, pattern='all'):",
            "",
            "        no_hosts = False",
            "        if len(inventory.list_hosts()) == 0:",
            "            # Empty inventory",
            "            display.warning(\"provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\")",
            "            no_hosts = True",
            "",
            "        inventory.subset(subset)",
            "",
            "        hosts = inventory.list_hosts(pattern)",
            "        if len(hosts) == 0 and no_hosts is False:",
            "            raise AnsibleError(\"Specified hosts and/or --limit does not match any hosts\")",
            "",
            "        return hosts"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "655": [
                "CLI",
                "version_info"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/vars/manager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "         self._hostvars = None"
            },
            "1": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         self._omit_token = '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest()"
            },
            "2": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "         self._options_vars = defaultdict(dict)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+        self.safe_basedir = False"
            },
            "4": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 126,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         # bad cache plugin is not fatal error"
            },
            "6": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         try:"
            },
            "7": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "             omit_token=self._omit_token,"
            },
            "8": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "             options_vars=self._options_vars,"
            },
            "9": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "             inventory=self._inventory,"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+            safe_basedir=self.safe_basedir,"
            },
            "11": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "         )"
            },
            "12": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "         return data"
            },
            "13": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 149,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "         self._omit_token = data.get('omit_token', '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest())"
            },
            "15": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "         self._inventory = data.get('inventory', None)"
            },
            "16": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "         self._options_vars = data.get('options_vars', dict())"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+        self.safe_basedir = data.get('safe_basedir', False)"
            },
            "18": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 161,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "     @property"
            },
            "20": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "     def extra_vars(self):"
            },
            "21": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         )"
            },
            "22": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 237,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         # default for all cases"
            },
            "24": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        basedirs = [self._loader.get_basedir()]"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+        basedirs = []"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+        if self.safe_basedir:  # avoid adhoc/console loading cwd"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+            basedirs = [self._loader.get_basedir()]"
            },
            "28": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 242,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "         if play:"
            },
            "30": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "             # first we compile any vars specified in defaults/main.yml"
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import sys",
            "",
            "from collections import defaultdict, MutableMapping",
            "",
            "try:",
            "    from hashlib import sha1",
            "except ImportError:",
            "    from sha import sha as sha1",
            "",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleParserError, AnsibleUndefinedVariable, AnsibleFileNotFound",
            "from ansible.inventory.host import Host",
            "from ansible.inventory.helpers import sort_groups, get_group_vars",
            "from ansible.module_utils._text import to_native",
            "from ansible.module_utils.six import iteritems, string_types, text_type",
            "from ansible.plugins.loader import lookup_loader, vars_loader",
            "from ansible.plugins.cache import FactCache",
            "from ansible.template import Templar",
            "from ansible.utils.listify import listify_lookup_plugin_terms",
            "from ansible.utils.vars import combine_vars",
            "from ansible.utils.unsafe_proxy import wrap_var",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "def preprocess_vars(a):",
            "    '''",
            "    Ensures that vars contained in the parameter passed in are",
            "    returned as a list of dictionaries, to ensure for instance",
            "    that vars loaded from a file conform to an expected state.",
            "    '''",
            "",
            "    if a is None:",
            "        return None",
            "    elif not isinstance(a, list):",
            "        data = [a]",
            "    else:",
            "        data = a",
            "",
            "    for item in data:",
            "        if not isinstance(item, MutableMapping):",
            "            raise AnsibleError(\"variable files must contain either a dictionary of variables, or a list of dictionaries. Got: %s (%s)\" % (a, type(a)))",
            "",
            "    return data",
            "",
            "",
            "def strip_internal_keys(dirty, exceptions=None):",
            "    '''",
            "    All keys stating with _ansible_ are internal, so create a copy of the 'dirty' dict",
            "    and remove them from the clean one before returning it",
            "    '''",
            "",
            "    if exceptions is None:",
            "        exceptions = ()",
            "    clean = dirty.copy()",
            "    for k in dirty.keys():",
            "        if isinstance(k, string_types) and k.startswith('_ansible_'):",
            "            if k not in exceptions:",
            "                del clean[k]",
            "        elif isinstance(dirty[k], dict):",
            "            clean[k] = strip_internal_keys(dirty[k])",
            "    return clean",
            "",
            "",
            "def remove_internal_keys(data):",
            "    '''",
            "    More nuanced version of strip_internal_keys",
            "    '''",
            "    for key in list(data.keys()):",
            "        if (key.startswith('_ansible_') and key != '_ansible_parsed') or key in C.INTERNAL_RESULT_KEYS:",
            "            display.warning(\"Removed unexpected internal key in module return: %s = %s\" % (key, data[key]))",
            "            del data[key]",
            "",
            "    # remove bad/empty internal keys",
            "    for key in ['warnings', 'deprecations']:",
            "        if key in data and not data[key]:",
            "            del data[key]",
            "",
            "",
            "class VariableManager:",
            "",
            "    _ALLOWED = frozenset(['plugins_by_group', 'groups_plugins_play', 'groups_plugins_inventory', 'groups_inventory',",
            "                          'all_plugins_play', 'all_plugins_inventory', 'all_inventory'])",
            "",
            "    def __init__(self, loader=None, inventory=None):",
            "",
            "        self._nonpersistent_fact_cache = defaultdict(dict)",
            "        self._vars_cache = defaultdict(dict)",
            "        self._extra_vars = defaultdict(dict)",
            "        self._host_vars_files = defaultdict(dict)",
            "        self._group_vars_files = defaultdict(dict)",
            "        self._inventory = inventory",
            "        self._loader = loader",
            "        self._hostvars = None",
            "        self._omit_token = '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest()",
            "        self._options_vars = defaultdict(dict)",
            "",
            "        # bad cache plugin is not fatal error",
            "        try:",
            "            self._fact_cache = FactCache()",
            "        except AnsibleError as e:",
            "            display.warning(to_native(e))",
            "            # fallback to a dict as in memory cache",
            "            self._fact_cache = {}",
            "",
            "    def __getstate__(self):",
            "        data = dict(",
            "            fact_cache=self._fact_cache,",
            "            np_fact_cache=self._nonpersistent_fact_cache,",
            "            vars_cache=self._vars_cache,",
            "            extra_vars=self._extra_vars,",
            "            host_vars_files=self._host_vars_files,",
            "            group_vars_files=self._group_vars_files,",
            "            omit_token=self._omit_token,",
            "            options_vars=self._options_vars,",
            "            inventory=self._inventory,",
            "        )",
            "        return data",
            "",
            "    def __setstate__(self, data):",
            "        self._fact_cache = data.get('fact_cache', defaultdict(dict))",
            "        self._nonpersistent_fact_cache = data.get('np_fact_cache', defaultdict(dict))",
            "        self._vars_cache = data.get('vars_cache', defaultdict(dict))",
            "        self._extra_vars = data.get('extra_vars', dict())",
            "        self._host_vars_files = data.get('host_vars_files', defaultdict(dict))",
            "        self._group_vars_files = data.get('group_vars_files', defaultdict(dict))",
            "        self._omit_token = data.get('omit_token', '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest())",
            "        self._inventory = data.get('inventory', None)",
            "        self._options_vars = data.get('options_vars', dict())",
            "",
            "    @property",
            "    def extra_vars(self):",
            "        ''' ensures a clean copy of the extra_vars are made '''",
            "        return self._extra_vars.copy()",
            "",
            "    @extra_vars.setter",
            "    def extra_vars(self, value):",
            "        ''' ensures a clean copy of the extra_vars are used to set the value '''",
            "        assert isinstance(value, MutableMapping), \"the type of 'value' for extra_vars should be a MutableMapping, but is a %s\" % type(value)",
            "        self._extra_vars = value.copy()",
            "",
            "    def set_inventory(self, inventory):",
            "        self._inventory = inventory",
            "",
            "    @property",
            "    def options_vars(self):",
            "        ''' ensures a clean copy of the options_vars are made '''",
            "        return self._options_vars.copy()",
            "",
            "    @options_vars.setter",
            "    def options_vars(self, value):",
            "        ''' ensures a clean copy of the options_vars are used to set the value '''",
            "        assert isinstance(value, dict), \"the type of 'value' for options_vars should be a dict, but is a %s\" % type(value)",
            "        self._options_vars = value.copy()",
            "",
            "    def _preprocess_vars(self, a):",
            "        '''",
            "        Ensures that vars contained in the parameter passed in are",
            "        returned as a list of dictionaries, to ensure for instance",
            "        that vars loaded from a file conform to an expected state.",
            "        '''",
            "",
            "        if a is None:",
            "            return None",
            "        elif not isinstance(a, list):",
            "            data = [a]",
            "        else:",
            "            data = a",
            "",
            "        for item in data:",
            "            if not isinstance(item, MutableMapping):",
            "                raise AnsibleError(\"variable files must contain either a dictionary of variables, or a list of dictionaries. Got: %s (%s)\" % (a, type(a)))",
            "",
            "        return data",
            "",
            "    def get_vars(self, play=None, host=None, task=None, include_hostvars=True, include_delegate_to=True, use_cache=True):",
            "        '''",
            "        Returns the variables, with optional \"context\" given via the parameters",
            "        for the play, host, and task (which could possibly result in different",
            "        sets of variables being returned due to the additional context).",
            "",
            "        The order of precedence is:",
            "        - play->roles->get_default_vars (if there is a play context)",
            "        - group_vars_files[host] (if there is a host context)",
            "        - host_vars_files[host] (if there is a host context)",
            "        - host->get_vars (if there is a host context)",
            "        - fact_cache[host] (if there is a host context)",
            "        - play vars (if there is a play context)",
            "        - play vars_files (if there's no host context, ignore",
            "          file names that cannot be templated)",
            "        - task->get_vars (if there is a task context)",
            "        - vars_cache[host] (if there is a host context)",
            "        - extra vars",
            "        '''",
            "",
            "        display.debug(\"in VariableManager get_vars()\")",
            "",
            "        all_vars = dict()",
            "        magic_variables = self._get_magic_variables(",
            "            play=play,",
            "            host=host,",
            "            task=task,",
            "            include_hostvars=include_hostvars,",
            "            include_delegate_to=include_delegate_to,",
            "        )",
            "",
            "        # default for all cases",
            "        basedirs = [self._loader.get_basedir()]",
            "",
            "        if play:",
            "            # first we compile any vars specified in defaults/main.yml",
            "            # for all roles within the specified play",
            "            for role in play.get_roles():",
            "                all_vars = combine_vars(all_vars, role.get_default_vars())",
            "",
            "        if task:",
            "            # set basedirs",
            "            if C.PLAYBOOK_VARS_ROOT == 'all':  # should be default",
            "                basedirs = task.get_search_path()",
            "            elif C.PLAYBOOK_VARS_ROOT in ('bottom', 'playbook_dir'):  # only option in 2.4.0",
            "                basedirs = [task.get_search_path()[0]]",
            "            elif C.PLAYBOOK_VARS_ROOT != 'top':",
            "                # preserves default basedirs, only option pre 2.3",
            "                raise AnsibleError('Unkown playbook vars logic: %s' % C.PLAYBOOK_VARS_ROOT)",
            "",
            "            # if we have a task in this context, and that task has a role, make",
            "            # sure it sees its defaults above any other roles, as we previously",
            "            # (v1) made sure each task had a copy of its roles default vars",
            "            if task._role is not None and (play or task.action == 'include_role'):",
            "                all_vars = combine_vars(all_vars, task._role.get_default_vars(dep_chain=task.get_dep_chain()))",
            "",
            "        if host:",
            "            # THE 'all' group and the rest of groups for a host, used below",
            "            all_group = self._inventory.groups.get('all')",
            "            host_groups = sort_groups([g for g in host.get_groups() if g.name not in ['all']])",
            "",
            "            def _get_plugin_vars(plugin, path, entities):",
            "                data = {}",
            "                try:",
            "                    data = plugin.get_vars(self._loader, path, entities)",
            "                except AttributeError:",
            "                    try:",
            "                        for entity in entities:",
            "                            if isinstance(entity, Host):",
            "                                data.update(plugin.get_host_vars(entity.name))",
            "                            else:",
            "                                data.update(plugin.get_group_vars(entity.name))",
            "                    except AttributeError:",
            "                        if hasattr(plugin, 'run'):",
            "                            raise AnsibleError(\"Cannot use v1 type vars plugin %s from %s\" % (plugin._load_name, plugin._original_path))",
            "                        else:",
            "                            raise AnsibleError(\"Invalid vars plugin %s from %s\" % (plugin._load_name, plugin._original_path))",
            "                return data",
            "",
            "            # internal fuctions that actually do the work",
            "            def _plugins_inventory(entities):",
            "                ''' merges all entities by inventory source '''",
            "                data = {}",
            "                for inventory_dir in self._inventory._sources:",
            "                    if ',' in inventory_dir and not os.path.exists(inventory_dir):  # skip host lists",
            "                        continue",
            "                    elif not os.path.isdir(inventory_dir):  # always pass 'inventory directory'",
            "                        inventory_dir = os.path.dirname(inventory_dir)",
            "",
            "                    for plugin in vars_loader.all():",
            "                        data = combine_vars(data, _get_plugin_vars(plugin, inventory_dir, entities))",
            "                return data",
            "",
            "            def _plugins_play(entities):",
            "                ''' merges all entities adjacent to play '''",
            "                data = {}",
            "                for plugin in vars_loader.all():",
            "                    for path in basedirs:",
            "                        data = combine_vars(data, _get_plugin_vars(plugin, path, entities))",
            "                return data",
            "",
            "            # configurable functions that are sortable via config, rememer to add to _ALLOWED if expanding this list",
            "            def all_inventory():",
            "                return all_group.get_vars()",
            "",
            "            def all_plugins_inventory():",
            "                return _plugins_inventory([all_group])",
            "",
            "            def all_plugins_play():",
            "                return _plugins_play([all_group])",
            "",
            "            def groups_inventory():",
            "                ''' gets group vars from inventory '''",
            "                return get_group_vars(host_groups)",
            "",
            "            def groups_plugins_inventory():",
            "                ''' gets plugin sources from inventory for groups '''",
            "                return _plugins_inventory(host_groups)",
            "",
            "            def groups_plugins_play():",
            "                ''' gets plugin sources from play for groups '''",
            "                return _plugins_play(host_groups)",
            "",
            "            def plugins_by_groups():",
            "                '''",
            "                    merges all plugin sources by group,",
            "                    This should be used instead, NOT in combination with the other groups_plugins* functions",
            "                '''",
            "                data = {}",
            "                for group in host_groups:",
            "                    data[group] = combine_vars(data[group], _plugins_inventory(group))",
            "                    data[group] = combine_vars(data[group], _plugins_play(group))",
            "                return data",
            "",
            "            # Merge groups as per precedence config",
            "            # only allow to call the functions we want exposed",
            "            for entry in C.VARIABLE_PRECEDENCE:",
            "                if entry in self._ALLOWED:",
            "                    display.debug('Calling %s to load vars for %s' % (entry, host.name))",
            "                    all_vars = combine_vars(all_vars, locals()[entry]())",
            "                else:",
            "                    display.warning('Ignoring unknown variable precedence entry: %s' % (entry))",
            "",
            "            # host vars, from inventory, inventory adjacent and play adjacent via plugins",
            "            all_vars = combine_vars(all_vars, host.get_vars())",
            "            all_vars = combine_vars(all_vars, _plugins_inventory([host]))",
            "            all_vars = combine_vars(all_vars, _plugins_play([host]))",
            "",
            "            # finally, the facts caches for this host, if it exists",
            "            try:",
            "                host_facts = wrap_var(self._fact_cache.get(host.name, {}))",
            "",
            "                # push facts to main namespace",
            "                all_vars = combine_vars(all_vars, host_facts)",
            "            except KeyError:",
            "                pass",
            "",
            "        if play:",
            "            all_vars = combine_vars(all_vars, play.get_vars())",
            "",
            "            for vars_file_item in play.get_vars_files():",
            "                # create a set of temporary vars here, which incorporate the extra",
            "                # and magic vars so we can properly template the vars_files entries",
            "                temp_vars = combine_vars(all_vars, self._extra_vars)",
            "                temp_vars = combine_vars(temp_vars, magic_variables)",
            "                templar = Templar(loader=self._loader, variables=temp_vars)",
            "",
            "                # we assume each item in the list is itself a list, as we",
            "                # support \"conditional includes\" for vars_files, which mimics",
            "                # the with_first_found mechanism.",
            "                vars_file_list = vars_file_item",
            "                if not isinstance(vars_file_list, list):",
            "                    vars_file_list = [vars_file_list]",
            "",
            "                # now we iterate through the (potential) files, and break out",
            "                # as soon as we read one from the list. If none are found, we",
            "                # raise an error, which is silently ignored at this point.",
            "                try:",
            "                    for vars_file in vars_file_list:",
            "                        vars_file = templar.template(vars_file)",
            "                        try:",
            "                            data = preprocess_vars(self._loader.load_from_file(vars_file, unsafe=True))",
            "                            if data is not None:",
            "                                for item in data:",
            "                                    all_vars = combine_vars(all_vars, item)",
            "                            break",
            "                        except AnsibleFileNotFound:",
            "                            # we continue on loader failures",
            "                            continue",
            "                        except AnsibleParserError:",
            "                            raise",
            "                    else:",
            "                        # if include_delegate_to is set to False, we ignore the missing",
            "                        # vars file here because we're working on a delegated host",
            "                        if include_delegate_to:",
            "                            raise AnsibleFileNotFound(\"vars file %s was not found\" % vars_file_item)",
            "                except (UndefinedError, AnsibleUndefinedVariable):",
            "                    if host is not None and self._fact_cache.get(host.name, dict()).get('module_setup') and task is not None:",
            "                        raise AnsibleUndefinedVariable(\"an undefined variable was found when attempting to template the vars_files item '%s'\" % vars_file_item,",
            "                                                       obj=vars_file_item)",
            "                    else:",
            "                        # we do not have a full context here, and the missing variable could be because of that",
            "                        # so just show a warning and continue",
            "                        display.vvv(\"skipping vars_file '%s' due to an undefined variable\" % vars_file_item)",
            "                        continue",
            "",
            "                display.vvv(\"Read vars_file '%s'\" % vars_file_item)",
            "",
            "            # By default, we now merge in all vars from all roles in the play,",
            "            # unless the user has disabled this via a config option",
            "            if not C.DEFAULT_PRIVATE_ROLE_VARS:",
            "                for role in play.get_roles():",
            "                    all_vars = combine_vars(all_vars, role.get_vars(include_params=False))",
            "",
            "        # next, we merge in the vars from the role, which will specifically",
            "        # follow the role dependency chain, and then we merge in the tasks",
            "        # vars (which will look at parent blocks/task includes)",
            "        if task:",
            "            if task._role:",
            "                all_vars = combine_vars(all_vars, task._role.get_vars(task.get_dep_chain(), include_params=False))",
            "            all_vars = combine_vars(all_vars, task.get_vars())",
            "",
            "        # next, we merge in the vars cache (include vars) and nonpersistent",
            "        # facts cache (set_fact/register), in that order",
            "        if host:",
            "            all_vars = combine_vars(all_vars, self._vars_cache.get(host.get_name(), dict()))",
            "            all_vars = combine_vars(all_vars, self._nonpersistent_fact_cache.get(host.name, dict()))",
            "",
            "        # next, we merge in role params and task include params",
            "        if task:",
            "            if task._role:",
            "                all_vars = combine_vars(all_vars, task._role.get_role_params(task.get_dep_chain()))",
            "",
            "            # special case for include tasks, where the include params",
            "            # may be specified in the vars field for the task, which should",
            "            # have higher precedence than the vars/np facts above",
            "            all_vars = combine_vars(all_vars, task.get_include_params())",
            "",
            "        # extra vars",
            "        all_vars = combine_vars(all_vars, self._extra_vars)",
            "",
            "        # magic variables",
            "        all_vars = combine_vars(all_vars, magic_variables)",
            "",
            "        # special case for the 'environment' magic variable, as someone",
            "        # may have set it as a variable and we don't want to stomp on it",
            "        if task:",
            "            all_vars['environment'] = task.environment",
            "",
            "        # if we have a task and we're delegating to another host, figure out the",
            "        # variables for that host now so we don't have to rely on hostvars later",
            "        if task and task.delegate_to is not None and include_delegate_to:",
            "            all_vars['ansible_delegated_vars'] = self._get_delegated_vars(play, task, all_vars)",
            "",
            "        # 'vars' magic var",
            "        if task or play:",
            "            # has to be copy, otherwise recursive ref",
            "            all_vars['vars'] = all_vars.copy()",
            "",
            "        display.debug(\"done with get_vars()\")",
            "        return all_vars",
            "",
            "    def _get_magic_variables(self, play, host, task, include_hostvars, include_delegate_to):",
            "        '''",
            "        Returns a dictionary of so-called \"magic\" variables in Ansible,",
            "        which are special variables we set internally for use.",
            "        '''",
            "",
            "        variables = {}",
            "        variables['playbook_dir'] = os.path.abspath(self._loader.get_basedir())",
            "        variables['ansible_playbook_python'] = sys.executable",
            "",
            "        if play:",
            "            variables['role_names'] = [r._role_name for r in play.roles]",
            "",
            "        if task:",
            "            if task._role:",
            "                variables['role_name'] = task._role.get_name()",
            "                variables['role_path'] = task._role._role_path",
            "                variables['role_uuid'] = text_type(task._role._uuid)",
            "",
            "        if self._inventory is not None:",
            "            variables['groups'] = self._inventory.get_groups_dict()",
            "            if play:",
            "                templar = Templar(loader=self._loader)",
            "                if templar.is_template(play.hosts):",
            "                    pattern = 'all'",
            "                else:",
            "                    pattern = play.hosts or 'all'",
            "                # add the list of hosts in the play, as adjusted for limit/filters",
            "                variables['ansible_play_hosts_all'] = [x.name for x in self._inventory.get_hosts(pattern=pattern, ignore_restrictions=True)]",
            "                variables['ansible_play_hosts'] = [x for x in variables['ansible_play_hosts_all'] if x not in play._removed_hosts]",
            "                variables['ansible_play_batch'] = [x.name for x in self._inventory.get_hosts() if x.name not in play._removed_hosts]",
            "",
            "                # DEPRECATED: play_hosts should be deprecated in favor of ansible_play_batch,",
            "                # however this would take work in the templating engine, so for now we'll add both",
            "                variables['play_hosts'] = variables['ansible_play_batch']",
            "",
            "        # the 'omit' value alows params to be left out if the variable they are based on is undefined",
            "        variables['omit'] = self._omit_token",
            "        # Set options vars",
            "        for option, option_value in iteritems(self._options_vars):",
            "            variables[option] = option_value",
            "",
            "        if self._hostvars is not None and include_hostvars:",
            "            variables['hostvars'] = self._hostvars",
            "",
            "        return variables",
            "",
            "    def _get_delegated_vars(self, play, task, existing_variables):",
            "        # we unfortunately need to template the delegate_to field here,",
            "        # as we're fetching vars before post_validate has been called on",
            "        # the task that has been passed in",
            "        vars_copy = existing_variables.copy()",
            "        templar = Templar(loader=self._loader, variables=vars_copy)",
            "",
            "        items = []",
            "        if task.loop is not None:",
            "            if task.loop in lookup_loader:",
            "                try:",
            "                    loop_terms = listify_lookup_plugin_terms(terms=task.loop_args, templar=templar,",
            "                                                             loader=self._loader, fail_on_undefined=True, convert_bare=False)",
            "                    items = lookup_loader.get(task.loop, loader=self._loader, templar=templar).run(terms=loop_terms, variables=vars_copy)",
            "                except AnsibleUndefinedVariable:",
            "                    # This task will be skipped later due to this, so we just setup",
            "                    # a dummy array for the later code so it doesn't fail",
            "                    items = [None]",
            "            else:",
            "                raise AnsibleError(\"Unexpected failure in finding the lookup named '%s' in the available lookup plugins\" % task.loop)",
            "        else:",
            "            items = [None]",
            "",
            "        delegated_host_vars = dict()",
            "        item_var = getattr(task.loop_control, 'loop_var', 'item')",
            "        for item in items:",
            "            # update the variables with the item value for templating, in case we need it",
            "            if item is not None:",
            "                vars_copy[item_var] = item",
            "",
            "            templar.set_available_variables(vars_copy)",
            "            delegated_host_name = templar.template(task.delegate_to, fail_on_undefined=False)",
            "            if delegated_host_name is None:",
            "                raise AnsibleError(message=\"Undefined delegate_to host for task:\", obj=task._ds)",
            "            if delegated_host_name in delegated_host_vars:",
            "                # no need to repeat ourselves, as the delegate_to value",
            "                # does not appear to be tied to the loop item variable",
            "                continue",
            "",
            "            # a dictionary of variables to use if we have to create a new host below",
            "            # we set the default port based on the default transport here, to make sure",
            "            # we use the proper default for windows",
            "            new_port = C.DEFAULT_REMOTE_PORT",
            "            if C.DEFAULT_TRANSPORT == 'winrm':",
            "                new_port = 5986",
            "",
            "            new_delegated_host_vars = dict(",
            "                ansible_delegated_host=delegated_host_name,",
            "                ansible_host=delegated_host_name,  # not redundant as other sources can change ansible_host",
            "                ansible_port=new_port,",
            "                ansible_user=C.DEFAULT_REMOTE_USER,",
            "                ansible_connection=C.DEFAULT_TRANSPORT,",
            "            )",
            "",
            "            # now try to find the delegated-to host in inventory, or failing that,",
            "            # create a new host on the fly so we can fetch variables for it",
            "            delegated_host = None",
            "            if self._inventory is not None:",
            "                delegated_host = self._inventory.get_host(delegated_host_name)",
            "                # try looking it up based on the address field, and finally",
            "                # fall back to creating a host on the fly to use for the var lookup",
            "                if delegated_host is None:",
            "                    if delegated_host_name in C.LOCALHOST:",
            "                        delegated_host = self._inventory.localhost",
            "                    else:",
            "                        for h in self._inventory.get_hosts(ignore_limits=True, ignore_restrictions=True):",
            "                            # check if the address matches, or if both the delegated_to host",
            "                            # and the current host are in the list of localhost aliases",
            "                            if h.address == delegated_host_name:",
            "                                delegated_host = h",
            "                                break",
            "                        else:",
            "                            delegated_host = Host(name=delegated_host_name)",
            "                            delegated_host.vars = combine_vars(delegated_host.vars, new_delegated_host_vars)",
            "            else:",
            "                delegated_host = Host(name=delegated_host_name)",
            "                delegated_host.vars = combine_vars(delegated_host.vars, new_delegated_host_vars)",
            "",
            "            # now we go fetch the vars for the delegated-to host and save them in our",
            "            # master dictionary of variables to be used later in the TaskExecutor/PlayContext",
            "            delegated_host_vars[delegated_host_name] = self.get_vars(",
            "                play=play,",
            "                host=delegated_host,",
            "                task=task,",
            "                include_delegate_to=False,",
            "                include_hostvars=False,",
            "            )",
            "        return delegated_host_vars",
            "",
            "    def clear_facts(self, hostname):",
            "        '''",
            "        Clears the facts for a host",
            "        '''",
            "        if hostname in self._fact_cache:",
            "            del self._fact_cache[hostname]",
            "",
            "    def set_host_facts(self, host, facts):",
            "        '''",
            "        Sets or updates the given facts for a host in the fact cache.",
            "        '''",
            "",
            "        assert isinstance(facts, dict), \"the type of 'facts' to set for host_facts should be a dict but is a %s\" % type(facts)",
            "",
            "        if host.name not in self._fact_cache:",
            "            self._fact_cache[host.name] = facts",
            "        else:",
            "            try:",
            "                self._fact_cache.update(host.name, facts)",
            "            except KeyError:",
            "                self._fact_cache[host.name] = facts",
            "",
            "    def set_nonpersistent_facts(self, host, facts):",
            "        '''",
            "        Sets or updates the given facts for a host in the fact cache.",
            "        '''",
            "",
            "        assert isinstance(facts, dict), \"the type of 'facts' to set for nonpersistent_facts should be a dict but is a %s\" % type(facts)",
            "",
            "        if host.name not in self._nonpersistent_fact_cache:",
            "            self._nonpersistent_fact_cache[host.name] = facts",
            "        else:",
            "            try:",
            "                self._nonpersistent_fact_cache[host.name].update(facts)",
            "            except KeyError:",
            "                self._nonpersistent_fact_cache[host.name] = facts",
            "",
            "    def set_host_variable(self, host, varname, value):",
            "        '''",
            "        Sets a value in the vars_cache for a host.",
            "        '''",
            "        host_name = host.get_name()",
            "        if host_name not in self._vars_cache:",
            "            self._vars_cache[host_name] = dict()",
            "        if varname in self._vars_cache[host_name] and isinstance(self._vars_cache[host_name][varname], MutableMapping) and isinstance(value, MutableMapping):",
            "            self._vars_cache[host_name] = combine_vars(self._vars_cache[host_name], {varname: value})",
            "        else:",
            "            self._vars_cache[host_name][varname] = value"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import os",
            "import sys",
            "",
            "from collections import defaultdict, MutableMapping",
            "",
            "try:",
            "    from hashlib import sha1",
            "except ImportError:",
            "    from sha import sha as sha1",
            "",
            "from jinja2.exceptions import UndefinedError",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleParserError, AnsibleUndefinedVariable, AnsibleFileNotFound",
            "from ansible.inventory.host import Host",
            "from ansible.inventory.helpers import sort_groups, get_group_vars",
            "from ansible.module_utils._text import to_native",
            "from ansible.module_utils.six import iteritems, string_types, text_type",
            "from ansible.plugins.loader import lookup_loader, vars_loader",
            "from ansible.plugins.cache import FactCache",
            "from ansible.template import Templar",
            "from ansible.utils.listify import listify_lookup_plugin_terms",
            "from ansible.utils.vars import combine_vars",
            "from ansible.utils.unsafe_proxy import wrap_var",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "def preprocess_vars(a):",
            "    '''",
            "    Ensures that vars contained in the parameter passed in are",
            "    returned as a list of dictionaries, to ensure for instance",
            "    that vars loaded from a file conform to an expected state.",
            "    '''",
            "",
            "    if a is None:",
            "        return None",
            "    elif not isinstance(a, list):",
            "        data = [a]",
            "    else:",
            "        data = a",
            "",
            "    for item in data:",
            "        if not isinstance(item, MutableMapping):",
            "            raise AnsibleError(\"variable files must contain either a dictionary of variables, or a list of dictionaries. Got: %s (%s)\" % (a, type(a)))",
            "",
            "    return data",
            "",
            "",
            "def strip_internal_keys(dirty, exceptions=None):",
            "    '''",
            "    All keys stating with _ansible_ are internal, so create a copy of the 'dirty' dict",
            "    and remove them from the clean one before returning it",
            "    '''",
            "",
            "    if exceptions is None:",
            "        exceptions = ()",
            "    clean = dirty.copy()",
            "    for k in dirty.keys():",
            "        if isinstance(k, string_types) and k.startswith('_ansible_'):",
            "            if k not in exceptions:",
            "                del clean[k]",
            "        elif isinstance(dirty[k], dict):",
            "            clean[k] = strip_internal_keys(dirty[k])",
            "    return clean",
            "",
            "",
            "def remove_internal_keys(data):",
            "    '''",
            "    More nuanced version of strip_internal_keys",
            "    '''",
            "    for key in list(data.keys()):",
            "        if (key.startswith('_ansible_') and key != '_ansible_parsed') or key in C.INTERNAL_RESULT_KEYS:",
            "            display.warning(\"Removed unexpected internal key in module return: %s = %s\" % (key, data[key]))",
            "            del data[key]",
            "",
            "    # remove bad/empty internal keys",
            "    for key in ['warnings', 'deprecations']:",
            "        if key in data and not data[key]:",
            "            del data[key]",
            "",
            "",
            "class VariableManager:",
            "",
            "    _ALLOWED = frozenset(['plugins_by_group', 'groups_plugins_play', 'groups_plugins_inventory', 'groups_inventory',",
            "                          'all_plugins_play', 'all_plugins_inventory', 'all_inventory'])",
            "",
            "    def __init__(self, loader=None, inventory=None):",
            "",
            "        self._nonpersistent_fact_cache = defaultdict(dict)",
            "        self._vars_cache = defaultdict(dict)",
            "        self._extra_vars = defaultdict(dict)",
            "        self._host_vars_files = defaultdict(dict)",
            "        self._group_vars_files = defaultdict(dict)",
            "        self._inventory = inventory",
            "        self._loader = loader",
            "        self._hostvars = None",
            "        self._omit_token = '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest()",
            "        self._options_vars = defaultdict(dict)",
            "        self.safe_basedir = False",
            "",
            "        # bad cache plugin is not fatal error",
            "        try:",
            "            self._fact_cache = FactCache()",
            "        except AnsibleError as e:",
            "            display.warning(to_native(e))",
            "            # fallback to a dict as in memory cache",
            "            self._fact_cache = {}",
            "",
            "    def __getstate__(self):",
            "        data = dict(",
            "            fact_cache=self._fact_cache,",
            "            np_fact_cache=self._nonpersistent_fact_cache,",
            "            vars_cache=self._vars_cache,",
            "            extra_vars=self._extra_vars,",
            "            host_vars_files=self._host_vars_files,",
            "            group_vars_files=self._group_vars_files,",
            "            omit_token=self._omit_token,",
            "            options_vars=self._options_vars,",
            "            inventory=self._inventory,",
            "            safe_basedir=self.safe_basedir,",
            "        )",
            "        return data",
            "",
            "    def __setstate__(self, data):",
            "        self._fact_cache = data.get('fact_cache', defaultdict(dict))",
            "        self._nonpersistent_fact_cache = data.get('np_fact_cache', defaultdict(dict))",
            "        self._vars_cache = data.get('vars_cache', defaultdict(dict))",
            "        self._extra_vars = data.get('extra_vars', dict())",
            "        self._host_vars_files = data.get('host_vars_files', defaultdict(dict))",
            "        self._group_vars_files = data.get('group_vars_files', defaultdict(dict))",
            "        self._omit_token = data.get('omit_token', '__omit_place_holder__%s' % sha1(os.urandom(64)).hexdigest())",
            "        self._inventory = data.get('inventory', None)",
            "        self._options_vars = data.get('options_vars', dict())",
            "        self.safe_basedir = data.get('safe_basedir', False)",
            "",
            "    @property",
            "    def extra_vars(self):",
            "        ''' ensures a clean copy of the extra_vars are made '''",
            "        return self._extra_vars.copy()",
            "",
            "    @extra_vars.setter",
            "    def extra_vars(self, value):",
            "        ''' ensures a clean copy of the extra_vars are used to set the value '''",
            "        assert isinstance(value, MutableMapping), \"the type of 'value' for extra_vars should be a MutableMapping, but is a %s\" % type(value)",
            "        self._extra_vars = value.copy()",
            "",
            "    def set_inventory(self, inventory):",
            "        self._inventory = inventory",
            "",
            "    @property",
            "    def options_vars(self):",
            "        ''' ensures a clean copy of the options_vars are made '''",
            "        return self._options_vars.copy()",
            "",
            "    @options_vars.setter",
            "    def options_vars(self, value):",
            "        ''' ensures a clean copy of the options_vars are used to set the value '''",
            "        assert isinstance(value, dict), \"the type of 'value' for options_vars should be a dict, but is a %s\" % type(value)",
            "        self._options_vars = value.copy()",
            "",
            "    def _preprocess_vars(self, a):",
            "        '''",
            "        Ensures that vars contained in the parameter passed in are",
            "        returned as a list of dictionaries, to ensure for instance",
            "        that vars loaded from a file conform to an expected state.",
            "        '''",
            "",
            "        if a is None:",
            "            return None",
            "        elif not isinstance(a, list):",
            "            data = [a]",
            "        else:",
            "            data = a",
            "",
            "        for item in data:",
            "            if not isinstance(item, MutableMapping):",
            "                raise AnsibleError(\"variable files must contain either a dictionary of variables, or a list of dictionaries. Got: %s (%s)\" % (a, type(a)))",
            "",
            "        return data",
            "",
            "    def get_vars(self, play=None, host=None, task=None, include_hostvars=True, include_delegate_to=True, use_cache=True):",
            "        '''",
            "        Returns the variables, with optional \"context\" given via the parameters",
            "        for the play, host, and task (which could possibly result in different",
            "        sets of variables being returned due to the additional context).",
            "",
            "        The order of precedence is:",
            "        - play->roles->get_default_vars (if there is a play context)",
            "        - group_vars_files[host] (if there is a host context)",
            "        - host_vars_files[host] (if there is a host context)",
            "        - host->get_vars (if there is a host context)",
            "        - fact_cache[host] (if there is a host context)",
            "        - play vars (if there is a play context)",
            "        - play vars_files (if there's no host context, ignore",
            "          file names that cannot be templated)",
            "        - task->get_vars (if there is a task context)",
            "        - vars_cache[host] (if there is a host context)",
            "        - extra vars",
            "        '''",
            "",
            "        display.debug(\"in VariableManager get_vars()\")",
            "",
            "        all_vars = dict()",
            "        magic_variables = self._get_magic_variables(",
            "            play=play,",
            "            host=host,",
            "            task=task,",
            "            include_hostvars=include_hostvars,",
            "            include_delegate_to=include_delegate_to,",
            "        )",
            "",
            "        # default for all cases",
            "        basedirs = []",
            "        if self.safe_basedir:  # avoid adhoc/console loading cwd",
            "            basedirs = [self._loader.get_basedir()]",
            "",
            "        if play:",
            "            # first we compile any vars specified in defaults/main.yml",
            "            # for all roles within the specified play",
            "            for role in play.get_roles():",
            "                all_vars = combine_vars(all_vars, role.get_default_vars())",
            "",
            "        if task:",
            "            # set basedirs",
            "            if C.PLAYBOOK_VARS_ROOT == 'all':  # should be default",
            "                basedirs = task.get_search_path()",
            "            elif C.PLAYBOOK_VARS_ROOT in ('bottom', 'playbook_dir'):  # only option in 2.4.0",
            "                basedirs = [task.get_search_path()[0]]",
            "            elif C.PLAYBOOK_VARS_ROOT != 'top':",
            "                # preserves default basedirs, only option pre 2.3",
            "                raise AnsibleError('Unkown playbook vars logic: %s' % C.PLAYBOOK_VARS_ROOT)",
            "",
            "            # if we have a task in this context, and that task has a role, make",
            "            # sure it sees its defaults above any other roles, as we previously",
            "            # (v1) made sure each task had a copy of its roles default vars",
            "            if task._role is not None and (play or task.action == 'include_role'):",
            "                all_vars = combine_vars(all_vars, task._role.get_default_vars(dep_chain=task.get_dep_chain()))",
            "",
            "        if host:",
            "            # THE 'all' group and the rest of groups for a host, used below",
            "            all_group = self._inventory.groups.get('all')",
            "            host_groups = sort_groups([g for g in host.get_groups() if g.name not in ['all']])",
            "",
            "            def _get_plugin_vars(plugin, path, entities):",
            "                data = {}",
            "                try:",
            "                    data = plugin.get_vars(self._loader, path, entities)",
            "                except AttributeError:",
            "                    try:",
            "                        for entity in entities:",
            "                            if isinstance(entity, Host):",
            "                                data.update(plugin.get_host_vars(entity.name))",
            "                            else:",
            "                                data.update(plugin.get_group_vars(entity.name))",
            "                    except AttributeError:",
            "                        if hasattr(plugin, 'run'):",
            "                            raise AnsibleError(\"Cannot use v1 type vars plugin %s from %s\" % (plugin._load_name, plugin._original_path))",
            "                        else:",
            "                            raise AnsibleError(\"Invalid vars plugin %s from %s\" % (plugin._load_name, plugin._original_path))",
            "                return data",
            "",
            "            # internal fuctions that actually do the work",
            "            def _plugins_inventory(entities):",
            "                ''' merges all entities by inventory source '''",
            "                data = {}",
            "                for inventory_dir in self._inventory._sources:",
            "                    if ',' in inventory_dir and not os.path.exists(inventory_dir):  # skip host lists",
            "                        continue",
            "                    elif not os.path.isdir(inventory_dir):  # always pass 'inventory directory'",
            "                        inventory_dir = os.path.dirname(inventory_dir)",
            "",
            "                    for plugin in vars_loader.all():",
            "                        data = combine_vars(data, _get_plugin_vars(plugin, inventory_dir, entities))",
            "                return data",
            "",
            "            def _plugins_play(entities):",
            "                ''' merges all entities adjacent to play '''",
            "                data = {}",
            "                for plugin in vars_loader.all():",
            "                    for path in basedirs:",
            "                        data = combine_vars(data, _get_plugin_vars(plugin, path, entities))",
            "                return data",
            "",
            "            # configurable functions that are sortable via config, rememer to add to _ALLOWED if expanding this list",
            "            def all_inventory():",
            "                return all_group.get_vars()",
            "",
            "            def all_plugins_inventory():",
            "                return _plugins_inventory([all_group])",
            "",
            "            def all_plugins_play():",
            "                return _plugins_play([all_group])",
            "",
            "            def groups_inventory():",
            "                ''' gets group vars from inventory '''",
            "                return get_group_vars(host_groups)",
            "",
            "            def groups_plugins_inventory():",
            "                ''' gets plugin sources from inventory for groups '''",
            "                return _plugins_inventory(host_groups)",
            "",
            "            def groups_plugins_play():",
            "                ''' gets plugin sources from play for groups '''",
            "                return _plugins_play(host_groups)",
            "",
            "            def plugins_by_groups():",
            "                '''",
            "                    merges all plugin sources by group,",
            "                    This should be used instead, NOT in combination with the other groups_plugins* functions",
            "                '''",
            "                data = {}",
            "                for group in host_groups:",
            "                    data[group] = combine_vars(data[group], _plugins_inventory(group))",
            "                    data[group] = combine_vars(data[group], _plugins_play(group))",
            "                return data",
            "",
            "            # Merge groups as per precedence config",
            "            # only allow to call the functions we want exposed",
            "            for entry in C.VARIABLE_PRECEDENCE:",
            "                if entry in self._ALLOWED:",
            "                    display.debug('Calling %s to load vars for %s' % (entry, host.name))",
            "                    all_vars = combine_vars(all_vars, locals()[entry]())",
            "                else:",
            "                    display.warning('Ignoring unknown variable precedence entry: %s' % (entry))",
            "",
            "            # host vars, from inventory, inventory adjacent and play adjacent via plugins",
            "            all_vars = combine_vars(all_vars, host.get_vars())",
            "            all_vars = combine_vars(all_vars, _plugins_inventory([host]))",
            "            all_vars = combine_vars(all_vars, _plugins_play([host]))",
            "",
            "            # finally, the facts caches for this host, if it exists",
            "            try:",
            "                host_facts = wrap_var(self._fact_cache.get(host.name, {}))",
            "",
            "                # push facts to main namespace",
            "                all_vars = combine_vars(all_vars, host_facts)",
            "            except KeyError:",
            "                pass",
            "",
            "        if play:",
            "            all_vars = combine_vars(all_vars, play.get_vars())",
            "",
            "            for vars_file_item in play.get_vars_files():",
            "                # create a set of temporary vars here, which incorporate the extra",
            "                # and magic vars so we can properly template the vars_files entries",
            "                temp_vars = combine_vars(all_vars, self._extra_vars)",
            "                temp_vars = combine_vars(temp_vars, magic_variables)",
            "                templar = Templar(loader=self._loader, variables=temp_vars)",
            "",
            "                # we assume each item in the list is itself a list, as we",
            "                # support \"conditional includes\" for vars_files, which mimics",
            "                # the with_first_found mechanism.",
            "                vars_file_list = vars_file_item",
            "                if not isinstance(vars_file_list, list):",
            "                    vars_file_list = [vars_file_list]",
            "",
            "                # now we iterate through the (potential) files, and break out",
            "                # as soon as we read one from the list. If none are found, we",
            "                # raise an error, which is silently ignored at this point.",
            "                try:",
            "                    for vars_file in vars_file_list:",
            "                        vars_file = templar.template(vars_file)",
            "                        try:",
            "                            data = preprocess_vars(self._loader.load_from_file(vars_file, unsafe=True))",
            "                            if data is not None:",
            "                                for item in data:",
            "                                    all_vars = combine_vars(all_vars, item)",
            "                            break",
            "                        except AnsibleFileNotFound:",
            "                            # we continue on loader failures",
            "                            continue",
            "                        except AnsibleParserError:",
            "                            raise",
            "                    else:",
            "                        # if include_delegate_to is set to False, we ignore the missing",
            "                        # vars file here because we're working on a delegated host",
            "                        if include_delegate_to:",
            "                            raise AnsibleFileNotFound(\"vars file %s was not found\" % vars_file_item)",
            "                except (UndefinedError, AnsibleUndefinedVariable):",
            "                    if host is not None and self._fact_cache.get(host.name, dict()).get('module_setup') and task is not None:",
            "                        raise AnsibleUndefinedVariable(\"an undefined variable was found when attempting to template the vars_files item '%s'\" % vars_file_item,",
            "                                                       obj=vars_file_item)",
            "                    else:",
            "                        # we do not have a full context here, and the missing variable could be because of that",
            "                        # so just show a warning and continue",
            "                        display.vvv(\"skipping vars_file '%s' due to an undefined variable\" % vars_file_item)",
            "                        continue",
            "",
            "                display.vvv(\"Read vars_file '%s'\" % vars_file_item)",
            "",
            "            # By default, we now merge in all vars from all roles in the play,",
            "            # unless the user has disabled this via a config option",
            "            if not C.DEFAULT_PRIVATE_ROLE_VARS:",
            "                for role in play.get_roles():",
            "                    all_vars = combine_vars(all_vars, role.get_vars(include_params=False))",
            "",
            "        # next, we merge in the vars from the role, which will specifically",
            "        # follow the role dependency chain, and then we merge in the tasks",
            "        # vars (which will look at parent blocks/task includes)",
            "        if task:",
            "            if task._role:",
            "                all_vars = combine_vars(all_vars, task._role.get_vars(task.get_dep_chain(), include_params=False))",
            "            all_vars = combine_vars(all_vars, task.get_vars())",
            "",
            "        # next, we merge in the vars cache (include vars) and nonpersistent",
            "        # facts cache (set_fact/register), in that order",
            "        if host:",
            "            all_vars = combine_vars(all_vars, self._vars_cache.get(host.get_name(), dict()))",
            "            all_vars = combine_vars(all_vars, self._nonpersistent_fact_cache.get(host.name, dict()))",
            "",
            "        # next, we merge in role params and task include params",
            "        if task:",
            "            if task._role:",
            "                all_vars = combine_vars(all_vars, task._role.get_role_params(task.get_dep_chain()))",
            "",
            "            # special case for include tasks, where the include params",
            "            # may be specified in the vars field for the task, which should",
            "            # have higher precedence than the vars/np facts above",
            "            all_vars = combine_vars(all_vars, task.get_include_params())",
            "",
            "        # extra vars",
            "        all_vars = combine_vars(all_vars, self._extra_vars)",
            "",
            "        # magic variables",
            "        all_vars = combine_vars(all_vars, magic_variables)",
            "",
            "        # special case for the 'environment' magic variable, as someone",
            "        # may have set it as a variable and we don't want to stomp on it",
            "        if task:",
            "            all_vars['environment'] = task.environment",
            "",
            "        # if we have a task and we're delegating to another host, figure out the",
            "        # variables for that host now so we don't have to rely on hostvars later",
            "        if task and task.delegate_to is not None and include_delegate_to:",
            "            all_vars['ansible_delegated_vars'] = self._get_delegated_vars(play, task, all_vars)",
            "",
            "        # 'vars' magic var",
            "        if task or play:",
            "            # has to be copy, otherwise recursive ref",
            "            all_vars['vars'] = all_vars.copy()",
            "",
            "        display.debug(\"done with get_vars()\")",
            "        return all_vars",
            "",
            "    def _get_magic_variables(self, play, host, task, include_hostvars, include_delegate_to):",
            "        '''",
            "        Returns a dictionary of so-called \"magic\" variables in Ansible,",
            "        which are special variables we set internally for use.",
            "        '''",
            "",
            "        variables = {}",
            "        variables['playbook_dir'] = os.path.abspath(self._loader.get_basedir())",
            "        variables['ansible_playbook_python'] = sys.executable",
            "",
            "        if play:",
            "            variables['role_names'] = [r._role_name for r in play.roles]",
            "",
            "        if task:",
            "            if task._role:",
            "                variables['role_name'] = task._role.get_name()",
            "                variables['role_path'] = task._role._role_path",
            "                variables['role_uuid'] = text_type(task._role._uuid)",
            "",
            "        if self._inventory is not None:",
            "            variables['groups'] = self._inventory.get_groups_dict()",
            "            if play:",
            "                templar = Templar(loader=self._loader)",
            "                if templar.is_template(play.hosts):",
            "                    pattern = 'all'",
            "                else:",
            "                    pattern = play.hosts or 'all'",
            "                # add the list of hosts in the play, as adjusted for limit/filters",
            "                variables['ansible_play_hosts_all'] = [x.name for x in self._inventory.get_hosts(pattern=pattern, ignore_restrictions=True)]",
            "                variables['ansible_play_hosts'] = [x for x in variables['ansible_play_hosts_all'] if x not in play._removed_hosts]",
            "                variables['ansible_play_batch'] = [x.name for x in self._inventory.get_hosts() if x.name not in play._removed_hosts]",
            "",
            "                # DEPRECATED: play_hosts should be deprecated in favor of ansible_play_batch,",
            "                # however this would take work in the templating engine, so for now we'll add both",
            "                variables['play_hosts'] = variables['ansible_play_batch']",
            "",
            "        # the 'omit' value alows params to be left out if the variable they are based on is undefined",
            "        variables['omit'] = self._omit_token",
            "        # Set options vars",
            "        for option, option_value in iteritems(self._options_vars):",
            "            variables[option] = option_value",
            "",
            "        if self._hostvars is not None and include_hostvars:",
            "            variables['hostvars'] = self._hostvars",
            "",
            "        return variables",
            "",
            "    def _get_delegated_vars(self, play, task, existing_variables):",
            "        # we unfortunately need to template the delegate_to field here,",
            "        # as we're fetching vars before post_validate has been called on",
            "        # the task that has been passed in",
            "        vars_copy = existing_variables.copy()",
            "        templar = Templar(loader=self._loader, variables=vars_copy)",
            "",
            "        items = []",
            "        if task.loop is not None:",
            "            if task.loop in lookup_loader:",
            "                try:",
            "                    loop_terms = listify_lookup_plugin_terms(terms=task.loop_args, templar=templar,",
            "                                                             loader=self._loader, fail_on_undefined=True, convert_bare=False)",
            "                    items = lookup_loader.get(task.loop, loader=self._loader, templar=templar).run(terms=loop_terms, variables=vars_copy)",
            "                except AnsibleUndefinedVariable:",
            "                    # This task will be skipped later due to this, so we just setup",
            "                    # a dummy array for the later code so it doesn't fail",
            "                    items = [None]",
            "            else:",
            "                raise AnsibleError(\"Unexpected failure in finding the lookup named '%s' in the available lookup plugins\" % task.loop)",
            "        else:",
            "            items = [None]",
            "",
            "        delegated_host_vars = dict()",
            "        item_var = getattr(task.loop_control, 'loop_var', 'item')",
            "        for item in items:",
            "            # update the variables with the item value for templating, in case we need it",
            "            if item is not None:",
            "                vars_copy[item_var] = item",
            "",
            "            templar.set_available_variables(vars_copy)",
            "            delegated_host_name = templar.template(task.delegate_to, fail_on_undefined=False)",
            "            if delegated_host_name is None:",
            "                raise AnsibleError(message=\"Undefined delegate_to host for task:\", obj=task._ds)",
            "            if delegated_host_name in delegated_host_vars:",
            "                # no need to repeat ourselves, as the delegate_to value",
            "                # does not appear to be tied to the loop item variable",
            "                continue",
            "",
            "            # a dictionary of variables to use if we have to create a new host below",
            "            # we set the default port based on the default transport here, to make sure",
            "            # we use the proper default for windows",
            "            new_port = C.DEFAULT_REMOTE_PORT",
            "            if C.DEFAULT_TRANSPORT == 'winrm':",
            "                new_port = 5986",
            "",
            "            new_delegated_host_vars = dict(",
            "                ansible_delegated_host=delegated_host_name,",
            "                ansible_host=delegated_host_name,  # not redundant as other sources can change ansible_host",
            "                ansible_port=new_port,",
            "                ansible_user=C.DEFAULT_REMOTE_USER,",
            "                ansible_connection=C.DEFAULT_TRANSPORT,",
            "            )",
            "",
            "            # now try to find the delegated-to host in inventory, or failing that,",
            "            # create a new host on the fly so we can fetch variables for it",
            "            delegated_host = None",
            "            if self._inventory is not None:",
            "                delegated_host = self._inventory.get_host(delegated_host_name)",
            "                # try looking it up based on the address field, and finally",
            "                # fall back to creating a host on the fly to use for the var lookup",
            "                if delegated_host is None:",
            "                    if delegated_host_name in C.LOCALHOST:",
            "                        delegated_host = self._inventory.localhost",
            "                    else:",
            "                        for h in self._inventory.get_hosts(ignore_limits=True, ignore_restrictions=True):",
            "                            # check if the address matches, or if both the delegated_to host",
            "                            # and the current host are in the list of localhost aliases",
            "                            if h.address == delegated_host_name:",
            "                                delegated_host = h",
            "                                break",
            "                        else:",
            "                            delegated_host = Host(name=delegated_host_name)",
            "                            delegated_host.vars = combine_vars(delegated_host.vars, new_delegated_host_vars)",
            "            else:",
            "                delegated_host = Host(name=delegated_host_name)",
            "                delegated_host.vars = combine_vars(delegated_host.vars, new_delegated_host_vars)",
            "",
            "            # now we go fetch the vars for the delegated-to host and save them in our",
            "            # master dictionary of variables to be used later in the TaskExecutor/PlayContext",
            "            delegated_host_vars[delegated_host_name] = self.get_vars(",
            "                play=play,",
            "                host=delegated_host,",
            "                task=task,",
            "                include_delegate_to=False,",
            "                include_hostvars=False,",
            "            )",
            "        return delegated_host_vars",
            "",
            "    def clear_facts(self, hostname):",
            "        '''",
            "        Clears the facts for a host",
            "        '''",
            "        if hostname in self._fact_cache:",
            "            del self._fact_cache[hostname]",
            "",
            "    def set_host_facts(self, host, facts):",
            "        '''",
            "        Sets or updates the given facts for a host in the fact cache.",
            "        '''",
            "",
            "        assert isinstance(facts, dict), \"the type of 'facts' to set for host_facts should be a dict but is a %s\" % type(facts)",
            "",
            "        if host.name not in self._fact_cache:",
            "            self._fact_cache[host.name] = facts",
            "        else:",
            "            try:",
            "                self._fact_cache.update(host.name, facts)",
            "            except KeyError:",
            "                self._fact_cache[host.name] = facts",
            "",
            "    def set_nonpersistent_facts(self, host, facts):",
            "        '''",
            "        Sets or updates the given facts for a host in the fact cache.",
            "        '''",
            "",
            "        assert isinstance(facts, dict), \"the type of 'facts' to set for nonpersistent_facts should be a dict but is a %s\" % type(facts)",
            "",
            "        if host.name not in self._nonpersistent_fact_cache:",
            "            self._nonpersistent_fact_cache[host.name] = facts",
            "        else:",
            "            try:",
            "                self._nonpersistent_fact_cache[host.name].update(facts)",
            "            except KeyError:",
            "                self._nonpersistent_fact_cache[host.name] = facts",
            "",
            "    def set_host_variable(self, host, varname, value):",
            "        '''",
            "        Sets a value in the vars_cache for a host.",
            "        '''",
            "        host_name = host.get_name()",
            "        if host_name not in self._vars_cache:",
            "            self._vars_cache[host_name] = dict()",
            "        if varname in self._vars_cache[host_name] and isinstance(self._vars_cache[host_name][varname], MutableMapping) and isinstance(value, MutableMapping):",
            "            self._vars_cache[host_name] = combine_vars(self._vars_cache[host_name], {varname: value})",
            "        else:",
            "            self._vars_cache[host_name][varname] = value"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "236": [
                "VariableManager",
                "get_vars"
            ]
        },
        "addLocation": [
            "lib.ansible.vars.manager.VariableManager"
        ]
    }
}