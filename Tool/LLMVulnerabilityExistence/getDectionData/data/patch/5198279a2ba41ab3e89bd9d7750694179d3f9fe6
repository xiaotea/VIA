{
    "superset/daos/dashboard.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "             return not db.session.query(dashboard_query.exists()).scalar()"
            },
            "1": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "         return True"
            },
            "2": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 183,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    @staticmethod"
            },
            "4": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def update_charts_owners(model: Dashboard, commit: bool = True) -> Dashboard:"
            },
            "5": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        owners = list(model.owners)"
            },
            "6": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for slc in model.slices:"
            },
            "7": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            slc.owners = list(set(owners) | set(slc.owners))"
            },
            "8": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if commit:"
            },
            "9": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            db.session.commit()"
            },
            "10": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return model"
            },
            "11": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "12": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "     @classmethod"
            },
            "13": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "     def delete(cls, items: Dashboard | list[Dashboard], commit: bool = True) -> None:"
            },
            "14": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "         item_ids = [item.id for item in get_iterable(items)]"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "import json",
            "import logging",
            "from datetime import datetime",
            "from typing import Any",
            "",
            "from flask import g",
            "from flask_appbuilder.models.sqla import Model",
            "from flask_appbuilder.models.sqla.interface import SQLAInterface",
            "from sqlalchemy.exc import SQLAlchemyError",
            "",
            "from superset import is_feature_enabled, security_manager",
            "from superset.daos.base import BaseDAO",
            "from superset.daos.exceptions import DAOConfigError, DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardAccessDeniedError,",
            "    DashboardForbiddenError,",
            "    DashboardNotFoundError,",
            ")",
            "from superset.dashboards.filter_sets.consts import (",
            "    DASHBOARD_ID_FIELD,",
            "    DESCRIPTION_FIELD,",
            "    JSON_METADATA_FIELD,",
            "    NAME_FIELD,",
            "    OWNER_ID_FIELD,",
            "    OWNER_TYPE_FIELD,",
            ")",
            "from superset.dashboards.filters import DashboardAccessFilter, is_uuid",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.core import FavStar, FavStarClassName",
            "from superset.models.dashboard import Dashboard, id_or_slug_filter",
            "from superset.models.embedded_dashboard import EmbeddedDashboard",
            "from superset.models.filter_set import FilterSet",
            "from superset.models.slice import Slice",
            "from superset.utils.core import get_iterable, get_user_id",
            "from superset.utils.dashboard_filter_scopes_converter import copy_filter_scopes",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DashboardDAO(BaseDAO[Dashboard]):",
            "    base_filter = DashboardAccessFilter",
            "",
            "    @classmethod",
            "    def get_by_id_or_slug(cls, id_or_slug: int | str) -> Dashboard:",
            "        if is_uuid(id_or_slug):",
            "            # just get dashboard if it's uuid",
            "            dashboard = Dashboard.get(id_or_slug)",
            "        else:",
            "            query = (",
            "                db.session.query(Dashboard)",
            "                .filter(id_or_slug_filter(id_or_slug))",
            "                .outerjoin(Dashboard.owners)",
            "                .outerjoin(Dashboard.roles)",
            "            )",
            "            # Apply dashboard base filters",
            "            query = cls.base_filter(\"id\", SQLAInterface(Dashboard, db.session)).apply(",
            "                query, None",
            "            )",
            "            dashboard = query.one_or_none()",
            "        if not dashboard:",
            "            raise DashboardNotFoundError()",
            "",
            "        # make sure we still have basic access check from security manager",
            "        try:",
            "            dashboard.raise_for_access()",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardAccessDeniedError() from ex",
            "",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def get_datasets_for_dashboard(id_or_slug: str) -> list[Any]:",
            "        dashboard = DashboardDAO.get_by_id_or_slug(id_or_slug)",
            "        return dashboard.datasets_trimmed_for_slices()",
            "",
            "    @staticmethod",
            "    def get_charts_for_dashboard(id_or_slug: str) -> list[Slice]:",
            "        return DashboardDAO.get_by_id_or_slug(id_or_slug).slices",
            "",
            "    @staticmethod",
            "    def get_dashboard_changed_on(id_or_slug_or_dashboard: str | Dashboard) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard: Dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return dashboard.changed_on.replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_slices_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: str | Dashboard,",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, or a change to one of its dependent slices.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        slices = dashboard.slices",
            "        slices_changed_on = max(",
            "            [slc.changed_on for slc in slices]",
            "            + ([datetime.fromtimestamp(0)] if len(slices) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, slices_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_datasets_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: str | Dashboard,",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, a change to one of its dependent datasets.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        datasources = dashboard.datasources",
            "        datasources_changed_on = max(",
            "            [datasource.changed_on for datasource in datasources]",
            "            + ([datetime.fromtimestamp(0)] if len(datasources) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, datasources_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def validate_slug_uniqueness(slug: str) -> bool:",
            "        if not slug:",
            "            return True",
            "        dashboard_query = db.session.query(Dashboard).filter(Dashboard.slug == slug)",
            "        return not db.session.query(dashboard_query.exists()).scalar()",
            "",
            "    @staticmethod",
            "    def validate_update_slug_uniqueness(dashboard_id: int, slug: str | None) -> bool:",
            "        if slug is not None:",
            "            dashboard_query = db.session.query(Dashboard).filter(",
            "                Dashboard.slug == slug, Dashboard.id != dashboard_id",
            "            )",
            "            return not db.session.query(dashboard_query.exists()).scalar()",
            "        return True",
            "",
            "    @staticmethod",
            "    def update_charts_owners(model: Dashboard, commit: bool = True) -> Dashboard:",
            "        owners = list(model.owners)",
            "        for slc in model.slices:",
            "            slc.owners = list(set(owners) | set(slc.owners))",
            "        if commit:",
            "            db.session.commit()",
            "        return model",
            "",
            "    @classmethod",
            "    def delete(cls, items: Dashboard | list[Dashboard], commit: bool = True) -> None:",
            "        item_ids = [item.id for item in get_iterable(items)]",
            "        try:",
            "            db.session.query(Dashboard).filter(Dashboard.id.in_(item_ids)).delete(",
            "                synchronize_session=\"fetch\"",
            "            )",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:",
            "            db.session.rollback()",
            "            raise ex",
            "",
            "    @staticmethod",
            "    def set_dash_metadata(  # pylint: disable=too-many-locals",
            "        dashboard: Dashboard,",
            "        data: dict[Any, Any],",
            "        old_to_new_slice_ids: dict[int, int] | None = None,",
            "        commit: bool = False,",
            "    ) -> Dashboard:",
            "        new_filter_scopes = {}",
            "        md = dashboard.params_dict",
            "",
            "        if (positions := data.get(\"positions\")) is not None:",
            "            # find slices in the position data",
            "            slice_ids = [",
            "                value.get(\"meta\", {}).get(\"chartId\")",
            "                for value in positions.values()",
            "                if isinstance(value, dict)",
            "            ]",
            "",
            "            session = db.session()",
            "            current_slices = session.query(Slice).filter(Slice.id.in_(slice_ids)).all()",
            "",
            "            dashboard.slices = current_slices",
            "",
            "            # add UUID to positions",
            "            uuid_map = {slice.id: str(slice.uuid) for slice in current_slices}",
            "            for obj in positions.values():",
            "                if (",
            "                    isinstance(obj, dict)",
            "                    and obj[\"type\"] == \"CHART\"",
            "                    and obj[\"meta\"][\"chartId\"]",
            "                ):",
            "                    chart_id = obj[\"meta\"][\"chartId\"]",
            "                    obj[\"meta\"][\"uuid\"] = uuid_map.get(chart_id)",
            "",
            "            # remove leading and trailing white spaces in the dumped json",
            "            dashboard.position_json = json.dumps(",
            "                positions, indent=None, separators=(\",\", \":\"), sort_keys=True",
            "            )",
            "",
            "            if \"filter_scopes\" in data:",
            "                # replace filter_id and immune ids from old slice id to new slice id:",
            "                # and remove slice ids that are not in dash anymore",
            "                slc_id_dict: dict[int, int] = {}",
            "                if old_to_new_slice_ids:",
            "                    slc_id_dict = {",
            "                        old: new",
            "                        for old, new in old_to_new_slice_ids.items()",
            "                        if new in slice_ids",
            "                    }",
            "                else:",
            "                    slc_id_dict = {sid: sid for sid in slice_ids}",
            "                new_filter_scopes = copy_filter_scopes(",
            "                    old_to_new_slc_id_dict=slc_id_dict,",
            "                    old_filter_scopes=json.loads(data[\"filter_scopes\"] or \"{}\")",
            "                    if isinstance(data[\"filter_scopes\"], str)",
            "                    else data[\"filter_scopes\"],",
            "                )",
            "",
            "            default_filters_data = json.loads(data.get(\"default_filters\", \"{}\"))",
            "            applicable_filters = {",
            "                key: v",
            "                for key, v in default_filters_data.items()",
            "                if int(key) in slice_ids",
            "            }",
            "            md[\"default_filters\"] = json.dumps(applicable_filters)",
            "",
            "            # positions have its own column, no need to store it in metadata",
            "            md.pop(\"positions\", None)",
            "",
            "        if new_filter_scopes:",
            "            md[\"filter_scopes\"] = new_filter_scopes",
            "        else:",
            "            md.pop(\"filter_scopes\", None)",
            "",
            "        md.setdefault(\"timed_refresh_immune_slices\", [])",
            "",
            "        if data.get(\"color_namespace\") is None:",
            "            md.pop(\"color_namespace\", None)",
            "        else:",
            "            md[\"color_namespace\"] = data.get(\"color_namespace\")",
            "",
            "        md[\"expanded_slices\"] = data.get(\"expanded_slices\", {})",
            "        md[\"refresh_frequency\"] = data.get(\"refresh_frequency\", 0)",
            "        md[\"color_scheme\"] = data.get(\"color_scheme\", \"\")",
            "        md[\"label_colors\"] = data.get(\"label_colors\", {})",
            "        md[\"shared_label_colors\"] = data.get(\"shared_label_colors\", {})",
            "        md[\"color_scheme_domain\"] = data.get(\"color_scheme_domain\", [])",
            "        md[\"cross_filters_enabled\"] = data.get(\"cross_filters_enabled\", True)",
            "        dashboard.json_metadata = json.dumps(md)",
            "",
            "        if commit:",
            "            db.session.commit()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def favorited_ids(dashboards: list[Dashboard]) -> list[FavStar]:",
            "        ids = [dash.id for dash in dashboards]",
            "        return [",
            "            star.obj_id",
            "            for star in db.session.query(FavStar.obj_id)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id.in_(ids),",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .all()",
            "        ]",
            "",
            "    @classmethod",
            "    def copy_dashboard(",
            "        cls, original_dash: Dashboard, data: dict[str, Any]",
            "    ) -> Dashboard:",
            "        if is_feature_enabled(\"DASHBOARD_RBAC\") and not security_manager.is_owner(",
            "            original_dash",
            "        ):",
            "            raise DashboardForbiddenError()",
            "",
            "        dash = Dashboard()",
            "        dash.owners = [g.user] if g.user else []",
            "        dash.dashboard_title = data[\"dashboard_title\"]",
            "        dash.css = data.get(\"css\")",
            "",
            "        metadata = json.loads(data[\"json_metadata\"])",
            "        old_to_new_slice_ids: dict[int, int] = {}",
            "        if data.get(\"duplicate_slices\"):",
            "            # Duplicating slices as well, mapping old ids to new ones",
            "            for slc in original_dash.slices:",
            "                new_slice = slc.clone()",
            "                new_slice.owners = [g.user] if g.user else []",
            "                db.session.add(new_slice)",
            "                db.session.flush()",
            "                new_slice.dashboards.append(dash)",
            "                old_to_new_slice_ids[slc.id] = new_slice.id",
            "",
            "            # update chartId of layout entities",
            "            for value in metadata[\"positions\"].values():",
            "                if isinstance(value, dict) and value.get(\"meta\", {}).get(\"chartId\"):",
            "                    old_id = value[\"meta\"][\"chartId\"]",
            "                    new_id = old_to_new_slice_ids.get(old_id)",
            "                    value[\"meta\"][\"chartId\"] = new_id",
            "        else:",
            "            dash.slices = original_dash.slices",
            "",
            "        dash.params = original_dash.params",
            "        cls.set_dash_metadata(dash, metadata, old_to_new_slice_ids)",
            "        db.session.add(dash)",
            "        db.session.commit()",
            "        return dash",
            "",
            "    @staticmethod",
            "    def add_favorite(dashboard: Dashboard) -> None:",
            "        ids = DashboardDAO.favorited_ids([dashboard])",
            "        if dashboard.id not in ids:",
            "            db.session.add(",
            "                FavStar(",
            "                    class_name=FavStarClassName.DASHBOARD,",
            "                    obj_id=dashboard.id,",
            "                    user_id=get_user_id(),",
            "                    dttm=datetime.now(),",
            "                )",
            "            )",
            "            db.session.commit()",
            "",
            "    @staticmethod",
            "    def remove_favorite(dashboard: Dashboard) -> None:",
            "        fav = (",
            "            db.session.query(FavStar)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id == dashboard.id,",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .one_or_none()",
            "        )",
            "        if fav:",
            "            db.session.delete(fav)",
            "            db.session.commit()",
            "",
            "",
            "class EmbeddedDashboardDAO(BaseDAO[EmbeddedDashboard]):",
            "    # There isn't really a regular scenario where we would rather get Embedded by id",
            "    id_column_name = \"uuid\"",
            "",
            "    @staticmethod",
            "    def upsert(dashboard: Dashboard, allowed_domains: list[str]) -> EmbeddedDashboard:",
            "        \"\"\"",
            "        Sets up a dashboard to be embeddable.",
            "        Upsert is used to preserve the embedded_dashboard uuid across updates.",
            "        \"\"\"",
            "        embedded: EmbeddedDashboard = (",
            "            dashboard.embedded[0] if dashboard.embedded else EmbeddedDashboard()",
            "        )",
            "        embedded.allow_domain_list = \",\".join(allowed_domains)",
            "        dashboard.embedded = [embedded]",
            "        db.session.commit()",
            "        return embedded",
            "",
            "    @classmethod",
            "    def create(cls, properties: dict[str, Any], commit: bool = True) -> Any:",
            "        \"\"\"",
            "        Use EmbeddedDashboardDAO.upsert() instead.",
            "        At least, until we are ok with more than one embedded instance per dashboard.",
            "        \"\"\"",
            "        raise NotImplementedError(\"Use EmbeddedDashboardDAO.upsert() instead.\")",
            "",
            "",
            "class FilterSetDAO(BaseDAO[FilterSet]):",
            "    @classmethod",
            "    def create(cls, properties: dict[str, Any], commit: bool = True) -> Model:",
            "        if cls.model_cls is None:",
            "            raise DAOConfigError()",
            "        model = FilterSet()",
            "        setattr(model, NAME_FIELD, properties[NAME_FIELD])",
            "        setattr(model, JSON_METADATA_FIELD, properties[JSON_METADATA_FIELD])",
            "        setattr(model, DESCRIPTION_FIELD, properties.get(DESCRIPTION_FIELD, None))",
            "        setattr(",
            "            model,",
            "            OWNER_ID_FIELD,",
            "            properties.get(OWNER_ID_FIELD, properties[DASHBOARD_ID_FIELD]),",
            "        )",
            "        setattr(model, OWNER_TYPE_FIELD, properties[OWNER_TYPE_FIELD])",
            "        setattr(model, DASHBOARD_ID_FIELD, properties[DASHBOARD_ID_FIELD])",
            "        try:",
            "            db.session.add(model)",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:  # pragma: no cover",
            "            db.session.rollback()",
            "            raise DAOCreateFailedError() from ex",
            "        return model"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "import json",
            "import logging",
            "from datetime import datetime",
            "from typing import Any",
            "",
            "from flask import g",
            "from flask_appbuilder.models.sqla import Model",
            "from flask_appbuilder.models.sqla.interface import SQLAInterface",
            "from sqlalchemy.exc import SQLAlchemyError",
            "",
            "from superset import is_feature_enabled, security_manager",
            "from superset.daos.base import BaseDAO",
            "from superset.daos.exceptions import DAOConfigError, DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardAccessDeniedError,",
            "    DashboardForbiddenError,",
            "    DashboardNotFoundError,",
            ")",
            "from superset.dashboards.filter_sets.consts import (",
            "    DASHBOARD_ID_FIELD,",
            "    DESCRIPTION_FIELD,",
            "    JSON_METADATA_FIELD,",
            "    NAME_FIELD,",
            "    OWNER_ID_FIELD,",
            "    OWNER_TYPE_FIELD,",
            ")",
            "from superset.dashboards.filters import DashboardAccessFilter, is_uuid",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.core import FavStar, FavStarClassName",
            "from superset.models.dashboard import Dashboard, id_or_slug_filter",
            "from superset.models.embedded_dashboard import EmbeddedDashboard",
            "from superset.models.filter_set import FilterSet",
            "from superset.models.slice import Slice",
            "from superset.utils.core import get_iterable, get_user_id",
            "from superset.utils.dashboard_filter_scopes_converter import copy_filter_scopes",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DashboardDAO(BaseDAO[Dashboard]):",
            "    base_filter = DashboardAccessFilter",
            "",
            "    @classmethod",
            "    def get_by_id_or_slug(cls, id_or_slug: int | str) -> Dashboard:",
            "        if is_uuid(id_or_slug):",
            "            # just get dashboard if it's uuid",
            "            dashboard = Dashboard.get(id_or_slug)",
            "        else:",
            "            query = (",
            "                db.session.query(Dashboard)",
            "                .filter(id_or_slug_filter(id_or_slug))",
            "                .outerjoin(Dashboard.owners)",
            "                .outerjoin(Dashboard.roles)",
            "            )",
            "            # Apply dashboard base filters",
            "            query = cls.base_filter(\"id\", SQLAInterface(Dashboard, db.session)).apply(",
            "                query, None",
            "            )",
            "            dashboard = query.one_or_none()",
            "        if not dashboard:",
            "            raise DashboardNotFoundError()",
            "",
            "        # make sure we still have basic access check from security manager",
            "        try:",
            "            dashboard.raise_for_access()",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardAccessDeniedError() from ex",
            "",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def get_datasets_for_dashboard(id_or_slug: str) -> list[Any]:",
            "        dashboard = DashboardDAO.get_by_id_or_slug(id_or_slug)",
            "        return dashboard.datasets_trimmed_for_slices()",
            "",
            "    @staticmethod",
            "    def get_charts_for_dashboard(id_or_slug: str) -> list[Slice]:",
            "        return DashboardDAO.get_by_id_or_slug(id_or_slug).slices",
            "",
            "    @staticmethod",
            "    def get_dashboard_changed_on(id_or_slug_or_dashboard: str | Dashboard) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard: Dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return dashboard.changed_on.replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_slices_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: str | Dashboard,",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, or a change to one of its dependent slices.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        slices = dashboard.slices",
            "        slices_changed_on = max(",
            "            [slc.changed_on for slc in slices]",
            "            + ([datetime.fromtimestamp(0)] if len(slices) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, slices_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_datasets_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: str | Dashboard,",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, a change to one of its dependent datasets.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        datasources = dashboard.datasources",
            "        datasources_changed_on = max(",
            "            [datasource.changed_on for datasource in datasources]",
            "            + ([datetime.fromtimestamp(0)] if len(datasources) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, datasources_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def validate_slug_uniqueness(slug: str) -> bool:",
            "        if not slug:",
            "            return True",
            "        dashboard_query = db.session.query(Dashboard).filter(Dashboard.slug == slug)",
            "        return not db.session.query(dashboard_query.exists()).scalar()",
            "",
            "    @staticmethod",
            "    def validate_update_slug_uniqueness(dashboard_id: int, slug: str | None) -> bool:",
            "        if slug is not None:",
            "            dashboard_query = db.session.query(Dashboard).filter(",
            "                Dashboard.slug == slug, Dashboard.id != dashboard_id",
            "            )",
            "            return not db.session.query(dashboard_query.exists()).scalar()",
            "        return True",
            "",
            "    @classmethod",
            "    def delete(cls, items: Dashboard | list[Dashboard], commit: bool = True) -> None:",
            "        item_ids = [item.id for item in get_iterable(items)]",
            "        try:",
            "            db.session.query(Dashboard).filter(Dashboard.id.in_(item_ids)).delete(",
            "                synchronize_session=\"fetch\"",
            "            )",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:",
            "            db.session.rollback()",
            "            raise ex",
            "",
            "    @staticmethod",
            "    def set_dash_metadata(  # pylint: disable=too-many-locals",
            "        dashboard: Dashboard,",
            "        data: dict[Any, Any],",
            "        old_to_new_slice_ids: dict[int, int] | None = None,",
            "        commit: bool = False,",
            "    ) -> Dashboard:",
            "        new_filter_scopes = {}",
            "        md = dashboard.params_dict",
            "",
            "        if (positions := data.get(\"positions\")) is not None:",
            "            # find slices in the position data",
            "            slice_ids = [",
            "                value.get(\"meta\", {}).get(\"chartId\")",
            "                for value in positions.values()",
            "                if isinstance(value, dict)",
            "            ]",
            "",
            "            session = db.session()",
            "            current_slices = session.query(Slice).filter(Slice.id.in_(slice_ids)).all()",
            "",
            "            dashboard.slices = current_slices",
            "",
            "            # add UUID to positions",
            "            uuid_map = {slice.id: str(slice.uuid) for slice in current_slices}",
            "            for obj in positions.values():",
            "                if (",
            "                    isinstance(obj, dict)",
            "                    and obj[\"type\"] == \"CHART\"",
            "                    and obj[\"meta\"][\"chartId\"]",
            "                ):",
            "                    chart_id = obj[\"meta\"][\"chartId\"]",
            "                    obj[\"meta\"][\"uuid\"] = uuid_map.get(chart_id)",
            "",
            "            # remove leading and trailing white spaces in the dumped json",
            "            dashboard.position_json = json.dumps(",
            "                positions, indent=None, separators=(\",\", \":\"), sort_keys=True",
            "            )",
            "",
            "            if \"filter_scopes\" in data:",
            "                # replace filter_id and immune ids from old slice id to new slice id:",
            "                # and remove slice ids that are not in dash anymore",
            "                slc_id_dict: dict[int, int] = {}",
            "                if old_to_new_slice_ids:",
            "                    slc_id_dict = {",
            "                        old: new",
            "                        for old, new in old_to_new_slice_ids.items()",
            "                        if new in slice_ids",
            "                    }",
            "                else:",
            "                    slc_id_dict = {sid: sid for sid in slice_ids}",
            "                new_filter_scopes = copy_filter_scopes(",
            "                    old_to_new_slc_id_dict=slc_id_dict,",
            "                    old_filter_scopes=json.loads(data[\"filter_scopes\"] or \"{}\")",
            "                    if isinstance(data[\"filter_scopes\"], str)",
            "                    else data[\"filter_scopes\"],",
            "                )",
            "",
            "            default_filters_data = json.loads(data.get(\"default_filters\", \"{}\"))",
            "            applicable_filters = {",
            "                key: v",
            "                for key, v in default_filters_data.items()",
            "                if int(key) in slice_ids",
            "            }",
            "            md[\"default_filters\"] = json.dumps(applicable_filters)",
            "",
            "            # positions have its own column, no need to store it in metadata",
            "            md.pop(\"positions\", None)",
            "",
            "        if new_filter_scopes:",
            "            md[\"filter_scopes\"] = new_filter_scopes",
            "        else:",
            "            md.pop(\"filter_scopes\", None)",
            "",
            "        md.setdefault(\"timed_refresh_immune_slices\", [])",
            "",
            "        if data.get(\"color_namespace\") is None:",
            "            md.pop(\"color_namespace\", None)",
            "        else:",
            "            md[\"color_namespace\"] = data.get(\"color_namespace\")",
            "",
            "        md[\"expanded_slices\"] = data.get(\"expanded_slices\", {})",
            "        md[\"refresh_frequency\"] = data.get(\"refresh_frequency\", 0)",
            "        md[\"color_scheme\"] = data.get(\"color_scheme\", \"\")",
            "        md[\"label_colors\"] = data.get(\"label_colors\", {})",
            "        md[\"shared_label_colors\"] = data.get(\"shared_label_colors\", {})",
            "        md[\"color_scheme_domain\"] = data.get(\"color_scheme_domain\", [])",
            "        md[\"cross_filters_enabled\"] = data.get(\"cross_filters_enabled\", True)",
            "        dashboard.json_metadata = json.dumps(md)",
            "",
            "        if commit:",
            "            db.session.commit()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def favorited_ids(dashboards: list[Dashboard]) -> list[FavStar]:",
            "        ids = [dash.id for dash in dashboards]",
            "        return [",
            "            star.obj_id",
            "            for star in db.session.query(FavStar.obj_id)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id.in_(ids),",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .all()",
            "        ]",
            "",
            "    @classmethod",
            "    def copy_dashboard(",
            "        cls, original_dash: Dashboard, data: dict[str, Any]",
            "    ) -> Dashboard:",
            "        if is_feature_enabled(\"DASHBOARD_RBAC\") and not security_manager.is_owner(",
            "            original_dash",
            "        ):",
            "            raise DashboardForbiddenError()",
            "",
            "        dash = Dashboard()",
            "        dash.owners = [g.user] if g.user else []",
            "        dash.dashboard_title = data[\"dashboard_title\"]",
            "        dash.css = data.get(\"css\")",
            "",
            "        metadata = json.loads(data[\"json_metadata\"])",
            "        old_to_new_slice_ids: dict[int, int] = {}",
            "        if data.get(\"duplicate_slices\"):",
            "            # Duplicating slices as well, mapping old ids to new ones",
            "            for slc in original_dash.slices:",
            "                new_slice = slc.clone()",
            "                new_slice.owners = [g.user] if g.user else []",
            "                db.session.add(new_slice)",
            "                db.session.flush()",
            "                new_slice.dashboards.append(dash)",
            "                old_to_new_slice_ids[slc.id] = new_slice.id",
            "",
            "            # update chartId of layout entities",
            "            for value in metadata[\"positions\"].values():",
            "                if isinstance(value, dict) and value.get(\"meta\", {}).get(\"chartId\"):",
            "                    old_id = value[\"meta\"][\"chartId\"]",
            "                    new_id = old_to_new_slice_ids.get(old_id)",
            "                    value[\"meta\"][\"chartId\"] = new_id",
            "        else:",
            "            dash.slices = original_dash.slices",
            "",
            "        dash.params = original_dash.params",
            "        cls.set_dash_metadata(dash, metadata, old_to_new_slice_ids)",
            "        db.session.add(dash)",
            "        db.session.commit()",
            "        return dash",
            "",
            "    @staticmethod",
            "    def add_favorite(dashboard: Dashboard) -> None:",
            "        ids = DashboardDAO.favorited_ids([dashboard])",
            "        if dashboard.id not in ids:",
            "            db.session.add(",
            "                FavStar(",
            "                    class_name=FavStarClassName.DASHBOARD,",
            "                    obj_id=dashboard.id,",
            "                    user_id=get_user_id(),",
            "                    dttm=datetime.now(),",
            "                )",
            "            )",
            "            db.session.commit()",
            "",
            "    @staticmethod",
            "    def remove_favorite(dashboard: Dashboard) -> None:",
            "        fav = (",
            "            db.session.query(FavStar)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id == dashboard.id,",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .one_or_none()",
            "        )",
            "        if fav:",
            "            db.session.delete(fav)",
            "            db.session.commit()",
            "",
            "",
            "class EmbeddedDashboardDAO(BaseDAO[EmbeddedDashboard]):",
            "    # There isn't really a regular scenario where we would rather get Embedded by id",
            "    id_column_name = \"uuid\"",
            "",
            "    @staticmethod",
            "    def upsert(dashboard: Dashboard, allowed_domains: list[str]) -> EmbeddedDashboard:",
            "        \"\"\"",
            "        Sets up a dashboard to be embeddable.",
            "        Upsert is used to preserve the embedded_dashboard uuid across updates.",
            "        \"\"\"",
            "        embedded: EmbeddedDashboard = (",
            "            dashboard.embedded[0] if dashboard.embedded else EmbeddedDashboard()",
            "        )",
            "        embedded.allow_domain_list = \",\".join(allowed_domains)",
            "        dashboard.embedded = [embedded]",
            "        db.session.commit()",
            "        return embedded",
            "",
            "    @classmethod",
            "    def create(cls, properties: dict[str, Any], commit: bool = True) -> Any:",
            "        \"\"\"",
            "        Use EmbeddedDashboardDAO.upsert() instead.",
            "        At least, until we are ok with more than one embedded instance per dashboard.",
            "        \"\"\"",
            "        raise NotImplementedError(\"Use EmbeddedDashboardDAO.upsert() instead.\")",
            "",
            "",
            "class FilterSetDAO(BaseDAO[FilterSet]):",
            "    @classmethod",
            "    def create(cls, properties: dict[str, Any], commit: bool = True) -> Model:",
            "        if cls.model_cls is None:",
            "            raise DAOConfigError()",
            "        model = FilterSet()",
            "        setattr(model, NAME_FIELD, properties[NAME_FIELD])",
            "        setattr(model, JSON_METADATA_FIELD, properties[JSON_METADATA_FIELD])",
            "        setattr(model, DESCRIPTION_FIELD, properties.get(DESCRIPTION_FIELD, None))",
            "        setattr(",
            "            model,",
            "            OWNER_ID_FIELD,",
            "            properties.get(OWNER_ID_FIELD, properties[DASHBOARD_ID_FIELD]),",
            "        )",
            "        setattr(model, OWNER_TYPE_FIELD, properties[OWNER_TYPE_FIELD])",
            "        setattr(model, DASHBOARD_ID_FIELD, properties[DASHBOARD_ID_FIELD])",
            "        try:",
            "            db.session.add(model)",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:  # pragma: no cover",
            "            db.session.rollback()",
            "            raise DAOCreateFailedError() from ex",
            "        return model"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "184": [
                "DashboardDAO"
            ],
            "185": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "186": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "187": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "188": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "189": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "190": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "191": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "192": [
                "DashboardDAO"
            ]
        },
        "addLocation": []
    },
    "superset/dashboards/commands/create.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     def run(self) -> Model:"
            },
            "1": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         self.validate()"
            },
            "2": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "         try:"
            },
            "3": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.create(self._properties, commit=False)"
            },
            "4": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=True)"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+            dashboard = DashboardDAO.create(self._properties, commit=True)"
            },
            "6": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         except DAOCreateFailedError as ex:"
            },
            "7": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "             logger.exception(ex.exception)"
            },
            "8": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "             raise DashboardCreateFailedError() from ex"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import logging",
            "from typing import Any, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset.commands.base import BaseCommand, CreateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.daos.dashboard import DashboardDAO",
            "from superset.daos.exceptions import DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardCreateFailedError,",
            "    DashboardInvalidError,",
            "    DashboardSlugExistsValidationError,",
            ")",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class CreateDashboardCommand(CreateMixin, BaseCommand):",
            "    def __init__(self, data: dict[str, Any]):",
            "        self._properties = data.copy()",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.create(self._properties, commit=False)",
            "            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=True)",
            "        except DAOCreateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardCreateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: list[ValidationError] = []",
            "        owner_ids: Optional[list[int]] = self._properties.get(\"owners\")",
            "        role_ids: Optional[list[int]] = self._properties.get(\"roles\")",
            "        slug: str = self._properties.get(\"slug\", \"\")",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_slug_uniqueness(slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        try:",
            "            owners = self.populate_owners(owner_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)",
            "",
            "        try:",
            "            roles = populate_roles(role_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import logging",
            "from typing import Any, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset.commands.base import BaseCommand, CreateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.daos.dashboard import DashboardDAO",
            "from superset.daos.exceptions import DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardCreateFailedError,",
            "    DashboardInvalidError,",
            "    DashboardSlugExistsValidationError,",
            ")",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class CreateDashboardCommand(CreateMixin, BaseCommand):",
            "    def __init__(self, data: dict[str, Any]):",
            "        self._properties = data.copy()",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.create(self._properties, commit=True)",
            "        except DAOCreateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardCreateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: list[ValidationError] = []",
            "        owner_ids: Optional[list[int]] = self._properties.get(\"owners\")",
            "        role_ids: Optional[list[int]] = self._properties.get(\"roles\")",
            "        slug: str = self._properties.get(\"slug\", \"\")",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_slug_uniqueness(slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        try:",
            "            owners = self.populate_owners(owner_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)",
            "",
            "        try:",
            "            roles = populate_roles(role_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "43": [
                "CreateDashboardCommand",
                "run"
            ],
            "44": [
                "CreateDashboardCommand",
                "run"
            ]
        },
        "addLocation": []
    },
    "superset/dashboards/commands/update.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "                     data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),"
            },
            "1": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "                     commit=False,"
            },
            "2": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "                 )"
            },
            "3": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=False)"
            },
            "4": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "             db.session.commit()"
            },
            "5": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         except DAOUpdateFailedError as ex:"
            },
            "6": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "             logger.exception(ex.exception)"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from typing import Any, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset import security_manager",
            "from superset.commands.base import BaseCommand, UpdateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.daos.dashboard import DashboardDAO",
            "from superset.daos.exceptions import DAOUpdateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardForbiddenError,",
            "    DashboardInvalidError,",
            "    DashboardNotFoundError,",
            "    DashboardSlugExistsValidationError,",
            "    DashboardUpdateFailedError,",
            ")",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.dashboard import Dashboard",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class UpdateDashboardCommand(UpdateMixin, BaseCommand):",
            "    def __init__(self, model_id: int, data: dict[str, Any]):",
            "        self._model_id = model_id",
            "        self._properties = data.copy()",
            "        self._model: Optional[Dashboard] = None",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        assert self._model",
            "",
            "        try:",
            "            dashboard = DashboardDAO.update(self._model, self._properties, commit=False)",
            "            if self._properties.get(\"json_metadata\"):",
            "                dashboard = DashboardDAO.set_dash_metadata(",
            "                    dashboard,",
            "                    data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),",
            "                    commit=False,",
            "                )",
            "            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=False)",
            "            db.session.commit()",
            "        except DAOUpdateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardUpdateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: list[ValidationError] = []",
            "        owners_ids: Optional[list[int]] = self._properties.get(\"owners\")",
            "        roles_ids: Optional[list[int]] = self._properties.get(\"roles\")",
            "        slug: Optional[str] = self._properties.get(\"slug\")",
            "",
            "        # Validate/populate model exists",
            "        self._model = DashboardDAO.find_by_id(self._model_id)",
            "        if not self._model:",
            "            raise DashboardNotFoundError()",
            "        # Check ownership",
            "        try:",
            "            security_manager.raise_for_ownership(self._model)",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardForbiddenError() from ex",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_update_slug_uniqueness(self._model_id, slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        # Validate/Populate owner",
            "        if owners_ids is None:",
            "            owners_ids = [owner.id for owner in self._model.owners]",
            "        try:",
            "            owners = self.populate_owners(owners_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)",
            "",
            "        # Validate/Populate role",
            "        if roles_ids is None:",
            "            roles_ids = [role.id for role in self._model.roles]",
            "        try:",
            "            roles = populate_roles(roles_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from typing import Any, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset import security_manager",
            "from superset.commands.base import BaseCommand, UpdateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.daos.dashboard import DashboardDAO",
            "from superset.daos.exceptions import DAOUpdateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardForbiddenError,",
            "    DashboardInvalidError,",
            "    DashboardNotFoundError,",
            "    DashboardSlugExistsValidationError,",
            "    DashboardUpdateFailedError,",
            ")",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.dashboard import Dashboard",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class UpdateDashboardCommand(UpdateMixin, BaseCommand):",
            "    def __init__(self, model_id: int, data: dict[str, Any]):",
            "        self._model_id = model_id",
            "        self._properties = data.copy()",
            "        self._model: Optional[Dashboard] = None",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        assert self._model",
            "",
            "        try:",
            "            dashboard = DashboardDAO.update(self._model, self._properties, commit=False)",
            "            if self._properties.get(\"json_metadata\"):",
            "                dashboard = DashboardDAO.set_dash_metadata(",
            "                    dashboard,",
            "                    data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),",
            "                    commit=False,",
            "                )",
            "            db.session.commit()",
            "        except DAOUpdateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardUpdateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: list[ValidationError] = []",
            "        owners_ids: Optional[list[int]] = self._properties.get(\"owners\")",
            "        roles_ids: Optional[list[int]] = self._properties.get(\"roles\")",
            "        slug: Optional[str] = self._properties.get(\"slug\")",
            "",
            "        # Validate/populate model exists",
            "        self._model = DashboardDAO.find_by_id(self._model_id)",
            "        if not self._model:",
            "            raise DashboardNotFoundError()",
            "        # Check ownership",
            "        try:",
            "            security_manager.raise_for_ownership(self._model)",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardForbiddenError() from ex",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_update_slug_uniqueness(self._model_id, slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        # Validate/Populate owner",
            "        if owners_ids is None:",
            "            owners_ids = [owner.id for owner in self._model.owners]",
            "        try:",
            "            owners = self.populate_owners(owners_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)",
            "",
            "        # Validate/Populate role",
            "        if roles_ids is None:",
            "            roles_ids = [role.id for role in self._model.roles]",
            "        try:",
            "            roles = populate_roles(roles_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            raise DashboardInvalidError(exceptions=exceptions)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "61": [
                "UpdateDashboardCommand",
                "run"
            ]
        },
        "addLocation": []
    }
}