{
    "rasa/core/featurizers/single_state_featurizer.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import logging"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+from typing import List, Optional, Dict, Text, Set, Any"
            },
            "2": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3,
                "PatchRowcode": "+"
            },
            "3": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import numpy as np"
            },
            "4": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import scipy.sparse"
            },
            "5": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from typing import List, Optional, Dict, Text, Set, Any"
            },
            "6": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization"
            },
            "8": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from rasa.nlu.extractors.extractor import EntityTagSpec"
            },
            "9": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": 363,
                "PatchRowcode": "             for action in domain.action_names_or_texts"
            },
            "10": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": 364,
                "PatchRowcode": "         ]"
            },
            "11": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": 365,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+    def to_dict(self) -> Dict[str, Any]:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+        return {"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+            \"action_texts\": self.action_texts,"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+            \"entity_tag_specs\": self.entity_tag_specs,"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+            \"feature_states\": self._default_feature_states,"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        }"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+    @classmethod"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 374,
                "PatchRowcode": "+    def create_from_dict("
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 375,
                "PatchRowcode": "+        cls, data: Dict[str, Any]"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 376,
                "PatchRowcode": "+    ) -> Optional[\"SingleStateFeaturizer\"]:"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 377,
                "PatchRowcode": "+        if not data:"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+            return None"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 380,
                "PatchRowcode": "+        featurizer = SingleStateFeaturizer()"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 381,
                "PatchRowcode": "+        featurizer.action_texts = data[\"action_texts\"]"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 382,
                "PatchRowcode": "+        featurizer._default_feature_states = data[\"feature_states\"]"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+        featurizer.entity_tag_specs = data[\"entity_tag_specs\"]"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+        return featurizer"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 385,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 386,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 387,
                "PatchRowcode": " class IntentTokenizerSingleStateFeaturizer(SingleStateFeaturizer):"
            },
            "34": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 388,
                "PatchRowcode": "     \"\"\"A SingleStateFeaturizer for use with policies that predict intent labels.\"\"\""
            }
        },
        "frontPatchFile": [
            "import logging",
            "import numpy as np",
            "import scipy.sparse",
            "from typing import List, Optional, Dict, Text, Set, Any",
            "",
            "from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization",
            "from rasa.nlu.extractors.extractor import EntityTagSpec",
            "from rasa.nlu.utils import bilou_utils",
            "from rasa.nlu.utils.bilou_utils import BILOU_PREFIXES",
            "from rasa.shared.core.domain import SubState, State, Domain",
            "from rasa.shared.core.constants import PREVIOUS_ACTION, ACTIVE_LOOP, USER, SLOTS",
            "from rasa.shared.core.trackers import is_prev_action_listen_in_state",
            "from rasa.shared.nlu.constants import (",
            "    ENTITIES,",
            "    FEATURE_TYPE_SENTENCE,",
            "    ACTION_TEXT,",
            "    ACTION_NAME,",
            "    INTENT,",
            "    NO_ENTITY_TAG,",
            "    ENTITY_ATTRIBUTE_TYPE,",
            "    ENTITY_TAGS,",
            "    TEXT,",
            ")",
            "from rasa.shared.nlu.training_data.features import Features",
            "from rasa.utils.tensorflow import model_data_utils",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class SingleStateFeaturizer:",
            "    \"\"\"Base class to transform the dialogue state into an ML format.",
            "",
            "    Subclasses of SingleStateFeaturizer will decide how a bot will",
            "    transform the dialogue state into a dictionary mapping an attribute",
            "    to its features. Possible attributes are: `INTENT`, `TEXT`, `ACTION_NAME`,",
            "    `ACTION_TEXT`, `ENTITIES`, `SLOTS` and `ACTIVE_LOOP`. Each attribute will be",
            "    featurized into a list of `rasa.utils.features.Features`.",
            "    \"\"\"",
            "",
            "    def __init__(self) -> None:",
            "        \"\"\"Initialize the single state featurizer.\"\"\"",
            "        self._default_feature_states: Dict[Text, Any] = {}",
            "        self.action_texts: List[Text] = []",
            "        self.entity_tag_specs: List[EntityTagSpec] = []",
            "",
            "    def _create_entity_tag_specs(",
            "        self, bilou_tagging: bool = False",
            "    ) -> List[EntityTagSpec]:",
            "        \"\"\"Returns the tag to index mapping for entities.",
            "",
            "        Returns:",
            "            Tag to index mapping.",
            "        \"\"\"",
            "        if ENTITIES not in self._default_feature_states:",
            "            return []",
            "",
            "        if bilou_tagging:",
            "            tag_id_index_mapping = {",
            "                f\"{prefix}{tag}\": idx_1 * len(BILOU_PREFIXES) + idx_2 + 1",
            "                for tag, idx_1 in self._default_feature_states[ENTITIES].items()",
            "                for idx_2, prefix in enumerate(BILOU_PREFIXES)",
            "            }",
            "        else:",
            "            tag_id_index_mapping = {",
            "                tag: idx + 1  # +1 to keep 0 for the NO_ENTITY_TAG",
            "                for tag, idx in self._default_feature_states[ENTITIES].items()",
            "            }",
            "",
            "        # NO_ENTITY_TAG corresponds to non-entity which should correspond to 0 index",
            "        # needed for correct prediction for padding",
            "        tag_id_index_mapping[NO_ENTITY_TAG] = 0",
            "",
            "        # TODO",
            "        #  The entity states used to create the tag-idx-mapping contains the",
            "        #  entities and the concatenated entity and roles/groups. We do not",
            "        #  distinguish between entities and roles/groups right now.",
            "        #  we return a list to anticipate that",
            "        return [",
            "            EntityTagSpec(",
            "                tag_name=ENTITY_ATTRIBUTE_TYPE,",
            "                tags_to_ids=tag_id_index_mapping,",
            "                ids_to_tags={value: key for key, value in tag_id_index_mapping.items()},",
            "                num_tags=len(tag_id_index_mapping),",
            "            )",
            "        ]",
            "",
            "    def prepare_for_training(self, domain: Domain, bilou_tagging: bool = False) -> None:",
            "        \"\"\"Gets necessary information for featurization from domain.",
            "",
            "        Args:",
            "            domain: An instance of :class:`rasa.shared.core.domain.Domain`.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "        \"\"\"",
            "        # store feature states for each attribute in order to create binary features",
            "        def convert_to_dict(feature_states: List[Text]) -> Dict[Text, int]:",
            "            return {",
            "                feature_state: idx for idx, feature_state in enumerate(feature_states)",
            "            }",
            "",
            "        self._default_feature_states[INTENT] = convert_to_dict(domain.intents)",
            "        self._default_feature_states[ACTION_NAME] = convert_to_dict(",
            "            domain.action_names_or_texts",
            "        )",
            "        self._default_feature_states[ENTITIES] = convert_to_dict(domain.entity_states)",
            "        self._default_feature_states[SLOTS] = convert_to_dict(domain.slot_states)",
            "        self._default_feature_states[ACTIVE_LOOP] = convert_to_dict(domain.form_names)",
            "        self.action_texts = domain.action_texts",
            "        self.entity_tag_specs = self._create_entity_tag_specs(bilou_tagging)",
            "",
            "    def _state_features_for_attribute(",
            "        self, sub_state: SubState, attribute: Text",
            "    ) -> Dict[Text, int]:",
            "        # FIXME: the code below is not type-safe, but fixing it",
            "        #        would require more refactoring, for instance using",
            "        #        data classes in our states",
            "        if attribute in {INTENT, ACTION_NAME}:",
            "            return {sub_state[attribute]: 1}  # type: ignore[dict-item]",
            "        elif attribute == ENTITIES:",
            "            return {entity: 1 for entity in sub_state.get(ENTITIES, [])}  # type: ignore[misc]  # noqa: E501",
            "        elif attribute == ACTIVE_LOOP:",
            "            return {sub_state[\"name\"]: 1}  # type: ignore[dict-item]",
            "        elif attribute == SLOTS:",
            "            return {",
            "                f\"{slot_name}_{i}\": value  # type: ignore[misc]",
            "                for slot_name, slot_as_feature in sub_state.items()",
            "                for i, value in enumerate(slot_as_feature)",
            "            }",
            "        else:",
            "            raise ValueError(",
            "                f\"Given attribute '{attribute}' is not supported. \"",
            "                f\"It must be one of '{self._default_feature_states.keys()}'.\"",
            "            )",
            "",
            "    def _create_features(",
            "        self, sub_state: SubState, attribute: Text, sparse: bool = False",
            "    ) -> List[Features]:",
            "        state_features = self._state_features_for_attribute(sub_state, attribute)",
            "",
            "        features = np.zeros(len(self._default_feature_states[attribute]), np.float32)",
            "        for state_feature, value in state_features.items():",
            "            # check that the value is in default_feature_states to be able to assign",
            "            # its value",
            "            if state_feature in self._default_feature_states[attribute]:",
            "                features[self._default_feature_states[attribute][state_feature]] = value",
            "        features = np.expand_dims(features, 0)",
            "",
            "        if sparse:",
            "            features = scipy.sparse.coo_matrix(features)",
            "",
            "        return [",
            "            Features(",
            "                features, FEATURE_TYPE_SENTENCE, attribute, self.__class__.__name__",
            "            )",
            "        ]",
            "",
            "    @staticmethod",
            "    def _to_sparse_sentence_features(",
            "        sparse_sequence_features: List[Features],",
            "    ) -> List[Features]:",
            "        return [",
            "            Features(",
            "                scipy.sparse.coo_matrix(feature.features.sum(0)),",
            "                FEATURE_TYPE_SENTENCE,",
            "                feature.attribute,",
            "                feature.origin,",
            "            )",
            "            for feature in sparse_sequence_features",
            "        ]",
            "",
            "    @staticmethod",
            "    def _get_name_attribute(attributes: Set[Text]) -> Optional[Text]:",
            "        # there is always either INTENT or ACTION_NAME",
            "        return next(",
            "            (",
            "                attribute",
            "                for attribute in attributes",
            "                if attribute in {INTENT, ACTION_NAME}",
            "            ),",
            "            None,",
            "        )",
            "",
            "    def _extract_state_features(",
            "        self,",
            "        sub_state: SubState,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        sparse: bool = False,",
            "    ) -> Dict[Text, List[Features]]:",
            "",
            "        # Remove entities from possible attributes",
            "        attributes = set(",
            "            attribute for attribute in sub_state.keys() if attribute != ENTITIES",
            "        )",
            "",
            "        if precomputations is not None:",
            "",
            "            # Collect features for all those attributes",
            "            attributes_to_features = precomputations.collect_features(",
            "                sub_state, attributes=attributes",
            "            )",
            "            # if features for INTENT or ACTION_NAME exist,",
            "            # they are always sparse sequence features;",
            "            # transform them to sentence sparse features",
            "            if attributes_to_features.get(INTENT):",
            "                attributes_to_features[INTENT] = self._to_sparse_sentence_features(",
            "                    attributes_to_features[INTENT]",
            "                )",
            "            if attributes_to_features.get(ACTION_NAME):",
            "                attributes_to_features[ACTION_NAME] = self._to_sparse_sentence_features(",
            "                    attributes_to_features[ACTION_NAME]",
            "                )",
            "",
            "            # Combine and sort the features:",
            "            # Per attribute, combine features of same type and level into one Feature,",
            "            # and (if there are any such features) store the results in a list where",
            "            # - all the sparse features are listed first and a",
            "            # - sequence feature is always listed before the sentence feature of the",
            "            #   same type (sparse/not sparse).",
            "            output = {",
            "                attribute: Features.reduce(",
            "                    features_list=features_list, expected_origins=None",
            "                )",
            "                for attribute, features_list in attributes_to_features.items()",
            "                if len(features_list) > 0  # otherwise, following will fail",
            "            }",
            "        else:",
            "            output = {}",
            "",
            "        # Check that the name attribute has features",
            "        name_attribute = self._get_name_attribute(attributes)",
            "        if name_attribute and name_attribute not in output:",
            "            # nlu pipeline didn't create features for user or action",
            "            # this might happen, for example, when we have action_name in the state",
            "            # but it did not get featurized because only character level",
            "            # CountVectorsFeaturizer was included in the config.",
            "            output[name_attribute] = self._create_features(",
            "                sub_state, name_attribute, sparse",
            "            )",
            "        return output",
            "",
            "    def encode_state(",
            "        self,",
            "        state: State,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Encode the given state.",
            "",
            "        Args:",
            "            state: The state to encode",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A dictionary of state_type to list of features.",
            "        \"\"\"",
            "        state_features = {}",
            "        for state_type, sub_state in state.items():",
            "            if state_type == PREVIOUS_ACTION:",
            "                state_features.update(",
            "                    self._extract_state_features(",
            "                        sub_state, precomputations=precomputations, sparse=True",
            "                    )",
            "                )",
            "            # featurize user only if it is \"real\" user input,",
            "            # i.e. input from a turn after action_listen",
            "            if state_type == USER and is_prev_action_listen_in_state(state):",
            "",
            "                state_features.update(",
            "                    self._extract_state_features(",
            "                        sub_state, precomputations=precomputations, sparse=True",
            "                    )",
            "                )",
            "                if sub_state.get(ENTITIES):",
            "                    state_features[ENTITIES] = self._create_features(",
            "                        sub_state, ENTITIES, sparse=True",
            "                    )",
            "",
            "            if state_type in {SLOTS, ACTIVE_LOOP}:",
            "                state_features[state_type] = self._create_features(",
            "                    sub_state, state_type, sparse=True",
            "                )",
            "",
            "        return state_features",
            "",
            "    def encode_entities(",
            "        self,",
            "        entity_data: Dict[Text, Any],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Encode the given entity data.",
            "",
            "        Produce numeric entity tags for tokens.",
            "",
            "        Args:",
            "            entity_data: The dict containing the text and entity labels and locations",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "",
            "        Returns:",
            "            A dictionary of entity type to list of features.",
            "        \"\"\"",
            "        # TODO",
            "        #  The entity states used to create the tag-idx-mapping contains the",
            "        #  entities and the concatenated entity and roles/groups. We do not",
            "        #  distinguish between entities and roles/groups right now.",
            "        if (",
            "            not entity_data",
            "            or not self.entity_tag_specs",
            "            or self.entity_tag_specs[0].num_tags < 2",
            "        ):",
            "            # we cannot build a classifier with fewer than 2 classes",
            "            return {}",
            "        if precomputations is None:",
            "            message = None",
            "        else:",
            "            message = precomputations.lookup_message(user_text=entity_data[TEXT])",
            "            message.data[ENTITIES] = entity_data[ENTITIES]",
            "",
            "        if not message:",
            "            return {}",
            "",
            "        if bilou_tagging:",
            "            bilou_utils.apply_bilou_schema_to_message(message)",
            "",
            "        return {",
            "            ENTITY_TAGS: [",
            "                model_data_utils.get_tag_ids(",
            "                    message, self.entity_tag_specs[0], bilou_tagging",
            "                )",
            "            ]",
            "        }",
            "",
            "    def _encode_action(",
            "        self,",
            "        action: Text,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        if action in self.action_texts:",
            "            action_as_sub_state = {ACTION_TEXT: action}",
            "        else:",
            "            action_as_sub_state = {ACTION_NAME: action}",
            "",
            "        return self._extract_state_features(",
            "            action_as_sub_state, precomputations=precomputations",
            "        )",
            "",
            "    def encode_all_labels(",
            "        self,",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[Dict[Text, List[Features]]]:",
            "        \"\"\"Encode all action from the domain.",
            "",
            "        Args:",
            "            domain: The domain that contains the actions.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A list of encoded actions.",
            "        \"\"\"",
            "        return [",
            "            self._encode_action(action, precomputations)",
            "            for action in domain.action_names_or_texts",
            "        ]",
            "",
            "",
            "class IntentTokenizerSingleStateFeaturizer(SingleStateFeaturizer):",
            "    \"\"\"A SingleStateFeaturizer for use with policies that predict intent labels.\"\"\"",
            "",
            "    def _encode_intent(",
            "        self,",
            "        intent: Text,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Extracts a numeric representation of an intent.",
            "",
            "        Args:",
            "            intent: Intent to be encoded.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            Encoded representation of intent.",
            "        \"\"\"",
            "        intent_as_sub_state = {INTENT: intent}",
            "        return self._extract_state_features(intent_as_sub_state, precomputations)",
            "",
            "    def encode_all_labels(",
            "        self,",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[Dict[Text, List[Features]]]:",
            "        \"\"\"Encodes all relevant labels from the domain using the given precomputations.",
            "",
            "        Args:",
            "            domain: The domain that contains the labels.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A list of encoded labels.",
            "        \"\"\"",
            "        return [",
            "            self._encode_intent(intent, precomputations) for intent in domain.intents",
            "        ]"
        ],
        "afterPatchFile": [
            "import logging",
            "from typing import List, Optional, Dict, Text, Set, Any",
            "",
            "import numpy as np",
            "import scipy.sparse",
            "",
            "from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization",
            "from rasa.nlu.extractors.extractor import EntityTagSpec",
            "from rasa.nlu.utils import bilou_utils",
            "from rasa.nlu.utils.bilou_utils import BILOU_PREFIXES",
            "from rasa.shared.core.domain import SubState, State, Domain",
            "from rasa.shared.core.constants import PREVIOUS_ACTION, ACTIVE_LOOP, USER, SLOTS",
            "from rasa.shared.core.trackers import is_prev_action_listen_in_state",
            "from rasa.shared.nlu.constants import (",
            "    ENTITIES,",
            "    FEATURE_TYPE_SENTENCE,",
            "    ACTION_TEXT,",
            "    ACTION_NAME,",
            "    INTENT,",
            "    NO_ENTITY_TAG,",
            "    ENTITY_ATTRIBUTE_TYPE,",
            "    ENTITY_TAGS,",
            "    TEXT,",
            ")",
            "from rasa.shared.nlu.training_data.features import Features",
            "from rasa.utils.tensorflow import model_data_utils",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class SingleStateFeaturizer:",
            "    \"\"\"Base class to transform the dialogue state into an ML format.",
            "",
            "    Subclasses of SingleStateFeaturizer will decide how a bot will",
            "    transform the dialogue state into a dictionary mapping an attribute",
            "    to its features. Possible attributes are: `INTENT`, `TEXT`, `ACTION_NAME`,",
            "    `ACTION_TEXT`, `ENTITIES`, `SLOTS` and `ACTIVE_LOOP`. Each attribute will be",
            "    featurized into a list of `rasa.utils.features.Features`.",
            "    \"\"\"",
            "",
            "    def __init__(self) -> None:",
            "        \"\"\"Initialize the single state featurizer.\"\"\"",
            "        self._default_feature_states: Dict[Text, Any] = {}",
            "        self.action_texts: List[Text] = []",
            "        self.entity_tag_specs: List[EntityTagSpec] = []",
            "",
            "    def _create_entity_tag_specs(",
            "        self, bilou_tagging: bool = False",
            "    ) -> List[EntityTagSpec]:",
            "        \"\"\"Returns the tag to index mapping for entities.",
            "",
            "        Returns:",
            "            Tag to index mapping.",
            "        \"\"\"",
            "        if ENTITIES not in self._default_feature_states:",
            "            return []",
            "",
            "        if bilou_tagging:",
            "            tag_id_index_mapping = {",
            "                f\"{prefix}{tag}\": idx_1 * len(BILOU_PREFIXES) + idx_2 + 1",
            "                for tag, idx_1 in self._default_feature_states[ENTITIES].items()",
            "                for idx_2, prefix in enumerate(BILOU_PREFIXES)",
            "            }",
            "        else:",
            "            tag_id_index_mapping = {",
            "                tag: idx + 1  # +1 to keep 0 for the NO_ENTITY_TAG",
            "                for tag, idx in self._default_feature_states[ENTITIES].items()",
            "            }",
            "",
            "        # NO_ENTITY_TAG corresponds to non-entity which should correspond to 0 index",
            "        # needed for correct prediction for padding",
            "        tag_id_index_mapping[NO_ENTITY_TAG] = 0",
            "",
            "        # TODO",
            "        #  The entity states used to create the tag-idx-mapping contains the",
            "        #  entities and the concatenated entity and roles/groups. We do not",
            "        #  distinguish between entities and roles/groups right now.",
            "        #  we return a list to anticipate that",
            "        return [",
            "            EntityTagSpec(",
            "                tag_name=ENTITY_ATTRIBUTE_TYPE,",
            "                tags_to_ids=tag_id_index_mapping,",
            "                ids_to_tags={value: key for key, value in tag_id_index_mapping.items()},",
            "                num_tags=len(tag_id_index_mapping),",
            "            )",
            "        ]",
            "",
            "    def prepare_for_training(self, domain: Domain, bilou_tagging: bool = False) -> None:",
            "        \"\"\"Gets necessary information for featurization from domain.",
            "",
            "        Args:",
            "            domain: An instance of :class:`rasa.shared.core.domain.Domain`.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "        \"\"\"",
            "        # store feature states for each attribute in order to create binary features",
            "        def convert_to_dict(feature_states: List[Text]) -> Dict[Text, int]:",
            "            return {",
            "                feature_state: idx for idx, feature_state in enumerate(feature_states)",
            "            }",
            "",
            "        self._default_feature_states[INTENT] = convert_to_dict(domain.intents)",
            "        self._default_feature_states[ACTION_NAME] = convert_to_dict(",
            "            domain.action_names_or_texts",
            "        )",
            "        self._default_feature_states[ENTITIES] = convert_to_dict(domain.entity_states)",
            "        self._default_feature_states[SLOTS] = convert_to_dict(domain.slot_states)",
            "        self._default_feature_states[ACTIVE_LOOP] = convert_to_dict(domain.form_names)",
            "        self.action_texts = domain.action_texts",
            "        self.entity_tag_specs = self._create_entity_tag_specs(bilou_tagging)",
            "",
            "    def _state_features_for_attribute(",
            "        self, sub_state: SubState, attribute: Text",
            "    ) -> Dict[Text, int]:",
            "        # FIXME: the code below is not type-safe, but fixing it",
            "        #        would require more refactoring, for instance using",
            "        #        data classes in our states",
            "        if attribute in {INTENT, ACTION_NAME}:",
            "            return {sub_state[attribute]: 1}  # type: ignore[dict-item]",
            "        elif attribute == ENTITIES:",
            "            return {entity: 1 for entity in sub_state.get(ENTITIES, [])}  # type: ignore[misc]  # noqa: E501",
            "        elif attribute == ACTIVE_LOOP:",
            "            return {sub_state[\"name\"]: 1}  # type: ignore[dict-item]",
            "        elif attribute == SLOTS:",
            "            return {",
            "                f\"{slot_name}_{i}\": value  # type: ignore[misc]",
            "                for slot_name, slot_as_feature in sub_state.items()",
            "                for i, value in enumerate(slot_as_feature)",
            "            }",
            "        else:",
            "            raise ValueError(",
            "                f\"Given attribute '{attribute}' is not supported. \"",
            "                f\"It must be one of '{self._default_feature_states.keys()}'.\"",
            "            )",
            "",
            "    def _create_features(",
            "        self, sub_state: SubState, attribute: Text, sparse: bool = False",
            "    ) -> List[Features]:",
            "        state_features = self._state_features_for_attribute(sub_state, attribute)",
            "",
            "        features = np.zeros(len(self._default_feature_states[attribute]), np.float32)",
            "        for state_feature, value in state_features.items():",
            "            # check that the value is in default_feature_states to be able to assign",
            "            # its value",
            "            if state_feature in self._default_feature_states[attribute]:",
            "                features[self._default_feature_states[attribute][state_feature]] = value",
            "        features = np.expand_dims(features, 0)",
            "",
            "        if sparse:",
            "            features = scipy.sparse.coo_matrix(features)",
            "",
            "        return [",
            "            Features(",
            "                features, FEATURE_TYPE_SENTENCE, attribute, self.__class__.__name__",
            "            )",
            "        ]",
            "",
            "    @staticmethod",
            "    def _to_sparse_sentence_features(",
            "        sparse_sequence_features: List[Features],",
            "    ) -> List[Features]:",
            "        return [",
            "            Features(",
            "                scipy.sparse.coo_matrix(feature.features.sum(0)),",
            "                FEATURE_TYPE_SENTENCE,",
            "                feature.attribute,",
            "                feature.origin,",
            "            )",
            "            for feature in sparse_sequence_features",
            "        ]",
            "",
            "    @staticmethod",
            "    def _get_name_attribute(attributes: Set[Text]) -> Optional[Text]:",
            "        # there is always either INTENT or ACTION_NAME",
            "        return next(",
            "            (",
            "                attribute",
            "                for attribute in attributes",
            "                if attribute in {INTENT, ACTION_NAME}",
            "            ),",
            "            None,",
            "        )",
            "",
            "    def _extract_state_features(",
            "        self,",
            "        sub_state: SubState,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        sparse: bool = False,",
            "    ) -> Dict[Text, List[Features]]:",
            "",
            "        # Remove entities from possible attributes",
            "        attributes = set(",
            "            attribute for attribute in sub_state.keys() if attribute != ENTITIES",
            "        )",
            "",
            "        if precomputations is not None:",
            "",
            "            # Collect features for all those attributes",
            "            attributes_to_features = precomputations.collect_features(",
            "                sub_state, attributes=attributes",
            "            )",
            "            # if features for INTENT or ACTION_NAME exist,",
            "            # they are always sparse sequence features;",
            "            # transform them to sentence sparse features",
            "            if attributes_to_features.get(INTENT):",
            "                attributes_to_features[INTENT] = self._to_sparse_sentence_features(",
            "                    attributes_to_features[INTENT]",
            "                )",
            "            if attributes_to_features.get(ACTION_NAME):",
            "                attributes_to_features[ACTION_NAME] = self._to_sparse_sentence_features(",
            "                    attributes_to_features[ACTION_NAME]",
            "                )",
            "",
            "            # Combine and sort the features:",
            "            # Per attribute, combine features of same type and level into one Feature,",
            "            # and (if there are any such features) store the results in a list where",
            "            # - all the sparse features are listed first and a",
            "            # - sequence feature is always listed before the sentence feature of the",
            "            #   same type (sparse/not sparse).",
            "            output = {",
            "                attribute: Features.reduce(",
            "                    features_list=features_list, expected_origins=None",
            "                )",
            "                for attribute, features_list in attributes_to_features.items()",
            "                if len(features_list) > 0  # otherwise, following will fail",
            "            }",
            "        else:",
            "            output = {}",
            "",
            "        # Check that the name attribute has features",
            "        name_attribute = self._get_name_attribute(attributes)",
            "        if name_attribute and name_attribute not in output:",
            "            # nlu pipeline didn't create features for user or action",
            "            # this might happen, for example, when we have action_name in the state",
            "            # but it did not get featurized because only character level",
            "            # CountVectorsFeaturizer was included in the config.",
            "            output[name_attribute] = self._create_features(",
            "                sub_state, name_attribute, sparse",
            "            )",
            "        return output",
            "",
            "    def encode_state(",
            "        self,",
            "        state: State,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Encode the given state.",
            "",
            "        Args:",
            "            state: The state to encode",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A dictionary of state_type to list of features.",
            "        \"\"\"",
            "        state_features = {}",
            "        for state_type, sub_state in state.items():",
            "            if state_type == PREVIOUS_ACTION:",
            "                state_features.update(",
            "                    self._extract_state_features(",
            "                        sub_state, precomputations=precomputations, sparse=True",
            "                    )",
            "                )",
            "            # featurize user only if it is \"real\" user input,",
            "            # i.e. input from a turn after action_listen",
            "            if state_type == USER and is_prev_action_listen_in_state(state):",
            "",
            "                state_features.update(",
            "                    self._extract_state_features(",
            "                        sub_state, precomputations=precomputations, sparse=True",
            "                    )",
            "                )",
            "                if sub_state.get(ENTITIES):",
            "                    state_features[ENTITIES] = self._create_features(",
            "                        sub_state, ENTITIES, sparse=True",
            "                    )",
            "",
            "            if state_type in {SLOTS, ACTIVE_LOOP}:",
            "                state_features[state_type] = self._create_features(",
            "                    sub_state, state_type, sparse=True",
            "                )",
            "",
            "        return state_features",
            "",
            "    def encode_entities(",
            "        self,",
            "        entity_data: Dict[Text, Any],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Encode the given entity data.",
            "",
            "        Produce numeric entity tags for tokens.",
            "",
            "        Args:",
            "            entity_data: The dict containing the text and entity labels and locations",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "",
            "        Returns:",
            "            A dictionary of entity type to list of features.",
            "        \"\"\"",
            "        # TODO",
            "        #  The entity states used to create the tag-idx-mapping contains the",
            "        #  entities and the concatenated entity and roles/groups. We do not",
            "        #  distinguish between entities and roles/groups right now.",
            "        if (",
            "            not entity_data",
            "            or not self.entity_tag_specs",
            "            or self.entity_tag_specs[0].num_tags < 2",
            "        ):",
            "            # we cannot build a classifier with fewer than 2 classes",
            "            return {}",
            "        if precomputations is None:",
            "            message = None",
            "        else:",
            "            message = precomputations.lookup_message(user_text=entity_data[TEXT])",
            "            message.data[ENTITIES] = entity_data[ENTITIES]",
            "",
            "        if not message:",
            "            return {}",
            "",
            "        if bilou_tagging:",
            "            bilou_utils.apply_bilou_schema_to_message(message)",
            "",
            "        return {",
            "            ENTITY_TAGS: [",
            "                model_data_utils.get_tag_ids(",
            "                    message, self.entity_tag_specs[0], bilou_tagging",
            "                )",
            "            ]",
            "        }",
            "",
            "    def _encode_action(",
            "        self,",
            "        action: Text,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        if action in self.action_texts:",
            "            action_as_sub_state = {ACTION_TEXT: action}",
            "        else:",
            "            action_as_sub_state = {ACTION_NAME: action}",
            "",
            "        return self._extract_state_features(",
            "            action_as_sub_state, precomputations=precomputations",
            "        )",
            "",
            "    def encode_all_labels(",
            "        self,",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[Dict[Text, List[Features]]]:",
            "        \"\"\"Encode all action from the domain.",
            "",
            "        Args:",
            "            domain: The domain that contains the actions.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A list of encoded actions.",
            "        \"\"\"",
            "        return [",
            "            self._encode_action(action, precomputations)",
            "            for action in domain.action_names_or_texts",
            "        ]",
            "",
            "    def to_dict(self) -> Dict[str, Any]:",
            "        return {",
            "            \"action_texts\": self.action_texts,",
            "            \"entity_tag_specs\": self.entity_tag_specs,",
            "            \"feature_states\": self._default_feature_states,",
            "        }",
            "",
            "    @classmethod",
            "    def create_from_dict(",
            "        cls, data: Dict[str, Any]",
            "    ) -> Optional[\"SingleStateFeaturizer\"]:",
            "        if not data:",
            "            return None",
            "",
            "        featurizer = SingleStateFeaturizer()",
            "        featurizer.action_texts = data[\"action_texts\"]",
            "        featurizer._default_feature_states = data[\"feature_states\"]",
            "        featurizer.entity_tag_specs = data[\"entity_tag_specs\"]",
            "        return featurizer",
            "",
            "",
            "class IntentTokenizerSingleStateFeaturizer(SingleStateFeaturizer):",
            "    \"\"\"A SingleStateFeaturizer for use with policies that predict intent labels.\"\"\"",
            "",
            "    def _encode_intent(",
            "        self,",
            "        intent: Text,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> Dict[Text, List[Features]]:",
            "        \"\"\"Extracts a numeric representation of an intent.",
            "",
            "        Args:",
            "            intent: Intent to be encoded.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            Encoded representation of intent.",
            "        \"\"\"",
            "        intent_as_sub_state = {INTENT: intent}",
            "        return self._extract_state_features(intent_as_sub_state, precomputations)",
            "",
            "    def encode_all_labels(",
            "        self,",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[Dict[Text, List[Features]]]:",
            "        \"\"\"Encodes all relevant labels from the domain using the given precomputations.",
            "",
            "        Args:",
            "            domain: The domain that contains the labels.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            A list of encoded labels.",
            "        \"\"\"",
            "        return [",
            "            self._encode_intent(intent, precomputations) for intent in domain.intents",
            "        ]"
        ],
        "action": [
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "4": []
        },
        "addLocation": []
    },
    "rasa/core/featurizers/tracker_featurizers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " from __future__ import annotations"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from pathlib import Path"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from collections import defaultdict"
            },
            "3": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from abc import abstractmethod"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import jsonpickle"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import logging"
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from tqdm import tqdm"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3,
                "PatchRowcode": "+import logging"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 4,
                "PatchRowcode": "+from abc import abstractmethod"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 5,
                "PatchRowcode": "+from collections import defaultdict"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 6,
                "PatchRowcode": "+from pathlib import Path"
            },
            "12": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from typing import ("
            },
            "13": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     Tuple,"
            },
            "14": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 9,
                "PatchRowcode": "     List,"
            },
            "15": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 16,
                "PatchRowcode": "     Set,"
            },
            "16": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 17,
                "PatchRowcode": "     DefaultDict,"
            },
            "17": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 18,
                "PatchRowcode": "     cast,"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+    Type,"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    Callable,"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+    ClassVar,"
            },
            "21": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " )"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " import numpy as np"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+from tqdm import tqdm"
            },
            "25": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.core.featurizers.single_state_featurizer import SingleStateFeaturizer"
            },
            "27": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization"
            },
            "28": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.core.exceptions import InvalidTrackerFeaturizerUsageError"
            },
            "29": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " import rasa.shared.core.trackers"
            },
            "30": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " import rasa.shared.utils.io"
            },
            "31": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.shared.nlu.constants import TEXT, INTENT, ENTITIES, ACTION_NAME"
            },
            "32": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.shared.nlu.training_data.features import Features"
            },
            "33": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.shared.core.trackers import DialogueStateTracker"
            },
            "34": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.shared.core.domain import State, Domain"
            },
            "35": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from rasa.shared.core.events import Event, ActionExecuted, UserUttered"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+from rasa.core.exceptions import InvalidTrackerFeaturizerUsageError"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+from rasa.core.featurizers.single_state_featurizer import SingleStateFeaturizer"
            },
            "39": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from rasa.shared.core.constants import ("
            },
            "40": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "     USER,"
            },
            "41": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "     ACTION_UNLIKELY_INTENT_NAME,"
            },
            "42": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "     PREVIOUS_ACTION,"
            },
            "43": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " )"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+from rasa.shared.core.domain import State, Domain"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+from rasa.shared.core.events import Event, ActionExecuted, UserUttered"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+from rasa.shared.core.trackers import DialogueStateTracker"
            },
            "47": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " from rasa.shared.exceptions import RasaException"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+from rasa.shared.nlu.constants import TEXT, INTENT, ENTITIES, ACTION_NAME"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+from rasa.shared.nlu.training_data.features import Features"
            },
            "50": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " from rasa.utils.tensorflow.constants import LABEL_PAD_ID"
            },
            "51": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " from rasa.utils.tensorflow.model_data import ragged_array_to_ndarray"
            },
            "52": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 45,
                "PatchRowcode": " "
            },
            "53": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " class TrackerFeaturizer:"
            },
            "54": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     \"\"\"Base class for actual tracker featurizers.\"\"\""
            },
            "55": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " "
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+    # Class registry to store all subclasses"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+    _registry: ClassVar[Dict[str, Type[\"TrackerFeaturizer\"]]] = {}"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    _featurizer_type: str = \"TrackerFeaturizer\""
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+"
            },
            "60": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "     def __init__("
            },
            "61": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         self, state_featurizer: Optional[SingleStateFeaturizer] = None"
            },
            "62": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "     ) -> None:"
            },
            "63": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "         \"\"\""
            },
            "64": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         self.state_featurizer = state_featurizer"
            },
            "65": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 83,
                "PatchRowcode": " "
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+    @classmethod"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+    def register(cls, featurizer_type: str) -> Callable:"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+        \"\"\"Decorator to register featurizer subclasses.\"\"\""
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        def wrapper(subclass: Type[\"TrackerFeaturizer\"]) -> Type[\"TrackerFeaturizer\"]:"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+            cls._registry[featurizer_type] = subclass"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            # Store the type identifier in the class for serialization"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            subclass._featurizer_type = featurizer_type"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+            return subclass"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+        return wrapper"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+    @classmethod"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+    def from_dict(cls, data: Dict[str, Any]) -> \"TrackerFeaturizer\":"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+        \"\"\"Create featurizer instance from dictionary.\"\"\""
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+        featurizer_type = data.pop(\"type\")"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+        if featurizer_type not in cls._registry:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+            raise ValueError(f\"Unknown featurizer type: {featurizer_type}\")"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+        # Get the correct subclass and instantiate it"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+        subclass = cls._registry[featurizer_type]"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        return subclass.create_from_dict(data)"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+    @classmethod"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+    @abstractmethod"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+    def create_from_dict(cls, data: Dict[str, Any]) -> \"TrackerFeaturizer\":"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        \"\"\"Each subclass must implement its own creation from dict method.\"\"\""
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+        pass"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+"
            },
            "96": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "     @staticmethod"
            },
            "97": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     def _create_states("
            },
            "98": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "         tracker: DialogueStateTracker,"
            },
            "99": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": 502,
                "PatchRowcode": "             self.state_featurizer.entity_tag_specs = []"
            },
            "100": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": 503,
                "PatchRowcode": " "
            },
            "101": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": 504,
                "PatchRowcode": "         # noinspection PyTypeChecker"
            },
            "102": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        rasa.shared.utils.io.write_text_file("
            },
            "103": {
                "beforePatchRowNumber": 469,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            str(jsonpickle.encode(self)), featurizer_file"
            },
            "104": {
                "beforePatchRowNumber": 470,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 505,
                "PatchRowcode": "+        rasa.shared.utils.io.dump_obj_as_json_to_file(featurizer_file, self.to_dict())"
            },
            "106": {
                "beforePatchRowNumber": 471,
                "afterPatchRowNumber": 506,
                "PatchRowcode": " "
            },
            "107": {
                "beforePatchRowNumber": 472,
                "afterPatchRowNumber": 507,
                "PatchRowcode": "     @staticmethod"
            },
            "108": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": 508,
                "PatchRowcode": "     def load(path: Union[Text, Path]) -> Optional[TrackerFeaturizer]:"
            },
            "109": {
                "beforePatchRowNumber": 481,
                "afterPatchRowNumber": 516,
                "PatchRowcode": "         \"\"\""
            },
            "110": {
                "beforePatchRowNumber": 482,
                "afterPatchRowNumber": 517,
                "PatchRowcode": "         featurizer_file = Path(path) / FEATURIZER_FILE"
            },
            "111": {
                "beforePatchRowNumber": 483,
                "afterPatchRowNumber": 518,
                "PatchRowcode": "         if featurizer_file.is_file():"
            },
            "112": {
                "beforePatchRowNumber": 484,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return jsonpickle.decode(rasa.shared.utils.io.read_file(featurizer_file))"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 519,
                "PatchRowcode": "+            data = rasa.shared.utils.io.read_json_file(featurizer_file)"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 520,
                "PatchRowcode": "+"
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 521,
                "PatchRowcode": "+            if \"type\" not in data:"
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 522,
                "PatchRowcode": "+                logger.error("
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 523,
                "PatchRowcode": "+                    f\"Couldn't load featurizer for policy. \""
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 524,
                "PatchRowcode": "+                    f\"File '{featurizer_file}' does not contain all \""
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 525,
                "PatchRowcode": "+                    f\"necessary information. 'type' is missing.\""
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 526,
                "PatchRowcode": "+                )"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 527,
                "PatchRowcode": "+                return None"
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 528,
                "PatchRowcode": "+"
            },
            "123": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 529,
                "PatchRowcode": "+            return TrackerFeaturizer.from_dict(data)"
            },
            "124": {
                "beforePatchRowNumber": 485,
                "afterPatchRowNumber": 530,
                "PatchRowcode": " "
            },
            "125": {
                "beforePatchRowNumber": 486,
                "afterPatchRowNumber": 531,
                "PatchRowcode": "         logger.error("
            },
            "126": {
                "beforePatchRowNumber": 487,
                "afterPatchRowNumber": 532,
                "PatchRowcode": "             f\"Couldn't load featurizer for policy. \""
            },
            "127": {
                "beforePatchRowNumber": 508,
                "afterPatchRowNumber": 553,
                "PatchRowcode": "             )"
            },
            "128": {
                "beforePatchRowNumber": 509,
                "afterPatchRowNumber": 554,
                "PatchRowcode": "         ]"
            },
            "129": {
                "beforePatchRowNumber": 510,
                "afterPatchRowNumber": 555,
                "PatchRowcode": " "
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 556,
                "PatchRowcode": "+    def to_dict(self) -> Dict[str, Any]:"
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 557,
                "PatchRowcode": "+        return {"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 558,
                "PatchRowcode": "+            \"type\": self.__class__._featurizer_type,"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 559,
                "PatchRowcode": "+            \"state_featurizer\": ("
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 560,
                "PatchRowcode": "+                self.state_featurizer.to_dict() if self.state_featurizer else None"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 561,
                "PatchRowcode": "+            ),"
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 562,
                "PatchRowcode": "+        }"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 563,
                "PatchRowcode": "+"
            },
            "138": {
                "beforePatchRowNumber": 511,
                "afterPatchRowNumber": 564,
                "PatchRowcode": " "
            },
            "139": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 565,
                "PatchRowcode": "+@TrackerFeaturizer.register(\"FullDialogueTrackerFeaturizer\")"
            },
            "140": {
                "beforePatchRowNumber": 512,
                "afterPatchRowNumber": 566,
                "PatchRowcode": " class FullDialogueTrackerFeaturizer(TrackerFeaturizer):"
            },
            "141": {
                "beforePatchRowNumber": 513,
                "afterPatchRowNumber": 567,
                "PatchRowcode": "     \"\"\"Creates full dialogue training data for time distributed architectures."
            },
            "142": {
                "beforePatchRowNumber": 514,
                "afterPatchRowNumber": 568,
                "PatchRowcode": " "
            },
            "143": {
                "beforePatchRowNumber": 646,
                "afterPatchRowNumber": 700,
                "PatchRowcode": " "
            },
            "144": {
                "beforePatchRowNumber": 647,
                "afterPatchRowNumber": 701,
                "PatchRowcode": "         return trackers_as_states"
            },
            "145": {
                "beforePatchRowNumber": 648,
                "afterPatchRowNumber": 702,
                "PatchRowcode": " "
            },
            "146": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 703,
                "PatchRowcode": "+    def to_dict(self) -> Dict[str, Any]:"
            },
            "147": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 704,
                "PatchRowcode": "+        return super().to_dict()"
            },
            "148": {
                "beforePatchRowNumber": 649,
                "afterPatchRowNumber": 705,
                "PatchRowcode": " "
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 706,
                "PatchRowcode": "+    @classmethod"
            },
            "150": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 707,
                "PatchRowcode": "+    def create_from_dict(cls, data: Dict[str, Any]) -> \"FullDialogueTrackerFeaturizer\":"
            },
            "151": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 708,
                "PatchRowcode": "+        state_featurizer = SingleStateFeaturizer.create_from_dict("
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 709,
                "PatchRowcode": "+            data[\"state_featurizer\"]"
            },
            "153": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 710,
                "PatchRowcode": "+        )"
            },
            "154": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 711,
                "PatchRowcode": "+        return cls("
            },
            "155": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 712,
                "PatchRowcode": "+            state_featurizer,"
            },
            "156": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 713,
                "PatchRowcode": "+        )"
            },
            "157": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 714,
                "PatchRowcode": "+"
            },
            "158": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 715,
                "PatchRowcode": "+"
            },
            "159": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 716,
                "PatchRowcode": "+@TrackerFeaturizer.register(\"MaxHistoryTrackerFeaturizer\")"
            },
            "160": {
                "beforePatchRowNumber": 650,
                "afterPatchRowNumber": 717,
                "PatchRowcode": " class MaxHistoryTrackerFeaturizer(TrackerFeaturizer):"
            },
            "161": {
                "beforePatchRowNumber": 651,
                "afterPatchRowNumber": 718,
                "PatchRowcode": "     \"\"\"Truncates the tracker history into `max_history` long sequences."
            },
            "162": {
                "beforePatchRowNumber": 652,
                "afterPatchRowNumber": 719,
                "PatchRowcode": " "
            },
            "163": {
                "beforePatchRowNumber": 887,
                "afterPatchRowNumber": 954,
                "PatchRowcode": " "
            },
            "164": {
                "beforePatchRowNumber": 888,
                "afterPatchRowNumber": 955,
                "PatchRowcode": "         return trackers_as_states"
            },
            "165": {
                "beforePatchRowNumber": 889,
                "afterPatchRowNumber": 956,
                "PatchRowcode": " "
            },
            "166": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 957,
                "PatchRowcode": "+    def to_dict(self) -> Dict[str, Any]:"
            },
            "167": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 958,
                "PatchRowcode": "+        data = super().to_dict()"
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 959,
                "PatchRowcode": "+        data.update("
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 960,
                "PatchRowcode": "+            {"
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 961,
                "PatchRowcode": "+                \"remove_duplicates\": self.remove_duplicates,"
            },
            "171": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 962,
                "PatchRowcode": "+                \"max_history\": self.max_history,"
            },
            "172": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 963,
                "PatchRowcode": "+            }"
            },
            "173": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 964,
                "PatchRowcode": "+        )"
            },
            "174": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 965,
                "PatchRowcode": "+        return data"
            },
            "175": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 966,
                "PatchRowcode": "+"
            },
            "176": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 967,
                "PatchRowcode": "+    @classmethod"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 968,
                "PatchRowcode": "+    def create_from_dict(cls, data: Dict[str, Any]) -> \"MaxHistoryTrackerFeaturizer\":"
            },
            "178": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 969,
                "PatchRowcode": "+        state_featurizer = SingleStateFeaturizer.create_from_dict("
            },
            "179": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 970,
                "PatchRowcode": "+            data[\"state_featurizer\"]"
            },
            "180": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 971,
                "PatchRowcode": "+        )"
            },
            "181": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 972,
                "PatchRowcode": "+        return cls(state_featurizer, data[\"max_history\"], data[\"remove_duplicates\"])"
            },
            "182": {
                "beforePatchRowNumber": 890,
                "afterPatchRowNumber": 973,
                "PatchRowcode": " "
            },
            "183": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 974,
                "PatchRowcode": "+"
            },
            "184": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 975,
                "PatchRowcode": "+@TrackerFeaturizer.register(\"IntentMaxHistoryTrackerFeaturizer\")"
            },
            "185": {
                "beforePatchRowNumber": 891,
                "afterPatchRowNumber": 976,
                "PatchRowcode": " class IntentMaxHistoryTrackerFeaturizer(MaxHistoryTrackerFeaturizer):"
            },
            "186": {
                "beforePatchRowNumber": 892,
                "afterPatchRowNumber": 977,
                "PatchRowcode": "     \"\"\"Truncates the tracker history into `max_history` long sequences."
            },
            "187": {
                "beforePatchRowNumber": 893,
                "afterPatchRowNumber": 978,
                "PatchRowcode": " "
            },
            "188": {
                "beforePatchRowNumber": 1166,
                "afterPatchRowNumber": 1251,
                "PatchRowcode": " "
            },
            "189": {
                "beforePatchRowNumber": 1167,
                "afterPatchRowNumber": 1252,
                "PatchRowcode": "         return trackers_as_states"
            },
            "190": {
                "beforePatchRowNumber": 1168,
                "afterPatchRowNumber": 1253,
                "PatchRowcode": " "
            },
            "191": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1254,
                "PatchRowcode": "+    def to_dict(self) -> Dict[str, Any]:"
            },
            "192": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1255,
                "PatchRowcode": "+        return super().to_dict()"
            },
            "193": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1256,
                "PatchRowcode": "+"
            },
            "194": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1257,
                "PatchRowcode": "+    @classmethod"
            },
            "195": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1258,
                "PatchRowcode": "+    def create_from_dict("
            },
            "196": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1259,
                "PatchRowcode": "+        cls, data: Dict[str, Any]"
            },
            "197": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1260,
                "PatchRowcode": "+    ) -> \"IntentMaxHistoryTrackerFeaturizer\":"
            },
            "198": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1261,
                "PatchRowcode": "+        state_featurizer = SingleStateFeaturizer.create_from_dict("
            },
            "199": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1262,
                "PatchRowcode": "+            data[\"state_featurizer\"]"
            },
            "200": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1263,
                "PatchRowcode": "+        )"
            },
            "201": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1264,
                "PatchRowcode": "+        return cls(state_featurizer, data[\"max_history\"], data[\"remove_duplicates\"])"
            },
            "202": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1265,
                "PatchRowcode": "+"
            },
            "203": {
                "beforePatchRowNumber": 1169,
                "afterPatchRowNumber": 1266,
                "PatchRowcode": " "
            },
            "204": {
                "beforePatchRowNumber": 1170,
                "afterPatchRowNumber": 1267,
                "PatchRowcode": " def _is_prev_action_unlikely_intent_in_state(state: State) -> bool:"
            },
            "205": {
                "beforePatchRowNumber": 1171,
                "afterPatchRowNumber": 1268,
                "PatchRowcode": "     prev_action_name = state.get(PREVIOUS_ACTION, {}).get(ACTION_NAME)"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "from pathlib import Path",
            "from collections import defaultdict",
            "from abc import abstractmethod",
            "import jsonpickle",
            "import logging",
            "",
            "from tqdm import tqdm",
            "from typing import (",
            "    Tuple,",
            "    List,",
            "    Optional,",
            "    Dict,",
            "    Text,",
            "    Union,",
            "    Any,",
            "    Iterator,",
            "    Set,",
            "    DefaultDict,",
            "    cast,",
            ")",
            "import numpy as np",
            "",
            "from rasa.core.featurizers.single_state_featurizer import SingleStateFeaturizer",
            "from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization",
            "from rasa.core.exceptions import InvalidTrackerFeaturizerUsageError",
            "import rasa.shared.core.trackers",
            "import rasa.shared.utils.io",
            "from rasa.shared.nlu.constants import TEXT, INTENT, ENTITIES, ACTION_NAME",
            "from rasa.shared.nlu.training_data.features import Features",
            "from rasa.shared.core.trackers import DialogueStateTracker",
            "from rasa.shared.core.domain import State, Domain",
            "from rasa.shared.core.events import Event, ActionExecuted, UserUttered",
            "from rasa.shared.core.constants import (",
            "    USER,",
            "    ACTION_UNLIKELY_INTENT_NAME,",
            "    PREVIOUS_ACTION,",
            ")",
            "from rasa.shared.exceptions import RasaException",
            "from rasa.utils.tensorflow.constants import LABEL_PAD_ID",
            "from rasa.utils.tensorflow.model_data import ragged_array_to_ndarray",
            "",
            "FEATURIZER_FILE = \"featurizer.json\"",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class InvalidStory(RasaException):",
            "    \"\"\"Exception that can be raised if story cannot be featurized.\"\"\"",
            "",
            "    def __init__(self, message: Text) -> None:",
            "        \"\"\"Creates an InvalidStory exception.",
            "",
            "        Args:",
            "          message: a custom exception message.",
            "        \"\"\"",
            "        self.message = message",
            "        super(InvalidStory, self).__init__()",
            "",
            "    def __str__(self) -> Text:",
            "        return self.message",
            "",
            "",
            "class TrackerFeaturizer:",
            "    \"\"\"Base class for actual tracker featurizers.\"\"\"",
            "",
            "    def __init__(",
            "        self, state_featurizer: Optional[SingleStateFeaturizer] = None",
            "    ) -> None:",
            "        \"\"\"Initializes the tracker featurizer.",
            "",
            "        Args:",
            "            state_featurizer: The state featurizer used to encode tracker states.",
            "        \"\"\"",
            "        self.state_featurizer = state_featurizer",
            "",
            "    @staticmethod",
            "    def _create_states(",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "    ) -> List[State]:",
            "        \"\"\"Creates states for the given tracker.",
            "",
            "        Args:",
            "            tracker: The tracker to transform to states.",
            "            domain: The domain of the tracker.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_rule_only_turns: If `True` ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "",
            "        Returns:",
            "            Trackers as states.",
            "        \"\"\"",
            "        return tracker.past_states(",
            "            domain,",
            "            omit_unset_slots=omit_unset_slots,",
            "            ignore_rule_only_turns=ignore_rule_only_turns,",
            "            rule_only_data=rule_only_data,",
            "        )",
            "",
            "    def _featurize_states(",
            "        self,",
            "        trackers_as_states: List[List[State]],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Featurizes state histories with `state_featurizer`.",
            "",
            "        Args:",
            "            trackers_as_states: Lists of states produced by a `DialogueStateTracker`",
            "                instance.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            Featurized tracker states.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            return [[{}]]",
            "        else:",
            "            return [",
            "                [",
            "                    self.state_featurizer.encode_state(state, precomputations)",
            "                    for state in tracker_states",
            "                ]",
            "                for tracker_states in trackers_as_states",
            "            ]",
            "",
            "    @staticmethod",
            "    def _convert_labels_to_ids(",
            "        trackers_as_actions: List[List[Text]], domain: Domain",
            "    ) -> np.ndarray:",
            "        \"\"\"Converts actions to label ids for each tracker.",
            "",
            "        Args:",
            "            trackers_as_actions: A list of tracker labels.",
            "",
            "        Returns:",
            "            Label IDs for each tracker",
            "        \"\"\"",
            "        # store labels in numpy arrays so that it corresponds to np arrays of input",
            "        # features",
            "        return ragged_array_to_ndarray(",
            "            [",
            "                np.array(",
            "                    [domain.index_for_action(action) for action in tracker_actions]",
            "                )",
            "                for tracker_actions in trackers_as_actions",
            "            ]",
            "        )",
            "",
            "    def _create_entity_tags(",
            "        self,",
            "        trackers_as_entities: List[List[Dict[Text, Any]]],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Featurizes extracted entities with `state_featurizer`.",
            "",
            "        Args:",
            "            trackers_as_entities: Extracted entities from trackers.",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: When `True` use the BILOU tagging scheme.",
            "",
            "        Returns:",
            "            Trackers as entity features.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            return [[{}]]",
            "        else:",
            "            return [",
            "                [",
            "                    self.state_featurizer.encode_entities(",
            "                        entity_data, precomputations, bilou_tagging",
            "                    )",
            "                    for entity_data in trackers_entities",
            "                ]",
            "                for trackers_entities in trackers_as_entities",
            "            ]",
            "",
            "    @staticmethod",
            "    def _entity_data(event: UserUttered) -> Dict[Text, Any]:",
            "        \"\"\"Extracts entities from event if not using intents.",
            "",
            "        Args:",
            "            event: The event from which to extract entities.",
            "",
            "        Returns:",
            "            Event text and entities if no intent is present.",
            "        \"\"\"",
            "        # train stories support both text and intent,",
            "        # but if intent is present, the text is ignored",
            "        if event.text and not event.intent_name:",
            "            return {TEXT: event.text, ENTITIES: event.entities}",
            "",
            "        # input is not textual, so add empty dict",
            "        return {}",
            "",
            "    @staticmethod",
            "    def _remove_user_text_if_intent(trackers_as_states: List[List[State]]) -> None:",
            "        \"\"\"Deletes user text from state dictionaries if intent is present.",
            "",
            "        Only featurizing either the intent or user text is currently supported. When",
            "        both are present in a state, the user text is removed so that only the intent",
            "        is featurized.",
            "",
            "        `trackers_as_states` is modified in place.",
            "",
            "        Args:",
            "            trackers_as_states: States produced by a `DialogueStateTracker` instance.",
            "        \"\"\"",
            "        for states in trackers_as_states:",
            "            for state in states:",
            "                # remove text features to only use intent",
            "                if state.get(USER, {}).get(INTENT) and state.get(USER, {}).get(TEXT):",
            "                    del state[USER][TEXT]",
            "",
            "    def training_states_and_labels(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]]]:",
            "        \"\"\"Transforms trackers to states and labels.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states and labels.",
            "        \"\"\"",
            "        (",
            "            trackers_as_states,",
            "            trackers_as_labels,",
            "            _,",
            "        ) = self.training_states_labels_and_entities(",
            "            trackers,",
            "            domain,",
            "            omit_unset_slots=omit_unset_slots,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "        return trackers_as_states, trackers_as_labels",
            "",
            "    @abstractmethod",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            f\"`{self.__class__.__name__}` should implement how to \"",
            "            f\"encode trackers as feature vectors\"",
            "        )",
            "",
            "    def prepare_for_featurization(",
            "        self, domain: Domain, bilou_tagging: bool = False",
            "    ) -> None:",
            "        \"\"\"Ensures that the featurizer is ready to be called during training.",
            "",
            "        State featurizer needs to build its vocabulary from the domain",
            "        for it to be ready to be used during training.",
            "",
            "        Args:",
            "            domain: Domain of the assistant.",
            "            bilou_tagging: Whether to consider bilou tagging.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            raise InvalidTrackerFeaturizerUsageError(",
            "                f\"Instance variable 'state_featurizer' is not set. \"",
            "                f\"During initialization set 'state_featurizer' to an instance of \"",
            "                f\"'{SingleStateFeaturizer.__class__.__name__}' class \"",
            "                f\"to get numerical features for trackers.\"",
            "            )",
            "        self.state_featurizer.prepare_for_training(domain, bilou_tagging)",
            "",
            "    def featurize_trackers(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[",
            "        List[List[Dict[Text, List[Features]]]],",
            "        np.ndarray,",
            "        List[List[Dict[Text, List[Features]]]],",
            "    ]:",
            "        \"\"\"Featurizes the training trackers.",
            "",
            "        Args:",
            "            trackers: list of training trackers",
            "            domain: the domain",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training state features.",
            "",
            "        Returns:",
            "            - a dictionary of state types (INTENT, TEXT, ACTION_NAME, ACTION_TEXT,",
            "              ENTITIES, SLOTS, ACTIVE_LOOP) to a list of features for all dialogue",
            "              turns in all training trackers",
            "            - the label ids (e.g. action ids) for every dialogue turn in all training",
            "              trackers",
            "            - A dictionary of entity type (ENTITY_TAGS) to a list of features",
            "              containing entity tag ids for text user inputs otherwise empty dict",
            "              for all dialogue turns in all training trackers",
            "        \"\"\"",
            "        self.prepare_for_featurization(domain, bilou_tagging)",
            "        (",
            "            trackers_as_states,",
            "            trackers_as_labels,",
            "            trackers_as_entities,",
            "        ) = self.training_states_labels_and_entities(",
            "            trackers,",
            "            domain,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "",
            "        tracker_state_features = self._featurize_states(",
            "            trackers_as_states, precomputations",
            "        )",
            "",
            "        if not tracker_state_features and not trackers_as_labels:",
            "            # If input and output were empty, it means there is",
            "            # no data on which the policy can be trained",
            "            # hence return them as it is. They'll be handled",
            "            # appropriately inside the policy.",
            "            return tracker_state_features, np.ndarray(trackers_as_labels), []",
            "",
            "        label_ids = self._convert_labels_to_ids(trackers_as_labels, domain)",
            "",
            "        entity_tags = self._create_entity_tags(",
            "            trackers_as_entities, precomputations, bilou_tagging",
            "        )",
            "",
            "        return tracker_state_features, label_ids, entity_tags",
            "",
            "    def _choose_last_user_input(",
            "        self, trackers_as_states: List[List[State]], use_text_for_last_user_input: bool",
            "    ) -> None:",
            "        for states in trackers_as_states:",
            "            last_state = states[-1]",
            "            # only update the state of the real user utterance",
            "            if not rasa.shared.core.trackers.is_prev_action_listen_in_state(last_state):",
            "                continue",
            "",
            "            if use_text_for_last_user_input:",
            "                # remove intent features to only use text",
            "                if last_state.get(USER, {}).get(INTENT):",
            "                    del last_state[USER][INTENT]",
            "                # don't add entities if text is used for featurization",
            "                if last_state.get(USER, {}).get(ENTITIES):",
            "                    del last_state[USER][ENTITIES]",
            "            else:",
            "                # remove text features to only use intent",
            "                if last_state.get(USER, {}).get(TEXT):",
            "                    del last_state[USER][TEXT]",
            "",
            "        # make sure that all dialogue steps are either intent or text based",
            "        self._remove_user_text_if_intent(trackers_as_states)",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"Featurizer must have the capacity to create feature vector\"",
            "        )",
            "",
            "    def create_state_features(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Creates state features for prediction.",
            "",
            "        Args:",
            "            trackers: A list of state trackers",
            "            domain: The domain",
            "            precomputations: Contains precomputed features and attributes.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from state features.",
            "",
            "        Returns:",
            "            Dictionaries of state type (INTENT, TEXT, ACTION_NAME, ACTION_TEXT,",
            "            ENTITIES, SLOTS, ACTIVE_LOOP) to a list of features for all dialogue",
            "            turns in all trackers.",
            "        \"\"\"",
            "        trackers_as_states = self.prediction_states(",
            "            trackers,",
            "            domain,",
            "            use_text_for_last_user_input,",
            "            ignore_rule_only_turns,",
            "            rule_only_data,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "        return self._featurize_states(trackers_as_states, precomputations)",
            "",
            "    def persist(self, path: Union[Text, Path]) -> None:",
            "        \"\"\"Persists the tracker featurizer to the given path.",
            "",
            "        Args:",
            "            path: The path to persist the tracker featurizer to.",
            "        \"\"\"",
            "        featurizer_file = Path(path) / FEATURIZER_FILE",
            "        rasa.shared.utils.io.create_directory_for_file(featurizer_file)",
            "",
            "        # entity tags are persisted in TED policy, they are not needed for prediction",
            "        if self.state_featurizer is not None:",
            "            self.state_featurizer.entity_tag_specs = []",
            "",
            "        # noinspection PyTypeChecker",
            "        rasa.shared.utils.io.write_text_file(",
            "            str(jsonpickle.encode(self)), featurizer_file",
            "        )",
            "",
            "    @staticmethod",
            "    def load(path: Union[Text, Path]) -> Optional[TrackerFeaturizer]:",
            "        \"\"\"Loads the featurizer from file.",
            "",
            "        Args:",
            "            path: The path to load the tracker featurizer from.",
            "",
            "        Returns:",
            "            The loaded tracker featurizer.",
            "        \"\"\"",
            "        featurizer_file = Path(path) / FEATURIZER_FILE",
            "        if featurizer_file.is_file():",
            "            return jsonpickle.decode(rasa.shared.utils.io.read_file(featurizer_file))",
            "",
            "        logger.error(",
            "            f\"Couldn't load featurizer for policy. \"",
            "            f\"File '{featurizer_file}' doesn't exist.\"",
            "        )",
            "        return None",
            "",
            "    @staticmethod",
            "    def _remove_action_unlikely_intent_from_states(states: List[State]) -> List[State]:",
            "        return [",
            "            state",
            "            for state in states",
            "            if not _is_prev_action_unlikely_intent_in_state(state)",
            "        ]",
            "",
            "    @staticmethod",
            "    def _remove_action_unlikely_intent_from_events(events: List[Event]) -> List[Event]:",
            "        return [",
            "            event",
            "            for event in events",
            "            if (",
            "                not isinstance(event, ActionExecuted)",
            "                or event.action_name != ACTION_UNLIKELY_INTENT_NAME",
            "            )",
            "        ]",
            "",
            "",
            "class FullDialogueTrackerFeaturizer(TrackerFeaturizer):",
            "    \"\"\"Creates full dialogue training data for time distributed architectures.",
            "",
            "    Creates training data that uses each time output for prediction.",
            "    \"\"\"",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, action labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, action labels, and entity data.",
            "        \"\"\"",
            "        trackers_as_states = []",
            "        trackers_as_actions = []",
            "        trackers_as_entities = []",
            "",
            "        logger.debug(",
            "            \"Creating states and action examples from \"",
            "            \"collected trackers (by {}({}))...\"",
            "            \"\".format(type(self).__name__, type(self.state_featurizer).__name__)",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "            states = self._create_states(",
            "                tracker, domain, omit_unset_slots=omit_unset_slots",
            "            )",
            "            events = tracker.applied_events()",
            "",
            "            if ignore_action_unlikely_intent:",
            "                states = self._remove_action_unlikely_intent_from_states(states)",
            "                events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "            delete_first_state = False",
            "            actions = []",
            "            entities = []",
            "            entity_data = {}",
            "            for event in events:",
            "                if isinstance(event, UserUttered):",
            "                    entity_data = self._entity_data(event)",
            "",
            "                if not isinstance(event, ActionExecuted):",
            "                    continue",
            "",
            "                if not event.unpredictable:",
            "                    # only actions which can be",
            "                    # predicted at a stories start",
            "                    action = event.action_name or event.action_text",
            "                    if action is not None:",
            "                        actions.append(action)",
            "                    entities.append(entity_data)",
            "                else:",
            "                    # unpredictable actions can be",
            "                    # only the first in the story",
            "                    if delete_first_state:",
            "                        raise InvalidStory(",
            "                            f\"Found two unpredictable actions in one story \"",
            "                            f\"'{tracker.sender_id}'. Check your story files.\"",
            "                        )",
            "                    delete_first_state = True",
            "",
            "                # reset entity_data for the the next turn",
            "                entity_data = {}",
            "",
            "            if delete_first_state:",
            "                states = states[1:]",
            "",
            "            trackers_as_states.append(states[:-1])",
            "            trackers_as_actions.append(actions)",
            "            trackers_as_entities.append(entities)",
            "",
            "        self._remove_user_text_if_intent(trackers_as_states)",
            "",
            "        return trackers_as_states, trackers_as_actions, trackers_as_entities",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        return trackers_as_states",
            "",
            "",
            "class MaxHistoryTrackerFeaturizer(TrackerFeaturizer):",
            "    \"\"\"Truncates the tracker history into `max_history` long sequences.",
            "",
            "    Creates training data from trackers where actions are the output prediction",
            "    labels. Tracker state sequences which represent policy input are truncated",
            "    to not excede `max_history` states.",
            "    \"\"\"",
            "",
            "    LABEL_NAME = \"action\"",
            "",
            "    def __init__(",
            "        self,",
            "        state_featurizer: Optional[SingleStateFeaturizer] = None,",
            "        max_history: Optional[int] = None,",
            "        remove_duplicates: bool = True,",
            "    ) -> None:",
            "        \"\"\"Initializes the tracker featurizer.",
            "",
            "        Args:",
            "            state_featurizer: The state featurizer used to encode the states.",
            "            max_history: The maximum length of an extracted state sequence.",
            "            remove_duplicates: Keep only unique training state sequence/label pairs.",
            "        \"\"\"",
            "        super().__init__(state_featurizer)",
            "        self.max_history = max_history",
            "        self.remove_duplicates = remove_duplicates",
            "",
            "    @staticmethod",
            "    def slice_state_history(",
            "        states: List[State], slice_length: Optional[int]",
            "    ) -> List[State]:",
            "        \"\"\"Slices states from the trackers history.",
            "",
            "        Args:",
            "            states: The states",
            "            slice_length: The slice length",
            "",
            "        Returns:",
            "            The sliced states.",
            "        \"\"\"",
            "        if not slice_length:",
            "            return states",
            "",
            "        return states[-slice_length:]",
            "",
            "    @staticmethod",
            "    def _hash_example(states: List[State], labels: Optional[List[Text]] = None) -> int:",
            "        \"\"\"Hashes states (and optionally label).",
            "",
            "        Produces a hash of the tracker state sequence (and optionally the labels).",
            "        If `labels` is `None`, labels don't get hashed.",
            "",
            "        Args:",
            "            states: The tracker state sequence to hash.",
            "            labels: Label strings associated with this state sequence.",
            "",
            "        Returns:",
            "            The hash of the states and (optionally) the label.",
            "        \"\"\"",
            "        frozen_states = tuple(",
            "            s if s is None else DialogueStateTracker.freeze_current_state(s)",
            "            for s in states",
            "        )",
            "        if labels is not None:",
            "            frozen_labels = tuple(labels)",
            "            return hash((frozen_states, frozen_labels))",
            "        else:",
            "            return hash(frozen_states)",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, action labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        example_states = []",
            "        example_labels = []",
            "        example_entities = []",
            "",
            "        # Store of example hashes for removing duplicate training examples.",
            "        hashed_examples = set()",
            "",
            "        logger.debug(",
            "            f\"Creating states and {self.LABEL_NAME} label examples from \"",
            "            f\"collected trackers \"",
            "            f\"(by {type(self).__name__}({type(self.state_featurizer).__name__}))...\"",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "",
            "            for states, label, entities in self._extract_examples(",
            "                tracker,",
            "                domain,",
            "                omit_unset_slots=omit_unset_slots,",
            "                ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "            ):",
            "",
            "                if self.remove_duplicates:",
            "                    hashed = self._hash_example(states, label)",
            "                    if hashed in hashed_examples:",
            "                        continue",
            "                    hashed_examples.add(hashed)",
            "",
            "                example_states.append(states)",
            "                example_labels.append(label)",
            "                example_entities.append(entities)",
            "",
            "                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_labels):d}\"})",
            "",
            "        self._remove_user_text_if_intent(example_states)",
            "",
            "        logger.debug(f\"Created {len(example_states)} {self.LABEL_NAME} examples.\")",
            "",
            "        return example_states, example_labels, example_entities",
            "",
            "    def _extract_examples(",
            "        self,",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Iterator[Tuple[List[State], List[Text], List[Dict[Text, Any]]]]:",
            "        \"\"\"Creates an iterator over training examples from a tracker.",
            "",
            "        Args:",
            "            trackers: The tracker from which to extract training examples.",
            "            domain: The domain of the training data.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            An iterator over example states, labels, and entity data.",
            "        \"\"\"",
            "        tracker_states = self._create_states(",
            "            tracker, domain, omit_unset_slots=omit_unset_slots",
            "        )",
            "        events = tracker.applied_events()",
            "",
            "        if ignore_action_unlikely_intent:",
            "            tracker_states = self._remove_action_unlikely_intent_from_states(",
            "                tracker_states",
            "            )",
            "            events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "        label_index = 0",
            "        entity_data = {}",
            "        for event in events:",
            "            if isinstance(event, UserUttered):",
            "                entity_data = self._entity_data(event)",
            "",
            "            elif isinstance(event, ActionExecuted):",
            "",
            "                label_index += 1",
            "",
            "                # use only actions which can be predicted at a stories start",
            "                if event.unpredictable:",
            "                    continue",
            "",
            "                sliced_states = self.slice_state_history(",
            "                    tracker_states[:label_index], self.max_history",
            "                )",
            "                label = cast(List[Text], [event.action_name or event.action_text])",
            "                entities = [entity_data]",
            "",
            "                yield sliced_states, label, entities",
            "",
            "                # reset entity_data for the the next turn",
            "                entity_data = {}",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        # Remove `action_unlikely_intent` from `trackers_as_states`.",
            "        # This must be done before state history slicing to ensure the",
            "        # max history of the sliced states matches training time.",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        trackers_as_states = [",
            "            self.slice_state_history(states, self.max_history)",
            "            for states in trackers_as_states",
            "        ]",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        return trackers_as_states",
            "",
            "",
            "class IntentMaxHistoryTrackerFeaturizer(MaxHistoryTrackerFeaturizer):",
            "    \"\"\"Truncates the tracker history into `max_history` long sequences.",
            "",
            "    Creates training data from trackers where intents are the output prediction",
            "    labels. Tracker state sequences which represent policy input are truncated",
            "    to not excede `max_history` states.",
            "    \"\"\"",
            "",
            "    LABEL_NAME = \"intent\"",
            "",
            "    @classmethod",
            "    def _convert_labels_to_ids(",
            "        cls, trackers_as_intents: List[List[Text]], domain: Domain",
            "    ) -> np.ndarray:",
            "        \"\"\"Converts a list of labels to a matrix of label ids.",
            "",
            "        The number of rows is equal to `len(trackers_as_intents)`. The number of",
            "        columns is equal to the maximum number of positive labels that any training",
            "        example is associated with. Rows are padded with `LABEL_PAD_ID` if not all rows",
            "        have the same number of labels.",
            "",
            "        Args:",
            "            trackers_as_intents: Positive example label ids",
            "                associated with each training example.",
            "            domain: The domain of the training data.",
            "",
            "        Returns:",
            "           A matrix of label ids.",
            "        \"\"\"",
            "        # store labels in numpy arrays so that it corresponds to np arrays",
            "        # of input features",
            "        label_ids = [",
            "            [domain.intents.index(intent) for intent in tracker_intents]",
            "            for tracker_intents in trackers_as_intents",
            "        ]",
            "",
            "        return np.array(cls._pad_label_ids(label_ids))",
            "",
            "    @staticmethod",
            "    def _pad_label_ids(label_ids: List[List[int]]) -> List[List[int]]:",
            "        \"\"\"Pads label ids so that all are of the same length.",
            "",
            "        Args:",
            "            label_ids: Label ids of varying lengths",
            "",
            "        Returns:",
            "            Label ids padded to be of uniform length.",
            "        \"\"\"",
            "        # If `label_ids` is an empty list, no padding needs to be added.",
            "        if not label_ids:",
            "            return label_ids",
            "",
            "        # Add `LABEL_PAD_ID` padding to labels array so that",
            "        # each example has equal number of labels",
            "        multiple_labels_count = [len(a) for a in label_ids]",
            "        max_labels_count = max(multiple_labels_count)",
            "        num_padding_needed = [max_labels_count - len(a) for a in label_ids]",
            "",
            "        padded_label_ids = []",
            "        for ids, num_pads in zip(label_ids, num_padding_needed):",
            "            padded_row = list(ids) + [LABEL_PAD_ID] * num_pads",
            "            padded_label_ids.append(padded_row)",
            "        return padded_label_ids",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, intent labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        example_states = []",
            "        example_entities = []",
            "",
            "        # Store of example hashes (of both states and labels) for removing",
            "        # duplicate training examples.",
            "        hashed_examples = set()",
            "        # Mapping of example state hash to set of",
            "        # positive labels associated with the state.",
            "        state_hash_to_label_set: DefaultDict[int, Set[Text]] = defaultdict(set)",
            "",
            "        logger.debug(",
            "            f\"Creating states and {self.LABEL_NAME} label examples from \"",
            "            f\"collected trackers \"",
            "            f\"(by {type(self).__name__}({type(self.state_featurizer).__name__}))...\"",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "",
            "            for states, label, entities in self._extract_examples(",
            "                tracker,",
            "                domain,",
            "                omit_unset_slots=omit_unset_slots,",
            "                ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "            ):",
            "",
            "                if self.remove_duplicates:",
            "                    hashed = self._hash_example(states, label)",
            "                    if hashed in hashed_examples:",
            "                        continue",
            "                    hashed_examples.add(hashed)",
            "",
            "                # Store all positive labels associated with a training state.",
            "                state_hash = self._hash_example(states)",
            "",
            "                # Only add unique example states unless `remove_duplicates` is `False`.",
            "                if (",
            "                    not self.remove_duplicates",
            "                    or state_hash not in state_hash_to_label_set",
            "                ):",
            "                    example_states.append(states)",
            "                    example_entities.append(entities)",
            "",
            "                state_hash_to_label_set[state_hash].add(label[0])",
            "",
            "                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_states):d}\"})",
            "",
            "        # Collect positive labels for each state example.",
            "        example_labels = [",
            "            list(state_hash_to_label_set[self._hash_example(state)])",
            "            for state in example_states",
            "        ]",
            "",
            "        self._remove_user_text_if_intent(example_states)",
            "",
            "        logger.debug(f\"Created {len(example_states)} {self.LABEL_NAME} examples.\")",
            "",
            "        return example_states, example_labels, example_entities",
            "",
            "    def _extract_examples(",
            "        self,",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Iterator[Tuple[List[State], List[Text], List[Dict[Text, Any]]]]:",
            "        \"\"\"Creates an iterator over training examples from a tracker.",
            "",
            "        Args:",
            "            tracker: The tracker from which to extract training examples.",
            "            domain: The domain of the training data.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            An iterator over example states, labels, and entity data.",
            "        \"\"\"",
            "        tracker_states = self._create_states(",
            "            tracker, domain, omit_unset_slots=omit_unset_slots",
            "        )",
            "        events = tracker.applied_events()",
            "",
            "        if ignore_action_unlikely_intent:",
            "            tracker_states = self._remove_action_unlikely_intent_from_states(",
            "                tracker_states",
            "            )",
            "            events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "        label_index = 0",
            "        for event in events:",
            "",
            "            if isinstance(event, ActionExecuted):",
            "                label_index += 1",
            "",
            "            elif isinstance(event, UserUttered):",
            "",
            "                sliced_states = self.slice_state_history(",
            "                    tracker_states[:label_index], self.max_history",
            "                )",
            "                label = cast(List[Text], [event.intent_name or event.text])",
            "                entities: List[Dict[Text, Any]] = [{}]",
            "",
            "                yield sliced_states, label, entities",
            "",
            "    @staticmethod",
            "    def _cleanup_last_user_state_with_action_listen(",
            "        trackers_as_states: List[List[State]],",
            "    ) -> List[List[State]]:",
            "        \"\"\"Removes the last tracker state if the previous action is `action_listen`.",
            "",
            "        States with the previous action equal to `action_listen` correspond to states",
            "        with a new user intent. This information is what `UnexpecTEDIntentPolicy` is",
            "        trying to predict so it needs to be removed before obtaining a prediction.",
            "",
            "        Args:",
            "            trackers_as_states: Trackers converted to states",
            "",
            "        Returns:",
            "            Filtered states with last `action_listen` removed.",
            "        \"\"\"",
            "        for states in trackers_as_states:",
            "            if not states:",
            "                continue",
            "            last_state = states[-1]",
            "            if rasa.shared.core.trackers.is_prev_action_listen_in_state(last_state):",
            "                del states[-1]",
            "",
            "        return trackers_as_states",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        # Remove `action_unlikely_intent` from `trackers_as_states`.",
            "        # This must be done before state history slicing to ensure the",
            "        # max history of the sliced states matches training time.",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        # `tracker_as_states` contain a state with intent = last intent",
            "        # and previous action = action_listen. This state needs to be",
            "        # removed as it was not present during training as well because",
            "        # predicting the last intent is what the policies using this",
            "        # featurizer do. This is specifically done before state history",
            "        # is sliced so that the number of past states is same as `max_history`.",
            "        self._cleanup_last_user_state_with_action_listen(trackers_as_states)",
            "",
            "        trackers_as_states = [",
            "            self.slice_state_history(states, self.max_history)",
            "            for states in trackers_as_states",
            "        ]",
            "",
            "        return trackers_as_states",
            "",
            "",
            "def _is_prev_action_unlikely_intent_in_state(state: State) -> bool:",
            "    prev_action_name = state.get(PREVIOUS_ACTION, {}).get(ACTION_NAME)",
            "    return prev_action_name == ACTION_UNLIKELY_INTENT_NAME"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import logging",
            "from abc import abstractmethod",
            "from collections import defaultdict",
            "from pathlib import Path",
            "from typing import (",
            "    Tuple,",
            "    List,",
            "    Optional,",
            "    Dict,",
            "    Text,",
            "    Union,",
            "    Any,",
            "    Iterator,",
            "    Set,",
            "    DefaultDict,",
            "    cast,",
            "    Type,",
            "    Callable,",
            "    ClassVar,",
            ")",
            "",
            "import numpy as np",
            "from tqdm import tqdm",
            "",
            "import rasa.shared.core.trackers",
            "import rasa.shared.utils.io",
            "from rasa.core.exceptions import InvalidTrackerFeaturizerUsageError",
            "from rasa.core.featurizers.precomputation import MessageContainerForCoreFeaturization",
            "from rasa.core.featurizers.single_state_featurizer import SingleStateFeaturizer",
            "from rasa.shared.core.constants import (",
            "    USER,",
            "    ACTION_UNLIKELY_INTENT_NAME,",
            "    PREVIOUS_ACTION,",
            ")",
            "from rasa.shared.core.domain import State, Domain",
            "from rasa.shared.core.events import Event, ActionExecuted, UserUttered",
            "from rasa.shared.core.trackers import DialogueStateTracker",
            "from rasa.shared.exceptions import RasaException",
            "from rasa.shared.nlu.constants import TEXT, INTENT, ENTITIES, ACTION_NAME",
            "from rasa.shared.nlu.training_data.features import Features",
            "from rasa.utils.tensorflow.constants import LABEL_PAD_ID",
            "from rasa.utils.tensorflow.model_data import ragged_array_to_ndarray",
            "",
            "FEATURIZER_FILE = \"featurizer.json\"",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class InvalidStory(RasaException):",
            "    \"\"\"Exception that can be raised if story cannot be featurized.\"\"\"",
            "",
            "    def __init__(self, message: Text) -> None:",
            "        \"\"\"Creates an InvalidStory exception.",
            "",
            "        Args:",
            "          message: a custom exception message.",
            "        \"\"\"",
            "        self.message = message",
            "        super(InvalidStory, self).__init__()",
            "",
            "    def __str__(self) -> Text:",
            "        return self.message",
            "",
            "",
            "class TrackerFeaturizer:",
            "    \"\"\"Base class for actual tracker featurizers.\"\"\"",
            "",
            "    # Class registry to store all subclasses",
            "    _registry: ClassVar[Dict[str, Type[\"TrackerFeaturizer\"]]] = {}",
            "    _featurizer_type: str = \"TrackerFeaturizer\"",
            "",
            "    def __init__(",
            "        self, state_featurizer: Optional[SingleStateFeaturizer] = None",
            "    ) -> None:",
            "        \"\"\"Initializes the tracker featurizer.",
            "",
            "        Args:",
            "            state_featurizer: The state featurizer used to encode tracker states.",
            "        \"\"\"",
            "        self.state_featurizer = state_featurizer",
            "",
            "    @classmethod",
            "    def register(cls, featurizer_type: str) -> Callable:",
            "        \"\"\"Decorator to register featurizer subclasses.\"\"\"",
            "",
            "        def wrapper(subclass: Type[\"TrackerFeaturizer\"]) -> Type[\"TrackerFeaturizer\"]:",
            "            cls._registry[featurizer_type] = subclass",
            "            # Store the type identifier in the class for serialization",
            "            subclass._featurizer_type = featurizer_type",
            "            return subclass",
            "",
            "        return wrapper",
            "",
            "    @classmethod",
            "    def from_dict(cls, data: Dict[str, Any]) -> \"TrackerFeaturizer\":",
            "        \"\"\"Create featurizer instance from dictionary.\"\"\"",
            "        featurizer_type = data.pop(\"type\")",
            "",
            "        if featurizer_type not in cls._registry:",
            "            raise ValueError(f\"Unknown featurizer type: {featurizer_type}\")",
            "",
            "        # Get the correct subclass and instantiate it",
            "        subclass = cls._registry[featurizer_type]",
            "        return subclass.create_from_dict(data)",
            "",
            "    @classmethod",
            "    @abstractmethod",
            "    def create_from_dict(cls, data: Dict[str, Any]) -> \"TrackerFeaturizer\":",
            "        \"\"\"Each subclass must implement its own creation from dict method.\"\"\"",
            "        pass",
            "",
            "    @staticmethod",
            "    def _create_states(",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "    ) -> List[State]:",
            "        \"\"\"Creates states for the given tracker.",
            "",
            "        Args:",
            "            tracker: The tracker to transform to states.",
            "            domain: The domain of the tracker.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_rule_only_turns: If `True` ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "",
            "        Returns:",
            "            Trackers as states.",
            "        \"\"\"",
            "        return tracker.past_states(",
            "            domain,",
            "            omit_unset_slots=omit_unset_slots,",
            "            ignore_rule_only_turns=ignore_rule_only_turns,",
            "            rule_only_data=rule_only_data,",
            "        )",
            "",
            "    def _featurize_states(",
            "        self,",
            "        trackers_as_states: List[List[State]],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Featurizes state histories with `state_featurizer`.",
            "",
            "        Args:",
            "            trackers_as_states: Lists of states produced by a `DialogueStateTracker`",
            "                instance.",
            "            precomputations: Contains precomputed features and attributes.",
            "",
            "        Returns:",
            "            Featurized tracker states.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            return [[{}]]",
            "        else:",
            "            return [",
            "                [",
            "                    self.state_featurizer.encode_state(state, precomputations)",
            "                    for state in tracker_states",
            "                ]",
            "                for tracker_states in trackers_as_states",
            "            ]",
            "",
            "    @staticmethod",
            "    def _convert_labels_to_ids(",
            "        trackers_as_actions: List[List[Text]], domain: Domain",
            "    ) -> np.ndarray:",
            "        \"\"\"Converts actions to label ids for each tracker.",
            "",
            "        Args:",
            "            trackers_as_actions: A list of tracker labels.",
            "",
            "        Returns:",
            "            Label IDs for each tracker",
            "        \"\"\"",
            "        # store labels in numpy arrays so that it corresponds to np arrays of input",
            "        # features",
            "        return ragged_array_to_ndarray(",
            "            [",
            "                np.array(",
            "                    [domain.index_for_action(action) for action in tracker_actions]",
            "                )",
            "                for tracker_actions in trackers_as_actions",
            "            ]",
            "        )",
            "",
            "    def _create_entity_tags(",
            "        self,",
            "        trackers_as_entities: List[List[Dict[Text, Any]]],",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Featurizes extracted entities with `state_featurizer`.",
            "",
            "        Args:",
            "            trackers_as_entities: Extracted entities from trackers.",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: When `True` use the BILOU tagging scheme.",
            "",
            "        Returns:",
            "            Trackers as entity features.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            return [[{}]]",
            "        else:",
            "            return [",
            "                [",
            "                    self.state_featurizer.encode_entities(",
            "                        entity_data, precomputations, bilou_tagging",
            "                    )",
            "                    for entity_data in trackers_entities",
            "                ]",
            "                for trackers_entities in trackers_as_entities",
            "            ]",
            "",
            "    @staticmethod",
            "    def _entity_data(event: UserUttered) -> Dict[Text, Any]:",
            "        \"\"\"Extracts entities from event if not using intents.",
            "",
            "        Args:",
            "            event: The event from which to extract entities.",
            "",
            "        Returns:",
            "            Event text and entities if no intent is present.",
            "        \"\"\"",
            "        # train stories support both text and intent,",
            "        # but if intent is present, the text is ignored",
            "        if event.text and not event.intent_name:",
            "            return {TEXT: event.text, ENTITIES: event.entities}",
            "",
            "        # input is not textual, so add empty dict",
            "        return {}",
            "",
            "    @staticmethod",
            "    def _remove_user_text_if_intent(trackers_as_states: List[List[State]]) -> None:",
            "        \"\"\"Deletes user text from state dictionaries if intent is present.",
            "",
            "        Only featurizing either the intent or user text is currently supported. When",
            "        both are present in a state, the user text is removed so that only the intent",
            "        is featurized.",
            "",
            "        `trackers_as_states` is modified in place.",
            "",
            "        Args:",
            "            trackers_as_states: States produced by a `DialogueStateTracker` instance.",
            "        \"\"\"",
            "        for states in trackers_as_states:",
            "            for state in states:",
            "                # remove text features to only use intent",
            "                if state.get(USER, {}).get(INTENT) and state.get(USER, {}).get(TEXT):",
            "                    del state[USER][TEXT]",
            "",
            "    def training_states_and_labels(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]]]:",
            "        \"\"\"Transforms trackers to states and labels.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states and labels.",
            "        \"\"\"",
            "        (",
            "            trackers_as_states,",
            "            trackers_as_labels,",
            "            _,",
            "        ) = self.training_states_labels_and_entities(",
            "            trackers,",
            "            domain,",
            "            omit_unset_slots=omit_unset_slots,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "        return trackers_as_states, trackers_as_labels",
            "",
            "    @abstractmethod",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            f\"`{self.__class__.__name__}` should implement how to \"",
            "            f\"encode trackers as feature vectors\"",
            "        )",
            "",
            "    def prepare_for_featurization(",
            "        self, domain: Domain, bilou_tagging: bool = False",
            "    ) -> None:",
            "        \"\"\"Ensures that the featurizer is ready to be called during training.",
            "",
            "        State featurizer needs to build its vocabulary from the domain",
            "        for it to be ready to be used during training.",
            "",
            "        Args:",
            "            domain: Domain of the assistant.",
            "            bilou_tagging: Whether to consider bilou tagging.",
            "        \"\"\"",
            "        if self.state_featurizer is None:",
            "            raise InvalidTrackerFeaturizerUsageError(",
            "                f\"Instance variable 'state_featurizer' is not set. \"",
            "                f\"During initialization set 'state_featurizer' to an instance of \"",
            "                f\"'{SingleStateFeaturizer.__class__.__name__}' class \"",
            "                f\"to get numerical features for trackers.\"",
            "            )",
            "        self.state_featurizer.prepare_for_training(domain, bilou_tagging)",
            "",
            "    def featurize_trackers(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        bilou_tagging: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[",
            "        List[List[Dict[Text, List[Features]]]],",
            "        np.ndarray,",
            "        List[List[Dict[Text, List[Features]]]],",
            "    ]:",
            "        \"\"\"Featurizes the training trackers.",
            "",
            "        Args:",
            "            trackers: list of training trackers",
            "            domain: the domain",
            "            precomputations: Contains precomputed features and attributes.",
            "            bilou_tagging: indicates whether BILOU tagging should be used or not",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training state features.",
            "",
            "        Returns:",
            "            - a dictionary of state types (INTENT, TEXT, ACTION_NAME, ACTION_TEXT,",
            "              ENTITIES, SLOTS, ACTIVE_LOOP) to a list of features for all dialogue",
            "              turns in all training trackers",
            "            - the label ids (e.g. action ids) for every dialogue turn in all training",
            "              trackers",
            "            - A dictionary of entity type (ENTITY_TAGS) to a list of features",
            "              containing entity tag ids for text user inputs otherwise empty dict",
            "              for all dialogue turns in all training trackers",
            "        \"\"\"",
            "        self.prepare_for_featurization(domain, bilou_tagging)",
            "        (",
            "            trackers_as_states,",
            "            trackers_as_labels,",
            "            trackers_as_entities,",
            "        ) = self.training_states_labels_and_entities(",
            "            trackers,",
            "            domain,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "",
            "        tracker_state_features = self._featurize_states(",
            "            trackers_as_states, precomputations",
            "        )",
            "",
            "        if not tracker_state_features and not trackers_as_labels:",
            "            # If input and output were empty, it means there is",
            "            # no data on which the policy can be trained",
            "            # hence return them as it is. They'll be handled",
            "            # appropriately inside the policy.",
            "            return tracker_state_features, np.ndarray(trackers_as_labels), []",
            "",
            "        label_ids = self._convert_labels_to_ids(trackers_as_labels, domain)",
            "",
            "        entity_tags = self._create_entity_tags(",
            "            trackers_as_entities, precomputations, bilou_tagging",
            "        )",
            "",
            "        return tracker_state_features, label_ids, entity_tags",
            "",
            "    def _choose_last_user_input(",
            "        self, trackers_as_states: List[List[State]], use_text_for_last_user_input: bool",
            "    ) -> None:",
            "        for states in trackers_as_states:",
            "            last_state = states[-1]",
            "            # only update the state of the real user utterance",
            "            if not rasa.shared.core.trackers.is_prev_action_listen_in_state(last_state):",
            "                continue",
            "",
            "            if use_text_for_last_user_input:",
            "                # remove intent features to only use text",
            "                if last_state.get(USER, {}).get(INTENT):",
            "                    del last_state[USER][INTENT]",
            "                # don't add entities if text is used for featurization",
            "                if last_state.get(USER, {}).get(ENTITIES):",
            "                    del last_state[USER][ENTITIES]",
            "            else:",
            "                # remove text features to only use intent",
            "                if last_state.get(USER, {}).get(TEXT):",
            "                    del last_state[USER][TEXT]",
            "",
            "        # make sure that all dialogue steps are either intent or text based",
            "        self._remove_user_text_if_intent(trackers_as_states)",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"Featurizer must have the capacity to create feature vector\"",
            "        )",
            "",
            "    def create_state_features(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        precomputations: Optional[MessageContainerForCoreFeaturization],",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[Dict[Text, List[Features]]]]:",
            "        \"\"\"Creates state features for prediction.",
            "",
            "        Args:",
            "            trackers: A list of state trackers",
            "            domain: The domain",
            "            precomputations: Contains precomputed features and attributes.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from state features.",
            "",
            "        Returns:",
            "            Dictionaries of state type (INTENT, TEXT, ACTION_NAME, ACTION_TEXT,",
            "            ENTITIES, SLOTS, ACTIVE_LOOP) to a list of features for all dialogue",
            "            turns in all trackers.",
            "        \"\"\"",
            "        trackers_as_states = self.prediction_states(",
            "            trackers,",
            "            domain,",
            "            use_text_for_last_user_input,",
            "            ignore_rule_only_turns,",
            "            rule_only_data,",
            "            ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "        )",
            "        return self._featurize_states(trackers_as_states, precomputations)",
            "",
            "    def persist(self, path: Union[Text, Path]) -> None:",
            "        \"\"\"Persists the tracker featurizer to the given path.",
            "",
            "        Args:",
            "            path: The path to persist the tracker featurizer to.",
            "        \"\"\"",
            "        featurizer_file = Path(path) / FEATURIZER_FILE",
            "        rasa.shared.utils.io.create_directory_for_file(featurizer_file)",
            "",
            "        # entity tags are persisted in TED policy, they are not needed for prediction",
            "        if self.state_featurizer is not None:",
            "            self.state_featurizer.entity_tag_specs = []",
            "",
            "        # noinspection PyTypeChecker",
            "        rasa.shared.utils.io.dump_obj_as_json_to_file(featurizer_file, self.to_dict())",
            "",
            "    @staticmethod",
            "    def load(path: Union[Text, Path]) -> Optional[TrackerFeaturizer]:",
            "        \"\"\"Loads the featurizer from file.",
            "",
            "        Args:",
            "            path: The path to load the tracker featurizer from.",
            "",
            "        Returns:",
            "            The loaded tracker featurizer.",
            "        \"\"\"",
            "        featurizer_file = Path(path) / FEATURIZER_FILE",
            "        if featurizer_file.is_file():",
            "            data = rasa.shared.utils.io.read_json_file(featurizer_file)",
            "",
            "            if \"type\" not in data:",
            "                logger.error(",
            "                    f\"Couldn't load featurizer for policy. \"",
            "                    f\"File '{featurizer_file}' does not contain all \"",
            "                    f\"necessary information. 'type' is missing.\"",
            "                )",
            "                return None",
            "",
            "            return TrackerFeaturizer.from_dict(data)",
            "",
            "        logger.error(",
            "            f\"Couldn't load featurizer for policy. \"",
            "            f\"File '{featurizer_file}' doesn't exist.\"",
            "        )",
            "        return None",
            "",
            "    @staticmethod",
            "    def _remove_action_unlikely_intent_from_states(states: List[State]) -> List[State]:",
            "        return [",
            "            state",
            "            for state in states",
            "            if not _is_prev_action_unlikely_intent_in_state(state)",
            "        ]",
            "",
            "    @staticmethod",
            "    def _remove_action_unlikely_intent_from_events(events: List[Event]) -> List[Event]:",
            "        return [",
            "            event",
            "            for event in events",
            "            if (",
            "                not isinstance(event, ActionExecuted)",
            "                or event.action_name != ACTION_UNLIKELY_INTENT_NAME",
            "            )",
            "        ]",
            "",
            "    def to_dict(self) -> Dict[str, Any]:",
            "        return {",
            "            \"type\": self.__class__._featurizer_type,",
            "            \"state_featurizer\": (",
            "                self.state_featurizer.to_dict() if self.state_featurizer else None",
            "            ),",
            "        }",
            "",
            "",
            "@TrackerFeaturizer.register(\"FullDialogueTrackerFeaturizer\")",
            "class FullDialogueTrackerFeaturizer(TrackerFeaturizer):",
            "    \"\"\"Creates full dialogue training data for time distributed architectures.",
            "",
            "    Creates training data that uses each time output for prediction.",
            "    \"\"\"",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, action labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, action labels, and entity data.",
            "        \"\"\"",
            "        trackers_as_states = []",
            "        trackers_as_actions = []",
            "        trackers_as_entities = []",
            "",
            "        logger.debug(",
            "            \"Creating states and action examples from \"",
            "            \"collected trackers (by {}({}))...\"",
            "            \"\".format(type(self).__name__, type(self.state_featurizer).__name__)",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "            states = self._create_states(",
            "                tracker, domain, omit_unset_slots=omit_unset_slots",
            "            )",
            "            events = tracker.applied_events()",
            "",
            "            if ignore_action_unlikely_intent:",
            "                states = self._remove_action_unlikely_intent_from_states(states)",
            "                events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "            delete_first_state = False",
            "            actions = []",
            "            entities = []",
            "            entity_data = {}",
            "            for event in events:",
            "                if isinstance(event, UserUttered):",
            "                    entity_data = self._entity_data(event)",
            "",
            "                if not isinstance(event, ActionExecuted):",
            "                    continue",
            "",
            "                if not event.unpredictable:",
            "                    # only actions which can be",
            "                    # predicted at a stories start",
            "                    action = event.action_name or event.action_text",
            "                    if action is not None:",
            "                        actions.append(action)",
            "                    entities.append(entity_data)",
            "                else:",
            "                    # unpredictable actions can be",
            "                    # only the first in the story",
            "                    if delete_first_state:",
            "                        raise InvalidStory(",
            "                            f\"Found two unpredictable actions in one story \"",
            "                            f\"'{tracker.sender_id}'. Check your story files.\"",
            "                        )",
            "                    delete_first_state = True",
            "",
            "                # reset entity_data for the the next turn",
            "                entity_data = {}",
            "",
            "            if delete_first_state:",
            "                states = states[1:]",
            "",
            "            trackers_as_states.append(states[:-1])",
            "            trackers_as_actions.append(actions)",
            "            trackers_as_entities.append(entities)",
            "",
            "        self._remove_user_text_if_intent(trackers_as_states)",
            "",
            "        return trackers_as_states, trackers_as_actions, trackers_as_entities",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        return trackers_as_states",
            "",
            "    def to_dict(self) -> Dict[str, Any]:",
            "        return super().to_dict()",
            "",
            "    @classmethod",
            "    def create_from_dict(cls, data: Dict[str, Any]) -> \"FullDialogueTrackerFeaturizer\":",
            "        state_featurizer = SingleStateFeaturizer.create_from_dict(",
            "            data[\"state_featurizer\"]",
            "        )",
            "        return cls(",
            "            state_featurizer,",
            "        )",
            "",
            "",
            "@TrackerFeaturizer.register(\"MaxHistoryTrackerFeaturizer\")",
            "class MaxHistoryTrackerFeaturizer(TrackerFeaturizer):",
            "    \"\"\"Truncates the tracker history into `max_history` long sequences.",
            "",
            "    Creates training data from trackers where actions are the output prediction",
            "    labels. Tracker state sequences which represent policy input are truncated",
            "    to not excede `max_history` states.",
            "    \"\"\"",
            "",
            "    LABEL_NAME = \"action\"",
            "",
            "    def __init__(",
            "        self,",
            "        state_featurizer: Optional[SingleStateFeaturizer] = None,",
            "        max_history: Optional[int] = None,",
            "        remove_duplicates: bool = True,",
            "    ) -> None:",
            "        \"\"\"Initializes the tracker featurizer.",
            "",
            "        Args:",
            "            state_featurizer: The state featurizer used to encode the states.",
            "            max_history: The maximum length of an extracted state sequence.",
            "            remove_duplicates: Keep only unique training state sequence/label pairs.",
            "        \"\"\"",
            "        super().__init__(state_featurizer)",
            "        self.max_history = max_history",
            "        self.remove_duplicates = remove_duplicates",
            "",
            "    @staticmethod",
            "    def slice_state_history(",
            "        states: List[State], slice_length: Optional[int]",
            "    ) -> List[State]:",
            "        \"\"\"Slices states from the trackers history.",
            "",
            "        Args:",
            "            states: The states",
            "            slice_length: The slice length",
            "",
            "        Returns:",
            "            The sliced states.",
            "        \"\"\"",
            "        if not slice_length:",
            "            return states",
            "",
            "        return states[-slice_length:]",
            "",
            "    @staticmethod",
            "    def _hash_example(states: List[State], labels: Optional[List[Text]] = None) -> int:",
            "        \"\"\"Hashes states (and optionally label).",
            "",
            "        Produces a hash of the tracker state sequence (and optionally the labels).",
            "        If `labels` is `None`, labels don't get hashed.",
            "",
            "        Args:",
            "            states: The tracker state sequence to hash.",
            "            labels: Label strings associated with this state sequence.",
            "",
            "        Returns:",
            "            The hash of the states and (optionally) the label.",
            "        \"\"\"",
            "        frozen_states = tuple(",
            "            s if s is None else DialogueStateTracker.freeze_current_state(s)",
            "            for s in states",
            "        )",
            "        if labels is not None:",
            "            frozen_labels = tuple(labels)",
            "            return hash((frozen_states, frozen_labels))",
            "        else:",
            "            return hash(frozen_states)",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, action labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        example_states = []",
            "        example_labels = []",
            "        example_entities = []",
            "",
            "        # Store of example hashes for removing duplicate training examples.",
            "        hashed_examples = set()",
            "",
            "        logger.debug(",
            "            f\"Creating states and {self.LABEL_NAME} label examples from \"",
            "            f\"collected trackers \"",
            "            f\"(by {type(self).__name__}({type(self.state_featurizer).__name__}))...\"",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "",
            "            for states, label, entities in self._extract_examples(",
            "                tracker,",
            "                domain,",
            "                omit_unset_slots=omit_unset_slots,",
            "                ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "            ):",
            "",
            "                if self.remove_duplicates:",
            "                    hashed = self._hash_example(states, label)",
            "                    if hashed in hashed_examples:",
            "                        continue",
            "                    hashed_examples.add(hashed)",
            "",
            "                example_states.append(states)",
            "                example_labels.append(label)",
            "                example_entities.append(entities)",
            "",
            "                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_labels):d}\"})",
            "",
            "        self._remove_user_text_if_intent(example_states)",
            "",
            "        logger.debug(f\"Created {len(example_states)} {self.LABEL_NAME} examples.\")",
            "",
            "        return example_states, example_labels, example_entities",
            "",
            "    def _extract_examples(",
            "        self,",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Iterator[Tuple[List[State], List[Text], List[Dict[Text, Any]]]]:",
            "        \"\"\"Creates an iterator over training examples from a tracker.",
            "",
            "        Args:",
            "            trackers: The tracker from which to extract training examples.",
            "            domain: The domain of the training data.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            An iterator over example states, labels, and entity data.",
            "        \"\"\"",
            "        tracker_states = self._create_states(",
            "            tracker, domain, omit_unset_slots=omit_unset_slots",
            "        )",
            "        events = tracker.applied_events()",
            "",
            "        if ignore_action_unlikely_intent:",
            "            tracker_states = self._remove_action_unlikely_intent_from_states(",
            "                tracker_states",
            "            )",
            "            events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "        label_index = 0",
            "        entity_data = {}",
            "        for event in events:",
            "            if isinstance(event, UserUttered):",
            "                entity_data = self._entity_data(event)",
            "",
            "            elif isinstance(event, ActionExecuted):",
            "",
            "                label_index += 1",
            "",
            "                # use only actions which can be predicted at a stories start",
            "                if event.unpredictable:",
            "                    continue",
            "",
            "                sliced_states = self.slice_state_history(",
            "                    tracker_states[:label_index], self.max_history",
            "                )",
            "                label = cast(List[Text], [event.action_name or event.action_text])",
            "                entities = [entity_data]",
            "",
            "                yield sliced_states, label, entities",
            "",
            "                # reset entity_data for the the next turn",
            "                entity_data = {}",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        # Remove `action_unlikely_intent` from `trackers_as_states`.",
            "        # This must be done before state history slicing to ensure the",
            "        # max history of the sliced states matches training time.",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        trackers_as_states = [",
            "            self.slice_state_history(states, self.max_history)",
            "            for states in trackers_as_states",
            "        ]",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        return trackers_as_states",
            "",
            "    def to_dict(self) -> Dict[str, Any]:",
            "        data = super().to_dict()",
            "        data.update(",
            "            {",
            "                \"remove_duplicates\": self.remove_duplicates,",
            "                \"max_history\": self.max_history,",
            "            }",
            "        )",
            "        return data",
            "",
            "    @classmethod",
            "    def create_from_dict(cls, data: Dict[str, Any]) -> \"MaxHistoryTrackerFeaturizer\":",
            "        state_featurizer = SingleStateFeaturizer.create_from_dict(",
            "            data[\"state_featurizer\"]",
            "        )",
            "        return cls(state_featurizer, data[\"max_history\"], data[\"remove_duplicates\"])",
            "",
            "",
            "@TrackerFeaturizer.register(\"IntentMaxHistoryTrackerFeaturizer\")",
            "class IntentMaxHistoryTrackerFeaturizer(MaxHistoryTrackerFeaturizer):",
            "    \"\"\"Truncates the tracker history into `max_history` long sequences.",
            "",
            "    Creates training data from trackers where intents are the output prediction",
            "    labels. Tracker state sequences which represent policy input are truncated",
            "    to not excede `max_history` states.",
            "    \"\"\"",
            "",
            "    LABEL_NAME = \"intent\"",
            "",
            "    @classmethod",
            "    def _convert_labels_to_ids(",
            "        cls, trackers_as_intents: List[List[Text]], domain: Domain",
            "    ) -> np.ndarray:",
            "        \"\"\"Converts a list of labels to a matrix of label ids.",
            "",
            "        The number of rows is equal to `len(trackers_as_intents)`. The number of",
            "        columns is equal to the maximum number of positive labels that any training",
            "        example is associated with. Rows are padded with `LABEL_PAD_ID` if not all rows",
            "        have the same number of labels.",
            "",
            "        Args:",
            "            trackers_as_intents: Positive example label ids",
            "                associated with each training example.",
            "            domain: The domain of the training data.",
            "",
            "        Returns:",
            "           A matrix of label ids.",
            "        \"\"\"",
            "        # store labels in numpy arrays so that it corresponds to np arrays",
            "        # of input features",
            "        label_ids = [",
            "            [domain.intents.index(intent) for intent in tracker_intents]",
            "            for tracker_intents in trackers_as_intents",
            "        ]",
            "",
            "        return np.array(cls._pad_label_ids(label_ids))",
            "",
            "    @staticmethod",
            "    def _pad_label_ids(label_ids: List[List[int]]) -> List[List[int]]:",
            "        \"\"\"Pads label ids so that all are of the same length.",
            "",
            "        Args:",
            "            label_ids: Label ids of varying lengths",
            "",
            "        Returns:",
            "            Label ids padded to be of uniform length.",
            "        \"\"\"",
            "        # If `label_ids` is an empty list, no padding needs to be added.",
            "        if not label_ids:",
            "            return label_ids",
            "",
            "        # Add `LABEL_PAD_ID` padding to labels array so that",
            "        # each example has equal number of labels",
            "        multiple_labels_count = [len(a) for a in label_ids]",
            "        max_labels_count = max(multiple_labels_count)",
            "        num_padding_needed = [max_labels_count - len(a) for a in label_ids]",
            "",
            "        padded_label_ids = []",
            "        for ids, num_pads in zip(label_ids, num_padding_needed):",
            "            padded_row = list(ids) + [LABEL_PAD_ID] * num_pads",
            "            padded_label_ids.append(padded_row)",
            "        return padded_label_ids",
            "",
            "    def training_states_labels_and_entities(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Tuple[List[List[State]], List[List[Text]], List[List[Dict[Text, Any]]]]:",
            "        \"\"\"Transforms trackers to states, intent labels, and entity data.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            Trackers as states, labels, and entity data.",
            "        \"\"\"",
            "        example_states = []",
            "        example_entities = []",
            "",
            "        # Store of example hashes (of both states and labels) for removing",
            "        # duplicate training examples.",
            "        hashed_examples = set()",
            "        # Mapping of example state hash to set of",
            "        # positive labels associated with the state.",
            "        state_hash_to_label_set: DefaultDict[int, Set[Text]] = defaultdict(set)",
            "",
            "        logger.debug(",
            "            f\"Creating states and {self.LABEL_NAME} label examples from \"",
            "            f\"collected trackers \"",
            "            f\"(by {type(self).__name__}({type(self.state_featurizer).__name__}))...\"",
            "        )",
            "        pbar = tqdm(",
            "            trackers,",
            "            desc=\"Processed trackers\",",
            "            disable=rasa.shared.utils.io.is_logging_disabled(),",
            "        )",
            "        for tracker in pbar:",
            "",
            "            for states, label, entities in self._extract_examples(",
            "                tracker,",
            "                domain,",
            "                omit_unset_slots=omit_unset_slots,",
            "                ignore_action_unlikely_intent=ignore_action_unlikely_intent,",
            "            ):",
            "",
            "                if self.remove_duplicates:",
            "                    hashed = self._hash_example(states, label)",
            "                    if hashed in hashed_examples:",
            "                        continue",
            "                    hashed_examples.add(hashed)",
            "",
            "                # Store all positive labels associated with a training state.",
            "                state_hash = self._hash_example(states)",
            "",
            "                # Only add unique example states unless `remove_duplicates` is `False`.",
            "                if (",
            "                    not self.remove_duplicates",
            "                    or state_hash not in state_hash_to_label_set",
            "                ):",
            "                    example_states.append(states)",
            "                    example_entities.append(entities)",
            "",
            "                state_hash_to_label_set[state_hash].add(label[0])",
            "",
            "                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_states):d}\"})",
            "",
            "        # Collect positive labels for each state example.",
            "        example_labels = [",
            "            list(state_hash_to_label_set[self._hash_example(state)])",
            "            for state in example_states",
            "        ]",
            "",
            "        self._remove_user_text_if_intent(example_states)",
            "",
            "        logger.debug(f\"Created {len(example_states)} {self.LABEL_NAME} examples.\")",
            "",
            "        return example_states, example_labels, example_entities",
            "",
            "    def _extract_examples(",
            "        self,",
            "        tracker: DialogueStateTracker,",
            "        domain: Domain,",
            "        omit_unset_slots: bool = False,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> Iterator[Tuple[List[State], List[Text], List[Dict[Text, Any]]]]:",
            "        \"\"\"Creates an iterator over training examples from a tracker.",
            "",
            "        Args:",
            "            tracker: The tracker from which to extract training examples.",
            "            domain: The domain of the training data.",
            "            omit_unset_slots: If `True` do not include the initial values of slots.",
            "            ignore_action_unlikely_intent: Whether to remove `action_unlikely_intent`",
            "                from training states.",
            "",
            "        Returns:",
            "            An iterator over example states, labels, and entity data.",
            "        \"\"\"",
            "        tracker_states = self._create_states(",
            "            tracker, domain, omit_unset_slots=omit_unset_slots",
            "        )",
            "        events = tracker.applied_events()",
            "",
            "        if ignore_action_unlikely_intent:",
            "            tracker_states = self._remove_action_unlikely_intent_from_states(",
            "                tracker_states",
            "            )",
            "            events = self._remove_action_unlikely_intent_from_events(events)",
            "",
            "        label_index = 0",
            "        for event in events:",
            "",
            "            if isinstance(event, ActionExecuted):",
            "                label_index += 1",
            "",
            "            elif isinstance(event, UserUttered):",
            "",
            "                sliced_states = self.slice_state_history(",
            "                    tracker_states[:label_index], self.max_history",
            "                )",
            "                label = cast(List[Text], [event.intent_name or event.text])",
            "                entities: List[Dict[Text, Any]] = [{}]",
            "",
            "                yield sliced_states, label, entities",
            "",
            "    @staticmethod",
            "    def _cleanup_last_user_state_with_action_listen(",
            "        trackers_as_states: List[List[State]],",
            "    ) -> List[List[State]]:",
            "        \"\"\"Removes the last tracker state if the previous action is `action_listen`.",
            "",
            "        States with the previous action equal to `action_listen` correspond to states",
            "        with a new user intent. This information is what `UnexpecTEDIntentPolicy` is",
            "        trying to predict so it needs to be removed before obtaining a prediction.",
            "",
            "        Args:",
            "            trackers_as_states: Trackers converted to states",
            "",
            "        Returns:",
            "            Filtered states with last `action_listen` removed.",
            "        \"\"\"",
            "        for states in trackers_as_states:",
            "            if not states:",
            "                continue",
            "            last_state = states[-1]",
            "            if rasa.shared.core.trackers.is_prev_action_listen_in_state(last_state):",
            "                del states[-1]",
            "",
            "        return trackers_as_states",
            "",
            "    def prediction_states(",
            "        self,",
            "        trackers: List[DialogueStateTracker],",
            "        domain: Domain,",
            "        use_text_for_last_user_input: bool = False,",
            "        ignore_rule_only_turns: bool = False,",
            "        rule_only_data: Optional[Dict[Text, Any]] = None,",
            "        ignore_action_unlikely_intent: bool = False,",
            "    ) -> List[List[State]]:",
            "        \"\"\"Transforms trackers to states for prediction.",
            "",
            "        Args:",
            "            trackers: The trackers to transform.",
            "            domain: The domain.",
            "            use_text_for_last_user_input: Indicates whether to use text or intent label",
            "                for featurizing last user input.",
            "            ignore_rule_only_turns: If True ignore dialogue turns that are present",
            "                only in rules.",
            "            rule_only_data: Slots and loops,",
            "                which only occur in rules but not in stories.",
            "            ignore_action_unlikely_intent: Whether to remove any states containing",
            "                `action_unlikely_intent` from prediction states.",
            "",
            "        Returns:",
            "            Trackers as states for prediction.",
            "        \"\"\"",
            "        trackers_as_states = [",
            "            self._create_states(",
            "                tracker,",
            "                domain,",
            "                ignore_rule_only_turns=ignore_rule_only_turns,",
            "                rule_only_data=rule_only_data,",
            "            )",
            "            for tracker in trackers",
            "        ]",
            "",
            "        # Remove `action_unlikely_intent` from `trackers_as_states`.",
            "        # This must be done before state history slicing to ensure the",
            "        # max history of the sliced states matches training time.",
            "        if ignore_action_unlikely_intent:",
            "            trackers_as_states = [",
            "                self._remove_action_unlikely_intent_from_states(states)",
            "                for states in trackers_as_states",
            "            ]",
            "",
            "        self._choose_last_user_input(trackers_as_states, use_text_for_last_user_input)",
            "",
            "        # `tracker_as_states` contain a state with intent = last intent",
            "        # and previous action = action_listen. This state needs to be",
            "        # removed as it was not present during training as well because",
            "        # predicting the last intent is what the policies using this",
            "        # featurizer do. This is specifically done before state history",
            "        # is sliced so that the number of past states is same as `max_history`.",
            "        self._cleanup_last_user_state_with_action_listen(trackers_as_states)",
            "",
            "        trackers_as_states = [",
            "            self.slice_state_history(states, self.max_history)",
            "            for states in trackers_as_states",
            "        ]",
            "",
            "        return trackers_as_states",
            "",
            "    def to_dict(self) -> Dict[str, Any]:",
            "        return super().to_dict()",
            "",
            "    @classmethod",
            "    def create_from_dict(",
            "        cls, data: Dict[str, Any]",
            "    ) -> \"IntentMaxHistoryTrackerFeaturizer\":",
            "        state_featurizer = SingleStateFeaturizer.create_from_dict(",
            "            data[\"state_featurizer\"]",
            "        )",
            "        return cls(state_featurizer, data[\"max_history\"], data[\"remove_duplicates\"])",
            "",
            "",
            "def _is_prev_action_unlikely_intent_in_state(state: State) -> bool:",
            "    prev_action_name = state.get(PREVIOUS_ACTION, {}).get(ACTION_NAME)",
            "    return prev_action_name == ACTION_UNLIKELY_INTENT_NAME"
        ],
        "action": [
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "2": [],
            "3": [],
            "4": [],
            "5": [],
            "6": [],
            "8": [],
            "24": [],
            "25": [],
            "26": [],
            "29": [],
            "30": [],
            "31": [],
            "32": [],
            "33": [],
            "468": [
                "TrackerFeaturizer",
                "persist"
            ],
            "469": [
                "TrackerFeaturizer",
                "persist"
            ],
            "470": [
                "TrackerFeaturizer",
                "persist"
            ],
            "484": [
                "TrackerFeaturizer",
                "load"
            ]
        },
        "addLocation": []
    }
}