{
    "onnx/external_data_helper.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from itertools import chain"
            },
            "1": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from typing import Callable, Iterable, Optional"
            },
            "2": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 11,
                "PatchRowcode": "+import onnx.onnx_cpp2py_export.checker as c_checker"
            },
            "4": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from onnx.onnx_pb import AttributeProto, GraphProto, ModelProto, TensorProto"
            },
            "5": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "         base_dir: directory that contains the external data."
            },
            "8": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "     info = ExternalDataInfo(tensor)"
            },
            "10": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    file_location = _sanitize_path(info.location)"
            },
            "11": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    external_data_file_path = os.path.join(base_dir, file_location)"
            },
            "12": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    external_data_file_path = c_checker._resolve_external_data_location(  # type: ignore[attr-defined]"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+        base_dir, info.location, tensor.name"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+    )"
            },
            "16": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "     with open(external_data_file_path, \"rb\") as data_file:"
            },
            "17": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "         if info.offset:"
            },
            "18": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 47,
                "PatchRowcode": "             data_file.seek(info.offset)"
            },
            "19": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "     yield from _get_attribute_tensors_from_graph(onnx_model_proto.graph)"
            },
            "20": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": 256,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": 257,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _sanitize_path(path: str) -> str:"
            },
            "23": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Remove path components which would allow traversing up a directory tree from a base path."
            },
            "24": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "25": {
                "beforePatchRowNumber": 260,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Note: This method is currently very basic and should be expanded."
            },
            "26": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "27": {
                "beforePatchRowNumber": 262,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return path.lstrip(\"/.\")"
            },
            "28": {
                "beforePatchRowNumber": 263,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "29": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "30": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 258,
                "PatchRowcode": " def _is_valid_filename(filename: str) -> bool:"
            },
            "31": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 259,
                "PatchRowcode": "     \"\"\"Utility to check whether the provided filename is valid.\"\"\""
            },
            "32": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": 260,
                "PatchRowcode": "     exp = re.compile('^[^<>:;,?\"*|/]+$')"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "#",
            "# SPDX-License-Identifier: Apache-2.0",
            "import os",
            "import re",
            "import sys",
            "import uuid",
            "from itertools import chain",
            "from typing import Callable, Iterable, Optional",
            "",
            "from onnx.onnx_pb import AttributeProto, GraphProto, ModelProto, TensorProto",
            "",
            "",
            "class ExternalDataInfo:",
            "    def __init__(self, tensor: TensorProto) -> None:",
            "        self.location = \"\"",
            "        self.offset = None",
            "        self.length = None",
            "        self.checksum = None",
            "        self.basepath = \"\"",
            "",
            "        for entry in tensor.external_data:",
            "            setattr(self, entry.key, entry.value)",
            "",
            "        if self.offset:",
            "            self.offset = int(self.offset)",
            "",
            "        if self.length:",
            "            self.length = int(self.length)",
            "",
            "",
            "def load_external_data_for_tensor(tensor: TensorProto, base_dir: str) -> None:",
            "    \"\"\"Loads data from an external file for tensor.",
            "    Ideally TensorProto should not hold any raw data but if it does it will be ignored.",
            "",
            "    Arguments:",
            "        tensor: a TensorProto object.",
            "        base_dir: directory that contains the external data.",
            "    \"\"\"",
            "    info = ExternalDataInfo(tensor)",
            "    file_location = _sanitize_path(info.location)",
            "    external_data_file_path = os.path.join(base_dir, file_location)",
            "",
            "    with open(external_data_file_path, \"rb\") as data_file:",
            "        if info.offset:",
            "            data_file.seek(info.offset)",
            "",
            "        if info.length:",
            "            tensor.raw_data = data_file.read(info.length)",
            "        else:",
            "            tensor.raw_data = data_file.read()",
            "",
            "",
            "def load_external_data_for_model(model: ModelProto, base_dir: str) -> None:",
            "    \"\"\"Loads external tensors into model",
            "",
            "    Arguments:",
            "        model: ModelProto to load external data to",
            "        base_dir: directory that contains external data",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        if uses_external_data(tensor):",
            "            load_external_data_for_tensor(tensor, base_dir)",
            "            # After loading raw_data from external_data, change the state of tensors",
            "            tensor.data_location = TensorProto.DEFAULT",
            "            # and remove external data",
            "            del tensor.external_data[:]",
            "",
            "",
            "def set_external_data(",
            "    tensor: TensorProto,",
            "    location: str,",
            "    offset: Optional[int] = None,",
            "    length: Optional[int] = None,",
            "    checksum: Optional[str] = None,",
            "    basepath: Optional[str] = None,",
            ") -> None:",
            "    if not tensor.HasField(\"raw_data\"):",
            "        raise ValueError(",
            "            \"Tensor \"",
            "            + tensor.name",
            "            + \"does not have raw_data field. Cannot set external data for this tensor.\"",
            "        )",
            "",
            "    del tensor.external_data[:]",
            "    tensor.data_location = TensorProto.EXTERNAL",
            "    for k, v in {",
            "        \"location\": location,",
            "        \"offset\": int(offset) if offset is not None else None,",
            "        \"length\": int(length) if length is not None else None,",
            "        \"checksum\": checksum,",
            "        \"basepath\": basepath,",
            "    }.items():",
            "        if v is not None:",
            "            entry = tensor.external_data.add()",
            "            entry.key = k",
            "            entry.value = str(v)",
            "",
            "",
            "def convert_model_to_external_data(",
            "    model: ModelProto,",
            "    all_tensors_to_one_file: bool = True,",
            "    location: Optional[str] = None,",
            "    size_threshold: int = 1024,",
            "    convert_attribute: bool = False,",
            ") -> None:",
            "    \"\"\"Call to set all tensors with raw data as external data. This call should precede 'save_model'.",
            "    'save_model' saves all the tensors data as external data after calling this function.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model to be converted.",
            "        all_tensors_to_one_file (bool): If true, save all tensors to one external file specified by location.",
            "            If false, save each tensor to a file named with the tensor name.",
            "        location: specify the external file relative to the model that all tensors to save to.",
            "            Path is relative to the model path.",
            "            If not specified, will use the model name.",
            "        size_threshold: Threshold for size of data. Only when tensor's data is >= the size_threshold",
            "            it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.",
            "        convert_attribute (bool): If true, convert all tensors to external data",
            "                       If false, convert only non-attribute tensors to external data",
            "    \"\"\"",
            "    tensors = _get_initializer_tensors(model)",
            "    if convert_attribute:",
            "        tensors = _get_all_tensors(model)",
            "",
            "    if all_tensors_to_one_file:",
            "        file_name = str(uuid.uuid1())",
            "        if location:",
            "            if os.path.isabs(location):",
            "                raise ValueError(",
            "                    \"location must be a relative path that is relative to the model path.\"",
            "                )",
            "            file_name = location",
            "        for tensor in tensors:",
            "            if (",
            "                tensor.HasField(\"raw_data\")",
            "                and sys.getsizeof(tensor.raw_data) >= size_threshold",
            "            ):",
            "                set_external_data(tensor, file_name)",
            "    else:",
            "        for tensor in tensors:",
            "            if (",
            "                tensor.HasField(\"raw_data\")",
            "                and sys.getsizeof(tensor.raw_data) >= size_threshold",
            "            ):",
            "                tensor_location = tensor.name",
            "                if not _is_valid_filename(tensor_location):",
            "                    tensor_location = str(uuid.uuid1())",
            "                set_external_data(tensor, tensor_location)",
            "",
            "",
            "def convert_model_from_external_data(model: ModelProto) -> None:",
            "    \"\"\"Call to set all tensors which use external data as embedded data.",
            "    save_model saves all the tensors data as embedded data after",
            "    calling this function.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model to be converted.",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        if uses_external_data(tensor):",
            "            if not tensor.HasField(\"raw_data\"):",
            "                raise ValueError(\"raw_data field doesn't exist.\")",
            "            del tensor.external_data[:]",
            "            tensor.data_location = TensorProto.DEFAULT",
            "",
            "",
            "def save_external_data(tensor: TensorProto, base_path: str) -> None:",
            "    \"\"\"Writes tensor data to an external file according to information in the `external_data` field.",
            "",
            "    Arguments:",
            "        tensor (TensorProto): Tensor object to be serialized",
            "        base_path: System path of a folder where tensor data is to be stored",
            "    \"\"\"",
            "    info = ExternalDataInfo(tensor)",
            "    external_data_file_path = os.path.join(base_path, info.location)",
            "",
            "    # Retrieve the tensor's data from raw_data or load external file",
            "    if not tensor.HasField(\"raw_data\"):",
            "        raise ValueError(\"raw_data field doesn't exist.\")",
            "",
            "    # Create file if it doesn't exist",
            "    if not os.path.isfile(external_data_file_path):",
            "        with open(external_data_file_path, \"ab\"):",
            "            pass",
            "",
            "    # Open file for reading and writing at random locations ('r+b')",
            "    with open(external_data_file_path, \"r+b\") as data_file:",
            "        data_file.seek(0, 2)",
            "        if info.offset is not None:",
            "            # Pad file to required offset if needed",
            "            file_size = data_file.tell()",
            "            if info.offset > file_size:",
            "                data_file.write(b\"\\0\" * (info.offset - file_size))",
            "",
            "            data_file.seek(info.offset)",
            "        offset = data_file.tell()",
            "        data_file.write(tensor.raw_data)",
            "        set_external_data(tensor, info.location, offset, data_file.tell() - offset)",
            "",
            "",
            "def _get_all_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Scan an ONNX model for all tensors and return as an iterator.\"\"\"",
            "    return chain(",
            "        _get_initializer_tensors(onnx_model_proto),",
            "        _get_attribute_tensors(onnx_model_proto),",
            "    )",
            "",
            "",
            "def _recursive_attribute_processor(",
            "    attribute: AttributeProto, func: Callable[[GraphProto], Iterable[TensorProto]]",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator through processing ONNX model attributes with functor.\"\"\"",
            "    if attribute.type == AttributeProto.GRAPH:",
            "        yield from func(attribute.g)",
            "    if attribute.type == AttributeProto.GRAPHS:",
            "        for graph in attribute.graphs:",
            "            yield from func(graph)",
            "",
            "",
            "def _get_initializer_tensors_from_graph(",
            "    onnx_model_proto_graph: GraphProto,",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of initializer tensors from ONNX model graph.\"\"\"",
            "    yield from onnx_model_proto_graph.initializer",
            "    for node in onnx_model_proto_graph.node:",
            "        for attribute in node.attribute:",
            "            yield from _recursive_attribute_processor(",
            "                attribute, _get_initializer_tensors_from_graph",
            "            )",
            "",
            "",
            "def _get_initializer_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of initializer tensors from ONNX model.\"\"\"",
            "    yield from _get_initializer_tensors_from_graph(onnx_model_proto.graph)",
            "",
            "",
            "def _get_attribute_tensors_from_graph(",
            "    onnx_model_proto_graph: GraphProto,",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of tensors from node attributes of an ONNX model graph.\"\"\"",
            "    for node in onnx_model_proto_graph.node:",
            "        for attribute in node.attribute:",
            "            if attribute.HasField(\"t\"):",
            "                yield attribute.t",
            "            yield from attribute.tensors",
            "            yield from _recursive_attribute_processor(",
            "                attribute, _get_attribute_tensors_from_graph",
            "            )",
            "",
            "",
            "def _get_attribute_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of tensors from node attributes of an ONNX model.\"\"\"",
            "    yield from _get_attribute_tensors_from_graph(onnx_model_proto.graph)",
            "",
            "",
            "def _sanitize_path(path: str) -> str:",
            "    \"\"\"Remove path components which would allow traversing up a directory tree from a base path.",
            "",
            "    Note: This method is currently very basic and should be expanded.",
            "    \"\"\"",
            "    return path.lstrip(\"/.\")",
            "",
            "",
            "def _is_valid_filename(filename: str) -> bool:",
            "    \"\"\"Utility to check whether the provided filename is valid.\"\"\"",
            "    exp = re.compile('^[^<>:;,?\"*|/]+$')",
            "    match = exp.match(filename)",
            "    return bool(match)",
            "",
            "",
            "def uses_external_data(tensor: TensorProto) -> bool:",
            "    \"\"\"Returns true if the tensor stores data in an external location.\"\"\"",
            "    return (  # type: ignore[no-any-return]",
            "        tensor.HasField(\"data_location\")",
            "        and tensor.data_location == TensorProto.EXTERNAL",
            "    )",
            "",
            "",
            "def remove_external_data_field(tensor: TensorProto, field_key: str) -> None:",
            "    \"\"\"Removes a field from a Tensor's external_data key-value store.",
            "",
            "    Modifies tensor object in place.",
            "",
            "    Arguments:",
            "        tensor (TensorProto): Tensor object from which value will be removed",
            "        field_key (string): The key of the field to be removed",
            "    \"\"\"",
            "    for i, field in enumerate(tensor.external_data):",
            "        if field.key == field_key:",
            "            del tensor.external_data[i]",
            "",
            "",
            "def write_external_data_tensors(model: ModelProto, filepath: str) -> ModelProto:",
            "    \"\"\"Serializes data for all the tensors which have data location set to TensorProto.External.",
            "",
            "    Note: This function also strips basepath information from all tensors' external_data fields.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model object which is the source of tensors to serialize.",
            "        filepath: System path to the directory which should be treated as base path for external data.",
            "",
            "    Returns:",
            "        ModelProto: The modified model object.",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        # Writing to external data happens in 2 passes:",
            "        # 1. Tensors with raw data which pass the necessary conditions (size threshold etc) are marked for serialization",
            "        # 2. The raw data in these tensors is serialized to a file",
            "        # Thus serialize only if tensor has raw data and it was marked for serialization",
            "        if uses_external_data(tensor) and tensor.HasField(\"raw_data\"):",
            "            save_external_data(tensor, filepath)",
            "            tensor.ClearField(\"raw_data\")",
            "",
            "    return model"
        ],
        "afterPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "#",
            "# SPDX-License-Identifier: Apache-2.0",
            "import os",
            "import re",
            "import sys",
            "import uuid",
            "from itertools import chain",
            "from typing import Callable, Iterable, Optional",
            "",
            "import onnx.onnx_cpp2py_export.checker as c_checker",
            "from onnx.onnx_pb import AttributeProto, GraphProto, ModelProto, TensorProto",
            "",
            "",
            "class ExternalDataInfo:",
            "    def __init__(self, tensor: TensorProto) -> None:",
            "        self.location = \"\"",
            "        self.offset = None",
            "        self.length = None",
            "        self.checksum = None",
            "        self.basepath = \"\"",
            "",
            "        for entry in tensor.external_data:",
            "            setattr(self, entry.key, entry.value)",
            "",
            "        if self.offset:",
            "            self.offset = int(self.offset)",
            "",
            "        if self.length:",
            "            self.length = int(self.length)",
            "",
            "",
            "def load_external_data_for_tensor(tensor: TensorProto, base_dir: str) -> None:",
            "    \"\"\"Loads data from an external file for tensor.",
            "    Ideally TensorProto should not hold any raw data but if it does it will be ignored.",
            "",
            "    Arguments:",
            "        tensor: a TensorProto object.",
            "        base_dir: directory that contains the external data.",
            "    \"\"\"",
            "    info = ExternalDataInfo(tensor)",
            "    external_data_file_path = c_checker._resolve_external_data_location(  # type: ignore[attr-defined]",
            "        base_dir, info.location, tensor.name",
            "    )",
            "    with open(external_data_file_path, \"rb\") as data_file:",
            "        if info.offset:",
            "            data_file.seek(info.offset)",
            "",
            "        if info.length:",
            "            tensor.raw_data = data_file.read(info.length)",
            "        else:",
            "            tensor.raw_data = data_file.read()",
            "",
            "",
            "def load_external_data_for_model(model: ModelProto, base_dir: str) -> None:",
            "    \"\"\"Loads external tensors into model",
            "",
            "    Arguments:",
            "        model: ModelProto to load external data to",
            "        base_dir: directory that contains external data",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        if uses_external_data(tensor):",
            "            load_external_data_for_tensor(tensor, base_dir)",
            "            # After loading raw_data from external_data, change the state of tensors",
            "            tensor.data_location = TensorProto.DEFAULT",
            "            # and remove external data",
            "            del tensor.external_data[:]",
            "",
            "",
            "def set_external_data(",
            "    tensor: TensorProto,",
            "    location: str,",
            "    offset: Optional[int] = None,",
            "    length: Optional[int] = None,",
            "    checksum: Optional[str] = None,",
            "    basepath: Optional[str] = None,",
            ") -> None:",
            "    if not tensor.HasField(\"raw_data\"):",
            "        raise ValueError(",
            "            \"Tensor \"",
            "            + tensor.name",
            "            + \"does not have raw_data field. Cannot set external data for this tensor.\"",
            "        )",
            "",
            "    del tensor.external_data[:]",
            "    tensor.data_location = TensorProto.EXTERNAL",
            "    for k, v in {",
            "        \"location\": location,",
            "        \"offset\": int(offset) if offset is not None else None,",
            "        \"length\": int(length) if length is not None else None,",
            "        \"checksum\": checksum,",
            "        \"basepath\": basepath,",
            "    }.items():",
            "        if v is not None:",
            "            entry = tensor.external_data.add()",
            "            entry.key = k",
            "            entry.value = str(v)",
            "",
            "",
            "def convert_model_to_external_data(",
            "    model: ModelProto,",
            "    all_tensors_to_one_file: bool = True,",
            "    location: Optional[str] = None,",
            "    size_threshold: int = 1024,",
            "    convert_attribute: bool = False,",
            ") -> None:",
            "    \"\"\"Call to set all tensors with raw data as external data. This call should precede 'save_model'.",
            "    'save_model' saves all the tensors data as external data after calling this function.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model to be converted.",
            "        all_tensors_to_one_file (bool): If true, save all tensors to one external file specified by location.",
            "            If false, save each tensor to a file named with the tensor name.",
            "        location: specify the external file relative to the model that all tensors to save to.",
            "            Path is relative to the model path.",
            "            If not specified, will use the model name.",
            "        size_threshold: Threshold for size of data. Only when tensor's data is >= the size_threshold",
            "            it will be converted to external data. To convert every tensor with raw data to external data set size_threshold=0.",
            "        convert_attribute (bool): If true, convert all tensors to external data",
            "                       If false, convert only non-attribute tensors to external data",
            "    \"\"\"",
            "    tensors = _get_initializer_tensors(model)",
            "    if convert_attribute:",
            "        tensors = _get_all_tensors(model)",
            "",
            "    if all_tensors_to_one_file:",
            "        file_name = str(uuid.uuid1())",
            "        if location:",
            "            if os.path.isabs(location):",
            "                raise ValueError(",
            "                    \"location must be a relative path that is relative to the model path.\"",
            "                )",
            "            file_name = location",
            "        for tensor in tensors:",
            "            if (",
            "                tensor.HasField(\"raw_data\")",
            "                and sys.getsizeof(tensor.raw_data) >= size_threshold",
            "            ):",
            "                set_external_data(tensor, file_name)",
            "    else:",
            "        for tensor in tensors:",
            "            if (",
            "                tensor.HasField(\"raw_data\")",
            "                and sys.getsizeof(tensor.raw_data) >= size_threshold",
            "            ):",
            "                tensor_location = tensor.name",
            "                if not _is_valid_filename(tensor_location):",
            "                    tensor_location = str(uuid.uuid1())",
            "                set_external_data(tensor, tensor_location)",
            "",
            "",
            "def convert_model_from_external_data(model: ModelProto) -> None:",
            "    \"\"\"Call to set all tensors which use external data as embedded data.",
            "    save_model saves all the tensors data as embedded data after",
            "    calling this function.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model to be converted.",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        if uses_external_data(tensor):",
            "            if not tensor.HasField(\"raw_data\"):",
            "                raise ValueError(\"raw_data field doesn't exist.\")",
            "            del tensor.external_data[:]",
            "            tensor.data_location = TensorProto.DEFAULT",
            "",
            "",
            "def save_external_data(tensor: TensorProto, base_path: str) -> None:",
            "    \"\"\"Writes tensor data to an external file according to information in the `external_data` field.",
            "",
            "    Arguments:",
            "        tensor (TensorProto): Tensor object to be serialized",
            "        base_path: System path of a folder where tensor data is to be stored",
            "    \"\"\"",
            "    info = ExternalDataInfo(tensor)",
            "    external_data_file_path = os.path.join(base_path, info.location)",
            "",
            "    # Retrieve the tensor's data from raw_data or load external file",
            "    if not tensor.HasField(\"raw_data\"):",
            "        raise ValueError(\"raw_data field doesn't exist.\")",
            "",
            "    # Create file if it doesn't exist",
            "    if not os.path.isfile(external_data_file_path):",
            "        with open(external_data_file_path, \"ab\"):",
            "            pass",
            "",
            "    # Open file for reading and writing at random locations ('r+b')",
            "    with open(external_data_file_path, \"r+b\") as data_file:",
            "        data_file.seek(0, 2)",
            "        if info.offset is not None:",
            "            # Pad file to required offset if needed",
            "            file_size = data_file.tell()",
            "            if info.offset > file_size:",
            "                data_file.write(b\"\\0\" * (info.offset - file_size))",
            "",
            "            data_file.seek(info.offset)",
            "        offset = data_file.tell()",
            "        data_file.write(tensor.raw_data)",
            "        set_external_data(tensor, info.location, offset, data_file.tell() - offset)",
            "",
            "",
            "def _get_all_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Scan an ONNX model for all tensors and return as an iterator.\"\"\"",
            "    return chain(",
            "        _get_initializer_tensors(onnx_model_proto),",
            "        _get_attribute_tensors(onnx_model_proto),",
            "    )",
            "",
            "",
            "def _recursive_attribute_processor(",
            "    attribute: AttributeProto, func: Callable[[GraphProto], Iterable[TensorProto]]",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator through processing ONNX model attributes with functor.\"\"\"",
            "    if attribute.type == AttributeProto.GRAPH:",
            "        yield from func(attribute.g)",
            "    if attribute.type == AttributeProto.GRAPHS:",
            "        for graph in attribute.graphs:",
            "            yield from func(graph)",
            "",
            "",
            "def _get_initializer_tensors_from_graph(",
            "    onnx_model_proto_graph: GraphProto,",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of initializer tensors from ONNX model graph.\"\"\"",
            "    yield from onnx_model_proto_graph.initializer",
            "    for node in onnx_model_proto_graph.node:",
            "        for attribute in node.attribute:",
            "            yield from _recursive_attribute_processor(",
            "                attribute, _get_initializer_tensors_from_graph",
            "            )",
            "",
            "",
            "def _get_initializer_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of initializer tensors from ONNX model.\"\"\"",
            "    yield from _get_initializer_tensors_from_graph(onnx_model_proto.graph)",
            "",
            "",
            "def _get_attribute_tensors_from_graph(",
            "    onnx_model_proto_graph: GraphProto,",
            ") -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of tensors from node attributes of an ONNX model graph.\"\"\"",
            "    for node in onnx_model_proto_graph.node:",
            "        for attribute in node.attribute:",
            "            if attribute.HasField(\"t\"):",
            "                yield attribute.t",
            "            yield from attribute.tensors",
            "            yield from _recursive_attribute_processor(",
            "                attribute, _get_attribute_tensors_from_graph",
            "            )",
            "",
            "",
            "def _get_attribute_tensors(onnx_model_proto: ModelProto) -> Iterable[TensorProto]:",
            "    \"\"\"Create an iterator of tensors from node attributes of an ONNX model.\"\"\"",
            "    yield from _get_attribute_tensors_from_graph(onnx_model_proto.graph)",
            "",
            "",
            "def _is_valid_filename(filename: str) -> bool:",
            "    \"\"\"Utility to check whether the provided filename is valid.\"\"\"",
            "    exp = re.compile('^[^<>:;,?\"*|/]+$')",
            "    match = exp.match(filename)",
            "    return bool(match)",
            "",
            "",
            "def uses_external_data(tensor: TensorProto) -> bool:",
            "    \"\"\"Returns true if the tensor stores data in an external location.\"\"\"",
            "    return (  # type: ignore[no-any-return]",
            "        tensor.HasField(\"data_location\")",
            "        and tensor.data_location == TensorProto.EXTERNAL",
            "    )",
            "",
            "",
            "def remove_external_data_field(tensor: TensorProto, field_key: str) -> None:",
            "    \"\"\"Removes a field from a Tensor's external_data key-value store.",
            "",
            "    Modifies tensor object in place.",
            "",
            "    Arguments:",
            "        tensor (TensorProto): Tensor object from which value will be removed",
            "        field_key (string): The key of the field to be removed",
            "    \"\"\"",
            "    for i, field in enumerate(tensor.external_data):",
            "        if field.key == field_key:",
            "            del tensor.external_data[i]",
            "",
            "",
            "def write_external_data_tensors(model: ModelProto, filepath: str) -> ModelProto:",
            "    \"\"\"Serializes data for all the tensors which have data location set to TensorProto.External.",
            "",
            "    Note: This function also strips basepath information from all tensors' external_data fields.",
            "",
            "    Arguments:",
            "        model (ModelProto): Model object which is the source of tensors to serialize.",
            "        filepath: System path to the directory which should be treated as base path for external data.",
            "",
            "    Returns:",
            "        ModelProto: The modified model object.",
            "    \"\"\"",
            "    for tensor in _get_all_tensors(model):",
            "        # Writing to external data happens in 2 passes:",
            "        # 1. Tensors with raw data which pass the necessary conditions (size threshold etc) are marked for serialization",
            "        # 2. The raw data in these tensors is serialized to a file",
            "        # Thus serialize only if tensor has raw data and it was marked for serialization",
            "        if uses_external_data(tensor) and tensor.HasField(\"raw_data\"):",
            "            save_external_data(tensor, filepath)",
            "            tensor.ClearField(\"raw_data\")",
            "",
            "    return model"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "41": [
                "load_external_data_for_tensor"
            ],
            "42": [
                "load_external_data_for_tensor"
            ],
            "43": [
                "load_external_data_for_tensor"
            ],
            "257": [
                "_sanitize_path"
            ],
            "258": [
                "_sanitize_path"
            ],
            "259": [
                "_sanitize_path"
            ],
            "260": [
                "_sanitize_path"
            ],
            "261": [
                "_sanitize_path"
            ],
            "262": [
                "_sanitize_path"
            ],
            "263": [],
            "264": []
        },
        "addLocation": []
    },
    "onnx/model_container.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import onnx"
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " import onnx.external_data_helper as ext_data"
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import onnx.helper"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+import onnx.onnx_cpp2py_export.checker as c_checker"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " def _set_external_data("
            },
            "7": {
                "beforePatchRowNumber": 288,
                "afterPatchRowNumber": 289,
                "PatchRowcode": "                 continue"
            },
            "8": {
                "beforePatchRowNumber": 289,
                "afterPatchRowNumber": 290,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 290,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "             info = ext_data.ExternalDataInfo(tensor)"
            },
            "10": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            file_location = ext_data._sanitize_path(info.location)"
            },
            "11": {
                "beforePatchRowNumber": 292,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            external_data_file_path = os.path.join(base_dir, file_location)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 292,
                "PatchRowcode": "+            external_data_file_path = c_checker._resolve_external_data_location(  # type: ignore[attr-defined]"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 293,
                "PatchRowcode": "+                base_dir, info.location, tensor.name"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+            )"
            },
            "15": {
                "beforePatchRowNumber": 293,
                "afterPatchRowNumber": 295,
                "PatchRowcode": "             key = f\"#t{i}\""
            },
            "16": {
                "beforePatchRowNumber": 294,
                "afterPatchRowNumber": 296,
                "PatchRowcode": "             _set_external_data(tensor, location=key)"
            },
            "17": {
                "beforePatchRowNumber": 295,
                "afterPatchRowNumber": 297,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "#",
            "# SPDX-License-Identifier: Apache-2.0",
            "\"\"\"Implements function make_large_model to easily create and save models",
            "bigger than 2 Gb.",
            "\"\"\"",
            "from __future__ import annotations",
            "",
            "import os",
            "import sys",
            "from typing import Any, Iterable",
            "",
            "import numpy as np",
            "",
            "import onnx",
            "import onnx.external_data_helper as ext_data",
            "import onnx.helper",
            "",
            "",
            "def _set_external_data(",
            "    tensor: onnx.TensorProto,",
            "    location: str,",
            "    offset: int | None = None,",
            "    length: int | None = None,",
            "    checksum: str | None = None,",
            "    basepath: str | None = None,",
            ") -> None:",
            "    del tensor.external_data[:]",
            "    tensor.data_location = onnx.TensorProto.EXTERNAL",
            "    for k, v in {",
            "        \"location\": location,",
            "        \"offset\": offset,",
            "        \"length\": length,",
            "        \"checksum\": checksum,",
            "        \"basepath\": basepath,",
            "    }.items():",
            "        if v is not None:",
            "            entry = tensor.external_data.add()",
            "            entry.key = k",
            "            entry.value = str(v)",
            "",
            "",
            "def _enumerate_subgraphs(graph):",
            "    for node in graph.node:",
            "        for att in node.attribute:",
            "            if att.g:",
            "                yield att.g",
            "                yield from _enumerate_subgraphs(att.g)",
            "",
            "",
            "def make_large_tensor_proto(",
            "    location: str, tensor_name: str, tensor_type: int, shape: tuple[int, ...]",
            ") -> onnx.TensorProto:",
            "    \"\"\"Create an external tensor.",
            "",
            "    Arguments:",
            "        location: unique identifier (not necessary a path)",
            "        tensor_name: tensor name in the graph",
            "        tensor_type: onnx type",
            "        shape: shape the of the initializer",
            "",
            "    Returns:",
            "        the created tensor",
            "    \"\"\"",
            "    tensor_location = location",
            "    tensor = onnx.TensorProto()",
            "    tensor.name = tensor_name",
            "    _set_external_data(tensor, tensor_location)",
            "    tensor.data_type = tensor_type",
            "    tensor.dims.extend(shape)",
            "    return tensor",
            "",
            "",
            "class ModelContainer:",
            "    \"\"\"Implements an API to store large tensors outside the main ModelProto,",
            "    it avoids copying large initializers when defining the model and these initializers",
            "    are never serialized through protobuf.",
            "    No tensor is stored on disk until the user explicitly saves the model.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.model_proto_: onnx.ModelProto | None = None",
            "        self.large_initializers: dict[str, np.ndarray] = {}",
            "",
            "    def check_model(self):",
            "        if self.model_proto is not None:",
            "            onnx.checker.check_model(self.model_proto)",
            "",
            "    def __getitem__(self, name: str) -> np.ndarray:",
            "        \"\"\"Returns an external tensor given its name.\"\"\"",
            "        if name not in self.large_initializers:",
            "            raise ValueError(",
            "                f\"Unable to find large tensor {name!r} among {sorted(self.large_initializers)}.\"",
            "            )",
            "        return self.large_initializers[name]",
            "",
            "    @property",
            "    def model_proto(self) -> onnx.ModelProto:",
            "        if self.model_proto_ is None:",
            "            raise RuntimeError(\"ModelContainer is empty.\")",
            "        return self.model_proto_",
            "",
            "    @model_proto.setter",
            "    def model_proto(self, model_proto: onnx.ModelProto):",
            "        self.model_proto_ = model_proto",
            "        self.graphs_ = list(self.enumerate_graph_protos())",
            "",
            "    def enumerate_graph_protos(self) -> Iterable[onnx.GraphProto]:",
            "        \"\"\"Enumerates all GraphProtos in a model.\"\"\"",
            "        yield self.model_proto.graph",
            "        yield from _enumerate_subgraphs(self.model_proto.graph)",
            "",
            "    def is_in_memory_external_initializer(self, name: str) -> bool:",
            "        \"\"\"Tells if an initializer name is an external initializer stored in memory.",
            "        The name must start with '#' in that case.",
            "        \"\"\"",
            "        return name.startswith(\"#\")",
            "",
            "    def set_large_initializers(self, large_initializers: dict[str, np.ndarray]):",
            "        \"\"\"Adds all large tensors (not stored in the model).\"\"\"",
            "        for k in large_initializers:",
            "            if not self.is_in_memory_external_initializer(k):",
            "                raise ValueError(",
            "                    f\"The location {k!r} must start with '#' to be ignored by check model.\"",
            "                )",
            "        self.large_initializers = large_initializers",
            "",
            "    def check_large_initializers(self):",
            "        for tensor in ext_data._get_all_tensors(self.model_proto):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "            prop: onnx.StringStringEntryProto | None = None",
            "            for ext in tensor.external_data:  # type: ignore[assignment]",
            "                if ext.key == \"location\":  # type: ignore[attr-defined]",
            "                    prop = ext",
            "            if prop is None:",
            "                raise RuntimeError(",
            "                    f\"No location found for tensor name {tensor.name!r}.\"",
            "                )",
            "            if prop.value not in self.large_initializers:",
            "                raise RuntimeError(",
            "                    f\"Unable to find large tensor named {tensor.name!r} \"",
            "                    f\"with location {prop.value!r} in \"",
            "                    f\"{sorted(self.large_initializers)}.\"",
            "                )",
            "",
            "    def _save_external(",
            "        self, file_path: str, all_tensors_to_one_file: bool",
            "    ) -> onnx.ModelProto:",
            "        \"\"\"Save the large model into a main onnx file and one file",
            "        per tensor. Follows the same format as :func:`write_external_data_tensors",
            "        <onnx.external_data_helper.write_external_data_tensors>`.",
            "        The main model needs to be modified to update the file location,",
            "        the function returns this modified copy.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            all_tensors_to_one_file: all tensors in one file",
            "",
            "        Returns:",
            "            modified main model proto",
            "        \"\"\"",
            "",
            "        def _clean_name(prefix: str, name: str, unique_names: dict[str, int]) -> str:",
            "            if prefix:",
            "                name = f\"{prefix}-{name}\"",
            "            for c in \":/\\\\;,!\":",
            "                name = name.replace(c, \"\")",
            "            base_name = name",
            "            if name in unique_names:",
            "                i = unique_names[name] + 1",
            "                unique_names[name] = i",
            "                return f\"{base_name}_{i}\"",
            "            unique_names[name] = 1",
            "            return name",
            "",
            "        unique_names: dict[str, int] = {}",
            "        folder = os.path.dirname(file_path)",
            "        if not os.path.exists(folder):",
            "            raise FileNotFoundError(f\"Folder {folder!r} does not exist.\")",
            "        proto = self.model_proto.SerializeToString()",
            "        copy = onnx.ModelProto()",
            "        copy.ParseFromString(proto)",
            "        prefix = os.path.splitext(os.path.split(file_path)[-1])[0]",
            "",
            "        if all_tensors_to_one_file:",
            "            file_weight = f\"{os.path.split(file_path)[1]}.weight\"",
            "            full_file_weight = f\"{file_path}.weight\"",
            "            offset = 0",
            "            with open(full_file_weight, \"wb\") as f:",
            "                pass",
            "",
            "        for tensor in ext_data._get_all_tensors(copy):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "            prop: onnx.StringStringEntryProto | None = None",
            "            for ext in tensor.external_data:  # type: ignore[assignment]",
            "                if ext.key == \"location\":  # type: ignore[attr-defined]",
            "                    prop = ext  # type: ignore[assignment]",
            "            if prop is None:",
            "                raise RuntimeError(",
            "                    f\"No location found for tensor name {tensor.name!r}.\"",
            "                )",
            "            if prop.value not in self.large_initializers:",
            "                raise RuntimeError(",
            "                    f\"Unable to find large tensor named {tensor.name!r} \"",
            "                    f\"with location {prop.value!r} in \"",
            "                    f\"{sorted(self.large_initializers)}.\"",
            "                )",
            "            np_tensor = self.large_initializers[prop.value]",
            "",
            "            if sys.byteorder == \"big\":",
            "                # Convert endian from little to big",
            "                tensor_bytes = np_tensor.byteswap().tobytes()",
            "            else:",
            "                tensor_bytes = np_tensor.tobytes()",
            "            if all_tensors_to_one_file:",
            "                _set_external_data(",
            "                    tensor,",
            "                    location=file_weight,",
            "                    offset=offset,",
            "                    length=len(tensor_bytes),",
            "                )",
            "                offset += len(tensor_bytes)",
            "                with open(full_file_weight, \"ab\") as f:",
            "                    f.write(tensor_bytes)",
            "            else:",
            "                name = f\"{_clean_name(prefix, prop.value, unique_names)}.weight\"",
            "                _set_external_data(tensor, location=name)",
            "                full_name = os.path.join(folder, name)",
            "                prop.value = name",
            "                with open(full_name, \"wb\") as f:",
            "                    f.write(tensor_bytes)",
            "",
            "        with open(file_path, \"wb\") as f:",
            "            f.write(copy.SerializeToString())",
            "        return copy",
            "",
            "    def save(",
            "        self,",
            "        file_path: str,",
            "        all_tensors_to_one_file: bool = False,",
            "    ) -> onnx.ModelProto:",
            "        \"\"\"Save the large model.",
            "        The function returns a ModelProto,",
            "        the current one if the model did not need any modification,",
            "        a modified copy of it if it required changes such as giving file names",
            "        to every external tensor.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            all_tensors_to_one_file: saves all large tensors in one file or",
            "                one file per lerge tensor",
            "",
            "        Returns:",
            "            the saved ModelProto",
            "        \"\"\"",
            "        return self._save_external(",
            "            file_path, all_tensors_to_one_file=all_tensors_to_one_file",
            "        )",
            "",
            "    def load(self, file_path: str, load_large_initializers: bool = True):",
            "        \"\"\"Load the large model.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            load_large_initializers: loads the large initializers,",
            "                if not done, the model is incomplete but it can be used to",
            "                look into the model without executing it and method",
            "                :meth:`_load_large_initializers` can be used to load them later",
            "        \"\"\"",
            "        self.model_proto_ = onnx.load_model(file_path, load_external_data=False)",
            "        if load_large_initializers:",
            "            self._load_large_initializers(file_path)",
            "",
            "    def _load_large_initializers(self, file_path):",
            "        \"\"\"Loads large initializers.",
            "",
            "        Arguments:",
            "            file_path: model file, the weight are expected to be in the same folder as this file",
            "        \"\"\"",
            "        if self.model_proto_ is None:",
            "            raise RuntimeError(\"A model must be loaded before loading the weights.\")",
            "        self.large_initializers = {}",
            "        base_dir = os.path.dirname(file_path)",
            "        for i, tensor in enumerate(ext_data._get_all_tensors(self.model_proto_)):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "",
            "            info = ext_data.ExternalDataInfo(tensor)",
            "            file_location = ext_data._sanitize_path(info.location)",
            "            external_data_file_path = os.path.join(base_dir, file_location)",
            "            key = f\"#t{i}\"",
            "            _set_external_data(tensor, location=key)",
            "",
            "            with open(external_data_file_path, \"rb\") as data_file:",
            "                if info.offset:",
            "                    data_file.seek(info.offset)",
            "",
            "                raw_data = (",
            "                    data_file.read(info.length) if info.length else data_file.read()",
            "                )",
            "",
            "                dtype = onnx.helper.tensor_dtype_to_np_dtype(tensor.data_type)",
            "                shape = tuple(tensor.dims)",
            "",
            "                if sys.byteorder == \"big\":",
            "                    np_tensor = (",
            "                        np.frombuffer(raw_data, dtype=dtype).byteswap().reshape(shape)",
            "                    )",
            "                else:",
            "                    np_tensor = np.frombuffer(raw_data, dtype=dtype).reshape(shape)",
            "",
            "                self.large_initializers[key] = np_tensor",
            "",
            "",
            "def make_large_model(",
            "    graph: onnx.GraphProto,",
            "    large_initializers: dict[str, np.ndarray] | None = None,",
            "    **kwargs: Any,",
            ") -> ModelContainer:",
            "    \"\"\"Construct a ModelContainer",
            "",
            "    C API and Python API of protobuf do not operate without serializing",
            "    the protos. This function uses the Python API of ModelContainer.",
            "",
            "    Arguments:",
            "        graph: *make_graph* returns",
            "        large_initializers: dictionary `name: large tensor`,",
            "            large tensor is any python object supporting the DLPack protocol,",
            "            the ownership the tensor is transferred to the ModelContainer,",
            "            the tensor must define method `tobytes` like numpy tensors",
            "        **kwargs: any attribute to add to the returned instance",
            "",
            "    Returns:",
            "        ModelContainer",
            "    \"\"\"",
            "    model = onnx.helper.make_model(graph, **kwargs)",
            "    large_model = ModelContainer()",
            "    large_model.model_proto = model",
            "    if large_initializers:",
            "        large_model.set_large_initializers(large_initializers)",
            "        large_model.check_large_initializers()",
            "    return large_model"
        ],
        "afterPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "#",
            "# SPDX-License-Identifier: Apache-2.0",
            "\"\"\"Implements function make_large_model to easily create and save models",
            "bigger than 2 Gb.",
            "\"\"\"",
            "from __future__ import annotations",
            "",
            "import os",
            "import sys",
            "from typing import Any, Iterable",
            "",
            "import numpy as np",
            "",
            "import onnx",
            "import onnx.external_data_helper as ext_data",
            "import onnx.helper",
            "import onnx.onnx_cpp2py_export.checker as c_checker",
            "",
            "",
            "def _set_external_data(",
            "    tensor: onnx.TensorProto,",
            "    location: str,",
            "    offset: int | None = None,",
            "    length: int | None = None,",
            "    checksum: str | None = None,",
            "    basepath: str | None = None,",
            ") -> None:",
            "    del tensor.external_data[:]",
            "    tensor.data_location = onnx.TensorProto.EXTERNAL",
            "    for k, v in {",
            "        \"location\": location,",
            "        \"offset\": offset,",
            "        \"length\": length,",
            "        \"checksum\": checksum,",
            "        \"basepath\": basepath,",
            "    }.items():",
            "        if v is not None:",
            "            entry = tensor.external_data.add()",
            "            entry.key = k",
            "            entry.value = str(v)",
            "",
            "",
            "def _enumerate_subgraphs(graph):",
            "    for node in graph.node:",
            "        for att in node.attribute:",
            "            if att.g:",
            "                yield att.g",
            "                yield from _enumerate_subgraphs(att.g)",
            "",
            "",
            "def make_large_tensor_proto(",
            "    location: str, tensor_name: str, tensor_type: int, shape: tuple[int, ...]",
            ") -> onnx.TensorProto:",
            "    \"\"\"Create an external tensor.",
            "",
            "    Arguments:",
            "        location: unique identifier (not necessary a path)",
            "        tensor_name: tensor name in the graph",
            "        tensor_type: onnx type",
            "        shape: shape the of the initializer",
            "",
            "    Returns:",
            "        the created tensor",
            "    \"\"\"",
            "    tensor_location = location",
            "    tensor = onnx.TensorProto()",
            "    tensor.name = tensor_name",
            "    _set_external_data(tensor, tensor_location)",
            "    tensor.data_type = tensor_type",
            "    tensor.dims.extend(shape)",
            "    return tensor",
            "",
            "",
            "class ModelContainer:",
            "    \"\"\"Implements an API to store large tensors outside the main ModelProto,",
            "    it avoids copying large initializers when defining the model and these initializers",
            "    are never serialized through protobuf.",
            "    No tensor is stored on disk until the user explicitly saves the model.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.model_proto_: onnx.ModelProto | None = None",
            "        self.large_initializers: dict[str, np.ndarray] = {}",
            "",
            "    def check_model(self):",
            "        if self.model_proto is not None:",
            "            onnx.checker.check_model(self.model_proto)",
            "",
            "    def __getitem__(self, name: str) -> np.ndarray:",
            "        \"\"\"Returns an external tensor given its name.\"\"\"",
            "        if name not in self.large_initializers:",
            "            raise ValueError(",
            "                f\"Unable to find large tensor {name!r} among {sorted(self.large_initializers)}.\"",
            "            )",
            "        return self.large_initializers[name]",
            "",
            "    @property",
            "    def model_proto(self) -> onnx.ModelProto:",
            "        if self.model_proto_ is None:",
            "            raise RuntimeError(\"ModelContainer is empty.\")",
            "        return self.model_proto_",
            "",
            "    @model_proto.setter",
            "    def model_proto(self, model_proto: onnx.ModelProto):",
            "        self.model_proto_ = model_proto",
            "        self.graphs_ = list(self.enumerate_graph_protos())",
            "",
            "    def enumerate_graph_protos(self) -> Iterable[onnx.GraphProto]:",
            "        \"\"\"Enumerates all GraphProtos in a model.\"\"\"",
            "        yield self.model_proto.graph",
            "        yield from _enumerate_subgraphs(self.model_proto.graph)",
            "",
            "    def is_in_memory_external_initializer(self, name: str) -> bool:",
            "        \"\"\"Tells if an initializer name is an external initializer stored in memory.",
            "        The name must start with '#' in that case.",
            "        \"\"\"",
            "        return name.startswith(\"#\")",
            "",
            "    def set_large_initializers(self, large_initializers: dict[str, np.ndarray]):",
            "        \"\"\"Adds all large tensors (not stored in the model).\"\"\"",
            "        for k in large_initializers:",
            "            if not self.is_in_memory_external_initializer(k):",
            "                raise ValueError(",
            "                    f\"The location {k!r} must start with '#' to be ignored by check model.\"",
            "                )",
            "        self.large_initializers = large_initializers",
            "",
            "    def check_large_initializers(self):",
            "        for tensor in ext_data._get_all_tensors(self.model_proto):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "            prop: onnx.StringStringEntryProto | None = None",
            "            for ext in tensor.external_data:  # type: ignore[assignment]",
            "                if ext.key == \"location\":  # type: ignore[attr-defined]",
            "                    prop = ext",
            "            if prop is None:",
            "                raise RuntimeError(",
            "                    f\"No location found for tensor name {tensor.name!r}.\"",
            "                )",
            "            if prop.value not in self.large_initializers:",
            "                raise RuntimeError(",
            "                    f\"Unable to find large tensor named {tensor.name!r} \"",
            "                    f\"with location {prop.value!r} in \"",
            "                    f\"{sorted(self.large_initializers)}.\"",
            "                )",
            "",
            "    def _save_external(",
            "        self, file_path: str, all_tensors_to_one_file: bool",
            "    ) -> onnx.ModelProto:",
            "        \"\"\"Save the large model into a main onnx file and one file",
            "        per tensor. Follows the same format as :func:`write_external_data_tensors",
            "        <onnx.external_data_helper.write_external_data_tensors>`.",
            "        The main model needs to be modified to update the file location,",
            "        the function returns this modified copy.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            all_tensors_to_one_file: all tensors in one file",
            "",
            "        Returns:",
            "            modified main model proto",
            "        \"\"\"",
            "",
            "        def _clean_name(prefix: str, name: str, unique_names: dict[str, int]) -> str:",
            "            if prefix:",
            "                name = f\"{prefix}-{name}\"",
            "            for c in \":/\\\\;,!\":",
            "                name = name.replace(c, \"\")",
            "            base_name = name",
            "            if name in unique_names:",
            "                i = unique_names[name] + 1",
            "                unique_names[name] = i",
            "                return f\"{base_name}_{i}\"",
            "            unique_names[name] = 1",
            "            return name",
            "",
            "        unique_names: dict[str, int] = {}",
            "        folder = os.path.dirname(file_path)",
            "        if not os.path.exists(folder):",
            "            raise FileNotFoundError(f\"Folder {folder!r} does not exist.\")",
            "        proto = self.model_proto.SerializeToString()",
            "        copy = onnx.ModelProto()",
            "        copy.ParseFromString(proto)",
            "        prefix = os.path.splitext(os.path.split(file_path)[-1])[0]",
            "",
            "        if all_tensors_to_one_file:",
            "            file_weight = f\"{os.path.split(file_path)[1]}.weight\"",
            "            full_file_weight = f\"{file_path}.weight\"",
            "            offset = 0",
            "            with open(full_file_weight, \"wb\") as f:",
            "                pass",
            "",
            "        for tensor in ext_data._get_all_tensors(copy):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "            prop: onnx.StringStringEntryProto | None = None",
            "            for ext in tensor.external_data:  # type: ignore[assignment]",
            "                if ext.key == \"location\":  # type: ignore[attr-defined]",
            "                    prop = ext  # type: ignore[assignment]",
            "            if prop is None:",
            "                raise RuntimeError(",
            "                    f\"No location found for tensor name {tensor.name!r}.\"",
            "                )",
            "            if prop.value not in self.large_initializers:",
            "                raise RuntimeError(",
            "                    f\"Unable to find large tensor named {tensor.name!r} \"",
            "                    f\"with location {prop.value!r} in \"",
            "                    f\"{sorted(self.large_initializers)}.\"",
            "                )",
            "            np_tensor = self.large_initializers[prop.value]",
            "",
            "            if sys.byteorder == \"big\":",
            "                # Convert endian from little to big",
            "                tensor_bytes = np_tensor.byteswap().tobytes()",
            "            else:",
            "                tensor_bytes = np_tensor.tobytes()",
            "            if all_tensors_to_one_file:",
            "                _set_external_data(",
            "                    tensor,",
            "                    location=file_weight,",
            "                    offset=offset,",
            "                    length=len(tensor_bytes),",
            "                )",
            "                offset += len(tensor_bytes)",
            "                with open(full_file_weight, \"ab\") as f:",
            "                    f.write(tensor_bytes)",
            "            else:",
            "                name = f\"{_clean_name(prefix, prop.value, unique_names)}.weight\"",
            "                _set_external_data(tensor, location=name)",
            "                full_name = os.path.join(folder, name)",
            "                prop.value = name",
            "                with open(full_name, \"wb\") as f:",
            "                    f.write(tensor_bytes)",
            "",
            "        with open(file_path, \"wb\") as f:",
            "            f.write(copy.SerializeToString())",
            "        return copy",
            "",
            "    def save(",
            "        self,",
            "        file_path: str,",
            "        all_tensors_to_one_file: bool = False,",
            "    ) -> onnx.ModelProto:",
            "        \"\"\"Save the large model.",
            "        The function returns a ModelProto,",
            "        the current one if the model did not need any modification,",
            "        a modified copy of it if it required changes such as giving file names",
            "        to every external tensor.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            all_tensors_to_one_file: saves all large tensors in one file or",
            "                one file per lerge tensor",
            "",
            "        Returns:",
            "            the saved ModelProto",
            "        \"\"\"",
            "        return self._save_external(",
            "            file_path, all_tensors_to_one_file=all_tensors_to_one_file",
            "        )",
            "",
            "    def load(self, file_path: str, load_large_initializers: bool = True):",
            "        \"\"\"Load the large model.",
            "",
            "        Arguments:",
            "            file_path: model file",
            "            load_large_initializers: loads the large initializers,",
            "                if not done, the model is incomplete but it can be used to",
            "                look into the model without executing it and method",
            "                :meth:`_load_large_initializers` can be used to load them later",
            "        \"\"\"",
            "        self.model_proto_ = onnx.load_model(file_path, load_external_data=False)",
            "        if load_large_initializers:",
            "            self._load_large_initializers(file_path)",
            "",
            "    def _load_large_initializers(self, file_path):",
            "        \"\"\"Loads large initializers.",
            "",
            "        Arguments:",
            "            file_path: model file, the weight are expected to be in the same folder as this file",
            "        \"\"\"",
            "        if self.model_proto_ is None:",
            "            raise RuntimeError(\"A model must be loaded before loading the weights.\")",
            "        self.large_initializers = {}",
            "        base_dir = os.path.dirname(file_path)",
            "        for i, tensor in enumerate(ext_data._get_all_tensors(self.model_proto_)):",
            "            if not ext_data.uses_external_data(tensor):",
            "                continue",
            "",
            "            info = ext_data.ExternalDataInfo(tensor)",
            "            external_data_file_path = c_checker._resolve_external_data_location(  # type: ignore[attr-defined]",
            "                base_dir, info.location, tensor.name",
            "            )",
            "            key = f\"#t{i}\"",
            "            _set_external_data(tensor, location=key)",
            "",
            "            with open(external_data_file_path, \"rb\") as data_file:",
            "                if info.offset:",
            "                    data_file.seek(info.offset)",
            "",
            "                raw_data = (",
            "                    data_file.read(info.length) if info.length else data_file.read()",
            "                )",
            "",
            "                dtype = onnx.helper.tensor_dtype_to_np_dtype(tensor.data_type)",
            "                shape = tuple(tensor.dims)",
            "",
            "                if sys.byteorder == \"big\":",
            "                    np_tensor = (",
            "                        np.frombuffer(raw_data, dtype=dtype).byteswap().reshape(shape)",
            "                    )",
            "                else:",
            "                    np_tensor = np.frombuffer(raw_data, dtype=dtype).reshape(shape)",
            "",
            "                self.large_initializers[key] = np_tensor",
            "",
            "",
            "def make_large_model(",
            "    graph: onnx.GraphProto,",
            "    large_initializers: dict[str, np.ndarray] | None = None,",
            "    **kwargs: Any,",
            ") -> ModelContainer:",
            "    \"\"\"Construct a ModelContainer",
            "",
            "    C API and Python API of protobuf do not operate without serializing",
            "    the protos. This function uses the Python API of ModelContainer.",
            "",
            "    Arguments:",
            "        graph: *make_graph* returns",
            "        large_initializers: dictionary `name: large tensor`,",
            "            large tensor is any python object supporting the DLPack protocol,",
            "            the ownership the tensor is transferred to the ModelContainer,",
            "            the tensor must define method `tobytes` like numpy tensors",
            "        **kwargs: any attribute to add to the returned instance",
            "",
            "    Returns:",
            "        ModelContainer",
            "    \"\"\"",
            "    model = onnx.helper.make_model(graph, **kwargs)",
            "    large_model = ModelContainer()",
            "    large_model.model_proto = model",
            "    if large_initializers:",
            "        large_model.set_large_initializers(large_initializers)",
            "        large_model.check_large_initializers()",
            "    return large_model"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "291": [
                "ModelContainer",
                "_load_large_initializers"
            ],
            "292": [
                "ModelContainer",
                "_load_large_initializers"
            ]
        },
        "addLocation": []
    },
    "onnx/test/test_external_data.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " # SPDX-License-Identifier: Apache-2.0"
            },
            "1": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from __future__ import annotations"
            },
            "2": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 6,
                "PatchRowcode": "+import itertools"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " import os"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " import pathlib"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " import tempfile"
            },
            "7": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 205,
                "PatchRowcode": "         attribute_tensor = new_model.graph.node[0].attribute[0].t"
            },
            "8": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "         np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)"
            },
            "9": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 207,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+    @parameterized.parameterized.expand(itertools.product((True, False), (True, False)))"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+    def test_save_external_invalid_single_file_data_and_check("
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+        self, use_absolute_path: bool, use_model_path: bool"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+    ) -> None:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+        model = onnx.load_model(self.model_filename, self.serialization_format)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+        model_dir = os.path.join(self.temp_dir, \"save_copy\")"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+        os.mkdir(model_dir)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 217,
                "PatchRowcode": "+        traversal_external_data_dir = os.path.join("
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+            self.temp_dir, \"invlid_external_data\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+        )"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+        os.mkdir(traversal_external_data_dir)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+        if use_absolute_path:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+            traversal_external_data_location = os.path.join("
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 224,
                "PatchRowcode": "+                traversal_external_data_dir, \"tensors.bin\""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 225,
                "PatchRowcode": "+            )"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+        else:"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 227,
                "PatchRowcode": "+            traversal_external_data_location = \"../invlid_external_data/tensors.bin\""
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 229,
                "PatchRowcode": "+        external_data_dir = os.path.join(self.temp_dir, \"external_data\")"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+        os.mkdir(external_data_dir)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+        new_model_filepath = os.path.join(model_dir, \"model.onnx\")"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+        def convert_model_to_external_data_no_check(model: ModelProto, location: str):"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+            for tensor in model.graph.initializer:"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+                if tensor.HasField(\"raw_data\"):"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 236,
                "PatchRowcode": "+                    set_external_data(tensor, location)"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+        convert_model_to_external_data_no_check("
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+            model,"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+            location=traversal_external_data_location,"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+        )"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+        onnx.save_model(model, new_model_filepath, self.serialization_format)"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+        if use_model_path:"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+            with self.assertRaises(onnx.checker.ValidationError):"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+                _ = onnx.load_model(new_model_filepath, self.serialization_format)"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+        else:"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+            onnx_model = onnx.load_model("
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+                new_model_filepath, self.serialization_format, load_external_data=False"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+            )"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+            with self.assertRaises(onnx.checker.ValidationError):"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+                load_external_data_for_model(onnx_model, external_data_dir)"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+"
            },
            "56": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 254,
                "PatchRowcode": " "
            },
            "57": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 255,
                "PatchRowcode": " @parameterized.parameterized_class("
            },
            "58": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 256,
                "PatchRowcode": "     ["
            }
        },
        "frontPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "",
            "# SPDX-License-Identifier: Apache-2.0",
            "from __future__ import annotations",
            "",
            "import os",
            "import pathlib",
            "import tempfile",
            "import unittest",
            "import uuid",
            "from typing import Any",
            "",
            "import numpy as np",
            "import parameterized",
            "",
            "import onnx",
            "from onnx import ModelProto, TensorProto, checker, helper, shape_inference",
            "from onnx.external_data_helper import (",
            "    convert_model_from_external_data,",
            "    convert_model_to_external_data,",
            "    load_external_data_for_model,",
            "    load_external_data_for_tensor,",
            "    set_external_data,",
            ")",
            "from onnx.numpy_helper import from_array, to_array",
            "",
            "",
            "class TestLoadExternalDataBase(unittest.TestCase):",
            "    \"\"\"Base class for testing external data related behaviors.",
            "",
            "    Subclasses should be parameterized with a serialization format.",
            "    \"\"\"",
            "",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512",
            "        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256",
            "        self.model_filename = self.create_test_model()",
            "",
            "    def tearDown(self) -> None:",
            "        self._temp_dir_obj.cleanup()",
            "",
            "    def get_temp_model_filename(self) -> str:",
            "        return os.path.join(self.temp_dir, str(uuid.uuid4()) + \".onnx\")",
            "",
            "    def create_external_data_tensor(",
            "        self, value: list[Any], tensor_name: str, location: str = \"\"",
            "    ) -> TensorProto:",
            "        tensor = from_array(np.array(value))",
            "        tensor.name = tensor_name",
            "        tensor_filename = location or f\"{tensor_name}.bin\"",
            "        set_external_data(tensor, location=tensor_filename)",
            "",
            "        with open(os.path.join(self.temp_dir, tensor_filename), \"wb\") as data_file:",
            "            data_file.write(tensor.raw_data)",
            "        tensor.ClearField(\"raw_data\")",
            "        tensor.data_location = onnx.TensorProto.EXTERNAL",
            "        return tensor",
            "",
            "    def create_test_model(self, location: str = \"\") -> str:",
            "        constant_node = onnx.helper.make_node(",
            "            \"Constant\",",
            "            inputs=[],",
            "            outputs=[\"values\"],",
            "            value=self.create_external_data_tensor(",
            "                self.attribute_value, \"attribute_value\"  # type: ignore[arg-type]",
            "            ),",
            "        )",
            "",
            "        initializers = [",
            "            self.create_external_data_tensor(",
            "                self.initializer_value, \"input_value\", location  # type: ignore[arg-type]",
            "            )",
            "        ]",
            "        inputs = [",
            "            helper.make_tensor_value_info(",
            "                \"input_value\", onnx.TensorProto.FLOAT, self.initializer_value.shape",
            "            )",
            "        ]",
            "",
            "        graph = helper.make_graph(",
            "            [constant_node],",
            "            \"test_graph\",",
            "            inputs=inputs,",
            "            outputs=[],",
            "            initializer=initializers,",
            "        )",
            "        model = helper.make_model(graph)",
            "",
            "        model_filename = os.path.join(self.temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, model_filename, self.serialization_format)",
            "",
            "        return model_filename",
            "",
            "    def test_check_model(self) -> None:",
            "        if self.serialization_format != \"protobuf\":",
            "            self.skipTest(",
            "                \"check_model supports protobuf only as binary when provided as a path\"",
            "            )",
            "        checker.check_model(self.model_filename)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestLoadExternalData(TestLoadExternalDataBase):",
            "    def test_load_external_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_load_external_data_for_model(self) -> None:",
            "        model = onnx.load_model(",
            "            self.model_filename, self.serialization_format, load_external_data=False",
            "        )",
            "        load_external_data_for_model(model, self.temp_dir)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_external_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        temp_dir = os.path.join(self.temp_dir, \"save_copy\")",
            "        os.mkdir(temp_dir)",
            "        new_model_filename = os.path.join(temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, new_model_filename, self.serialization_format)",
            "",
            "        new_model = onnx.load_model(new_model_filename, self.serialization_format)",
            "        initializer_tensor = new_model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = new_model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestLoadExternalDataSingleFile(TestLoadExternalDataBase):",
            "    def create_external_data_tensors(",
            "        self, tensors_data: list[tuple[list[Any], Any]]",
            "    ) -> list[TensorProto]:",
            "        tensor_filename = \"tensors.bin\"",
            "        tensors = []",
            "",
            "        with open(os.path.join(self.temp_dir, tensor_filename), \"ab\") as data_file:",
            "            for value, tensor_name in tensors_data:",
            "                tensor = from_array(np.array(value))",
            "                offset = data_file.tell()",
            "                if offset % 4096 != 0:",
            "                    data_file.write(b\"\\0\" * (4096 - offset % 4096))",
            "                    offset = offset + 4096 - offset % 4096",
            "",
            "                data_file.write(tensor.raw_data)",
            "                set_external_data(",
            "                    tensor,",
            "                    location=tensor_filename,",
            "                    offset=offset,",
            "                    length=data_file.tell() - offset,",
            "                )",
            "                tensor.name = tensor_name",
            "                tensor.ClearField(\"raw_data\")",
            "                tensor.data_location = onnx.TensorProto.EXTERNAL",
            "                tensors.append(tensor)",
            "",
            "        return tensors",
            "",
            "    def test_load_external_single_file_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_external_single_file_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        temp_dir = os.path.join(self.temp_dir, \"save_copy\")",
            "        os.mkdir(temp_dir)",
            "        new_model_filename = os.path.join(temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, new_model_filename, self.serialization_format)",
            "",
            "        new_model = onnx.load_model(new_model_filename, self.serialization_format)",
            "        initializer_tensor = new_model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = new_model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestSaveAllTensorsAsExternalData(unittest.TestCase):",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512",
            "        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256",
            "        self.model = self.create_test_model_proto()",
            "",
            "    def get_temp_model_filename(self):",
            "        return os.path.join(self.temp_dir, str(uuid.uuid4()) + \".onnx\")",
            "",
            "    def create_data_tensors(",
            "        self, tensors_data: list[tuple[list[Any], Any]]",
            "    ) -> list[TensorProto]:",
            "        tensors = []",
            "        for value, tensor_name in tensors_data:",
            "            tensor = from_array(np.array(value))",
            "            tensor.name = tensor_name",
            "            tensors.append(tensor)",
            "",
            "        return tensors",
            "",
            "    def create_test_model_proto(self) -> ModelProto:",
            "        tensors = self.create_data_tensors(",
            "            [",
            "                (self.attribute_value, \"attribute_value\"),  # type: ignore[list-item]",
            "                (self.initializer_value, \"input_value\"),  # type: ignore[list-item]",
            "            ]",
            "        )",
            "",
            "        constant_node = onnx.helper.make_node(",
            "            \"Constant\", inputs=[], outputs=[\"values\"], value=tensors[0]",
            "        )",
            "",
            "        inputs = [",
            "            helper.make_tensor_value_info(",
            "                \"input_value\", onnx.TensorProto.FLOAT, self.initializer_value.shape",
            "            )",
            "        ]",
            "",
            "        graph = helper.make_graph(",
            "            [constant_node],",
            "            \"test_graph\",",
            "            inputs=inputs,",
            "            outputs=[],",
            "            initializer=[tensors[1]],",
            "        )",
            "        return helper.make_model(graph)",
            "",
            "    @unittest.skipIf(",
            "        serialization_format != \"protobuf\",",
            "        \"check_model supports protobuf only when provided as a path\",",
            "    )",
            "    def test_check_model(self) -> None:",
            "        checker.check_model(self.model)",
            "",
            "    def test_convert_model_to_external_data_with_size_threshold(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(self.model, size_threshold=1024)",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(initializer_tensor.HasField(\"data_location\"))",
            "",
            "    def test_convert_model_to_external_data_without_size_threshold(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        convert_model_to_external_data(self.model, size_threshold=0)",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        external_data_file = str(uuid.uuid4())",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=True,",
            "            location=external_data_file,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, external_data_file)))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        # test convert model from external data",
            "        convert_model_from_external_data(model)",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(model, model_file_path, self.serialization_format)",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(len(initializer_tensor.external_data))",
            "        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(len(attribute_tensor.external_data))",
            "        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model, size_threshold=0, all_tensors_to_one_file=True",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, model_file_path)))",
            "",
            "    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=False,",
            "            convert_attribute=False,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertFalse(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=False,",
            "            convert_attribute=True,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "    def test_convert_model_to_external_data_does_not_convert_attribute_values(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "            all_tensors_to_one_file=False,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertFalse(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model, size_threshold=0, convert_attribute=True",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "        self.assertTrue(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=False,",
            "        )",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_save_model_does_convert_and_saves_the_model(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_model_without_loading_external_data(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "        # Save without load_external_data",
            "        model = onnx.load_model(",
            "            model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        onnx.save_model(",
            "            model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "        # Load the saved model again; Only works if the saved path is under the same directory",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_model_with_existing_raw_data_should_override(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        original_raw_data = self.model.graph.initializer[0].raw_data",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            size_threshold=0,",
            "        )",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "",
            "        model = onnx.load_model(",
            "            model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        initializer_tensor = model.graph.initializer[0]",
            "        initializer_tensor.raw_data = b\"dummpy_raw_data\"",
            "        # If raw_data and external tensor exist at the same time, override existing raw_data",
            "        load_external_data_for_tensor(initializer_tensor, self.temp_dir)",
            "        self.assertEqual(initializer_tensor.raw_data, original_raw_data)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestExternalDataToArray(unittest.TestCase):",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self._model_file_path: str = os.path.join(self.temp_dir, \"model.onnx\")",
            "        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)",
            "        self.small_data = (200, 300)",
            "        self.model = self.create_test_model()",
            "",
            "    @property",
            "    def model_file_path(self):",
            "        return self._model_file_path",
            "",
            "    def tearDown(self) -> None:",
            "        self._temp_dir_obj.cleanup()",
            "",
            "    def create_test_model(self) -> ModelProto:",
            "        X = helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, self.large_data.shape)",
            "        input_init = helper.make_tensor(",
            "            name=\"X\",",
            "            data_type=TensorProto.FLOAT,",
            "            dims=self.large_data.shape,",
            "            vals=self.large_data.tobytes(),",
            "            raw=True,",
            "        )",
            "",
            "        shape_data = np.array(self.small_data, np.int64)",
            "        shape_init = helper.make_tensor(",
            "            name=\"Shape\",",
            "            data_type=TensorProto.INT64,",
            "            dims=shape_data.shape,",
            "            vals=shape_data.tobytes(),",
            "            raw=True,",
            "        )",
            "        C = helper.make_tensor_value_info(\"C\", TensorProto.INT64, self.small_data)",
            "",
            "        reshape = onnx.helper.make_node(",
            "            \"Reshape\",",
            "            inputs=[\"X\", \"Shape\"],",
            "            outputs=[\"Y\"],",
            "        )",
            "        cast = onnx.helper.make_node(",
            "            \"Cast\", inputs=[\"Y\"], outputs=[\"C\"], to=TensorProto.INT64",
            "        )",
            "",
            "        graph_def = helper.make_graph(",
            "            [reshape, cast],",
            "            \"test-model\",",
            "            [X],",
            "            [C],",
            "            initializer=[input_init, shape_init],",
            "        )",
            "        model = helper.make_model(graph_def, producer_name=\"onnx-example\")",
            "        return model",
            "",
            "    @unittest.skipIf(",
            "        serialization_format != \"protobuf\",",
            "        \"check_model supports protobuf only when provided as a path\",",
            "    )",
            "    def test_check_model(self) -> None:",
            "        checker.check_model(self.model)",
            "",
            "    def test_reshape_inference_with_external_data_fail(self) -> None:",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            size_threshold=0,",
            "        )",
            "        model_without_external_data = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        # Shape inference of Reshape uses ParseData",
            "        # ParseData cannot handle external data and should throw the error as follows:",
            "        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape",
            "        self.assertRaises(",
            "            shape_inference.InferenceError,",
            "            shape_inference.infer_shapes,",
            "            model_without_external_data,",
            "            strict_mode=True,",
            "        )",
            "",
            "    def test_to_array_with_external_data(self) -> None:",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            size_threshold=0,",
            "        )",
            "        # raw_data of external tensor is not loaded",
            "        model = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        # Specify self.temp_dir to load external tensor",
            "        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)",
            "        np.testing.assert_allclose(loaded_large_data, self.large_data)",
            "",
            "    def test_save_model_with_external_data_multiple_times(self) -> None:",
            "        # Test onnx.save should respectively handle typical tensor and external tensor properly",
            "        # 1st save: save two tensors which have raw_data",
            "        # Only w_large will be stored as external tensors since it's larger than 1024",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            location=None,",
            "            size_threshold=1024,",
            "            convert_attribute=True,",
            "        )",
            "        model_without_loading_external = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        large_input_tensor = model_without_loading_external.graph.initializer[0]",
            "        self.assertTrue(large_input_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(large_input_tensor, self.temp_dir), self.large_data",
            "        )",
            "",
            "        small_shape_tensor = model_without_loading_external.graph.initializer[1]",
            "        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(small_shape_tensor), self.small_data)",
            "",
            "        # 2nd save: one tensor has raw_data (small); one external tensor (large)",
            "        # Save them both as external tensors this time",
            "        onnx.save_model(",
            "            model_without_loading_external,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=True,",
            "        )",
            "",
            "        model_without_loading_external = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        large_input_tensor = model_without_loading_external.graph.initializer[0]",
            "        self.assertTrue(large_input_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(large_input_tensor, self.temp_dir), self.large_data",
            "        )",
            "",
            "        small_shape_tensor = model_without_loading_external.graph.initializer[1]",
            "        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(small_shape_tensor, self.temp_dir), self.small_data",
            "        )",
            "",
            "",
            "class TestNotAllowToLoadExternalDataOutsideModelDirectory(TestLoadExternalDataBase):",
            "    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model",
            "    directory.",
            "    \"\"\"",
            "",
            "    def create_external_data_tensor(",
            "        self, value: list[Any], tensor_name: str, location: str = \"\"",
            "    ) -> TensorProto:",
            "        tensor = from_array(np.array(value))",
            "        tensor.name = tensor_name",
            "        tensor_filename = location or f\"{tensor_name}.bin\"",
            "",
            "        set_external_data(tensor, location=tensor_filename)",
            "",
            "        tensor.ClearField(\"raw_data\")",
            "        tensor.data_location = onnx.TensorProto.EXTERNAL",
            "        return tensor",
            "",
            "    def test_check_model(self) -> None:",
            "        \"\"\"We only test the model validation as onnxruntime uses this to load the model.\"\"\"",
            "        self.model_filename = self.create_test_model(\"../../file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_relative(self) -> None:",
            "        \"\"\"More relative path test.\"\"\"",
            "        self.model_filename = self.create_test_model(\"../test/../file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_absolute(self) -> None:",
            "        \"\"\"ONNX checker disallows using absolute path as location in external tensor.\"\"\"",
            "        self.model_filename = self.create_test_model(\"//file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "",
            "@unittest.skipIf(os.name != \"nt\", reason=\"Skip Windows test\")",
            "class TestNotAllowToLoadExternalDataOutsideModelDirectoryOnWindows(",
            "    TestNotAllowToLoadExternalDataOutsideModelDirectory",
            "):",
            "    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model",
            "    directory.",
            "    \"\"\"",
            "",
            "    def test_check_model(self) -> None:",
            "        \"\"\"We only test the model validation as onnxruntime uses this to load the model.\"\"\"",
            "        self.model_filename = self.create_test_model(\"..\\\\..\\\\file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_relative(self) -> None:",
            "        \"\"\"More relative path test.\"\"\"",
            "        self.model_filename = self.create_test_model(\"..\\\\test\\\\..\\\\file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_absolute(self) -> None:",
            "        \"\"\"ONNX checker disallows using absolute path as location in external tensor.\"\"\"",
            "        self.model_filename = self.create_test_model(\"C:/file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "",
            "class TestSaveAllTensorsAsExternalDataWithPath(TestSaveAllTensorsAsExternalData):",
            "    def get_temp_model_filename(self) -> pathlib.Path:",
            "        return pathlib.Path(super().get_temp_model_filename())",
            "",
            "",
            "class TestExternalDataToArrayWithPath(TestExternalDataToArray):",
            "    @property",
            "    def model_file_path(self) -> pathlib.Path:",
            "        return pathlib.Path(self._model_file_path)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    unittest.main()"
        ],
        "afterPatchFile": [
            "# Copyright (c) ONNX Project Contributors",
            "",
            "# SPDX-License-Identifier: Apache-2.0",
            "from __future__ import annotations",
            "",
            "import itertools",
            "import os",
            "import pathlib",
            "import tempfile",
            "import unittest",
            "import uuid",
            "from typing import Any",
            "",
            "import numpy as np",
            "import parameterized",
            "",
            "import onnx",
            "from onnx import ModelProto, TensorProto, checker, helper, shape_inference",
            "from onnx.external_data_helper import (",
            "    convert_model_from_external_data,",
            "    convert_model_to_external_data,",
            "    load_external_data_for_model,",
            "    load_external_data_for_tensor,",
            "    set_external_data,",
            ")",
            "from onnx.numpy_helper import from_array, to_array",
            "",
            "",
            "class TestLoadExternalDataBase(unittest.TestCase):",
            "    \"\"\"Base class for testing external data related behaviors.",
            "",
            "    Subclasses should be parameterized with a serialization format.",
            "    \"\"\"",
            "",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512",
            "        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256",
            "        self.model_filename = self.create_test_model()",
            "",
            "    def tearDown(self) -> None:",
            "        self._temp_dir_obj.cleanup()",
            "",
            "    def get_temp_model_filename(self) -> str:",
            "        return os.path.join(self.temp_dir, str(uuid.uuid4()) + \".onnx\")",
            "",
            "    def create_external_data_tensor(",
            "        self, value: list[Any], tensor_name: str, location: str = \"\"",
            "    ) -> TensorProto:",
            "        tensor = from_array(np.array(value))",
            "        tensor.name = tensor_name",
            "        tensor_filename = location or f\"{tensor_name}.bin\"",
            "        set_external_data(tensor, location=tensor_filename)",
            "",
            "        with open(os.path.join(self.temp_dir, tensor_filename), \"wb\") as data_file:",
            "            data_file.write(tensor.raw_data)",
            "        tensor.ClearField(\"raw_data\")",
            "        tensor.data_location = onnx.TensorProto.EXTERNAL",
            "        return tensor",
            "",
            "    def create_test_model(self, location: str = \"\") -> str:",
            "        constant_node = onnx.helper.make_node(",
            "            \"Constant\",",
            "            inputs=[],",
            "            outputs=[\"values\"],",
            "            value=self.create_external_data_tensor(",
            "                self.attribute_value, \"attribute_value\"  # type: ignore[arg-type]",
            "            ),",
            "        )",
            "",
            "        initializers = [",
            "            self.create_external_data_tensor(",
            "                self.initializer_value, \"input_value\", location  # type: ignore[arg-type]",
            "            )",
            "        ]",
            "        inputs = [",
            "            helper.make_tensor_value_info(",
            "                \"input_value\", onnx.TensorProto.FLOAT, self.initializer_value.shape",
            "            )",
            "        ]",
            "",
            "        graph = helper.make_graph(",
            "            [constant_node],",
            "            \"test_graph\",",
            "            inputs=inputs,",
            "            outputs=[],",
            "            initializer=initializers,",
            "        )",
            "        model = helper.make_model(graph)",
            "",
            "        model_filename = os.path.join(self.temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, model_filename, self.serialization_format)",
            "",
            "        return model_filename",
            "",
            "    def test_check_model(self) -> None:",
            "        if self.serialization_format != \"protobuf\":",
            "            self.skipTest(",
            "                \"check_model supports protobuf only as binary when provided as a path\"",
            "            )",
            "        checker.check_model(self.model_filename)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestLoadExternalData(TestLoadExternalDataBase):",
            "    def test_load_external_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_load_external_data_for_model(self) -> None:",
            "        model = onnx.load_model(",
            "            self.model_filename, self.serialization_format, load_external_data=False",
            "        )",
            "        load_external_data_for_model(model, self.temp_dir)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_external_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        temp_dir = os.path.join(self.temp_dir, \"save_copy\")",
            "        os.mkdir(temp_dir)",
            "        new_model_filename = os.path.join(temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, new_model_filename, self.serialization_format)",
            "",
            "        new_model = onnx.load_model(new_model_filename, self.serialization_format)",
            "        initializer_tensor = new_model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = new_model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestLoadExternalDataSingleFile(TestLoadExternalDataBase):",
            "    def create_external_data_tensors(",
            "        self, tensors_data: list[tuple[list[Any], Any]]",
            "    ) -> list[TensorProto]:",
            "        tensor_filename = \"tensors.bin\"",
            "        tensors = []",
            "",
            "        with open(os.path.join(self.temp_dir, tensor_filename), \"ab\") as data_file:",
            "            for value, tensor_name in tensors_data:",
            "                tensor = from_array(np.array(value))",
            "                offset = data_file.tell()",
            "                if offset % 4096 != 0:",
            "                    data_file.write(b\"\\0\" * (4096 - offset % 4096))",
            "                    offset = offset + 4096 - offset % 4096",
            "",
            "                data_file.write(tensor.raw_data)",
            "                set_external_data(",
            "                    tensor,",
            "                    location=tensor_filename,",
            "                    offset=offset,",
            "                    length=data_file.tell() - offset,",
            "                )",
            "                tensor.name = tensor_name",
            "                tensor.ClearField(\"raw_data\")",
            "                tensor.data_location = onnx.TensorProto.EXTERNAL",
            "                tensors.append(tensor)",
            "",
            "        return tensors",
            "",
            "    def test_load_external_single_file_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_external_single_file_data(self) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        temp_dir = os.path.join(self.temp_dir, \"save_copy\")",
            "        os.mkdir(temp_dir)",
            "        new_model_filename = os.path.join(temp_dir, \"model.onnx\")",
            "        onnx.save_model(model, new_model_filename, self.serialization_format)",
            "",
            "        new_model = onnx.load_model(new_model_filename, self.serialization_format)",
            "        initializer_tensor = new_model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = new_model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    @parameterized.parameterized.expand(itertools.product((True, False), (True, False)))",
            "    def test_save_external_invalid_single_file_data_and_check(",
            "        self, use_absolute_path: bool, use_model_path: bool",
            "    ) -> None:",
            "        model = onnx.load_model(self.model_filename, self.serialization_format)",
            "",
            "        model_dir = os.path.join(self.temp_dir, \"save_copy\")",
            "        os.mkdir(model_dir)",
            "",
            "        traversal_external_data_dir = os.path.join(",
            "            self.temp_dir, \"invlid_external_data\"",
            "        )",
            "        os.mkdir(traversal_external_data_dir)",
            "",
            "        if use_absolute_path:",
            "            traversal_external_data_location = os.path.join(",
            "                traversal_external_data_dir, \"tensors.bin\"",
            "            )",
            "        else:",
            "            traversal_external_data_location = \"../invlid_external_data/tensors.bin\"",
            "",
            "        external_data_dir = os.path.join(self.temp_dir, \"external_data\")",
            "        os.mkdir(external_data_dir)",
            "        new_model_filepath = os.path.join(model_dir, \"model.onnx\")",
            "",
            "        def convert_model_to_external_data_no_check(model: ModelProto, location: str):",
            "            for tensor in model.graph.initializer:",
            "                if tensor.HasField(\"raw_data\"):",
            "                    set_external_data(tensor, location)",
            "",
            "        convert_model_to_external_data_no_check(",
            "            model,",
            "            location=traversal_external_data_location,",
            "        )",
            "",
            "        onnx.save_model(model, new_model_filepath, self.serialization_format)",
            "        if use_model_path:",
            "            with self.assertRaises(onnx.checker.ValidationError):",
            "                _ = onnx.load_model(new_model_filepath, self.serialization_format)",
            "        else:",
            "            onnx_model = onnx.load_model(",
            "                new_model_filepath, self.serialization_format, load_external_data=False",
            "            )",
            "            with self.assertRaises(onnx.checker.ValidationError):",
            "                load_external_data_for_model(onnx_model, external_data_dir)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestSaveAllTensorsAsExternalData(unittest.TestCase):",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512",
            "        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256",
            "        self.model = self.create_test_model_proto()",
            "",
            "    def get_temp_model_filename(self):",
            "        return os.path.join(self.temp_dir, str(uuid.uuid4()) + \".onnx\")",
            "",
            "    def create_data_tensors(",
            "        self, tensors_data: list[tuple[list[Any], Any]]",
            "    ) -> list[TensorProto]:",
            "        tensors = []",
            "        for value, tensor_name in tensors_data:",
            "            tensor = from_array(np.array(value))",
            "            tensor.name = tensor_name",
            "            tensors.append(tensor)",
            "",
            "        return tensors",
            "",
            "    def create_test_model_proto(self) -> ModelProto:",
            "        tensors = self.create_data_tensors(",
            "            [",
            "                (self.attribute_value, \"attribute_value\"),  # type: ignore[list-item]",
            "                (self.initializer_value, \"input_value\"),  # type: ignore[list-item]",
            "            ]",
            "        )",
            "",
            "        constant_node = onnx.helper.make_node(",
            "            \"Constant\", inputs=[], outputs=[\"values\"], value=tensors[0]",
            "        )",
            "",
            "        inputs = [",
            "            helper.make_tensor_value_info(",
            "                \"input_value\", onnx.TensorProto.FLOAT, self.initializer_value.shape",
            "            )",
            "        ]",
            "",
            "        graph = helper.make_graph(",
            "            [constant_node],",
            "            \"test_graph\",",
            "            inputs=inputs,",
            "            outputs=[],",
            "            initializer=[tensors[1]],",
            "        )",
            "        return helper.make_model(graph)",
            "",
            "    @unittest.skipIf(",
            "        serialization_format != \"protobuf\",",
            "        \"check_model supports protobuf only when provided as a path\",",
            "    )",
            "    def test_check_model(self) -> None:",
            "        checker.check_model(self.model)",
            "",
            "    def test_convert_model_to_external_data_with_size_threshold(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(self.model, size_threshold=1024)",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(initializer_tensor.HasField(\"data_location\"))",
            "",
            "    def test_convert_model_to_external_data_without_size_threshold(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        convert_model_to_external_data(self.model, size_threshold=0)",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        external_data_file = str(uuid.uuid4())",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=True,",
            "            location=external_data_file,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, external_data_file)))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        # test convert model from external data",
            "        convert_model_from_external_data(model)",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(model, model_file_path, self.serialization_format)",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(len(initializer_tensor.external_data))",
            "        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(len(attribute_tensor.external_data))",
            "        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model, size_threshold=0, all_tensors_to_one_file=True",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, model_file_path)))",
            "",
            "    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=False,",
            "            convert_attribute=False,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertFalse(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            all_tensors_to_one_file=False,",
            "            convert_attribute=True,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "    def test_convert_model_to_external_data_does_not_convert_attribute_values(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "            all_tensors_to_one_file=False,",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        self.assertTrue(os.path.isfile(os.path.join(self.temp_dir, \"input_value\")))",
            "        self.assertFalse(os.path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "",
            "        convert_model_to_external_data(",
            "            self.model, size_threshold=0, convert_attribute=True",
            "        )",
            "        onnx.save_model(self.model, model_file_path, self.serialization_format)",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "        self.assertTrue(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(",
            "        self,",
            "    ) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=False,",
            "        )",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertFalse(initializer_tensor.HasField(\"data_location\"))",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "",
            "    def test_save_model_does_convert_and_saves_the_model(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_model_without_loading_external_data(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "        # Save without load_external_data",
            "        model = onnx.load_model(",
            "            model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        onnx.save_model(",
            "            model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=False,",
            "        )",
            "        # Load the saved model again; Only works if the saved path is under the same directory",
            "        model = onnx.load_model(model_file_path, self.serialization_format)",
            "",
            "        initializer_tensor = model.graph.initializer[0]",
            "        self.assertTrue(initializer_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(initializer_tensor), self.initializer_value)",
            "",
            "        attribute_tensor = model.graph.node[0].attribute[0].t",
            "        self.assertFalse(attribute_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(attribute_tensor), self.attribute_value)",
            "",
            "    def test_save_model_with_existing_raw_data_should_override(self) -> None:",
            "        model_file_path = self.get_temp_model_filename()",
            "        original_raw_data = self.model.graph.initializer[0].raw_data",
            "        onnx.save_model(",
            "            self.model,",
            "            model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            size_threshold=0,",
            "        )",
            "        self.assertTrue(os.path.isfile(model_file_path))",
            "",
            "        model = onnx.load_model(",
            "            model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        initializer_tensor = model.graph.initializer[0]",
            "        initializer_tensor.raw_data = b\"dummpy_raw_data\"",
            "        # If raw_data and external tensor exist at the same time, override existing raw_data",
            "        load_external_data_for_tensor(initializer_tensor, self.temp_dir)",
            "        self.assertEqual(initializer_tensor.raw_data, original_raw_data)",
            "",
            "",
            "@parameterized.parameterized_class(",
            "    [",
            "        {\"serialization_format\": \"protobuf\"},",
            "        {\"serialization_format\": \"textproto\"},",
            "    ]",
            ")",
            "class TestExternalDataToArray(unittest.TestCase):",
            "    serialization_format: str = \"protobuf\"",
            "",
            "    def setUp(self) -> None:",
            "        self._temp_dir_obj = tempfile.TemporaryDirectory()",
            "        self.temp_dir: str = self._temp_dir_obj.name",
            "        self._model_file_path: str = os.path.join(self.temp_dir, \"model.onnx\")",
            "        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)",
            "        self.small_data = (200, 300)",
            "        self.model = self.create_test_model()",
            "",
            "    @property",
            "    def model_file_path(self):",
            "        return self._model_file_path",
            "",
            "    def tearDown(self) -> None:",
            "        self._temp_dir_obj.cleanup()",
            "",
            "    def create_test_model(self) -> ModelProto:",
            "        X = helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, self.large_data.shape)",
            "        input_init = helper.make_tensor(",
            "            name=\"X\",",
            "            data_type=TensorProto.FLOAT,",
            "            dims=self.large_data.shape,",
            "            vals=self.large_data.tobytes(),",
            "            raw=True,",
            "        )",
            "",
            "        shape_data = np.array(self.small_data, np.int64)",
            "        shape_init = helper.make_tensor(",
            "            name=\"Shape\",",
            "            data_type=TensorProto.INT64,",
            "            dims=shape_data.shape,",
            "            vals=shape_data.tobytes(),",
            "            raw=True,",
            "        )",
            "        C = helper.make_tensor_value_info(\"C\", TensorProto.INT64, self.small_data)",
            "",
            "        reshape = onnx.helper.make_node(",
            "            \"Reshape\",",
            "            inputs=[\"X\", \"Shape\"],",
            "            outputs=[\"Y\"],",
            "        )",
            "        cast = onnx.helper.make_node(",
            "            \"Cast\", inputs=[\"Y\"], outputs=[\"C\"], to=TensorProto.INT64",
            "        )",
            "",
            "        graph_def = helper.make_graph(",
            "            [reshape, cast],",
            "            \"test-model\",",
            "            [X],",
            "            [C],",
            "            initializer=[input_init, shape_init],",
            "        )",
            "        model = helper.make_model(graph_def, producer_name=\"onnx-example\")",
            "        return model",
            "",
            "    @unittest.skipIf(",
            "        serialization_format != \"protobuf\",",
            "        \"check_model supports protobuf only when provided as a path\",",
            "    )",
            "    def test_check_model(self) -> None:",
            "        checker.check_model(self.model)",
            "",
            "    def test_reshape_inference_with_external_data_fail(self) -> None:",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            size_threshold=0,",
            "        )",
            "        model_without_external_data = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        # Shape inference of Reshape uses ParseData",
            "        # ParseData cannot handle external data and should throw the error as follows:",
            "        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape",
            "        self.assertRaises(",
            "            shape_inference.InferenceError,",
            "            shape_inference.infer_shapes,",
            "            model_without_external_data,",
            "            strict_mode=True,",
            "        )",
            "",
            "    def test_to_array_with_external_data(self) -> None:",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            size_threshold=0,",
            "        )",
            "        # raw_data of external tensor is not loaded",
            "        model = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        # Specify self.temp_dir to load external tensor",
            "        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)",
            "        np.testing.assert_allclose(loaded_large_data, self.large_data)",
            "",
            "    def test_save_model_with_external_data_multiple_times(self) -> None:",
            "        # Test onnx.save should respectively handle typical tensor and external tensor properly",
            "        # 1st save: save two tensors which have raw_data",
            "        # Only w_large will be stored as external tensors since it's larger than 1024",
            "        onnx.save_model(",
            "            self.model,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            location=None,",
            "            size_threshold=1024,",
            "            convert_attribute=True,",
            "        )",
            "        model_without_loading_external = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        large_input_tensor = model_without_loading_external.graph.initializer[0]",
            "        self.assertTrue(large_input_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(large_input_tensor, self.temp_dir), self.large_data",
            "        )",
            "",
            "        small_shape_tensor = model_without_loading_external.graph.initializer[1]",
            "        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(to_array(small_shape_tensor), self.small_data)",
            "",
            "        # 2nd save: one tensor has raw_data (small); one external tensor (large)",
            "        # Save them both as external tensors this time",
            "        onnx.save_model(",
            "            model_without_loading_external,",
            "            self.model_file_path,",
            "            self.serialization_format,",
            "            save_as_external_data=True,",
            "            all_tensors_to_one_file=False,",
            "            location=None,",
            "            size_threshold=0,",
            "            convert_attribute=True,",
            "        )",
            "",
            "        model_without_loading_external = onnx.load(",
            "            self.model_file_path, self.serialization_format, load_external_data=False",
            "        )",
            "        large_input_tensor = model_without_loading_external.graph.initializer[0]",
            "        self.assertTrue(large_input_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(large_input_tensor, self.temp_dir), self.large_data",
            "        )",
            "",
            "        small_shape_tensor = model_without_loading_external.graph.initializer[1]",
            "        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))",
            "        np.testing.assert_allclose(",
            "            to_array(small_shape_tensor, self.temp_dir), self.small_data",
            "        )",
            "",
            "",
            "class TestNotAllowToLoadExternalDataOutsideModelDirectory(TestLoadExternalDataBase):",
            "    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model",
            "    directory.",
            "    \"\"\"",
            "",
            "    def create_external_data_tensor(",
            "        self, value: list[Any], tensor_name: str, location: str = \"\"",
            "    ) -> TensorProto:",
            "        tensor = from_array(np.array(value))",
            "        tensor.name = tensor_name",
            "        tensor_filename = location or f\"{tensor_name}.bin\"",
            "",
            "        set_external_data(tensor, location=tensor_filename)",
            "",
            "        tensor.ClearField(\"raw_data\")",
            "        tensor.data_location = onnx.TensorProto.EXTERNAL",
            "        return tensor",
            "",
            "    def test_check_model(self) -> None:",
            "        \"\"\"We only test the model validation as onnxruntime uses this to load the model.\"\"\"",
            "        self.model_filename = self.create_test_model(\"../../file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_relative(self) -> None:",
            "        \"\"\"More relative path test.\"\"\"",
            "        self.model_filename = self.create_test_model(\"../test/../file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_absolute(self) -> None:",
            "        \"\"\"ONNX checker disallows using absolute path as location in external tensor.\"\"\"",
            "        self.model_filename = self.create_test_model(\"//file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "",
            "@unittest.skipIf(os.name != \"nt\", reason=\"Skip Windows test\")",
            "class TestNotAllowToLoadExternalDataOutsideModelDirectoryOnWindows(",
            "    TestNotAllowToLoadExternalDataOutsideModelDirectory",
            "):",
            "    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model",
            "    directory.",
            "    \"\"\"",
            "",
            "    def test_check_model(self) -> None:",
            "        \"\"\"We only test the model validation as onnxruntime uses this to load the model.\"\"\"",
            "        self.model_filename = self.create_test_model(\"..\\\\..\\\\file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_relative(self) -> None:",
            "        \"\"\"More relative path test.\"\"\"",
            "        self.model_filename = self.create_test_model(\"..\\\\test\\\\..\\\\file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "    def test_check_model_absolute(self) -> None:",
            "        \"\"\"ONNX checker disallows using absolute path as location in external tensor.\"\"\"",
            "        self.model_filename = self.create_test_model(\"C:/file.bin\")",
            "        with self.assertRaises(onnx.checker.ValidationError):",
            "            checker.check_model(self.model_filename)",
            "",
            "",
            "class TestSaveAllTensorsAsExternalDataWithPath(TestSaveAllTensorsAsExternalData):",
            "    def get_temp_model_filename(self) -> pathlib.Path:",
            "        return pathlib.Path(super().get_temp_model_filename())",
            "",
            "",
            "class TestExternalDataToArrayWithPath(TestExternalDataToArray):",
            "    @property",
            "    def model_file_path(self) -> pathlib.Path:",
            "        return pathlib.Path(self._model_file_path)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    unittest.main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "pypdf.generic._data_structures",
            "onnx.test.test_external_data.TestLoadExternalDataSingleFile.self"
        ]
    }
}