{
    "lib/ansible/cli/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " from ansible.release import __version__"
            },
            "1": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " from ansible.utils.path import unfrackpath"
            },
            "2": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " from ansible.utils.vars import load_extra_vars, load_options_vars"
            },
            "3": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from ansible.utils.unsafe_proxy import AnsibleUnsafeBytes"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+from ansible.utils.unsafe_proxy import AnsibleUnsafeText"
            },
            "5": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " from ansible.vars.manager import VariableManager"
            },
            "6": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " from ansible.parsing.vault import PromptVaultSecret, get_file_vault_secret"
            },
            "7": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": 323,
                "PatchRowcode": "             if op.ask_pass:"
            },
            "9": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 324,
                "PatchRowcode": "                 sshpass = getpass.getpass(prompt=\"SSH password: \")"
            },
            "10": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": 325,
                "PatchRowcode": "                 become_prompt = \"%s password[defaults to SSH password]: \" % become_prompt_method"
            },
            "11": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if sshpass:"
            },
            "12": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    sshpass = to_bytes(sshpass, errors='strict', nonstring='simplerepr')"
            },
            "13": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 326,
                "PatchRowcode": "             else:"
            },
            "14": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 327,
                "PatchRowcode": "                 become_prompt = \"%s password: \" % become_prompt_method"
            },
            "15": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 328,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 329,
                "PatchRowcode": "             if op.become_ask_pass:"
            },
            "17": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 330,
                "PatchRowcode": "                 becomepass = getpass.getpass(prompt=become_prompt)"
            },
            "18": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "                 if op.ask_pass and becomepass == '':"
            },
            "19": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 332,
                "PatchRowcode": "                     becomepass = sshpass"
            },
            "20": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if becomepass:"
            },
            "21": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    becomepass = to_bytes(becomepass)"
            },
            "22": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 333,
                "PatchRowcode": "         except EOFError:"
            },
            "23": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "             pass"
            },
            "24": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 335,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "         # we 'wrap' the passwords to prevent templating as"
            },
            "26": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": 337,
                "PatchRowcode": "         # they can contain special chars and trigger it incorrectly"
            },
            "27": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "         if sshpass:"
            },
            "28": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            sshpass = AnsibleUnsafeBytes(sshpass)"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+            sshpass = AnsibleUnsafeText(to_text(sshpass))"
            },
            "30": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "         if becomepass:"
            },
            "31": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            becomepass = AnsibleUnsafeBytes(becomepass)"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+            becomepass = AnsibleUnsafeText(to_text(becomepass))"
            },
            "33": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 342,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "         return (sshpass, becomepass)"
            },
            "35": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 344,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# (c) 2016, Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import getpass",
            "import operator",
            "import optparse",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import time",
            "import yaml",
            "",
            "from abc import ABCMeta, abstractmethod",
            "",
            "import ansible",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleOptionsError, AnsibleError",
            "from ansible.inventory.manager import InventoryManager",
            "from ansible.module_utils.six import with_metaclass, string_types",
            "from ansible.module_utils._text import to_bytes, to_text",
            "from ansible.parsing.dataloader import DataLoader",
            "from ansible.release import __version__",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.vars import load_extra_vars, load_options_vars",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeBytes",
            "from ansible.vars.manager import VariableManager",
            "from ansible.parsing.vault import PromptVaultSecret, get_file_vault_secret",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "class SortedOptParser(optparse.OptionParser):",
            "    '''Optparser which sorts the options by opt before outputting --help'''",
            "",
            "    def format_help(self, formatter=None, epilog=None):",
            "        self.option_list.sort(key=operator.methodcaller('get_opt_string'))",
            "        return optparse.OptionParser.format_help(self, formatter=None)",
            "",
            "",
            "# Note: Inherit from SortedOptParser so that we get our format_help method",
            "class InvalidOptsParser(SortedOptParser):",
            "    '''Ignore invalid options.",
            "",
            "    Meant for the special case where we need to take care of help and version",
            "    but may not know the full range of options yet.  (See it in use in set_action)",
            "    '''",
            "    def __init__(self, parser):",
            "        # Since this is special purposed to just handle help and version, we",
            "        # take a pre-existing option parser here and set our options from",
            "        # that.  This allows us to give accurate help based on the given",
            "        # option parser.",
            "        SortedOptParser.__init__(self, usage=parser.usage,",
            "                                 option_list=parser.option_list,",
            "                                 option_class=parser.option_class,",
            "                                 conflict_handler=parser.conflict_handler,",
            "                                 description=parser.description,",
            "                                 formatter=parser.formatter,",
            "                                 add_help_option=False,",
            "                                 prog=parser.prog,",
            "                                 epilog=parser.epilog)",
            "        self.version = parser.version",
            "",
            "    def _process_long_opt(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_long_opt(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "    def _process_short_opts(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_short_opts(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "",
            "class CLI(with_metaclass(ABCMeta, object)):",
            "    ''' code behind bin/ansible* programs '''",
            "",
            "    VALID_ACTIONS = []",
            "",
            "    _ITALIC = re.compile(r\"I\\(([^)]+)\\)\")",
            "    _BOLD = re.compile(r\"B\\(([^)]+)\\)\")",
            "    _MODULE = re.compile(r\"M\\(([^)]+)\\)\")",
            "    _URL = re.compile(r\"U\\(([^)]+)\\)\")",
            "    _CONST = re.compile(r\"C\\(([^)]+)\\)\")",
            "",
            "    PAGER = 'less'",
            "",
            "    # -F (quit-if-one-screen) -R (allow raw ansi control chars)",
            "    # -S (chop long lines) -X (disable termcap init and de-init)",
            "    LESS_OPTS = 'FRSX'",
            "    SKIP_INVENTORY_DEFAULTS = False",
            "",
            "    def __init__(self, args, callback=None):",
            "        \"\"\"",
            "        Base init method for all command line programs",
            "        \"\"\"",
            "",
            "        self.args = args",
            "        self.options = None",
            "        self.parser = None",
            "        self.action = None",
            "        self.callback = callback",
            "",
            "    def set_action(self):",
            "        \"\"\"",
            "        Get the action the user wants to execute from the sys argv list.",
            "        \"\"\"",
            "        for i in range(0, len(self.args)):",
            "            arg = self.args[i]",
            "            if arg in self.VALID_ACTIONS:",
            "                self.action = arg",
            "                del self.args[i]",
            "                break",
            "",
            "        if not self.action:",
            "            # if we're asked for help or version, we don't need an action.",
            "            # have to use a special purpose Option Parser to figure that out as",
            "            # the standard OptionParser throws an error for unknown options and",
            "            # without knowing action, we only know of a subset of the options",
            "            # that could be legal for this command",
            "            tmp_parser = InvalidOptsParser(self.parser)",
            "            tmp_options, tmp_args = tmp_parser.parse_args(self.args)",
            "            if not(hasattr(tmp_options, 'help') and tmp_options.help) or (hasattr(tmp_options, 'version') and tmp_options.version):",
            "                raise AnsibleOptionsError(\"Missing required action\")",
            "",
            "    def execute(self):",
            "        \"\"\"",
            "        Actually runs a child defined method using the execute_<action> pattern",
            "        \"\"\"",
            "        fn = getattr(self, \"execute_%s\" % self.action)",
            "        fn()",
            "",
            "    @abstractmethod",
            "    def run(self):",
            "        \"\"\"Run the ansible command",
            "",
            "        Subclasses must implement this method.  It does the actual work of",
            "        running an Ansible command.",
            "        \"\"\"",
            "",
            "        display.vv(to_text(self.parser.get_version()))",
            "",
            "        if C.CONFIG_FILE:",
            "            display.v(u\"Using %s as config file\" % to_text(C.CONFIG_FILE))",
            "        else:",
            "            display.v(u\"No config file found; using defaults\")",
            "",
            "        # warn about deprecated config options",
            "        for deprecated in C.config.DEPRECATED:",
            "            name = deprecated[0]",
            "            why = deprecated[1]['why']",
            "            if 'alternatives' in deprecated[1]:",
            "                alt = ', use %s instead' % deprecated[1]['alternatives']",
            "            else:",
            "                alt = ''",
            "            ver = deprecated[1]['version']",
            "            display.deprecated(\"%s option, %s %s\" % (name, why, alt), version=ver)",
            "",
            "    @staticmethod",
            "    def split_vault_id(vault_id):",
            "        # return (before_@, after_@)",
            "        # if no @, return whole string as after_",
            "        if '@' not in vault_id:",
            "            return (None, vault_id)",
            "",
            "        parts = vault_id.split('@', 1)",
            "        ret = tuple(parts)",
            "        return ret",
            "",
            "    @staticmethod",
            "    def build_vault_ids(vault_ids, vault_password_files=None,",
            "                        ask_vault_pass=None, create_new_password=None,",
            "                        auto_prompt=True):",
            "        vault_password_files = vault_password_files or []",
            "        vault_ids = vault_ids or []",
            "",
            "        # convert vault_password_files into vault_ids slugs",
            "        for password_file in vault_password_files:",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, password_file)",
            "",
            "            # note this makes --vault-id higher precendence than --vault-password-file",
            "            # if we want to intertwingle them in order probably need a cli callback to populate vault_ids",
            "            # used by --vault-id and --vault-password-file",
            "            vault_ids.append(id_slug)",
            "",
            "        # if an action needs an encrypt password (create_new_password=True) and we dont",
            "        # have other secrets setup, then automatically add a password prompt as well.",
            "        # prompts cant/shouldnt work without a tty, so dont add prompt secrets",
            "        if ask_vault_pass or (not vault_ids and auto_prompt):",
            "",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, u'prompt_ask_vault_pass')",
            "            vault_ids.append(id_slug)",
            "",
            "        return vault_ids",
            "",
            "    # TODO: remove the now unused args",
            "    @staticmethod",
            "    def setup_vault_secrets(loader, vault_ids, vault_password_files=None,",
            "                            ask_vault_pass=None, create_new_password=False,",
            "                            auto_prompt=True):",
            "        # list of tuples",
            "        vault_secrets = []",
            "",
            "        # Depending on the vault_id value (including how --ask-vault-pass / --vault-password-file create a vault_id)",
            "        # we need to show different prompts. This is for compat with older Towers that expect a",
            "        # certain vault password prompt format, so 'promp_ask_vault_pass' vault_id gets the old format.",
            "        prompt_formats = {}",
            "",
            "        # If there are configured default vault identities, they are considered 'first'",
            "        # so we prepend them to vault_ids (from cli) here",
            "",
            "        vault_password_files = vault_password_files or []",
            "        if C.DEFAULT_VAULT_PASSWORD_FILE:",
            "            vault_password_files.append(C.DEFAULT_VAULT_PASSWORD_FILE)",
            "",
            "        if create_new_password:",
            "            prompt_formats['prompt'] = ['New vault password (%(vault_id)s): ',",
            "                                        'Confirm vew vault password (%(vault_id)s): ']",
            "            # 2.3 format prompts for --ask-vault-pass",
            "            prompt_formats['prompt_ask_vault_pass'] = ['New Vault password: ',",
            "                                                       'Confirm New Vault password: ']",
            "        else:",
            "            prompt_formats['prompt'] = ['Vault password (%(vault_id)s): ']",
            "            # The format when we use just --ask-vault-pass needs to match 'Vault password:\\s*?$'",
            "            prompt_formats['prompt_ask_vault_pass'] = ['Vault password: ']",
            "",
            "        vault_ids = CLI.build_vault_ids(vault_ids,",
            "                                        vault_password_files,",
            "                                        ask_vault_pass,",
            "                                        create_new_password,",
            "                                        auto_prompt=auto_prompt)",
            "",
            "        for vault_id_slug in vault_ids:",
            "            vault_id_name, vault_id_value = CLI.split_vault_id(vault_id_slug)",
            "            if vault_id_value in ['prompt', 'prompt_ask_vault_pass']:",
            "",
            "                # --vault-id some_name@prompt_ask_vault_pass --vault-id other_name@prompt_ask_vault_pass will be a little",
            "                # confusing since it will use the old format without the vault id in the prompt",
            "                built_vault_id = vault_id_name or C.DEFAULT_VAULT_IDENTITY",
            "",
            "                # choose the prompt based on --vault-id=prompt or --ask-vault-pass. --ask-vault-pass",
            "                # always gets the old format for Tower compatibility.",
            "                # ie, we used --ask-vault-pass, so we need to use the old vault password prompt",
            "                # format since Tower needs to match on that format.",
            "                prompted_vault_secret = PromptVaultSecret(prompt_formats=prompt_formats[vault_id_value],",
            "                                                          vault_id=built_vault_id)",
            "",
            "                # a empty or invalid password from the prompt will warn and continue to the next",
            "                # without erroring globablly",
            "                try:",
            "                    prompted_vault_secret.load()",
            "                except AnsibleError as exc:",
            "                    display.warning('Error in vault password prompt (%s): %s' % (vault_id_name, exc))",
            "                    raise",
            "",
            "                vault_secrets.append((built_vault_id, prompted_vault_secret))",
            "",
            "                # update loader with new secrets incrementally, so we can load a vault password",
            "                # that is encrypted with a vault secret provided earlier",
            "                loader.set_vault_secrets(vault_secrets)",
            "                continue",
            "",
            "            # assuming anything else is a password file",
            "            display.vvvvv('Reading vault password file: %s' % vault_id_value)",
            "            # read vault_pass from a file",
            "            file_vault_secret = get_file_vault_secret(filename=vault_id_value,",
            "                                                      vault_id=vault_id_name,",
            "                                                      loader=loader)",
            "",
            "            # an invalid password file will error globally",
            "            try:",
            "                file_vault_secret.load()",
            "            except AnsibleError as exc:",
            "                display.warning('Error in vault password file loading (%s): %s' % (vault_id_name, exc))",
            "                raise",
            "",
            "            if vault_id_name:",
            "                vault_secrets.append((vault_id_name, file_vault_secret))",
            "            else:",
            "                vault_secrets.append((C.DEFAULT_VAULT_IDENTITY, file_vault_secret))",
            "",
            "            # update loader with as-yet-known vault secrets",
            "            loader.set_vault_secrets(vault_secrets)",
            "",
            "        return vault_secrets",
            "",
            "    def ask_passwords(self):",
            "        ''' prompt for connection and become passwords if needed '''",
            "",
            "        op = self.options",
            "        sshpass = None",
            "        becomepass = None",
            "        become_prompt = ''",
            "",
            "        become_prompt_method = \"BECOME\" if C.AGNOSTIC_BECOME_PROMPT else op.become_method.upper()",
            "",
            "        try:",
            "            if op.ask_pass:",
            "                sshpass = getpass.getpass(prompt=\"SSH password: \")",
            "                become_prompt = \"%s password[defaults to SSH password]: \" % become_prompt_method",
            "                if sshpass:",
            "                    sshpass = to_bytes(sshpass, errors='strict', nonstring='simplerepr')",
            "            else:",
            "                become_prompt = \"%s password: \" % become_prompt_method",
            "",
            "            if op.become_ask_pass:",
            "                becomepass = getpass.getpass(prompt=become_prompt)",
            "                if op.ask_pass and becomepass == '':",
            "                    becomepass = sshpass",
            "                if becomepass:",
            "                    becomepass = to_bytes(becomepass)",
            "        except EOFError:",
            "            pass",
            "",
            "        # we 'wrap' the passwords to prevent templating as",
            "        # they can contain special chars and trigger it incorrectly",
            "        if sshpass:",
            "            sshpass = AnsibleUnsafeBytes(sshpass)",
            "        if becomepass:",
            "            becomepass = AnsibleUnsafeBytes(becomepass)",
            "",
            "        return (sshpass, becomepass)",
            "",
            "    def normalize_become_options(self):",
            "        ''' this keeps backwards compatibility with sudo/su self.options '''",
            "        self.options.become_ask_pass = self.options.become_ask_pass or self.options.ask_sudo_pass or self.options.ask_su_pass or C.DEFAULT_BECOME_ASK_PASS",
            "        self.options.become_user = self.options.become_user or self.options.sudo_user or self.options.su_user or C.DEFAULT_BECOME_USER",
            "",
            "        def _dep(which):",
            "            display.deprecated('The %s command line option has been deprecated in favor of the \"become\" command line arguments' % which, '2.9')",
            "",
            "        if self.options.become:",
            "            pass",
            "        elif self.options.sudo:",
            "            self.options.become = True",
            "            self.options.become_method = 'sudo'",
            "            _dep('sudo')",
            "        elif self.options.su:",
            "            self.options.become = True",
            "            self.options.become_method = 'su'",
            "            _dep('su')",
            "",
            "        # other deprecations:",
            "        if self.options.ask_sudo_pass or self.options.sudo_user:",
            "            _dep('sudo')",
            "        if self.options.ask_su_pass or self.options.su_user:",
            "            _dep('su')",
            "",
            "    def validate_conflicts(self, vault_opts=False, runas_opts=False, fork_opts=False, vault_rekey_opts=False):",
            "        ''' check for conflicting options '''",
            "",
            "        op = self.options",
            "",
            "        if vault_opts:",
            "            # Check for vault related conflicts",
            "            if (op.ask_vault_pass and op.vault_password_files):",
            "                self.parser.error(\"--ask-vault-pass and --vault-password-file are mutually exclusive\")",
            "",
            "        if vault_rekey_opts:",
            "            if (op.new_vault_id and op.new_vault_password_file):",
            "                self.parser.error(\"--new-vault-password-file and --new-vault-id are mutually exclusive\")",
            "",
            "        if runas_opts:",
            "            # Check for privilege escalation conflicts",
            "            if ((op.su or op.su_user) and (op.sudo or op.sudo_user) or",
            "                    (op.su or op.su_user) and (op.become or op.become_user) or",
            "                    (op.sudo or op.sudo_user) and (op.become or op.become_user)):",
            "",
            "                self.parser.error(\"Sudo arguments ('--sudo', '--sudo-user', and '--ask-sudo-pass') and su arguments ('--su', '--su-user', and '--ask-su-pass') \"",
            "                                  \"and become arguments ('--become', '--become-user', and '--ask-become-pass') are exclusive of each other\")",
            "",
            "        if fork_opts:",
            "            if op.forks < 1:",
            "                self.parser.error(\"The number of processes (--forks) must be >= 1\")",
            "",
            "    @staticmethod",
            "    def unfrack_paths(option, opt, value, parser):",
            "        paths = getattr(parser.values, option.dest)",
            "        if paths is None:",
            "            paths = []",
            "",
            "        if isinstance(value, string_types):",
            "            paths[:0] = [unfrackpath(x) for x in value.split(os.pathsep) if x]",
            "        elif isinstance(value, list):",
            "            paths[:0] = [unfrackpath(x) for x in value if x]",
            "        else:",
            "            pass  # FIXME: should we raise options error?",
            "",
            "        setattr(parser.values, option.dest, paths)",
            "",
            "    @staticmethod",
            "    def unfrack_path(option, opt, value, parser):",
            "        if value != '-':",
            "            setattr(parser.values, option.dest, unfrackpath(value))",
            "        else:",
            "            setattr(parser.values, option.dest, value)",
            "",
            "    @staticmethod",
            "    def base_parser(usage=\"\", output_opts=False, runas_opts=False, meta_opts=False, runtask_opts=False, vault_opts=False, module_opts=False,",
            "                    async_opts=False, connect_opts=False, subset_opts=False, check_opts=False, inventory_opts=False, epilog=None, fork_opts=False,",
            "                    runas_prompt_opts=False, desc=None, basedir_opts=False, vault_rekey_opts=False):",
            "        ''' create an options parser for most ansible scripts '''",
            "",
            "        # base opts",
            "        parser = SortedOptParser(usage, version=CLI.version(\"%prog\"), description=desc, epilog=epilog)",
            "        parser.add_option('-v', '--verbose', dest='verbosity', default=C.DEFAULT_VERBOSITY, action=\"count\",",
            "                          help=\"verbose mode (-vvv for more, -vvvv to enable connection debugging)\")",
            "",
            "        if inventory_opts:",
            "            parser.add_option('-i', '--inventory', '--inventory-file', dest='inventory', action=\"append\",",
            "                              help=\"specify inventory host path or comma separated host list. --inventory-file is deprecated\")",
            "            parser.add_option('--list-hosts', dest='listhosts', action='store_true',",
            "                              help='outputs a list of matching hosts; does not execute anything else')",
            "            parser.add_option('-l', '--limit', default=C.DEFAULT_SUBSET, dest='subset',",
            "                              help='further limit selected hosts to an additional pattern')",
            "",
            "        if module_opts:",
            "            parser.add_option('-M', '--module-path', dest='module_path', default=None,",
            "                              help=\"prepend colon-separated path(s) to module library (default=%s)\" % C.DEFAULT_MODULE_PATH,",
            "                              action=\"callback\", callback=CLI.unfrack_paths, type='str')",
            "        if runtask_opts:",
            "            parser.add_option('-e', '--extra-vars', dest=\"extra_vars\", action=\"append\",",
            "                              help=\"set additional variables as key=value or YAML/JSON, if filename prepend with @\", default=[])",
            "",
            "        if fork_opts:",
            "            parser.add_option('-f', '--forks', dest='forks', default=C.DEFAULT_FORKS, type='int',",
            "                              help=\"specify number of parallel processes to use (default=%s)\" % C.DEFAULT_FORKS)",
            "",
            "        if vault_opts:",
            "            parser.add_option('--ask-vault-pass', default=C.DEFAULT_ASK_VAULT_PASS, dest='ask_vault_pass', action='store_true',",
            "                              help='ask for vault password')",
            "            parser.add_option('--vault-password-file', default=[], dest='vault_password_files',",
            "                              help=\"vault password file\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--vault-id', default=[], dest='vault_ids', action='append', type='string',",
            "                              help='the vault identity to use')",
            "",
            "        if vault_rekey_opts:",
            "            parser.add_option('--new-vault-password-file', default=None, dest='new_vault_password_file',",
            "                              help=\"new vault password file for rekey\", action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            parser.add_option('--new-vault-id', default=None, dest='new_vault_id', type='string',",
            "                              help='the new vault identity to use for rekey')",
            "",
            "        if subset_opts:",
            "            parser.add_option('-t', '--tags', dest='tags', default=C.TAGS_RUN, action='append',",
            "                              help=\"only run plays and tasks tagged with these values\")",
            "            parser.add_option('--skip-tags', dest='skip_tags', default=C.TAGS_SKIP, action='append',",
            "                              help=\"only run plays and tasks whose tags do not match these values\")",
            "",
            "        if output_opts:",
            "            parser.add_option('-o', '--one-line', dest='one_line', action='store_true',",
            "                              help='condense output')",
            "            parser.add_option('-t', '--tree', dest='tree', default=None,",
            "                              help='log output to this directory')",
            "",
            "        if connect_opts:",
            "            connect_group = optparse.OptionGroup(parser, \"Connection Options\", \"control as whom and how to connect to hosts\")",
            "            connect_group.add_option('-k', '--ask-pass', default=C.DEFAULT_ASK_PASS, dest='ask_pass', action='store_true',",
            "                                     help='ask for connection password')",
            "            connect_group.add_option('--private-key', '--key-file', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',",
            "                                     help='use this file to authenticate the connection', action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            connect_group.add_option('-u', '--user', default=C.DEFAULT_REMOTE_USER, dest='remote_user',",
            "                                     help='connect as this user (default=%s)' % C.DEFAULT_REMOTE_USER)",
            "            connect_group.add_option('-c', '--connection', dest='connection', default=C.DEFAULT_TRANSPORT,",
            "                                     help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)",
            "            connect_group.add_option('-T', '--timeout', default=C.DEFAULT_TIMEOUT, type='int', dest='timeout',",
            "                                     help=\"override the connection timeout in seconds (default=%s)\" % C.DEFAULT_TIMEOUT)",
            "            connect_group.add_option('--ssh-common-args', default='', dest='ssh_common_args',",
            "                                     help=\"specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand)\")",
            "            connect_group.add_option('--sftp-extra-args', default='', dest='sftp_extra_args',",
            "                                     help=\"specify extra arguments to pass to sftp only (e.g. -f, -l)\")",
            "            connect_group.add_option('--scp-extra-args', default='', dest='scp_extra_args',",
            "                                     help=\"specify extra arguments to pass to scp only (e.g. -l)\")",
            "            connect_group.add_option('--ssh-extra-args', default='', dest='ssh_extra_args',",
            "                                     help=\"specify extra arguments to pass to ssh only (e.g. -R)\")",
            "",
            "            parser.add_option_group(connect_group)",
            "",
            "        runas_group = None",
            "        rg = optparse.OptionGroup(parser, \"Privilege Escalation Options\", \"control how and which user you become as on target hosts\")",
            "        if runas_opts:",
            "            runas_group = rg",
            "            # priv user defaults to root later on to enable detecting when this option was given here",
            "            runas_group.add_option(\"-s\", \"--sudo\", default=C.DEFAULT_SUDO, action=\"store_true\", dest='sudo',",
            "                                   help=\"run operations with sudo (nopasswd) (deprecated, use become)\")",
            "            runas_group.add_option('-U', '--sudo-user', dest='sudo_user', default=None,",
            "                                   help='desired sudo user (default=root) (deprecated, use become)')",
            "            runas_group.add_option('-S', '--su', default=C.DEFAULT_SU, action='store_true',",
            "                                   help='run operations with su (deprecated, use become)')",
            "            runas_group.add_option('-R', '--su-user', default=None,",
            "                                   help='run operations with su as this user (default=%s) (deprecated, use become)' % C.DEFAULT_SU_USER)",
            "",
            "            # consolidated privilege escalation (become)",
            "            runas_group.add_option(\"-b\", \"--become\", default=C.DEFAULT_BECOME, action=\"store_true\", dest='become',",
            "                                   help=\"run operations with become (does not imply password prompting)\")",
            "            runas_group.add_option('--become-method', dest='become_method', default=C.DEFAULT_BECOME_METHOD, type='choice', choices=C.BECOME_METHODS,",
            "                                   help=\"privilege escalation method to use (default=%s), valid choices: [ %s ]\" %",
            "                                   (C.DEFAULT_BECOME_METHOD, ' | '.join(C.BECOME_METHODS)))",
            "            runas_group.add_option('--become-user', default=None, dest='become_user', type='string',",
            "                                   help='run operations as this user (default=%s)' % C.DEFAULT_BECOME_USER)",
            "",
            "        if runas_opts or runas_prompt_opts:",
            "            if not runas_group:",
            "                runas_group = rg",
            "            runas_group.add_option('--ask-sudo-pass', default=C.DEFAULT_ASK_SUDO_PASS, dest='ask_sudo_pass', action='store_true',",
            "                                   help='ask for sudo password (deprecated, use become)')",
            "            runas_group.add_option('--ask-su-pass', default=C.DEFAULT_ASK_SU_PASS, dest='ask_su_pass', action='store_true',",
            "                                   help='ask for su password (deprecated, use become)')",
            "            runas_group.add_option('-K', '--ask-become-pass', default=False, dest='become_ask_pass', action='store_true',",
            "                                   help='ask for privilege escalation password')",
            "",
            "        if runas_group:",
            "            parser.add_option_group(runas_group)",
            "",
            "        if async_opts:",
            "            parser.add_option('-P', '--poll', default=C.DEFAULT_POLL_INTERVAL, type='int', dest='poll_interval',",
            "                              help=\"set the poll interval if using -B (default=%s)\" % C.DEFAULT_POLL_INTERVAL)",
            "            parser.add_option('-B', '--background', dest='seconds', type='int', default=0,",
            "                              help='run asynchronously, failing after X seconds (default=N/A)')",
            "",
            "        if check_opts:",
            "            parser.add_option(\"-C\", \"--check\", default=False, dest='check', action='store_true',",
            "                              help=\"don't make any changes; instead, try to predict some of the changes that may occur\")",
            "            parser.add_option('--syntax-check', dest='syntax', action='store_true',",
            "                              help=\"perform a syntax check on the playbook, but do not execute it\")",
            "            parser.add_option(\"-D\", \"--diff\", default=C.DIFF_ALWAYS, dest='diff', action='store_true',",
            "                              help=\"when changing (small) files and templates, show the differences in those files; works great with --check\")",
            "",
            "        if meta_opts:",
            "            parser.add_option('--force-handlers', default=C.DEFAULT_FORCE_HANDLERS, dest='force_handlers', action='store_true',",
            "                              help=\"run handlers even if a task fails\")",
            "            parser.add_option('--flush-cache', dest='flush_cache', action='store_true',",
            "                              help=\"clear the fact cache for every host in inventory\")",
            "",
            "        if basedir_opts:",
            "            parser.add_option('--playbook-dir', default=None, dest='basedir', action='store',",
            "                              help=\"Since this tool does not use playbooks, use this as a subsitute playbook directory.\"",
            "                                   \"This sets the relative path for many features including roles/ group_vars/ etc.\")",
            "        return parser",
            "",
            "    @abstractmethod",
            "    def parse(self):",
            "        \"\"\"Parse the command line args",
            "",
            "        This method parses the command line arguments.  It uses the parser",
            "        stored in the self.parser attribute and saves the args and options in",
            "        self.args and self.options respectively.",
            "",
            "        Subclasses need to implement this method.  They will usually create",
            "        a base_parser, add their own options to the base_parser, and then call",
            "        this method to do the actual parsing.  An implementation will look",
            "        something like this::",
            "",
            "            def parse(self):",
            "                parser = super(MyCLI, self).base_parser(usage=\"My Ansible CLI\", inventory_opts=True)",
            "                parser.add_option('--my-option', dest='my_option', action='store')",
            "                self.parser = parser",
            "                super(MyCLI, self).parse()",
            "                # If some additional transformations are needed for the",
            "                # arguments and options, do it here.",
            "        \"\"\"",
            "",
            "        self.options, self.args = self.parser.parse_args(self.args[1:])",
            "",
            "        # process tags",
            "        if hasattr(self.options, 'tags') and not self.options.tags:",
            "            # optparse defaults does not do what's expected",
            "            self.options.tags = ['all']",
            "        if hasattr(self.options, 'tags') and self.options.tags:",
            "            tags = set()",
            "            for tag_set in self.options.tags:",
            "                for tag in tag_set.split(u','):",
            "                    tags.add(tag.strip())",
            "            self.options.tags = list(tags)",
            "",
            "        # process skip_tags",
            "        if hasattr(self.options, 'skip_tags') and self.options.skip_tags:",
            "            skip_tags = set()",
            "            for tag_set in self.options.skip_tags:",
            "                for tag in tag_set.split(u','):",
            "                    skip_tags.add(tag.strip())",
            "            self.options.skip_tags = list(skip_tags)",
            "",
            "        # process inventory options except for CLIs that require their own processing",
            "        if hasattr(self.options, 'inventory') and not self.SKIP_INVENTORY_DEFAULTS:",
            "",
            "            if self.options.inventory:",
            "",
            "                # should always be list",
            "                if isinstance(self.options.inventory, string_types):",
            "                    self.options.inventory = [self.options.inventory]",
            "",
            "                # Ensure full paths when needed",
            "                self.options.inventory = [unfrackpath(opt, follow=False) if ',' not in opt else opt for opt in self.options.inventory]",
            "            else:",
            "                self.options.inventory = C.DEFAULT_HOST_LIST",
            "",
            "    @staticmethod",
            "    def version(prog):",
            "        ''' return ansible version '''",
            "        result = \"{0} {1}\".format(prog, __version__)",
            "        gitinfo = CLI._gitinfo()",
            "        if gitinfo:",
            "            result = result + \" {0}\".format(gitinfo)",
            "        result += \"\\n  config file = %s\" % C.CONFIG_FILE",
            "        if C.DEFAULT_MODULE_PATH is None:",
            "            cpath = \"Default w/o overrides\"",
            "        else:",
            "            cpath = C.DEFAULT_MODULE_PATH",
            "        result = result + \"\\n  configured module search path = %s\" % cpath",
            "        result = result + \"\\n  ansible python module location = %s\" % ':'.join(ansible.__path__)",
            "        result = result + \"\\n  executable location = %s\" % sys.argv[0]",
            "        result = result + \"\\n  python version = %s\" % ''.join(sys.version.splitlines())",
            "        return result",
            "",
            "    @staticmethod",
            "    def version_info(gitinfo=False):",
            "        ''' return full ansible version info '''",
            "        if gitinfo:",
            "            # expensive call, user with care",
            "            ansible_version_string = CLI.version('')",
            "        else:",
            "            ansible_version_string = __version__",
            "        ansible_version = ansible_version_string.split()[0]",
            "        ansible_versions = ansible_version.split('.')",
            "        for counter in range(len(ansible_versions)):",
            "            if ansible_versions[counter] == \"\":",
            "                ansible_versions[counter] = 0",
            "            try:",
            "                ansible_versions[counter] = int(ansible_versions[counter])",
            "            except Exception:",
            "                pass",
            "        if len(ansible_versions) < 3:",
            "            for counter in range(len(ansible_versions), 3):",
            "                ansible_versions.append(0)",
            "        return {'string': ansible_version_string.strip(),",
            "                'full': ansible_version,",
            "                'major': ansible_versions[0],",
            "                'minor': ansible_versions[1],",
            "                'revision': ansible_versions[2]}",
            "",
            "    @staticmethod",
            "    def _git_repo_info(repo_path):",
            "        ''' returns a string containing git branch, commit id and commit date '''",
            "        result = None",
            "        if os.path.exists(repo_path):",
            "            # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.",
            "            if os.path.isfile(repo_path):",
            "                try:",
            "                    gitdir = yaml.safe_load(open(repo_path)).get('gitdir')",
            "                    # There is a possibility the .git file to have an absolute path.",
            "                    if os.path.isabs(gitdir):",
            "                        repo_path = gitdir",
            "                    else:",
            "                        repo_path = os.path.join(repo_path[:-4], gitdir)",
            "                except (IOError, AttributeError):",
            "                    return ''",
            "            f = open(os.path.join(repo_path, \"HEAD\"))",
            "            line = f.readline().rstrip(\"\\n\")",
            "            if line.startswith(\"ref:\"):",
            "                branch_path = os.path.join(repo_path, line[5:])",
            "            else:",
            "                branch_path = None",
            "            f.close()",
            "            if branch_path and os.path.exists(branch_path):",
            "                branch = '/'.join(line.split('/')[2:])",
            "                f = open(branch_path)",
            "                commit = f.readline()[:10]",
            "                f.close()",
            "            else:",
            "                # detached HEAD",
            "                commit = line[:10]",
            "                branch = 'detached HEAD'",
            "                branch_path = os.path.join(repo_path, \"HEAD\")",
            "",
            "            date = time.localtime(os.stat(branch_path).st_mtime)",
            "            if time.daylight == 0:",
            "                offset = time.timezone",
            "            else:",
            "                offset = time.altzone",
            "            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit, time.strftime(\"%Y/%m/%d %H:%M:%S\", date), int(offset / -36))",
            "        else:",
            "            result = ''",
            "        return result",
            "",
            "    @staticmethod",
            "    def _gitinfo():",
            "        basedir = os.path.join(os.path.dirname(__file__), '..', '..', '..')",
            "        repo_path = os.path.join(basedir, '.git')",
            "        result = CLI._git_repo_info(repo_path)",
            "        submodules = os.path.join(basedir, '.gitmodules')",
            "        if not os.path.exists(submodules):",
            "            return result",
            "        f = open(submodules)",
            "        for line in f:",
            "            tokens = line.strip().split(' ')",
            "            if tokens[0] == 'path':",
            "                submodule_path = tokens[2]",
            "                submodule_info = CLI._git_repo_info(os.path.join(basedir, submodule_path, '.git'))",
            "                if not submodule_info:",
            "                    submodule_info = ' not found - use git submodule update --init ' + submodule_path",
            "                result += \"\\n  {0}: {1}\".format(submodule_path, submodule_info)",
            "        f.close()",
            "        return result",
            "",
            "    def pager(self, text):",
            "        ''' find reasonable way to display text '''",
            "        # this is a much simpler form of what is in pydoc.py",
            "        if not sys.stdout.isatty():",
            "            display.display(text, screen_only=True)",
            "        elif 'PAGER' in os.environ:",
            "            if sys.platform == 'win32':",
            "                display.display(text, screen_only=True)",
            "            else:",
            "                self.pager_pipe(text, os.environ['PAGER'])",
            "        else:",
            "            p = subprocess.Popen('less --version', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
            "            p.communicate()",
            "            if p.returncode == 0:",
            "                self.pager_pipe(text, 'less')",
            "            else:",
            "                display.display(text, screen_only=True)",
            "",
            "    @staticmethod",
            "    def pager_pipe(text, cmd):",
            "        ''' pipe text through a pager '''",
            "        if 'LESS' not in os.environ:",
            "            os.environ['LESS'] = CLI.LESS_OPTS",
            "        try:",
            "            cmd = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=sys.stdout)",
            "            cmd.communicate(input=to_bytes(text))",
            "        except IOError:",
            "            pass",
            "        except KeyboardInterrupt:",
            "            pass",
            "",
            "    @classmethod",
            "    def tty_ify(cls, text):",
            "",
            "        t = cls._ITALIC.sub(\"`\" + r\"\\1\" + \"'\", text)    # I(word) => `word'",
            "        t = cls._BOLD.sub(\"*\" + r\"\\1\" + \"*\", t)         # B(word) => *word*",
            "        t = cls._MODULE.sub(\"[\" + r\"\\1\" + \"]\", t)       # M(word) => [word]",
            "        t = cls._URL.sub(r\"\\1\", t)                      # U(word) => word",
            "        t = cls._CONST.sub(\"`\" + r\"\\1\" + \"'\", t)        # C(word) => `word'",
            "",
            "        return t",
            "",
            "    @staticmethod",
            "    def _play_prereqs(options):",
            "",
            "        # all needs loader",
            "        loader = DataLoader()",
            "",
            "        basedir = getattr(options, 'basedir', False)",
            "        if basedir:",
            "            loader.set_basedir(basedir)",
            "",
            "        vault_ids = options.vault_ids",
            "        default_vault_ids = C.DEFAULT_VAULT_IDENTITY_LIST",
            "        vault_ids = default_vault_ids + vault_ids",
            "",
            "        vault_secrets = CLI.setup_vault_secrets(loader,",
            "                                                vault_ids=vault_ids,",
            "                                                vault_password_files=options.vault_password_files,",
            "                                                ask_vault_pass=options.ask_vault_pass,",
            "                                                auto_prompt=False)",
            "        loader.set_vault_secrets(vault_secrets)",
            "",
            "        # create the inventory, and filter it based on the subset specified (if any)",
            "        inventory = InventoryManager(loader=loader, sources=options.inventory)",
            "",
            "        # create the variable manager, which will be shared throughout",
            "        # the code, ensuring a consistent view of global variables",
            "        variable_manager = VariableManager(loader=loader, inventory=inventory)",
            "",
            "        if hasattr(options, 'basedir'):",
            "            if options.basedir:",
            "                variable_manager.safe_basedir = True",
            "        else:",
            "            variable_manager.safe_basedir = True",
            "",
            "        # load vars from cli options",
            "        variable_manager.extra_vars = load_extra_vars(loader=loader, options=options)",
            "        variable_manager.options_vars = load_options_vars(options, CLI.version_info(gitinfo=False))",
            "",
            "        return loader, inventory, variable_manager",
            "",
            "    @staticmethod",
            "    def get_host_list(inventory, subset, pattern='all'):",
            "",
            "        no_hosts = False",
            "        if len(inventory.list_hosts()) == 0:",
            "            # Empty inventory",
            "            if C.LOCALHOST_WARNING:",
            "                display.warning(\"provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\")",
            "            no_hosts = True",
            "",
            "        inventory.subset(subset)",
            "",
            "        hosts = inventory.list_hosts(pattern)",
            "        if len(hosts) == 0 and no_hosts is False:",
            "            raise AnsibleError(\"Specified hosts and/or --limit does not match any hosts\")",
            "",
            "        return hosts"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "# (c) 2016, Toshio Kuratomi <tkuratomi@ansible.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import getpass",
            "import operator",
            "import optparse",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import time",
            "import yaml",
            "",
            "from abc import ABCMeta, abstractmethod",
            "",
            "import ansible",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleOptionsError, AnsibleError",
            "from ansible.inventory.manager import InventoryManager",
            "from ansible.module_utils.six import with_metaclass, string_types",
            "from ansible.module_utils._text import to_bytes, to_text",
            "from ansible.parsing.dataloader import DataLoader",
            "from ansible.release import __version__",
            "from ansible.utils.path import unfrackpath",
            "from ansible.utils.vars import load_extra_vars, load_options_vars",
            "from ansible.utils.unsafe_proxy import AnsibleUnsafeText",
            "from ansible.vars.manager import VariableManager",
            "from ansible.parsing.vault import PromptVaultSecret, get_file_vault_secret",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "class SortedOptParser(optparse.OptionParser):",
            "    '''Optparser which sorts the options by opt before outputting --help'''",
            "",
            "    def format_help(self, formatter=None, epilog=None):",
            "        self.option_list.sort(key=operator.methodcaller('get_opt_string'))",
            "        return optparse.OptionParser.format_help(self, formatter=None)",
            "",
            "",
            "# Note: Inherit from SortedOptParser so that we get our format_help method",
            "class InvalidOptsParser(SortedOptParser):",
            "    '''Ignore invalid options.",
            "",
            "    Meant for the special case where we need to take care of help and version",
            "    but may not know the full range of options yet.  (See it in use in set_action)",
            "    '''",
            "    def __init__(self, parser):",
            "        # Since this is special purposed to just handle help and version, we",
            "        # take a pre-existing option parser here and set our options from",
            "        # that.  This allows us to give accurate help based on the given",
            "        # option parser.",
            "        SortedOptParser.__init__(self, usage=parser.usage,",
            "                                 option_list=parser.option_list,",
            "                                 option_class=parser.option_class,",
            "                                 conflict_handler=parser.conflict_handler,",
            "                                 description=parser.description,",
            "                                 formatter=parser.formatter,",
            "                                 add_help_option=False,",
            "                                 prog=parser.prog,",
            "                                 epilog=parser.epilog)",
            "        self.version = parser.version",
            "",
            "    def _process_long_opt(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_long_opt(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "    def _process_short_opts(self, rargs, values):",
            "        try:",
            "            optparse.OptionParser._process_short_opts(self, rargs, values)",
            "        except optparse.BadOptionError:",
            "            pass",
            "",
            "",
            "class CLI(with_metaclass(ABCMeta, object)):",
            "    ''' code behind bin/ansible* programs '''",
            "",
            "    VALID_ACTIONS = []",
            "",
            "    _ITALIC = re.compile(r\"I\\(([^)]+)\\)\")",
            "    _BOLD = re.compile(r\"B\\(([^)]+)\\)\")",
            "    _MODULE = re.compile(r\"M\\(([^)]+)\\)\")",
            "    _URL = re.compile(r\"U\\(([^)]+)\\)\")",
            "    _CONST = re.compile(r\"C\\(([^)]+)\\)\")",
            "",
            "    PAGER = 'less'",
            "",
            "    # -F (quit-if-one-screen) -R (allow raw ansi control chars)",
            "    # -S (chop long lines) -X (disable termcap init and de-init)",
            "    LESS_OPTS = 'FRSX'",
            "    SKIP_INVENTORY_DEFAULTS = False",
            "",
            "    def __init__(self, args, callback=None):",
            "        \"\"\"",
            "        Base init method for all command line programs",
            "        \"\"\"",
            "",
            "        self.args = args",
            "        self.options = None",
            "        self.parser = None",
            "        self.action = None",
            "        self.callback = callback",
            "",
            "    def set_action(self):",
            "        \"\"\"",
            "        Get the action the user wants to execute from the sys argv list.",
            "        \"\"\"",
            "        for i in range(0, len(self.args)):",
            "            arg = self.args[i]",
            "            if arg in self.VALID_ACTIONS:",
            "                self.action = arg",
            "                del self.args[i]",
            "                break",
            "",
            "        if not self.action:",
            "            # if we're asked for help or version, we don't need an action.",
            "            # have to use a special purpose Option Parser to figure that out as",
            "            # the standard OptionParser throws an error for unknown options and",
            "            # without knowing action, we only know of a subset of the options",
            "            # that could be legal for this command",
            "            tmp_parser = InvalidOptsParser(self.parser)",
            "            tmp_options, tmp_args = tmp_parser.parse_args(self.args)",
            "            if not(hasattr(tmp_options, 'help') and tmp_options.help) or (hasattr(tmp_options, 'version') and tmp_options.version):",
            "                raise AnsibleOptionsError(\"Missing required action\")",
            "",
            "    def execute(self):",
            "        \"\"\"",
            "        Actually runs a child defined method using the execute_<action> pattern",
            "        \"\"\"",
            "        fn = getattr(self, \"execute_%s\" % self.action)",
            "        fn()",
            "",
            "    @abstractmethod",
            "    def run(self):",
            "        \"\"\"Run the ansible command",
            "",
            "        Subclasses must implement this method.  It does the actual work of",
            "        running an Ansible command.",
            "        \"\"\"",
            "",
            "        display.vv(to_text(self.parser.get_version()))",
            "",
            "        if C.CONFIG_FILE:",
            "            display.v(u\"Using %s as config file\" % to_text(C.CONFIG_FILE))",
            "        else:",
            "            display.v(u\"No config file found; using defaults\")",
            "",
            "        # warn about deprecated config options",
            "        for deprecated in C.config.DEPRECATED:",
            "            name = deprecated[0]",
            "            why = deprecated[1]['why']",
            "            if 'alternatives' in deprecated[1]:",
            "                alt = ', use %s instead' % deprecated[1]['alternatives']",
            "            else:",
            "                alt = ''",
            "            ver = deprecated[1]['version']",
            "            display.deprecated(\"%s option, %s %s\" % (name, why, alt), version=ver)",
            "",
            "    @staticmethod",
            "    def split_vault_id(vault_id):",
            "        # return (before_@, after_@)",
            "        # if no @, return whole string as after_",
            "        if '@' not in vault_id:",
            "            return (None, vault_id)",
            "",
            "        parts = vault_id.split('@', 1)",
            "        ret = tuple(parts)",
            "        return ret",
            "",
            "    @staticmethod",
            "    def build_vault_ids(vault_ids, vault_password_files=None,",
            "                        ask_vault_pass=None, create_new_password=None,",
            "                        auto_prompt=True):",
            "        vault_password_files = vault_password_files or []",
            "        vault_ids = vault_ids or []",
            "",
            "        # convert vault_password_files into vault_ids slugs",
            "        for password_file in vault_password_files:",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, password_file)",
            "",
            "            # note this makes --vault-id higher precendence than --vault-password-file",
            "            # if we want to intertwingle them in order probably need a cli callback to populate vault_ids",
            "            # used by --vault-id and --vault-password-file",
            "            vault_ids.append(id_slug)",
            "",
            "        # if an action needs an encrypt password (create_new_password=True) and we dont",
            "        # have other secrets setup, then automatically add a password prompt as well.",
            "        # prompts cant/shouldnt work without a tty, so dont add prompt secrets",
            "        if ask_vault_pass or (not vault_ids and auto_prompt):",
            "",
            "            id_slug = u'%s@%s' % (C.DEFAULT_VAULT_IDENTITY, u'prompt_ask_vault_pass')",
            "            vault_ids.append(id_slug)",
            "",
            "        return vault_ids",
            "",
            "    # TODO: remove the now unused args",
            "    @staticmethod",
            "    def setup_vault_secrets(loader, vault_ids, vault_password_files=None,",
            "                            ask_vault_pass=None, create_new_password=False,",
            "                            auto_prompt=True):",
            "        # list of tuples",
            "        vault_secrets = []",
            "",
            "        # Depending on the vault_id value (including how --ask-vault-pass / --vault-password-file create a vault_id)",
            "        # we need to show different prompts. This is for compat with older Towers that expect a",
            "        # certain vault password prompt format, so 'promp_ask_vault_pass' vault_id gets the old format.",
            "        prompt_formats = {}",
            "",
            "        # If there are configured default vault identities, they are considered 'first'",
            "        # so we prepend them to vault_ids (from cli) here",
            "",
            "        vault_password_files = vault_password_files or []",
            "        if C.DEFAULT_VAULT_PASSWORD_FILE:",
            "            vault_password_files.append(C.DEFAULT_VAULT_PASSWORD_FILE)",
            "",
            "        if create_new_password:",
            "            prompt_formats['prompt'] = ['New vault password (%(vault_id)s): ',",
            "                                        'Confirm vew vault password (%(vault_id)s): ']",
            "            # 2.3 format prompts for --ask-vault-pass",
            "            prompt_formats['prompt_ask_vault_pass'] = ['New Vault password: ',",
            "                                                       'Confirm New Vault password: ']",
            "        else:",
            "            prompt_formats['prompt'] = ['Vault password (%(vault_id)s): ']",
            "            # The format when we use just --ask-vault-pass needs to match 'Vault password:\\s*?$'",
            "            prompt_formats['prompt_ask_vault_pass'] = ['Vault password: ']",
            "",
            "        vault_ids = CLI.build_vault_ids(vault_ids,",
            "                                        vault_password_files,",
            "                                        ask_vault_pass,",
            "                                        create_new_password,",
            "                                        auto_prompt=auto_prompt)",
            "",
            "        for vault_id_slug in vault_ids:",
            "            vault_id_name, vault_id_value = CLI.split_vault_id(vault_id_slug)",
            "            if vault_id_value in ['prompt', 'prompt_ask_vault_pass']:",
            "",
            "                # --vault-id some_name@prompt_ask_vault_pass --vault-id other_name@prompt_ask_vault_pass will be a little",
            "                # confusing since it will use the old format without the vault id in the prompt",
            "                built_vault_id = vault_id_name or C.DEFAULT_VAULT_IDENTITY",
            "",
            "                # choose the prompt based on --vault-id=prompt or --ask-vault-pass. --ask-vault-pass",
            "                # always gets the old format for Tower compatibility.",
            "                # ie, we used --ask-vault-pass, so we need to use the old vault password prompt",
            "                # format since Tower needs to match on that format.",
            "                prompted_vault_secret = PromptVaultSecret(prompt_formats=prompt_formats[vault_id_value],",
            "                                                          vault_id=built_vault_id)",
            "",
            "                # a empty or invalid password from the prompt will warn and continue to the next",
            "                # without erroring globablly",
            "                try:",
            "                    prompted_vault_secret.load()",
            "                except AnsibleError as exc:",
            "                    display.warning('Error in vault password prompt (%s): %s' % (vault_id_name, exc))",
            "                    raise",
            "",
            "                vault_secrets.append((built_vault_id, prompted_vault_secret))",
            "",
            "                # update loader with new secrets incrementally, so we can load a vault password",
            "                # that is encrypted with a vault secret provided earlier",
            "                loader.set_vault_secrets(vault_secrets)",
            "                continue",
            "",
            "            # assuming anything else is a password file",
            "            display.vvvvv('Reading vault password file: %s' % vault_id_value)",
            "            # read vault_pass from a file",
            "            file_vault_secret = get_file_vault_secret(filename=vault_id_value,",
            "                                                      vault_id=vault_id_name,",
            "                                                      loader=loader)",
            "",
            "            # an invalid password file will error globally",
            "            try:",
            "                file_vault_secret.load()",
            "            except AnsibleError as exc:",
            "                display.warning('Error in vault password file loading (%s): %s' % (vault_id_name, exc))",
            "                raise",
            "",
            "            if vault_id_name:",
            "                vault_secrets.append((vault_id_name, file_vault_secret))",
            "            else:",
            "                vault_secrets.append((C.DEFAULT_VAULT_IDENTITY, file_vault_secret))",
            "",
            "            # update loader with as-yet-known vault secrets",
            "            loader.set_vault_secrets(vault_secrets)",
            "",
            "        return vault_secrets",
            "",
            "    def ask_passwords(self):",
            "        ''' prompt for connection and become passwords if needed '''",
            "",
            "        op = self.options",
            "        sshpass = None",
            "        becomepass = None",
            "        become_prompt = ''",
            "",
            "        become_prompt_method = \"BECOME\" if C.AGNOSTIC_BECOME_PROMPT else op.become_method.upper()",
            "",
            "        try:",
            "            if op.ask_pass:",
            "                sshpass = getpass.getpass(prompt=\"SSH password: \")",
            "                become_prompt = \"%s password[defaults to SSH password]: \" % become_prompt_method",
            "            else:",
            "                become_prompt = \"%s password: \" % become_prompt_method",
            "",
            "            if op.become_ask_pass:",
            "                becomepass = getpass.getpass(prompt=become_prompt)",
            "                if op.ask_pass and becomepass == '':",
            "                    becomepass = sshpass",
            "        except EOFError:",
            "            pass",
            "",
            "        # we 'wrap' the passwords to prevent templating as",
            "        # they can contain special chars and trigger it incorrectly",
            "        if sshpass:",
            "            sshpass = AnsibleUnsafeText(to_text(sshpass))",
            "        if becomepass:",
            "            becomepass = AnsibleUnsafeText(to_text(becomepass))",
            "",
            "        return (sshpass, becomepass)",
            "",
            "    def normalize_become_options(self):",
            "        ''' this keeps backwards compatibility with sudo/su self.options '''",
            "        self.options.become_ask_pass = self.options.become_ask_pass or self.options.ask_sudo_pass or self.options.ask_su_pass or C.DEFAULT_BECOME_ASK_PASS",
            "        self.options.become_user = self.options.become_user or self.options.sudo_user or self.options.su_user or C.DEFAULT_BECOME_USER",
            "",
            "        def _dep(which):",
            "            display.deprecated('The %s command line option has been deprecated in favor of the \"become\" command line arguments' % which, '2.9')",
            "",
            "        if self.options.become:",
            "            pass",
            "        elif self.options.sudo:",
            "            self.options.become = True",
            "            self.options.become_method = 'sudo'",
            "            _dep('sudo')",
            "        elif self.options.su:",
            "            self.options.become = True",
            "            self.options.become_method = 'su'",
            "            _dep('su')",
            "",
            "        # other deprecations:",
            "        if self.options.ask_sudo_pass or self.options.sudo_user:",
            "            _dep('sudo')",
            "        if self.options.ask_su_pass or self.options.su_user:",
            "            _dep('su')",
            "",
            "    def validate_conflicts(self, vault_opts=False, runas_opts=False, fork_opts=False, vault_rekey_opts=False):",
            "        ''' check for conflicting options '''",
            "",
            "        op = self.options",
            "",
            "        if vault_opts:",
            "            # Check for vault related conflicts",
            "            if (op.ask_vault_pass and op.vault_password_files):",
            "                self.parser.error(\"--ask-vault-pass and --vault-password-file are mutually exclusive\")",
            "",
            "        if vault_rekey_opts:",
            "            if (op.new_vault_id and op.new_vault_password_file):",
            "                self.parser.error(\"--new-vault-password-file and --new-vault-id are mutually exclusive\")",
            "",
            "        if runas_opts:",
            "            # Check for privilege escalation conflicts",
            "            if ((op.su or op.su_user) and (op.sudo or op.sudo_user) or",
            "                    (op.su or op.su_user) and (op.become or op.become_user) or",
            "                    (op.sudo or op.sudo_user) and (op.become or op.become_user)):",
            "",
            "                self.parser.error(\"Sudo arguments ('--sudo', '--sudo-user', and '--ask-sudo-pass') and su arguments ('--su', '--su-user', and '--ask-su-pass') \"",
            "                                  \"and become arguments ('--become', '--become-user', and '--ask-become-pass') are exclusive of each other\")",
            "",
            "        if fork_opts:",
            "            if op.forks < 1:",
            "                self.parser.error(\"The number of processes (--forks) must be >= 1\")",
            "",
            "    @staticmethod",
            "    def unfrack_paths(option, opt, value, parser):",
            "        paths = getattr(parser.values, option.dest)",
            "        if paths is None:",
            "            paths = []",
            "",
            "        if isinstance(value, string_types):",
            "            paths[:0] = [unfrackpath(x) for x in value.split(os.pathsep) if x]",
            "        elif isinstance(value, list):",
            "            paths[:0] = [unfrackpath(x) for x in value if x]",
            "        else:",
            "            pass  # FIXME: should we raise options error?",
            "",
            "        setattr(parser.values, option.dest, paths)",
            "",
            "    @staticmethod",
            "    def unfrack_path(option, opt, value, parser):",
            "        if value != '-':",
            "            setattr(parser.values, option.dest, unfrackpath(value))",
            "        else:",
            "            setattr(parser.values, option.dest, value)",
            "",
            "    @staticmethod",
            "    def base_parser(usage=\"\", output_opts=False, runas_opts=False, meta_opts=False, runtask_opts=False, vault_opts=False, module_opts=False,",
            "                    async_opts=False, connect_opts=False, subset_opts=False, check_opts=False, inventory_opts=False, epilog=None, fork_opts=False,",
            "                    runas_prompt_opts=False, desc=None, basedir_opts=False, vault_rekey_opts=False):",
            "        ''' create an options parser for most ansible scripts '''",
            "",
            "        # base opts",
            "        parser = SortedOptParser(usage, version=CLI.version(\"%prog\"), description=desc, epilog=epilog)",
            "        parser.add_option('-v', '--verbose', dest='verbosity', default=C.DEFAULT_VERBOSITY, action=\"count\",",
            "                          help=\"verbose mode (-vvv for more, -vvvv to enable connection debugging)\")",
            "",
            "        if inventory_opts:",
            "            parser.add_option('-i', '--inventory', '--inventory-file', dest='inventory', action=\"append\",",
            "                              help=\"specify inventory host path or comma separated host list. --inventory-file is deprecated\")",
            "            parser.add_option('--list-hosts', dest='listhosts', action='store_true',",
            "                              help='outputs a list of matching hosts; does not execute anything else')",
            "            parser.add_option('-l', '--limit', default=C.DEFAULT_SUBSET, dest='subset',",
            "                              help='further limit selected hosts to an additional pattern')",
            "",
            "        if module_opts:",
            "            parser.add_option('-M', '--module-path', dest='module_path', default=None,",
            "                              help=\"prepend colon-separated path(s) to module library (default=%s)\" % C.DEFAULT_MODULE_PATH,",
            "                              action=\"callback\", callback=CLI.unfrack_paths, type='str')",
            "        if runtask_opts:",
            "            parser.add_option('-e', '--extra-vars', dest=\"extra_vars\", action=\"append\",",
            "                              help=\"set additional variables as key=value or YAML/JSON, if filename prepend with @\", default=[])",
            "",
            "        if fork_opts:",
            "            parser.add_option('-f', '--forks', dest='forks', default=C.DEFAULT_FORKS, type='int',",
            "                              help=\"specify number of parallel processes to use (default=%s)\" % C.DEFAULT_FORKS)",
            "",
            "        if vault_opts:",
            "            parser.add_option('--ask-vault-pass', default=C.DEFAULT_ASK_VAULT_PASS, dest='ask_vault_pass', action='store_true',",
            "                              help='ask for vault password')",
            "            parser.add_option('--vault-password-file', default=[], dest='vault_password_files',",
            "                              help=\"vault password file\", action=\"callback\", callback=CLI.unfrack_paths, type='string')",
            "            parser.add_option('--vault-id', default=[], dest='vault_ids', action='append', type='string',",
            "                              help='the vault identity to use')",
            "",
            "        if vault_rekey_opts:",
            "            parser.add_option('--new-vault-password-file', default=None, dest='new_vault_password_file',",
            "                              help=\"new vault password file for rekey\", action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            parser.add_option('--new-vault-id', default=None, dest='new_vault_id', type='string',",
            "                              help='the new vault identity to use for rekey')",
            "",
            "        if subset_opts:",
            "            parser.add_option('-t', '--tags', dest='tags', default=C.TAGS_RUN, action='append',",
            "                              help=\"only run plays and tasks tagged with these values\")",
            "            parser.add_option('--skip-tags', dest='skip_tags', default=C.TAGS_SKIP, action='append',",
            "                              help=\"only run plays and tasks whose tags do not match these values\")",
            "",
            "        if output_opts:",
            "            parser.add_option('-o', '--one-line', dest='one_line', action='store_true',",
            "                              help='condense output')",
            "            parser.add_option('-t', '--tree', dest='tree', default=None,",
            "                              help='log output to this directory')",
            "",
            "        if connect_opts:",
            "            connect_group = optparse.OptionGroup(parser, \"Connection Options\", \"control as whom and how to connect to hosts\")",
            "            connect_group.add_option('-k', '--ask-pass', default=C.DEFAULT_ASK_PASS, dest='ask_pass', action='store_true',",
            "                                     help='ask for connection password')",
            "            connect_group.add_option('--private-key', '--key-file', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',",
            "                                     help='use this file to authenticate the connection', action=\"callback\", callback=CLI.unfrack_path, type='string')",
            "            connect_group.add_option('-u', '--user', default=C.DEFAULT_REMOTE_USER, dest='remote_user',",
            "                                     help='connect as this user (default=%s)' % C.DEFAULT_REMOTE_USER)",
            "            connect_group.add_option('-c', '--connection', dest='connection', default=C.DEFAULT_TRANSPORT,",
            "                                     help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)",
            "            connect_group.add_option('-T', '--timeout', default=C.DEFAULT_TIMEOUT, type='int', dest='timeout',",
            "                                     help=\"override the connection timeout in seconds (default=%s)\" % C.DEFAULT_TIMEOUT)",
            "            connect_group.add_option('--ssh-common-args', default='', dest='ssh_common_args',",
            "                                     help=\"specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand)\")",
            "            connect_group.add_option('--sftp-extra-args', default='', dest='sftp_extra_args',",
            "                                     help=\"specify extra arguments to pass to sftp only (e.g. -f, -l)\")",
            "            connect_group.add_option('--scp-extra-args', default='', dest='scp_extra_args',",
            "                                     help=\"specify extra arguments to pass to scp only (e.g. -l)\")",
            "            connect_group.add_option('--ssh-extra-args', default='', dest='ssh_extra_args',",
            "                                     help=\"specify extra arguments to pass to ssh only (e.g. -R)\")",
            "",
            "            parser.add_option_group(connect_group)",
            "",
            "        runas_group = None",
            "        rg = optparse.OptionGroup(parser, \"Privilege Escalation Options\", \"control how and which user you become as on target hosts\")",
            "        if runas_opts:",
            "            runas_group = rg",
            "            # priv user defaults to root later on to enable detecting when this option was given here",
            "            runas_group.add_option(\"-s\", \"--sudo\", default=C.DEFAULT_SUDO, action=\"store_true\", dest='sudo',",
            "                                   help=\"run operations with sudo (nopasswd) (deprecated, use become)\")",
            "            runas_group.add_option('-U', '--sudo-user', dest='sudo_user', default=None,",
            "                                   help='desired sudo user (default=root) (deprecated, use become)')",
            "            runas_group.add_option('-S', '--su', default=C.DEFAULT_SU, action='store_true',",
            "                                   help='run operations with su (deprecated, use become)')",
            "            runas_group.add_option('-R', '--su-user', default=None,",
            "                                   help='run operations with su as this user (default=%s) (deprecated, use become)' % C.DEFAULT_SU_USER)",
            "",
            "            # consolidated privilege escalation (become)",
            "            runas_group.add_option(\"-b\", \"--become\", default=C.DEFAULT_BECOME, action=\"store_true\", dest='become',",
            "                                   help=\"run operations with become (does not imply password prompting)\")",
            "            runas_group.add_option('--become-method', dest='become_method', default=C.DEFAULT_BECOME_METHOD, type='choice', choices=C.BECOME_METHODS,",
            "                                   help=\"privilege escalation method to use (default=%s), valid choices: [ %s ]\" %",
            "                                   (C.DEFAULT_BECOME_METHOD, ' | '.join(C.BECOME_METHODS)))",
            "            runas_group.add_option('--become-user', default=None, dest='become_user', type='string',",
            "                                   help='run operations as this user (default=%s)' % C.DEFAULT_BECOME_USER)",
            "",
            "        if runas_opts or runas_prompt_opts:",
            "            if not runas_group:",
            "                runas_group = rg",
            "            runas_group.add_option('--ask-sudo-pass', default=C.DEFAULT_ASK_SUDO_PASS, dest='ask_sudo_pass', action='store_true',",
            "                                   help='ask for sudo password (deprecated, use become)')",
            "            runas_group.add_option('--ask-su-pass', default=C.DEFAULT_ASK_SU_PASS, dest='ask_su_pass', action='store_true',",
            "                                   help='ask for su password (deprecated, use become)')",
            "            runas_group.add_option('-K', '--ask-become-pass', default=False, dest='become_ask_pass', action='store_true',",
            "                                   help='ask for privilege escalation password')",
            "",
            "        if runas_group:",
            "            parser.add_option_group(runas_group)",
            "",
            "        if async_opts:",
            "            parser.add_option('-P', '--poll', default=C.DEFAULT_POLL_INTERVAL, type='int', dest='poll_interval',",
            "                              help=\"set the poll interval if using -B (default=%s)\" % C.DEFAULT_POLL_INTERVAL)",
            "            parser.add_option('-B', '--background', dest='seconds', type='int', default=0,",
            "                              help='run asynchronously, failing after X seconds (default=N/A)')",
            "",
            "        if check_opts:",
            "            parser.add_option(\"-C\", \"--check\", default=False, dest='check', action='store_true',",
            "                              help=\"don't make any changes; instead, try to predict some of the changes that may occur\")",
            "            parser.add_option('--syntax-check', dest='syntax', action='store_true',",
            "                              help=\"perform a syntax check on the playbook, but do not execute it\")",
            "            parser.add_option(\"-D\", \"--diff\", default=C.DIFF_ALWAYS, dest='diff', action='store_true',",
            "                              help=\"when changing (small) files and templates, show the differences in those files; works great with --check\")",
            "",
            "        if meta_opts:",
            "            parser.add_option('--force-handlers', default=C.DEFAULT_FORCE_HANDLERS, dest='force_handlers', action='store_true',",
            "                              help=\"run handlers even if a task fails\")",
            "            parser.add_option('--flush-cache', dest='flush_cache', action='store_true',",
            "                              help=\"clear the fact cache for every host in inventory\")",
            "",
            "        if basedir_opts:",
            "            parser.add_option('--playbook-dir', default=None, dest='basedir', action='store',",
            "                              help=\"Since this tool does not use playbooks, use this as a subsitute playbook directory.\"",
            "                                   \"This sets the relative path for many features including roles/ group_vars/ etc.\")",
            "        return parser",
            "",
            "    @abstractmethod",
            "    def parse(self):",
            "        \"\"\"Parse the command line args",
            "",
            "        This method parses the command line arguments.  It uses the parser",
            "        stored in the self.parser attribute and saves the args and options in",
            "        self.args and self.options respectively.",
            "",
            "        Subclasses need to implement this method.  They will usually create",
            "        a base_parser, add their own options to the base_parser, and then call",
            "        this method to do the actual parsing.  An implementation will look",
            "        something like this::",
            "",
            "            def parse(self):",
            "                parser = super(MyCLI, self).base_parser(usage=\"My Ansible CLI\", inventory_opts=True)",
            "                parser.add_option('--my-option', dest='my_option', action='store')",
            "                self.parser = parser",
            "                super(MyCLI, self).parse()",
            "                # If some additional transformations are needed for the",
            "                # arguments and options, do it here.",
            "        \"\"\"",
            "",
            "        self.options, self.args = self.parser.parse_args(self.args[1:])",
            "",
            "        # process tags",
            "        if hasattr(self.options, 'tags') and not self.options.tags:",
            "            # optparse defaults does not do what's expected",
            "            self.options.tags = ['all']",
            "        if hasattr(self.options, 'tags') and self.options.tags:",
            "            tags = set()",
            "            for tag_set in self.options.tags:",
            "                for tag in tag_set.split(u','):",
            "                    tags.add(tag.strip())",
            "            self.options.tags = list(tags)",
            "",
            "        # process skip_tags",
            "        if hasattr(self.options, 'skip_tags') and self.options.skip_tags:",
            "            skip_tags = set()",
            "            for tag_set in self.options.skip_tags:",
            "                for tag in tag_set.split(u','):",
            "                    skip_tags.add(tag.strip())",
            "            self.options.skip_tags = list(skip_tags)",
            "",
            "        # process inventory options except for CLIs that require their own processing",
            "        if hasattr(self.options, 'inventory') and not self.SKIP_INVENTORY_DEFAULTS:",
            "",
            "            if self.options.inventory:",
            "",
            "                # should always be list",
            "                if isinstance(self.options.inventory, string_types):",
            "                    self.options.inventory = [self.options.inventory]",
            "",
            "                # Ensure full paths when needed",
            "                self.options.inventory = [unfrackpath(opt, follow=False) if ',' not in opt else opt for opt in self.options.inventory]",
            "            else:",
            "                self.options.inventory = C.DEFAULT_HOST_LIST",
            "",
            "    @staticmethod",
            "    def version(prog):",
            "        ''' return ansible version '''",
            "        result = \"{0} {1}\".format(prog, __version__)",
            "        gitinfo = CLI._gitinfo()",
            "        if gitinfo:",
            "            result = result + \" {0}\".format(gitinfo)",
            "        result += \"\\n  config file = %s\" % C.CONFIG_FILE",
            "        if C.DEFAULT_MODULE_PATH is None:",
            "            cpath = \"Default w/o overrides\"",
            "        else:",
            "            cpath = C.DEFAULT_MODULE_PATH",
            "        result = result + \"\\n  configured module search path = %s\" % cpath",
            "        result = result + \"\\n  ansible python module location = %s\" % ':'.join(ansible.__path__)",
            "        result = result + \"\\n  executable location = %s\" % sys.argv[0]",
            "        result = result + \"\\n  python version = %s\" % ''.join(sys.version.splitlines())",
            "        return result",
            "",
            "    @staticmethod",
            "    def version_info(gitinfo=False):",
            "        ''' return full ansible version info '''",
            "        if gitinfo:",
            "            # expensive call, user with care",
            "            ansible_version_string = CLI.version('')",
            "        else:",
            "            ansible_version_string = __version__",
            "        ansible_version = ansible_version_string.split()[0]",
            "        ansible_versions = ansible_version.split('.')",
            "        for counter in range(len(ansible_versions)):",
            "            if ansible_versions[counter] == \"\":",
            "                ansible_versions[counter] = 0",
            "            try:",
            "                ansible_versions[counter] = int(ansible_versions[counter])",
            "            except Exception:",
            "                pass",
            "        if len(ansible_versions) < 3:",
            "            for counter in range(len(ansible_versions), 3):",
            "                ansible_versions.append(0)",
            "        return {'string': ansible_version_string.strip(),",
            "                'full': ansible_version,",
            "                'major': ansible_versions[0],",
            "                'minor': ansible_versions[1],",
            "                'revision': ansible_versions[2]}",
            "",
            "    @staticmethod",
            "    def _git_repo_info(repo_path):",
            "        ''' returns a string containing git branch, commit id and commit date '''",
            "        result = None",
            "        if os.path.exists(repo_path):",
            "            # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.",
            "            if os.path.isfile(repo_path):",
            "                try:",
            "                    gitdir = yaml.safe_load(open(repo_path)).get('gitdir')",
            "                    # There is a possibility the .git file to have an absolute path.",
            "                    if os.path.isabs(gitdir):",
            "                        repo_path = gitdir",
            "                    else:",
            "                        repo_path = os.path.join(repo_path[:-4], gitdir)",
            "                except (IOError, AttributeError):",
            "                    return ''",
            "            f = open(os.path.join(repo_path, \"HEAD\"))",
            "            line = f.readline().rstrip(\"\\n\")",
            "            if line.startswith(\"ref:\"):",
            "                branch_path = os.path.join(repo_path, line[5:])",
            "            else:",
            "                branch_path = None",
            "            f.close()",
            "            if branch_path and os.path.exists(branch_path):",
            "                branch = '/'.join(line.split('/')[2:])",
            "                f = open(branch_path)",
            "                commit = f.readline()[:10]",
            "                f.close()",
            "            else:",
            "                # detached HEAD",
            "                commit = line[:10]",
            "                branch = 'detached HEAD'",
            "                branch_path = os.path.join(repo_path, \"HEAD\")",
            "",
            "            date = time.localtime(os.stat(branch_path).st_mtime)",
            "            if time.daylight == 0:",
            "                offset = time.timezone",
            "            else:",
            "                offset = time.altzone",
            "            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit, time.strftime(\"%Y/%m/%d %H:%M:%S\", date), int(offset / -36))",
            "        else:",
            "            result = ''",
            "        return result",
            "",
            "    @staticmethod",
            "    def _gitinfo():",
            "        basedir = os.path.join(os.path.dirname(__file__), '..', '..', '..')",
            "        repo_path = os.path.join(basedir, '.git')",
            "        result = CLI._git_repo_info(repo_path)",
            "        submodules = os.path.join(basedir, '.gitmodules')",
            "        if not os.path.exists(submodules):",
            "            return result",
            "        f = open(submodules)",
            "        for line in f:",
            "            tokens = line.strip().split(' ')",
            "            if tokens[0] == 'path':",
            "                submodule_path = tokens[2]",
            "                submodule_info = CLI._git_repo_info(os.path.join(basedir, submodule_path, '.git'))",
            "                if not submodule_info:",
            "                    submodule_info = ' not found - use git submodule update --init ' + submodule_path",
            "                result += \"\\n  {0}: {1}\".format(submodule_path, submodule_info)",
            "        f.close()",
            "        return result",
            "",
            "    def pager(self, text):",
            "        ''' find reasonable way to display text '''",
            "        # this is a much simpler form of what is in pydoc.py",
            "        if not sys.stdout.isatty():",
            "            display.display(text, screen_only=True)",
            "        elif 'PAGER' in os.environ:",
            "            if sys.platform == 'win32':",
            "                display.display(text, screen_only=True)",
            "            else:",
            "                self.pager_pipe(text, os.environ['PAGER'])",
            "        else:",
            "            p = subprocess.Popen('less --version', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
            "            p.communicate()",
            "            if p.returncode == 0:",
            "                self.pager_pipe(text, 'less')",
            "            else:",
            "                display.display(text, screen_only=True)",
            "",
            "    @staticmethod",
            "    def pager_pipe(text, cmd):",
            "        ''' pipe text through a pager '''",
            "        if 'LESS' not in os.environ:",
            "            os.environ['LESS'] = CLI.LESS_OPTS",
            "        try:",
            "            cmd = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=sys.stdout)",
            "            cmd.communicate(input=to_bytes(text))",
            "        except IOError:",
            "            pass",
            "        except KeyboardInterrupt:",
            "            pass",
            "",
            "    @classmethod",
            "    def tty_ify(cls, text):",
            "",
            "        t = cls._ITALIC.sub(\"`\" + r\"\\1\" + \"'\", text)    # I(word) => `word'",
            "        t = cls._BOLD.sub(\"*\" + r\"\\1\" + \"*\", t)         # B(word) => *word*",
            "        t = cls._MODULE.sub(\"[\" + r\"\\1\" + \"]\", t)       # M(word) => [word]",
            "        t = cls._URL.sub(r\"\\1\", t)                      # U(word) => word",
            "        t = cls._CONST.sub(\"`\" + r\"\\1\" + \"'\", t)        # C(word) => `word'",
            "",
            "        return t",
            "",
            "    @staticmethod",
            "    def _play_prereqs(options):",
            "",
            "        # all needs loader",
            "        loader = DataLoader()",
            "",
            "        basedir = getattr(options, 'basedir', False)",
            "        if basedir:",
            "            loader.set_basedir(basedir)",
            "",
            "        vault_ids = options.vault_ids",
            "        default_vault_ids = C.DEFAULT_VAULT_IDENTITY_LIST",
            "        vault_ids = default_vault_ids + vault_ids",
            "",
            "        vault_secrets = CLI.setup_vault_secrets(loader,",
            "                                                vault_ids=vault_ids,",
            "                                                vault_password_files=options.vault_password_files,",
            "                                                ask_vault_pass=options.ask_vault_pass,",
            "                                                auto_prompt=False)",
            "        loader.set_vault_secrets(vault_secrets)",
            "",
            "        # create the inventory, and filter it based on the subset specified (if any)",
            "        inventory = InventoryManager(loader=loader, sources=options.inventory)",
            "",
            "        # create the variable manager, which will be shared throughout",
            "        # the code, ensuring a consistent view of global variables",
            "        variable_manager = VariableManager(loader=loader, inventory=inventory)",
            "",
            "        if hasattr(options, 'basedir'):",
            "            if options.basedir:",
            "                variable_manager.safe_basedir = True",
            "        else:",
            "            variable_manager.safe_basedir = True",
            "",
            "        # load vars from cli options",
            "        variable_manager.extra_vars = load_extra_vars(loader=loader, options=options)",
            "        variable_manager.options_vars = load_options_vars(options, CLI.version_info(gitinfo=False))",
            "",
            "        return loader, inventory, variable_manager",
            "",
            "    @staticmethod",
            "    def get_host_list(inventory, subset, pattern='all'):",
            "",
            "        no_hosts = False",
            "        if len(inventory.list_hosts()) == 0:",
            "            # Empty inventory",
            "            if C.LOCALHOST_WARNING:",
            "                display.warning(\"provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\")",
            "            no_hosts = True",
            "",
            "        inventory.subset(subset)",
            "",
            "        hosts = inventory.list_hosts(pattern)",
            "        if len(hosts) == 0 and no_hosts is False:",
            "            raise AnsibleError(\"Specified hosts and/or --limit does not match any hosts\")",
            "",
            "        return hosts"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "45": [],
            "326": [
                "CLI",
                "ask_passwords"
            ],
            "327": [
                "CLI",
                "ask_passwords"
            ],
            "335": [
                "CLI",
                "ask_passwords"
            ],
            "336": [
                "CLI",
                "ask_passwords"
            ],
            "343": [
                "CLI",
                "ask_passwords"
            ],
            "345": [
                "CLI",
                "ask_passwords"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/template/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": 220,
                "PatchRowcode": "             for item in val:"
            },
            "1": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": 221,
                "PatchRowcode": "                 if self._is_unsafe(item):"
            },
            "2": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": 222,
                "PatchRowcode": "                     return True"
            },
            "3": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        elif isinstance(val, string_types) and hasattr(val, '__UNSAFE__'):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+        elif hasattr(val, '__UNSAFE__'):"
            },
            "5": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": 224,
                "PatchRowcode": "             return True"
            },
            "6": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "         return False"
            },
            "7": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 226,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import contextlib",
            "import datetime",
            "import os",
            "import pwd",
            "import re",
            "import time",
            "",
            "from collections import Sequence, Mapping",
            "from functools import wraps",
            "from io import StringIO",
            "from numbers import Number",
            "",
            "try:",
            "    from hashlib import sha1",
            "except ImportError:",
            "    from sha import sha as sha1",
            "",
            "from jinja2.exceptions import TemplateSyntaxError, UndefinedError",
            "from jinja2.loaders import FileSystemLoader",
            "from jinja2.runtime import Context, StrictUndefined",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleFilterError, AnsibleUndefinedVariable, AnsibleAssertionError",
            "from ansible.module_utils.six import string_types, text_type",
            "from ansible.module_utils._text import to_native, to_text, to_bytes",
            "from ansible.plugins.loader import filter_loader, lookup_loader, test_loader",
            "from ansible.template.safe_eval import safe_eval",
            "from ansible.template.template import AnsibleJ2Template",
            "from ansible.template.vars import AnsibleJ2Vars",
            "from ansible.utils.unsafe_proxy import UnsafeProxy, wrap_var",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "__all__ = ['Templar', 'generate_ansible_template_vars']",
            "",
            "# A regex for checking to see if a variable we're trying to",
            "# expand is just a single variable name.",
            "",
            "# Primitive Types which we don't want Jinja to convert to strings.",
            "NON_TEMPLATED_TYPES = (bool, Number)",
            "",
            "JINJA2_OVERRIDE = '#jinja2:'",
            "",
            "USE_JINJA2_NATIVE = False",
            "if C.DEFAULT_JINJA2_NATIVE:",
            "    try:",
            "        from jinja2.nativetypes import NativeEnvironment as Environment",
            "        from ansible.template.native_helpers import ansible_native_concat as j2_concat",
            "        USE_JINJA2_NATIVE = True",
            "    except ImportError:",
            "        from jinja2 import Environment",
            "        from jinja2.utils import concat as j2_concat",
            "        from jinja2 import __version__ as j2_version",
            "        display.warning(",
            "            'jinja2_native requires Jinja 2.10 and above. '",
            "            'Version detected: %s. Falling back to default.' % j2_version",
            "        )",
            "else:",
            "    from jinja2 import Environment",
            "    from jinja2.utils import concat as j2_concat",
            "",
            "",
            "def generate_ansible_template_vars(path):",
            "    b_path = to_bytes(path)",
            "    try:",
            "        template_uid = pwd.getpwuid(os.stat(b_path).st_uid).pw_name",
            "    except (KeyError, TypeError):",
            "        template_uid = os.stat(b_path).st_uid",
            "",
            "    temp_vars = {}",
            "    temp_vars['template_host'] = to_text(os.uname()[1])",
            "    temp_vars['template_path'] = path",
            "    temp_vars['template_mtime'] = datetime.datetime.fromtimestamp(os.path.getmtime(b_path))",
            "    temp_vars['template_uid'] = to_text(template_uid)",
            "    temp_vars['template_fullpath'] = os.path.abspath(path)",
            "    temp_vars['template_run_date'] = datetime.datetime.now()",
            "",
            "    managed_default = C.DEFAULT_MANAGED_STR",
            "    managed_str = managed_default.format(",
            "        host=temp_vars['template_host'],",
            "        uid=temp_vars['template_uid'],",
            "        file=temp_vars['template_path'],",
            "    )",
            "    temp_vars['ansible_managed'] = to_text(time.strftime(to_native(managed_str), time.localtime(os.path.getmtime(b_path))))",
            "",
            "    return temp_vars",
            "",
            "",
            "def _escape_backslashes(data, jinja_env):",
            "    \"\"\"Double backslashes within jinja2 expressions",
            "",
            "    A user may enter something like this in a playbook::",
            "",
            "      debug:",
            "        msg: \"Test Case 1\\\\3; {{ test1_name | regex_replace('^(.*)_name$', '\\\\1')}}\"",
            "",
            "    The string inside of the {{ gets interpreted multiple times First by yaml.",
            "    Then by python.  And finally by jinja2 as part of it's variable.  Because",
            "    it is processed by both python and jinja2, the backslash escaped",
            "    characters get unescaped twice.  This means that we'd normally have to use",
            "    four backslashes to escape that.  This is painful for playbook authors as",
            "    they have to remember different rules for inside vs outside of a jinja2",
            "    expression (The backslashes outside of the \"{{ }}\" only get processed by",
            "    yaml and python.  So they only need to be escaped once).  The following",
            "    code fixes this by automatically performing the extra quoting of",
            "    backslashes inside of a jinja2 expression.",
            "",
            "    \"\"\"",
            "    if '\\\\' in data and '{{' in data:",
            "        new_data = []",
            "        d2 = jinja_env.preprocess(data)",
            "        in_var = False",
            "",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] == 'variable_begin':",
            "                in_var = True",
            "                new_data.append(token[2])",
            "            elif token[1] == 'variable_end':",
            "                in_var = False",
            "                new_data.append(token[2])",
            "            elif in_var and token[1] == 'string':",
            "                # Double backslashes only if we're inside of a jinja2 variable",
            "                new_data.append(token[2].replace('\\\\', '\\\\\\\\'))",
            "            else:",
            "                new_data.append(token[2])",
            "",
            "        data = ''.join(new_data)",
            "",
            "    return data",
            "",
            "",
            "def _count_newlines_from_end(in_str):",
            "    '''",
            "    Counts the number of newlines at the end of a string. This is used during",
            "    the jinja2 templating to ensure the count matches the input, since some newlines",
            "    may be thrown away during the templating.",
            "    '''",
            "",
            "    try:",
            "        i = len(in_str)",
            "        j = i - 1",
            "        while in_str[j] == '\\n':",
            "            j -= 1",
            "        return i - 1 - j",
            "    except IndexError:",
            "        # Uncommon cases: zero length string and string containing only newlines",
            "        return i",
            "",
            "",
            "def tests_as_filters_warning(name, func):",
            "    '''",
            "    Closure to enable displaying a deprecation warning when tests are used as a filter",
            "",
            "    This closure is only used when registering ansible provided tests as filters",
            "",
            "    This function should be removed in 2.9 along with registering ansible provided tests as filters",
            "    in Templar._get_filters",
            "    '''",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        display.deprecated(",
            "            'Using tests as filters is deprecated. Instead of using `result|%(name)s` use '",
            "            '`result is %(name)s`' % dict(name=name),",
            "            version='2.9'",
            "        )",
            "        return func(*args, **kwargs)",
            "    return wrapper",
            "",
            "",
            "class AnsibleContext(Context):",
            "    '''",
            "    A custom context, which intercepts resolve() calls and sets a flag",
            "    internally if any variable lookup returns an AnsibleUnsafe value. This",
            "    flag is checked post-templating, and (when set) will result in the",
            "    final templated result being wrapped via UnsafeProxy.",
            "    '''",
            "    def __init__(self, *args, **kwargs):",
            "        super(AnsibleContext, self).__init__(*args, **kwargs)",
            "        self.unsafe = False",
            "",
            "    def _is_unsafe(self, val):",
            "        '''",
            "        Our helper function, which will also recursively check dict and",
            "        list entries due to the fact that they may be repr'd and contain",
            "        a key or value which contains jinja2 syntax and would otherwise",
            "        lose the AnsibleUnsafe value.",
            "        '''",
            "        if isinstance(val, dict):",
            "            for key in val.keys():",
            "                if self._is_unsafe(val[key]):",
            "                    return True",
            "        elif isinstance(val, list):",
            "            for item in val:",
            "                if self._is_unsafe(item):",
            "                    return True",
            "        elif isinstance(val, string_types) and hasattr(val, '__UNSAFE__'):",
            "            return True",
            "        return False",
            "",
            "    def _update_unsafe(self, val):",
            "        if val is not None and not self.unsafe and self._is_unsafe(val):",
            "            self.unsafe = True",
            "",
            "    def resolve(self, key):",
            "        '''",
            "        The intercepted resolve(), which uses the helper above to set the",
            "        internal flag whenever an unsafe variable value is returned.",
            "        '''",
            "        val = super(AnsibleContext, self).resolve(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "    def resolve_or_missing(self, key):",
            "        val = super(AnsibleContext, self).resolve_or_missing(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "",
            "class AnsibleEnvironment(Environment):",
            "    '''",
            "    Our custom environment, which simply allows us to override the class-level",
            "    values for the Template and Context classes used by jinja2 internally.",
            "    '''",
            "    context_class = AnsibleContext",
            "    template_class = AnsibleJ2Template",
            "",
            "",
            "class Templar:",
            "    '''",
            "    The main class for templating, with the main entry-point of template().",
            "    '''",
            "",
            "    def __init__(self, loader, shared_loader_obj=None, variables=None):",
            "        variables = {} if variables is None else variables",
            "",
            "        self._loader = loader",
            "        self._filters = None",
            "        self._tests = None",
            "        self._available_variables = variables",
            "        self._cached_result = {}",
            "",
            "        if loader:",
            "            self._basedir = loader.get_basedir()",
            "        else:",
            "            self._basedir = './'",
            "",
            "        if shared_loader_obj:",
            "            self._filter_loader = getattr(shared_loader_obj, 'filter_loader')",
            "            self._test_loader = getattr(shared_loader_obj, 'test_loader')",
            "            self._lookup_loader = getattr(shared_loader_obj, 'lookup_loader')",
            "        else:",
            "            self._filter_loader = filter_loader",
            "            self._test_loader = test_loader",
            "            self._lookup_loader = lookup_loader",
            "",
            "        # flags to determine whether certain failures during templating",
            "        # should result in fatal errors being raised",
            "        self._fail_on_lookup_errors = True",
            "        self._fail_on_filter_errors = True",
            "        self._fail_on_undefined_errors = C.DEFAULT_UNDEFINED_VAR_BEHAVIOR",
            "",
            "        self.environment = AnsibleEnvironment(",
            "            trim_blocks=True,",
            "            undefined=StrictUndefined,",
            "            extensions=self._get_extensions(),",
            "            finalize=self._finalize,",
            "            loader=FileSystemLoader(self._basedir),",
            "        )",
            "",
            "        # the current rendering context under which the templar class is working",
            "        self.cur_context = None",
            "",
            "        self.SINGLE_VAR = re.compile(r\"^%s\\s*(\\w*)\\s*%s$\" % (self.environment.variable_start_string, self.environment.variable_end_string))",
            "",
            "        self._clean_regex = re.compile(r'(?:%s|%s|%s|%s)' % (",
            "            self.environment.variable_start_string,",
            "            self.environment.block_start_string,",
            "            self.environment.block_end_string,",
            "            self.environment.variable_end_string",
            "        ))",
            "        self._no_type_regex = re.compile(r'.*?\\|\\s*(?:%s)(?:\\([^\\|]*\\))?\\s*\\)?\\s*(?:%s)' %",
            "                                         ('|'.join(C.STRING_TYPE_FILTERS), self.environment.variable_end_string))",
            "",
            "    def _get_filters(self, builtin_filters):",
            "        '''",
            "        Returns filter plugins, after loading and caching them if need be",
            "        '''",
            "",
            "        if self._filters is not None:",
            "            return self._filters.copy()",
            "",
            "        self._filters = dict()",
            "",
            "        # TODO: Remove registering tests as filters in 2.9",
            "        for name, func in self._get_tests().items():",
            "            if name in builtin_filters:",
            "                # If we have a custom test named the same as a builtin filter, don't register as a filter",
            "                continue",
            "            self._filters[name] = tests_as_filters_warning(name, func)",
            "",
            "        for fp in self._filter_loader.all():",
            "            self._filters.update(fp.filters())",
            "",
            "        return self._filters.copy()",
            "",
            "    def _get_tests(self):",
            "        '''",
            "        Returns tests plugins, after loading and caching them if need be",
            "        '''",
            "",
            "        if self._tests is not None:",
            "            return self._tests.copy()",
            "",
            "        self._tests = dict()",
            "        for fp in self._test_loader.all():",
            "            self._tests.update(fp.tests())",
            "",
            "        return self._tests.copy()",
            "",
            "    def _get_extensions(self):",
            "        '''",
            "        Return jinja2 extensions to load.",
            "",
            "        If some extensions are set via jinja_extensions in ansible.cfg, we try",
            "        to load them with the jinja environment.",
            "        '''",
            "",
            "        jinja_exts = []",
            "        if C.DEFAULT_JINJA2_EXTENSIONS:",
            "            # make sure the configuration directive doesn't contain spaces",
            "            # and split extensions in an array",
            "            jinja_exts = C.DEFAULT_JINJA2_EXTENSIONS.replace(\" \", \"\").split(',')",
            "",
            "        return jinja_exts",
            "",
            "    def _clean_data(self, orig_data):",
            "        ''' remove jinja2 template tags from data '''",
            "",
            "        if hasattr(orig_data, '__ENCRYPTED__'):",
            "            ret = orig_data",
            "",
            "        elif isinstance(orig_data, list):",
            "            clean_list = []",
            "            for list_item in orig_data:",
            "                clean_list.append(self._clean_data(list_item))",
            "            ret = clean_list",
            "",
            "        elif isinstance(orig_data, (dict, Mapping)):",
            "            clean_dict = {}",
            "            for k in orig_data:",
            "                clean_dict[self._clean_data(k)] = self._clean_data(orig_data[k])",
            "            ret = clean_dict",
            "",
            "        elif isinstance(orig_data, string_types):",
            "            # This will error with str data (needs unicode), but all strings should already be converted already.",
            "            # If you get exception, the problem is at the data origin, do not add to_text here.",
            "            with contextlib.closing(StringIO(orig_data)) as data:",
            "                # these variables keep track of opening block locations, as we only",
            "                # want to replace matched pairs of print/block tags",
            "                print_openings = []",
            "                block_openings = []",
            "                for mo in self._clean_regex.finditer(orig_data):",
            "                    token = mo.group(0)",
            "                    token_start = mo.start(0)",
            "",
            "                    if token[0] == self.environment.variable_start_string[0]:",
            "                        if token == self.environment.block_start_string:",
            "                            block_openings.append(token_start)",
            "                        elif token == self.environment.variable_start_string:",
            "                            print_openings.append(token_start)",
            "",
            "                    elif token[1] == self.environment.variable_end_string[1]:",
            "                        prev_idx = None",
            "                        if token == self.environment.block_end_string and block_openings:",
            "                            prev_idx = block_openings.pop()",
            "                        elif token == self.environment.variable_end_string and print_openings:",
            "                            prev_idx = print_openings.pop()",
            "",
            "                        if prev_idx is not None:",
            "                            # replace the opening",
            "                            data.seek(prev_idx, os.SEEK_SET)",
            "                            data.write(to_text(self.environment.comment_start_string))",
            "                            # replace the closing",
            "                            data.seek(token_start, os.SEEK_SET)",
            "                            data.write(to_text(self.environment.comment_end_string))",
            "",
            "                    else:",
            "                        raise AnsibleError(\"Error while cleaning data for safety: unhandled regex match\")",
            "",
            "                ret = data.getvalue()",
            "        else:",
            "            ret = orig_data",
            "",
            "        return ret",
            "",
            "    def set_available_variables(self, variables):",
            "        '''",
            "        Sets the list of template variables this Templar instance will use",
            "        to template things, so we don't have to pass them around between",
            "        internal methods. We also clear the template cache here, as the variables",
            "        are being changed.",
            "        '''",
            "",
            "        if not isinstance(variables, dict):",
            "            raise AnsibleAssertionError(\"the type of 'variables' should be a dict but was a %s\" % (type(variables)))",
            "        self._available_variables = variables",
            "        self._cached_result = {}",
            "",
            "    def template(self, variable, convert_bare=False, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None,",
            "                 convert_data=True, static_vars=None, cache=True, disable_lookups=False):",
            "        '''",
            "        Templates (possibly recursively) any given data as input. If convert_bare is",
            "        set to True, the given data will be wrapped as a jinja2 variable ('{{foo}}')",
            "        before being sent through the template engine.",
            "        '''",
            "        static_vars = [''] if static_vars is None else static_vars",
            "",
            "        # Don't template unsafe variables, just return them.",
            "        if hasattr(variable, '__UNSAFE__'):",
            "            return variable",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            if convert_bare:",
            "                variable = self._convert_bare_variable(variable)",
            "",
            "            if isinstance(variable, string_types):",
            "                result = variable",
            "",
            "                if self._contains_vars(variable):",
            "                    # Check to see if the string we are trying to render is just referencing a single",
            "                    # var.  In this case we don't want to accidentally change the type of the variable",
            "                    # to a string by using the jinja template renderer. We just want to pass it.",
            "                    only_one = self.SINGLE_VAR.match(variable)",
            "                    if only_one:",
            "                        var_name = only_one.group(1)",
            "                        if var_name in self._available_variables:",
            "                            resolved_val = self._available_variables[var_name]",
            "                            if isinstance(resolved_val, NON_TEMPLATED_TYPES):",
            "                                return resolved_val",
            "                            elif resolved_val is None:",
            "                                return C.DEFAULT_NULL_REPRESENTATION",
            "",
            "                    # Using a cache in order to prevent template calls with already templated variables",
            "                    sha1_hash = None",
            "                    if cache:",
            "                        variable_hash = sha1(text_type(variable).encode('utf-8'))",
            "                        options_hash = sha1(",
            "                            (",
            "                                text_type(preserve_trailing_newlines) +",
            "                                text_type(escape_backslashes) +",
            "                                text_type(fail_on_undefined) +",
            "                                text_type(overrides)",
            "                            ).encode('utf-8')",
            "                        )",
            "                        sha1_hash = variable_hash.hexdigest() + options_hash.hexdigest()",
            "                    if cache and sha1_hash in self._cached_result:",
            "                        result = self._cached_result[sha1_hash]",
            "                    else:",
            "                        result = self.do_template(",
            "                            variable,",
            "                            preserve_trailing_newlines=preserve_trailing_newlines,",
            "                            escape_backslashes=escape_backslashes,",
            "                            fail_on_undefined=fail_on_undefined,",
            "                            overrides=overrides,",
            "                            disable_lookups=disable_lookups,",
            "                        )",
            "",
            "                        if not USE_JINJA2_NATIVE:",
            "                            unsafe = hasattr(result, '__UNSAFE__')",
            "                            if convert_data and not self._no_type_regex.match(variable):",
            "                                # if this looks like a dictionary or list, convert it to such using the safe_eval method",
            "                                if (result.startswith(\"{\") and not result.startswith(self.environment.variable_start_string)) or \\",
            "                                        result.startswith(\"[\") or result in (\"True\", \"False\"):",
            "                                    eval_results = safe_eval(result, include_exceptions=True)",
            "                                    if eval_results[1] is None:",
            "                                        result = eval_results[0]",
            "                                        if unsafe:",
            "                                            result = wrap_var(result)",
            "                                    else:",
            "                                        # FIXME: if the safe_eval raised an error, should we do something with it?",
            "                                        pass",
            "",
            "                        # we only cache in the case where we have a single variable",
            "                        # name, to make sure we're not putting things which may otherwise",
            "                        # be dynamic in the cache (filters, lookups, etc.)",
            "                        if cache:",
            "                            self._cached_result[sha1_hash] = result",
            "",
            "                return result",
            "",
            "            elif isinstance(variable, (list, tuple)):",
            "                return [self.template(",
            "                    v,",
            "                    preserve_trailing_newlines=preserve_trailing_newlines,",
            "                    fail_on_undefined=fail_on_undefined,",
            "                    overrides=overrides,",
            "                    disable_lookups=disable_lookups,",
            "                ) for v in variable]",
            "            elif isinstance(variable, (dict, Mapping)):",
            "                d = {}",
            "                # we don't use iteritems() here to avoid problems if the underlying dict",
            "                # changes sizes due to the templating, which can happen with hostvars",
            "                for k in variable.keys():",
            "                    if k not in static_vars:",
            "                        d[k] = self.template(",
            "                            variable[k],",
            "                            preserve_trailing_newlines=preserve_trailing_newlines,",
            "                            fail_on_undefined=fail_on_undefined,",
            "                            overrides=overrides,",
            "                            disable_lookups=disable_lookups,",
            "                        )",
            "                    else:",
            "                        d[k] = variable[k]",
            "                return d",
            "            else:",
            "                return variable",
            "",
            "        except AnsibleFilterError:",
            "            if self._fail_on_filter_errors:",
            "                raise",
            "            else:",
            "                return variable",
            "",
            "    def is_template(self, data):",
            "        ''' lets us know if data has a template'''",
            "        if isinstance(data, string_types):",
            "            try:",
            "                new = self.do_template(data, fail_on_undefined=True)",
            "            except (AnsibleUndefinedVariable, UndefinedError):",
            "                return True",
            "            except:",
            "                return False",
            "            return (new != data)",
            "        elif isinstance(data, (list, tuple)):",
            "            for v in data:",
            "                if self.is_template(v):",
            "                    return True",
            "        elif isinstance(data, dict):",
            "            for k in data:",
            "                if self.is_template(k) or self.is_template(data[k]):",
            "                    return True",
            "        return False",
            "",
            "    def templatable(self, data):",
            "        '''",
            "        returns True if the data can be templated w/o errors",
            "        '''",
            "        templatable = True",
            "        try:",
            "            self.template(data)",
            "        except:",
            "            templatable = False",
            "        return templatable",
            "",
            "    def _contains_vars(self, data):",
            "        '''",
            "        returns True if the data contains a variable pattern",
            "        '''",
            "        if isinstance(data, string_types):",
            "            for marker in (self.environment.block_start_string, self.environment.variable_start_string, self.environment.comment_start_string):",
            "                if marker in data:",
            "                    return True",
            "        return False",
            "",
            "    def _convert_bare_variable(self, variable):",
            "        '''",
            "        Wraps a bare string, which may have an attribute portion (ie. foo.bar)",
            "        in jinja2 variable braces so that it is evaluated properly.",
            "        '''",
            "",
            "        if isinstance(variable, string_types):",
            "            contains_filters = \"|\" in variable",
            "            first_part = variable.split(\"|\")[0].split(\".\")[0].split(\"[\")[0]",
            "            if (contains_filters or first_part in self._available_variables) and self.environment.variable_start_string not in variable:",
            "                return \"%s%s%s\" % (self.environment.variable_start_string, variable, self.environment.variable_end_string)",
            "",
            "        # the variable didn't meet the conditions to be converted,",
            "        # so just return it as-is",
            "        return variable",
            "",
            "    def _finalize(self, thing):",
            "        '''",
            "        A custom finalize method for jinja2, which prevents None from being returned. This",
            "        avoids a string of ``\"None\"`` as ``None`` has no importance in YAML.",
            "",
            "        If using ANSIBLE_JINJA2_NATIVE we bypass this and return the actual value always",
            "        '''",
            "        if USE_JINJA2_NATIVE:",
            "            return thing",
            "        return thing if thing is not None else ''",
            "",
            "    def _fail_lookup(self, name, *args, **kwargs):",
            "        raise AnsibleError(\"The lookup `%s` was found, however lookups were disabled from templating\" % name)",
            "",
            "    def _query_lookup(self, name, *args, **kwargs):",
            "        ''' wrapper for lookup, force wantlist true'''",
            "        kwargs['wantlist'] = True",
            "        return self._lookup(name, *args, **kwargs)",
            "",
            "    def _lookup(self, name, *args, **kwargs):",
            "        instance = self._lookup_loader.get(name.lower(), loader=self._loader, templar=self)",
            "",
            "        if instance is not None:",
            "            wantlist = kwargs.pop('wantlist', False)",
            "            allow_unsafe = kwargs.pop('allow_unsafe', C.DEFAULT_ALLOW_UNSAFE_LOOKUPS)",
            "            errors = kwargs.pop('errors', 'strict')",
            "",
            "            from ansible.utils.listify import listify_lookup_plugin_terms",
            "            loop_terms = listify_lookup_plugin_terms(terms=args, templar=self, loader=self._loader, fail_on_undefined=True, convert_bare=False)",
            "            # safely catch run failures per #5059",
            "            try:",
            "                ran = instance.run(loop_terms, variables=self._available_variables, **kwargs)",
            "            except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "                raise AnsibleUndefinedVariable(e)",
            "            except Exception as e:",
            "                if self._fail_on_lookup_errors:",
            "                    msg = u\"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s\" % \\",
            "                          (name, type(e), to_text(e))",
            "                    if errors == 'warn':",
            "                        display.warning(msg)",
            "                    elif errors == 'ignore':",
            "                        display.display(msg, log_only=True)",
            "                    else:",
            "                        raise AnsibleError(to_native(msg))",
            "                ran = None",
            "",
            "            if ran and not allow_unsafe:",
            "                if wantlist:",
            "                    ran = wrap_var(ran)",
            "                else:",
            "                    try:",
            "                        ran = UnsafeProxy(\",\".join(ran))",
            "                    except TypeError:",
            "                        # Lookup Plugins should always return lists.  Throw an error if that's not",
            "                        # the case:",
            "                        if not isinstance(ran, Sequence):",
            "                            raise AnsibleError(\"The lookup plugin '%s' did not return a list.\"",
            "                                               % name)",
            "",
            "                        # The TypeError we can recover from is when the value *inside* of the list",
            "                        # is not a string",
            "                        if len(ran) == 1:",
            "                            ran = wrap_var(ran[0])",
            "                        else:",
            "                            ran = wrap_var(ran)",
            "",
            "                if self.cur_context:",
            "                    self.cur_context.unsafe = True",
            "            return ran",
            "        else:",
            "            raise AnsibleError(\"lookup plugin (%s) not found\" % name)",
            "",
            "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False):",
            "        if USE_JINJA2_NATIVE and not isinstance(data, string_types):",
            "            return data",
            "",
            "        # For preserving the number of input newlines in the output (used",
            "        # later in this method)",
            "        data_newlines = _count_newlines_from_end(data)",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            # allows template header overrides to change jinja2 options.",
            "            if overrides is None:",
            "                myenv = self.environment.overlay()",
            "            else:",
            "                myenv = self.environment.overlay(overrides)",
            "",
            "            # Get jinja env overrides from template",
            "            if hasattr(data, 'startswith') and data.startswith(JINJA2_OVERRIDE):",
            "                eol = data.find('\\n')",
            "                line = data[len(JINJA2_OVERRIDE):eol]",
            "                data = data[eol + 1:]",
            "                for pair in line.split(','):",
            "                    (key, val) = pair.split(':')",
            "                    key = key.strip()",
            "                    setattr(myenv, key, ast.literal_eval(val.strip()))",
            "",
            "            # Adds Ansible custom filters and tests",
            "            myenv.filters.update(self._get_filters(myenv.filters))",
            "            myenv.tests.update(self._get_tests())",
            "",
            "            if escape_backslashes:",
            "                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".",
            "                data = _escape_backslashes(data, myenv)",
            "",
            "            try:",
            "                t = myenv.from_string(data)",
            "            except TemplateSyntaxError as e:",
            "                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)))",
            "            except Exception as e:",
            "                if 'recursion' in to_native(e):",
            "                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data))",
            "                else:",
            "                    return data",
            "",
            "            # jinja2 global is inconsistent across versions, this normalizes them",
            "            t.globals['dict'] = dict",
            "",
            "            if disable_lookups:",
            "                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup",
            "            else:",
            "                t.globals['lookup'] = self._lookup",
            "                t.globals['query'] = t.globals['q'] = self._query_lookup",
            "",
            "            t.globals['finalize'] = self._finalize",
            "",
            "            jvars = AnsibleJ2Vars(self, t.globals)",
            "",
            "            self.cur_context = new_context = t.new_context(jvars, shared=True)",
            "            rf = t.root_render_func(new_context)",
            "",
            "            try:",
            "                res = j2_concat(rf)",
            "                if getattr(new_context, 'unsafe', False):",
            "                    res = wrap_var(res)",
            "            except TypeError as te:",
            "                if 'StrictUndefined' in to_native(te):",
            "                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)",
            "                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)",
            "                    raise AnsibleUndefinedVariable(errmsg)",
            "                else:",
            "                    display.debug(\"failing because of a type error, template data is: %s\" % to_native(data))",
            "                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)))",
            "",
            "            if USE_JINJA2_NATIVE and not isinstance(res, string_types):",
            "                return res",
            "",
            "            if preserve_trailing_newlines:",
            "                # The low level calls above do not preserve the newline",
            "                # characters at the end of the input data, so we use the",
            "                # calculate the difference in newlines and append them",
            "                # to the resulting output for parity",
            "                #",
            "                # jinja2 added a keep_trailing_newline option in 2.7 when",
            "                # creating an Environment.  That would let us make this code",
            "                # better (remove a single newline if",
            "                # preserve_trailing_newlines is False).  Once we can depend on",
            "                # that version being present, modify our code to set that when",
            "                # initializing self.environment and remove a single trailing",
            "                # newline here if preserve_newlines is False.",
            "                res_newlines = _count_newlines_from_end(res)",
            "                if data_newlines > res_newlines:",
            "                    res += self.environment.newline_sequence * (data_newlines - res_newlines)",
            "            return res",
            "        except (UndefinedError, AnsibleUndefinedVariable) as e:",
            "            if fail_on_undefined:",
            "                raise AnsibleUndefinedVariable(e)",
            "            else:",
            "                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))",
            "                return data",
            "",
            "    # for backwards compatibility in case anyone is using old private method directly",
            "    _do_template = do_template"
        ],
        "afterPatchFile": [
            "# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "# Make coding more python3-ish",
            "from __future__ import (absolute_import, division, print_function)",
            "__metaclass__ = type",
            "",
            "import ast",
            "import contextlib",
            "import datetime",
            "import os",
            "import pwd",
            "import re",
            "import time",
            "",
            "from collections import Sequence, Mapping",
            "from functools import wraps",
            "from io import StringIO",
            "from numbers import Number",
            "",
            "try:",
            "    from hashlib import sha1",
            "except ImportError:",
            "    from sha import sha as sha1",
            "",
            "from jinja2.exceptions import TemplateSyntaxError, UndefinedError",
            "from jinja2.loaders import FileSystemLoader",
            "from jinja2.runtime import Context, StrictUndefined",
            "",
            "from ansible import constants as C",
            "from ansible.errors import AnsibleError, AnsibleFilterError, AnsibleUndefinedVariable, AnsibleAssertionError",
            "from ansible.module_utils.six import string_types, text_type",
            "from ansible.module_utils._text import to_native, to_text, to_bytes",
            "from ansible.plugins.loader import filter_loader, lookup_loader, test_loader",
            "from ansible.template.safe_eval import safe_eval",
            "from ansible.template.template import AnsibleJ2Template",
            "from ansible.template.vars import AnsibleJ2Vars",
            "from ansible.utils.unsafe_proxy import UnsafeProxy, wrap_var",
            "",
            "try:",
            "    from __main__ import display",
            "except ImportError:",
            "    from ansible.utils.display import Display",
            "    display = Display()",
            "",
            "",
            "__all__ = ['Templar', 'generate_ansible_template_vars']",
            "",
            "# A regex for checking to see if a variable we're trying to",
            "# expand is just a single variable name.",
            "",
            "# Primitive Types which we don't want Jinja to convert to strings.",
            "NON_TEMPLATED_TYPES = (bool, Number)",
            "",
            "JINJA2_OVERRIDE = '#jinja2:'",
            "",
            "USE_JINJA2_NATIVE = False",
            "if C.DEFAULT_JINJA2_NATIVE:",
            "    try:",
            "        from jinja2.nativetypes import NativeEnvironment as Environment",
            "        from ansible.template.native_helpers import ansible_native_concat as j2_concat",
            "        USE_JINJA2_NATIVE = True",
            "    except ImportError:",
            "        from jinja2 import Environment",
            "        from jinja2.utils import concat as j2_concat",
            "        from jinja2 import __version__ as j2_version",
            "        display.warning(",
            "            'jinja2_native requires Jinja 2.10 and above. '",
            "            'Version detected: %s. Falling back to default.' % j2_version",
            "        )",
            "else:",
            "    from jinja2 import Environment",
            "    from jinja2.utils import concat as j2_concat",
            "",
            "",
            "def generate_ansible_template_vars(path):",
            "    b_path = to_bytes(path)",
            "    try:",
            "        template_uid = pwd.getpwuid(os.stat(b_path).st_uid).pw_name",
            "    except (KeyError, TypeError):",
            "        template_uid = os.stat(b_path).st_uid",
            "",
            "    temp_vars = {}",
            "    temp_vars['template_host'] = to_text(os.uname()[1])",
            "    temp_vars['template_path'] = path",
            "    temp_vars['template_mtime'] = datetime.datetime.fromtimestamp(os.path.getmtime(b_path))",
            "    temp_vars['template_uid'] = to_text(template_uid)",
            "    temp_vars['template_fullpath'] = os.path.abspath(path)",
            "    temp_vars['template_run_date'] = datetime.datetime.now()",
            "",
            "    managed_default = C.DEFAULT_MANAGED_STR",
            "    managed_str = managed_default.format(",
            "        host=temp_vars['template_host'],",
            "        uid=temp_vars['template_uid'],",
            "        file=temp_vars['template_path'],",
            "    )",
            "    temp_vars['ansible_managed'] = to_text(time.strftime(to_native(managed_str), time.localtime(os.path.getmtime(b_path))))",
            "",
            "    return temp_vars",
            "",
            "",
            "def _escape_backslashes(data, jinja_env):",
            "    \"\"\"Double backslashes within jinja2 expressions",
            "",
            "    A user may enter something like this in a playbook::",
            "",
            "      debug:",
            "        msg: \"Test Case 1\\\\3; {{ test1_name | regex_replace('^(.*)_name$', '\\\\1')}}\"",
            "",
            "    The string inside of the {{ gets interpreted multiple times First by yaml.",
            "    Then by python.  And finally by jinja2 as part of it's variable.  Because",
            "    it is processed by both python and jinja2, the backslash escaped",
            "    characters get unescaped twice.  This means that we'd normally have to use",
            "    four backslashes to escape that.  This is painful for playbook authors as",
            "    they have to remember different rules for inside vs outside of a jinja2",
            "    expression (The backslashes outside of the \"{{ }}\" only get processed by",
            "    yaml and python.  So they only need to be escaped once).  The following",
            "    code fixes this by automatically performing the extra quoting of",
            "    backslashes inside of a jinja2 expression.",
            "",
            "    \"\"\"",
            "    if '\\\\' in data and '{{' in data:",
            "        new_data = []",
            "        d2 = jinja_env.preprocess(data)",
            "        in_var = False",
            "",
            "        for token in jinja_env.lex(d2):",
            "            if token[1] == 'variable_begin':",
            "                in_var = True",
            "                new_data.append(token[2])",
            "            elif token[1] == 'variable_end':",
            "                in_var = False",
            "                new_data.append(token[2])",
            "            elif in_var and token[1] == 'string':",
            "                # Double backslashes only if we're inside of a jinja2 variable",
            "                new_data.append(token[2].replace('\\\\', '\\\\\\\\'))",
            "            else:",
            "                new_data.append(token[2])",
            "",
            "        data = ''.join(new_data)",
            "",
            "    return data",
            "",
            "",
            "def _count_newlines_from_end(in_str):",
            "    '''",
            "    Counts the number of newlines at the end of a string. This is used during",
            "    the jinja2 templating to ensure the count matches the input, since some newlines",
            "    may be thrown away during the templating.",
            "    '''",
            "",
            "    try:",
            "        i = len(in_str)",
            "        j = i - 1",
            "        while in_str[j] == '\\n':",
            "            j -= 1",
            "        return i - 1 - j",
            "    except IndexError:",
            "        # Uncommon cases: zero length string and string containing only newlines",
            "        return i",
            "",
            "",
            "def tests_as_filters_warning(name, func):",
            "    '''",
            "    Closure to enable displaying a deprecation warning when tests are used as a filter",
            "",
            "    This closure is only used when registering ansible provided tests as filters",
            "",
            "    This function should be removed in 2.9 along with registering ansible provided tests as filters",
            "    in Templar._get_filters",
            "    '''",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        display.deprecated(",
            "            'Using tests as filters is deprecated. Instead of using `result|%(name)s` use '",
            "            '`result is %(name)s`' % dict(name=name),",
            "            version='2.9'",
            "        )",
            "        return func(*args, **kwargs)",
            "    return wrapper",
            "",
            "",
            "class AnsibleContext(Context):",
            "    '''",
            "    A custom context, which intercepts resolve() calls and sets a flag",
            "    internally if any variable lookup returns an AnsibleUnsafe value. This",
            "    flag is checked post-templating, and (when set) will result in the",
            "    final templated result being wrapped via UnsafeProxy.",
            "    '''",
            "    def __init__(self, *args, **kwargs):",
            "        super(AnsibleContext, self).__init__(*args, **kwargs)",
            "        self.unsafe = False",
            "",
            "    def _is_unsafe(self, val):",
            "        '''",
            "        Our helper function, which will also recursively check dict and",
            "        list entries due to the fact that they may be repr'd and contain",
            "        a key or value which contains jinja2 syntax and would otherwise",
            "        lose the AnsibleUnsafe value.",
            "        '''",
            "        if isinstance(val, dict):",
            "            for key in val.keys():",
            "                if self._is_unsafe(val[key]):",
            "                    return True",
            "        elif isinstance(val, list):",
            "            for item in val:",
            "                if self._is_unsafe(item):",
            "                    return True",
            "        elif hasattr(val, '__UNSAFE__'):",
            "            return True",
            "        return False",
            "",
            "    def _update_unsafe(self, val):",
            "        if val is not None and not self.unsafe and self._is_unsafe(val):",
            "            self.unsafe = True",
            "",
            "    def resolve(self, key):",
            "        '''",
            "        The intercepted resolve(), which uses the helper above to set the",
            "        internal flag whenever an unsafe variable value is returned.",
            "        '''",
            "        val = super(AnsibleContext, self).resolve(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "    def resolve_or_missing(self, key):",
            "        val = super(AnsibleContext, self).resolve_or_missing(key)",
            "        self._update_unsafe(val)",
            "        return val",
            "",
            "",
            "class AnsibleEnvironment(Environment):",
            "    '''",
            "    Our custom environment, which simply allows us to override the class-level",
            "    values for the Template and Context classes used by jinja2 internally.",
            "    '''",
            "    context_class = AnsibleContext",
            "    template_class = AnsibleJ2Template",
            "",
            "",
            "class Templar:",
            "    '''",
            "    The main class for templating, with the main entry-point of template().",
            "    '''",
            "",
            "    def __init__(self, loader, shared_loader_obj=None, variables=None):",
            "        variables = {} if variables is None else variables",
            "",
            "        self._loader = loader",
            "        self._filters = None",
            "        self._tests = None",
            "        self._available_variables = variables",
            "        self._cached_result = {}",
            "",
            "        if loader:",
            "            self._basedir = loader.get_basedir()",
            "        else:",
            "            self._basedir = './'",
            "",
            "        if shared_loader_obj:",
            "            self._filter_loader = getattr(shared_loader_obj, 'filter_loader')",
            "            self._test_loader = getattr(shared_loader_obj, 'test_loader')",
            "            self._lookup_loader = getattr(shared_loader_obj, 'lookup_loader')",
            "        else:",
            "            self._filter_loader = filter_loader",
            "            self._test_loader = test_loader",
            "            self._lookup_loader = lookup_loader",
            "",
            "        # flags to determine whether certain failures during templating",
            "        # should result in fatal errors being raised",
            "        self._fail_on_lookup_errors = True",
            "        self._fail_on_filter_errors = True",
            "        self._fail_on_undefined_errors = C.DEFAULT_UNDEFINED_VAR_BEHAVIOR",
            "",
            "        self.environment = AnsibleEnvironment(",
            "            trim_blocks=True,",
            "            undefined=StrictUndefined,",
            "            extensions=self._get_extensions(),",
            "            finalize=self._finalize,",
            "            loader=FileSystemLoader(self._basedir),",
            "        )",
            "",
            "        # the current rendering context under which the templar class is working",
            "        self.cur_context = None",
            "",
            "        self.SINGLE_VAR = re.compile(r\"^%s\\s*(\\w*)\\s*%s$\" % (self.environment.variable_start_string, self.environment.variable_end_string))",
            "",
            "        self._clean_regex = re.compile(r'(?:%s|%s|%s|%s)' % (",
            "            self.environment.variable_start_string,",
            "            self.environment.block_start_string,",
            "            self.environment.block_end_string,",
            "            self.environment.variable_end_string",
            "        ))",
            "        self._no_type_regex = re.compile(r'.*?\\|\\s*(?:%s)(?:\\([^\\|]*\\))?\\s*\\)?\\s*(?:%s)' %",
            "                                         ('|'.join(C.STRING_TYPE_FILTERS), self.environment.variable_end_string))",
            "",
            "    def _get_filters(self, builtin_filters):",
            "        '''",
            "        Returns filter plugins, after loading and caching them if need be",
            "        '''",
            "",
            "        if self._filters is not None:",
            "            return self._filters.copy()",
            "",
            "        self._filters = dict()",
            "",
            "        # TODO: Remove registering tests as filters in 2.9",
            "        for name, func in self._get_tests().items():",
            "            if name in builtin_filters:",
            "                # If we have a custom test named the same as a builtin filter, don't register as a filter",
            "                continue",
            "            self._filters[name] = tests_as_filters_warning(name, func)",
            "",
            "        for fp in self._filter_loader.all():",
            "            self._filters.update(fp.filters())",
            "",
            "        return self._filters.copy()",
            "",
            "    def _get_tests(self):",
            "        '''",
            "        Returns tests plugins, after loading and caching them if need be",
            "        '''",
            "",
            "        if self._tests is not None:",
            "            return self._tests.copy()",
            "",
            "        self._tests = dict()",
            "        for fp in self._test_loader.all():",
            "            self._tests.update(fp.tests())",
            "",
            "        return self._tests.copy()",
            "",
            "    def _get_extensions(self):",
            "        '''",
            "        Return jinja2 extensions to load.",
            "",
            "        If some extensions are set via jinja_extensions in ansible.cfg, we try",
            "        to load them with the jinja environment.",
            "        '''",
            "",
            "        jinja_exts = []",
            "        if C.DEFAULT_JINJA2_EXTENSIONS:",
            "            # make sure the configuration directive doesn't contain spaces",
            "            # and split extensions in an array",
            "            jinja_exts = C.DEFAULT_JINJA2_EXTENSIONS.replace(\" \", \"\").split(',')",
            "",
            "        return jinja_exts",
            "",
            "    def _clean_data(self, orig_data):",
            "        ''' remove jinja2 template tags from data '''",
            "",
            "        if hasattr(orig_data, '__ENCRYPTED__'):",
            "            ret = orig_data",
            "",
            "        elif isinstance(orig_data, list):",
            "            clean_list = []",
            "            for list_item in orig_data:",
            "                clean_list.append(self._clean_data(list_item))",
            "            ret = clean_list",
            "",
            "        elif isinstance(orig_data, (dict, Mapping)):",
            "            clean_dict = {}",
            "            for k in orig_data:",
            "                clean_dict[self._clean_data(k)] = self._clean_data(orig_data[k])",
            "            ret = clean_dict",
            "",
            "        elif isinstance(orig_data, string_types):",
            "            # This will error with str data (needs unicode), but all strings should already be converted already.",
            "            # If you get exception, the problem is at the data origin, do not add to_text here.",
            "            with contextlib.closing(StringIO(orig_data)) as data:",
            "                # these variables keep track of opening block locations, as we only",
            "                # want to replace matched pairs of print/block tags",
            "                print_openings = []",
            "                block_openings = []",
            "                for mo in self._clean_regex.finditer(orig_data):",
            "                    token = mo.group(0)",
            "                    token_start = mo.start(0)",
            "",
            "                    if token[0] == self.environment.variable_start_string[0]:",
            "                        if token == self.environment.block_start_string:",
            "                            block_openings.append(token_start)",
            "                        elif token == self.environment.variable_start_string:",
            "                            print_openings.append(token_start)",
            "",
            "                    elif token[1] == self.environment.variable_end_string[1]:",
            "                        prev_idx = None",
            "                        if token == self.environment.block_end_string and block_openings:",
            "                            prev_idx = block_openings.pop()",
            "                        elif token == self.environment.variable_end_string and print_openings:",
            "                            prev_idx = print_openings.pop()",
            "",
            "                        if prev_idx is not None:",
            "                            # replace the opening",
            "                            data.seek(prev_idx, os.SEEK_SET)",
            "                            data.write(to_text(self.environment.comment_start_string))",
            "                            # replace the closing",
            "                            data.seek(token_start, os.SEEK_SET)",
            "                            data.write(to_text(self.environment.comment_end_string))",
            "",
            "                    else:",
            "                        raise AnsibleError(\"Error while cleaning data for safety: unhandled regex match\")",
            "",
            "                ret = data.getvalue()",
            "        else:",
            "            ret = orig_data",
            "",
            "        return ret",
            "",
            "    def set_available_variables(self, variables):",
            "        '''",
            "        Sets the list of template variables this Templar instance will use",
            "        to template things, so we don't have to pass them around between",
            "        internal methods. We also clear the template cache here, as the variables",
            "        are being changed.",
            "        '''",
            "",
            "        if not isinstance(variables, dict):",
            "            raise AnsibleAssertionError(\"the type of 'variables' should be a dict but was a %s\" % (type(variables)))",
            "        self._available_variables = variables",
            "        self._cached_result = {}",
            "",
            "    def template(self, variable, convert_bare=False, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None,",
            "                 convert_data=True, static_vars=None, cache=True, disable_lookups=False):",
            "        '''",
            "        Templates (possibly recursively) any given data as input. If convert_bare is",
            "        set to True, the given data will be wrapped as a jinja2 variable ('{{foo}}')",
            "        before being sent through the template engine.",
            "        '''",
            "        static_vars = [''] if static_vars is None else static_vars",
            "",
            "        # Don't template unsafe variables, just return them.",
            "        if hasattr(variable, '__UNSAFE__'):",
            "            return variable",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            if convert_bare:",
            "                variable = self._convert_bare_variable(variable)",
            "",
            "            if isinstance(variable, string_types):",
            "                result = variable",
            "",
            "                if self._contains_vars(variable):",
            "                    # Check to see if the string we are trying to render is just referencing a single",
            "                    # var.  In this case we don't want to accidentally change the type of the variable",
            "                    # to a string by using the jinja template renderer. We just want to pass it.",
            "                    only_one = self.SINGLE_VAR.match(variable)",
            "                    if only_one:",
            "                        var_name = only_one.group(1)",
            "                        if var_name in self._available_variables:",
            "                            resolved_val = self._available_variables[var_name]",
            "                            if isinstance(resolved_val, NON_TEMPLATED_TYPES):",
            "                                return resolved_val",
            "                            elif resolved_val is None:",
            "                                return C.DEFAULT_NULL_REPRESENTATION",
            "",
            "                    # Using a cache in order to prevent template calls with already templated variables",
            "                    sha1_hash = None",
            "                    if cache:",
            "                        variable_hash = sha1(text_type(variable).encode('utf-8'))",
            "                        options_hash = sha1(",
            "                            (",
            "                                text_type(preserve_trailing_newlines) +",
            "                                text_type(escape_backslashes) +",
            "                                text_type(fail_on_undefined) +",
            "                                text_type(overrides)",
            "                            ).encode('utf-8')",
            "                        )",
            "                        sha1_hash = variable_hash.hexdigest() + options_hash.hexdigest()",
            "                    if cache and sha1_hash in self._cached_result:",
            "                        result = self._cached_result[sha1_hash]",
            "                    else:",
            "                        result = self.do_template(",
            "                            variable,",
            "                            preserve_trailing_newlines=preserve_trailing_newlines,",
            "                            escape_backslashes=escape_backslashes,",
            "                            fail_on_undefined=fail_on_undefined,",
            "                            overrides=overrides,",
            "                            disable_lookups=disable_lookups,",
            "                        )",
            "",
            "                        if not USE_JINJA2_NATIVE:",
            "                            unsafe = hasattr(result, '__UNSAFE__')",
            "                            if convert_data and not self._no_type_regex.match(variable):",
            "                                # if this looks like a dictionary or list, convert it to such using the safe_eval method",
            "                                if (result.startswith(\"{\") and not result.startswith(self.environment.variable_start_string)) or \\",
            "                                        result.startswith(\"[\") or result in (\"True\", \"False\"):",
            "                                    eval_results = safe_eval(result, include_exceptions=True)",
            "                                    if eval_results[1] is None:",
            "                                        result = eval_results[0]",
            "                                        if unsafe:",
            "                                            result = wrap_var(result)",
            "                                    else:",
            "                                        # FIXME: if the safe_eval raised an error, should we do something with it?",
            "                                        pass",
            "",
            "                        # we only cache in the case where we have a single variable",
            "                        # name, to make sure we're not putting things which may otherwise",
            "                        # be dynamic in the cache (filters, lookups, etc.)",
            "                        if cache:",
            "                            self._cached_result[sha1_hash] = result",
            "",
            "                return result",
            "",
            "            elif isinstance(variable, (list, tuple)):",
            "                return [self.template(",
            "                    v,",
            "                    preserve_trailing_newlines=preserve_trailing_newlines,",
            "                    fail_on_undefined=fail_on_undefined,",
            "                    overrides=overrides,",
            "                    disable_lookups=disable_lookups,",
            "                ) for v in variable]",
            "            elif isinstance(variable, (dict, Mapping)):",
            "                d = {}",
            "                # we don't use iteritems() here to avoid problems if the underlying dict",
            "                # changes sizes due to the templating, which can happen with hostvars",
            "                for k in variable.keys():",
            "                    if k not in static_vars:",
            "                        d[k] = self.template(",
            "                            variable[k],",
            "                            preserve_trailing_newlines=preserve_trailing_newlines,",
            "                            fail_on_undefined=fail_on_undefined,",
            "                            overrides=overrides,",
            "                            disable_lookups=disable_lookups,",
            "                        )",
            "                    else:",
            "                        d[k] = variable[k]",
            "                return d",
            "            else:",
            "                return variable",
            "",
            "        except AnsibleFilterError:",
            "            if self._fail_on_filter_errors:",
            "                raise",
            "            else:",
            "                return variable",
            "",
            "    def is_template(self, data):",
            "        ''' lets us know if data has a template'''",
            "        if isinstance(data, string_types):",
            "            try:",
            "                new = self.do_template(data, fail_on_undefined=True)",
            "            except (AnsibleUndefinedVariable, UndefinedError):",
            "                return True",
            "            except:",
            "                return False",
            "            return (new != data)",
            "        elif isinstance(data, (list, tuple)):",
            "            for v in data:",
            "                if self.is_template(v):",
            "                    return True",
            "        elif isinstance(data, dict):",
            "            for k in data:",
            "                if self.is_template(k) or self.is_template(data[k]):",
            "                    return True",
            "        return False",
            "",
            "    def templatable(self, data):",
            "        '''",
            "        returns True if the data can be templated w/o errors",
            "        '''",
            "        templatable = True",
            "        try:",
            "            self.template(data)",
            "        except:",
            "            templatable = False",
            "        return templatable",
            "",
            "    def _contains_vars(self, data):",
            "        '''",
            "        returns True if the data contains a variable pattern",
            "        '''",
            "        if isinstance(data, string_types):",
            "            for marker in (self.environment.block_start_string, self.environment.variable_start_string, self.environment.comment_start_string):",
            "                if marker in data:",
            "                    return True",
            "        return False",
            "",
            "    def _convert_bare_variable(self, variable):",
            "        '''",
            "        Wraps a bare string, which may have an attribute portion (ie. foo.bar)",
            "        in jinja2 variable braces so that it is evaluated properly.",
            "        '''",
            "",
            "        if isinstance(variable, string_types):",
            "            contains_filters = \"|\" in variable",
            "            first_part = variable.split(\"|\")[0].split(\".\")[0].split(\"[\")[0]",
            "            if (contains_filters or first_part in self._available_variables) and self.environment.variable_start_string not in variable:",
            "                return \"%s%s%s\" % (self.environment.variable_start_string, variable, self.environment.variable_end_string)",
            "",
            "        # the variable didn't meet the conditions to be converted,",
            "        # so just return it as-is",
            "        return variable",
            "",
            "    def _finalize(self, thing):",
            "        '''",
            "        A custom finalize method for jinja2, which prevents None from being returned. This",
            "        avoids a string of ``\"None\"`` as ``None`` has no importance in YAML.",
            "",
            "        If using ANSIBLE_JINJA2_NATIVE we bypass this and return the actual value always",
            "        '''",
            "        if USE_JINJA2_NATIVE:",
            "            return thing",
            "        return thing if thing is not None else ''",
            "",
            "    def _fail_lookup(self, name, *args, **kwargs):",
            "        raise AnsibleError(\"The lookup `%s` was found, however lookups were disabled from templating\" % name)",
            "",
            "    def _query_lookup(self, name, *args, **kwargs):",
            "        ''' wrapper for lookup, force wantlist true'''",
            "        kwargs['wantlist'] = True",
            "        return self._lookup(name, *args, **kwargs)",
            "",
            "    def _lookup(self, name, *args, **kwargs):",
            "        instance = self._lookup_loader.get(name.lower(), loader=self._loader, templar=self)",
            "",
            "        if instance is not None:",
            "            wantlist = kwargs.pop('wantlist', False)",
            "            allow_unsafe = kwargs.pop('allow_unsafe', C.DEFAULT_ALLOW_UNSAFE_LOOKUPS)",
            "            errors = kwargs.pop('errors', 'strict')",
            "",
            "            from ansible.utils.listify import listify_lookup_plugin_terms",
            "            loop_terms = listify_lookup_plugin_terms(terms=args, templar=self, loader=self._loader, fail_on_undefined=True, convert_bare=False)",
            "            # safely catch run failures per #5059",
            "            try:",
            "                ran = instance.run(loop_terms, variables=self._available_variables, **kwargs)",
            "            except (AnsibleUndefinedVariable, UndefinedError) as e:",
            "                raise AnsibleUndefinedVariable(e)",
            "            except Exception as e:",
            "                if self._fail_on_lookup_errors:",
            "                    msg = u\"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s\" % \\",
            "                          (name, type(e), to_text(e))",
            "                    if errors == 'warn':",
            "                        display.warning(msg)",
            "                    elif errors == 'ignore':",
            "                        display.display(msg, log_only=True)",
            "                    else:",
            "                        raise AnsibleError(to_native(msg))",
            "                ran = None",
            "",
            "            if ran and not allow_unsafe:",
            "                if wantlist:",
            "                    ran = wrap_var(ran)",
            "                else:",
            "                    try:",
            "                        ran = UnsafeProxy(\",\".join(ran))",
            "                    except TypeError:",
            "                        # Lookup Plugins should always return lists.  Throw an error if that's not",
            "                        # the case:",
            "                        if not isinstance(ran, Sequence):",
            "                            raise AnsibleError(\"The lookup plugin '%s' did not return a list.\"",
            "                                               % name)",
            "",
            "                        # The TypeError we can recover from is when the value *inside* of the list",
            "                        # is not a string",
            "                        if len(ran) == 1:",
            "                            ran = wrap_var(ran[0])",
            "                        else:",
            "                            ran = wrap_var(ran)",
            "",
            "                if self.cur_context:",
            "                    self.cur_context.unsafe = True",
            "            return ran",
            "        else:",
            "            raise AnsibleError(\"lookup plugin (%s) not found\" % name)",
            "",
            "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False):",
            "        if USE_JINJA2_NATIVE and not isinstance(data, string_types):",
            "            return data",
            "",
            "        # For preserving the number of input newlines in the output (used",
            "        # later in this method)",
            "        data_newlines = _count_newlines_from_end(data)",
            "",
            "        if fail_on_undefined is None:",
            "            fail_on_undefined = self._fail_on_undefined_errors",
            "",
            "        try:",
            "            # allows template header overrides to change jinja2 options.",
            "            if overrides is None:",
            "                myenv = self.environment.overlay()",
            "            else:",
            "                myenv = self.environment.overlay(overrides)",
            "",
            "            # Get jinja env overrides from template",
            "            if hasattr(data, 'startswith') and data.startswith(JINJA2_OVERRIDE):",
            "                eol = data.find('\\n')",
            "                line = data[len(JINJA2_OVERRIDE):eol]",
            "                data = data[eol + 1:]",
            "                for pair in line.split(','):",
            "                    (key, val) = pair.split(':')",
            "                    key = key.strip()",
            "                    setattr(myenv, key, ast.literal_eval(val.strip()))",
            "",
            "            # Adds Ansible custom filters and tests",
            "            myenv.filters.update(self._get_filters(myenv.filters))",
            "            myenv.tests.update(self._get_tests())",
            "",
            "            if escape_backslashes:",
            "                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".",
            "                data = _escape_backslashes(data, myenv)",
            "",
            "            try:",
            "                t = myenv.from_string(data)",
            "            except TemplateSyntaxError as e:",
            "                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)))",
            "            except Exception as e:",
            "                if 'recursion' in to_native(e):",
            "                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data))",
            "                else:",
            "                    return data",
            "",
            "            # jinja2 global is inconsistent across versions, this normalizes them",
            "            t.globals['dict'] = dict",
            "",
            "            if disable_lookups:",
            "                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup",
            "            else:",
            "                t.globals['lookup'] = self._lookup",
            "                t.globals['query'] = t.globals['q'] = self._query_lookup",
            "",
            "            t.globals['finalize'] = self._finalize",
            "",
            "            jvars = AnsibleJ2Vars(self, t.globals)",
            "",
            "            self.cur_context = new_context = t.new_context(jvars, shared=True)",
            "            rf = t.root_render_func(new_context)",
            "",
            "            try:",
            "                res = j2_concat(rf)",
            "                if getattr(new_context, 'unsafe', False):",
            "                    res = wrap_var(res)",
            "            except TypeError as te:",
            "                if 'StrictUndefined' in to_native(te):",
            "                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)",
            "                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)",
            "                    raise AnsibleUndefinedVariable(errmsg)",
            "                else:",
            "                    display.debug(\"failing because of a type error, template data is: %s\" % to_native(data))",
            "                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)))",
            "",
            "            if USE_JINJA2_NATIVE and not isinstance(res, string_types):",
            "                return res",
            "",
            "            if preserve_trailing_newlines:",
            "                # The low level calls above do not preserve the newline",
            "                # characters at the end of the input data, so we use the",
            "                # calculate the difference in newlines and append them",
            "                # to the resulting output for parity",
            "                #",
            "                # jinja2 added a keep_trailing_newline option in 2.7 when",
            "                # creating an Environment.  That would let us make this code",
            "                # better (remove a single newline if",
            "                # preserve_trailing_newlines is False).  Once we can depend on",
            "                # that version being present, modify our code to set that when",
            "                # initializing self.environment and remove a single trailing",
            "                # newline here if preserve_newlines is False.",
            "                res_newlines = _count_newlines_from_end(res)",
            "                if data_newlines > res_newlines:",
            "                    res += self.environment.newline_sequence * (data_newlines - res_newlines)",
            "            return res",
            "        except (UndefinedError, AnsibleUndefinedVariable) as e:",
            "            if fail_on_undefined:",
            "                raise AnsibleUndefinedVariable(e)",
            "            else:",
            "                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))",
            "                return data",
            "",
            "    # for backwards compatibility in case anyone is using old private method directly",
            "    _do_template = do_template"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "223": [
                "AnsibleContext",
                "_is_unsafe"
            ]
        },
        "addLocation": []
    }
}