{
    "synapse/federation/federation_base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": 278,
                "PatchRowcode": "             pdu_to_check.sender_domain,"
            },
            "1": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": 279,
                "PatchRowcode": "             e.getErrorMessage(),"
            },
            "2": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": 280,
                "PatchRowcode": "         )"
            },
            "3": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # XX not really sure if these are the right codes, but they are what"
            },
            "4": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # we've done for ages"
            },
            "5": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+        raise SynapseError(403, errmsg, Codes.FORBIDDEN)"
            },
            "7": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": 282,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 285,
                "afterPatchRowNumber": 283,
                "PatchRowcode": "     for p, d in zip(pdus_to_check_sender, more_deferreds):"
            },
            "9": {
                "beforePatchRowNumber": 286,
                "afterPatchRowNumber": 284,
                "PatchRowcode": "         d.addErrback(sender_err, p)"
            },
            "10": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 312,
                "PatchRowcode": "                 \"event id %s: unable to verify signature for event id domain: %s\""
            },
            "11": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 313,
                "PatchRowcode": "                 % (pdu_to_check.pdu.event_id, e.getErrorMessage())"
            },
            "12": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 314,
                "PatchRowcode": "             )"
            },
            "13": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # XX as above: not really sure if these are the right codes"
            },
            "14": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+            raise SynapseError(403, errmsg, Codes.FORBIDDEN)"
            },
            "16": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": 316,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 320,
                "afterPatchRowNumber": 317,
                "PatchRowcode": "         for p, d in zip(pdus_to_check_event_id, more_deferreds):"
            },
            "18": {
                "beforePatchRowNumber": 321,
                "afterPatchRowNumber": 318,
                "PatchRowcode": "             d.addErrback(event_err, p)"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "from collections import namedtuple",
            "",
            "import six",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.defer import DeferredList",
            "",
            "from synapse.api.constants import MAX_DEPTH, EventTypes, Membership",
            "from synapse.api.errors import Codes, SynapseError",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS, EventFormatVersions",
            "from synapse.crypto.event_signing import check_event_content_hash",
            "from synapse.events import event_type_from_format_version",
            "from synapse.events.utils import prune_event",
            "from synapse.http.servlet import assert_params_in_dict",
            "from synapse.logging.context import (",
            "    LoggingContext,",
            "    PreserveLoggingContext,",
            "    make_deferred_yieldable,",
            "    preserve_fn,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util import unwrapFirstError",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class FederationBase(object):",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.store = hs.get_datastore()",
            "        self._clock = hs.get_clock()",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_sigs_and_hash_and_fetch(",
            "        self, origin, pdus, room_version, outlier=False, include_none=False",
            "    ):",
            "        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each",
            "        one. If a PDU fails its signature check then we check if we have it in",
            "        the database and if not then request if from the originating server of",
            "        that PDU.",
            "",
            "        If a PDU fails its content hash check then it is redacted.",
            "",
            "        The given list of PDUs are not modified, instead the function returns",
            "        a new list.",
            "",
            "        Args:",
            "            origin (str)",
            "            pdu (list)",
            "            room_version (str)",
            "            outlier (bool): Whether the events are outliers or not",
            "            include_none (str): Whether to include None in the returned list",
            "                for events that have failed their checks",
            "",
            "        Returns:",
            "            Deferred : A list of PDUs that have valid signatures and hashes.",
            "        \"\"\"",
            "        deferreds = self._check_sigs_and_hashes(room_version, pdus)",
            "",
            "        @defer.inlineCallbacks",
            "        def handle_check_result(pdu, deferred):",
            "            try:",
            "                res = yield make_deferred_yieldable(deferred)",
            "            except SynapseError:",
            "                res = None",
            "",
            "            if not res:",
            "                # Check local db.",
            "                res = yield self.store.get_event(",
            "                    pdu.event_id, allow_rejected=True, allow_none=True",
            "                )",
            "",
            "            if not res and pdu.origin != origin:",
            "                try:",
            "                    res = yield self.get_pdu(",
            "                        destinations=[pdu.origin],",
            "                        event_id=pdu.event_id,",
            "                        room_version=room_version,",
            "                        outlier=outlier,",
            "                        timeout=10000,",
            "                    )",
            "                except SynapseError:",
            "                    pass",
            "",
            "            if not res:",
            "                logger.warn(",
            "                    \"Failed to find copy of %s with valid signature\", pdu.event_id",
            "                )",
            "",
            "            return res",
            "",
            "        handle = preserve_fn(handle_check_result)",
            "        deferreds2 = [handle(pdu, deferred) for pdu, deferred in zip(pdus, deferreds)]",
            "",
            "        valid_pdus = yield make_deferred_yieldable(",
            "            defer.gatherResults(deferreds2, consumeErrors=True)",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if include_none:",
            "            return valid_pdus",
            "        else:",
            "            return [p for p in valid_pdus if p]",
            "",
            "    def _check_sigs_and_hash(self, room_version, pdu):",
            "        return make_deferred_yieldable(",
            "            self._check_sigs_and_hashes(room_version, [pdu])[0]",
            "        )",
            "",
            "    def _check_sigs_and_hashes(self, room_version, pdus):",
            "        \"\"\"Checks that each of the received events is correctly signed by the",
            "        sending server.",
            "",
            "        Args:",
            "            room_version (str): The room version of the PDUs",
            "            pdus (list[FrozenEvent]): the events to be checked",
            "",
            "        Returns:",
            "            list[Deferred]: for each input event, a deferred which:",
            "              * returns the original event if the checks pass",
            "              * returns a redacted version of the event (if the signature",
            "                matched but the hash did not)",
            "              * throws a SynapseError if the signature check failed.",
            "            The deferreds run their callbacks in the sentinel",
            "        \"\"\"",
            "        deferreds = _check_sigs_on_pdus(self.keyring, room_version, pdus)",
            "",
            "        ctx = LoggingContext.current_context()",
            "",
            "        def callback(_, pdu):",
            "            with PreserveLoggingContext(ctx):",
            "                if not check_event_content_hash(pdu):",
            "                    # let's try to distinguish between failures because the event was",
            "                    # redacted (which are somewhat expected) vs actual ball-tampering",
            "                    # incidents.",
            "                    #",
            "                    # This is just a heuristic, so we just assume that if the keys are",
            "                    # about the same between the redacted and received events, then the",
            "                    # received event was probably a redacted copy (but we then use our",
            "                    # *actual* redacted copy to be on the safe side.)",
            "                    redacted_event = prune_event(pdu)",
            "                    if set(redacted_event.keys()) == set(pdu.keys()) and set(",
            "                        six.iterkeys(redacted_event.content)",
            "                    ) == set(six.iterkeys(pdu.content)):",
            "                        logger.info(",
            "                            \"Event %s seems to have been redacted; using our redacted \"",
            "                            \"copy\",",
            "                            pdu.event_id,",
            "                        )",
            "                    else:",
            "                        logger.warning(",
            "                            \"Event %s content has been tampered, redacting\",",
            "                            pdu.event_id,",
            "                        )",
            "                    return redacted_event",
            "",
            "                if self.spam_checker.check_event_for_spam(pdu):",
            "                    logger.warn(",
            "                        \"Event contains spam, redacting %s: %s\",",
            "                        pdu.event_id,",
            "                        pdu.get_pdu_json(),",
            "                    )",
            "                    return prune_event(pdu)",
            "",
            "                return pdu",
            "",
            "        def errback(failure, pdu):",
            "            failure.trap(SynapseError)",
            "            with PreserveLoggingContext(ctx):",
            "                logger.warn(",
            "                    \"Signature check failed for %s: %s\",",
            "                    pdu.event_id,",
            "                    failure.getErrorMessage(),",
            "                )",
            "            return failure",
            "",
            "        for deferred, pdu in zip(deferreds, pdus):",
            "            deferred.addCallbacks(",
            "                callback, errback, callbackArgs=[pdu], errbackArgs=[pdu]",
            "            )",
            "",
            "        return deferreds",
            "",
            "",
            "class PduToCheckSig(",
            "    namedtuple(",
            "        \"PduToCheckSig\", [\"pdu\", \"redacted_pdu_json\", \"sender_domain\", \"deferreds\"]",
            "    )",
            "):",
            "    pass",
            "",
            "",
            "def _check_sigs_on_pdus(keyring, room_version, pdus):",
            "    \"\"\"Check that the given events are correctly signed",
            "",
            "    Args:",
            "        keyring (synapse.crypto.Keyring): keyring object to do the checks",
            "        room_version (str): the room version of the PDUs",
            "        pdus (Collection[EventBase]): the events to be checked",
            "",
            "    Returns:",
            "        List[Deferred]: a Deferred for each event in pdus, which will either succeed if",
            "           the signatures are valid, or fail (with a SynapseError) if not.",
            "    \"\"\"",
            "",
            "    # we want to check that the event is signed by:",
            "    #",
            "    # (a) the sender's server",
            "    #",
            "    #     - except in the case of invites created from a 3pid invite, which are exempt",
            "    #     from this check, because the sender has to match that of the original 3pid",
            "    #     invite, but the event may come from a different HS, for reasons that I don't",
            "    #     entirely grok (why do the senders have to match? and if they do, why doesn't the",
            "    #     joining server ask the inviting server to do the switcheroo with",
            "    #     exchange_third_party_invite?).",
            "    #",
            "    #     That's pretty awful, since redacting such an invite will render it invalid",
            "    #     (because it will then look like a regular invite without a valid signature),",
            "    #     and signatures are *supposed* to be valid whether or not an event has been",
            "    #     redacted. But this isn't the worst of the ways that 3pid invites are broken.",
            "    #",
            "    # (b) for V1 and V2 rooms, the server which created the event_id",
            "    #",
            "    # let's start by getting the domain for each pdu, and flattening the event back",
            "    # to JSON.",
            "",
            "    pdus_to_check = [",
            "        PduToCheckSig(",
            "            pdu=p,",
            "            redacted_pdu_json=prune_event(p).get_pdu_json(),",
            "            sender_domain=get_domain_from_id(p.sender),",
            "            deferreds=[],",
            "        )",
            "        for p in pdus",
            "    ]",
            "",
            "    v = KNOWN_ROOM_VERSIONS.get(room_version)",
            "    if not v:",
            "        raise RuntimeError(\"Unrecognized room version %s\" % (room_version,))",
            "",
            "    # First we check that the sender event is signed by the sender's domain",
            "    # (except if its a 3pid invite, in which case it may be sent by any server)",
            "    pdus_to_check_sender = [p for p in pdus_to_check if not _is_invite_via_3pid(p.pdu)]",
            "",
            "    more_deferreds = keyring.verify_json_objects_for_server(",
            "        [",
            "            (",
            "                p.sender_domain,",
            "                p.redacted_pdu_json,",
            "                p.pdu.origin_server_ts if v.enforce_key_validity else 0,",
            "                p.pdu.event_id,",
            "            )",
            "            for p in pdus_to_check_sender",
            "        ]",
            "    )",
            "",
            "    def sender_err(e, pdu_to_check):",
            "        errmsg = \"event id %s: unable to verify signature for sender %s: %s\" % (",
            "            pdu_to_check.pdu.event_id,",
            "            pdu_to_check.sender_domain,",
            "            e.getErrorMessage(),",
            "        )",
            "        # XX not really sure if these are the right codes, but they are what",
            "        # we've done for ages",
            "        raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)",
            "",
            "    for p, d in zip(pdus_to_check_sender, more_deferreds):",
            "        d.addErrback(sender_err, p)",
            "        p.deferreds.append(d)",
            "",
            "    # now let's look for events where the sender's domain is different to the",
            "    # event id's domain (normally only the case for joins/leaves), and add additional",
            "    # checks. Only do this if the room version has a concept of event ID domain",
            "    # (ie, the room version uses old-style non-hash event IDs).",
            "    if v.event_format == EventFormatVersions.V1:",
            "        pdus_to_check_event_id = [",
            "            p",
            "            for p in pdus_to_check",
            "            if p.sender_domain != get_domain_from_id(p.pdu.event_id)",
            "        ]",
            "",
            "        more_deferreds = keyring.verify_json_objects_for_server(",
            "            [",
            "                (",
            "                    get_domain_from_id(p.pdu.event_id),",
            "                    p.redacted_pdu_json,",
            "                    p.pdu.origin_server_ts if v.enforce_key_validity else 0,",
            "                    p.pdu.event_id,",
            "                )",
            "                for p in pdus_to_check_event_id",
            "            ]",
            "        )",
            "",
            "        def event_err(e, pdu_to_check):",
            "            errmsg = (",
            "                \"event id %s: unable to verify signature for event id domain: %s\"",
            "                % (pdu_to_check.pdu.event_id, e.getErrorMessage())",
            "            )",
            "            # XX as above: not really sure if these are the right codes",
            "            raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)",
            "",
            "        for p, d in zip(pdus_to_check_event_id, more_deferreds):",
            "            d.addErrback(event_err, p)",
            "            p.deferreds.append(d)",
            "",
            "    # replace lists of deferreds with single Deferreds",
            "    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]",
            "",
            "",
            "def _flatten_deferred_list(deferreds):",
            "    \"\"\"Given a list of deferreds, either return the single deferred,",
            "    combine into a DeferredList, or return an already resolved deferred.",
            "    \"\"\"",
            "    if len(deferreds) > 1:",
            "        return DeferredList(deferreds, fireOnOneErrback=True, consumeErrors=True)",
            "    elif len(deferreds) == 1:",
            "        return deferreds[0]",
            "    else:",
            "        return defer.succeed(None)",
            "",
            "",
            "def _is_invite_via_3pid(event):",
            "    return (",
            "        event.type == EventTypes.Member",
            "        and event.membership == Membership.INVITE",
            "        and \"third_party_invite\" in event.content",
            "    )",
            "",
            "",
            "def event_from_pdu_json(pdu_json, event_format_version, outlier=False):",
            "    \"\"\"Construct a FrozenEvent from an event json received over federation",
            "",
            "    Args:",
            "        pdu_json (object): pdu as received over federation",
            "        event_format_version (int): The event format version",
            "        outlier (bool): True to mark this event as an outlier",
            "",
            "    Returns:",
            "        FrozenEvent",
            "",
            "    Raises:",
            "        SynapseError: if the pdu is missing required fields or is otherwise",
            "            not a valid matrix event",
            "    \"\"\"",
            "    # we could probably enforce a bunch of other fields here (room_id, sender,",
            "    # origin, etc etc)",
            "    assert_params_in_dict(pdu_json, (\"type\", \"depth\"))",
            "",
            "    depth = pdu_json[\"depth\"]",
            "    if not isinstance(depth, six.integer_types):",
            "        raise SynapseError(400, \"Depth %r not an intger\" % (depth,), Codes.BAD_JSON)",
            "",
            "    if depth < 0:",
            "        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)",
            "    elif depth > MAX_DEPTH:",
            "        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)",
            "",
            "    event = event_type_from_format_version(event_format_version)(pdu_json)",
            "",
            "    event.internal_metadata.outlier = outlier",
            "",
            "    return event"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "from collections import namedtuple",
            "",
            "import six",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.defer import DeferredList",
            "",
            "from synapse.api.constants import MAX_DEPTH, EventTypes, Membership",
            "from synapse.api.errors import Codes, SynapseError",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS, EventFormatVersions",
            "from synapse.crypto.event_signing import check_event_content_hash",
            "from synapse.events import event_type_from_format_version",
            "from synapse.events.utils import prune_event",
            "from synapse.http.servlet import assert_params_in_dict",
            "from synapse.logging.context import (",
            "    LoggingContext,",
            "    PreserveLoggingContext,",
            "    make_deferred_yieldable,",
            "    preserve_fn,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util import unwrapFirstError",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class FederationBase(object):",
            "    def __init__(self, hs):",
            "        self.hs = hs",
            "",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.store = hs.get_datastore()",
            "        self._clock = hs.get_clock()",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_sigs_and_hash_and_fetch(",
            "        self, origin, pdus, room_version, outlier=False, include_none=False",
            "    ):",
            "        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each",
            "        one. If a PDU fails its signature check then we check if we have it in",
            "        the database and if not then request if from the originating server of",
            "        that PDU.",
            "",
            "        If a PDU fails its content hash check then it is redacted.",
            "",
            "        The given list of PDUs are not modified, instead the function returns",
            "        a new list.",
            "",
            "        Args:",
            "            origin (str)",
            "            pdu (list)",
            "            room_version (str)",
            "            outlier (bool): Whether the events are outliers or not",
            "            include_none (str): Whether to include None in the returned list",
            "                for events that have failed their checks",
            "",
            "        Returns:",
            "            Deferred : A list of PDUs that have valid signatures and hashes.",
            "        \"\"\"",
            "        deferreds = self._check_sigs_and_hashes(room_version, pdus)",
            "",
            "        @defer.inlineCallbacks",
            "        def handle_check_result(pdu, deferred):",
            "            try:",
            "                res = yield make_deferred_yieldable(deferred)",
            "            except SynapseError:",
            "                res = None",
            "",
            "            if not res:",
            "                # Check local db.",
            "                res = yield self.store.get_event(",
            "                    pdu.event_id, allow_rejected=True, allow_none=True",
            "                )",
            "",
            "            if not res and pdu.origin != origin:",
            "                try:",
            "                    res = yield self.get_pdu(",
            "                        destinations=[pdu.origin],",
            "                        event_id=pdu.event_id,",
            "                        room_version=room_version,",
            "                        outlier=outlier,",
            "                        timeout=10000,",
            "                    )",
            "                except SynapseError:",
            "                    pass",
            "",
            "            if not res:",
            "                logger.warn(",
            "                    \"Failed to find copy of %s with valid signature\", pdu.event_id",
            "                )",
            "",
            "            return res",
            "",
            "        handle = preserve_fn(handle_check_result)",
            "        deferreds2 = [handle(pdu, deferred) for pdu, deferred in zip(pdus, deferreds)]",
            "",
            "        valid_pdus = yield make_deferred_yieldable(",
            "            defer.gatherResults(deferreds2, consumeErrors=True)",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if include_none:",
            "            return valid_pdus",
            "        else:",
            "            return [p for p in valid_pdus if p]",
            "",
            "    def _check_sigs_and_hash(self, room_version, pdu):",
            "        return make_deferred_yieldable(",
            "            self._check_sigs_and_hashes(room_version, [pdu])[0]",
            "        )",
            "",
            "    def _check_sigs_and_hashes(self, room_version, pdus):",
            "        \"\"\"Checks that each of the received events is correctly signed by the",
            "        sending server.",
            "",
            "        Args:",
            "            room_version (str): The room version of the PDUs",
            "            pdus (list[FrozenEvent]): the events to be checked",
            "",
            "        Returns:",
            "            list[Deferred]: for each input event, a deferred which:",
            "              * returns the original event if the checks pass",
            "              * returns a redacted version of the event (if the signature",
            "                matched but the hash did not)",
            "              * throws a SynapseError if the signature check failed.",
            "            The deferreds run their callbacks in the sentinel",
            "        \"\"\"",
            "        deferreds = _check_sigs_on_pdus(self.keyring, room_version, pdus)",
            "",
            "        ctx = LoggingContext.current_context()",
            "",
            "        def callback(_, pdu):",
            "            with PreserveLoggingContext(ctx):",
            "                if not check_event_content_hash(pdu):",
            "                    # let's try to distinguish between failures because the event was",
            "                    # redacted (which are somewhat expected) vs actual ball-tampering",
            "                    # incidents.",
            "                    #",
            "                    # This is just a heuristic, so we just assume that if the keys are",
            "                    # about the same between the redacted and received events, then the",
            "                    # received event was probably a redacted copy (but we then use our",
            "                    # *actual* redacted copy to be on the safe side.)",
            "                    redacted_event = prune_event(pdu)",
            "                    if set(redacted_event.keys()) == set(pdu.keys()) and set(",
            "                        six.iterkeys(redacted_event.content)",
            "                    ) == set(six.iterkeys(pdu.content)):",
            "                        logger.info(",
            "                            \"Event %s seems to have been redacted; using our redacted \"",
            "                            \"copy\",",
            "                            pdu.event_id,",
            "                        )",
            "                    else:",
            "                        logger.warning(",
            "                            \"Event %s content has been tampered, redacting\",",
            "                            pdu.event_id,",
            "                        )",
            "                    return redacted_event",
            "",
            "                if self.spam_checker.check_event_for_spam(pdu):",
            "                    logger.warn(",
            "                        \"Event contains spam, redacting %s: %s\",",
            "                        pdu.event_id,",
            "                        pdu.get_pdu_json(),",
            "                    )",
            "                    return prune_event(pdu)",
            "",
            "                return pdu",
            "",
            "        def errback(failure, pdu):",
            "            failure.trap(SynapseError)",
            "            with PreserveLoggingContext(ctx):",
            "                logger.warn(",
            "                    \"Signature check failed for %s: %s\",",
            "                    pdu.event_id,",
            "                    failure.getErrorMessage(),",
            "                )",
            "            return failure",
            "",
            "        for deferred, pdu in zip(deferreds, pdus):",
            "            deferred.addCallbacks(",
            "                callback, errback, callbackArgs=[pdu], errbackArgs=[pdu]",
            "            )",
            "",
            "        return deferreds",
            "",
            "",
            "class PduToCheckSig(",
            "    namedtuple(",
            "        \"PduToCheckSig\", [\"pdu\", \"redacted_pdu_json\", \"sender_domain\", \"deferreds\"]",
            "    )",
            "):",
            "    pass",
            "",
            "",
            "def _check_sigs_on_pdus(keyring, room_version, pdus):",
            "    \"\"\"Check that the given events are correctly signed",
            "",
            "    Args:",
            "        keyring (synapse.crypto.Keyring): keyring object to do the checks",
            "        room_version (str): the room version of the PDUs",
            "        pdus (Collection[EventBase]): the events to be checked",
            "",
            "    Returns:",
            "        List[Deferred]: a Deferred for each event in pdus, which will either succeed if",
            "           the signatures are valid, or fail (with a SynapseError) if not.",
            "    \"\"\"",
            "",
            "    # we want to check that the event is signed by:",
            "    #",
            "    # (a) the sender's server",
            "    #",
            "    #     - except in the case of invites created from a 3pid invite, which are exempt",
            "    #     from this check, because the sender has to match that of the original 3pid",
            "    #     invite, but the event may come from a different HS, for reasons that I don't",
            "    #     entirely grok (why do the senders have to match? and if they do, why doesn't the",
            "    #     joining server ask the inviting server to do the switcheroo with",
            "    #     exchange_third_party_invite?).",
            "    #",
            "    #     That's pretty awful, since redacting such an invite will render it invalid",
            "    #     (because it will then look like a regular invite without a valid signature),",
            "    #     and signatures are *supposed* to be valid whether or not an event has been",
            "    #     redacted. But this isn't the worst of the ways that 3pid invites are broken.",
            "    #",
            "    # (b) for V1 and V2 rooms, the server which created the event_id",
            "    #",
            "    # let's start by getting the domain for each pdu, and flattening the event back",
            "    # to JSON.",
            "",
            "    pdus_to_check = [",
            "        PduToCheckSig(",
            "            pdu=p,",
            "            redacted_pdu_json=prune_event(p).get_pdu_json(),",
            "            sender_domain=get_domain_from_id(p.sender),",
            "            deferreds=[],",
            "        )",
            "        for p in pdus",
            "    ]",
            "",
            "    v = KNOWN_ROOM_VERSIONS.get(room_version)",
            "    if not v:",
            "        raise RuntimeError(\"Unrecognized room version %s\" % (room_version,))",
            "",
            "    # First we check that the sender event is signed by the sender's domain",
            "    # (except if its a 3pid invite, in which case it may be sent by any server)",
            "    pdus_to_check_sender = [p for p in pdus_to_check if not _is_invite_via_3pid(p.pdu)]",
            "",
            "    more_deferreds = keyring.verify_json_objects_for_server(",
            "        [",
            "            (",
            "                p.sender_domain,",
            "                p.redacted_pdu_json,",
            "                p.pdu.origin_server_ts if v.enforce_key_validity else 0,",
            "                p.pdu.event_id,",
            "            )",
            "            for p in pdus_to_check_sender",
            "        ]",
            "    )",
            "",
            "    def sender_err(e, pdu_to_check):",
            "        errmsg = \"event id %s: unable to verify signature for sender %s: %s\" % (",
            "            pdu_to_check.pdu.event_id,",
            "            pdu_to_check.sender_domain,",
            "            e.getErrorMessage(),",
            "        )",
            "        raise SynapseError(403, errmsg, Codes.FORBIDDEN)",
            "",
            "    for p, d in zip(pdus_to_check_sender, more_deferreds):",
            "        d.addErrback(sender_err, p)",
            "        p.deferreds.append(d)",
            "",
            "    # now let's look for events where the sender's domain is different to the",
            "    # event id's domain (normally only the case for joins/leaves), and add additional",
            "    # checks. Only do this if the room version has a concept of event ID domain",
            "    # (ie, the room version uses old-style non-hash event IDs).",
            "    if v.event_format == EventFormatVersions.V1:",
            "        pdus_to_check_event_id = [",
            "            p",
            "            for p in pdus_to_check",
            "            if p.sender_domain != get_domain_from_id(p.pdu.event_id)",
            "        ]",
            "",
            "        more_deferreds = keyring.verify_json_objects_for_server(",
            "            [",
            "                (",
            "                    get_domain_from_id(p.pdu.event_id),",
            "                    p.redacted_pdu_json,",
            "                    p.pdu.origin_server_ts if v.enforce_key_validity else 0,",
            "                    p.pdu.event_id,",
            "                )",
            "                for p in pdus_to_check_event_id",
            "            ]",
            "        )",
            "",
            "        def event_err(e, pdu_to_check):",
            "            errmsg = (",
            "                \"event id %s: unable to verify signature for event id domain: %s\"",
            "                % (pdu_to_check.pdu.event_id, e.getErrorMessage())",
            "            )",
            "            raise SynapseError(403, errmsg, Codes.FORBIDDEN)",
            "",
            "        for p, d in zip(pdus_to_check_event_id, more_deferreds):",
            "            d.addErrback(event_err, p)",
            "            p.deferreds.append(d)",
            "",
            "    # replace lists of deferreds with single Deferreds",
            "    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]",
            "",
            "",
            "def _flatten_deferred_list(deferreds):",
            "    \"\"\"Given a list of deferreds, either return the single deferred,",
            "    combine into a DeferredList, or return an already resolved deferred.",
            "    \"\"\"",
            "    if len(deferreds) > 1:",
            "        return DeferredList(deferreds, fireOnOneErrback=True, consumeErrors=True)",
            "    elif len(deferreds) == 1:",
            "        return deferreds[0]",
            "    else:",
            "        return defer.succeed(None)",
            "",
            "",
            "def _is_invite_via_3pid(event):",
            "    return (",
            "        event.type == EventTypes.Member",
            "        and event.membership == Membership.INVITE",
            "        and \"third_party_invite\" in event.content",
            "    )",
            "",
            "",
            "def event_from_pdu_json(pdu_json, event_format_version, outlier=False):",
            "    \"\"\"Construct a FrozenEvent from an event json received over federation",
            "",
            "    Args:",
            "        pdu_json (object): pdu as received over federation",
            "        event_format_version (int): The event format version",
            "        outlier (bool): True to mark this event as an outlier",
            "",
            "    Returns:",
            "        FrozenEvent",
            "",
            "    Raises:",
            "        SynapseError: if the pdu is missing required fields or is otherwise",
            "            not a valid matrix event",
            "    \"\"\"",
            "    # we could probably enforce a bunch of other fields here (room_id, sender,",
            "    # origin, etc etc)",
            "    assert_params_in_dict(pdu_json, (\"type\", \"depth\"))",
            "",
            "    depth = pdu_json[\"depth\"]",
            "    if not isinstance(depth, six.integer_types):",
            "        raise SynapseError(400, \"Depth %r not an intger\" % (depth,), Codes.BAD_JSON)",
            "",
            "    if depth < 0:",
            "        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)",
            "    elif depth > MAX_DEPTH:",
            "        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)",
            "",
            "    event = event_type_from_format_version(event_format_version)(pdu_json)",
            "",
            "    event.internal_metadata.outlier = outlier",
            "",
            "    return event"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "281": [
                "_check_sigs_on_pdus",
                "sender_err"
            ],
            "282": [
                "_check_sigs_on_pdus",
                "sender_err"
            ],
            "283": [
                "_check_sigs_on_pdus",
                "sender_err"
            ],
            "317": [
                "_check_sigs_on_pdus",
                "event_err"
            ],
            "318": [
                "_check_sigs_on_pdus",
                "event_err"
            ]
        },
        "addLocation": []
    },
    "synapse/federation/federation_server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 370,
                "PatchRowcode": "         pdu = event_from_pdu_json(content, format_ver)"
            },
            "1": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 371,
                "PatchRowcode": "         origin_host, _ = parse_server_name(origin)"
            },
            "2": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 372,
                "PatchRowcode": "         yield self.check_server_matches_acl(origin_host, pdu.room_id)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+        pdu = yield self._check_sigs_and_hash(room_version, pdu)"
            },
            "4": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "         ret_pdu = yield self.handler.on_invite_request(origin, pdu)"
            },
            "5": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "         time_now = self._clock.time_msec()"
            },
            "6": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "         return {\"event\": ret_pdu.get_pdu_json(time_now)}"
            },
            "7": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 387,
                "PatchRowcode": "         yield self.check_server_matches_acl(origin_host, pdu.room_id)"
            },
            "8": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 388,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 389,
                "PatchRowcode": "         logger.debug(\"on_send_join_request: pdu sigs: %s\", pdu.signatures)"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 390,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+        pdu = yield self._check_sigs_and_hash(room_version, pdu)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 392,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 393,
                "PatchRowcode": "         res_pdus = yield self.handler.on_send_join_request(origin, pdu)"
            },
            "14": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 394,
                "PatchRowcode": "         time_now = self._clock.time_msec()"
            },
            "15": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "         return ("
            },
            "16": {
                "beforePatchRowNumber": 421,
                "afterPatchRowNumber": 425,
                "PatchRowcode": "         yield self.check_server_matches_acl(origin_host, pdu.room_id)"
            },
            "17": {
                "beforePatchRowNumber": 422,
                "afterPatchRowNumber": 426,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 423,
                "afterPatchRowNumber": 427,
                "PatchRowcode": "         logger.debug(\"on_send_leave_request: pdu sigs: %s\", pdu.signatures)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 428,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 429,
                "PatchRowcode": "+        pdu = yield self._check_sigs_and_hash(room_version, pdu)"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 430,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": 424,
                "afterPatchRowNumber": 431,
                "PatchRowcode": "         yield self.handler.on_send_leave_request(origin, pdu)"
            },
            "23": {
                "beforePatchRowNumber": 425,
                "afterPatchRowNumber": 432,
                "PatchRowcode": "         return 200, {}"
            },
            "24": {
                "beforePatchRowNumber": 426,
                "afterPatchRowNumber": 433,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "",
            "import six",
            "from six import iteritems",
            "",
            "from canonicaljson import json",
            "from prometheus_client import Counter",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.abstract import isIPAddress",
            "from twisted.python import failure",
            "",
            "from synapse.api.constants import EventTypes, Membership",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    Codes,",
            "    FederationError,",
            "    IncompatibleRoomVersionError,",
            "    NotFoundError,",
            "    SynapseError,",
            "    UnsupportedRoomVersionError,",
            ")",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS",
            "from synapse.events import room_version_to_event_format",
            "from synapse.federation.federation_base import FederationBase, event_from_pdu_json",
            "from synapse.federation.persistence import TransactionActions",
            "from synapse.federation.units import Edu, Transaction",
            "from synapse.http.endpoint import parse_server_name",
            "from synapse.logging.context import nested_logging_context",
            "from synapse.logging.opentracing import log_kv, start_active_span_from_edu, trace",
            "from synapse.logging.utils import log_function",
            "from synapse.replication.http.federation import (",
            "    ReplicationFederationSendEduRestServlet,",
            "    ReplicationGetQueryRestServlet,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util import glob_to_regex",
            "from synapse.util.async_helpers import Linearizer, concurrently_execute",
            "from synapse.util.caches.response_cache import ResponseCache",
            "",
            "# when processing incoming transactions, we try to handle multiple rooms in",
            "# parallel, up to this limit.",
            "TRANSACTION_CONCURRENCY_LIMIT = 10",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "received_pdus_counter = Counter(\"synapse_federation_server_received_pdus\", \"\")",
            "",
            "received_edus_counter = Counter(\"synapse_federation_server_received_edus\", \"\")",
            "",
            "received_queries_counter = Counter(",
            "    \"synapse_federation_server_received_queries\", \"\", [\"type\"]",
            ")",
            "",
            "",
            "class FederationServer(FederationBase):",
            "    def __init__(self, hs):",
            "        super(FederationServer, self).__init__(hs)",
            "",
            "        self.auth = hs.get_auth()",
            "        self.handler = hs.get_handlers().federation_handler",
            "",
            "        self._server_linearizer = Linearizer(\"fed_server\")",
            "        self._transaction_linearizer = Linearizer(\"fed_txn_handler\")",
            "",
            "        self.transaction_actions = TransactionActions(self.store)",
            "",
            "        self.registry = hs.get_federation_registry()",
            "",
            "        # We cache responses to state queries, as they take a while and often",
            "        # come in waves.",
            "        self._state_resp_cache = ResponseCache(hs, \"state_resp\", timeout_ms=30000)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, versions, limit):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            pdus = yield self.handler.on_backfill_request(",
            "                origin, room_id, versions, limit",
            "            )",
            "",
            "            res = self._transaction_from_pdus(pdus).get_dict()",
            "",
            "        return 200, res",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_incoming_transaction(self, origin, transaction_data):",
            "        # keep this as early as possible to make the calculated origin ts as",
            "        # accurate as possible.",
            "        request_time = self._clock.time_msec()",
            "",
            "        transaction = Transaction(**transaction_data)",
            "",
            "        if not transaction.transaction_id:",
            "            raise Exception(\"Transaction missing transaction_id\")",
            "",
            "        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)",
            "",
            "        # use a linearizer to ensure that we don't process the same transaction",
            "        # multiple times in parallel.",
            "        with (",
            "            yield self._transaction_linearizer.queue(",
            "                (origin, transaction.transaction_id)",
            "            )",
            "        ):",
            "            result = yield self._handle_incoming_transaction(",
            "                origin, transaction, request_time",
            "            )",
            "",
            "        return result",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_incoming_transaction(self, origin, transaction, request_time):",
            "        \"\"\" Process an incoming transaction and return the HTTP response",
            "",
            "        Args:",
            "            origin (unicode): the server making the request",
            "            transaction (Transaction): incoming transaction",
            "            request_time (int): timestamp that the HTTP request arrived at",
            "",
            "        Returns:",
            "            Deferred[(int, object)]: http response code and body",
            "        \"\"\"",
            "        response = yield self.transaction_actions.have_responded(origin, transaction)",
            "",
            "        if response:",
            "            logger.debug(",
            "                \"[%s] We've already responded to this request\",",
            "                transaction.transaction_id,",
            "            )",
            "            return response",
            "",
            "        logger.debug(\"[%s] Transaction is new\", transaction.transaction_id)",
            "",
            "        # Reject if PDU count > 50 and EDU count > 100",
            "        if len(transaction.pdus) > 50 or (",
            "            hasattr(transaction, \"edus\") and len(transaction.edus) > 100",
            "        ):",
            "",
            "            logger.info(\"Transaction PDU or EDU count too large. Returning 400\")",
            "",
            "            response = {}",
            "            yield self.transaction_actions.set_response(",
            "                origin, transaction, 400, response",
            "            )",
            "            return 400, response",
            "",
            "        received_pdus_counter.inc(len(transaction.pdus))",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "",
            "        pdus_by_room = {}",
            "",
            "        for p in transaction.pdus:",
            "            if \"unsigned\" in p:",
            "                unsigned = p[\"unsigned\"]",
            "                if \"age\" in unsigned:",
            "                    p[\"age\"] = unsigned[\"age\"]",
            "            if \"age\" in p:",
            "                p[\"age_ts\"] = request_time - int(p[\"age\"])",
            "                del p[\"age\"]",
            "",
            "            # We try and pull out an event ID so that if later checks fail we",
            "            # can log something sensible. We don't mandate an event ID here in",
            "            # case future event formats get rid of the key.",
            "            possible_event_id = p.get(\"event_id\", \"<Unknown>\")",
            "",
            "            # Now we get the room ID so that we can check that we know the",
            "            # version of the room.",
            "            room_id = p.get(\"room_id\")",
            "            if not room_id:",
            "                logger.info(",
            "                    \"Ignoring PDU as does not have a room_id. Event ID: %s\",",
            "                    possible_event_id,",
            "                )",
            "                continue",
            "",
            "            try:",
            "                room_version = yield self.store.get_room_version(room_id)",
            "            except NotFoundError:",
            "                logger.info(\"Ignoring PDU for unknown room_id: %s\", room_id)",
            "                continue",
            "",
            "            try:",
            "                format_ver = room_version_to_event_format(room_version)",
            "            except UnsupportedRoomVersionError:",
            "                # this can happen if support for a given room version is withdrawn,",
            "                # so that we still get events for said room.",
            "                logger.info(",
            "                    \"Ignoring PDU for room %s with unknown version %s\",",
            "                    room_id,",
            "                    room_version,",
            "                )",
            "                continue",
            "",
            "            event = event_from_pdu_json(p, format_ver)",
            "            pdus_by_room.setdefault(room_id, []).append(event)",
            "",
            "        pdu_results = {}",
            "",
            "        # we can process different rooms in parallel (which is useful if they",
            "        # require callouts to other servers to fetch missing events), but",
            "        # impose a limit to avoid going too crazy with ram/cpu.",
            "",
            "        @defer.inlineCallbacks",
            "        def process_pdus_for_room(room_id):",
            "            logger.debug(\"Processing PDUs for %s\", room_id)",
            "            try:",
            "                yield self.check_server_matches_acl(origin_host, room_id)",
            "            except AuthError as e:",
            "                logger.warn(\"Ignoring PDUs for room %s from banned server\", room_id)",
            "                for pdu in pdus_by_room[room_id]:",
            "                    event_id = pdu.event_id",
            "                    pdu_results[event_id] = e.error_dict()",
            "                return",
            "",
            "            for pdu in pdus_by_room[room_id]:",
            "                event_id = pdu.event_id",
            "                with nested_logging_context(event_id):",
            "                    try:",
            "                        yield self._handle_received_pdu(origin, pdu)",
            "                        pdu_results[event_id] = {}",
            "                    except FederationError as e:",
            "                        logger.warn(\"Error handling PDU %s: %s\", event_id, e)",
            "                        pdu_results[event_id] = {\"error\": str(e)}",
            "                    except Exception as e:",
            "                        f = failure.Failure()",
            "                        pdu_results[event_id] = {\"error\": str(e)}",
            "                        logger.error(",
            "                            \"Failed to handle PDU %s\",",
            "                            event_id,",
            "                            exc_info=(f.type, f.value, f.getTracebackObject()),",
            "                        )",
            "",
            "        yield concurrently_execute(",
            "            process_pdus_for_room, pdus_by_room.keys(), TRANSACTION_CONCURRENCY_LIMIT",
            "        )",
            "",
            "        if hasattr(transaction, \"edus\"):",
            "            for edu in (Edu(**x) for x in transaction.edus):",
            "                yield self.received_edu(origin, edu.edu_type, edu.content)",
            "",
            "        response = {\"pdus\": pdu_results}",
            "",
            "        logger.debug(\"Returning: %s\", str(response))",
            "",
            "        yield self.transaction_actions.set_response(origin, transaction, 200, response)",
            "        return 200, response",
            "",
            "    @defer.inlineCallbacks",
            "    def received_edu(self, origin, edu_type, content):",
            "        received_edus_counter.inc()",
            "        yield self.registry.on_edu(edu_type, origin, content)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_context_state_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        # we grab the linearizer to protect ourselves from servers which hammer",
            "        # us. In theory we might already have the response to this query",
            "        # in the cache so we could return it without waiting for the linearizer",
            "        # - but that's non-trivial to get right, and anyway somewhat defeats",
            "        # the point of the linearizer.",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            resp = yield self._state_resp_cache.wrap(",
            "                (room_id, event_id),",
            "                self._on_context_state_request_compute,",
            "                room_id,",
            "                event_id,",
            "            )",
            "",
            "        return 200, resp",
            "",
            "    @defer.inlineCallbacks",
            "    def on_state_ids_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        state_ids = yield self.handler.get_state_ids_for_pdu(room_id, event_id)",
            "        auth_chain_ids = yield self.store.get_auth_chain_ids(state_ids)",
            "",
            "        return 200, {\"pdu_ids\": state_ids, \"auth_chain_ids\": auth_chain_ids}",
            "",
            "    @defer.inlineCallbacks",
            "    def _on_context_state_request_compute(self, room_id, event_id):",
            "        pdus = yield self.handler.get_state_for_pdu(room_id, event_id)",
            "        auth_chain = yield self.store.get_auth_chain([pdu.event_id for pdu in pdus])",
            "",
            "        return {",
            "            \"pdus\": [pdu.get_pdu_json() for pdu in pdus],",
            "            \"auth_chain\": [pdu.get_pdu_json() for pdu in auth_chain],",
            "        }",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pdu_request(self, origin, event_id):",
            "        pdu = yield self.handler.get_persisted_pdu(origin, event_id)",
            "",
            "        if pdu:",
            "            return 200, self._transaction_from_pdus([pdu]).get_dict()",
            "        else:",
            "            return 404, \"\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_request(self, query_type, args):",
            "        received_queries_counter.labels(query_type).inc()",
            "        resp = yield self.registry.on_query(query_type, args)",
            "        return 200, resp",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_join_request(self, origin, room_id, user_id, supported_versions):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        if room_version not in supported_versions:",
            "            logger.warn(\"Room version %s not in %s\", room_version, supported_versions)",
            "            raise IncompatibleRoomVersionError(room_version=room_version)",
            "",
            "        pdu = yield self.handler.on_make_join_request(origin, room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": pdu.get_pdu_json(time_now), \"room_version\": room_version}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, content, room_version):",
            "        if room_version not in KNOWN_ROOM_VERSIONS:",
            "            raise SynapseError(",
            "                400,",
            "                \"Homeserver does not support this room version\",",
            "                Codes.UNSUPPORTED_ROOM_VERSION,",
            "            )",
            "",
            "        format_ver = room_version_to_event_format(room_version)",
            "",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "        ret_pdu = yield self.handler.on_invite_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": ret_pdu.get_pdu_json(time_now)}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_join_request(self, origin, content, room_id):",
            "        logger.debug(\"on_send_join_request: content: %s\", content)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        format_ver = room_version_to_event_format(room_version)",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_join_request: pdu sigs: %s\", pdu.signatures)",
            "        res_pdus = yield self.handler.on_send_join_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        return (",
            "            200,",
            "            {",
            "                \"state\": [p.get_pdu_json(time_now) for p in res_pdus[\"state\"]],",
            "                \"auth_chain\": [",
            "                    p.get_pdu_json(time_now) for p in res_pdus[\"auth_chain\"]",
            "                ],",
            "            },",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "        pdu = yield self.handler.on_make_leave_request(origin, room_id, user_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": pdu.get_pdu_json(time_now), \"room_version\": room_version}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_leave_request(self, origin, content, room_id):",
            "        logger.debug(\"on_send_leave_request: content: %s\", content)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        format_ver = room_version_to_event_format(room_version)",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_leave_request: pdu sigs: %s\", pdu.signatures)",
            "        yield self.handler.on_send_leave_request(origin, pdu)",
            "        return 200, {}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, origin, room_id, event_id):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            time_now = self._clock.time_msec()",
            "            auth_pdus = yield self.handler.on_event_auth(event_id)",
            "            res = {\"auth_chain\": [a.get_pdu_json(time_now) for a in auth_pdus]}",
            "        return 200, res",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth_request(self, origin, content, room_id, event_id):",
            "        \"\"\"",
            "        Content is a dict with keys::",
            "            auth_chain (list): A list of events that give the auth chain.",
            "            missing (list): A list of event_ids indicating what the other",
            "              side (`origin`) think we're missing.",
            "            rejects (dict): A mapping from event_id to a 2-tuple of reason",
            "              string and a proof (or None) of why the event was rejected.",
            "              The keys of this dict give the list of events the `origin` has",
            "              rejected.",
            "",
            "        Args:",
            "            origin (str)",
            "            content (dict)",
            "            event_id (str)",
            "",
            "        Returns:",
            "            Deferred: Results in `dict` with the same format as `content`",
            "        \"\"\"",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            room_version = yield self.store.get_room_version(room_id)",
            "            format_ver = room_version_to_event_format(room_version)",
            "",
            "            auth_chain = [",
            "                event_from_pdu_json(e, format_ver) for e in content[\"auth_chain\"]",
            "            ]",
            "",
            "            signed_auth = yield self._check_sigs_and_hash_and_fetch(",
            "                origin, auth_chain, outlier=True, room_version=room_version",
            "            )",
            "",
            "            ret = yield self.handler.on_query_auth(",
            "                origin,",
            "                event_id,",
            "                room_id,",
            "                signed_auth,",
            "                content.get(\"rejects\", []),",
            "                content.get(\"missing\", []),",
            "            )",
            "",
            "            time_now = self._clock.time_msec()",
            "            send_content = {",
            "                \"auth_chain\": [e.get_pdu_json(time_now) for e in ret[\"auth_chain\"]],",
            "                \"rejects\": ret.get(\"rejects\", []),",
            "                \"missing\": ret.get(\"missing\", []),",
            "            }",
            "",
            "        return 200, send_content",
            "",
            "    @log_function",
            "    def on_query_client_keys(self, origin, content):",
            "        return self.on_query_request(\"client_keys\", content)",
            "",
            "    def on_query_user_devices(self, origin, user_id):",
            "        return self.on_query_request(\"user_devices\", user_id)",
            "",
            "    @trace",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_claim_client_keys(self, origin, content):",
            "        query = []",
            "        for user_id, device_keys in content.get(\"one_time_keys\", {}).items():",
            "            for device_id, algorithm in device_keys.items():",
            "                query.append((user_id, device_id, algorithm))",
            "",
            "        log_kv({\"message\": \"Claiming one time keys.\", \"user, device pairs\": query})",
            "        results = yield self.store.claim_e2e_one_time_keys(query)",
            "",
            "        json_result = {}",
            "        for user_id, device_keys in results.items():",
            "            for device_id, keys in device_keys.items():",
            "                for key_id, json_bytes in keys.items():",
            "                    json_result.setdefault(user_id, {})[device_id] = {",
            "                        key_id: json.loads(json_bytes)",
            "                    }",
            "",
            "        logger.info(",
            "            \"Claimed one-time-keys: %s\",",
            "            \",\".join(",
            "                (",
            "                    \"%s for %s:%s\" % (key_id, user_id, device_id)",
            "                    for user_id, user_keys in iteritems(json_result)",
            "                    for device_id, device_keys in iteritems(user_keys)",
            "                    for key_id, _ in iteritems(device_keys)",
            "                )",
            "            ),",
            "        )",
            "",
            "        return {\"one_time_keys\": json_result}",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_get_missing_events(",
            "        self, origin, room_id, earliest_events, latest_events, limit",
            "    ):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            logger.info(",
            "                \"on_get_missing_events: earliest_events: %r, latest_events: %r,\"",
            "                \" limit: %d\",",
            "                earliest_events,",
            "                latest_events,",
            "                limit,",
            "            )",
            "",
            "            missing_events = yield self.handler.on_get_missing_events(",
            "                origin, room_id, earliest_events, latest_events, limit",
            "            )",
            "",
            "            if len(missing_events) < 5:",
            "                logger.info(",
            "                    \"Returning %d events: %r\", len(missing_events), missing_events",
            "                )",
            "            else:",
            "                logger.info(\"Returning %d events\", len(missing_events))",
            "",
            "            time_now = self._clock.time_msec()",
            "",
            "        return {\"events\": [ev.get_pdu_json(time_now) for ev in missing_events]}",
            "",
            "    @log_function",
            "    def on_openid_userinfo(self, token):",
            "        ts_now_ms = self._clock.time_msec()",
            "        return self.store.get_user_id_for_open_id_token(token, ts_now_ms)",
            "",
            "    def _transaction_from_pdus(self, pdu_list):",
            "        \"\"\"Returns a new Transaction containing the given PDUs suitable for",
            "        transmission.",
            "        \"\"\"",
            "        time_now = self._clock.time_msec()",
            "        pdus = [p.get_pdu_json(time_now) for p in pdu_list]",
            "        return Transaction(",
            "            origin=self.server_name,",
            "            pdus=pdus,",
            "            origin_server_ts=int(time_now),",
            "            destination=None,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_received_pdu(self, origin, pdu):",
            "        \"\"\" Process a PDU received in a federation /send/ transaction.",
            "",
            "        If the event is invalid, then this method throws a FederationError.",
            "        (The error will then be logged and sent back to the sender (which",
            "        probably won't do anything with it), and other events in the",
            "        transaction will be processed as normal).",
            "",
            "        It is likely that we'll then receive other events which refer to",
            "        this rejected_event in their prev_events, etc.  When that happens,",
            "        we'll attempt to fetch the rejected event again, which will presumably",
            "        fail, so those second-generation events will also get rejected.",
            "",
            "        Eventually, we get to the point where there are more than 10 events",
            "        between any new events and the original rejected event. Since we",
            "        only try to backfill 10 events deep on received pdu, we then accept the",
            "        new event, possibly introducing a discontinuity in the DAG, with new",
            "        forward extremities, so normal service is approximately returned,",
            "        until we try to backfill across the discontinuity.",
            "",
            "        Args:",
            "            origin (str): server which sent the pdu",
            "            pdu (FrozenEvent): received pdu",
            "",
            "        Returns (Deferred): completes with None",
            "",
            "        Raises: FederationError if the signatures / hash do not match, or",
            "            if the event was unacceptable for any other reason (eg, too large,",
            "            too many prev_events, couldn't find the prev_events)",
            "        \"\"\"",
            "        # check that it's actually being sent from a valid destination to",
            "        # workaround bug #1753 in 0.18.5 and 0.18.6",
            "        if origin != get_domain_from_id(pdu.sender):",
            "            # We continue to accept join events from any server; this is",
            "            # necessary for the federation join dance to work correctly.",
            "            # (When we join over federation, the \"helper\" server is",
            "            # responsible for sending out the join event, rather than the",
            "            # origin. See bug #1893. This is also true for some third party",
            "            # invites).",
            "            if not (",
            "                pdu.type == \"m.room.member\"",
            "                and pdu.content",
            "                and pdu.content.get(\"membership\", None)",
            "                in (Membership.JOIN, Membership.INVITE)",
            "            ):",
            "                logger.info(",
            "                    \"Discarding PDU %s from invalid origin %s\", pdu.event_id, origin",
            "                )",
            "                return",
            "            else:",
            "                logger.info(\"Accepting join PDU %s from %s\", pdu.event_id, origin)",
            "",
            "        # We've already checked that we know the room version by this point",
            "        room_version = yield self.store.get_room_version(pdu.room_id)",
            "",
            "        # Check signature.",
            "        try:",
            "            pdu = yield self._check_sigs_and_hash(room_version, pdu)",
            "        except SynapseError as e:",
            "            raise FederationError(\"ERROR\", e.code, e.msg, affected=pdu.event_id)",
            "",
            "        yield self.handler.on_receive_pdu(origin, pdu, sent_to_us_directly=True)",
            "",
            "    def __str__(self):",
            "        return \"<ReplicationLayer(%s)>\" % self.server_name",
            "",
            "    @defer.inlineCallbacks",
            "    def exchange_third_party_invite(",
            "        self, sender_user_id, target_user_id, room_id, signed",
            "    ):",
            "        ret = yield self.handler.exchange_third_party_invite(",
            "            sender_user_id, target_user_id, room_id, signed",
            "        )",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def on_exchange_third_party_invite_request(self, room_id, event_dict):",
            "        ret = yield self.handler.on_exchange_third_party_invite_request(",
            "            room_id, event_dict",
            "        )",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def check_server_matches_acl(self, server_name, room_id):",
            "        \"\"\"Check if the given server is allowed by the server ACLs in the room",
            "",
            "        Args:",
            "            server_name (str): name of server, *without any port part*",
            "            room_id (str): ID of the room to check",
            "",
            "        Raises:",
            "            AuthError if the server does not match the ACL",
            "        \"\"\"",
            "        state_ids = yield self.store.get_current_state_ids(room_id)",
            "        acl_event_id = state_ids.get((EventTypes.ServerACL, \"\"))",
            "",
            "        if not acl_event_id:",
            "            return",
            "",
            "        acl_event = yield self.store.get_event(acl_event_id)",
            "        if server_matches_acl_event(server_name, acl_event):",
            "            return",
            "",
            "        raise AuthError(code=403, msg=\"Server is banned from room\")",
            "",
            "",
            "def server_matches_acl_event(server_name, acl_event):",
            "    \"\"\"Check if the given server is allowed by the ACL event",
            "",
            "    Args:",
            "        server_name (str): name of server, without any port part",
            "        acl_event (EventBase): m.room.server_acl event",
            "",
            "    Returns:",
            "        bool: True if this server is allowed by the ACLs",
            "    \"\"\"",
            "    logger.debug(\"Checking %s against acl %s\", server_name, acl_event.content)",
            "",
            "    # first of all, check if literal IPs are blocked, and if so, whether the",
            "    # server name is a literal IP",
            "    allow_ip_literals = acl_event.content.get(\"allow_ip_literals\", True)",
            "    if not isinstance(allow_ip_literals, bool):",
            "        logger.warn(\"Ignorning non-bool allow_ip_literals flag\")",
            "        allow_ip_literals = True",
            "    if not allow_ip_literals:",
            "        # check for ipv6 literals. These start with '['.",
            "        if server_name[0] == \"[\":",
            "            return False",
            "",
            "        # check for ipv4 literals. We can just lift the routine from twisted.",
            "        if isIPAddress(server_name):",
            "            return False",
            "",
            "    # next,  check the deny list",
            "    deny = acl_event.content.get(\"deny\", [])",
            "    if not isinstance(deny, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list deny ACL %s\", deny)",
            "        deny = []",
            "    for e in deny:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched deny rule %s\", server_name, e)",
            "            return False",
            "",
            "    # then the allow list.",
            "    allow = acl_event.content.get(\"allow\", [])",
            "    if not isinstance(allow, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list allow ACL %s\", allow)",
            "        allow = []",
            "    for e in allow:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched allow rule %s\", server_name, e)",
            "            return True",
            "",
            "    # everything else should be rejected.",
            "    # logger.info(\"%s fell through\", server_name)",
            "    return False",
            "",
            "",
            "def _acl_entry_matches(server_name, acl_entry):",
            "    if not isinstance(acl_entry, six.string_types):",
            "        logger.warn(",
            "            \"Ignoring non-str ACL entry '%s' (is %s)\", acl_entry, type(acl_entry)",
            "        )",
            "        return False",
            "    regex = glob_to_regex(acl_entry)",
            "    return regex.match(server_name)",
            "",
            "",
            "class FederationHandlerRegistry(object):",
            "    \"\"\"Allows classes to register themselves as handlers for a given EDU or",
            "    query type for incoming federation traffic.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.edu_handlers = {}",
            "        self.query_handlers = {}",
            "",
            "    def register_edu_handler(self, edu_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation EDU of the given type.",
            "",
            "        Args:",
            "            edu_type (str): The type of the incoming EDU to register handler for",
            "            handler (Callable[[str, dict]]): A callable invoked on incoming EDU",
            "                of the given type. The arguments are the origin server name and",
            "                the EDU contents.",
            "        \"\"\"",
            "        if edu_type in self.edu_handlers:",
            "            raise KeyError(\"Already have an EDU handler for %s\" % (edu_type,))",
            "",
            "        logger.info(\"Registering federation EDU handler for %r\", edu_type)",
            "",
            "        self.edu_handlers[edu_type] = handler",
            "",
            "    def register_query_handler(self, query_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation query of the given type.",
            "",
            "        Args:",
            "            query_type (str): Category name of the query, which should match",
            "                the string used by make_query.",
            "            handler (Callable[[dict], Deferred[dict]]): Invoked to handle",
            "                incoming queries of this type. The return will be yielded",
            "                on and the result used as the response to the query request.",
            "        \"\"\"",
            "        if query_type in self.query_handlers:",
            "            raise KeyError(\"Already have a Query handler for %s\" % (query_type,))",
            "",
            "        logger.info(\"Registering federation query handler for %r\", query_type)",
            "",
            "        self.query_handlers[query_type] = handler",
            "",
            "    @defer.inlineCallbacks",
            "    def on_edu(self, edu_type, origin, content):",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for EDU type %s\", edu_type)",
            "",
            "        with start_active_span_from_edu(content, \"handle_edu\"):",
            "            try:",
            "                yield handler(origin, content)",
            "            except SynapseError as e:",
            "                logger.info(\"Failed to handle edu %r: %r\", edu_type, e)",
            "            except Exception:",
            "                logger.exception(\"Failed to handle edu %r\", edu_type)",
            "",
            "    def on_query(self, query_type, args):",
            "        handler = self.query_handlers.get(query_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for query type %s\", query_type)",
            "            raise NotFoundError(\"No handler for Query type '%s'\" % (query_type,))",
            "",
            "        return handler(args)",
            "",
            "",
            "class ReplicationFederationHandlerRegistry(FederationHandlerRegistry):",
            "    \"\"\"A FederationHandlerRegistry for worker processes.",
            "",
            "    When receiving EDU or queries it will check if an appropriate handler has",
            "    been registered on the worker, if there isn't one then it calls off to the",
            "    master process.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "        self.clock = hs.get_clock()",
            "",
            "        self._get_query_client = ReplicationGetQueryRestServlet.make_client(hs)",
            "        self._send_edu = ReplicationFederationSendEduRestServlet.make_client(hs)",
            "",
            "        super(ReplicationFederationHandlerRegistry, self).__init__()",
            "",
            "    def on_edu(self, edu_type, origin, content):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        if not self.config.use_presence and edu_type == \"m.presence\":",
            "            return",
            "",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if handler:",
            "            return super(ReplicationFederationHandlerRegistry, self).on_edu(",
            "                edu_type, origin, content",
            "            )",
            "",
            "        return self._send_edu(edu_type=edu_type, origin=origin, content=content)",
            "",
            "    def on_query(self, query_type, args):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.query_handlers.get(query_type)",
            "        if handler:",
            "            return handler(args)",
            "",
            "        return self._get_query_client(query_type=query_type, args=args)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2018 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "import logging",
            "",
            "import six",
            "from six import iteritems",
            "",
            "from canonicaljson import json",
            "from prometheus_client import Counter",
            "",
            "from twisted.internet import defer",
            "from twisted.internet.abstract import isIPAddress",
            "from twisted.python import failure",
            "",
            "from synapse.api.constants import EventTypes, Membership",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    Codes,",
            "    FederationError,",
            "    IncompatibleRoomVersionError,",
            "    NotFoundError,",
            "    SynapseError,",
            "    UnsupportedRoomVersionError,",
            ")",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS",
            "from synapse.events import room_version_to_event_format",
            "from synapse.federation.federation_base import FederationBase, event_from_pdu_json",
            "from synapse.federation.persistence import TransactionActions",
            "from synapse.federation.units import Edu, Transaction",
            "from synapse.http.endpoint import parse_server_name",
            "from synapse.logging.context import nested_logging_context",
            "from synapse.logging.opentracing import log_kv, start_active_span_from_edu, trace",
            "from synapse.logging.utils import log_function",
            "from synapse.replication.http.federation import (",
            "    ReplicationFederationSendEduRestServlet,",
            "    ReplicationGetQueryRestServlet,",
            ")",
            "from synapse.types import get_domain_from_id",
            "from synapse.util import glob_to_regex",
            "from synapse.util.async_helpers import Linearizer, concurrently_execute",
            "from synapse.util.caches.response_cache import ResponseCache",
            "",
            "# when processing incoming transactions, we try to handle multiple rooms in",
            "# parallel, up to this limit.",
            "TRANSACTION_CONCURRENCY_LIMIT = 10",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "received_pdus_counter = Counter(\"synapse_federation_server_received_pdus\", \"\")",
            "",
            "received_edus_counter = Counter(\"synapse_federation_server_received_edus\", \"\")",
            "",
            "received_queries_counter = Counter(",
            "    \"synapse_federation_server_received_queries\", \"\", [\"type\"]",
            ")",
            "",
            "",
            "class FederationServer(FederationBase):",
            "    def __init__(self, hs):",
            "        super(FederationServer, self).__init__(hs)",
            "",
            "        self.auth = hs.get_auth()",
            "        self.handler = hs.get_handlers().federation_handler",
            "",
            "        self._server_linearizer = Linearizer(\"fed_server\")",
            "        self._transaction_linearizer = Linearizer(\"fed_txn_handler\")",
            "",
            "        self.transaction_actions = TransactionActions(self.store)",
            "",
            "        self.registry = hs.get_federation_registry()",
            "",
            "        # We cache responses to state queries, as they take a while and often",
            "        # come in waves.",
            "        self._state_resp_cache = ResponseCache(hs, \"state_resp\", timeout_ms=30000)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, versions, limit):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            pdus = yield self.handler.on_backfill_request(",
            "                origin, room_id, versions, limit",
            "            )",
            "",
            "            res = self._transaction_from_pdus(pdus).get_dict()",
            "",
            "        return 200, res",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_incoming_transaction(self, origin, transaction_data):",
            "        # keep this as early as possible to make the calculated origin ts as",
            "        # accurate as possible.",
            "        request_time = self._clock.time_msec()",
            "",
            "        transaction = Transaction(**transaction_data)",
            "",
            "        if not transaction.transaction_id:",
            "            raise Exception(\"Transaction missing transaction_id\")",
            "",
            "        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)",
            "",
            "        # use a linearizer to ensure that we don't process the same transaction",
            "        # multiple times in parallel.",
            "        with (",
            "            yield self._transaction_linearizer.queue(",
            "                (origin, transaction.transaction_id)",
            "            )",
            "        ):",
            "            result = yield self._handle_incoming_transaction(",
            "                origin, transaction, request_time",
            "            )",
            "",
            "        return result",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_incoming_transaction(self, origin, transaction, request_time):",
            "        \"\"\" Process an incoming transaction and return the HTTP response",
            "",
            "        Args:",
            "            origin (unicode): the server making the request",
            "            transaction (Transaction): incoming transaction",
            "            request_time (int): timestamp that the HTTP request arrived at",
            "",
            "        Returns:",
            "            Deferred[(int, object)]: http response code and body",
            "        \"\"\"",
            "        response = yield self.transaction_actions.have_responded(origin, transaction)",
            "",
            "        if response:",
            "            logger.debug(",
            "                \"[%s] We've already responded to this request\",",
            "                transaction.transaction_id,",
            "            )",
            "            return response",
            "",
            "        logger.debug(\"[%s] Transaction is new\", transaction.transaction_id)",
            "",
            "        # Reject if PDU count > 50 and EDU count > 100",
            "        if len(transaction.pdus) > 50 or (",
            "            hasattr(transaction, \"edus\") and len(transaction.edus) > 100",
            "        ):",
            "",
            "            logger.info(\"Transaction PDU or EDU count too large. Returning 400\")",
            "",
            "            response = {}",
            "            yield self.transaction_actions.set_response(",
            "                origin, transaction, 400, response",
            "            )",
            "            return 400, response",
            "",
            "        received_pdus_counter.inc(len(transaction.pdus))",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "",
            "        pdus_by_room = {}",
            "",
            "        for p in transaction.pdus:",
            "            if \"unsigned\" in p:",
            "                unsigned = p[\"unsigned\"]",
            "                if \"age\" in unsigned:",
            "                    p[\"age\"] = unsigned[\"age\"]",
            "            if \"age\" in p:",
            "                p[\"age_ts\"] = request_time - int(p[\"age\"])",
            "                del p[\"age\"]",
            "",
            "            # We try and pull out an event ID so that if later checks fail we",
            "            # can log something sensible. We don't mandate an event ID here in",
            "            # case future event formats get rid of the key.",
            "            possible_event_id = p.get(\"event_id\", \"<Unknown>\")",
            "",
            "            # Now we get the room ID so that we can check that we know the",
            "            # version of the room.",
            "            room_id = p.get(\"room_id\")",
            "            if not room_id:",
            "                logger.info(",
            "                    \"Ignoring PDU as does not have a room_id. Event ID: %s\",",
            "                    possible_event_id,",
            "                )",
            "                continue",
            "",
            "            try:",
            "                room_version = yield self.store.get_room_version(room_id)",
            "            except NotFoundError:",
            "                logger.info(\"Ignoring PDU for unknown room_id: %s\", room_id)",
            "                continue",
            "",
            "            try:",
            "                format_ver = room_version_to_event_format(room_version)",
            "            except UnsupportedRoomVersionError:",
            "                # this can happen if support for a given room version is withdrawn,",
            "                # so that we still get events for said room.",
            "                logger.info(",
            "                    \"Ignoring PDU for room %s with unknown version %s\",",
            "                    room_id,",
            "                    room_version,",
            "                )",
            "                continue",
            "",
            "            event = event_from_pdu_json(p, format_ver)",
            "            pdus_by_room.setdefault(room_id, []).append(event)",
            "",
            "        pdu_results = {}",
            "",
            "        # we can process different rooms in parallel (which is useful if they",
            "        # require callouts to other servers to fetch missing events), but",
            "        # impose a limit to avoid going too crazy with ram/cpu.",
            "",
            "        @defer.inlineCallbacks",
            "        def process_pdus_for_room(room_id):",
            "            logger.debug(\"Processing PDUs for %s\", room_id)",
            "            try:",
            "                yield self.check_server_matches_acl(origin_host, room_id)",
            "            except AuthError as e:",
            "                logger.warn(\"Ignoring PDUs for room %s from banned server\", room_id)",
            "                for pdu in pdus_by_room[room_id]:",
            "                    event_id = pdu.event_id",
            "                    pdu_results[event_id] = e.error_dict()",
            "                return",
            "",
            "            for pdu in pdus_by_room[room_id]:",
            "                event_id = pdu.event_id",
            "                with nested_logging_context(event_id):",
            "                    try:",
            "                        yield self._handle_received_pdu(origin, pdu)",
            "                        pdu_results[event_id] = {}",
            "                    except FederationError as e:",
            "                        logger.warn(\"Error handling PDU %s: %s\", event_id, e)",
            "                        pdu_results[event_id] = {\"error\": str(e)}",
            "                    except Exception as e:",
            "                        f = failure.Failure()",
            "                        pdu_results[event_id] = {\"error\": str(e)}",
            "                        logger.error(",
            "                            \"Failed to handle PDU %s\",",
            "                            event_id,",
            "                            exc_info=(f.type, f.value, f.getTracebackObject()),",
            "                        )",
            "",
            "        yield concurrently_execute(",
            "            process_pdus_for_room, pdus_by_room.keys(), TRANSACTION_CONCURRENCY_LIMIT",
            "        )",
            "",
            "        if hasattr(transaction, \"edus\"):",
            "            for edu in (Edu(**x) for x in transaction.edus):",
            "                yield self.received_edu(origin, edu.edu_type, edu.content)",
            "",
            "        response = {\"pdus\": pdu_results}",
            "",
            "        logger.debug(\"Returning: %s\", str(response))",
            "",
            "        yield self.transaction_actions.set_response(origin, transaction, 200, response)",
            "        return 200, response",
            "",
            "    @defer.inlineCallbacks",
            "    def received_edu(self, origin, edu_type, content):",
            "        received_edus_counter.inc()",
            "        yield self.registry.on_edu(edu_type, origin, content)",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_context_state_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        # we grab the linearizer to protect ourselves from servers which hammer",
            "        # us. In theory we might already have the response to this query",
            "        # in the cache so we could return it without waiting for the linearizer",
            "        # - but that's non-trivial to get right, and anyway somewhat defeats",
            "        # the point of the linearizer.",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            resp = yield self._state_resp_cache.wrap(",
            "                (room_id, event_id),",
            "                self._on_context_state_request_compute,",
            "                room_id,",
            "                event_id,",
            "            )",
            "",
            "        return 200, resp",
            "",
            "    @defer.inlineCallbacks",
            "    def on_state_ids_request(self, origin, room_id, event_id):",
            "        if not event_id:",
            "            raise NotImplementedError(\"Specify an event\")",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        state_ids = yield self.handler.get_state_ids_for_pdu(room_id, event_id)",
            "        auth_chain_ids = yield self.store.get_auth_chain_ids(state_ids)",
            "",
            "        return 200, {\"pdu_ids\": state_ids, \"auth_chain_ids\": auth_chain_ids}",
            "",
            "    @defer.inlineCallbacks",
            "    def _on_context_state_request_compute(self, room_id, event_id):",
            "        pdus = yield self.handler.get_state_for_pdu(room_id, event_id)",
            "        auth_chain = yield self.store.get_auth_chain([pdu.event_id for pdu in pdus])",
            "",
            "        return {",
            "            \"pdus\": [pdu.get_pdu_json() for pdu in pdus],",
            "            \"auth_chain\": [pdu.get_pdu_json() for pdu in auth_chain],",
            "        }",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_pdu_request(self, origin, event_id):",
            "        pdu = yield self.handler.get_persisted_pdu(origin, event_id)",
            "",
            "        if pdu:",
            "            return 200, self._transaction_from_pdus([pdu]).get_dict()",
            "        else:",
            "            return 404, \"\"",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_request(self, query_type, args):",
            "        received_queries_counter.labels(query_type).inc()",
            "        resp = yield self.registry.on_query(query_type, args)",
            "        return 200, resp",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_join_request(self, origin, room_id, user_id, supported_versions):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        if room_version not in supported_versions:",
            "            logger.warn(\"Room version %s not in %s\", room_version, supported_versions)",
            "            raise IncompatibleRoomVersionError(room_version=room_version)",
            "",
            "        pdu = yield self.handler.on_make_join_request(origin, room_id, user_id)",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": pdu.get_pdu_json(time_now), \"room_version\": room_version}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, content, room_version):",
            "        if room_version not in KNOWN_ROOM_VERSIONS:",
            "            raise SynapseError(",
            "                400,",
            "                \"Homeserver does not support this room version\",",
            "                Codes.UNSUPPORTED_ROOM_VERSION,",
            "            )",
            "",
            "        format_ver = room_version_to_event_format(room_version)",
            "",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "        pdu = yield self._check_sigs_and_hash(room_version, pdu)",
            "        ret_pdu = yield self.handler.on_invite_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": ret_pdu.get_pdu_json(time_now)}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_join_request(self, origin, content, room_id):",
            "        logger.debug(\"on_send_join_request: content: %s\", content)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        format_ver = room_version_to_event_format(room_version)",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_join_request: pdu sigs: %s\", pdu.signatures)",
            "",
            "        pdu = yield self._check_sigs_and_hash(room_version, pdu)",
            "",
            "        res_pdus = yield self.handler.on_send_join_request(origin, pdu)",
            "        time_now = self._clock.time_msec()",
            "        return (",
            "            200,",
            "            {",
            "                \"state\": [p.get_pdu_json(time_now) for p in res_pdus[\"state\"]],",
            "                \"auth_chain\": [",
            "                    p.get_pdu_json(time_now) for p in res_pdus[\"auth_chain\"]",
            "                ],",
            "            },",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, room_id)",
            "        pdu = yield self.handler.on_make_leave_request(origin, room_id, user_id)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        time_now = self._clock.time_msec()",
            "        return {\"event\": pdu.get_pdu_json(time_now), \"room_version\": room_version}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_send_leave_request(self, origin, content, room_id):",
            "        logger.debug(\"on_send_leave_request: content: %s\", content)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        format_ver = room_version_to_event_format(room_version)",
            "        pdu = event_from_pdu_json(content, format_ver)",
            "",
            "        origin_host, _ = parse_server_name(origin)",
            "        yield self.check_server_matches_acl(origin_host, pdu.room_id)",
            "",
            "        logger.debug(\"on_send_leave_request: pdu sigs: %s\", pdu.signatures)",
            "",
            "        pdu = yield self._check_sigs_and_hash(room_version, pdu)",
            "",
            "        yield self.handler.on_send_leave_request(origin, pdu)",
            "        return 200, {}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, origin, room_id, event_id):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            time_now = self._clock.time_msec()",
            "            auth_pdus = yield self.handler.on_event_auth(event_id)",
            "            res = {\"auth_chain\": [a.get_pdu_json(time_now) for a in auth_pdus]}",
            "        return 200, res",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth_request(self, origin, content, room_id, event_id):",
            "        \"\"\"",
            "        Content is a dict with keys::",
            "            auth_chain (list): A list of events that give the auth chain.",
            "            missing (list): A list of event_ids indicating what the other",
            "              side (`origin`) think we're missing.",
            "            rejects (dict): A mapping from event_id to a 2-tuple of reason",
            "              string and a proof (or None) of why the event was rejected.",
            "              The keys of this dict give the list of events the `origin` has",
            "              rejected.",
            "",
            "        Args:",
            "            origin (str)",
            "            content (dict)",
            "            event_id (str)",
            "",
            "        Returns:",
            "            Deferred: Results in `dict` with the same format as `content`",
            "        \"\"\"",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            room_version = yield self.store.get_room_version(room_id)",
            "            format_ver = room_version_to_event_format(room_version)",
            "",
            "            auth_chain = [",
            "                event_from_pdu_json(e, format_ver) for e in content[\"auth_chain\"]",
            "            ]",
            "",
            "            signed_auth = yield self._check_sigs_and_hash_and_fetch(",
            "                origin, auth_chain, outlier=True, room_version=room_version",
            "            )",
            "",
            "            ret = yield self.handler.on_query_auth(",
            "                origin,",
            "                event_id,",
            "                room_id,",
            "                signed_auth,",
            "                content.get(\"rejects\", []),",
            "                content.get(\"missing\", []),",
            "            )",
            "",
            "            time_now = self._clock.time_msec()",
            "            send_content = {",
            "                \"auth_chain\": [e.get_pdu_json(time_now) for e in ret[\"auth_chain\"]],",
            "                \"rejects\": ret.get(\"rejects\", []),",
            "                \"missing\": ret.get(\"missing\", []),",
            "            }",
            "",
            "        return 200, send_content",
            "",
            "    @log_function",
            "    def on_query_client_keys(self, origin, content):",
            "        return self.on_query_request(\"client_keys\", content)",
            "",
            "    def on_query_user_devices(self, origin, user_id):",
            "        return self.on_query_request(\"user_devices\", user_id)",
            "",
            "    @trace",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_claim_client_keys(self, origin, content):",
            "        query = []",
            "        for user_id, device_keys in content.get(\"one_time_keys\", {}).items():",
            "            for device_id, algorithm in device_keys.items():",
            "                query.append((user_id, device_id, algorithm))",
            "",
            "        log_kv({\"message\": \"Claiming one time keys.\", \"user, device pairs\": query})",
            "        results = yield self.store.claim_e2e_one_time_keys(query)",
            "",
            "        json_result = {}",
            "        for user_id, device_keys in results.items():",
            "            for device_id, keys in device_keys.items():",
            "                for key_id, json_bytes in keys.items():",
            "                    json_result.setdefault(user_id, {})[device_id] = {",
            "                        key_id: json.loads(json_bytes)",
            "                    }",
            "",
            "        logger.info(",
            "            \"Claimed one-time-keys: %s\",",
            "            \",\".join(",
            "                (",
            "                    \"%s for %s:%s\" % (key_id, user_id, device_id)",
            "                    for user_id, user_keys in iteritems(json_result)",
            "                    for device_id, device_keys in iteritems(user_keys)",
            "                    for key_id, _ in iteritems(device_keys)",
            "                )",
            "            ),",
            "        )",
            "",
            "        return {\"one_time_keys\": json_result}",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_get_missing_events(",
            "        self, origin, room_id, earliest_events, latest_events, limit",
            "    ):",
            "        with (yield self._server_linearizer.queue((origin, room_id))):",
            "            origin_host, _ = parse_server_name(origin)",
            "            yield self.check_server_matches_acl(origin_host, room_id)",
            "",
            "            logger.info(",
            "                \"on_get_missing_events: earliest_events: %r, latest_events: %r,\"",
            "                \" limit: %d\",",
            "                earliest_events,",
            "                latest_events,",
            "                limit,",
            "            )",
            "",
            "            missing_events = yield self.handler.on_get_missing_events(",
            "                origin, room_id, earliest_events, latest_events, limit",
            "            )",
            "",
            "            if len(missing_events) < 5:",
            "                logger.info(",
            "                    \"Returning %d events: %r\", len(missing_events), missing_events",
            "                )",
            "            else:",
            "                logger.info(\"Returning %d events\", len(missing_events))",
            "",
            "            time_now = self._clock.time_msec()",
            "",
            "        return {\"events\": [ev.get_pdu_json(time_now) for ev in missing_events]}",
            "",
            "    @log_function",
            "    def on_openid_userinfo(self, token):",
            "        ts_now_ms = self._clock.time_msec()",
            "        return self.store.get_user_id_for_open_id_token(token, ts_now_ms)",
            "",
            "    def _transaction_from_pdus(self, pdu_list):",
            "        \"\"\"Returns a new Transaction containing the given PDUs suitable for",
            "        transmission.",
            "        \"\"\"",
            "        time_now = self._clock.time_msec()",
            "        pdus = [p.get_pdu_json(time_now) for p in pdu_list]",
            "        return Transaction(",
            "            origin=self.server_name,",
            "            pdus=pdus,",
            "            origin_server_ts=int(time_now),",
            "            destination=None,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_received_pdu(self, origin, pdu):",
            "        \"\"\" Process a PDU received in a federation /send/ transaction.",
            "",
            "        If the event is invalid, then this method throws a FederationError.",
            "        (The error will then be logged and sent back to the sender (which",
            "        probably won't do anything with it), and other events in the",
            "        transaction will be processed as normal).",
            "",
            "        It is likely that we'll then receive other events which refer to",
            "        this rejected_event in their prev_events, etc.  When that happens,",
            "        we'll attempt to fetch the rejected event again, which will presumably",
            "        fail, so those second-generation events will also get rejected.",
            "",
            "        Eventually, we get to the point where there are more than 10 events",
            "        between any new events and the original rejected event. Since we",
            "        only try to backfill 10 events deep on received pdu, we then accept the",
            "        new event, possibly introducing a discontinuity in the DAG, with new",
            "        forward extremities, so normal service is approximately returned,",
            "        until we try to backfill across the discontinuity.",
            "",
            "        Args:",
            "            origin (str): server which sent the pdu",
            "            pdu (FrozenEvent): received pdu",
            "",
            "        Returns (Deferred): completes with None",
            "",
            "        Raises: FederationError if the signatures / hash do not match, or",
            "            if the event was unacceptable for any other reason (eg, too large,",
            "            too many prev_events, couldn't find the prev_events)",
            "        \"\"\"",
            "        # check that it's actually being sent from a valid destination to",
            "        # workaround bug #1753 in 0.18.5 and 0.18.6",
            "        if origin != get_domain_from_id(pdu.sender):",
            "            # We continue to accept join events from any server; this is",
            "            # necessary for the federation join dance to work correctly.",
            "            # (When we join over federation, the \"helper\" server is",
            "            # responsible for sending out the join event, rather than the",
            "            # origin. See bug #1893. This is also true for some third party",
            "            # invites).",
            "            if not (",
            "                pdu.type == \"m.room.member\"",
            "                and pdu.content",
            "                and pdu.content.get(\"membership\", None)",
            "                in (Membership.JOIN, Membership.INVITE)",
            "            ):",
            "                logger.info(",
            "                    \"Discarding PDU %s from invalid origin %s\", pdu.event_id, origin",
            "                )",
            "                return",
            "            else:",
            "                logger.info(\"Accepting join PDU %s from %s\", pdu.event_id, origin)",
            "",
            "        # We've already checked that we know the room version by this point",
            "        room_version = yield self.store.get_room_version(pdu.room_id)",
            "",
            "        # Check signature.",
            "        try:",
            "            pdu = yield self._check_sigs_and_hash(room_version, pdu)",
            "        except SynapseError as e:",
            "            raise FederationError(\"ERROR\", e.code, e.msg, affected=pdu.event_id)",
            "",
            "        yield self.handler.on_receive_pdu(origin, pdu, sent_to_us_directly=True)",
            "",
            "    def __str__(self):",
            "        return \"<ReplicationLayer(%s)>\" % self.server_name",
            "",
            "    @defer.inlineCallbacks",
            "    def exchange_third_party_invite(",
            "        self, sender_user_id, target_user_id, room_id, signed",
            "    ):",
            "        ret = yield self.handler.exchange_third_party_invite(",
            "            sender_user_id, target_user_id, room_id, signed",
            "        )",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def on_exchange_third_party_invite_request(self, room_id, event_dict):",
            "        ret = yield self.handler.on_exchange_third_party_invite_request(",
            "            room_id, event_dict",
            "        )",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def check_server_matches_acl(self, server_name, room_id):",
            "        \"\"\"Check if the given server is allowed by the server ACLs in the room",
            "",
            "        Args:",
            "            server_name (str): name of server, *without any port part*",
            "            room_id (str): ID of the room to check",
            "",
            "        Raises:",
            "            AuthError if the server does not match the ACL",
            "        \"\"\"",
            "        state_ids = yield self.store.get_current_state_ids(room_id)",
            "        acl_event_id = state_ids.get((EventTypes.ServerACL, \"\"))",
            "",
            "        if not acl_event_id:",
            "            return",
            "",
            "        acl_event = yield self.store.get_event(acl_event_id)",
            "        if server_matches_acl_event(server_name, acl_event):",
            "            return",
            "",
            "        raise AuthError(code=403, msg=\"Server is banned from room\")",
            "",
            "",
            "def server_matches_acl_event(server_name, acl_event):",
            "    \"\"\"Check if the given server is allowed by the ACL event",
            "",
            "    Args:",
            "        server_name (str): name of server, without any port part",
            "        acl_event (EventBase): m.room.server_acl event",
            "",
            "    Returns:",
            "        bool: True if this server is allowed by the ACLs",
            "    \"\"\"",
            "    logger.debug(\"Checking %s against acl %s\", server_name, acl_event.content)",
            "",
            "    # first of all, check if literal IPs are blocked, and if so, whether the",
            "    # server name is a literal IP",
            "    allow_ip_literals = acl_event.content.get(\"allow_ip_literals\", True)",
            "    if not isinstance(allow_ip_literals, bool):",
            "        logger.warn(\"Ignorning non-bool allow_ip_literals flag\")",
            "        allow_ip_literals = True",
            "    if not allow_ip_literals:",
            "        # check for ipv6 literals. These start with '['.",
            "        if server_name[0] == \"[\":",
            "            return False",
            "",
            "        # check for ipv4 literals. We can just lift the routine from twisted.",
            "        if isIPAddress(server_name):",
            "            return False",
            "",
            "    # next,  check the deny list",
            "    deny = acl_event.content.get(\"deny\", [])",
            "    if not isinstance(deny, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list deny ACL %s\", deny)",
            "        deny = []",
            "    for e in deny:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched deny rule %s\", server_name, e)",
            "            return False",
            "",
            "    # then the allow list.",
            "    allow = acl_event.content.get(\"allow\", [])",
            "    if not isinstance(allow, (list, tuple)):",
            "        logger.warn(\"Ignorning non-list allow ACL %s\", allow)",
            "        allow = []",
            "    for e in allow:",
            "        if _acl_entry_matches(server_name, e):",
            "            # logger.info(\"%s matched allow rule %s\", server_name, e)",
            "            return True",
            "",
            "    # everything else should be rejected.",
            "    # logger.info(\"%s fell through\", server_name)",
            "    return False",
            "",
            "",
            "def _acl_entry_matches(server_name, acl_entry):",
            "    if not isinstance(acl_entry, six.string_types):",
            "        logger.warn(",
            "            \"Ignoring non-str ACL entry '%s' (is %s)\", acl_entry, type(acl_entry)",
            "        )",
            "        return False",
            "    regex = glob_to_regex(acl_entry)",
            "    return regex.match(server_name)",
            "",
            "",
            "class FederationHandlerRegistry(object):",
            "    \"\"\"Allows classes to register themselves as handlers for a given EDU or",
            "    query type for incoming federation traffic.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.edu_handlers = {}",
            "        self.query_handlers = {}",
            "",
            "    def register_edu_handler(self, edu_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation EDU of the given type.",
            "",
            "        Args:",
            "            edu_type (str): The type of the incoming EDU to register handler for",
            "            handler (Callable[[str, dict]]): A callable invoked on incoming EDU",
            "                of the given type. The arguments are the origin server name and",
            "                the EDU contents.",
            "        \"\"\"",
            "        if edu_type in self.edu_handlers:",
            "            raise KeyError(\"Already have an EDU handler for %s\" % (edu_type,))",
            "",
            "        logger.info(\"Registering federation EDU handler for %r\", edu_type)",
            "",
            "        self.edu_handlers[edu_type] = handler",
            "",
            "    def register_query_handler(self, query_type, handler):",
            "        \"\"\"Sets the handler callable that will be used to handle an incoming",
            "        federation query of the given type.",
            "",
            "        Args:",
            "            query_type (str): Category name of the query, which should match",
            "                the string used by make_query.",
            "            handler (Callable[[dict], Deferred[dict]]): Invoked to handle",
            "                incoming queries of this type. The return will be yielded",
            "                on and the result used as the response to the query request.",
            "        \"\"\"",
            "        if query_type in self.query_handlers:",
            "            raise KeyError(\"Already have a Query handler for %s\" % (query_type,))",
            "",
            "        logger.info(\"Registering federation query handler for %r\", query_type)",
            "",
            "        self.query_handlers[query_type] = handler",
            "",
            "    @defer.inlineCallbacks",
            "    def on_edu(self, edu_type, origin, content):",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for EDU type %s\", edu_type)",
            "",
            "        with start_active_span_from_edu(content, \"handle_edu\"):",
            "            try:",
            "                yield handler(origin, content)",
            "            except SynapseError as e:",
            "                logger.info(\"Failed to handle edu %r: %r\", edu_type, e)",
            "            except Exception:",
            "                logger.exception(\"Failed to handle edu %r\", edu_type)",
            "",
            "    def on_query(self, query_type, args):",
            "        handler = self.query_handlers.get(query_type)",
            "        if not handler:",
            "            logger.warn(\"No handler registered for query type %s\", query_type)",
            "            raise NotFoundError(\"No handler for Query type '%s'\" % (query_type,))",
            "",
            "        return handler(args)",
            "",
            "",
            "class ReplicationFederationHandlerRegistry(FederationHandlerRegistry):",
            "    \"\"\"A FederationHandlerRegistry for worker processes.",
            "",
            "    When receiving EDU or queries it will check if an appropriate handler has",
            "    been registered on the worker, if there isn't one then it calls off to the",
            "    master process.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "        self.clock = hs.get_clock()",
            "",
            "        self._get_query_client = ReplicationGetQueryRestServlet.make_client(hs)",
            "        self._send_edu = ReplicationFederationSendEduRestServlet.make_client(hs)",
            "",
            "        super(ReplicationFederationHandlerRegistry, self).__init__()",
            "",
            "    def on_edu(self, edu_type, origin, content):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        if not self.config.use_presence and edu_type == \"m.presence\":",
            "            return",
            "",
            "        handler = self.edu_handlers.get(edu_type)",
            "        if handler:",
            "            return super(ReplicationFederationHandlerRegistry, self).on_edu(",
            "                edu_type, origin, content",
            "            )",
            "",
            "        return self._send_edu(edu_type=edu_type, origin=origin, content=content)",
            "",
            "    def on_query(self, query_type, args):",
            "        \"\"\"Overrides FederationHandlerRegistry",
            "        \"\"\"",
            "        handler = self.query_handlers.get(query_type)",
            "        if handler:",
            "            return handler(args)",
            "",
            "        return self._get_query_client(query_type=query_type, args=args)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.jinja2.filters"
        ]
    },
    "synapse/handlers/federation.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1222,
                "afterPatchRowNumber": 1222,
                "PatchRowcode": "         Returns:"
            },
            "1": {
                "beforePatchRowNumber": 1223,
                "afterPatchRowNumber": 1223,
                "PatchRowcode": "             Deferred[FrozenEvent]"
            },
            "2": {
                "beforePatchRowNumber": 1224,
                "afterPatchRowNumber": 1224,
                "PatchRowcode": "         \"\"\""
            },
            "3": {
                "beforePatchRowNumber": 1225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "4": {
                "beforePatchRowNumber": 1226,
                "afterPatchRowNumber": 1225,
                "PatchRowcode": "         if get_domain_from_id(user_id) != origin:"
            },
            "5": {
                "beforePatchRowNumber": 1227,
                "afterPatchRowNumber": 1226,
                "PatchRowcode": "             logger.info("
            },
            "6": {
                "beforePatchRowNumber": 1228,
                "afterPatchRowNumber": 1227,
                "PatchRowcode": "                 \"Got /make_join request for user %r from different origin %s, ignoring\","
            },
            "7": {
                "beforePatchRowNumber": 1280,
                "afterPatchRowNumber": 1279,
                "PatchRowcode": "         event = pdu"
            },
            "8": {
                "beforePatchRowNumber": 1281,
                "afterPatchRowNumber": 1280,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 1282,
                "afterPatchRowNumber": 1281,
                "PatchRowcode": "         logger.debug("
            },
            "10": {
                "beforePatchRowNumber": 1283,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"on_send_join_request: Got event: %s, signatures: %s\","
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1282,
                "PatchRowcode": "+            \"on_send_join_request from %s: Got event: %s, signatures: %s\","
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1283,
                "PatchRowcode": "+            origin,"
            },
            "13": {
                "beforePatchRowNumber": 1284,
                "afterPatchRowNumber": 1284,
                "PatchRowcode": "             event.event_id,"
            },
            "14": {
                "beforePatchRowNumber": 1285,
                "afterPatchRowNumber": 1285,
                "PatchRowcode": "             event.signatures,"
            },
            "15": {
                "beforePatchRowNumber": 1286,
                "afterPatchRowNumber": 1286,
                "PatchRowcode": "         )"
            },
            "16": {
                "beforePatchRowNumber": 1287,
                "afterPatchRowNumber": 1287,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1288,
                "PatchRowcode": "+        if get_domain_from_id(event.sender) != origin:"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1289,
                "PatchRowcode": "+            logger.info("
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1290,
                "PatchRowcode": "+                \"Got /send_join request for user %r from different origin %s\","
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1291,
                "PatchRowcode": "+                event.sender,"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1292,
                "PatchRowcode": "+                origin,"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1293,
                "PatchRowcode": "+            )"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1294,
                "PatchRowcode": "+            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1295,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 1288,
                "afterPatchRowNumber": 1296,
                "PatchRowcode": "         event.internal_metadata.outlier = False"
            },
            "26": {
                "beforePatchRowNumber": 1289,
                "afterPatchRowNumber": 1297,
                "PatchRowcode": "         # Send this event on behalf of the origin server."
            },
            "27": {
                "beforePatchRowNumber": 1290,
                "afterPatchRowNumber": 1298,
                "PatchRowcode": "         #"
            },
            "28": {
                "beforePatchRowNumber": 1503,
                "afterPatchRowNumber": 1511,
                "PatchRowcode": "             event.signatures,"
            },
            "29": {
                "beforePatchRowNumber": 1504,
                "afterPatchRowNumber": 1512,
                "PatchRowcode": "         )"
            },
            "30": {
                "beforePatchRowNumber": 1505,
                "afterPatchRowNumber": 1513,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1514,
                "PatchRowcode": "+        if get_domain_from_id(event.sender) != origin:"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1515,
                "PatchRowcode": "+            logger.info("
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1516,
                "PatchRowcode": "+                \"Got /send_leave request for user %r from different origin %s\","
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1517,
                "PatchRowcode": "+                event.sender,"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1518,
                "PatchRowcode": "+                origin,"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1519,
                "PatchRowcode": "+            )"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1520,
                "PatchRowcode": "+            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1521,
                "PatchRowcode": "+"
            },
            "39": {
                "beforePatchRowNumber": 1506,
                "afterPatchRowNumber": 1522,
                "PatchRowcode": "         event.internal_metadata.outlier = False"
            },
            "40": {
                "beforePatchRowNumber": 1507,
                "afterPatchRowNumber": 1523,
                "PatchRowcode": " "
            },
            "41": {
                "beforePatchRowNumber": 1508,
                "afterPatchRowNumber": 1524,
                "PatchRowcode": "         context = yield self._handle_new_event(origin, event)"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "# Copyright 2017-2018 New Vector Ltd",
            "# Copyright 2019 The Matrix.org Foundation C.I.C.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Contains handlers for federation events.\"\"\"",
            "",
            "import itertools",
            "import logging",
            "",
            "import six",
            "from six import iteritems, itervalues",
            "from six.moves import http_client, zip",
            "",
            "from signedjson.key import decode_verify_key_bytes",
            "from signedjson.sign import verify_signed_json",
            "from unpaddedbase64 import decode_base64",
            "",
            "from twisted.internet import defer",
            "",
            "from synapse import event_auth",
            "from synapse.api.constants import EventTypes, Membership, RejectedReason",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    CodeMessageException,",
            "    Codes,",
            "    FederationDeniedError,",
            "    FederationError,",
            "    RequestSendFailed,",
            "    StoreError,",
            "    SynapseError,",
            ")",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS, RoomVersions",
            "from synapse.crypto.event_signing import compute_event_signature",
            "from synapse.event_auth import auth_types_for_event",
            "from synapse.events.validator import EventValidator",
            "from synapse.logging.context import (",
            "    make_deferred_yieldable,",
            "    nested_logging_context,",
            "    preserve_fn,",
            "    run_in_background,",
            ")",
            "from synapse.logging.utils import log_function",
            "from synapse.replication.http.federation import (",
            "    ReplicationCleanRoomRestServlet,",
            "    ReplicationFederationSendEventsRestServlet,",
            ")",
            "from synapse.replication.http.membership import ReplicationUserJoinedLeftRoomRestServlet",
            "from synapse.state import StateResolutionStore, resolve_events_with_store",
            "from synapse.types import UserID, get_domain_from_id",
            "from synapse.util import unwrapFirstError",
            "from synapse.util.async_helpers import Linearizer",
            "from synapse.util.distributor import user_joined_room",
            "from synapse.util.retryutils import NotRetryingDestination",
            "from synapse.visibility import filter_events_for_server",
            "",
            "from ._base import BaseHandler",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def shortstr(iterable, maxitems=5):",
            "    \"\"\"If iterable has maxitems or fewer, return the stringification of a list",
            "    containing those items.",
            "",
            "    Otherwise, return the stringification of a a list with the first maxitems items,",
            "    followed by \"...\".",
            "",
            "    Args:",
            "        iterable (Iterable): iterable to truncate",
            "        maxitems (int): number of items to return before truncating",
            "",
            "    Returns:",
            "        unicode",
            "    \"\"\"",
            "",
            "    items = list(itertools.islice(iterable, maxitems + 1))",
            "    if len(items) <= maxitems:",
            "        return str(items)",
            "    return \"[\" + \", \".join(repr(r) for r in items[:maxitems]) + \", ...]\"",
            "",
            "",
            "class FederationHandler(BaseHandler):",
            "    \"\"\"Handles events that originated from federation.",
            "        Responsible for:",
            "        a) handling received Pdus before handing them on as Events to the rest",
            "        of the home server (including auth and state conflict resoultion)",
            "        b) converting events that were produced by local clients that may need",
            "        to be sent to remote home servers.",
            "        c) doing the necessary dances to invite remote users and join remote",
            "        rooms.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        super(FederationHandler, self).__init__(hs)",
            "",
            "        self.hs = hs",
            "",
            "        self.store = hs.get_datastore()",
            "        self.federation_client = hs.get_federation_client()",
            "        self.state_handler = hs.get_state_handler()",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.action_generator = hs.get_action_generator()",
            "        self.is_mine_id = hs.is_mine_id",
            "        self.pusher_pool = hs.get_pusherpool()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.event_creation_handler = hs.get_event_creation_handler()",
            "        self._server_notices_mxid = hs.config.server_notices_mxid",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "",
            "        self._send_events_to_master = ReplicationFederationSendEventsRestServlet.make_client(",
            "            hs",
            "        )",
            "        self._notify_user_membership_change = ReplicationUserJoinedLeftRoomRestServlet.make_client(",
            "            hs",
            "        )",
            "        self._clean_room_for_join_client = ReplicationCleanRoomRestServlet.make_client(",
            "            hs",
            "        )",
            "",
            "        # When joining a room we need to queue any events for that room up",
            "        self.room_queues = {}",
            "        self._room_pdu_linearizer = Linearizer(\"fed_room_pdu\")",
            "",
            "        self.third_party_event_rules = hs.get_third_party_event_rules()",
            "",
            "    @defer.inlineCallbacks",
            "    def on_receive_pdu(self, origin, pdu, sent_to_us_directly=False):",
            "        \"\"\" Process a PDU received via a federation /send/ transaction, or",
            "        via backfill of missing prev_events",
            "",
            "        Args:",
            "            origin (str): server which initiated the /send/ transaction. Will",
            "                be used to fetch missing events or state.",
            "            pdu (FrozenEvent): received PDU",
            "            sent_to_us_directly (bool): True if this event was pushed to us; False if",
            "                we pulled it as the result of a missing prev_event.",
            "",
            "        Returns (Deferred): completes with None",
            "        \"\"\"",
            "",
            "        room_id = pdu.room_id",
            "        event_id = pdu.event_id",
            "",
            "        logger.info(\"[%s %s] handling received PDU: %s\", room_id, event_id, pdu)",
            "",
            "        # We reprocess pdus when we have seen them only as outliers",
            "        existing = yield self.store.get_event(",
            "            event_id, allow_none=True, allow_rejected=True",
            "        )",
            "",
            "        # FIXME: Currently we fetch an event again when we already have it",
            "        # if it has been marked as an outlier.",
            "",
            "        already_seen = existing and (",
            "            not existing.internal_metadata.is_outlier()",
            "            or pdu.internal_metadata.is_outlier()",
            "        )",
            "        if already_seen:",
            "            logger.debug(\"[%s %s]: Already seen pdu\", room_id, event_id)",
            "            return",
            "",
            "        # do some initial sanity-checking of the event. In particular, make",
            "        # sure it doesn't have hundreds of prev_events or auth_events, which",
            "        # could cause a huge state resolution or cascade of event fetches.",
            "        try:",
            "            self._sanity_check_event(pdu)",
            "        except SynapseError as err:",
            "            logger.warn(",
            "                \"[%s %s] Received event failed sanity checks\", room_id, event_id",
            "            )",
            "            raise FederationError(\"ERROR\", err.code, err.msg, affected=pdu.event_id)",
            "",
            "        # If we are currently in the process of joining this room, then we",
            "        # queue up events for later processing.",
            "        if room_id in self.room_queues:",
            "            logger.info(",
            "                \"[%s %s] Queuing PDU from %s for now: join in progress\",",
            "                room_id,",
            "                event_id,",
            "                origin,",
            "            )",
            "            self.room_queues[room_id].append((pdu, origin))",
            "            return",
            "",
            "        # If we're not in the room just ditch the event entirely. This is",
            "        # probably an old server that has come back and thinks we're still in",
            "        # the room (or we've been rejoined to the room by a state reset).",
            "        #",
            "        # Note that if we were never in the room then we would have already",
            "        # dropped the event, since we wouldn't know the room version.",
            "        is_in_room = yield self.auth.check_host_in_room(room_id, self.server_name)",
            "        if not is_in_room:",
            "            logger.info(",
            "                \"[%s %s] Ignoring PDU from %s as we're not in the room\",",
            "                room_id,",
            "                event_id,",
            "                origin,",
            "            )",
            "            return None",
            "",
            "        state = None",
            "        auth_chain = []",
            "",
            "        # Get missing pdus if necessary.",
            "        if not pdu.internal_metadata.is_outlier():",
            "            # We only backfill backwards to the min depth.",
            "            min_depth = yield self.get_min_depth_for_context(pdu.room_id)",
            "",
            "            logger.debug(\"[%s %s] min_depth: %d\", room_id, event_id, min_depth)",
            "",
            "            prevs = set(pdu.prev_event_ids())",
            "            seen = yield self.store.have_seen_events(prevs)",
            "",
            "            if min_depth and pdu.depth < min_depth:",
            "                # This is so that we don't notify the user about this",
            "                # message, to work around the fact that some events will",
            "                # reference really really old events we really don't want to",
            "                # send to the clients.",
            "                pdu.internal_metadata.outlier = True",
            "            elif min_depth and pdu.depth > min_depth:",
            "                missing_prevs = prevs - seen",
            "                if sent_to_us_directly and missing_prevs:",
            "                    # If we're missing stuff, ensure we only fetch stuff one",
            "                    # at a time.",
            "                    logger.info(",
            "                        \"[%s %s] Acquiring room lock to fetch %d missing prev_events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(missing_prevs),",
            "                        shortstr(missing_prevs),",
            "                    )",
            "                    with (yield self._room_pdu_linearizer.queue(pdu.room_id)):",
            "                        logger.info(",
            "                            \"[%s %s] Acquired room lock to fetch %d missing prev_events\",",
            "                            room_id,",
            "                            event_id,",
            "                            len(missing_prevs),",
            "                        )",
            "",
            "                        yield self._get_missing_events_for_pdu(",
            "                            origin, pdu, prevs, min_depth",
            "                        )",
            "",
            "                        # Update the set of things we've seen after trying to",
            "                        # fetch the missing stuff",
            "                        seen = yield self.store.have_seen_events(prevs)",
            "",
            "                        if not prevs - seen:",
            "                            logger.info(",
            "                                \"[%s %s] Found all missing prev_events\",",
            "                                room_id,",
            "                                event_id,",
            "                            )",
            "                elif missing_prevs:",
            "                    logger.info(",
            "                        \"[%s %s] Not recursively fetching %d missing prev_events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(missing_prevs),",
            "                        shortstr(missing_prevs),",
            "                    )",
            "",
            "            if prevs - seen:",
            "                # We've still not been able to get all of the prev_events for this event.",
            "                #",
            "                # In this case, we need to fall back to asking another server in the",
            "                # federation for the state at this event. That's ok provided we then",
            "                # resolve the state against other bits of the DAG before using it (which",
            "                # will ensure that you can't just take over a room by sending an event,",
            "                # withholding its prev_events, and declaring yourself to be an admin in",
            "                # the subsequent state request).",
            "                #",
            "                # Now, if we're pulling this event as a missing prev_event, then clearly",
            "                # this event is not going to become the only forward-extremity and we are",
            "                # guaranteed to resolve its state against our existing forward",
            "                # extremities, so that should be fine.",
            "                #",
            "                # On the other hand, if this event was pushed to us, it is possible for",
            "                # it to become the only forward-extremity in the room, and we would then",
            "                # trust its state to be the state for the whole room. This is very bad.",
            "                # Further, if the event was pushed to us, there is no excuse for us not to",
            "                # have all the prev_events. We therefore reject any such events.",
            "                #",
            "                # XXX this really feels like it could/should be merged with the above,",
            "                # but there is an interaction with min_depth that I'm not really",
            "                # following.",
            "",
            "                if sent_to_us_directly:",
            "                    logger.warn(",
            "                        \"[%s %s] Rejecting: failed to fetch %d prev events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(prevs - seen),",
            "                        shortstr(prevs - seen),",
            "                    )",
            "                    raise FederationError(",
            "                        \"ERROR\",",
            "                        403,",
            "                        (",
            "                            \"Your server isn't divulging details about prev_events \"",
            "                            \"referenced in this event.\"",
            "                        ),",
            "                        affected=pdu.event_id,",
            "                    )",
            "",
            "                # Calculate the state after each of the previous events, and",
            "                # resolve them to find the correct state at the current event.",
            "                auth_chains = set()",
            "                event_map = {event_id: pdu}",
            "                try:",
            "                    # Get the state of the events we know about",
            "                    ours = yield self.store.get_state_groups_ids(room_id, seen)",
            "",
            "                    # state_maps is a list of mappings from (type, state_key) to event_id",
            "                    state_maps = list(",
            "                        ours.values()",
            "                    )  # type: list[dict[tuple[str, str], str]]",
            "",
            "                    # we don't need this any more, let's delete it.",
            "                    del ours",
            "",
            "                    # Ask the remote server for the states we don't",
            "                    # know about",
            "                    for p in prevs - seen:",
            "                        logger.info(",
            "                            \"[%s %s] Requesting state at missing prev_event %s\",",
            "                            room_id,",
            "                            event_id,",
            "                            p,",
            "                        )",
            "",
            "                        room_version = yield self.store.get_room_version(room_id)",
            "",
            "                        with nested_logging_context(p):",
            "                            # note that if any of the missing prevs share missing state or",
            "                            # auth events, the requests to fetch those events are deduped",
            "                            # by the get_pdu_cache in federation_client.",
            "                            remote_state, got_auth_chain = (",
            "                                yield self.federation_client.get_state_for_room(",
            "                                    origin, room_id, p",
            "                                )",
            "                            )",
            "",
            "                            # we want the state *after* p; get_state_for_room returns the",
            "                            # state *before* p.",
            "                            remote_event = yield self.federation_client.get_pdu(",
            "                                [origin], p, room_version, outlier=True",
            "                            )",
            "",
            "                            if remote_event is None:",
            "                                raise Exception(",
            "                                    \"Unable to get missing prev_event %s\" % (p,)",
            "                                )",
            "",
            "                            if remote_event.is_state():",
            "                                remote_state.append(remote_event)",
            "",
            "                            # XXX hrm I'm not convinced that duplicate events will compare",
            "                            # for equality, so I'm not sure this does what the author",
            "                            # hoped.",
            "                            auth_chains.update(got_auth_chain)",
            "",
            "                            remote_state_map = {",
            "                                (x.type, x.state_key): x.event_id for x in remote_state",
            "                            }",
            "                            state_maps.append(remote_state_map)",
            "",
            "                            for x in remote_state:",
            "                                event_map[x.event_id] = x",
            "",
            "                    state_map = yield resolve_events_with_store(",
            "                        room_version,",
            "                        state_maps,",
            "                        event_map,",
            "                        state_res_store=StateResolutionStore(self.store),",
            "                    )",
            "",
            "                    # We need to give _process_received_pdu the actual state events",
            "                    # rather than event ids, so generate that now.",
            "",
            "                    # First though we need to fetch all the events that are in",
            "                    # state_map, so we can build up the state below.",
            "                    evs = yield self.store.get_events(",
            "                        list(state_map.values()),",
            "                        get_prev_content=False,",
            "                        check_redacted=False,",
            "                    )",
            "                    event_map.update(evs)",
            "",
            "                    state = [event_map[e] for e in six.itervalues(state_map)]",
            "                    auth_chain = list(auth_chains)",
            "                except Exception:",
            "                    logger.warn(",
            "                        \"[%s %s] Error attempting to resolve state at missing \"",
            "                        \"prev_events\",",
            "                        room_id,",
            "                        event_id,",
            "                        exc_info=True,",
            "                    )",
            "                    raise FederationError(",
            "                        \"ERROR\",",
            "                        403,",
            "                        \"We can't get valid state history.\",",
            "                        affected=event_id,",
            "                    )",
            "",
            "        yield self._process_received_pdu(",
            "            origin, pdu, state=state, auth_chain=auth_chain",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _get_missing_events_for_pdu(self, origin, pdu, prevs, min_depth):",
            "        \"\"\"",
            "        Args:",
            "            origin (str): Origin of the pdu. Will be called to get the missing events",
            "            pdu: received pdu",
            "            prevs (set(str)): List of event ids which we are missing",
            "            min_depth (int): Minimum depth of events to return.",
            "        \"\"\"",
            "",
            "        room_id = pdu.room_id",
            "        event_id = pdu.event_id",
            "",
            "        seen = yield self.store.have_seen_events(prevs)",
            "",
            "        if not prevs - seen:",
            "            return",
            "",
            "        latest = yield self.store.get_latest_event_ids_in_room(room_id)",
            "",
            "        # We add the prev events that we have seen to the latest",
            "        # list to ensure the remote server doesn't give them to us",
            "        latest = set(latest)",
            "        latest |= seen",
            "",
            "        logger.info(",
            "            \"[%s %s]: Requesting missing events between %s and %s\",",
            "            room_id,",
            "            event_id,",
            "            shortstr(latest),",
            "            event_id,",
            "        )",
            "",
            "        # XXX: we set timeout to 10s to help workaround",
            "        # https://github.com/matrix-org/synapse/issues/1733.",
            "        # The reason is to avoid holding the linearizer lock",
            "        # whilst processing inbound /send transactions, causing",
            "        # FDs to stack up and block other inbound transactions",
            "        # which empirically can currently take up to 30 minutes.",
            "        #",
            "        # N.B. this explicitly disables retry attempts.",
            "        #",
            "        # N.B. this also increases our chances of falling back to",
            "        # fetching fresh state for the room if the missing event",
            "        # can't be found, which slightly reduces our security.",
            "        # it may also increase our DAG extremity count for the room,",
            "        # causing additional state resolution?  See #1760.",
            "        # However, fetching state doesn't hold the linearizer lock",
            "        # apparently.",
            "        #",
            "        # see https://github.com/matrix-org/synapse/pull/1744",
            "        #",
            "        # ----",
            "        #",
            "        # Update richvdh 2018/09/18: There are a number of problems with timing this",
            "        # request out agressively on the client side:",
            "        #",
            "        # - it plays badly with the server-side rate-limiter, which starts tarpitting you",
            "        #   if you send too many requests at once, so you end up with the server carefully",
            "        #   working through the backlog of your requests, which you have already timed",
            "        #   out.",
            "        #",
            "        # - for this request in particular, we now (as of",
            "        #   https://github.com/matrix-org/synapse/pull/3456) reject any PDUs where the",
            "        #   server can't produce a plausible-looking set of prev_events - so we becone",
            "        #   much more likely to reject the event.",
            "        #",
            "        # - contrary to what it says above, we do *not* fall back to fetching fresh state",
            "        #   for the room if get_missing_events times out. Rather, we give up processing",
            "        #   the PDU whose prevs we are missing, which then makes it much more likely that",
            "        #   we'll end up back here for the *next* PDU in the list, which exacerbates the",
            "        #   problem.",
            "        #",
            "        # - the agressive 10s timeout was introduced to deal with incoming federation",
            "        #   requests taking 8 hours to process. It's not entirely clear why that was going",
            "        #   on; certainly there were other issues causing traffic storms which are now",
            "        #   resolved, and I think in any case we may be more sensible about our locking",
            "        #   now. We're *certainly* more sensible about our logging.",
            "        #",
            "        # All that said: Let's try increasing the timout to 60s and see what happens.",
            "",
            "        try:",
            "            missing_events = yield self.federation_client.get_missing_events(",
            "                origin,",
            "                room_id,",
            "                earliest_events_ids=list(latest),",
            "                latest_events=[pdu],",
            "                limit=10,",
            "                min_depth=min_depth,",
            "                timeout=60000,",
            "            )",
            "        except RequestSendFailed as e:",
            "            # We failed to get the missing events, but since we need to handle",
            "            # the case of `get_missing_events` not returning the necessary",
            "            # events anyway, it is safe to simply log the error and continue.",
            "            logger.warn(\"[%s %s]: Failed to get prev_events: %s\", room_id, event_id, e)",
            "            return",
            "",
            "        logger.info(",
            "            \"[%s %s]: Got %d prev_events: %s\",",
            "            room_id,",
            "            event_id,",
            "            len(missing_events),",
            "            shortstr(missing_events),",
            "        )",
            "",
            "        # We want to sort these by depth so we process them and",
            "        # tell clients about them in order.",
            "        missing_events.sort(key=lambda x: x.depth)",
            "",
            "        for ev in missing_events:",
            "            logger.info(",
            "                \"[%s %s] Handling received prev_event %s\",",
            "                room_id,",
            "                event_id,",
            "                ev.event_id,",
            "            )",
            "            with nested_logging_context(ev.event_id):",
            "                try:",
            "                    yield self.on_receive_pdu(origin, ev, sent_to_us_directly=False)",
            "                except FederationError as e:",
            "                    if e.code == 403:",
            "                        logger.warn(",
            "                            \"[%s %s] Received prev_event %s failed history check.\",",
            "                            room_id,",
            "                            event_id,",
            "                            ev.event_id,",
            "                        )",
            "                    else:",
            "                        raise",
            "",
            "    @defer.inlineCallbacks",
            "    def _process_received_pdu(self, origin, event, state, auth_chain):",
            "        \"\"\" Called when we have a new pdu. We need to do auth checks and put it",
            "        through the StateHandler.",
            "        \"\"\"",
            "        room_id = event.room_id",
            "        event_id = event.event_id",
            "",
            "        logger.debug(\"[%s %s] Processing event: %s\", room_id, event_id, event)",
            "",
            "        event_ids = set()",
            "        if state:",
            "            event_ids |= {e.event_id for e in state}",
            "        if auth_chain:",
            "            event_ids |= {e.event_id for e in auth_chain}",
            "",
            "        seen_ids = yield self.store.have_seen_events(event_ids)",
            "",
            "        if state and auth_chain is not None:",
            "            # If we have any state or auth_chain given to us by the replication",
            "            # layer, then we should handle them (if we haven't before.)",
            "",
            "            event_infos = []",
            "",
            "            for e in itertools.chain(auth_chain, state):",
            "                if e.event_id in seen_ids:",
            "                    continue",
            "                e.internal_metadata.outlier = True",
            "                auth_ids = e.auth_event_ids()",
            "                auth = {",
            "                    (e.type, e.state_key): e",
            "                    for e in auth_chain",
            "                    if e.event_id in auth_ids or e.type == EventTypes.Create",
            "                }",
            "                event_infos.append({\"event\": e, \"auth_events\": auth})",
            "                seen_ids.add(e.event_id)",
            "",
            "            logger.info(",
            "                \"[%s %s] persisting newly-received auth/state events %s\",",
            "                room_id,",
            "                event_id,",
            "                [e[\"event\"].event_id for e in event_infos],",
            "            )",
            "            yield self._handle_new_events(origin, event_infos)",
            "",
            "        try:",
            "            context = yield self._handle_new_event(origin, event, state=state)",
            "        except AuthError as e:",
            "            raise FederationError(\"ERROR\", e.code, e.msg, affected=event.event_id)",
            "",
            "        room = yield self.store.get_room(room_id)",
            "",
            "        if not room:",
            "            try:",
            "                yield self.store.store_room(",
            "                    room_id=room_id, room_creator_user_id=\"\", is_public=False",
            "                )",
            "            except StoreError:",
            "                logger.exception(\"Failed to store room.\")",
            "",
            "        if event.type == EventTypes.Member:",
            "            if event.membership == Membership.JOIN:",
            "                # Only fire user_joined_room if the user has acutally",
            "                # joined the room. Don't bother if the user is just",
            "                # changing their profile info.",
            "                newly_joined = True",
            "",
            "                prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "",
            "                prev_state_id = prev_state_ids.get((event.type, event.state_key))",
            "                if prev_state_id:",
            "                    prev_state = yield self.store.get_event(",
            "                        prev_state_id, allow_none=True",
            "                    )",
            "                    if prev_state and prev_state.membership == Membership.JOIN:",
            "                        newly_joined = False",
            "",
            "                if newly_joined:",
            "                    user = UserID.from_string(event.state_key)",
            "                    yield self.user_joined_room(user, room_id)",
            "",
            "    @log_function",
            "    @defer.inlineCallbacks",
            "    def backfill(self, dest, room_id, limit, extremities):",
            "        \"\"\" Trigger a backfill request to `dest` for the given `room_id`",
            "",
            "        This will attempt to get more events from the remote. If the other side",
            "        has no new events to offer, this will return an empty list.",
            "",
            "        As the events are received, we check their signatures, and also do some",
            "        sanity-checking on them. If any of the backfilled events are invalid,",
            "        this method throws a SynapseError.",
            "",
            "        TODO: make this more useful to distinguish failures of the remote",
            "        server from invalid events (there is probably no point in trying to",
            "        re-fetch invalid events from every other HS in the room.)",
            "        \"\"\"",
            "        if dest == self.server_name:",
            "            raise SynapseError(400, \"Can't backfill from self.\")",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        events = yield self.federation_client.backfill(",
            "            dest, room_id, limit=limit, extremities=extremities",
            "        )",
            "",
            "        # ideally we'd sanity check the events here for excess prev_events etc,",
            "        # but it's hard to reject events at this point without completely",
            "        # breaking backfill in the same way that it is currently broken by",
            "        # events whose signature we cannot verify (#3121).",
            "        #",
            "        # So for now we accept the events anyway. #3124 tracks this.",
            "        #",
            "        # for ev in events:",
            "        #     self._sanity_check_event(ev)",
            "",
            "        # Don't bother processing events we already have.",
            "        seen_events = yield self.store.have_events_in_timeline(",
            "            set(e.event_id for e in events)",
            "        )",
            "",
            "        events = [e for e in events if e.event_id not in seen_events]",
            "",
            "        if not events:",
            "            return []",
            "",
            "        event_map = {e.event_id: e for e in events}",
            "",
            "        event_ids = set(e.event_id for e in events)",
            "",
            "        edges = [ev.event_id for ev in events if set(ev.prev_event_ids()) - event_ids]",
            "",
            "        logger.info(\"backfill: Got %d events with %d edges\", len(events), len(edges))",
            "",
            "        # For each edge get the current state.",
            "",
            "        auth_events = {}",
            "        state_events = {}",
            "        events_to_state = {}",
            "        for e_id in edges:",
            "            state, auth = yield self.federation_client.get_state_for_room(",
            "                destination=dest, room_id=room_id, event_id=e_id",
            "            )",
            "            auth_events.update({a.event_id: a for a in auth})",
            "            auth_events.update({s.event_id: s for s in state})",
            "            state_events.update({s.event_id: s for s in state})",
            "            events_to_state[e_id] = state",
            "",
            "        required_auth = set(",
            "            a_id",
            "            for event in events",
            "            + list(state_events.values())",
            "            + list(auth_events.values())",
            "            for a_id in event.auth_event_ids()",
            "        )",
            "        auth_events.update(",
            "            {e_id: event_map[e_id] for e_id in required_auth if e_id in event_map}",
            "        )",
            "        missing_auth = required_auth - set(auth_events)",
            "        failed_to_fetch = set()",
            "",
            "        # Try and fetch any missing auth events from both DB and remote servers.",
            "        # We repeatedly do this until we stop finding new auth events.",
            "        while missing_auth - failed_to_fetch:",
            "            logger.info(\"Missing auth for backfill: %r\", missing_auth)",
            "            ret_events = yield self.store.get_events(missing_auth - failed_to_fetch)",
            "            auth_events.update(ret_events)",
            "",
            "            required_auth.update(",
            "                a_id for event in ret_events.values() for a_id in event.auth_event_ids()",
            "            )",
            "            missing_auth = required_auth - set(auth_events)",
            "",
            "            if missing_auth - failed_to_fetch:",
            "                logger.info(",
            "                    \"Fetching missing auth for backfill: %r\",",
            "                    missing_auth - failed_to_fetch,",
            "                )",
            "",
            "                results = yield make_deferred_yieldable(",
            "                    defer.gatherResults(",
            "                        [",
            "                            run_in_background(",
            "                                self.federation_client.get_pdu,",
            "                                [dest],",
            "                                event_id,",
            "                                room_version=room_version,",
            "                                outlier=True,",
            "                                timeout=10000,",
            "                            )",
            "                            for event_id in missing_auth - failed_to_fetch",
            "                        ],",
            "                        consumeErrors=True,",
            "                    )",
            "                ).addErrback(unwrapFirstError)",
            "                auth_events.update({a.event_id: a for a in results if a})",
            "                required_auth.update(",
            "                    a_id",
            "                    for event in results",
            "                    if event",
            "                    for a_id in event.auth_event_ids()",
            "                )",
            "                missing_auth = required_auth - set(auth_events)",
            "",
            "                failed_to_fetch = missing_auth - set(auth_events)",
            "",
            "        seen_events = yield self.store.have_seen_events(",
            "            set(auth_events.keys()) | set(state_events.keys())",
            "        )",
            "",
            "        # We now have a chunk of events plus associated state and auth chain to",
            "        # persist. We do the persistence in two steps:",
            "        #   1. Auth events and state get persisted as outliers, plus the",
            "        #      backward extremities get persisted (as non-outliers).",
            "        #   2. The rest of the events in the chunk get persisted one by one, as",
            "        #      each one depends on the previous event for its state.",
            "        #",
            "        # The important thing is that events in the chunk get persisted as",
            "        # non-outliers, including when those events are also in the state or",
            "        # auth chain. Caution must therefore be taken to ensure that they are",
            "        # not accidentally marked as outliers.",
            "",
            "        # Step 1a: persist auth events that *don't* appear in the chunk",
            "        ev_infos = []",
            "        for a in auth_events.values():",
            "            # We only want to persist auth events as outliers that we haven't",
            "            # seen and aren't about to persist as part of the backfilled chunk.",
            "            if a.event_id in seen_events or a.event_id in event_map:",
            "                continue",
            "",
            "            a.internal_metadata.outlier = True",
            "            ev_infos.append(",
            "                {",
            "                    \"event\": a,",
            "                    \"auth_events\": {",
            "                        (",
            "                            auth_events[a_id].type,",
            "                            auth_events[a_id].state_key,",
            "                        ): auth_events[a_id]",
            "                        for a_id in a.auth_event_ids()",
            "                        if a_id in auth_events",
            "                    },",
            "                }",
            "            )",
            "",
            "        # Step 1b: persist the events in the chunk we fetched state for (i.e.",
            "        # the backwards extremities) as non-outliers.",
            "        for e_id in events_to_state:",
            "            # For paranoia we ensure that these events are marked as",
            "            # non-outliers",
            "            ev = event_map[e_id]",
            "            assert not ev.internal_metadata.is_outlier()",
            "",
            "            ev_infos.append(",
            "                {",
            "                    \"event\": ev,",
            "                    \"state\": events_to_state[e_id],",
            "                    \"auth_events\": {",
            "                        (",
            "                            auth_events[a_id].type,",
            "                            auth_events[a_id].state_key,",
            "                        ): auth_events[a_id]",
            "                        for a_id in ev.auth_event_ids()",
            "                        if a_id in auth_events",
            "                    },",
            "                }",
            "            )",
            "",
            "        yield self._handle_new_events(dest, ev_infos, backfilled=True)",
            "",
            "        # Step 2: Persist the rest of the events in the chunk one by one",
            "        events.sort(key=lambda e: e.depth)",
            "",
            "        for event in events:",
            "            if event in events_to_state:",
            "                continue",
            "",
            "            # For paranoia we ensure that these events are marked as",
            "            # non-outliers",
            "            assert not event.internal_metadata.is_outlier()",
            "",
            "            # We store these one at a time since each event depends on the",
            "            # previous to work out the state.",
            "            # TODO: We can probably do something more clever here.",
            "            yield self._handle_new_event(dest, event, backfilled=True)",
            "",
            "        return events",
            "",
            "    @defer.inlineCallbacks",
            "    def maybe_backfill(self, room_id, current_depth):",
            "        \"\"\"Checks the database to see if we should backfill before paginating,",
            "        and if so do.",
            "        \"\"\"",
            "        extremities = yield self.store.get_oldest_events_with_depth_in_room(room_id)",
            "",
            "        if not extremities:",
            "            logger.debug(\"Not backfilling as no extremeties found.\")",
            "            return",
            "",
            "        # We only want to paginate if we can actually see the events we'll get,",
            "        # as otherwise we'll just spend a lot of resources to get redacted",
            "        # events.",
            "        #",
            "        # We do this by filtering all the backwards extremities and seeing if",
            "        # any remain. Given we don't have the extremity events themselves, we",
            "        # need to actually check the events that reference them.",
            "        #",
            "        # *Note*: the spec wants us to keep backfilling until we reach the start",
            "        # of the room in case we are allowed to see some of the history. However",
            "        # in practice that causes more issues than its worth, as a) its",
            "        # relatively rare for there to be any visible history and b) even when",
            "        # there is its often sufficiently long ago that clients would stop",
            "        # attempting to paginate before backfill reached the visible history.",
            "        #",
            "        # TODO: If we do do a backfill then we should filter the backwards",
            "        #   extremities to only include those that point to visible portions of",
            "        #   history.",
            "        #",
            "        # TODO: Correctly handle the case where we are allowed to see the",
            "        #   forward event but not the backward extremity, e.g. in the case of",
            "        #   initial join of the server where we are allowed to see the join",
            "        #   event but not anything before it. This would require looking at the",
            "        #   state *before* the event, ignoring the special casing certain event",
            "        #   types have.",
            "",
            "        forward_events = yield self.store.get_successor_events(list(extremities))",
            "",
            "        extremities_events = yield self.store.get_events(",
            "            forward_events, check_redacted=False, get_prev_content=False",
            "        )",
            "",
            "        # We set `check_history_visibility_only` as we might otherwise get false",
            "        # positives from users having been erased.",
            "        filtered_extremities = yield filter_events_for_server(",
            "            self.store,",
            "            self.server_name,",
            "            list(extremities_events.values()),",
            "            redact=False,",
            "            check_history_visibility_only=True,",
            "        )",
            "",
            "        if not filtered_extremities:",
            "            return False",
            "",
            "        # Check if we reached a point where we should start backfilling.",
            "        sorted_extremeties_tuple = sorted(extremities.items(), key=lambda e: -int(e[1]))",
            "        max_depth = sorted_extremeties_tuple[0][1]",
            "",
            "        # We don't want to specify too many extremities as it causes the backfill",
            "        # request URI to be too long.",
            "        extremities = dict(sorted_extremeties_tuple[:5])",
            "",
            "        if current_depth > max_depth:",
            "            logger.debug(",
            "                \"Not backfilling as we don't need to. %d < %d\", max_depth, current_depth",
            "            )",
            "            return",
            "",
            "        # Now we need to decide which hosts to hit first.",
            "",
            "        # First we try hosts that are already in the room",
            "        # TODO: HEURISTIC ALERT.",
            "",
            "        curr_state = yield self.state_handler.get_current_state(room_id)",
            "",
            "        def get_domains_from_state(state):",
            "            \"\"\"Get joined domains from state",
            "",
            "            Args:",
            "                state (dict[tuple, FrozenEvent]): State map from type/state",
            "                    key to event.",
            "",
            "            Returns:",
            "                list[tuple[str, int]]: Returns a list of servers with the",
            "                lowest depth of their joins. Sorted by lowest depth first.",
            "            \"\"\"",
            "            joined_users = [",
            "                (state_key, int(event.depth))",
            "                for (e_type, state_key), event in iteritems(state)",
            "                if e_type == EventTypes.Member and event.membership == Membership.JOIN",
            "            ]",
            "",
            "            joined_domains = {}",
            "            for u, d in joined_users:",
            "                try:",
            "                    dom = get_domain_from_id(u)",
            "                    old_d = joined_domains.get(dom)",
            "                    if old_d:",
            "                        joined_domains[dom] = min(d, old_d)",
            "                    else:",
            "                        joined_domains[dom] = d",
            "                except Exception:",
            "                    pass",
            "",
            "            return sorted(joined_domains.items(), key=lambda d: d[1])",
            "",
            "        curr_domains = get_domains_from_state(curr_state)",
            "",
            "        likely_domains = [",
            "            domain for domain, depth in curr_domains if domain != self.server_name",
            "        ]",
            "",
            "        @defer.inlineCallbacks",
            "        def try_backfill(domains):",
            "            # TODO: Should we try multiple of these at a time?",
            "            for dom in domains:",
            "                try:",
            "                    yield self.backfill(",
            "                        dom, room_id, limit=100, extremities=extremities",
            "                    )",
            "                    # If this succeeded then we probably already have the",
            "                    # appropriate stuff.",
            "                    # TODO: We can probably do something more intelligent here.",
            "                    return True",
            "                except SynapseError as e:",
            "                    logger.info(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except CodeMessageException as e:",
            "                    if 400 <= e.code < 500:",
            "                        raise",
            "",
            "                    logger.info(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except NotRetryingDestination as e:",
            "                    logger.info(str(e))",
            "                    continue",
            "                except RequestSendFailed as e:",
            "                    logger.info(\"Falied to get backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except FederationDeniedError as e:",
            "                    logger.info(e)",
            "                    continue",
            "                except Exception as e:",
            "                    logger.exception(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "",
            "            return False",
            "",
            "        success = yield try_backfill(likely_domains)",
            "        if success:",
            "            return True",
            "",
            "        # Huh, well *those* domains didn't work out. Lets try some domains",
            "        # from the time.",
            "",
            "        tried_domains = set(likely_domains)",
            "        tried_domains.add(self.server_name)",
            "",
            "        event_ids = list(extremities.keys())",
            "",
            "        logger.debug(\"calling resolve_state_groups in _maybe_backfill\")",
            "        resolve = preserve_fn(self.state_handler.resolve_state_groups_for_events)",
            "        states = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [resolve(room_id, [e]) for e in event_ids], consumeErrors=True",
            "            )",
            "        )",
            "",
            "        # dict[str, dict[tuple, str]], a map from event_id to state map of",
            "        # event_ids.",
            "        states = dict(zip(event_ids, [s.state for s in states]))",
            "",
            "        state_map = yield self.store.get_events(",
            "            [e_id for ids in itervalues(states) for e_id in itervalues(ids)],",
            "            get_prev_content=False,",
            "        )",
            "        states = {",
            "            key: {",
            "                k: state_map[e_id]",
            "                for k, e_id in iteritems(state_dict)",
            "                if e_id in state_map",
            "            }",
            "            for key, state_dict in iteritems(states)",
            "        }",
            "",
            "        for e_id, _ in sorted_extremeties_tuple:",
            "            likely_domains = get_domains_from_state(states[e_id])",
            "",
            "            success = yield try_backfill(",
            "                [dom for dom, _ in likely_domains if dom not in tried_domains]",
            "            )",
            "            if success:",
            "                return True",
            "",
            "            tried_domains.update(dom for dom, _ in likely_domains)",
            "",
            "        return False",
            "",
            "    def _sanity_check_event(self, ev):",
            "        \"\"\"",
            "        Do some early sanity checks of a received event",
            "",
            "        In particular, checks it doesn't have an excessive number of",
            "        prev_events or auth_events, which could cause a huge state resolution",
            "        or cascade of event fetches.",
            "",
            "        Args:",
            "            ev (synapse.events.EventBase): event to be checked",
            "",
            "        Returns: None",
            "",
            "        Raises:",
            "            SynapseError if the event does not pass muster",
            "        \"\"\"",
            "        if len(ev.prev_event_ids()) > 20:",
            "            logger.warn(",
            "                \"Rejecting event %s which has %i prev_events\",",
            "                ev.event_id,",
            "                len(ev.prev_event_ids()),",
            "            )",
            "            raise SynapseError(http_client.BAD_REQUEST, \"Too many prev_events\")",
            "",
            "        if len(ev.auth_event_ids()) > 10:",
            "            logger.warn(",
            "                \"Rejecting event %s which has %i auth_events\",",
            "                ev.event_id,",
            "                len(ev.auth_event_ids()),",
            "            )",
            "            raise SynapseError(http_client.BAD_REQUEST, \"Too many auth_events\")",
            "",
            "    @defer.inlineCallbacks",
            "    def send_invite(self, target_host, event):",
            "        \"\"\" Sends the invite to the remote server for signing.",
            "",
            "        Invites must be signed by the invitee's server before distribution.",
            "        \"\"\"",
            "        pdu = yield self.federation_client.send_invite(",
            "            destination=target_host,",
            "            room_id=event.room_id,",
            "            event_id=event.event_id,",
            "            pdu=event,",
            "        )",
            "",
            "        return pdu",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, event_id):",
            "        event = yield self.store.get_event(event_id)",
            "        auth = yield self.store.get_auth_chain(",
            "            [auth_id for auth_id in event.auth_event_ids()], include_given=True",
            "        )",
            "        return [e for e in auth]",
            "",
            "    @log_function",
            "    @defer.inlineCallbacks",
            "    def do_invite_join(self, target_hosts, room_id, joinee, content):",
            "        \"\"\" Attempts to join the `joinee` to the room `room_id` via the",
            "        server `target_host`.",
            "",
            "        This first triggers a /make_join/ request that returns a partial",
            "        event that we can fill out and sign. This is then sent to the",
            "        remote server via /send_join/ which responds with the state at that",
            "        event and the auth_chains.",
            "",
            "        We suspend processing of any received events from this room until we",
            "        have finished processing the join.",
            "        \"\"\"",
            "        logger.debug(\"Joining %s to %s\", joinee, room_id)",
            "",
            "        origin, event, event_format_version = yield self._make_and_verify_event(",
            "            target_hosts,",
            "            room_id,",
            "            joinee,",
            "            \"join\",",
            "            content,",
            "            params={\"ver\": KNOWN_ROOM_VERSIONS},",
            "        )",
            "",
            "        # This shouldn't happen, because the RoomMemberHandler has a",
            "        # linearizer lock which only allows one operation per user per room",
            "        # at a time - so this is just paranoia.",
            "        assert room_id not in self.room_queues",
            "",
            "        self.room_queues[room_id] = []",
            "",
            "        yield self._clean_room_for_join(room_id)",
            "",
            "        handled_events = set()",
            "",
            "        try:",
            "            # Try the host we successfully got a response to /make_join/",
            "            # request first.",
            "            try:",
            "                target_hosts.remove(origin)",
            "                target_hosts.insert(0, origin)",
            "            except ValueError:",
            "                pass",
            "            ret = yield self.federation_client.send_join(",
            "                target_hosts, event, event_format_version",
            "            )",
            "",
            "            origin = ret[\"origin\"]",
            "            state = ret[\"state\"]",
            "            auth_chain = ret[\"auth_chain\"]",
            "            auth_chain.sort(key=lambda e: e.depth)",
            "",
            "            handled_events.update([s.event_id for s in state])",
            "            handled_events.update([a.event_id for a in auth_chain])",
            "            handled_events.add(event.event_id)",
            "",
            "            logger.debug(\"do_invite_join auth_chain: %s\", auth_chain)",
            "            logger.debug(\"do_invite_join state: %s\", state)",
            "",
            "            logger.debug(\"do_invite_join event: %s\", event)",
            "",
            "            try:",
            "                yield self.store.store_room(",
            "                    room_id=room_id, room_creator_user_id=\"\", is_public=False",
            "                )",
            "            except Exception:",
            "                # FIXME",
            "                pass",
            "",
            "            yield self._persist_auth_tree(origin, auth_chain, state, event)",
            "",
            "            logger.debug(\"Finished joining %s to %s\", joinee, room_id)",
            "        finally:",
            "            room_queue = self.room_queues[room_id]",
            "            del self.room_queues[room_id]",
            "",
            "            # we don't need to wait for the queued events to be processed -",
            "            # it's just a best-effort thing at this point. We do want to do",
            "            # them roughly in order, though, otherwise we'll end up making",
            "            # lots of requests for missing prev_events which we do actually",
            "            # have. Hence we fire off the deferred, but don't wait for it.",
            "",
            "            run_in_background(self._handle_queued_pdus, room_queue)",
            "",
            "        return True",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_queued_pdus(self, room_queue):",
            "        \"\"\"Process PDUs which got queued up while we were busy send_joining.",
            "",
            "        Args:",
            "            room_queue (list[FrozenEvent, str]): list of PDUs to be processed",
            "                and the servers that sent them",
            "        \"\"\"",
            "        for p, origin in room_queue:",
            "            try:",
            "                logger.info(",
            "                    \"Processing queued PDU %s which was received \"",
            "                    \"while we were joining %s\",",
            "                    p.event_id,",
            "                    p.room_id,",
            "                )",
            "                with nested_logging_context(p.event_id):",
            "                    yield self.on_receive_pdu(origin, p, sent_to_us_directly=True)",
            "            except Exception as e:",
            "                logger.warn(",
            "                    \"Error handling queued PDU %s from %s: %s\", p.event_id, origin, e",
            "                )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_make_join_request(self, origin, room_id, user_id):",
            "        \"\"\" We've received a /make_join/ request, so we create a partial",
            "        join event for the room and return that. We do *not* persist or",
            "        process it until the other server has signed it and sent it back.",
            "",
            "        Args:",
            "            origin (str): The (verified) server name of the requesting server.",
            "            room_id (str): Room to create join event in",
            "            user_id (str): The user to create the join for",
            "",
            "        Returns:",
            "            Deferred[FrozenEvent]",
            "        \"\"\"",
            "",
            "        if get_domain_from_id(user_id) != origin:",
            "            logger.info(",
            "                \"Got /make_join request for user %r from different origin %s, ignoring\",",
            "                user_id,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        event_content = {\"membership\": Membership.JOIN}",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        builder = self.event_builder_factory.new(",
            "            room_version,",
            "            {",
            "                \"type\": EventTypes.Member,",
            "                \"content\": event_content,",
            "                \"room_id\": room_id,",
            "                \"sender\": user_id,",
            "                \"state_key\": user_id,",
            "            },",
            "        )",
            "",
            "        try:",
            "            event, context = yield self.event_creation_handler.create_new_client_event(",
            "                builder=builder",
            "            )",
            "        except AuthError as e:",
            "            logger.warn(\"Failed to create join %r because %s\", event, e)",
            "            raise e",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Creation of join %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        # The remote hasn't signed it yet, obviously. We'll do the full checks",
            "        # when we get the event back in `on_send_join_request`",
            "        yield self.auth.check_from_context(",
            "            room_version, event, context, do_sig_check=False",
            "        )",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_send_join_request(self, origin, pdu):",
            "        \"\"\" We have received a join event for a room. Fully process it and",
            "        respond with the current state and auth chains.",
            "        \"\"\"",
            "        event = pdu",
            "",
            "        logger.debug(",
            "            \"on_send_join_request: Got event: %s, signatures: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        event.internal_metadata.outlier = False",
            "        # Send this event on behalf of the origin server.",
            "        #",
            "        # The reasons we have the destination server rather than the origin",
            "        # server send it are slightly mysterious: the origin server should have",
            "        # all the neccessary state once it gets the response to the send_join,",
            "        # so it could send the event itself if it wanted to. It may be that",
            "        # doing it this way reduces failure modes, or avoids certain attacks",
            "        # where a new server selectively tells a subset of the federation that",
            "        # it has joined.",
            "        #",
            "        # The fact is that, as of the current writing, Synapse doesn't send out",
            "        # the join event over federation after joining, and changing it now",
            "        # would introduce the danger of backwards-compatibility problems.",
            "        event.internal_metadata.send_on_behalf_of = origin",
            "",
            "        context = yield self._handle_new_event(origin, event)",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Sending of join %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        logger.debug(",
            "            \"on_send_join_request: After _handle_new_event: %s, sigs: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        if event.type == EventTypes.Member:",
            "            if event.content[\"membership\"] == Membership.JOIN:",
            "                user = UserID.from_string(event.state_key)",
            "                yield self.user_joined_room(user, event.room_id)",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "",
            "        state_ids = list(prev_state_ids.values())",
            "        auth_chain = yield self.store.get_auth_chain(state_ids)",
            "",
            "        state = yield self.store.get_events(list(prev_state_ids.values()))",
            "",
            "        return {\"state\": list(state.values()), \"auth_chain\": auth_chain}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, pdu):",
            "        \"\"\" We've got an invite event. Process and persist it. Sign it.",
            "",
            "        Respond with the now signed event.",
            "        \"\"\"",
            "        event = pdu",
            "",
            "        if event.state_key is None:",
            "            raise SynapseError(400, \"The invite event did not have a state key\")",
            "",
            "        is_blocked = yield self.store.is_room_blocked(event.room_id)",
            "        if is_blocked:",
            "            raise SynapseError(403, \"This room has been blocked on this server\")",
            "",
            "        if self.hs.config.block_non_admin_invites:",
            "            raise SynapseError(403, \"This server does not accept room invites\")",
            "",
            "        if not self.spam_checker.user_may_invite(",
            "            event.sender, event.state_key, event.room_id",
            "        ):",
            "            raise SynapseError(",
            "                403, \"This user is not permitted to send invites to this server/user\"",
            "            )",
            "",
            "        membership = event.content.get(\"membership\")",
            "        if event.type != EventTypes.Member or membership != Membership.INVITE:",
            "            raise SynapseError(400, \"The event was not an m.room.member invite event\")",
            "",
            "        sender_domain = get_domain_from_id(event.sender)",
            "        if sender_domain != origin:",
            "            raise SynapseError(",
            "                400, \"The invite event was not from the server sending it\"",
            "            )",
            "",
            "        if not self.is_mine_id(event.state_key):",
            "            raise SynapseError(400, \"The invite event must be for this server\")",
            "",
            "        # block any attempts to invite the server notices mxid",
            "        if event.state_key == self._server_notices_mxid:",
            "            raise SynapseError(http_client.FORBIDDEN, \"Cannot invite this user\")",
            "",
            "        event.internal_metadata.outlier = True",
            "        event.internal_metadata.out_of_band_membership = True",
            "",
            "        event.signatures.update(",
            "            compute_event_signature(",
            "                event.get_pdu_json(), self.hs.hostname, self.hs.config.signing_key[0]",
            "            )",
            "        )",
            "",
            "        context = yield self.state_handler.compute_event_context(event)",
            "        yield self.persist_events_and_notify([(event, context)])",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    def do_remotely_reject_invite(self, target_hosts, room_id, user_id):",
            "        origin, event, event_format_version = yield self._make_and_verify_event(",
            "            target_hosts, room_id, user_id, \"leave\"",
            "        )",
            "        # Mark as outlier as we don't have any state for this event; we're not",
            "        # even in the room.",
            "        event.internal_metadata.outlier = True",
            "        event.internal_metadata.out_of_band_membership = True",
            "",
            "        # Try the host that we succesfully called /make_leave/ on first for",
            "        # the /send_leave/ request.",
            "        try:",
            "            target_hosts.remove(origin)",
            "            target_hosts.insert(0, origin)",
            "        except ValueError:",
            "            pass",
            "",
            "        yield self.federation_client.send_leave(target_hosts, event)",
            "",
            "        context = yield self.state_handler.compute_event_context(event)",
            "        yield self.persist_events_and_notify([(event, context)])",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    def _make_and_verify_event(",
            "        self, target_hosts, room_id, user_id, membership, content={}, params=None",
            "    ):",
            "        origin, event, format_ver = yield self.federation_client.make_membership_event(",
            "            target_hosts, room_id, user_id, membership, content, params=params",
            "        )",
            "",
            "        logger.debug(\"Got response to make_%s: %s\", membership, event)",
            "",
            "        # We should assert some things.",
            "        # FIXME: Do this in a nicer way",
            "        assert event.type == EventTypes.Member",
            "        assert event.user_id == user_id",
            "        assert event.state_key == user_id",
            "        assert event.room_id == room_id",
            "        return origin, event, format_ver",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        \"\"\" We've received a /make_leave/ request, so we create a partial",
            "        leave event for the room and return that. We do *not* persist or",
            "        process it until the other server has signed it and sent it back.",
            "",
            "        Args:",
            "            origin (str): The (verified) server name of the requesting server.",
            "            room_id (str): Room to create leave event in",
            "            user_id (str): The user to create the leave for",
            "",
            "        Returns:",
            "            Deferred[FrozenEvent]",
            "        \"\"\"",
            "        if get_domain_from_id(user_id) != origin:",
            "            logger.info(",
            "                \"Got /make_leave request for user %r from different origin %s, ignoring\",",
            "                user_id,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        builder = self.event_builder_factory.new(",
            "            room_version,",
            "            {",
            "                \"type\": EventTypes.Member,",
            "                \"content\": {\"membership\": Membership.LEAVE},",
            "                \"room_id\": room_id,",
            "                \"sender\": user_id,",
            "                \"state_key\": user_id,",
            "            },",
            "        )",
            "",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.warning(\"Creation of leave %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        try:",
            "            # The remote hasn't signed it yet, obviously. We'll do the full checks",
            "            # when we get the event back in `on_send_leave_request`",
            "            yield self.auth.check_from_context(",
            "                room_version, event, context, do_sig_check=False",
            "            )",
            "        except AuthError as e:",
            "            logger.warn(\"Failed to create new leave %r because %s\", event, e)",
            "            raise e",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_send_leave_request(self, origin, pdu):",
            "        \"\"\" We have received a leave event for a room. Fully process it.\"\"\"",
            "        event = pdu",
            "",
            "        logger.debug(",
            "            \"on_send_leave_request: Got event: %s, signatures: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        event.internal_metadata.outlier = False",
            "",
            "        context = yield self._handle_new_event(origin, event)",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Sending of leave %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        logger.debug(",
            "            \"on_send_leave_request: After _handle_new_event: %s, sigs: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        return None",
            "",
            "    @defer.inlineCallbacks",
            "    def get_state_for_pdu(self, room_id, event_id):",
            "        \"\"\"Returns the state at the event. i.e. not including said event.",
            "        \"\"\"",
            "",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        state_groups = yield self.store.get_state_groups(room_id, [event_id])",
            "",
            "        if state_groups:",
            "            _, state = list(iteritems(state_groups)).pop()",
            "            results = {(e.type, e.state_key): e for e in state}",
            "",
            "            if event.is_state():",
            "                # Get previous state",
            "                if \"replaces_state\" in event.unsigned:",
            "                    prev_id = event.unsigned[\"replaces_state\"]",
            "                    if prev_id != event.event_id:",
            "                        prev_event = yield self.store.get_event(prev_id)",
            "                        results[(event.type, event.state_key)] = prev_event",
            "                else:",
            "                    del results[(event.type, event.state_key)]",
            "",
            "            res = list(results.values())",
            "            return res",
            "        else:",
            "            return []",
            "",
            "    @defer.inlineCallbacks",
            "    def get_state_ids_for_pdu(self, room_id, event_id):",
            "        \"\"\"Returns the state at the event. i.e. not including said event.",
            "        \"\"\"",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        state_groups = yield self.store.get_state_groups_ids(room_id, [event_id])",
            "",
            "        if state_groups:",
            "            _, state = list(state_groups.items()).pop()",
            "            results = state",
            "",
            "            if event.is_state():",
            "                # Get previous state",
            "                if \"replaces_state\" in event.unsigned:",
            "                    prev_id = event.unsigned[\"replaces_state\"]",
            "                    if prev_id != event.event_id:",
            "                        results[(event.type, event.state_key)] = prev_id",
            "                else:",
            "                    results.pop((event.type, event.state_key), None)",
            "",
            "            return list(results.values())",
            "        else:",
            "            return []",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, pdu_list, limit):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        events = yield self.store.get_backfill_events(room_id, pdu_list, limit)",
            "",
            "        events = yield filter_events_for_server(self.store, origin, events)",
            "",
            "        return events",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def get_persisted_pdu(self, origin, event_id):",
            "        \"\"\"Get an event from the database for the given server.",
            "",
            "        Args:",
            "            origin [str]: hostname of server which is requesting the event; we",
            "               will check that the server is allowed to see it.",
            "            event_id [str]: id of the event being requested",
            "",
            "        Returns:",
            "            Deferred[EventBase|None]: None if we know nothing about the event;",
            "                otherwise the (possibly-redacted) event.",
            "",
            "        Raises:",
            "            AuthError if the server is not currently in the room",
            "        \"\"\"",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=True, allow_rejected=True",
            "        )",
            "",
            "        if event:",
            "            in_room = yield self.auth.check_host_in_room(event.room_id, origin)",
            "            if not in_room:",
            "                raise AuthError(403, \"Host not in room.\")",
            "",
            "            events = yield filter_events_for_server(self.store, origin, [event])",
            "            event = events[0]",
            "            return event",
            "        else:",
            "            return None",
            "",
            "    def get_min_depth_for_context(self, context):",
            "        return self.store.get_min_depth(context)",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_new_event(",
            "        self, origin, event, state=None, auth_events=None, backfilled=False",
            "    ):",
            "        context = yield self._prep_event(",
            "            origin, event, state=state, auth_events=auth_events, backfilled=backfilled",
            "        )",
            "",
            "        # reraise does not allow inlineCallbacks to preserve the stacktrace, so we",
            "        # hack around with a try/finally instead.",
            "        success = False",
            "        try:",
            "            if not event.internal_metadata.is_outlier() and not backfilled:",
            "                yield self.action_generator.handle_push_actions_for_event(",
            "                    event, context",
            "                )",
            "",
            "            yield self.persist_events_and_notify(",
            "                [(event, context)], backfilled=backfilled",
            "            )",
            "            success = True",
            "        finally:",
            "            if not success:",
            "                run_in_background(",
            "                    self.store.remove_push_actions_from_staging, event.event_id",
            "                )",
            "",
            "        return context",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_new_events(self, origin, event_infos, backfilled=False):",
            "        \"\"\"Creates the appropriate contexts and persists events. The events",
            "        should not depend on one another, e.g. this should be used to persist",
            "        a bunch of outliers, but not a chunk of individual events that depend",
            "        on each other for state calculations.",
            "",
            "        Notifies about the events where appropriate.",
            "        \"\"\"",
            "",
            "        @defer.inlineCallbacks",
            "        def prep(ev_info):",
            "            event = ev_info[\"event\"]",
            "            with nested_logging_context(suffix=event.event_id):",
            "                res = yield self._prep_event(",
            "                    origin,",
            "                    event,",
            "                    state=ev_info.get(\"state\"),",
            "                    auth_events=ev_info.get(\"auth_events\"),",
            "                    backfilled=backfilled,",
            "                )",
            "            return res",
            "",
            "        contexts = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [run_in_background(prep, ev_info) for ev_info in event_infos],",
            "                consumeErrors=True,",
            "            )",
            "        )",
            "",
            "        yield self.persist_events_and_notify(",
            "            [",
            "                (ev_info[\"event\"], context)",
            "                for ev_info, context in zip(event_infos, contexts)",
            "            ],",
            "            backfilled=backfilled,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _persist_auth_tree(self, origin, auth_events, state, event):",
            "        \"\"\"Checks the auth chain is valid (and passes auth checks) for the",
            "        state and event. Then persists the auth chain and state atomically.",
            "        Persists the event separately. Notifies about the persisted events",
            "        where appropriate.",
            "",
            "        Will attempt to fetch missing auth events.",
            "",
            "        Args:",
            "            origin (str): Where the events came from",
            "            auth_events (list)",
            "            state (list)",
            "            event (Event)",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        events_to_context = {}",
            "        for e in itertools.chain(auth_events, state):",
            "            e.internal_metadata.outlier = True",
            "            ctx = yield self.state_handler.compute_event_context(e)",
            "            events_to_context[e.event_id] = ctx",
            "",
            "        event_map = {",
            "            e.event_id: e for e in itertools.chain(auth_events, state, [event])",
            "        }",
            "",
            "        create_event = None",
            "        for e in auth_events:",
            "            if (e.type, e.state_key) == (EventTypes.Create, \"\"):",
            "                create_event = e",
            "                break",
            "",
            "        if create_event is None:",
            "            # If the state doesn't have a create event then the room is",
            "            # invalid, and it would fail auth checks anyway.",
            "            raise SynapseError(400, \"No create event in state\")",
            "",
            "        room_version = create_event.content.get(",
            "            \"room_version\", RoomVersions.V1.identifier",
            "        )",
            "",
            "        missing_auth_events = set()",
            "        for e in itertools.chain(auth_events, state, [event]):",
            "            for e_id in e.auth_event_ids():",
            "                if e_id not in event_map:",
            "                    missing_auth_events.add(e_id)",
            "",
            "        for e_id in missing_auth_events:",
            "            m_ev = yield self.federation_client.get_pdu(",
            "                [origin], e_id, room_version=room_version, outlier=True, timeout=10000",
            "            )",
            "            if m_ev and m_ev.event_id == e_id:",
            "                event_map[e_id] = m_ev",
            "            else:",
            "                logger.info(\"Failed to find auth event %r\", e_id)",
            "",
            "        for e in itertools.chain(auth_events, state, [event]):",
            "            auth_for_e = {",
            "                (event_map[e_id].type, event_map[e_id].state_key): event_map[e_id]",
            "                for e_id in e.auth_event_ids()",
            "                if e_id in event_map",
            "            }",
            "            if create_event:",
            "                auth_for_e[(EventTypes.Create, \"\")] = create_event",
            "",
            "            try:",
            "                event_auth.check(room_version, e, auth_events=auth_for_e)",
            "            except SynapseError as err:",
            "                # we may get SynapseErrors here as well as AuthErrors. For",
            "                # instance, there are a couple of (ancient) events in some",
            "                # rooms whose senders do not have the correct sigil; these",
            "                # cause SynapseErrors in auth.check. We don't want to give up",
            "                # the attempt to federate altogether in such cases.",
            "",
            "                logger.warn(\"Rejecting %s because %s\", e.event_id, err.msg)",
            "",
            "                if e == event:",
            "                    raise",
            "                events_to_context[e.event_id].rejected = RejectedReason.AUTH_ERROR",
            "",
            "        yield self.persist_events_and_notify(",
            "            [",
            "                (e, events_to_context[e.event_id])",
            "                for e in itertools.chain(auth_events, state)",
            "            ]",
            "        )",
            "",
            "        new_event_context = yield self.state_handler.compute_event_context(",
            "            event, old_state=state",
            "        )",
            "",
            "        yield self.persist_events_and_notify([(event, new_event_context)])",
            "",
            "    @defer.inlineCallbacks",
            "    def _prep_event(self, origin, event, state, auth_events, backfilled):",
            "        \"\"\"",
            "",
            "        Args:",
            "            origin:",
            "            event:",
            "            state:",
            "            auth_events:",
            "            backfilled (bool)",
            "",
            "        Returns:",
            "            Deferred, which resolves to synapse.events.snapshot.EventContext",
            "        \"\"\"",
            "        context = yield self.state_handler.compute_event_context(event, old_state=state)",
            "",
            "        if not auth_events:",
            "            prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "            auth_events_ids = yield self.auth.compute_auth_events(",
            "                event, prev_state_ids, for_verification=True",
            "            )",
            "            auth_events = yield self.store.get_events(auth_events_ids)",
            "            auth_events = {(e.type, e.state_key): e for e in auth_events.values()}",
            "",
            "        # This is a hack to fix some old rooms where the initial join event",
            "        # didn't reference the create event in its auth events.",
            "        if event.type == EventTypes.Member and not event.auth_event_ids():",
            "            if len(event.prev_event_ids()) == 1 and event.depth < 5:",
            "                c = yield self.store.get_event(",
            "                    event.prev_event_ids()[0], allow_none=True",
            "                )",
            "                if c and c.type == EventTypes.Create:",
            "                    auth_events[(c.type, c.state_key)] = c",
            "",
            "        try:",
            "            yield self.do_auth(origin, event, context, auth_events=auth_events)",
            "        except AuthError as e:",
            "            logger.warn(\"[%s %s] Rejecting: %s\", event.room_id, event.event_id, e.msg)",
            "",
            "            context.rejected = RejectedReason.AUTH_ERROR",
            "",
            "        if not context.rejected:",
            "            yield self._check_for_soft_fail(event, state, backfilled)",
            "",
            "        if event.type == EventTypes.GuestAccess and not context.rejected:",
            "            yield self.maybe_kick_guest_users(event)",
            "",
            "        return context",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_for_soft_fail(self, event, state, backfilled):",
            "        \"\"\"Checks if we should soft fail the event, if so marks the event as",
            "        such.",
            "",
            "        Args:",
            "            event (FrozenEvent)",
            "            state (dict|None): The state at the event if we don't have all the",
            "                event's prev events",
            "            backfilled (bool): Whether the event is from backfill",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        # For new (non-backfilled and non-outlier) events we check if the event",
            "        # passes auth based on the current state. If it doesn't then we",
            "        # \"soft-fail\" the event.",
            "        do_soft_fail_check = not backfilled and not event.internal_metadata.is_outlier()",
            "        if do_soft_fail_check:",
            "            extrem_ids = yield self.store.get_latest_event_ids_in_room(event.room_id)",
            "",
            "            extrem_ids = set(extrem_ids)",
            "            prev_event_ids = set(event.prev_event_ids())",
            "",
            "            if extrem_ids == prev_event_ids:",
            "                # If they're the same then the current state is the same as the",
            "                # state at the event, so no point rechecking auth for soft fail.",
            "                do_soft_fail_check = False",
            "",
            "        if do_soft_fail_check:",
            "            room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "            # Calculate the \"current state\".",
            "            if state is not None:",
            "                # If we're explicitly given the state then we won't have all the",
            "                # prev events, and so we have a gap in the graph. In this case",
            "                # we want to be a little careful as we might have been down for",
            "                # a while and have an incorrect view of the current state,",
            "                # however we still want to do checks as gaps are easy to",
            "                # maliciously manufacture.",
            "                #",
            "                # So we use a \"current state\" that is actually a state",
            "                # resolution across the current forward extremities and the",
            "                # given state at the event. This should correctly handle cases",
            "                # like bans, especially with state res v2.",
            "",
            "                state_sets = yield self.store.get_state_groups(",
            "                    event.room_id, extrem_ids",
            "                )",
            "                state_sets = list(state_sets.values())",
            "                state_sets.append(state)",
            "                current_state_ids = yield self.state_handler.resolve_events(",
            "                    room_version, state_sets, event",
            "                )",
            "                current_state_ids = {",
            "                    k: e.event_id for k, e in iteritems(current_state_ids)",
            "                }",
            "            else:",
            "                current_state_ids = yield self.state_handler.get_current_state_ids(",
            "                    event.room_id, latest_event_ids=extrem_ids",
            "                )",
            "",
            "            logger.debug(",
            "                \"Doing soft-fail check for %s: state %s\",",
            "                event.event_id,",
            "                current_state_ids,",
            "            )",
            "",
            "            # Now check if event pass auth against said current state",
            "            auth_types = auth_types_for_event(event)",
            "            current_state_ids = [",
            "                e for k, e in iteritems(current_state_ids) if k in auth_types",
            "            ]",
            "",
            "            current_auth_events = yield self.store.get_events(current_state_ids)",
            "            current_auth_events = {",
            "                (e.type, e.state_key): e for e in current_auth_events.values()",
            "            }",
            "",
            "            try:",
            "                event_auth.check(room_version, event, auth_events=current_auth_events)",
            "            except AuthError as e:",
            "                logger.warn(\"Soft-failing %r because %s\", event, e)",
            "                event.internal_metadata.soft_failed = True",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth(",
            "        self, origin, event_id, room_id, remote_auth_chain, rejects, missing",
            "    ):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        # Just go through and process each event in `remote_auth_chain`. We",
            "        # don't want to fall into the trap of `missing` being wrong.",
            "        for e in remote_auth_chain:",
            "            try:",
            "                yield self._handle_new_event(origin, e)",
            "            except AuthError:",
            "                pass",
            "",
            "        # Now get the current auth_chain for the event.",
            "        local_auth_chain = yield self.store.get_auth_chain(",
            "            [auth_id for auth_id in event.auth_event_ids()], include_given=True",
            "        )",
            "",
            "        # TODO: Check if we would now reject event_id. If so we need to tell",
            "        # everyone.",
            "",
            "        ret = yield self.construct_auth_difference(local_auth_chain, remote_auth_chain)",
            "",
            "        logger.debug(\"on_query_auth returning: %s\", ret)",
            "",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def on_get_missing_events(",
            "        self, origin, room_id, earliest_events, latest_events, limit",
            "    ):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        limit = min(limit, 20)",
            "",
            "        missing_events = yield self.store.get_missing_events(",
            "            room_id=room_id,",
            "            earliest_events=earliest_events,",
            "            latest_events=latest_events,",
            "            limit=limit,",
            "        )",
            "",
            "        missing_events = yield filter_events_for_server(",
            "            self.store, origin, missing_events",
            "        )",
            "",
            "        return missing_events",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def do_auth(self, origin, event, context, auth_events):",
            "        \"\"\"",
            "",
            "        Args:",
            "            origin (str):",
            "            event (synapse.events.EventBase):",
            "            context (synapse.events.snapshot.EventContext):",
            "            auth_events (dict[(str, str)->synapse.events.EventBase]):",
            "                Map from (event_type, state_key) to event",
            "",
            "                What we expect the event's auth_events to be, based on the event's",
            "                position in the dag. I think? maybe??",
            "",
            "                Also NB that this function adds entries to it.",
            "        Returns:",
            "            defer.Deferred[None]",
            "        \"\"\"",
            "        room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "        try:",
            "            yield self._update_auth_events_and_context_for_auth(",
            "                origin, event, context, auth_events",
            "            )",
            "        except Exception:",
            "            # We don't really mind if the above fails, so lets not fail",
            "            # processing if it does. However, it really shouldn't fail so",
            "            # let's still log as an exception since we'll still want to fix",
            "            # any bugs.",
            "            logger.exception(",
            "                \"Failed to double check auth events for %s with remote. \"",
            "                \"Ignoring failure and continuing processing of event.\",",
            "                event.event_id,",
            "            )",
            "",
            "        try:",
            "            event_auth.check(room_version, event, auth_events=auth_events)",
            "        except AuthError as e:",
            "            logger.warn(\"Failed auth resolution for %r because %s\", event, e)",
            "            raise e",
            "",
            "    @defer.inlineCallbacks",
            "    def _update_auth_events_and_context_for_auth(",
            "        self, origin, event, context, auth_events",
            "    ):",
            "        \"\"\"Helper for do_auth. See there for docs.",
            "",
            "        Checks whether a given event has the expected auth events. If it",
            "        doesn't then we talk to the remote server to compare state to see if",
            "        we can come to a consensus (e.g. if one server missed some valid",
            "        state).",
            "",
            "        This attempts to resovle any potential divergence of state between",
            "        servers, but is not essential and so failures should not block further",
            "        processing of the event.",
            "",
            "        Args:",
            "            origin (str):",
            "            event (synapse.events.EventBase):",
            "            context (synapse.events.snapshot.EventContext):",
            "            auth_events (dict[(str, str)->synapse.events.EventBase]):",
            "",
            "        Returns:",
            "            defer.Deferred[None]",
            "        \"\"\"",
            "        event_auth_events = set(event.auth_event_ids())",
            "",
            "        if event.is_state():",
            "            event_key = (event.type, event.state_key)",
            "        else:",
            "            event_key = None",
            "",
            "        # if the event's auth_events refers to events which are not in our",
            "        # calculated auth_events, we need to fetch those events from somewhere.",
            "        #",
            "        # we start by fetching them from the store, and then try calling /event_auth/.",
            "        missing_auth = event_auth_events.difference(",
            "            e.event_id for e in auth_events.values()",
            "        )",
            "",
            "        if missing_auth:",
            "            # TODO: can we use store.have_seen_events here instead?",
            "            have_events = yield self.store.get_seen_events_with_rejections(missing_auth)",
            "            logger.debug(\"Got events %s from store\", have_events)",
            "            missing_auth.difference_update(have_events.keys())",
            "        else:",
            "            have_events = {}",
            "",
            "        have_events.update({e.event_id: \"\" for e in auth_events.values()})",
            "",
            "        if missing_auth:",
            "            # If we don't have all the auth events, we need to get them.",
            "            logger.info(\"auth_events contains unknown events: %s\", missing_auth)",
            "            try:",
            "                try:",
            "                    remote_auth_chain = yield self.federation_client.get_event_auth(",
            "                        origin, event.room_id, event.event_id",
            "                    )",
            "                except RequestSendFailed as e:",
            "                    # The other side isn't around or doesn't implement the",
            "                    # endpoint, so lets just bail out.",
            "                    logger.info(\"Failed to get event auth from remote: %s\", e)",
            "                    return",
            "",
            "                seen_remotes = yield self.store.have_seen_events(",
            "                    [e.event_id for e in remote_auth_chain]",
            "                )",
            "",
            "                for e in remote_auth_chain:",
            "                    if e.event_id in seen_remotes:",
            "                        continue",
            "",
            "                    if e.event_id == event.event_id:",
            "                        continue",
            "",
            "                    try:",
            "                        auth_ids = e.auth_event_ids()",
            "                        auth = {",
            "                            (e.type, e.state_key): e",
            "                            for e in remote_auth_chain",
            "                            if e.event_id in auth_ids or e.type == EventTypes.Create",
            "                        }",
            "                        e.internal_metadata.outlier = True",
            "",
            "                        logger.debug(",
            "                            \"do_auth %s missing_auth: %s\", event.event_id, e.event_id",
            "                        )",
            "                        yield self._handle_new_event(origin, e, auth_events=auth)",
            "",
            "                        if e.event_id in event_auth_events:",
            "                            auth_events[(e.type, e.state_key)] = e",
            "                    except AuthError:",
            "                        pass",
            "",
            "                have_events = yield self.store.get_seen_events_with_rejections(",
            "                    event.auth_event_ids()",
            "                )",
            "            except Exception:",
            "                # FIXME:",
            "                logger.exception(\"Failed to get auth chain\")",
            "",
            "        if event.internal_metadata.is_outlier():",
            "            logger.info(\"Skipping auth_event fetch for outlier\")",
            "            return",
            "",
            "        # FIXME: Assumes we have and stored all the state for all the",
            "        # prev_events",
            "        different_auth = event_auth_events.difference(",
            "            e.event_id for e in auth_events.values()",
            "        )",
            "",
            "        if not different_auth:",
            "            return",
            "",
            "        logger.info(",
            "            \"auth_events refers to events which are not in our calculated auth \"",
            "            \"chain: %s\",",
            "            different_auth,",
            "        )",
            "",
            "        room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "        different_events = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [",
            "                    run_in_background(",
            "                        self.store.get_event, d, allow_none=True, allow_rejected=False",
            "                    )",
            "                    for d in different_auth",
            "                    if d in have_events and not have_events[d]",
            "                ],",
            "                consumeErrors=True,",
            "            )",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if different_events:",
            "            local_view = dict(auth_events)",
            "            remote_view = dict(auth_events)",
            "            remote_view.update(",
            "                {(d.type, d.state_key): d for d in different_events if d}",
            "            )",
            "",
            "            new_state = yield self.state_handler.resolve_events(",
            "                room_version,",
            "                [list(local_view.values()), list(remote_view.values())],",
            "                event,",
            "            )",
            "",
            "            logger.info(",
            "                \"After state res: updating auth_events with new state %s\",",
            "                {",
            "                    (d.type, d.state_key): d.event_id",
            "                    for d in new_state.values()",
            "                    if auth_events.get((d.type, d.state_key)) != d",
            "                },",
            "            )",
            "",
            "            auth_events.update(new_state)",
            "",
            "            yield self._update_context_for_auth_events(",
            "                event, context, auth_events, event_key",
            "            )",
            "",
            "    @defer.inlineCallbacks",
            "    def _update_context_for_auth_events(self, event, context, auth_events, event_key):",
            "        \"\"\"Update the state_ids in an event context after auth event resolution,",
            "        storing the changes as a new state group.",
            "",
            "        Args:",
            "            event (Event): The event we're handling the context for",
            "",
            "            context (synapse.events.snapshot.EventContext): event context",
            "                to be updated",
            "",
            "            auth_events (dict[(str, str)->str]): Events to update in the event",
            "                context.",
            "",
            "            event_key ((str, str)): (type, state_key) for the current event.",
            "                this will not be included in the current_state in the context.",
            "        \"\"\"",
            "        state_updates = {",
            "            k: a.event_id for k, a in iteritems(auth_events) if k != event_key",
            "        }",
            "        current_state_ids = yield context.get_current_state_ids(self.store)",
            "        current_state_ids = dict(current_state_ids)",
            "",
            "        current_state_ids.update(state_updates)",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        prev_state_ids = dict(prev_state_ids)",
            "",
            "        prev_state_ids.update({k: a.event_id for k, a in iteritems(auth_events)})",
            "",
            "        # create a new state group as a delta from the existing one.",
            "        prev_group = context.state_group",
            "        state_group = yield self.store.store_state_group(",
            "            event.event_id,",
            "            event.room_id,",
            "            prev_group=prev_group,",
            "            delta_ids=state_updates,",
            "            current_state_ids=current_state_ids,",
            "        )",
            "",
            "        yield context.update_state(",
            "            state_group=state_group,",
            "            current_state_ids=current_state_ids,",
            "            prev_state_ids=prev_state_ids,",
            "            prev_group=prev_group,",
            "            delta_ids=state_updates,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def construct_auth_difference(self, local_auth, remote_auth):",
            "        \"\"\" Given a local and remote auth chain, find the differences. This",
            "        assumes that we have already processed all events in remote_auth",
            "",
            "        Params:",
            "            local_auth (list)",
            "            remote_auth (list)",
            "",
            "        Returns:",
            "            dict",
            "        \"\"\"",
            "",
            "        logger.debug(\"construct_auth_difference Start!\")",
            "",
            "        # TODO: Make sure we are OK with local_auth or remote_auth having more",
            "        # auth events in them than strictly necessary.",
            "",
            "        def sort_fun(ev):",
            "            return ev.depth, ev.event_id",
            "",
            "        logger.debug(\"construct_auth_difference after sort_fun!\")",
            "",
            "        # We find the differences by starting at the \"bottom\" of each list",
            "        # and iterating up on both lists. The lists are ordered by depth and",
            "        # then event_id, we iterate up both lists until we find the event ids",
            "        # don't match. Then we look at depth/event_id to see which side is",
            "        # missing that event, and iterate only up that list. Repeat.",
            "",
            "        remote_list = list(remote_auth)",
            "        remote_list.sort(key=sort_fun)",
            "",
            "        local_list = list(local_auth)",
            "        local_list.sort(key=sort_fun)",
            "",
            "        local_iter = iter(local_list)",
            "        remote_iter = iter(remote_list)",
            "",
            "        logger.debug(\"construct_auth_difference before get_next!\")",
            "",
            "        def get_next(it, opt=None):",
            "            try:",
            "                return next(it)",
            "            except Exception:",
            "                return opt",
            "",
            "        current_local = get_next(local_iter)",
            "        current_remote = get_next(remote_iter)",
            "",
            "        logger.debug(\"construct_auth_difference before while\")",
            "",
            "        missing_remotes = []",
            "        missing_locals = []",
            "        while current_local or current_remote:",
            "            if current_remote is None:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "                continue",
            "",
            "            if current_local is None:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            if current_local.event_id == current_remote.event_id:",
            "                current_local = get_next(local_iter)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            if current_local.depth < current_remote.depth:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "                continue",
            "",
            "            if current_local.depth > current_remote.depth:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            # They have the same depth, so we fall back to the event_id order",
            "            if current_local.event_id < current_remote.event_id:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "",
            "            if current_local.event_id > current_remote.event_id:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "        logger.debug(\"construct_auth_difference after while\")",
            "",
            "        # missing locals should be sent to the server",
            "        # We should find why we are missing remotes, as they will have been",
            "        # rejected.",
            "",
            "        # Remove events from missing_remotes if they are referencing a missing",
            "        # remote. We only care about the \"root\" rejected ones.",
            "        missing_remote_ids = [e.event_id for e in missing_remotes]",
            "        base_remote_rejected = list(missing_remotes)",
            "        for e in missing_remotes:",
            "            for e_id in e.auth_event_ids():",
            "                if e_id in missing_remote_ids:",
            "                    try:",
            "                        base_remote_rejected.remove(e)",
            "                    except ValueError:",
            "                        pass",
            "",
            "        reason_map = {}",
            "",
            "        for e in base_remote_rejected:",
            "            reason = yield self.store.get_rejection_reason(e.event_id)",
            "            if reason is None:",
            "                # TODO: e is not in the current state, so we should",
            "                # construct some proof of that.",
            "                continue",
            "",
            "            reason_map[e.event_id] = reason",
            "",
            "        logger.debug(\"construct_auth_difference returning\")",
            "",
            "        return {",
            "            \"auth_chain\": local_auth,",
            "            \"rejects\": {",
            "                e.event_id: {\"reason\": reason_map[e.event_id], \"proof\": None}",
            "                for e in base_remote_rejected",
            "            },",
            "            \"missing\": [e.event_id for e in missing_locals],",
            "        }",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def exchange_third_party_invite(",
            "        self, sender_user_id, target_user_id, room_id, signed",
            "    ):",
            "        third_party_invite = {\"signed\": signed}",
            "",
            "        event_dict = {",
            "            \"type\": EventTypes.Member,",
            "            \"content\": {",
            "                \"membership\": Membership.INVITE,",
            "                \"third_party_invite\": third_party_invite,",
            "            },",
            "            \"room_id\": room_id,",
            "            \"sender\": sender_user_id,",
            "            \"state_key\": target_user_id,",
            "        }",
            "",
            "        if (yield self.auth.check_host_in_room(room_id, self.hs.hostname)):",
            "            room_version = yield self.store.get_room_version(room_id)",
            "            builder = self.event_builder_factory.new(room_version, event_dict)",
            "",
            "            EventValidator().validate_builder(builder)",
            "            event, context = yield self.event_creation_handler.create_new_client_event(",
            "                builder=builder",
            "            )",
            "",
            "            event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "                event, context",
            "            )",
            "            if not event_allowed:",
            "                logger.info(",
            "                    \"Creation of threepid invite %s forbidden by third-party rules\",",
            "                    event,",
            "                )",
            "                raise SynapseError(",
            "                    403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "                )",
            "",
            "            event, context = yield self.add_display_name_to_third_party_invite(",
            "                room_version, event_dict, event, context",
            "            )",
            "",
            "            EventValidator().validate_new(event)",
            "",
            "            # We need to tell the transaction queue to send this out, even",
            "            # though the sender isn't a local user.",
            "            event.internal_metadata.send_on_behalf_of = self.hs.hostname",
            "",
            "            try:",
            "                yield self.auth.check_from_context(room_version, event, context)",
            "            except AuthError as e:",
            "                logger.warn(\"Denying new third party invite %r because %s\", event, e)",
            "                raise e",
            "",
            "            yield self._check_signature(event, context)",
            "            member_handler = self.hs.get_room_member_handler()",
            "            yield member_handler.send_membership_event(None, event, context)",
            "        else:",
            "            destinations = set(x.split(\":\", 1)[-1] for x in (sender_user_id, room_id))",
            "            yield self.federation_client.forward_third_party_invite(",
            "                destinations, room_id, event_dict",
            "            )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_exchange_third_party_invite_request(self, room_id, event_dict):",
            "        \"\"\"Handle an exchange_third_party_invite request from a remote server",
            "",
            "        The remote server will call this when it wants to turn a 3pid invite",
            "        into a normal m.room.member invite.",
            "",
            "        Args:",
            "            room_id (str): The ID of the room.",
            "",
            "            event_dict (dict[str, Any]): Dictionary containing the event body.",
            "",
            "        Returns:",
            "            Deferred: resolves (to None)",
            "        \"\"\"",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        # NB: event_dict has a particular specced format we might need to fudge",
            "        # if we change event formats too much.",
            "        builder = self.event_builder_factory.new(room_version, event_dict)",
            "",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.warning(",
            "                \"Exchange of threepid invite %s forbidden by third-party rules\", event",
            "            )",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        event, context = yield self.add_display_name_to_third_party_invite(",
            "            room_version, event_dict, event, context",
            "        )",
            "",
            "        try:",
            "            yield self.auth.check_from_context(room_version, event, context)",
            "        except AuthError as e:",
            "            logger.warn(\"Denying third party invite %r because %s\", event, e)",
            "            raise e",
            "        yield self._check_signature(event, context)",
            "",
            "        # We need to tell the transaction queue to send this out, even",
            "        # though the sender isn't a local user.",
            "        event.internal_metadata.send_on_behalf_of = get_domain_from_id(event.sender)",
            "",
            "        member_handler = self.hs.get_room_member_handler()",
            "        yield member_handler.send_membership_event(None, event, context)",
            "",
            "    @defer.inlineCallbacks",
            "    def add_display_name_to_third_party_invite(",
            "        self, room_version, event_dict, event, context",
            "    ):",
            "        key = (",
            "            EventTypes.ThirdPartyInvite,",
            "            event.content[\"third_party_invite\"][\"signed\"][\"token\"],",
            "        )",
            "        original_invite = None",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        original_invite_id = prev_state_ids.get(key)",
            "        if original_invite_id:",
            "            original_invite = yield self.store.get_event(",
            "                original_invite_id, allow_none=True",
            "            )",
            "        if original_invite:",
            "            # If the m.room.third_party_invite event's content is empty, it means the",
            "            # invite has been revoked. In this case, we don't have to raise an error here",
            "            # because the auth check will fail on the invite (because it's not able to",
            "            # fetch public keys from the m.room.third_party_invite event's content, which",
            "            # is empty).",
            "            display_name = original_invite.content.get(\"display_name\")",
            "            event_dict[\"content\"][\"third_party_invite\"][\"display_name\"] = display_name",
            "        else:",
            "            logger.info(",
            "                \"Could not find invite event for third_party_invite: %r\", event_dict",
            "            )",
            "            # We don't discard here as this is not the appropriate place to do",
            "            # auth checks. If we need the invite and don't have it then the",
            "            # auth check code will explode appropriately.",
            "",
            "        builder = self.event_builder_factory.new(room_version, event_dict)",
            "        EventValidator().validate_builder(builder)",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "        EventValidator().validate_new(event)",
            "        return (event, context)",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_signature(self, event, context):",
            "        \"\"\"",
            "        Checks that the signature in the event is consistent with its invite.",
            "",
            "        Args:",
            "            event (Event): The m.room.member event to check",
            "            context (EventContext):",
            "",
            "        Raises:",
            "            AuthError: if signature didn't match any keys, or key has been",
            "                revoked,",
            "            SynapseError: if a transient error meant a key couldn't be checked",
            "                for revocation.",
            "        \"\"\"",
            "        signed = event.content[\"third_party_invite\"][\"signed\"]",
            "        token = signed[\"token\"]",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        invite_event_id = prev_state_ids.get((EventTypes.ThirdPartyInvite, token))",
            "",
            "        invite_event = None",
            "        if invite_event_id:",
            "            invite_event = yield self.store.get_event(invite_event_id, allow_none=True)",
            "",
            "        if not invite_event:",
            "            raise AuthError(403, \"Could not find invite\")",
            "",
            "        logger.debug(\"Checking auth on event %r\", event.content)",
            "",
            "        last_exception = None",
            "        # for each public key in the 3pid invite event",
            "        for public_key_object in self.hs.get_auth().get_public_keys(invite_event):",
            "            try:",
            "                # for each sig on the third_party_invite block of the actual invite",
            "                for server, signature_block in signed[\"signatures\"].items():",
            "                    for key_name, encoded_signature in signature_block.items():",
            "                        if not key_name.startswith(\"ed25519:\"):",
            "                            continue",
            "",
            "                        logger.debug(",
            "                            \"Attempting to verify sig with key %s from %r \"",
            "                            \"against pubkey %r\",",
            "                            key_name,",
            "                            server,",
            "                            public_key_object,",
            "                        )",
            "",
            "                        try:",
            "                            public_key = public_key_object[\"public_key\"]",
            "                            verify_key = decode_verify_key_bytes(",
            "                                key_name, decode_base64(public_key)",
            "                            )",
            "                            verify_signed_json(signed, server, verify_key)",
            "                            logger.debug(",
            "                                \"Successfully verified sig with key %s from %r \"",
            "                                \"against pubkey %r\",",
            "                                key_name,",
            "                                server,",
            "                                public_key_object,",
            "                            )",
            "                        except Exception:",
            "                            logger.info(",
            "                                \"Failed to verify sig with key %s from %r \"",
            "                                \"against pubkey %r\",",
            "                                key_name,",
            "                                server,",
            "                                public_key_object,",
            "                            )",
            "                            raise",
            "                        try:",
            "                            if \"key_validity_url\" in public_key_object:",
            "                                yield self._check_key_revocation(",
            "                                    public_key, public_key_object[\"key_validity_url\"]",
            "                                )",
            "                        except Exception:",
            "                            logger.info(",
            "                                \"Failed to query key_validity_url %s\",",
            "                                public_key_object[\"key_validity_url\"],",
            "                            )",
            "                            raise",
            "                        return",
            "            except Exception as e:",
            "                last_exception = e",
            "        raise last_exception",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_key_revocation(self, public_key, url):",
            "        \"\"\"",
            "        Checks whether public_key has been revoked.",
            "",
            "        Args:",
            "            public_key (str): base-64 encoded public key.",
            "            url (str): Key revocation URL.",
            "",
            "        Raises:",
            "            AuthError: if they key has been revoked.",
            "            SynapseError: if a transient error meant a key couldn't be checked",
            "                for revocation.",
            "        \"\"\"",
            "        try:",
            "            response = yield self.http_client.get_json(url, {\"public_key\": public_key})",
            "        except Exception:",
            "            raise SynapseError(502, \"Third party certificate could not be checked\")",
            "        if \"valid\" not in response or not response[\"valid\"]:",
            "            raise AuthError(403, \"Third party certificate was invalid\")",
            "",
            "    @defer.inlineCallbacks",
            "    def persist_events_and_notify(self, event_and_contexts, backfilled=False):",
            "        \"\"\"Persists events and tells the notifier/pushers about them, if",
            "        necessary.",
            "",
            "        Args:",
            "            event_and_contexts(list[tuple[FrozenEvent, EventContext]])",
            "            backfilled (bool): Whether these events are a result of",
            "                backfilling or not",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            yield self._send_events_to_master(",
            "                store=self.store,",
            "                event_and_contexts=event_and_contexts,",
            "                backfilled=backfilled,",
            "            )",
            "        else:",
            "            max_stream_id = yield self.store.persist_events(",
            "                event_and_contexts, backfilled=backfilled",
            "            )",
            "",
            "            if not backfilled:  # Never notify for backfilled events",
            "                for event, _ in event_and_contexts:",
            "                    yield self._notify_persisted_event(event, max_stream_id)",
            "",
            "    def _notify_persisted_event(self, event, max_stream_id):",
            "        \"\"\"Checks to see if notifier/pushers should be notified about the",
            "        event or not.",
            "",
            "        Args:",
            "            event (FrozenEvent)",
            "            max_stream_id (int): The max_stream_id returned by persist_events",
            "        \"\"\"",
            "",
            "        extra_users = []",
            "        if event.type == EventTypes.Member:",
            "            target_user_id = event.state_key",
            "",
            "            # We notify for memberships if its an invite for one of our",
            "            # users",
            "            if event.internal_metadata.is_outlier():",
            "                if event.membership != Membership.INVITE:",
            "                    if not self.is_mine_id(target_user_id):",
            "                        return",
            "",
            "            target_user = UserID.from_string(target_user_id)",
            "            extra_users.append(target_user)",
            "        elif event.internal_metadata.is_outlier():",
            "            return",
            "",
            "        event_stream_id = event.internal_metadata.stream_ordering",
            "        self.notifier.on_new_room_event(",
            "            event, event_stream_id, max_stream_id, extra_users=extra_users",
            "        )",
            "",
            "        return self.pusher_pool.on_new_notifications(event_stream_id, max_stream_id)",
            "",
            "    def _clean_room_for_join(self, room_id):",
            "        \"\"\"Called to clean up any data in DB for a given room, ready for the",
            "        server to join the room.",
            "",
            "        Args:",
            "            room_id (str)",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            return self._clean_room_for_join_client(room_id)",
            "        else:",
            "            return self.store.clean_room_for_join(room_id)",
            "",
            "    def user_joined_room(self, user, room_id):",
            "        \"\"\"Called when a new user has joined the room",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            return self._notify_user_membership_change(",
            "                room_id=room_id, user_id=user.to_string(), change=\"joined\"",
            "            )",
            "        else:",
            "            return user_joined_room(self.distributor, user, room_id)",
            "",
            "    @defer.inlineCallbacks",
            "    def get_room_complexity(self, remote_room_hosts, room_id):",
            "        \"\"\"",
            "        Fetch the complexity of a remote room over federation.",
            "",
            "        Args:",
            "            remote_room_hosts (list[str]): The remote servers to ask.",
            "            room_id (str): The room ID to ask about.",
            "",
            "        Returns:",
            "            Deferred[dict] or Deferred[None]: Dict contains the complexity",
            "            metric versions, while None means we could not fetch the complexity.",
            "        \"\"\"",
            "",
            "        for host in remote_room_hosts:",
            "            res = yield self.federation_client.get_room_complexity(host, room_id)",
            "",
            "            # We got a result, return it.",
            "            if res:",
            "                defer.returnValue(res)",
            "",
            "        # We fell off the bottom, couldn't get the complexity from anyone. Oh",
            "        # well.",
            "        defer.returnValue(None)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# Copyright 2014-2016 OpenMarket Ltd",
            "# Copyright 2017-2018 New Vector Ltd",
            "# Copyright 2019 The Matrix.org Foundation C.I.C.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Contains handlers for federation events.\"\"\"",
            "",
            "import itertools",
            "import logging",
            "",
            "import six",
            "from six import iteritems, itervalues",
            "from six.moves import http_client, zip",
            "",
            "from signedjson.key import decode_verify_key_bytes",
            "from signedjson.sign import verify_signed_json",
            "from unpaddedbase64 import decode_base64",
            "",
            "from twisted.internet import defer",
            "",
            "from synapse import event_auth",
            "from synapse.api.constants import EventTypes, Membership, RejectedReason",
            "from synapse.api.errors import (",
            "    AuthError,",
            "    CodeMessageException,",
            "    Codes,",
            "    FederationDeniedError,",
            "    FederationError,",
            "    RequestSendFailed,",
            "    StoreError,",
            "    SynapseError,",
            ")",
            "from synapse.api.room_versions import KNOWN_ROOM_VERSIONS, RoomVersions",
            "from synapse.crypto.event_signing import compute_event_signature",
            "from synapse.event_auth import auth_types_for_event",
            "from synapse.events.validator import EventValidator",
            "from synapse.logging.context import (",
            "    make_deferred_yieldable,",
            "    nested_logging_context,",
            "    preserve_fn,",
            "    run_in_background,",
            ")",
            "from synapse.logging.utils import log_function",
            "from synapse.replication.http.federation import (",
            "    ReplicationCleanRoomRestServlet,",
            "    ReplicationFederationSendEventsRestServlet,",
            ")",
            "from synapse.replication.http.membership import ReplicationUserJoinedLeftRoomRestServlet",
            "from synapse.state import StateResolutionStore, resolve_events_with_store",
            "from synapse.types import UserID, get_domain_from_id",
            "from synapse.util import unwrapFirstError",
            "from synapse.util.async_helpers import Linearizer",
            "from synapse.util.distributor import user_joined_room",
            "from synapse.util.retryutils import NotRetryingDestination",
            "from synapse.visibility import filter_events_for_server",
            "",
            "from ._base import BaseHandler",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def shortstr(iterable, maxitems=5):",
            "    \"\"\"If iterable has maxitems or fewer, return the stringification of a list",
            "    containing those items.",
            "",
            "    Otherwise, return the stringification of a a list with the first maxitems items,",
            "    followed by \"...\".",
            "",
            "    Args:",
            "        iterable (Iterable): iterable to truncate",
            "        maxitems (int): number of items to return before truncating",
            "",
            "    Returns:",
            "        unicode",
            "    \"\"\"",
            "",
            "    items = list(itertools.islice(iterable, maxitems + 1))",
            "    if len(items) <= maxitems:",
            "        return str(items)",
            "    return \"[\" + \", \".join(repr(r) for r in items[:maxitems]) + \", ...]\"",
            "",
            "",
            "class FederationHandler(BaseHandler):",
            "    \"\"\"Handles events that originated from federation.",
            "        Responsible for:",
            "        a) handling received Pdus before handing them on as Events to the rest",
            "        of the home server (including auth and state conflict resoultion)",
            "        b) converting events that were produced by local clients that may need",
            "        to be sent to remote home servers.",
            "        c) doing the necessary dances to invite remote users and join remote",
            "        rooms.",
            "    \"\"\"",
            "",
            "    def __init__(self, hs):",
            "        super(FederationHandler, self).__init__(hs)",
            "",
            "        self.hs = hs",
            "",
            "        self.store = hs.get_datastore()",
            "        self.federation_client = hs.get_federation_client()",
            "        self.state_handler = hs.get_state_handler()",
            "        self.server_name = hs.hostname",
            "        self.keyring = hs.get_keyring()",
            "        self.action_generator = hs.get_action_generator()",
            "        self.is_mine_id = hs.is_mine_id",
            "        self.pusher_pool = hs.get_pusherpool()",
            "        self.spam_checker = hs.get_spam_checker()",
            "        self.event_creation_handler = hs.get_event_creation_handler()",
            "        self._server_notices_mxid = hs.config.server_notices_mxid",
            "        self.config = hs.config",
            "        self.http_client = hs.get_simple_http_client()",
            "",
            "        self._send_events_to_master = ReplicationFederationSendEventsRestServlet.make_client(",
            "            hs",
            "        )",
            "        self._notify_user_membership_change = ReplicationUserJoinedLeftRoomRestServlet.make_client(",
            "            hs",
            "        )",
            "        self._clean_room_for_join_client = ReplicationCleanRoomRestServlet.make_client(",
            "            hs",
            "        )",
            "",
            "        # When joining a room we need to queue any events for that room up",
            "        self.room_queues = {}",
            "        self._room_pdu_linearizer = Linearizer(\"fed_room_pdu\")",
            "",
            "        self.third_party_event_rules = hs.get_third_party_event_rules()",
            "",
            "    @defer.inlineCallbacks",
            "    def on_receive_pdu(self, origin, pdu, sent_to_us_directly=False):",
            "        \"\"\" Process a PDU received via a federation /send/ transaction, or",
            "        via backfill of missing prev_events",
            "",
            "        Args:",
            "            origin (str): server which initiated the /send/ transaction. Will",
            "                be used to fetch missing events or state.",
            "            pdu (FrozenEvent): received PDU",
            "            sent_to_us_directly (bool): True if this event was pushed to us; False if",
            "                we pulled it as the result of a missing prev_event.",
            "",
            "        Returns (Deferred): completes with None",
            "        \"\"\"",
            "",
            "        room_id = pdu.room_id",
            "        event_id = pdu.event_id",
            "",
            "        logger.info(\"[%s %s] handling received PDU: %s\", room_id, event_id, pdu)",
            "",
            "        # We reprocess pdus when we have seen them only as outliers",
            "        existing = yield self.store.get_event(",
            "            event_id, allow_none=True, allow_rejected=True",
            "        )",
            "",
            "        # FIXME: Currently we fetch an event again when we already have it",
            "        # if it has been marked as an outlier.",
            "",
            "        already_seen = existing and (",
            "            not existing.internal_metadata.is_outlier()",
            "            or pdu.internal_metadata.is_outlier()",
            "        )",
            "        if already_seen:",
            "            logger.debug(\"[%s %s]: Already seen pdu\", room_id, event_id)",
            "            return",
            "",
            "        # do some initial sanity-checking of the event. In particular, make",
            "        # sure it doesn't have hundreds of prev_events or auth_events, which",
            "        # could cause a huge state resolution or cascade of event fetches.",
            "        try:",
            "            self._sanity_check_event(pdu)",
            "        except SynapseError as err:",
            "            logger.warn(",
            "                \"[%s %s] Received event failed sanity checks\", room_id, event_id",
            "            )",
            "            raise FederationError(\"ERROR\", err.code, err.msg, affected=pdu.event_id)",
            "",
            "        # If we are currently in the process of joining this room, then we",
            "        # queue up events for later processing.",
            "        if room_id in self.room_queues:",
            "            logger.info(",
            "                \"[%s %s] Queuing PDU from %s for now: join in progress\",",
            "                room_id,",
            "                event_id,",
            "                origin,",
            "            )",
            "            self.room_queues[room_id].append((pdu, origin))",
            "            return",
            "",
            "        # If we're not in the room just ditch the event entirely. This is",
            "        # probably an old server that has come back and thinks we're still in",
            "        # the room (or we've been rejoined to the room by a state reset).",
            "        #",
            "        # Note that if we were never in the room then we would have already",
            "        # dropped the event, since we wouldn't know the room version.",
            "        is_in_room = yield self.auth.check_host_in_room(room_id, self.server_name)",
            "        if not is_in_room:",
            "            logger.info(",
            "                \"[%s %s] Ignoring PDU from %s as we're not in the room\",",
            "                room_id,",
            "                event_id,",
            "                origin,",
            "            )",
            "            return None",
            "",
            "        state = None",
            "        auth_chain = []",
            "",
            "        # Get missing pdus if necessary.",
            "        if not pdu.internal_metadata.is_outlier():",
            "            # We only backfill backwards to the min depth.",
            "            min_depth = yield self.get_min_depth_for_context(pdu.room_id)",
            "",
            "            logger.debug(\"[%s %s] min_depth: %d\", room_id, event_id, min_depth)",
            "",
            "            prevs = set(pdu.prev_event_ids())",
            "            seen = yield self.store.have_seen_events(prevs)",
            "",
            "            if min_depth and pdu.depth < min_depth:",
            "                # This is so that we don't notify the user about this",
            "                # message, to work around the fact that some events will",
            "                # reference really really old events we really don't want to",
            "                # send to the clients.",
            "                pdu.internal_metadata.outlier = True",
            "            elif min_depth and pdu.depth > min_depth:",
            "                missing_prevs = prevs - seen",
            "                if sent_to_us_directly and missing_prevs:",
            "                    # If we're missing stuff, ensure we only fetch stuff one",
            "                    # at a time.",
            "                    logger.info(",
            "                        \"[%s %s] Acquiring room lock to fetch %d missing prev_events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(missing_prevs),",
            "                        shortstr(missing_prevs),",
            "                    )",
            "                    with (yield self._room_pdu_linearizer.queue(pdu.room_id)):",
            "                        logger.info(",
            "                            \"[%s %s] Acquired room lock to fetch %d missing prev_events\",",
            "                            room_id,",
            "                            event_id,",
            "                            len(missing_prevs),",
            "                        )",
            "",
            "                        yield self._get_missing_events_for_pdu(",
            "                            origin, pdu, prevs, min_depth",
            "                        )",
            "",
            "                        # Update the set of things we've seen after trying to",
            "                        # fetch the missing stuff",
            "                        seen = yield self.store.have_seen_events(prevs)",
            "",
            "                        if not prevs - seen:",
            "                            logger.info(",
            "                                \"[%s %s] Found all missing prev_events\",",
            "                                room_id,",
            "                                event_id,",
            "                            )",
            "                elif missing_prevs:",
            "                    logger.info(",
            "                        \"[%s %s] Not recursively fetching %d missing prev_events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(missing_prevs),",
            "                        shortstr(missing_prevs),",
            "                    )",
            "",
            "            if prevs - seen:",
            "                # We've still not been able to get all of the prev_events for this event.",
            "                #",
            "                # In this case, we need to fall back to asking another server in the",
            "                # federation for the state at this event. That's ok provided we then",
            "                # resolve the state against other bits of the DAG before using it (which",
            "                # will ensure that you can't just take over a room by sending an event,",
            "                # withholding its prev_events, and declaring yourself to be an admin in",
            "                # the subsequent state request).",
            "                #",
            "                # Now, if we're pulling this event as a missing prev_event, then clearly",
            "                # this event is not going to become the only forward-extremity and we are",
            "                # guaranteed to resolve its state against our existing forward",
            "                # extremities, so that should be fine.",
            "                #",
            "                # On the other hand, if this event was pushed to us, it is possible for",
            "                # it to become the only forward-extremity in the room, and we would then",
            "                # trust its state to be the state for the whole room. This is very bad.",
            "                # Further, if the event was pushed to us, there is no excuse for us not to",
            "                # have all the prev_events. We therefore reject any such events.",
            "                #",
            "                # XXX this really feels like it could/should be merged with the above,",
            "                # but there is an interaction with min_depth that I'm not really",
            "                # following.",
            "",
            "                if sent_to_us_directly:",
            "                    logger.warn(",
            "                        \"[%s %s] Rejecting: failed to fetch %d prev events: %s\",",
            "                        room_id,",
            "                        event_id,",
            "                        len(prevs - seen),",
            "                        shortstr(prevs - seen),",
            "                    )",
            "                    raise FederationError(",
            "                        \"ERROR\",",
            "                        403,",
            "                        (",
            "                            \"Your server isn't divulging details about prev_events \"",
            "                            \"referenced in this event.\"",
            "                        ),",
            "                        affected=pdu.event_id,",
            "                    )",
            "",
            "                # Calculate the state after each of the previous events, and",
            "                # resolve them to find the correct state at the current event.",
            "                auth_chains = set()",
            "                event_map = {event_id: pdu}",
            "                try:",
            "                    # Get the state of the events we know about",
            "                    ours = yield self.store.get_state_groups_ids(room_id, seen)",
            "",
            "                    # state_maps is a list of mappings from (type, state_key) to event_id",
            "                    state_maps = list(",
            "                        ours.values()",
            "                    )  # type: list[dict[tuple[str, str], str]]",
            "",
            "                    # we don't need this any more, let's delete it.",
            "                    del ours",
            "",
            "                    # Ask the remote server for the states we don't",
            "                    # know about",
            "                    for p in prevs - seen:",
            "                        logger.info(",
            "                            \"[%s %s] Requesting state at missing prev_event %s\",",
            "                            room_id,",
            "                            event_id,",
            "                            p,",
            "                        )",
            "",
            "                        room_version = yield self.store.get_room_version(room_id)",
            "",
            "                        with nested_logging_context(p):",
            "                            # note that if any of the missing prevs share missing state or",
            "                            # auth events, the requests to fetch those events are deduped",
            "                            # by the get_pdu_cache in federation_client.",
            "                            remote_state, got_auth_chain = (",
            "                                yield self.federation_client.get_state_for_room(",
            "                                    origin, room_id, p",
            "                                )",
            "                            )",
            "",
            "                            # we want the state *after* p; get_state_for_room returns the",
            "                            # state *before* p.",
            "                            remote_event = yield self.federation_client.get_pdu(",
            "                                [origin], p, room_version, outlier=True",
            "                            )",
            "",
            "                            if remote_event is None:",
            "                                raise Exception(",
            "                                    \"Unable to get missing prev_event %s\" % (p,)",
            "                                )",
            "",
            "                            if remote_event.is_state():",
            "                                remote_state.append(remote_event)",
            "",
            "                            # XXX hrm I'm not convinced that duplicate events will compare",
            "                            # for equality, so I'm not sure this does what the author",
            "                            # hoped.",
            "                            auth_chains.update(got_auth_chain)",
            "",
            "                            remote_state_map = {",
            "                                (x.type, x.state_key): x.event_id for x in remote_state",
            "                            }",
            "                            state_maps.append(remote_state_map)",
            "",
            "                            for x in remote_state:",
            "                                event_map[x.event_id] = x",
            "",
            "                    state_map = yield resolve_events_with_store(",
            "                        room_version,",
            "                        state_maps,",
            "                        event_map,",
            "                        state_res_store=StateResolutionStore(self.store),",
            "                    )",
            "",
            "                    # We need to give _process_received_pdu the actual state events",
            "                    # rather than event ids, so generate that now.",
            "",
            "                    # First though we need to fetch all the events that are in",
            "                    # state_map, so we can build up the state below.",
            "                    evs = yield self.store.get_events(",
            "                        list(state_map.values()),",
            "                        get_prev_content=False,",
            "                        check_redacted=False,",
            "                    )",
            "                    event_map.update(evs)",
            "",
            "                    state = [event_map[e] for e in six.itervalues(state_map)]",
            "                    auth_chain = list(auth_chains)",
            "                except Exception:",
            "                    logger.warn(",
            "                        \"[%s %s] Error attempting to resolve state at missing \"",
            "                        \"prev_events\",",
            "                        room_id,",
            "                        event_id,",
            "                        exc_info=True,",
            "                    )",
            "                    raise FederationError(",
            "                        \"ERROR\",",
            "                        403,",
            "                        \"We can't get valid state history.\",",
            "                        affected=event_id,",
            "                    )",
            "",
            "        yield self._process_received_pdu(",
            "            origin, pdu, state=state, auth_chain=auth_chain",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _get_missing_events_for_pdu(self, origin, pdu, prevs, min_depth):",
            "        \"\"\"",
            "        Args:",
            "            origin (str): Origin of the pdu. Will be called to get the missing events",
            "            pdu: received pdu",
            "            prevs (set(str)): List of event ids which we are missing",
            "            min_depth (int): Minimum depth of events to return.",
            "        \"\"\"",
            "",
            "        room_id = pdu.room_id",
            "        event_id = pdu.event_id",
            "",
            "        seen = yield self.store.have_seen_events(prevs)",
            "",
            "        if not prevs - seen:",
            "            return",
            "",
            "        latest = yield self.store.get_latest_event_ids_in_room(room_id)",
            "",
            "        # We add the prev events that we have seen to the latest",
            "        # list to ensure the remote server doesn't give them to us",
            "        latest = set(latest)",
            "        latest |= seen",
            "",
            "        logger.info(",
            "            \"[%s %s]: Requesting missing events between %s and %s\",",
            "            room_id,",
            "            event_id,",
            "            shortstr(latest),",
            "            event_id,",
            "        )",
            "",
            "        # XXX: we set timeout to 10s to help workaround",
            "        # https://github.com/matrix-org/synapse/issues/1733.",
            "        # The reason is to avoid holding the linearizer lock",
            "        # whilst processing inbound /send transactions, causing",
            "        # FDs to stack up and block other inbound transactions",
            "        # which empirically can currently take up to 30 minutes.",
            "        #",
            "        # N.B. this explicitly disables retry attempts.",
            "        #",
            "        # N.B. this also increases our chances of falling back to",
            "        # fetching fresh state for the room if the missing event",
            "        # can't be found, which slightly reduces our security.",
            "        # it may also increase our DAG extremity count for the room,",
            "        # causing additional state resolution?  See #1760.",
            "        # However, fetching state doesn't hold the linearizer lock",
            "        # apparently.",
            "        #",
            "        # see https://github.com/matrix-org/synapse/pull/1744",
            "        #",
            "        # ----",
            "        #",
            "        # Update richvdh 2018/09/18: There are a number of problems with timing this",
            "        # request out agressively on the client side:",
            "        #",
            "        # - it plays badly with the server-side rate-limiter, which starts tarpitting you",
            "        #   if you send too many requests at once, so you end up with the server carefully",
            "        #   working through the backlog of your requests, which you have already timed",
            "        #   out.",
            "        #",
            "        # - for this request in particular, we now (as of",
            "        #   https://github.com/matrix-org/synapse/pull/3456) reject any PDUs where the",
            "        #   server can't produce a plausible-looking set of prev_events - so we becone",
            "        #   much more likely to reject the event.",
            "        #",
            "        # - contrary to what it says above, we do *not* fall back to fetching fresh state",
            "        #   for the room if get_missing_events times out. Rather, we give up processing",
            "        #   the PDU whose prevs we are missing, which then makes it much more likely that",
            "        #   we'll end up back here for the *next* PDU in the list, which exacerbates the",
            "        #   problem.",
            "        #",
            "        # - the agressive 10s timeout was introduced to deal with incoming federation",
            "        #   requests taking 8 hours to process. It's not entirely clear why that was going",
            "        #   on; certainly there were other issues causing traffic storms which are now",
            "        #   resolved, and I think in any case we may be more sensible about our locking",
            "        #   now. We're *certainly* more sensible about our logging.",
            "        #",
            "        # All that said: Let's try increasing the timout to 60s and see what happens.",
            "",
            "        try:",
            "            missing_events = yield self.federation_client.get_missing_events(",
            "                origin,",
            "                room_id,",
            "                earliest_events_ids=list(latest),",
            "                latest_events=[pdu],",
            "                limit=10,",
            "                min_depth=min_depth,",
            "                timeout=60000,",
            "            )",
            "        except RequestSendFailed as e:",
            "            # We failed to get the missing events, but since we need to handle",
            "            # the case of `get_missing_events` not returning the necessary",
            "            # events anyway, it is safe to simply log the error and continue.",
            "            logger.warn(\"[%s %s]: Failed to get prev_events: %s\", room_id, event_id, e)",
            "            return",
            "",
            "        logger.info(",
            "            \"[%s %s]: Got %d prev_events: %s\",",
            "            room_id,",
            "            event_id,",
            "            len(missing_events),",
            "            shortstr(missing_events),",
            "        )",
            "",
            "        # We want to sort these by depth so we process them and",
            "        # tell clients about them in order.",
            "        missing_events.sort(key=lambda x: x.depth)",
            "",
            "        for ev in missing_events:",
            "            logger.info(",
            "                \"[%s %s] Handling received prev_event %s\",",
            "                room_id,",
            "                event_id,",
            "                ev.event_id,",
            "            )",
            "            with nested_logging_context(ev.event_id):",
            "                try:",
            "                    yield self.on_receive_pdu(origin, ev, sent_to_us_directly=False)",
            "                except FederationError as e:",
            "                    if e.code == 403:",
            "                        logger.warn(",
            "                            \"[%s %s] Received prev_event %s failed history check.\",",
            "                            room_id,",
            "                            event_id,",
            "                            ev.event_id,",
            "                        )",
            "                    else:",
            "                        raise",
            "",
            "    @defer.inlineCallbacks",
            "    def _process_received_pdu(self, origin, event, state, auth_chain):",
            "        \"\"\" Called when we have a new pdu. We need to do auth checks and put it",
            "        through the StateHandler.",
            "        \"\"\"",
            "        room_id = event.room_id",
            "        event_id = event.event_id",
            "",
            "        logger.debug(\"[%s %s] Processing event: %s\", room_id, event_id, event)",
            "",
            "        event_ids = set()",
            "        if state:",
            "            event_ids |= {e.event_id for e in state}",
            "        if auth_chain:",
            "            event_ids |= {e.event_id for e in auth_chain}",
            "",
            "        seen_ids = yield self.store.have_seen_events(event_ids)",
            "",
            "        if state and auth_chain is not None:",
            "            # If we have any state or auth_chain given to us by the replication",
            "            # layer, then we should handle them (if we haven't before.)",
            "",
            "            event_infos = []",
            "",
            "            for e in itertools.chain(auth_chain, state):",
            "                if e.event_id in seen_ids:",
            "                    continue",
            "                e.internal_metadata.outlier = True",
            "                auth_ids = e.auth_event_ids()",
            "                auth = {",
            "                    (e.type, e.state_key): e",
            "                    for e in auth_chain",
            "                    if e.event_id in auth_ids or e.type == EventTypes.Create",
            "                }",
            "                event_infos.append({\"event\": e, \"auth_events\": auth})",
            "                seen_ids.add(e.event_id)",
            "",
            "            logger.info(",
            "                \"[%s %s] persisting newly-received auth/state events %s\",",
            "                room_id,",
            "                event_id,",
            "                [e[\"event\"].event_id for e in event_infos],",
            "            )",
            "            yield self._handle_new_events(origin, event_infos)",
            "",
            "        try:",
            "            context = yield self._handle_new_event(origin, event, state=state)",
            "        except AuthError as e:",
            "            raise FederationError(\"ERROR\", e.code, e.msg, affected=event.event_id)",
            "",
            "        room = yield self.store.get_room(room_id)",
            "",
            "        if not room:",
            "            try:",
            "                yield self.store.store_room(",
            "                    room_id=room_id, room_creator_user_id=\"\", is_public=False",
            "                )",
            "            except StoreError:",
            "                logger.exception(\"Failed to store room.\")",
            "",
            "        if event.type == EventTypes.Member:",
            "            if event.membership == Membership.JOIN:",
            "                # Only fire user_joined_room if the user has acutally",
            "                # joined the room. Don't bother if the user is just",
            "                # changing their profile info.",
            "                newly_joined = True",
            "",
            "                prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "",
            "                prev_state_id = prev_state_ids.get((event.type, event.state_key))",
            "                if prev_state_id:",
            "                    prev_state = yield self.store.get_event(",
            "                        prev_state_id, allow_none=True",
            "                    )",
            "                    if prev_state and prev_state.membership == Membership.JOIN:",
            "                        newly_joined = False",
            "",
            "                if newly_joined:",
            "                    user = UserID.from_string(event.state_key)",
            "                    yield self.user_joined_room(user, room_id)",
            "",
            "    @log_function",
            "    @defer.inlineCallbacks",
            "    def backfill(self, dest, room_id, limit, extremities):",
            "        \"\"\" Trigger a backfill request to `dest` for the given `room_id`",
            "",
            "        This will attempt to get more events from the remote. If the other side",
            "        has no new events to offer, this will return an empty list.",
            "",
            "        As the events are received, we check their signatures, and also do some",
            "        sanity-checking on them. If any of the backfilled events are invalid,",
            "        this method throws a SynapseError.",
            "",
            "        TODO: make this more useful to distinguish failures of the remote",
            "        server from invalid events (there is probably no point in trying to",
            "        re-fetch invalid events from every other HS in the room.)",
            "        \"\"\"",
            "        if dest == self.server_name:",
            "            raise SynapseError(400, \"Can't backfill from self.\")",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        events = yield self.federation_client.backfill(",
            "            dest, room_id, limit=limit, extremities=extremities",
            "        )",
            "",
            "        # ideally we'd sanity check the events here for excess prev_events etc,",
            "        # but it's hard to reject events at this point without completely",
            "        # breaking backfill in the same way that it is currently broken by",
            "        # events whose signature we cannot verify (#3121).",
            "        #",
            "        # So for now we accept the events anyway. #3124 tracks this.",
            "        #",
            "        # for ev in events:",
            "        #     self._sanity_check_event(ev)",
            "",
            "        # Don't bother processing events we already have.",
            "        seen_events = yield self.store.have_events_in_timeline(",
            "            set(e.event_id for e in events)",
            "        )",
            "",
            "        events = [e for e in events if e.event_id not in seen_events]",
            "",
            "        if not events:",
            "            return []",
            "",
            "        event_map = {e.event_id: e for e in events}",
            "",
            "        event_ids = set(e.event_id for e in events)",
            "",
            "        edges = [ev.event_id for ev in events if set(ev.prev_event_ids()) - event_ids]",
            "",
            "        logger.info(\"backfill: Got %d events with %d edges\", len(events), len(edges))",
            "",
            "        # For each edge get the current state.",
            "",
            "        auth_events = {}",
            "        state_events = {}",
            "        events_to_state = {}",
            "        for e_id in edges:",
            "            state, auth = yield self.federation_client.get_state_for_room(",
            "                destination=dest, room_id=room_id, event_id=e_id",
            "            )",
            "            auth_events.update({a.event_id: a for a in auth})",
            "            auth_events.update({s.event_id: s for s in state})",
            "            state_events.update({s.event_id: s for s in state})",
            "            events_to_state[e_id] = state",
            "",
            "        required_auth = set(",
            "            a_id",
            "            for event in events",
            "            + list(state_events.values())",
            "            + list(auth_events.values())",
            "            for a_id in event.auth_event_ids()",
            "        )",
            "        auth_events.update(",
            "            {e_id: event_map[e_id] for e_id in required_auth if e_id in event_map}",
            "        )",
            "        missing_auth = required_auth - set(auth_events)",
            "        failed_to_fetch = set()",
            "",
            "        # Try and fetch any missing auth events from both DB and remote servers.",
            "        # We repeatedly do this until we stop finding new auth events.",
            "        while missing_auth - failed_to_fetch:",
            "            logger.info(\"Missing auth for backfill: %r\", missing_auth)",
            "            ret_events = yield self.store.get_events(missing_auth - failed_to_fetch)",
            "            auth_events.update(ret_events)",
            "",
            "            required_auth.update(",
            "                a_id for event in ret_events.values() for a_id in event.auth_event_ids()",
            "            )",
            "            missing_auth = required_auth - set(auth_events)",
            "",
            "            if missing_auth - failed_to_fetch:",
            "                logger.info(",
            "                    \"Fetching missing auth for backfill: %r\",",
            "                    missing_auth - failed_to_fetch,",
            "                )",
            "",
            "                results = yield make_deferred_yieldable(",
            "                    defer.gatherResults(",
            "                        [",
            "                            run_in_background(",
            "                                self.federation_client.get_pdu,",
            "                                [dest],",
            "                                event_id,",
            "                                room_version=room_version,",
            "                                outlier=True,",
            "                                timeout=10000,",
            "                            )",
            "                            for event_id in missing_auth - failed_to_fetch",
            "                        ],",
            "                        consumeErrors=True,",
            "                    )",
            "                ).addErrback(unwrapFirstError)",
            "                auth_events.update({a.event_id: a for a in results if a})",
            "                required_auth.update(",
            "                    a_id",
            "                    for event in results",
            "                    if event",
            "                    for a_id in event.auth_event_ids()",
            "                )",
            "                missing_auth = required_auth - set(auth_events)",
            "",
            "                failed_to_fetch = missing_auth - set(auth_events)",
            "",
            "        seen_events = yield self.store.have_seen_events(",
            "            set(auth_events.keys()) | set(state_events.keys())",
            "        )",
            "",
            "        # We now have a chunk of events plus associated state and auth chain to",
            "        # persist. We do the persistence in two steps:",
            "        #   1. Auth events and state get persisted as outliers, plus the",
            "        #      backward extremities get persisted (as non-outliers).",
            "        #   2. The rest of the events in the chunk get persisted one by one, as",
            "        #      each one depends on the previous event for its state.",
            "        #",
            "        # The important thing is that events in the chunk get persisted as",
            "        # non-outliers, including when those events are also in the state or",
            "        # auth chain. Caution must therefore be taken to ensure that they are",
            "        # not accidentally marked as outliers.",
            "",
            "        # Step 1a: persist auth events that *don't* appear in the chunk",
            "        ev_infos = []",
            "        for a in auth_events.values():",
            "            # We only want to persist auth events as outliers that we haven't",
            "            # seen and aren't about to persist as part of the backfilled chunk.",
            "            if a.event_id in seen_events or a.event_id in event_map:",
            "                continue",
            "",
            "            a.internal_metadata.outlier = True",
            "            ev_infos.append(",
            "                {",
            "                    \"event\": a,",
            "                    \"auth_events\": {",
            "                        (",
            "                            auth_events[a_id].type,",
            "                            auth_events[a_id].state_key,",
            "                        ): auth_events[a_id]",
            "                        for a_id in a.auth_event_ids()",
            "                        if a_id in auth_events",
            "                    },",
            "                }",
            "            )",
            "",
            "        # Step 1b: persist the events in the chunk we fetched state for (i.e.",
            "        # the backwards extremities) as non-outliers.",
            "        for e_id in events_to_state:",
            "            # For paranoia we ensure that these events are marked as",
            "            # non-outliers",
            "            ev = event_map[e_id]",
            "            assert not ev.internal_metadata.is_outlier()",
            "",
            "            ev_infos.append(",
            "                {",
            "                    \"event\": ev,",
            "                    \"state\": events_to_state[e_id],",
            "                    \"auth_events\": {",
            "                        (",
            "                            auth_events[a_id].type,",
            "                            auth_events[a_id].state_key,",
            "                        ): auth_events[a_id]",
            "                        for a_id in ev.auth_event_ids()",
            "                        if a_id in auth_events",
            "                    },",
            "                }",
            "            )",
            "",
            "        yield self._handle_new_events(dest, ev_infos, backfilled=True)",
            "",
            "        # Step 2: Persist the rest of the events in the chunk one by one",
            "        events.sort(key=lambda e: e.depth)",
            "",
            "        for event in events:",
            "            if event in events_to_state:",
            "                continue",
            "",
            "            # For paranoia we ensure that these events are marked as",
            "            # non-outliers",
            "            assert not event.internal_metadata.is_outlier()",
            "",
            "            # We store these one at a time since each event depends on the",
            "            # previous to work out the state.",
            "            # TODO: We can probably do something more clever here.",
            "            yield self._handle_new_event(dest, event, backfilled=True)",
            "",
            "        return events",
            "",
            "    @defer.inlineCallbacks",
            "    def maybe_backfill(self, room_id, current_depth):",
            "        \"\"\"Checks the database to see if we should backfill before paginating,",
            "        and if so do.",
            "        \"\"\"",
            "        extremities = yield self.store.get_oldest_events_with_depth_in_room(room_id)",
            "",
            "        if not extremities:",
            "            logger.debug(\"Not backfilling as no extremeties found.\")",
            "            return",
            "",
            "        # We only want to paginate if we can actually see the events we'll get,",
            "        # as otherwise we'll just spend a lot of resources to get redacted",
            "        # events.",
            "        #",
            "        # We do this by filtering all the backwards extremities and seeing if",
            "        # any remain. Given we don't have the extremity events themselves, we",
            "        # need to actually check the events that reference them.",
            "        #",
            "        # *Note*: the spec wants us to keep backfilling until we reach the start",
            "        # of the room in case we are allowed to see some of the history. However",
            "        # in practice that causes more issues than its worth, as a) its",
            "        # relatively rare for there to be any visible history and b) even when",
            "        # there is its often sufficiently long ago that clients would stop",
            "        # attempting to paginate before backfill reached the visible history.",
            "        #",
            "        # TODO: If we do do a backfill then we should filter the backwards",
            "        #   extremities to only include those that point to visible portions of",
            "        #   history.",
            "        #",
            "        # TODO: Correctly handle the case where we are allowed to see the",
            "        #   forward event but not the backward extremity, e.g. in the case of",
            "        #   initial join of the server where we are allowed to see the join",
            "        #   event but not anything before it. This would require looking at the",
            "        #   state *before* the event, ignoring the special casing certain event",
            "        #   types have.",
            "",
            "        forward_events = yield self.store.get_successor_events(list(extremities))",
            "",
            "        extremities_events = yield self.store.get_events(",
            "            forward_events, check_redacted=False, get_prev_content=False",
            "        )",
            "",
            "        # We set `check_history_visibility_only` as we might otherwise get false",
            "        # positives from users having been erased.",
            "        filtered_extremities = yield filter_events_for_server(",
            "            self.store,",
            "            self.server_name,",
            "            list(extremities_events.values()),",
            "            redact=False,",
            "            check_history_visibility_only=True,",
            "        )",
            "",
            "        if not filtered_extremities:",
            "            return False",
            "",
            "        # Check if we reached a point where we should start backfilling.",
            "        sorted_extremeties_tuple = sorted(extremities.items(), key=lambda e: -int(e[1]))",
            "        max_depth = sorted_extremeties_tuple[0][1]",
            "",
            "        # We don't want to specify too many extremities as it causes the backfill",
            "        # request URI to be too long.",
            "        extremities = dict(sorted_extremeties_tuple[:5])",
            "",
            "        if current_depth > max_depth:",
            "            logger.debug(",
            "                \"Not backfilling as we don't need to. %d < %d\", max_depth, current_depth",
            "            )",
            "            return",
            "",
            "        # Now we need to decide which hosts to hit first.",
            "",
            "        # First we try hosts that are already in the room",
            "        # TODO: HEURISTIC ALERT.",
            "",
            "        curr_state = yield self.state_handler.get_current_state(room_id)",
            "",
            "        def get_domains_from_state(state):",
            "            \"\"\"Get joined domains from state",
            "",
            "            Args:",
            "                state (dict[tuple, FrozenEvent]): State map from type/state",
            "                    key to event.",
            "",
            "            Returns:",
            "                list[tuple[str, int]]: Returns a list of servers with the",
            "                lowest depth of their joins. Sorted by lowest depth first.",
            "            \"\"\"",
            "            joined_users = [",
            "                (state_key, int(event.depth))",
            "                for (e_type, state_key), event in iteritems(state)",
            "                if e_type == EventTypes.Member and event.membership == Membership.JOIN",
            "            ]",
            "",
            "            joined_domains = {}",
            "            for u, d in joined_users:",
            "                try:",
            "                    dom = get_domain_from_id(u)",
            "                    old_d = joined_domains.get(dom)",
            "                    if old_d:",
            "                        joined_domains[dom] = min(d, old_d)",
            "                    else:",
            "                        joined_domains[dom] = d",
            "                except Exception:",
            "                    pass",
            "",
            "            return sorted(joined_domains.items(), key=lambda d: d[1])",
            "",
            "        curr_domains = get_domains_from_state(curr_state)",
            "",
            "        likely_domains = [",
            "            domain for domain, depth in curr_domains if domain != self.server_name",
            "        ]",
            "",
            "        @defer.inlineCallbacks",
            "        def try_backfill(domains):",
            "            # TODO: Should we try multiple of these at a time?",
            "            for dom in domains:",
            "                try:",
            "                    yield self.backfill(",
            "                        dom, room_id, limit=100, extremities=extremities",
            "                    )",
            "                    # If this succeeded then we probably already have the",
            "                    # appropriate stuff.",
            "                    # TODO: We can probably do something more intelligent here.",
            "                    return True",
            "                except SynapseError as e:",
            "                    logger.info(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except CodeMessageException as e:",
            "                    if 400 <= e.code < 500:",
            "                        raise",
            "",
            "                    logger.info(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except NotRetryingDestination as e:",
            "                    logger.info(str(e))",
            "                    continue",
            "                except RequestSendFailed as e:",
            "                    logger.info(\"Falied to get backfill from %s because %s\", dom, e)",
            "                    continue",
            "                except FederationDeniedError as e:",
            "                    logger.info(e)",
            "                    continue",
            "                except Exception as e:",
            "                    logger.exception(\"Failed to backfill from %s because %s\", dom, e)",
            "                    continue",
            "",
            "            return False",
            "",
            "        success = yield try_backfill(likely_domains)",
            "        if success:",
            "            return True",
            "",
            "        # Huh, well *those* domains didn't work out. Lets try some domains",
            "        # from the time.",
            "",
            "        tried_domains = set(likely_domains)",
            "        tried_domains.add(self.server_name)",
            "",
            "        event_ids = list(extremities.keys())",
            "",
            "        logger.debug(\"calling resolve_state_groups in _maybe_backfill\")",
            "        resolve = preserve_fn(self.state_handler.resolve_state_groups_for_events)",
            "        states = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [resolve(room_id, [e]) for e in event_ids], consumeErrors=True",
            "            )",
            "        )",
            "",
            "        # dict[str, dict[tuple, str]], a map from event_id to state map of",
            "        # event_ids.",
            "        states = dict(zip(event_ids, [s.state for s in states]))",
            "",
            "        state_map = yield self.store.get_events(",
            "            [e_id for ids in itervalues(states) for e_id in itervalues(ids)],",
            "            get_prev_content=False,",
            "        )",
            "        states = {",
            "            key: {",
            "                k: state_map[e_id]",
            "                for k, e_id in iteritems(state_dict)",
            "                if e_id in state_map",
            "            }",
            "            for key, state_dict in iteritems(states)",
            "        }",
            "",
            "        for e_id, _ in sorted_extremeties_tuple:",
            "            likely_domains = get_domains_from_state(states[e_id])",
            "",
            "            success = yield try_backfill(",
            "                [dom for dom, _ in likely_domains if dom not in tried_domains]",
            "            )",
            "            if success:",
            "                return True",
            "",
            "            tried_domains.update(dom for dom, _ in likely_domains)",
            "",
            "        return False",
            "",
            "    def _sanity_check_event(self, ev):",
            "        \"\"\"",
            "        Do some early sanity checks of a received event",
            "",
            "        In particular, checks it doesn't have an excessive number of",
            "        prev_events or auth_events, which could cause a huge state resolution",
            "        or cascade of event fetches.",
            "",
            "        Args:",
            "            ev (synapse.events.EventBase): event to be checked",
            "",
            "        Returns: None",
            "",
            "        Raises:",
            "            SynapseError if the event does not pass muster",
            "        \"\"\"",
            "        if len(ev.prev_event_ids()) > 20:",
            "            logger.warn(",
            "                \"Rejecting event %s which has %i prev_events\",",
            "                ev.event_id,",
            "                len(ev.prev_event_ids()),",
            "            )",
            "            raise SynapseError(http_client.BAD_REQUEST, \"Too many prev_events\")",
            "",
            "        if len(ev.auth_event_ids()) > 10:",
            "            logger.warn(",
            "                \"Rejecting event %s which has %i auth_events\",",
            "                ev.event_id,",
            "                len(ev.auth_event_ids()),",
            "            )",
            "            raise SynapseError(http_client.BAD_REQUEST, \"Too many auth_events\")",
            "",
            "    @defer.inlineCallbacks",
            "    def send_invite(self, target_host, event):",
            "        \"\"\" Sends the invite to the remote server for signing.",
            "",
            "        Invites must be signed by the invitee's server before distribution.",
            "        \"\"\"",
            "        pdu = yield self.federation_client.send_invite(",
            "            destination=target_host,",
            "            room_id=event.room_id,",
            "            event_id=event.event_id,",
            "            pdu=event,",
            "        )",
            "",
            "        return pdu",
            "",
            "    @defer.inlineCallbacks",
            "    def on_event_auth(self, event_id):",
            "        event = yield self.store.get_event(event_id)",
            "        auth = yield self.store.get_auth_chain(",
            "            [auth_id for auth_id in event.auth_event_ids()], include_given=True",
            "        )",
            "        return [e for e in auth]",
            "",
            "    @log_function",
            "    @defer.inlineCallbacks",
            "    def do_invite_join(self, target_hosts, room_id, joinee, content):",
            "        \"\"\" Attempts to join the `joinee` to the room `room_id` via the",
            "        server `target_host`.",
            "",
            "        This first triggers a /make_join/ request that returns a partial",
            "        event that we can fill out and sign. This is then sent to the",
            "        remote server via /send_join/ which responds with the state at that",
            "        event and the auth_chains.",
            "",
            "        We suspend processing of any received events from this room until we",
            "        have finished processing the join.",
            "        \"\"\"",
            "        logger.debug(\"Joining %s to %s\", joinee, room_id)",
            "",
            "        origin, event, event_format_version = yield self._make_and_verify_event(",
            "            target_hosts,",
            "            room_id,",
            "            joinee,",
            "            \"join\",",
            "            content,",
            "            params={\"ver\": KNOWN_ROOM_VERSIONS},",
            "        )",
            "",
            "        # This shouldn't happen, because the RoomMemberHandler has a",
            "        # linearizer lock which only allows one operation per user per room",
            "        # at a time - so this is just paranoia.",
            "        assert room_id not in self.room_queues",
            "",
            "        self.room_queues[room_id] = []",
            "",
            "        yield self._clean_room_for_join(room_id)",
            "",
            "        handled_events = set()",
            "",
            "        try:",
            "            # Try the host we successfully got a response to /make_join/",
            "            # request first.",
            "            try:",
            "                target_hosts.remove(origin)",
            "                target_hosts.insert(0, origin)",
            "            except ValueError:",
            "                pass",
            "            ret = yield self.federation_client.send_join(",
            "                target_hosts, event, event_format_version",
            "            )",
            "",
            "            origin = ret[\"origin\"]",
            "            state = ret[\"state\"]",
            "            auth_chain = ret[\"auth_chain\"]",
            "            auth_chain.sort(key=lambda e: e.depth)",
            "",
            "            handled_events.update([s.event_id for s in state])",
            "            handled_events.update([a.event_id for a in auth_chain])",
            "            handled_events.add(event.event_id)",
            "",
            "            logger.debug(\"do_invite_join auth_chain: %s\", auth_chain)",
            "            logger.debug(\"do_invite_join state: %s\", state)",
            "",
            "            logger.debug(\"do_invite_join event: %s\", event)",
            "",
            "            try:",
            "                yield self.store.store_room(",
            "                    room_id=room_id, room_creator_user_id=\"\", is_public=False",
            "                )",
            "            except Exception:",
            "                # FIXME",
            "                pass",
            "",
            "            yield self._persist_auth_tree(origin, auth_chain, state, event)",
            "",
            "            logger.debug(\"Finished joining %s to %s\", joinee, room_id)",
            "        finally:",
            "            room_queue = self.room_queues[room_id]",
            "            del self.room_queues[room_id]",
            "",
            "            # we don't need to wait for the queued events to be processed -",
            "            # it's just a best-effort thing at this point. We do want to do",
            "            # them roughly in order, though, otherwise we'll end up making",
            "            # lots of requests for missing prev_events which we do actually",
            "            # have. Hence we fire off the deferred, but don't wait for it.",
            "",
            "            run_in_background(self._handle_queued_pdus, room_queue)",
            "",
            "        return True",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_queued_pdus(self, room_queue):",
            "        \"\"\"Process PDUs which got queued up while we were busy send_joining.",
            "",
            "        Args:",
            "            room_queue (list[FrozenEvent, str]): list of PDUs to be processed",
            "                and the servers that sent them",
            "        \"\"\"",
            "        for p, origin in room_queue:",
            "            try:",
            "                logger.info(",
            "                    \"Processing queued PDU %s which was received \"",
            "                    \"while we were joining %s\",",
            "                    p.event_id,",
            "                    p.room_id,",
            "                )",
            "                with nested_logging_context(p.event_id):",
            "                    yield self.on_receive_pdu(origin, p, sent_to_us_directly=True)",
            "            except Exception as e:",
            "                logger.warn(",
            "                    \"Error handling queued PDU %s from %s: %s\", p.event_id, origin, e",
            "                )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_make_join_request(self, origin, room_id, user_id):",
            "        \"\"\" We've received a /make_join/ request, so we create a partial",
            "        join event for the room and return that. We do *not* persist or",
            "        process it until the other server has signed it and sent it back.",
            "",
            "        Args:",
            "            origin (str): The (verified) server name of the requesting server.",
            "            room_id (str): Room to create join event in",
            "            user_id (str): The user to create the join for",
            "",
            "        Returns:",
            "            Deferred[FrozenEvent]",
            "        \"\"\"",
            "        if get_domain_from_id(user_id) != origin:",
            "            logger.info(",
            "                \"Got /make_join request for user %r from different origin %s, ignoring\",",
            "                user_id,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        event_content = {\"membership\": Membership.JOIN}",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        builder = self.event_builder_factory.new(",
            "            room_version,",
            "            {",
            "                \"type\": EventTypes.Member,",
            "                \"content\": event_content,",
            "                \"room_id\": room_id,",
            "                \"sender\": user_id,",
            "                \"state_key\": user_id,",
            "            },",
            "        )",
            "",
            "        try:",
            "            event, context = yield self.event_creation_handler.create_new_client_event(",
            "                builder=builder",
            "            )",
            "        except AuthError as e:",
            "            logger.warn(\"Failed to create join %r because %s\", event, e)",
            "            raise e",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Creation of join %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        # The remote hasn't signed it yet, obviously. We'll do the full checks",
            "        # when we get the event back in `on_send_join_request`",
            "        yield self.auth.check_from_context(",
            "            room_version, event, context, do_sig_check=False",
            "        )",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_send_join_request(self, origin, pdu):",
            "        \"\"\" We have received a join event for a room. Fully process it and",
            "        respond with the current state and auth chains.",
            "        \"\"\"",
            "        event = pdu",
            "",
            "        logger.debug(",
            "            \"on_send_join_request from %s: Got event: %s, signatures: %s\",",
            "            origin,",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        if get_domain_from_id(event.sender) != origin:",
            "            logger.info(",
            "                \"Got /send_join request for user %r from different origin %s\",",
            "                event.sender,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        event.internal_metadata.outlier = False",
            "        # Send this event on behalf of the origin server.",
            "        #",
            "        # The reasons we have the destination server rather than the origin",
            "        # server send it are slightly mysterious: the origin server should have",
            "        # all the neccessary state once it gets the response to the send_join,",
            "        # so it could send the event itself if it wanted to. It may be that",
            "        # doing it this way reduces failure modes, or avoids certain attacks",
            "        # where a new server selectively tells a subset of the federation that",
            "        # it has joined.",
            "        #",
            "        # The fact is that, as of the current writing, Synapse doesn't send out",
            "        # the join event over federation after joining, and changing it now",
            "        # would introduce the danger of backwards-compatibility problems.",
            "        event.internal_metadata.send_on_behalf_of = origin",
            "",
            "        context = yield self._handle_new_event(origin, event)",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Sending of join %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        logger.debug(",
            "            \"on_send_join_request: After _handle_new_event: %s, sigs: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        if event.type == EventTypes.Member:",
            "            if event.content[\"membership\"] == Membership.JOIN:",
            "                user = UserID.from_string(event.state_key)",
            "                yield self.user_joined_room(user, event.room_id)",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "",
            "        state_ids = list(prev_state_ids.values())",
            "        auth_chain = yield self.store.get_auth_chain(state_ids)",
            "",
            "        state = yield self.store.get_events(list(prev_state_ids.values()))",
            "",
            "        return {\"state\": list(state.values()), \"auth_chain\": auth_chain}",
            "",
            "    @defer.inlineCallbacks",
            "    def on_invite_request(self, origin, pdu):",
            "        \"\"\" We've got an invite event. Process and persist it. Sign it.",
            "",
            "        Respond with the now signed event.",
            "        \"\"\"",
            "        event = pdu",
            "",
            "        if event.state_key is None:",
            "            raise SynapseError(400, \"The invite event did not have a state key\")",
            "",
            "        is_blocked = yield self.store.is_room_blocked(event.room_id)",
            "        if is_blocked:",
            "            raise SynapseError(403, \"This room has been blocked on this server\")",
            "",
            "        if self.hs.config.block_non_admin_invites:",
            "            raise SynapseError(403, \"This server does not accept room invites\")",
            "",
            "        if not self.spam_checker.user_may_invite(",
            "            event.sender, event.state_key, event.room_id",
            "        ):",
            "            raise SynapseError(",
            "                403, \"This user is not permitted to send invites to this server/user\"",
            "            )",
            "",
            "        membership = event.content.get(\"membership\")",
            "        if event.type != EventTypes.Member or membership != Membership.INVITE:",
            "            raise SynapseError(400, \"The event was not an m.room.member invite event\")",
            "",
            "        sender_domain = get_domain_from_id(event.sender)",
            "        if sender_domain != origin:",
            "            raise SynapseError(",
            "                400, \"The invite event was not from the server sending it\"",
            "            )",
            "",
            "        if not self.is_mine_id(event.state_key):",
            "            raise SynapseError(400, \"The invite event must be for this server\")",
            "",
            "        # block any attempts to invite the server notices mxid",
            "        if event.state_key == self._server_notices_mxid:",
            "            raise SynapseError(http_client.FORBIDDEN, \"Cannot invite this user\")",
            "",
            "        event.internal_metadata.outlier = True",
            "        event.internal_metadata.out_of_band_membership = True",
            "",
            "        event.signatures.update(",
            "            compute_event_signature(",
            "                event.get_pdu_json(), self.hs.hostname, self.hs.config.signing_key[0]",
            "            )",
            "        )",
            "",
            "        context = yield self.state_handler.compute_event_context(event)",
            "        yield self.persist_events_and_notify([(event, context)])",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    def do_remotely_reject_invite(self, target_hosts, room_id, user_id):",
            "        origin, event, event_format_version = yield self._make_and_verify_event(",
            "            target_hosts, room_id, user_id, \"leave\"",
            "        )",
            "        # Mark as outlier as we don't have any state for this event; we're not",
            "        # even in the room.",
            "        event.internal_metadata.outlier = True",
            "        event.internal_metadata.out_of_band_membership = True",
            "",
            "        # Try the host that we succesfully called /make_leave/ on first for",
            "        # the /send_leave/ request.",
            "        try:",
            "            target_hosts.remove(origin)",
            "            target_hosts.insert(0, origin)",
            "        except ValueError:",
            "            pass",
            "",
            "        yield self.federation_client.send_leave(target_hosts, event)",
            "",
            "        context = yield self.state_handler.compute_event_context(event)",
            "        yield self.persist_events_and_notify([(event, context)])",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    def _make_and_verify_event(",
            "        self, target_hosts, room_id, user_id, membership, content={}, params=None",
            "    ):",
            "        origin, event, format_ver = yield self.federation_client.make_membership_event(",
            "            target_hosts, room_id, user_id, membership, content, params=params",
            "        )",
            "",
            "        logger.debug(\"Got response to make_%s: %s\", membership, event)",
            "",
            "        # We should assert some things.",
            "        # FIXME: Do this in a nicer way",
            "        assert event.type == EventTypes.Member",
            "        assert event.user_id == user_id",
            "        assert event.state_key == user_id",
            "        assert event.room_id == room_id",
            "        return origin, event, format_ver",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_make_leave_request(self, origin, room_id, user_id):",
            "        \"\"\" We've received a /make_leave/ request, so we create a partial",
            "        leave event for the room and return that. We do *not* persist or",
            "        process it until the other server has signed it and sent it back.",
            "",
            "        Args:",
            "            origin (str): The (verified) server name of the requesting server.",
            "            room_id (str): Room to create leave event in",
            "            user_id (str): The user to create the leave for",
            "",
            "        Returns:",
            "            Deferred[FrozenEvent]",
            "        \"\"\"",
            "        if get_domain_from_id(user_id) != origin:",
            "            logger.info(",
            "                \"Got /make_leave request for user %r from different origin %s, ignoring\",",
            "                user_id,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        room_version = yield self.store.get_room_version(room_id)",
            "        builder = self.event_builder_factory.new(",
            "            room_version,",
            "            {",
            "                \"type\": EventTypes.Member,",
            "                \"content\": {\"membership\": Membership.LEAVE},",
            "                \"room_id\": room_id,",
            "                \"sender\": user_id,",
            "                \"state_key\": user_id,",
            "            },",
            "        )",
            "",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.warning(\"Creation of leave %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        try:",
            "            # The remote hasn't signed it yet, obviously. We'll do the full checks",
            "            # when we get the event back in `on_send_leave_request`",
            "            yield self.auth.check_from_context(",
            "                room_version, event, context, do_sig_check=False",
            "            )",
            "        except AuthError as e:",
            "            logger.warn(\"Failed to create new leave %r because %s\", event, e)",
            "            raise e",
            "",
            "        return event",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_send_leave_request(self, origin, pdu):",
            "        \"\"\" We have received a leave event for a room. Fully process it.\"\"\"",
            "        event = pdu",
            "",
            "        logger.debug(",
            "            \"on_send_leave_request: Got event: %s, signatures: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        if get_domain_from_id(event.sender) != origin:",
            "            logger.info(",
            "                \"Got /send_leave request for user %r from different origin %s\",",
            "                event.sender,",
            "                origin,",
            "            )",
            "            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)",
            "",
            "        event.internal_metadata.outlier = False",
            "",
            "        context = yield self._handle_new_event(origin, event)",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.info(\"Sending of leave %s forbidden by third-party rules\", event)",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        logger.debug(",
            "            \"on_send_leave_request: After _handle_new_event: %s, sigs: %s\",",
            "            event.event_id,",
            "            event.signatures,",
            "        )",
            "",
            "        return None",
            "",
            "    @defer.inlineCallbacks",
            "    def get_state_for_pdu(self, room_id, event_id):",
            "        \"\"\"Returns the state at the event. i.e. not including said event.",
            "        \"\"\"",
            "",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        state_groups = yield self.store.get_state_groups(room_id, [event_id])",
            "",
            "        if state_groups:",
            "            _, state = list(iteritems(state_groups)).pop()",
            "            results = {(e.type, e.state_key): e for e in state}",
            "",
            "            if event.is_state():",
            "                # Get previous state",
            "                if \"replaces_state\" in event.unsigned:",
            "                    prev_id = event.unsigned[\"replaces_state\"]",
            "                    if prev_id != event.event_id:",
            "                        prev_event = yield self.store.get_event(prev_id)",
            "                        results[(event.type, event.state_key)] = prev_event",
            "                else:",
            "                    del results[(event.type, event.state_key)]",
            "",
            "            res = list(results.values())",
            "            return res",
            "        else:",
            "            return []",
            "",
            "    @defer.inlineCallbacks",
            "    def get_state_ids_for_pdu(self, room_id, event_id):",
            "        \"\"\"Returns the state at the event. i.e. not including said event.",
            "        \"\"\"",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        state_groups = yield self.store.get_state_groups_ids(room_id, [event_id])",
            "",
            "        if state_groups:",
            "            _, state = list(state_groups.items()).pop()",
            "            results = state",
            "",
            "            if event.is_state():",
            "                # Get previous state",
            "                if \"replaces_state\" in event.unsigned:",
            "                    prev_id = event.unsigned[\"replaces_state\"]",
            "                    if prev_id != event.event_id:",
            "                        results[(event.type, event.state_key)] = prev_id",
            "                else:",
            "                    results.pop((event.type, event.state_key), None)",
            "",
            "            return list(results.values())",
            "        else:",
            "            return []",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_backfill_request(self, origin, room_id, pdu_list, limit):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        events = yield self.store.get_backfill_events(room_id, pdu_list, limit)",
            "",
            "        events = yield filter_events_for_server(self.store, origin, events)",
            "",
            "        return events",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def get_persisted_pdu(self, origin, event_id):",
            "        \"\"\"Get an event from the database for the given server.",
            "",
            "        Args:",
            "            origin [str]: hostname of server which is requesting the event; we",
            "               will check that the server is allowed to see it.",
            "            event_id [str]: id of the event being requested",
            "",
            "        Returns:",
            "            Deferred[EventBase|None]: None if we know nothing about the event;",
            "                otherwise the (possibly-redacted) event.",
            "",
            "        Raises:",
            "            AuthError if the server is not currently in the room",
            "        \"\"\"",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=True, allow_rejected=True",
            "        )",
            "",
            "        if event:",
            "            in_room = yield self.auth.check_host_in_room(event.room_id, origin)",
            "            if not in_room:",
            "                raise AuthError(403, \"Host not in room.\")",
            "",
            "            events = yield filter_events_for_server(self.store, origin, [event])",
            "            event = events[0]",
            "            return event",
            "        else:",
            "            return None",
            "",
            "    def get_min_depth_for_context(self, context):",
            "        return self.store.get_min_depth(context)",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_new_event(",
            "        self, origin, event, state=None, auth_events=None, backfilled=False",
            "    ):",
            "        context = yield self._prep_event(",
            "            origin, event, state=state, auth_events=auth_events, backfilled=backfilled",
            "        )",
            "",
            "        # reraise does not allow inlineCallbacks to preserve the stacktrace, so we",
            "        # hack around with a try/finally instead.",
            "        success = False",
            "        try:",
            "            if not event.internal_metadata.is_outlier() and not backfilled:",
            "                yield self.action_generator.handle_push_actions_for_event(",
            "                    event, context",
            "                )",
            "",
            "            yield self.persist_events_and_notify(",
            "                [(event, context)], backfilled=backfilled",
            "            )",
            "            success = True",
            "        finally:",
            "            if not success:",
            "                run_in_background(",
            "                    self.store.remove_push_actions_from_staging, event.event_id",
            "                )",
            "",
            "        return context",
            "",
            "    @defer.inlineCallbacks",
            "    def _handle_new_events(self, origin, event_infos, backfilled=False):",
            "        \"\"\"Creates the appropriate contexts and persists events. The events",
            "        should not depend on one another, e.g. this should be used to persist",
            "        a bunch of outliers, but not a chunk of individual events that depend",
            "        on each other for state calculations.",
            "",
            "        Notifies about the events where appropriate.",
            "        \"\"\"",
            "",
            "        @defer.inlineCallbacks",
            "        def prep(ev_info):",
            "            event = ev_info[\"event\"]",
            "            with nested_logging_context(suffix=event.event_id):",
            "                res = yield self._prep_event(",
            "                    origin,",
            "                    event,",
            "                    state=ev_info.get(\"state\"),",
            "                    auth_events=ev_info.get(\"auth_events\"),",
            "                    backfilled=backfilled,",
            "                )",
            "            return res",
            "",
            "        contexts = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [run_in_background(prep, ev_info) for ev_info in event_infos],",
            "                consumeErrors=True,",
            "            )",
            "        )",
            "",
            "        yield self.persist_events_and_notify(",
            "            [",
            "                (ev_info[\"event\"], context)",
            "                for ev_info, context in zip(event_infos, contexts)",
            "            ],",
            "            backfilled=backfilled,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def _persist_auth_tree(self, origin, auth_events, state, event):",
            "        \"\"\"Checks the auth chain is valid (and passes auth checks) for the",
            "        state and event. Then persists the auth chain and state atomically.",
            "        Persists the event separately. Notifies about the persisted events",
            "        where appropriate.",
            "",
            "        Will attempt to fetch missing auth events.",
            "",
            "        Args:",
            "            origin (str): Where the events came from",
            "            auth_events (list)",
            "            state (list)",
            "            event (Event)",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        events_to_context = {}",
            "        for e in itertools.chain(auth_events, state):",
            "            e.internal_metadata.outlier = True",
            "            ctx = yield self.state_handler.compute_event_context(e)",
            "            events_to_context[e.event_id] = ctx",
            "",
            "        event_map = {",
            "            e.event_id: e for e in itertools.chain(auth_events, state, [event])",
            "        }",
            "",
            "        create_event = None",
            "        for e in auth_events:",
            "            if (e.type, e.state_key) == (EventTypes.Create, \"\"):",
            "                create_event = e",
            "                break",
            "",
            "        if create_event is None:",
            "            # If the state doesn't have a create event then the room is",
            "            # invalid, and it would fail auth checks anyway.",
            "            raise SynapseError(400, \"No create event in state\")",
            "",
            "        room_version = create_event.content.get(",
            "            \"room_version\", RoomVersions.V1.identifier",
            "        )",
            "",
            "        missing_auth_events = set()",
            "        for e in itertools.chain(auth_events, state, [event]):",
            "            for e_id in e.auth_event_ids():",
            "                if e_id not in event_map:",
            "                    missing_auth_events.add(e_id)",
            "",
            "        for e_id in missing_auth_events:",
            "            m_ev = yield self.federation_client.get_pdu(",
            "                [origin], e_id, room_version=room_version, outlier=True, timeout=10000",
            "            )",
            "            if m_ev and m_ev.event_id == e_id:",
            "                event_map[e_id] = m_ev",
            "            else:",
            "                logger.info(\"Failed to find auth event %r\", e_id)",
            "",
            "        for e in itertools.chain(auth_events, state, [event]):",
            "            auth_for_e = {",
            "                (event_map[e_id].type, event_map[e_id].state_key): event_map[e_id]",
            "                for e_id in e.auth_event_ids()",
            "                if e_id in event_map",
            "            }",
            "            if create_event:",
            "                auth_for_e[(EventTypes.Create, \"\")] = create_event",
            "",
            "            try:",
            "                event_auth.check(room_version, e, auth_events=auth_for_e)",
            "            except SynapseError as err:",
            "                # we may get SynapseErrors here as well as AuthErrors. For",
            "                # instance, there are a couple of (ancient) events in some",
            "                # rooms whose senders do not have the correct sigil; these",
            "                # cause SynapseErrors in auth.check. We don't want to give up",
            "                # the attempt to federate altogether in such cases.",
            "",
            "                logger.warn(\"Rejecting %s because %s\", e.event_id, err.msg)",
            "",
            "                if e == event:",
            "                    raise",
            "                events_to_context[e.event_id].rejected = RejectedReason.AUTH_ERROR",
            "",
            "        yield self.persist_events_and_notify(",
            "            [",
            "                (e, events_to_context[e.event_id])",
            "                for e in itertools.chain(auth_events, state)",
            "            ]",
            "        )",
            "",
            "        new_event_context = yield self.state_handler.compute_event_context(",
            "            event, old_state=state",
            "        )",
            "",
            "        yield self.persist_events_and_notify([(event, new_event_context)])",
            "",
            "    @defer.inlineCallbacks",
            "    def _prep_event(self, origin, event, state, auth_events, backfilled):",
            "        \"\"\"",
            "",
            "        Args:",
            "            origin:",
            "            event:",
            "            state:",
            "            auth_events:",
            "            backfilled (bool)",
            "",
            "        Returns:",
            "            Deferred, which resolves to synapse.events.snapshot.EventContext",
            "        \"\"\"",
            "        context = yield self.state_handler.compute_event_context(event, old_state=state)",
            "",
            "        if not auth_events:",
            "            prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "            auth_events_ids = yield self.auth.compute_auth_events(",
            "                event, prev_state_ids, for_verification=True",
            "            )",
            "            auth_events = yield self.store.get_events(auth_events_ids)",
            "            auth_events = {(e.type, e.state_key): e for e in auth_events.values()}",
            "",
            "        # This is a hack to fix some old rooms where the initial join event",
            "        # didn't reference the create event in its auth events.",
            "        if event.type == EventTypes.Member and not event.auth_event_ids():",
            "            if len(event.prev_event_ids()) == 1 and event.depth < 5:",
            "                c = yield self.store.get_event(",
            "                    event.prev_event_ids()[0], allow_none=True",
            "                )",
            "                if c and c.type == EventTypes.Create:",
            "                    auth_events[(c.type, c.state_key)] = c",
            "",
            "        try:",
            "            yield self.do_auth(origin, event, context, auth_events=auth_events)",
            "        except AuthError as e:",
            "            logger.warn(\"[%s %s] Rejecting: %s\", event.room_id, event.event_id, e.msg)",
            "",
            "            context.rejected = RejectedReason.AUTH_ERROR",
            "",
            "        if not context.rejected:",
            "            yield self._check_for_soft_fail(event, state, backfilled)",
            "",
            "        if event.type == EventTypes.GuestAccess and not context.rejected:",
            "            yield self.maybe_kick_guest_users(event)",
            "",
            "        return context",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_for_soft_fail(self, event, state, backfilled):",
            "        \"\"\"Checks if we should soft fail the event, if so marks the event as",
            "        such.",
            "",
            "        Args:",
            "            event (FrozenEvent)",
            "            state (dict|None): The state at the event if we don't have all the",
            "                event's prev events",
            "            backfilled (bool): Whether the event is from backfill",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        # For new (non-backfilled and non-outlier) events we check if the event",
            "        # passes auth based on the current state. If it doesn't then we",
            "        # \"soft-fail\" the event.",
            "        do_soft_fail_check = not backfilled and not event.internal_metadata.is_outlier()",
            "        if do_soft_fail_check:",
            "            extrem_ids = yield self.store.get_latest_event_ids_in_room(event.room_id)",
            "",
            "            extrem_ids = set(extrem_ids)",
            "            prev_event_ids = set(event.prev_event_ids())",
            "",
            "            if extrem_ids == prev_event_ids:",
            "                # If they're the same then the current state is the same as the",
            "                # state at the event, so no point rechecking auth for soft fail.",
            "                do_soft_fail_check = False",
            "",
            "        if do_soft_fail_check:",
            "            room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "            # Calculate the \"current state\".",
            "            if state is not None:",
            "                # If we're explicitly given the state then we won't have all the",
            "                # prev events, and so we have a gap in the graph. In this case",
            "                # we want to be a little careful as we might have been down for",
            "                # a while and have an incorrect view of the current state,",
            "                # however we still want to do checks as gaps are easy to",
            "                # maliciously manufacture.",
            "                #",
            "                # So we use a \"current state\" that is actually a state",
            "                # resolution across the current forward extremities and the",
            "                # given state at the event. This should correctly handle cases",
            "                # like bans, especially with state res v2.",
            "",
            "                state_sets = yield self.store.get_state_groups(",
            "                    event.room_id, extrem_ids",
            "                )",
            "                state_sets = list(state_sets.values())",
            "                state_sets.append(state)",
            "                current_state_ids = yield self.state_handler.resolve_events(",
            "                    room_version, state_sets, event",
            "                )",
            "                current_state_ids = {",
            "                    k: e.event_id for k, e in iteritems(current_state_ids)",
            "                }",
            "            else:",
            "                current_state_ids = yield self.state_handler.get_current_state_ids(",
            "                    event.room_id, latest_event_ids=extrem_ids",
            "                )",
            "",
            "            logger.debug(",
            "                \"Doing soft-fail check for %s: state %s\",",
            "                event.event_id,",
            "                current_state_ids,",
            "            )",
            "",
            "            # Now check if event pass auth against said current state",
            "            auth_types = auth_types_for_event(event)",
            "            current_state_ids = [",
            "                e for k, e in iteritems(current_state_ids) if k in auth_types",
            "            ]",
            "",
            "            current_auth_events = yield self.store.get_events(current_state_ids)",
            "            current_auth_events = {",
            "                (e.type, e.state_key): e for e in current_auth_events.values()",
            "            }",
            "",
            "            try:",
            "                event_auth.check(room_version, event, auth_events=current_auth_events)",
            "            except AuthError as e:",
            "                logger.warn(\"Soft-failing %r because %s\", event, e)",
            "                event.internal_metadata.soft_failed = True",
            "",
            "    @defer.inlineCallbacks",
            "    def on_query_auth(",
            "        self, origin, event_id, room_id, remote_auth_chain, rejects, missing",
            "    ):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        event = yield self.store.get_event(",
            "            event_id, allow_none=False, check_room_id=room_id",
            "        )",
            "",
            "        # Just go through and process each event in `remote_auth_chain`. We",
            "        # don't want to fall into the trap of `missing` being wrong.",
            "        for e in remote_auth_chain:",
            "            try:",
            "                yield self._handle_new_event(origin, e)",
            "            except AuthError:",
            "                pass",
            "",
            "        # Now get the current auth_chain for the event.",
            "        local_auth_chain = yield self.store.get_auth_chain(",
            "            [auth_id for auth_id in event.auth_event_ids()], include_given=True",
            "        )",
            "",
            "        # TODO: Check if we would now reject event_id. If so we need to tell",
            "        # everyone.",
            "",
            "        ret = yield self.construct_auth_difference(local_auth_chain, remote_auth_chain)",
            "",
            "        logger.debug(\"on_query_auth returning: %s\", ret)",
            "",
            "        return ret",
            "",
            "    @defer.inlineCallbacks",
            "    def on_get_missing_events(",
            "        self, origin, room_id, earliest_events, latest_events, limit",
            "    ):",
            "        in_room = yield self.auth.check_host_in_room(room_id, origin)",
            "        if not in_room:",
            "            raise AuthError(403, \"Host not in room.\")",
            "",
            "        limit = min(limit, 20)",
            "",
            "        missing_events = yield self.store.get_missing_events(",
            "            room_id=room_id,",
            "            earliest_events=earliest_events,",
            "            latest_events=latest_events,",
            "            limit=limit,",
            "        )",
            "",
            "        missing_events = yield filter_events_for_server(",
            "            self.store, origin, missing_events",
            "        )",
            "",
            "        return missing_events",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def do_auth(self, origin, event, context, auth_events):",
            "        \"\"\"",
            "",
            "        Args:",
            "            origin (str):",
            "            event (synapse.events.EventBase):",
            "            context (synapse.events.snapshot.EventContext):",
            "            auth_events (dict[(str, str)->synapse.events.EventBase]):",
            "                Map from (event_type, state_key) to event",
            "",
            "                What we expect the event's auth_events to be, based on the event's",
            "                position in the dag. I think? maybe??",
            "",
            "                Also NB that this function adds entries to it.",
            "        Returns:",
            "            defer.Deferred[None]",
            "        \"\"\"",
            "        room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "        try:",
            "            yield self._update_auth_events_and_context_for_auth(",
            "                origin, event, context, auth_events",
            "            )",
            "        except Exception:",
            "            # We don't really mind if the above fails, so lets not fail",
            "            # processing if it does. However, it really shouldn't fail so",
            "            # let's still log as an exception since we'll still want to fix",
            "            # any bugs.",
            "            logger.exception(",
            "                \"Failed to double check auth events for %s with remote. \"",
            "                \"Ignoring failure and continuing processing of event.\",",
            "                event.event_id,",
            "            )",
            "",
            "        try:",
            "            event_auth.check(room_version, event, auth_events=auth_events)",
            "        except AuthError as e:",
            "            logger.warn(\"Failed auth resolution for %r because %s\", event, e)",
            "            raise e",
            "",
            "    @defer.inlineCallbacks",
            "    def _update_auth_events_and_context_for_auth(",
            "        self, origin, event, context, auth_events",
            "    ):",
            "        \"\"\"Helper for do_auth. See there for docs.",
            "",
            "        Checks whether a given event has the expected auth events. If it",
            "        doesn't then we talk to the remote server to compare state to see if",
            "        we can come to a consensus (e.g. if one server missed some valid",
            "        state).",
            "",
            "        This attempts to resovle any potential divergence of state between",
            "        servers, but is not essential and so failures should not block further",
            "        processing of the event.",
            "",
            "        Args:",
            "            origin (str):",
            "            event (synapse.events.EventBase):",
            "            context (synapse.events.snapshot.EventContext):",
            "            auth_events (dict[(str, str)->synapse.events.EventBase]):",
            "",
            "        Returns:",
            "            defer.Deferred[None]",
            "        \"\"\"",
            "        event_auth_events = set(event.auth_event_ids())",
            "",
            "        if event.is_state():",
            "            event_key = (event.type, event.state_key)",
            "        else:",
            "            event_key = None",
            "",
            "        # if the event's auth_events refers to events which are not in our",
            "        # calculated auth_events, we need to fetch those events from somewhere.",
            "        #",
            "        # we start by fetching them from the store, and then try calling /event_auth/.",
            "        missing_auth = event_auth_events.difference(",
            "            e.event_id for e in auth_events.values()",
            "        )",
            "",
            "        if missing_auth:",
            "            # TODO: can we use store.have_seen_events here instead?",
            "            have_events = yield self.store.get_seen_events_with_rejections(missing_auth)",
            "            logger.debug(\"Got events %s from store\", have_events)",
            "            missing_auth.difference_update(have_events.keys())",
            "        else:",
            "            have_events = {}",
            "",
            "        have_events.update({e.event_id: \"\" for e in auth_events.values()})",
            "",
            "        if missing_auth:",
            "            # If we don't have all the auth events, we need to get them.",
            "            logger.info(\"auth_events contains unknown events: %s\", missing_auth)",
            "            try:",
            "                try:",
            "                    remote_auth_chain = yield self.federation_client.get_event_auth(",
            "                        origin, event.room_id, event.event_id",
            "                    )",
            "                except RequestSendFailed as e:",
            "                    # The other side isn't around or doesn't implement the",
            "                    # endpoint, so lets just bail out.",
            "                    logger.info(\"Failed to get event auth from remote: %s\", e)",
            "                    return",
            "",
            "                seen_remotes = yield self.store.have_seen_events(",
            "                    [e.event_id for e in remote_auth_chain]",
            "                )",
            "",
            "                for e in remote_auth_chain:",
            "                    if e.event_id in seen_remotes:",
            "                        continue",
            "",
            "                    if e.event_id == event.event_id:",
            "                        continue",
            "",
            "                    try:",
            "                        auth_ids = e.auth_event_ids()",
            "                        auth = {",
            "                            (e.type, e.state_key): e",
            "                            for e in remote_auth_chain",
            "                            if e.event_id in auth_ids or e.type == EventTypes.Create",
            "                        }",
            "                        e.internal_metadata.outlier = True",
            "",
            "                        logger.debug(",
            "                            \"do_auth %s missing_auth: %s\", event.event_id, e.event_id",
            "                        )",
            "                        yield self._handle_new_event(origin, e, auth_events=auth)",
            "",
            "                        if e.event_id in event_auth_events:",
            "                            auth_events[(e.type, e.state_key)] = e",
            "                    except AuthError:",
            "                        pass",
            "",
            "                have_events = yield self.store.get_seen_events_with_rejections(",
            "                    event.auth_event_ids()",
            "                )",
            "            except Exception:",
            "                # FIXME:",
            "                logger.exception(\"Failed to get auth chain\")",
            "",
            "        if event.internal_metadata.is_outlier():",
            "            logger.info(\"Skipping auth_event fetch for outlier\")",
            "            return",
            "",
            "        # FIXME: Assumes we have and stored all the state for all the",
            "        # prev_events",
            "        different_auth = event_auth_events.difference(",
            "            e.event_id for e in auth_events.values()",
            "        )",
            "",
            "        if not different_auth:",
            "            return",
            "",
            "        logger.info(",
            "            \"auth_events refers to events which are not in our calculated auth \"",
            "            \"chain: %s\",",
            "            different_auth,",
            "        )",
            "",
            "        room_version = yield self.store.get_room_version(event.room_id)",
            "",
            "        different_events = yield make_deferred_yieldable(",
            "            defer.gatherResults(",
            "                [",
            "                    run_in_background(",
            "                        self.store.get_event, d, allow_none=True, allow_rejected=False",
            "                    )",
            "                    for d in different_auth",
            "                    if d in have_events and not have_events[d]",
            "                ],",
            "                consumeErrors=True,",
            "            )",
            "        ).addErrback(unwrapFirstError)",
            "",
            "        if different_events:",
            "            local_view = dict(auth_events)",
            "            remote_view = dict(auth_events)",
            "            remote_view.update(",
            "                {(d.type, d.state_key): d for d in different_events if d}",
            "            )",
            "",
            "            new_state = yield self.state_handler.resolve_events(",
            "                room_version,",
            "                [list(local_view.values()), list(remote_view.values())],",
            "                event,",
            "            )",
            "",
            "            logger.info(",
            "                \"After state res: updating auth_events with new state %s\",",
            "                {",
            "                    (d.type, d.state_key): d.event_id",
            "                    for d in new_state.values()",
            "                    if auth_events.get((d.type, d.state_key)) != d",
            "                },",
            "            )",
            "",
            "            auth_events.update(new_state)",
            "",
            "            yield self._update_context_for_auth_events(",
            "                event, context, auth_events, event_key",
            "            )",
            "",
            "    @defer.inlineCallbacks",
            "    def _update_context_for_auth_events(self, event, context, auth_events, event_key):",
            "        \"\"\"Update the state_ids in an event context after auth event resolution,",
            "        storing the changes as a new state group.",
            "",
            "        Args:",
            "            event (Event): The event we're handling the context for",
            "",
            "            context (synapse.events.snapshot.EventContext): event context",
            "                to be updated",
            "",
            "            auth_events (dict[(str, str)->str]): Events to update in the event",
            "                context.",
            "",
            "            event_key ((str, str)): (type, state_key) for the current event.",
            "                this will not be included in the current_state in the context.",
            "        \"\"\"",
            "        state_updates = {",
            "            k: a.event_id for k, a in iteritems(auth_events) if k != event_key",
            "        }",
            "        current_state_ids = yield context.get_current_state_ids(self.store)",
            "        current_state_ids = dict(current_state_ids)",
            "",
            "        current_state_ids.update(state_updates)",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        prev_state_ids = dict(prev_state_ids)",
            "",
            "        prev_state_ids.update({k: a.event_id for k, a in iteritems(auth_events)})",
            "",
            "        # create a new state group as a delta from the existing one.",
            "        prev_group = context.state_group",
            "        state_group = yield self.store.store_state_group(",
            "            event.event_id,",
            "            event.room_id,",
            "            prev_group=prev_group,",
            "            delta_ids=state_updates,",
            "            current_state_ids=current_state_ids,",
            "        )",
            "",
            "        yield context.update_state(",
            "            state_group=state_group,",
            "            current_state_ids=current_state_ids,",
            "            prev_state_ids=prev_state_ids,",
            "            prev_group=prev_group,",
            "            delta_ids=state_updates,",
            "        )",
            "",
            "    @defer.inlineCallbacks",
            "    def construct_auth_difference(self, local_auth, remote_auth):",
            "        \"\"\" Given a local and remote auth chain, find the differences. This",
            "        assumes that we have already processed all events in remote_auth",
            "",
            "        Params:",
            "            local_auth (list)",
            "            remote_auth (list)",
            "",
            "        Returns:",
            "            dict",
            "        \"\"\"",
            "",
            "        logger.debug(\"construct_auth_difference Start!\")",
            "",
            "        # TODO: Make sure we are OK with local_auth or remote_auth having more",
            "        # auth events in them than strictly necessary.",
            "",
            "        def sort_fun(ev):",
            "            return ev.depth, ev.event_id",
            "",
            "        logger.debug(\"construct_auth_difference after sort_fun!\")",
            "",
            "        # We find the differences by starting at the \"bottom\" of each list",
            "        # and iterating up on both lists. The lists are ordered by depth and",
            "        # then event_id, we iterate up both lists until we find the event ids",
            "        # don't match. Then we look at depth/event_id to see which side is",
            "        # missing that event, and iterate only up that list. Repeat.",
            "",
            "        remote_list = list(remote_auth)",
            "        remote_list.sort(key=sort_fun)",
            "",
            "        local_list = list(local_auth)",
            "        local_list.sort(key=sort_fun)",
            "",
            "        local_iter = iter(local_list)",
            "        remote_iter = iter(remote_list)",
            "",
            "        logger.debug(\"construct_auth_difference before get_next!\")",
            "",
            "        def get_next(it, opt=None):",
            "            try:",
            "                return next(it)",
            "            except Exception:",
            "                return opt",
            "",
            "        current_local = get_next(local_iter)",
            "        current_remote = get_next(remote_iter)",
            "",
            "        logger.debug(\"construct_auth_difference before while\")",
            "",
            "        missing_remotes = []",
            "        missing_locals = []",
            "        while current_local or current_remote:",
            "            if current_remote is None:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "                continue",
            "",
            "            if current_local is None:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            if current_local.event_id == current_remote.event_id:",
            "                current_local = get_next(local_iter)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            if current_local.depth < current_remote.depth:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "                continue",
            "",
            "            if current_local.depth > current_remote.depth:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "            # They have the same depth, so we fall back to the event_id order",
            "            if current_local.event_id < current_remote.event_id:",
            "                missing_locals.append(current_local)",
            "                current_local = get_next(local_iter)",
            "",
            "            if current_local.event_id > current_remote.event_id:",
            "                missing_remotes.append(current_remote)",
            "                current_remote = get_next(remote_iter)",
            "                continue",
            "",
            "        logger.debug(\"construct_auth_difference after while\")",
            "",
            "        # missing locals should be sent to the server",
            "        # We should find why we are missing remotes, as they will have been",
            "        # rejected.",
            "",
            "        # Remove events from missing_remotes if they are referencing a missing",
            "        # remote. We only care about the \"root\" rejected ones.",
            "        missing_remote_ids = [e.event_id for e in missing_remotes]",
            "        base_remote_rejected = list(missing_remotes)",
            "        for e in missing_remotes:",
            "            for e_id in e.auth_event_ids():",
            "                if e_id in missing_remote_ids:",
            "                    try:",
            "                        base_remote_rejected.remove(e)",
            "                    except ValueError:",
            "                        pass",
            "",
            "        reason_map = {}",
            "",
            "        for e in base_remote_rejected:",
            "            reason = yield self.store.get_rejection_reason(e.event_id)",
            "            if reason is None:",
            "                # TODO: e is not in the current state, so we should",
            "                # construct some proof of that.",
            "                continue",
            "",
            "            reason_map[e.event_id] = reason",
            "",
            "        logger.debug(\"construct_auth_difference returning\")",
            "",
            "        return {",
            "            \"auth_chain\": local_auth,",
            "            \"rejects\": {",
            "                e.event_id: {\"reason\": reason_map[e.event_id], \"proof\": None}",
            "                for e in base_remote_rejected",
            "            },",
            "            \"missing\": [e.event_id for e in missing_locals],",
            "        }",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def exchange_third_party_invite(",
            "        self, sender_user_id, target_user_id, room_id, signed",
            "    ):",
            "        third_party_invite = {\"signed\": signed}",
            "",
            "        event_dict = {",
            "            \"type\": EventTypes.Member,",
            "            \"content\": {",
            "                \"membership\": Membership.INVITE,",
            "                \"third_party_invite\": third_party_invite,",
            "            },",
            "            \"room_id\": room_id,",
            "            \"sender\": sender_user_id,",
            "            \"state_key\": target_user_id,",
            "        }",
            "",
            "        if (yield self.auth.check_host_in_room(room_id, self.hs.hostname)):",
            "            room_version = yield self.store.get_room_version(room_id)",
            "            builder = self.event_builder_factory.new(room_version, event_dict)",
            "",
            "            EventValidator().validate_builder(builder)",
            "            event, context = yield self.event_creation_handler.create_new_client_event(",
            "                builder=builder",
            "            )",
            "",
            "            event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "                event, context",
            "            )",
            "            if not event_allowed:",
            "                logger.info(",
            "                    \"Creation of threepid invite %s forbidden by third-party rules\",",
            "                    event,",
            "                )",
            "                raise SynapseError(",
            "                    403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "                )",
            "",
            "            event, context = yield self.add_display_name_to_third_party_invite(",
            "                room_version, event_dict, event, context",
            "            )",
            "",
            "            EventValidator().validate_new(event)",
            "",
            "            # We need to tell the transaction queue to send this out, even",
            "            # though the sender isn't a local user.",
            "            event.internal_metadata.send_on_behalf_of = self.hs.hostname",
            "",
            "            try:",
            "                yield self.auth.check_from_context(room_version, event, context)",
            "            except AuthError as e:",
            "                logger.warn(\"Denying new third party invite %r because %s\", event, e)",
            "                raise e",
            "",
            "            yield self._check_signature(event, context)",
            "            member_handler = self.hs.get_room_member_handler()",
            "            yield member_handler.send_membership_event(None, event, context)",
            "        else:",
            "            destinations = set(x.split(\":\", 1)[-1] for x in (sender_user_id, room_id))",
            "            yield self.federation_client.forward_third_party_invite(",
            "                destinations, room_id, event_dict",
            "            )",
            "",
            "    @defer.inlineCallbacks",
            "    @log_function",
            "    def on_exchange_third_party_invite_request(self, room_id, event_dict):",
            "        \"\"\"Handle an exchange_third_party_invite request from a remote server",
            "",
            "        The remote server will call this when it wants to turn a 3pid invite",
            "        into a normal m.room.member invite.",
            "",
            "        Args:",
            "            room_id (str): The ID of the room.",
            "",
            "            event_dict (dict[str, Any]): Dictionary containing the event body.",
            "",
            "        Returns:",
            "            Deferred: resolves (to None)",
            "        \"\"\"",
            "        room_version = yield self.store.get_room_version(room_id)",
            "",
            "        # NB: event_dict has a particular specced format we might need to fudge",
            "        # if we change event formats too much.",
            "        builder = self.event_builder_factory.new(room_version, event_dict)",
            "",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "",
            "        event_allowed = yield self.third_party_event_rules.check_event_allowed(",
            "            event, context",
            "        )",
            "        if not event_allowed:",
            "            logger.warning(",
            "                \"Exchange of threepid invite %s forbidden by third-party rules\", event",
            "            )",
            "            raise SynapseError(",
            "                403, \"This event is not allowed in this context\", Codes.FORBIDDEN",
            "            )",
            "",
            "        event, context = yield self.add_display_name_to_third_party_invite(",
            "            room_version, event_dict, event, context",
            "        )",
            "",
            "        try:",
            "            yield self.auth.check_from_context(room_version, event, context)",
            "        except AuthError as e:",
            "            logger.warn(\"Denying third party invite %r because %s\", event, e)",
            "            raise e",
            "        yield self._check_signature(event, context)",
            "",
            "        # We need to tell the transaction queue to send this out, even",
            "        # though the sender isn't a local user.",
            "        event.internal_metadata.send_on_behalf_of = get_domain_from_id(event.sender)",
            "",
            "        member_handler = self.hs.get_room_member_handler()",
            "        yield member_handler.send_membership_event(None, event, context)",
            "",
            "    @defer.inlineCallbacks",
            "    def add_display_name_to_third_party_invite(",
            "        self, room_version, event_dict, event, context",
            "    ):",
            "        key = (",
            "            EventTypes.ThirdPartyInvite,",
            "            event.content[\"third_party_invite\"][\"signed\"][\"token\"],",
            "        )",
            "        original_invite = None",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        original_invite_id = prev_state_ids.get(key)",
            "        if original_invite_id:",
            "            original_invite = yield self.store.get_event(",
            "                original_invite_id, allow_none=True",
            "            )",
            "        if original_invite:",
            "            # If the m.room.third_party_invite event's content is empty, it means the",
            "            # invite has been revoked. In this case, we don't have to raise an error here",
            "            # because the auth check will fail on the invite (because it's not able to",
            "            # fetch public keys from the m.room.third_party_invite event's content, which",
            "            # is empty).",
            "            display_name = original_invite.content.get(\"display_name\")",
            "            event_dict[\"content\"][\"third_party_invite\"][\"display_name\"] = display_name",
            "        else:",
            "            logger.info(",
            "                \"Could not find invite event for third_party_invite: %r\", event_dict",
            "            )",
            "            # We don't discard here as this is not the appropriate place to do",
            "            # auth checks. If we need the invite and don't have it then the",
            "            # auth check code will explode appropriately.",
            "",
            "        builder = self.event_builder_factory.new(room_version, event_dict)",
            "        EventValidator().validate_builder(builder)",
            "        event, context = yield self.event_creation_handler.create_new_client_event(",
            "            builder=builder",
            "        )",
            "        EventValidator().validate_new(event)",
            "        return (event, context)",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_signature(self, event, context):",
            "        \"\"\"",
            "        Checks that the signature in the event is consistent with its invite.",
            "",
            "        Args:",
            "            event (Event): The m.room.member event to check",
            "            context (EventContext):",
            "",
            "        Raises:",
            "            AuthError: if signature didn't match any keys, or key has been",
            "                revoked,",
            "            SynapseError: if a transient error meant a key couldn't be checked",
            "                for revocation.",
            "        \"\"\"",
            "        signed = event.content[\"third_party_invite\"][\"signed\"]",
            "        token = signed[\"token\"]",
            "",
            "        prev_state_ids = yield context.get_prev_state_ids(self.store)",
            "        invite_event_id = prev_state_ids.get((EventTypes.ThirdPartyInvite, token))",
            "",
            "        invite_event = None",
            "        if invite_event_id:",
            "            invite_event = yield self.store.get_event(invite_event_id, allow_none=True)",
            "",
            "        if not invite_event:",
            "            raise AuthError(403, \"Could not find invite\")",
            "",
            "        logger.debug(\"Checking auth on event %r\", event.content)",
            "",
            "        last_exception = None",
            "        # for each public key in the 3pid invite event",
            "        for public_key_object in self.hs.get_auth().get_public_keys(invite_event):",
            "            try:",
            "                # for each sig on the third_party_invite block of the actual invite",
            "                for server, signature_block in signed[\"signatures\"].items():",
            "                    for key_name, encoded_signature in signature_block.items():",
            "                        if not key_name.startswith(\"ed25519:\"):",
            "                            continue",
            "",
            "                        logger.debug(",
            "                            \"Attempting to verify sig with key %s from %r \"",
            "                            \"against pubkey %r\",",
            "                            key_name,",
            "                            server,",
            "                            public_key_object,",
            "                        )",
            "",
            "                        try:",
            "                            public_key = public_key_object[\"public_key\"]",
            "                            verify_key = decode_verify_key_bytes(",
            "                                key_name, decode_base64(public_key)",
            "                            )",
            "                            verify_signed_json(signed, server, verify_key)",
            "                            logger.debug(",
            "                                \"Successfully verified sig with key %s from %r \"",
            "                                \"against pubkey %r\",",
            "                                key_name,",
            "                                server,",
            "                                public_key_object,",
            "                            )",
            "                        except Exception:",
            "                            logger.info(",
            "                                \"Failed to verify sig with key %s from %r \"",
            "                                \"against pubkey %r\",",
            "                                key_name,",
            "                                server,",
            "                                public_key_object,",
            "                            )",
            "                            raise",
            "                        try:",
            "                            if \"key_validity_url\" in public_key_object:",
            "                                yield self._check_key_revocation(",
            "                                    public_key, public_key_object[\"key_validity_url\"]",
            "                                )",
            "                        except Exception:",
            "                            logger.info(",
            "                                \"Failed to query key_validity_url %s\",",
            "                                public_key_object[\"key_validity_url\"],",
            "                            )",
            "                            raise",
            "                        return",
            "            except Exception as e:",
            "                last_exception = e",
            "        raise last_exception",
            "",
            "    @defer.inlineCallbacks",
            "    def _check_key_revocation(self, public_key, url):",
            "        \"\"\"",
            "        Checks whether public_key has been revoked.",
            "",
            "        Args:",
            "            public_key (str): base-64 encoded public key.",
            "            url (str): Key revocation URL.",
            "",
            "        Raises:",
            "            AuthError: if they key has been revoked.",
            "            SynapseError: if a transient error meant a key couldn't be checked",
            "                for revocation.",
            "        \"\"\"",
            "        try:",
            "            response = yield self.http_client.get_json(url, {\"public_key\": public_key})",
            "        except Exception:",
            "            raise SynapseError(502, \"Third party certificate could not be checked\")",
            "        if \"valid\" not in response or not response[\"valid\"]:",
            "            raise AuthError(403, \"Third party certificate was invalid\")",
            "",
            "    @defer.inlineCallbacks",
            "    def persist_events_and_notify(self, event_and_contexts, backfilled=False):",
            "        \"\"\"Persists events and tells the notifier/pushers about them, if",
            "        necessary.",
            "",
            "        Args:",
            "            event_and_contexts(list[tuple[FrozenEvent, EventContext]])",
            "            backfilled (bool): Whether these events are a result of",
            "                backfilling or not",
            "",
            "        Returns:",
            "            Deferred",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            yield self._send_events_to_master(",
            "                store=self.store,",
            "                event_and_contexts=event_and_contexts,",
            "                backfilled=backfilled,",
            "            )",
            "        else:",
            "            max_stream_id = yield self.store.persist_events(",
            "                event_and_contexts, backfilled=backfilled",
            "            )",
            "",
            "            if not backfilled:  # Never notify for backfilled events",
            "                for event, _ in event_and_contexts:",
            "                    yield self._notify_persisted_event(event, max_stream_id)",
            "",
            "    def _notify_persisted_event(self, event, max_stream_id):",
            "        \"\"\"Checks to see if notifier/pushers should be notified about the",
            "        event or not.",
            "",
            "        Args:",
            "            event (FrozenEvent)",
            "            max_stream_id (int): The max_stream_id returned by persist_events",
            "        \"\"\"",
            "",
            "        extra_users = []",
            "        if event.type == EventTypes.Member:",
            "            target_user_id = event.state_key",
            "",
            "            # We notify for memberships if its an invite for one of our",
            "            # users",
            "            if event.internal_metadata.is_outlier():",
            "                if event.membership != Membership.INVITE:",
            "                    if not self.is_mine_id(target_user_id):",
            "                        return",
            "",
            "            target_user = UserID.from_string(target_user_id)",
            "            extra_users.append(target_user)",
            "        elif event.internal_metadata.is_outlier():",
            "            return",
            "",
            "        event_stream_id = event.internal_metadata.stream_ordering",
            "        self.notifier.on_new_room_event(",
            "            event, event_stream_id, max_stream_id, extra_users=extra_users",
            "        )",
            "",
            "        return self.pusher_pool.on_new_notifications(event_stream_id, max_stream_id)",
            "",
            "    def _clean_room_for_join(self, room_id):",
            "        \"\"\"Called to clean up any data in DB for a given room, ready for the",
            "        server to join the room.",
            "",
            "        Args:",
            "            room_id (str)",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            return self._clean_room_for_join_client(room_id)",
            "        else:",
            "            return self.store.clean_room_for_join(room_id)",
            "",
            "    def user_joined_room(self, user, room_id):",
            "        \"\"\"Called when a new user has joined the room",
            "        \"\"\"",
            "        if self.config.worker_app:",
            "            return self._notify_user_membership_change(",
            "                room_id=room_id, user_id=user.to_string(), change=\"joined\"",
            "            )",
            "        else:",
            "            return user_joined_room(self.distributor, user, room_id)",
            "",
            "    @defer.inlineCallbacks",
            "    def get_room_complexity(self, remote_room_hosts, room_id):",
            "        \"\"\"",
            "        Fetch the complexity of a remote room over federation.",
            "",
            "        Args:",
            "            remote_room_hosts (list[str]): The remote servers to ask.",
            "            room_id (str): The room ID to ask about.",
            "",
            "        Returns:",
            "            Deferred[dict] or Deferred[None]: Dict contains the complexity",
            "            metric versions, while None means we could not fetch the complexity.",
            "        \"\"\"",
            "",
            "        for host in remote_room_hosts:",
            "            res = yield self.federation_client.get_room_complexity(host, room_id)",
            "",
            "            # We got a result, return it.",
            "            if res:",
            "                defer.returnValue(res)",
            "",
            "        # We fell off the bottom, couldn't get the complexity from anyone. Oh",
            "        # well.",
            "        defer.returnValue(None)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1225": [
                "FederationHandler",
                "on_make_join_request"
            ],
            "1283": [
                "FederationHandler",
                "on_send_join_request"
            ]
        },
        "addLocation": []
    }
}