{
    "rdiffweb/controller/tests/test_page_admin_users.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 396,
                "afterPatchRowNumber": 396,
                "PatchRowcode": "         self.assertInBody(\"Cannot edit user `invalid`: user doesn&#39;t exists\")"
            },
            "1": {
                "beforePatchRowNumber": 397,
                "afterPatchRowNumber": 397,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": 398,
                "PatchRowcode": "     def test_user_invalid_root(self):"
            },
            "3": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Delete all user's"
            },
            "4": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for user in UserObject.query.all():"
            },
            "5": {
                "beforePatchRowNumber": 401,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if user.username != self.USERNAME:"
            },
            "6": {
                "beforePatchRowNumber": 402,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                user.delete().commit()"
            },
            "7": {
                "beforePatchRowNumber": 403,
                "afterPatchRowNumber": 399,
                "PatchRowcode": "         # Change the user's root"
            },
            "8": {
                "beforePatchRowNumber": 404,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        user = UserObject.get_user('admin')"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+        user = UserObject.get_user(self.USERNAME)"
            },
            "10": {
                "beforePatchRowNumber": 405,
                "afterPatchRowNumber": 401,
                "PatchRowcode": "         user.user_root = \"/invalid\""
            },
            "11": {
                "beforePatchRowNumber": 406,
                "afterPatchRowNumber": 402,
                "PatchRowcode": "         user.commit()"
            },
            "12": {
                "beforePatchRowNumber": 407,
                "afterPatchRowNumber": 403,
                "PatchRowcode": "         self.getPage(\"/admin/users\")"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from unittest.mock import ANY, MagicMock",
            "",
            "import cherrypy",
            "from parameterized import parameterized",
            "",
            "import rdiffweb.test",
            "from rdiffweb.core.model import UserObject",
            "",
            "",
            "class AbstractAdminTest(rdiffweb.test.WebCase):",
            "",
            "    login = True",
            "",
            "    def setUp(self):",
            "        super().setUp()",
            "        self._quota = {}",
            "        self.listener = MagicMock()",
            "        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)",
            "        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)",
            "        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)",
            "        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)",
            "        self.listener.get_disk_quota.side_effect = self._load_quota",
            "        cherrypy.engine.subscribe('get_disk_quota', self.listener.get_disk_quota, priority=40)",
            "        self.listener.get_disk_usage.return_value = 0",
            "        cherrypy.engine.subscribe('get_disk_usage', self.listener.get_disk_usage, priority=40)",
            "        self.listener.set_disk_quota.side_effect = self._store_quota",
            "        cherrypy.engine.subscribe('set_disk_quota', self.listener.set_disk_quota, priority=40)",
            "",
            "    def tearDown(self):",
            "        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)",
            "        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)",
            "        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)",
            "        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)",
            "        cherrypy.engine.unsubscribe('get_disk_quota', self.listener.get_disk_quota)",
            "        cherrypy.engine.unsubscribe('get_disk_usage', self.listener.get_disk_usage)",
            "        cherrypy.engine.unsubscribe('set_disk_quota', self.listener.set_disk_quota)",
            "        return super().tearDown()",
            "",
            "    def _store_quota(self, userobj, value):",
            "        self._quota[userobj.username] = value",
            "",
            "    def _load_quota(self, userobj):",
            "        return self._quota.get(userobj.username, 0)",
            "",
            "    def _add_user(self, username=None, email=None, password=None, user_root=None, role=None, mfa=None, fullname=None):",
            "        b = {}",
            "        b['action'] = 'add'",
            "        if username is not None:",
            "            b['username'] = username",
            "        if email is not None:",
            "            b['email'] = email",
            "        if password is not None:",
            "            b['password'] = password",
            "        if user_root is not None:",
            "            b['user_root'] = user_root",
            "        if role is not None:",
            "            b['role'] = str(role)",
            "        if mfa is not None:",
            "            b['mfa'] = str(mfa)",
            "        if fullname is not None:",
            "            b['fullname'] = str(fullname)",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def _edit_user(",
            "        self, username=None, email=None, password=None, user_root=None, role=None, disk_quota=None, mfa=None",
            "    ):",
            "        b = {}",
            "        b['action'] = 'edit'",
            "        if username is not None:",
            "            b['username'] = username",
            "        if email is not None:",
            "            b['email'] = email",
            "        if password is not None:",
            "            b['password'] = password",
            "        if user_root is not None:",
            "            b['user_root'] = user_root",
            "        if role is not None:",
            "            b['role'] = str(role)",
            "        if disk_quota is not None:",
            "            b['disk_quota'] = disk_quota",
            "        if mfa is not None:",
            "            b['mfa'] = str(mfa)",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def _delete_user(self, username='test1'):",
            "        b = {'action': 'delete', 'username': username}",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def test_add_user_with_role_admin(self):",
            "        # When trying to create a new user with role admin",
            "        self._add_user(\"admin_role\", \"admin_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.ADMIN_ROLE)",
            "        # Then page return success",
            "        self.assertStatus(200)",
            "        # Then database is updated",
            "        userobj = UserObject.get_user('admin_role')",
            "        self.assertEqual(UserObject.ADMIN_ROLE, userobj.role)",
            "        # Then notification was raised",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_add_user_with_role_maintainer(self):",
            "        self._add_user(\"maintainer_role\", \"maintainer_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.MAINTAINER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertEqual(UserObject.MAINTAINER_ROLE, UserObject.get_user('maintainer_role').role)",
            "",
            "    def test_add_user_with_role_user(self):",
            "        self._add_user(\"user_role\", \"user_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertEqual(UserObject.USER_ROLE, UserObject.get_user('user_role').role)",
            "",
            "    def test_add_user_with_invalid_role(self):",
            "        # When trying to create a new user with an invalid role (admin instead of 0)",
            "        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", 'admin')",
            "        # Then an error message is displayed to the user",
            "        self.assertStatus(200)",
            "        self.assertInBody('Role: Invalid Choice: could not coerce')",
            "        # Then listener are not called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "        # When trying to create a new user with an invalid role (-1)",
            "        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", -1)",
            "        # Then an error message is displayed to the user",
            "        self.assertStatus(200)",
            "        self.assertInBody('User Role: Not a valid choice')",
            "        # Then listener are not called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "    def test_add_edit_delete(self):",
            "        #  Add user to be listed",
            "        self.listener.user_password_changed.reset_mock()",
            "        self._add_user(",
            "            \"test2\", \"test2@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE, mfa=UserObject.DISABLED_MFA",
            "        )",
            "        self.assertInBody(\"User added successfully.\")",
            "        self.assertInBody(\"test2\")",
            "        self.assertInBody(\"test2@test.com\")",
            "        self.listener.user_added.assert_called_once()",
            "        self.listener.user_password_changed.assert_called_once()",
            "        self.listener.user_password_changed.reset_mock()",
            "        #  Update user",
            "        self._edit_user(",
            "            \"test2\", \"chaned@test.com\", \"new-password\", \"/tmp/\", UserObject.ADMIN_ROLE, mfa=UserObject.ENABLED_MFA",
            "        )",
            "        self.listener.user_attr_changed.assert_called()",
            "        self.listener.user_password_changed.assert_called_once()",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertInBody(\"test2\")",
            "        self.assertInBody(\"chaned@test.com\")",
            "        self.assertNotInBody(\"/home/\")",
            "        self.assertInBody(\"/tmp/\")",
            "",
            "        self._delete_user(\"test2\")",
            "        self.listener.user_deleted.assert_called()",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"User account removed.\")",
            "        self.assertNotInBody(\"test2\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            # Invalid",
            "            ('evil.com', False),",
            "            ('http://test', False),",
            "            ('email@test.test', False),",
            "            ('/test/', False),",
            "            # Valid",
            "            ('My fullname', True),",
            "            ('Test Test', True),",
            "            ('\u00c9ric Terrien-Pascal', True),",
            "            (\"Tel'c\", True),",
            "        ]",
            "    )",
            "    def test_edit_fullname_with_special_character(self, new_fullname, expected_valid):",
            "        # Given an existing user",
            "        # When updating the user's fullname",
            "        self.getPage(",
            "            \"/admin/users/\",",
            "            method='POST',",
            "            body={'action': 'edit', 'username': self.USERNAME, 'fullname': new_fullname},",
            "        )",
            "        self.assertStatus(200)",
            "        if expected_valid:",
            "            self.assertInBody(\"User information modified successfully.\")",
            "            self.assertNotInBody(\"Fullname: Must not contain any special characters.\")",
            "        else:",
            "            self.assertNotInBody(\"User information modified successfully.\")",
            "            self.assertInBody(\"Fullname: Must not contain any special characters.\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            # Invalid",
            "            ('http://username', False),",
            "            ('username@test.test', False),",
            "            ('/username/', False),",
            "            # Valid",
            "            ('username.com', True),",
            "            ('admin_user', True),",
            "            ('test.test', True),",
            "            ('test-test', True),",
            "        ]",
            "    )",
            "    def test_add_user_with_special_character(self, new_username, expected_valid):",
            "        self._add_user(new_username, \"eric@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        if expected_valid:",
            "            self.assertInBody(\"User added successfully.\")",
            "            self.assertNotInBody(\"Username: Must not contain any special characters.\")",
            "        else:",
            "            self.assertNotInBody(\"User added successfully.\")",
            "            self.assertInBody(\"Username: Must not contain any special characters.\")",
            "",
            "    def test_add_user_with_empty_username(self):",
            "        \"\"\"",
            "        Verify failure trying to create user without username.",
            "        \"\"\"",
            "        self._add_user(\"\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Username: This field is required.\")",
            "",
            "    def test_add_user_with_existing_username(self):",
            "        \"\"\"",
            "        Verify failure trying to add the same user.",
            "        \"\"\"",
            "        # Given a user named `test1`",
            "        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # When trying to create a new user with the same name",
            "        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then the user list is displayed with an error message.",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"User test1 already exists.\")",
            "",
            "    def test_add_user_with_invalid_root_directory(self):",
            "        \"\"\"",
            "        Verify failure to add a user with invalid root directory.",
            "        \"\"\"",
            "        try:",
            "            self._delete_user(\"test5\")",
            "        except Exception:",
            "            pass",
            "        self._add_user(\"test5\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")",
            "",
            "    def test_add_without_email(self):",
            "        #  Add user to be listed",
            "        self._add_user(\"test2\", None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "",
            "    def test_add_without_user_root(self):",
            "        #  Add user to be listed",
            "        self._add_user(\"test6\", None, \"pr3j5Dwi\", None, UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "",
            "        user = UserObject.get_user('test6')",
            "        self.assertEqual('', user.user_root)",
            "",
            "    def test_add_with_username_too_long(self):",
            "        # Given a too long username",
            "        username = \"test2\" * 52",
            "        # When trying to create the user",
            "        self._add_user(username, None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Username too long.\")",
            "",
            "    def test_add_with_email_too_long(self):",
            "        # Given a too long username",
            "        email = (\"test2\" * 50) + \"@test.com\"",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", email, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Email too long.\")",
            "",
            "    def test_add_with_user_root_too_long(self):",
            "        # Given a too long user root",
            "        user_root = \"/temp/\" * 50",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", user_root, UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Root directory too long.\")",
            "",
            "    def test_add_with_fullname_too_long(self):",
            "        # Given a too long user root",
            "        fullname = \"fullname\" * 50",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE, fullname=fullname)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Fullname too long.\")",
            "",
            "    def test_delete_user_with_not_existing_username(self):",
            "        \"\"\"",
            "        Verify failure to delete invalid username.",
            "        \"\"\"",
            "        self._delete_user(\"test3\")",
            "        self.assertInBody(\"User doesn&#39;t exists!\")",
            "",
            "    def test_delete_our_self(self):",
            "        \"\"\"",
            "        Verify failure to delete our self.",
            "        \"\"\"",
            "        self._delete_user(self.USERNAME)",
            "        self.assertInBody(\"You cannot remove your own account!\")",
            "",
            "    def test_delete_user_admin(self):",
            "        \"\"\"",
            "        Verify failure to delete our self.",
            "        \"\"\"",
            "        # Create another admin user",
            "        self._add_user('admin2', '', 'pr3j5Dwi', '', UserObject.ADMIN_ROLE)",
            "        self.getPage(\"/logout\")",
            "        self.assertStatus(303)",
            "        self.assertHeaderItemValue('Location', self.baseurl + '/')",
            "        self._login('admin2', 'pr3j5Dwi')",
            "",
            "        # Try deleting admin user",
            "        self._delete_user(self.USERNAME)",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"can&#39;t delete admin user\")",
            "",
            "    def test_delete_user_method_get(self):",
            "        # Given a user",
            "        user = UserObject.add_user('newuser')",
            "        user.commit()",
            "        # When trying to delete this user using method GET",
            "        self.getPage(\"/admin/users/?action=delete&username=newuser\", method='GET')",
            "        # Then page return without error",
            "        self.assertStatus(200)",
            "        # Then user is not deleted",
            "        self.assertIsNotNone(UserObject.get_user('newuser'))",
            "",
            "    def test_change_password_with_too_short(self):",
            "        self._edit_user(self.USERNAME, password='short')",
            "        self.assertInBody(\"Password must have between 8 and 128 characters.\")",
            "",
            "    def test_change_password_with_too_long(self):",
            "        new_password = 'a' * 129",
            "        self._edit_user(self.USERNAME, password=new_password)",
            "        self.assertInBody(\"Password must have between 8 and 128 characters.\")",
            "",
            "    def test_change_admin_password(self):",
            "        # Given rdiffweb is configured with admin-password option",
            "        self.app.cfg.admin_password = 'hardcoded'",
            "        try:",
            "            # When trying to update admin password",
            "            self._edit_user('admin', password='new-password')",
            "            # Then the form is refused with 200 OK with an error message.",
            "            self.assertStatus(200)",
            "            self.assertInBody(\"can&#39;t update admin-password defined in configuration file\")",
            "        finally:",
            "            self.app.cfg.admin_password = None",
            "",
            "    def test_edit_user_with_invalid_path(self):",
            "        \"\"\"",
            "        Verify failure trying to update user with invalid path.",
            "        \"\"\"",
            "        userobj = UserObject.add_user('test1')",
            "        userobj.commit()",
            "        self._edit_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        self.assertNotInBody(\"User added successfully.\")",
            "        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")",
            "",
            "    def test_list(self):",
            "        self.getPage(\"/admin/users/\")",
            "        self.assertInBody(\"Users\")",
            "        self.assertInBody(\"User management\")",
            "        self.assertInBody(\"Add user\")",
            "",
            "    def test_edit_user_with_not_existing_username(self):",
            "        \"\"\"",
            "        Verify failure trying to update invalid user.",
            "        \"\"\"",
            "        # Given an invalid username",
            "        username = 'invalid'",
            "        # When trying to edit the user",
            "        self._edit_user(username, \"test1@test.com\", \"test\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        # Then the user list is displayed with an error message",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot edit user `invalid`: user doesn&#39;t exists\")",
            "",
            "    def test_user_invalid_root(self):",
            "        # Delete all user's",
            "        for user in UserObject.query.all():",
            "            if user.username != self.USERNAME:",
            "                user.delete().commit()",
            "        # Change the user's root",
            "        user = UserObject.get_user('admin')",
            "        user.user_root = \"/invalid\"",
            "        user.commit()",
            "        self.getPage(\"/admin/users\")",
            "        self.assertInBody(\"Root directory not accessible!\")",
            "",
            "        # Query the page by default",
            "        user = UserObject.get_user('admin')",
            "        user.user_root = \"/tmp/\"",
            "        user.commit()",
            "        self.getPage(\"/admin/users\")",
            "        self.assertNotInBody(\"Root directory not accessible!\")",
            "",
            "    def test_get_quota(self):",
            "        # Mock a quota.",
            "        self.listener.get_disk_quota.side_effect = None",
            "        self.listener.get_disk_quota.return_value = 654321",
            "        # When querying the user list",
            "        self.getPage(\"/admin/users/\")",
            "        self.assertStatus(200)",
            "        # Then get_disk_quota listenre is called",
            "        self.listener.get_disk_quota.assert_called()",
            "        # Then the quota value is displayed in human readable format",
            "        self.assertInBody(\"638.99 KiB\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota(self):",
            "        # When updating user quota.",
            "        self._edit_user(\"admin\", disk_quota='8765432')",
            "        # Then listenr get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_gib(self):",
            "        # When updating user quota",
            "        self._edit_user(\"admin\", disk_quota='1GiB')",
            "        # Then listern get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 1073741824)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_with_comma(self):",
            "        # When updating quota with comma value",
            "        self._edit_user(\"admin\", disk_quota='1,5 GiB')",
            "        # Then listner get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 1610612736)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_with_leading_dot(self):",
            "        # When updating quota with leading dot",
            "        self._edit_user(\"admin\", disk_quota='.5 GiB')",
            "        # Then listener get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 536870912)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_empty(self):",
            "        # When quota is not defined",
            "        self._edit_user(\"admin\", disk_quota='')",
            "        # Then listener is not called.",
            "        self.listener.set_disk_quota.assert_not_called()",
            "        # Then message is not displayed",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_same_value(self):",
            "        # Given an exiting quota",
            "        self.listener.get_disk_quota.side_effect = None",
            "        self.listener.get_disk_quota.return_value = 1234567890",
            "        # When setting the quota value to the same value",
            "        self._edit_user(\"admin\", disk_quota='1.15 GiB')",
            "        #  Then listener is not called",
            "        self.listener.set_disk_quota.assert_not_called()",
            "        # Then message is not displayed",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_unsupported(self):",
            "        # Given setting quota is not supported",
            "        self.listener.set_disk_quota.side_effect = None",
            "        self.listener.set_disk_quota.return_value = None",
            "        # When updating the quota",
            "        self._edit_user(\"admin\", disk_quota='8765432')",
            "        # Then",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)",
            "        self.assertInBody(\"Setting user&#39;s quota is not supported\")",
            "        self.assertStatus(200)",
            "",
            "    def test_edit_own_role(self):",
            "        # Given an administrator",
            "        # When trygin to update your own role",
            "        self._edit_user(username=self.USERNAME, role=UserObject.MAINTAINER_ROLE)",
            "        # Then an error is returned",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot edit your own role.\")",
            "",
            "    def test_edit_own_mfa(self):",
            "        # Given an administrator",
            "        # When trygin to update your own role",
            "        self._edit_user(username=self.USERNAME, mfa=UserObject.ENABLED_MFA)",
            "        # Then an error is returned",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot change your own two-factor authentication settings.\")"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from unittest.mock import ANY, MagicMock",
            "",
            "import cherrypy",
            "from parameterized import parameterized",
            "",
            "import rdiffweb.test",
            "from rdiffweb.core.model import UserObject",
            "",
            "",
            "class AbstractAdminTest(rdiffweb.test.WebCase):",
            "",
            "    login = True",
            "",
            "    def setUp(self):",
            "        super().setUp()",
            "        self._quota = {}",
            "        self.listener = MagicMock()",
            "        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)",
            "        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)",
            "        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)",
            "        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)",
            "        self.listener.get_disk_quota.side_effect = self._load_quota",
            "        cherrypy.engine.subscribe('get_disk_quota', self.listener.get_disk_quota, priority=40)",
            "        self.listener.get_disk_usage.return_value = 0",
            "        cherrypy.engine.subscribe('get_disk_usage', self.listener.get_disk_usage, priority=40)",
            "        self.listener.set_disk_quota.side_effect = self._store_quota",
            "        cherrypy.engine.subscribe('set_disk_quota', self.listener.set_disk_quota, priority=40)",
            "",
            "    def tearDown(self):",
            "        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)",
            "        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)",
            "        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)",
            "        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)",
            "        cherrypy.engine.unsubscribe('get_disk_quota', self.listener.get_disk_quota)",
            "        cherrypy.engine.unsubscribe('get_disk_usage', self.listener.get_disk_usage)",
            "        cherrypy.engine.unsubscribe('set_disk_quota', self.listener.set_disk_quota)",
            "        return super().tearDown()",
            "",
            "    def _store_quota(self, userobj, value):",
            "        self._quota[userobj.username] = value",
            "",
            "    def _load_quota(self, userobj):",
            "        return self._quota.get(userobj.username, 0)",
            "",
            "    def _add_user(self, username=None, email=None, password=None, user_root=None, role=None, mfa=None, fullname=None):",
            "        b = {}",
            "        b['action'] = 'add'",
            "        if username is not None:",
            "            b['username'] = username",
            "        if email is not None:",
            "            b['email'] = email",
            "        if password is not None:",
            "            b['password'] = password",
            "        if user_root is not None:",
            "            b['user_root'] = user_root",
            "        if role is not None:",
            "            b['role'] = str(role)",
            "        if mfa is not None:",
            "            b['mfa'] = str(mfa)",
            "        if fullname is not None:",
            "            b['fullname'] = str(fullname)",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def _edit_user(",
            "        self, username=None, email=None, password=None, user_root=None, role=None, disk_quota=None, mfa=None",
            "    ):",
            "        b = {}",
            "        b['action'] = 'edit'",
            "        if username is not None:",
            "            b['username'] = username",
            "        if email is not None:",
            "            b['email'] = email",
            "        if password is not None:",
            "            b['password'] = password",
            "        if user_root is not None:",
            "            b['user_root'] = user_root",
            "        if role is not None:",
            "            b['role'] = str(role)",
            "        if disk_quota is not None:",
            "            b['disk_quota'] = disk_quota",
            "        if mfa is not None:",
            "            b['mfa'] = str(mfa)",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def _delete_user(self, username='test1'):",
            "        b = {'action': 'delete', 'username': username}",
            "        self.getPage(\"/admin/users/\", method='POST', body=b)",
            "",
            "    def test_add_user_with_role_admin(self):",
            "        # When trying to create a new user with role admin",
            "        self._add_user(\"admin_role\", \"admin_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.ADMIN_ROLE)",
            "        # Then page return success",
            "        self.assertStatus(200)",
            "        # Then database is updated",
            "        userobj = UserObject.get_user('admin_role')",
            "        self.assertEqual(UserObject.ADMIN_ROLE, userobj.role)",
            "        # Then notification was raised",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_add_user_with_role_maintainer(self):",
            "        self._add_user(\"maintainer_role\", \"maintainer_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.MAINTAINER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertEqual(UserObject.MAINTAINER_ROLE, UserObject.get_user('maintainer_role').role)",
            "",
            "    def test_add_user_with_role_user(self):",
            "        self._add_user(\"user_role\", \"user_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertEqual(UserObject.USER_ROLE, UserObject.get_user('user_role').role)",
            "",
            "    def test_add_user_with_invalid_role(self):",
            "        # When trying to create a new user with an invalid role (admin instead of 0)",
            "        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", 'admin')",
            "        # Then an error message is displayed to the user",
            "        self.assertStatus(200)",
            "        self.assertInBody('Role: Invalid Choice: could not coerce')",
            "        # Then listener are not called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "        # When trying to create a new user with an invalid role (-1)",
            "        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", -1)",
            "        # Then an error message is displayed to the user",
            "        self.assertStatus(200)",
            "        self.assertInBody('User Role: Not a valid choice')",
            "        # Then listener are not called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "    def test_add_edit_delete(self):",
            "        #  Add user to be listed",
            "        self.listener.user_password_changed.reset_mock()",
            "        self._add_user(",
            "            \"test2\", \"test2@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE, mfa=UserObject.DISABLED_MFA",
            "        )",
            "        self.assertInBody(\"User added successfully.\")",
            "        self.assertInBody(\"test2\")",
            "        self.assertInBody(\"test2@test.com\")",
            "        self.listener.user_added.assert_called_once()",
            "        self.listener.user_password_changed.assert_called_once()",
            "        self.listener.user_password_changed.reset_mock()",
            "        #  Update user",
            "        self._edit_user(",
            "            \"test2\", \"chaned@test.com\", \"new-password\", \"/tmp/\", UserObject.ADMIN_ROLE, mfa=UserObject.ENABLED_MFA",
            "        )",
            "        self.listener.user_attr_changed.assert_called()",
            "        self.listener.user_password_changed.assert_called_once()",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertInBody(\"test2\")",
            "        self.assertInBody(\"chaned@test.com\")",
            "        self.assertNotInBody(\"/home/\")",
            "        self.assertInBody(\"/tmp/\")",
            "",
            "        self._delete_user(\"test2\")",
            "        self.listener.user_deleted.assert_called()",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"User account removed.\")",
            "        self.assertNotInBody(\"test2\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            # Invalid",
            "            ('evil.com', False),",
            "            ('http://test', False),",
            "            ('email@test.test', False),",
            "            ('/test/', False),",
            "            # Valid",
            "            ('My fullname', True),",
            "            ('Test Test', True),",
            "            ('\u00c9ric Terrien-Pascal', True),",
            "            (\"Tel'c\", True),",
            "        ]",
            "    )",
            "    def test_edit_fullname_with_special_character(self, new_fullname, expected_valid):",
            "        # Given an existing user",
            "        # When updating the user's fullname",
            "        self.getPage(",
            "            \"/admin/users/\",",
            "            method='POST',",
            "            body={'action': 'edit', 'username': self.USERNAME, 'fullname': new_fullname},",
            "        )",
            "        self.assertStatus(200)",
            "        if expected_valid:",
            "            self.assertInBody(\"User information modified successfully.\")",
            "            self.assertNotInBody(\"Fullname: Must not contain any special characters.\")",
            "        else:",
            "            self.assertNotInBody(\"User information modified successfully.\")",
            "            self.assertInBody(\"Fullname: Must not contain any special characters.\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            # Invalid",
            "            ('http://username', False),",
            "            ('username@test.test', False),",
            "            ('/username/', False),",
            "            # Valid",
            "            ('username.com', True),",
            "            ('admin_user', True),",
            "            ('test.test', True),",
            "            ('test-test', True),",
            "        ]",
            "    )",
            "    def test_add_user_with_special_character(self, new_username, expected_valid):",
            "        self._add_user(new_username, \"eric@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        if expected_valid:",
            "            self.assertInBody(\"User added successfully.\")",
            "            self.assertNotInBody(\"Username: Must not contain any special characters.\")",
            "        else:",
            "            self.assertNotInBody(\"User added successfully.\")",
            "            self.assertInBody(\"Username: Must not contain any special characters.\")",
            "",
            "    def test_add_user_with_empty_username(self):",
            "        \"\"\"",
            "        Verify failure trying to create user without username.",
            "        \"\"\"",
            "        self._add_user(\"\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Username: This field is required.\")",
            "",
            "    def test_add_user_with_existing_username(self):",
            "        \"\"\"",
            "        Verify failure trying to add the same user.",
            "        \"\"\"",
            "        # Given a user named `test1`",
            "        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # When trying to create a new user with the same name",
            "        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then the user list is displayed with an error message.",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"User test1 already exists.\")",
            "",
            "    def test_add_user_with_invalid_root_directory(self):",
            "        \"\"\"",
            "        Verify failure to add a user with invalid root directory.",
            "        \"\"\"",
            "        try:",
            "            self._delete_user(\"test5\")",
            "        except Exception:",
            "            pass",
            "        self._add_user(\"test5\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")",
            "",
            "    def test_add_without_email(self):",
            "        #  Add user to be listed",
            "        self._add_user(\"test2\", None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "",
            "    def test_add_without_user_root(self):",
            "        #  Add user to be listed",
            "        self._add_user(\"test6\", None, \"pr3j5Dwi\", None, UserObject.USER_ROLE)",
            "        self.assertInBody(\"User added successfully.\")",
            "",
            "        user = UserObject.get_user('test6')",
            "        self.assertEqual('', user.user_root)",
            "",
            "    def test_add_with_username_too_long(self):",
            "        # Given a too long username",
            "        username = \"test2\" * 52",
            "        # When trying to create the user",
            "        self._add_user(username, None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Username too long.\")",
            "",
            "    def test_add_with_email_too_long(self):",
            "        # Given a too long username",
            "        email = (\"test2\" * 50) + \"@test.com\"",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", email, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Email too long.\")",
            "",
            "    def test_add_with_user_root_too_long(self):",
            "        # Given a too long user root",
            "        user_root = \"/temp/\" * 50",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", user_root, UserObject.USER_ROLE)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Root directory too long.\")",
            "",
            "    def test_add_with_fullname_too_long(self):",
            "        # Given a too long user root",
            "        fullname = \"fullname\" * 50",
            "        # When trying to create the user",
            "        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE, fullname=fullname)",
            "        # Then an error is raised",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Fullname too long.\")",
            "",
            "    def test_delete_user_with_not_existing_username(self):",
            "        \"\"\"",
            "        Verify failure to delete invalid username.",
            "        \"\"\"",
            "        self._delete_user(\"test3\")",
            "        self.assertInBody(\"User doesn&#39;t exists!\")",
            "",
            "    def test_delete_our_self(self):",
            "        \"\"\"",
            "        Verify failure to delete our self.",
            "        \"\"\"",
            "        self._delete_user(self.USERNAME)",
            "        self.assertInBody(\"You cannot remove your own account!\")",
            "",
            "    def test_delete_user_admin(self):",
            "        \"\"\"",
            "        Verify failure to delete our self.",
            "        \"\"\"",
            "        # Create another admin user",
            "        self._add_user('admin2', '', 'pr3j5Dwi', '', UserObject.ADMIN_ROLE)",
            "        self.getPage(\"/logout\")",
            "        self.assertStatus(303)",
            "        self.assertHeaderItemValue('Location', self.baseurl + '/')",
            "        self._login('admin2', 'pr3j5Dwi')",
            "",
            "        # Try deleting admin user",
            "        self._delete_user(self.USERNAME)",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"can&#39;t delete admin user\")",
            "",
            "    def test_delete_user_method_get(self):",
            "        # Given a user",
            "        user = UserObject.add_user('newuser')",
            "        user.commit()",
            "        # When trying to delete this user using method GET",
            "        self.getPage(\"/admin/users/?action=delete&username=newuser\", method='GET')",
            "        # Then page return without error",
            "        self.assertStatus(200)",
            "        # Then user is not deleted",
            "        self.assertIsNotNone(UserObject.get_user('newuser'))",
            "",
            "    def test_change_password_with_too_short(self):",
            "        self._edit_user(self.USERNAME, password='short')",
            "        self.assertInBody(\"Password must have between 8 and 128 characters.\")",
            "",
            "    def test_change_password_with_too_long(self):",
            "        new_password = 'a' * 129",
            "        self._edit_user(self.USERNAME, password=new_password)",
            "        self.assertInBody(\"Password must have between 8 and 128 characters.\")",
            "",
            "    def test_change_admin_password(self):",
            "        # Given rdiffweb is configured with admin-password option",
            "        self.app.cfg.admin_password = 'hardcoded'",
            "        try:",
            "            # When trying to update admin password",
            "            self._edit_user('admin', password='new-password')",
            "            # Then the form is refused with 200 OK with an error message.",
            "            self.assertStatus(200)",
            "            self.assertInBody(\"can&#39;t update admin-password defined in configuration file\")",
            "        finally:",
            "            self.app.cfg.admin_password = None",
            "",
            "    def test_edit_user_with_invalid_path(self):",
            "        \"\"\"",
            "        Verify failure trying to update user with invalid path.",
            "        \"\"\"",
            "        userobj = UserObject.add_user('test1')",
            "        userobj.commit()",
            "        self._edit_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        self.assertNotInBody(\"User added successfully.\")",
            "        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")",
            "",
            "    def test_list(self):",
            "        self.getPage(\"/admin/users/\")",
            "        self.assertInBody(\"Users\")",
            "        self.assertInBody(\"User management\")",
            "        self.assertInBody(\"Add user\")",
            "",
            "    def test_edit_user_with_not_existing_username(self):",
            "        \"\"\"",
            "        Verify failure trying to update invalid user.",
            "        \"\"\"",
            "        # Given an invalid username",
            "        username = 'invalid'",
            "        # When trying to edit the user",
            "        self._edit_user(username, \"test1@test.com\", \"test\", \"/var/invalid/\", UserObject.USER_ROLE)",
            "        # Then the user list is displayed with an error message",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot edit user `invalid`: user doesn&#39;t exists\")",
            "",
            "    def test_user_invalid_root(self):",
            "        # Change the user's root",
            "        user = UserObject.get_user(self.USERNAME)",
            "        user.user_root = \"/invalid\"",
            "        user.commit()",
            "        self.getPage(\"/admin/users\")",
            "        self.assertInBody(\"Root directory not accessible!\")",
            "",
            "        # Query the page by default",
            "        user = UserObject.get_user('admin')",
            "        user.user_root = \"/tmp/\"",
            "        user.commit()",
            "        self.getPage(\"/admin/users\")",
            "        self.assertNotInBody(\"Root directory not accessible!\")",
            "",
            "    def test_get_quota(self):",
            "        # Mock a quota.",
            "        self.listener.get_disk_quota.side_effect = None",
            "        self.listener.get_disk_quota.return_value = 654321",
            "        # When querying the user list",
            "        self.getPage(\"/admin/users/\")",
            "        self.assertStatus(200)",
            "        # Then get_disk_quota listenre is called",
            "        self.listener.get_disk_quota.assert_called()",
            "        # Then the quota value is displayed in human readable format",
            "        self.assertInBody(\"638.99 KiB\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota(self):",
            "        # When updating user quota.",
            "        self._edit_user(\"admin\", disk_quota='8765432')",
            "        # Then listenr get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_gib(self):",
            "        # When updating user quota",
            "        self._edit_user(\"admin\", disk_quota='1GiB')",
            "        # Then listern get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 1073741824)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_with_comma(self):",
            "        # When updating quota with comma value",
            "        self._edit_user(\"admin\", disk_quota='1,5 GiB')",
            "        # Then listner get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 1610612736)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_as_with_leading_dot(self):",
            "        # When updating quota with leading dot",
            "        self._edit_user(\"admin\", disk_quota='.5 GiB')",
            "        # Then listener get called",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 536870912)",
            "        # Then a success message is displayed",
            "        self.assertInBody(\"User information modified successfully.\")",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_empty(self):",
            "        # When quota is not defined",
            "        self._edit_user(\"admin\", disk_quota='')",
            "        # Then listener is not called.",
            "        self.listener.set_disk_quota.assert_not_called()",
            "        # Then message is not displayed",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_same_value(self):",
            "        # Given an exiting quota",
            "        self.listener.get_disk_quota.side_effect = None",
            "        self.listener.get_disk_quota.return_value = 1234567890",
            "        # When setting the quota value to the same value",
            "        self._edit_user(\"admin\", disk_quota='1.15 GiB')",
            "        #  Then listener is not called",
            "        self.listener.set_disk_quota.assert_not_called()",
            "        # Then message is not displayed",
            "        self.assertStatus(200)",
            "",
            "    def test_set_quota_unsupported(self):",
            "        # Given setting quota is not supported",
            "        self.listener.set_disk_quota.side_effect = None",
            "        self.listener.set_disk_quota.return_value = None",
            "        # When updating the quota",
            "        self._edit_user(\"admin\", disk_quota='8765432')",
            "        # Then",
            "        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)",
            "        self.assertInBody(\"Setting user&#39;s quota is not supported\")",
            "        self.assertStatus(200)",
            "",
            "    def test_edit_own_role(self):",
            "        # Given an administrator",
            "        # When trygin to update your own role",
            "        self._edit_user(username=self.USERNAME, role=UserObject.MAINTAINER_ROLE)",
            "        # Then an error is returned",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot edit your own role.\")",
            "",
            "    def test_edit_own_mfa(self):",
            "        # Given an administrator",
            "        # When trygin to update your own role",
            "        self._edit_user(username=self.USERNAME, mfa=UserObject.ENABLED_MFA)",
            "        # Then an error is returned",
            "        self.assertStatus(200)",
            "        self.assertInBody(\"Cannot change your own two-factor authentication settings.\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "399": [
                "AbstractAdminTest",
                "test_user_invalid_root"
            ],
            "400": [
                "AbstractAdminTest",
                "test_user_invalid_root"
            ],
            "401": [
                "AbstractAdminTest",
                "test_user_invalid_root"
            ],
            "402": [
                "AbstractAdminTest",
                "test_user_invalid_root"
            ],
            "404": [
                "AbstractAdminTest",
                "test_user_invalid_root"
            ]
        },
        "addLocation": []
    },
    "rdiffweb/core/librdiff.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 845,
                "afterPatchRowNumber": 845,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 846,
                "afterPatchRowNumber": 846,
                "PatchRowcode": "     \"\"\"Represent one rdiff-backup repository.\"\"\""
            },
            "2": {
                "beforePatchRowNumber": 847,
                "afterPatchRowNumber": 847,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 848,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __init__(self, user_root, path, encoding):"
            },
            "4": {
                "beforePatchRowNumber": 849,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if isinstance(user_root, str):"
            },
            "5": {
                "beforePatchRowNumber": 850,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            user_root = os.fsencode(user_root)"
            },
            "6": {
                "beforePatchRowNumber": 851,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if isinstance(path, str):"
            },
            "7": {
                "beforePatchRowNumber": 852,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            path = os.fsencode(path)"
            },
            "8": {
                "beforePatchRowNumber": 853,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert isinstance(user_root, bytes)"
            },
            "9": {
                "beforePatchRowNumber": 854,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert isinstance(path, bytes)"
            },
            "10": {
                "beforePatchRowNumber": 855,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert encoding"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 848,
                "PatchRowcode": "+    def __init__(self, full_path, encoding):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 849,
                "PatchRowcode": "+        assert encoding, 'encoding is required'"
            },
            "13": {
                "beforePatchRowNumber": 856,
                "afterPatchRowNumber": 850,
                "PatchRowcode": "         self._encoding = encodings.search_function(encoding)"
            },
            "14": {
                "beforePatchRowNumber": 857,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert self._encoding"
            },
            "15": {
                "beforePatchRowNumber": 858,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.path = path.strip(b\"/\")"
            },
            "16": {
                "beforePatchRowNumber": 859,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if self.path:"
            },
            "17": {
                "beforePatchRowNumber": 860,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.full_path = os.path.normpath(os.path.join(user_root, self.path))"
            },
            "18": {
                "beforePatchRowNumber": 861,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else:"
            },
            "19": {
                "beforePatchRowNumber": 862,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.full_path = os.path.normpath(user_root)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 851,
                "PatchRowcode": "+        assert self._encoding, 'encoding must be a valid charset'"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 852,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 853,
                "PatchRowcode": "+        # Validate and sanitize the full_path"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 854,
                "PatchRowcode": "+        assert full_path, 'full path is required'"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 855,
                "PatchRowcode": "+        self.full_path = os.fsencode(full_path) if isinstance(full_path, str) else full_path"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 856,
                "PatchRowcode": "+        assert os.path.isabs(self.full_path), 'full_path must be absolute path'"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 857,
                "PatchRowcode": "+        self.full_path = os.path.normpath(self.full_path)"
            },
            "27": {
                "beforePatchRowNumber": 863,
                "afterPatchRowNumber": 858,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 864,
                "afterPatchRowNumber": 859,
                "PatchRowcode": "         # The location of rdiff-backup-data directory."
            },
            "29": {
                "beforePatchRowNumber": 865,
                "afterPatchRowNumber": 860,
                "PatchRowcode": "         self._data_path = os.path.join(self.full_path, RDIFF_BACKUP_DATA)"
            },
            "30": {
                "beforePatchRowNumber": 1087,
                "afterPatchRowNumber": 1082,
                "PatchRowcode": "         assert isinstance(path, bytes)"
            },
            "31": {
                "beforePatchRowNumber": 1088,
                "afterPatchRowNumber": 1083,
                "PatchRowcode": "         path = path.strip(b'/')"
            },
            "32": {
                "beforePatchRowNumber": 1089,
                "afterPatchRowNumber": 1084,
                "PatchRowcode": "         if path in [b'.', b'']:"
            },
            "33": {
                "beforePatchRowNumber": 1090,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # For repository we use either path if defined or the directory base name"
            },
            "34": {
                "beforePatchRowNumber": 1091,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if not self.path:"
            },
            "35": {
                "beforePatchRowNumber": 1092,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return self._decode(unquote(os.path.basename(self.full_path)))"
            },
            "36": {
                "beforePatchRowNumber": 1093,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return self._decode(unquote(self.path))"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1085,
                "PatchRowcode": "+            # For repository the directory base name"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1086,
                "PatchRowcode": "+            return self._decode(unquote(os.path.basename(self.full_path)))"
            },
            "39": {
                "beforePatchRowNumber": 1094,
                "afterPatchRowNumber": 1087,
                "PatchRowcode": "         else:"
            },
            "40": {
                "beforePatchRowNumber": 1095,
                "afterPatchRowNumber": 1088,
                "PatchRowcode": "             # For path, we use the dir name"
            },
            "41": {
                "beforePatchRowNumber": 1096,
                "afterPatchRowNumber": 1089,
                "PatchRowcode": "             return self._decode(unquote(os.path.basename(path)))"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import bisect",
            "import calendar",
            "import encodings",
            "import logging",
            "import os",
            "import re",
            "import shutil",
            "import subprocess",
            "import sys",
            "import threading",
            "import time",
            "from datetime import timedelta",
            "from subprocess import CalledProcessError",
            "",
            "import psutil",
            "from cached_property import cached_property",
            "",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "# Define the logger",
            "logger = logging.getLogger(__name__)",
            "",
            "# Constant for the rdiff-backup-data folder name.",
            "RDIFF_BACKUP_DATA = b\"rdiff-backup-data\"",
            "",
            "# Increment folder name.",
            "INCREMENTS = b\"increments\"",
            "",
            "# Define the default LANG environment variable to be passed to rdiff-backup",
            "# restore command line to make sure the binary output stdout as utf8 otherwise",
            "# we end up with \\x encoded characters.",
            "STDOUT_ENCODING = 'utf-8'",
            "LANG = \"en_US.\" + STDOUT_ENCODING",
            "",
            "",
            "def rdiff_backup_version():",
            "    \"\"\"",
            "    Get rdiff-backup version",
            "    \"\"\"",
            "    try:",
            "        output = subprocess.check_output([find_rdiff_backup(), '--version'])",
            "        m = re.search(b'([0-9]+).([0-9]+).([0-9]+)', output)",
            "        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))",
            "    except Exception:",
            "        return (0, 0, 0)",
            "",
            "",
            "def find_rdiff_backup():",
            "    \"\"\"",
            "    Lookup for `rdiff-backup` executable. Raise an exception if not found.",
            "    \"\"\"",
            "    cmd = shutil.which('rdiff-backup')",
            "    if not cmd:",
            "        raise FileNotFoundError(\"can't find `rdiff-backup` executable in PATH: %s\" % os.environ['PATH'])",
            "    return os.fsencode(cmd)",
            "",
            "",
            "def find_rdiff_backup_delete():",
            "    \"\"\"",
            "    Lookup for `rdiff-backup-delete` executable. Raise an exception if not found.",
            "    \"\"\"",
            "    cmd = shutil.which('rdiff-backup-delete')",
            "    if not cmd:",
            "        raise FileNotFoundError(",
            "            \"can't find `rdiff-backup-delete` executable in PATH: %s, make sure you have rdiff-backup >= 2.0.1 installed\"",
            "            % os.environ['PATH']",
            "        )",
            "    return os.fsencode(cmd)",
            "",
            "",
            "def unquote(name):",
            "    \"\"\"Remove quote from the given name.\"\"\"",
            "    assert isinstance(name, bytes)",
            "",
            "    # This function just gives back the original text if it can decode it",
            "    def unquoted_char(match):",
            "        \"\"\"For each ;000 return the corresponding byte.\"\"\"",
            "        if len(match.group()) != 4:",
            "            return match.group",
            "        try:",
            "            return bytes([int(match.group()[1:])])",
            "        except ValueError:",
            "            return match.group",
            "",
            "    # Remove quote using regex",
            "    return re.sub(b\";[0-9]{3}\", unquoted_char, name, re.S)",
            "",
            "",
            "def popen(cmd, stderr=None, env=None):",
            "    \"\"\"",
            "    Alternative to os.popen() to support a `cmd` with a list of arguments and",
            "    return a file object that return bytes instead of string.",
            "",
            "    `stderr` could be subprocess.STDOUT or subprocess.DEVNULL or a function.",
            "    Otherwise, the error is redirect to logger.",
            "    \"\"\"",
            "    # Check if stderr should be pipe.",
            "    pipe_stderr = stderr == subprocess.PIPE or hasattr(stderr, '__call__') or stderr is None",
            "    proc = subprocess.Popen(",
            "        cmd,",
            "        shell=False,",
            "        stdout=subprocess.PIPE,",
            "        stderr=subprocess.PIPE if pipe_stderr else stderr,",
            "        env=env,",
            "    )",
            "    if pipe_stderr:",
            "        t = threading.Thread(target=_readerthread, args=(proc.stderr, stderr))",
            "        t.daemon = True",
            "        t.start()",
            "    return _wrap_close(proc.stdout, proc)",
            "",
            "",
            "# Helper for popen() to redirect stderr to a logger.",
            "",
            "",
            "def _readerthread(stream, func):",
            "    \"\"\"",
            "    Read stderr and pipe each line to logger.",
            "    \"\"\"",
            "    func = func or logger.debug",
            "    for line in stream:",
            "        func(line.decode(STDOUT_ENCODING, 'replace').strip('\\n'))",
            "    stream.close()",
            "",
            "",
            "# Helper for popen() to close process when the pipe is closed.",
            "",
            "",
            "class _wrap_close:",
            "    def __init__(self, stream, proc):",
            "        self._stream = stream",
            "        self._proc = proc",
            "",
            "    def close(self):",
            "        self._stream.close()",
            "        returncode = self._proc.wait()",
            "        if returncode == 0:",
            "            return None",
            "        return returncode",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    def __getattr__(self, name):",
            "        return getattr(self._stream, name)",
            "",
            "    def __iter__(self):",
            "        return iter(self._stream)",
            "",
            "",
            "class AccessDeniedError(Exception):",
            "    pass",
            "",
            "",
            "class DoesNotExistError(Exception):",
            "    pass",
            "",
            "",
            "class RdiffTime(object):",
            "",
            "    \"\"\"Time information has two components: the local time, stored in GMT as",
            "    seconds since Epoch, and the timezone, stored as a seconds offset. Since",
            "    the server may not be in the same timezone as the user, we cannot rely on",
            "    the built-in localtime() functions, but look at the rdiff-backup string",
            "    for timezone information.  As a general rule, we always display the",
            "    \"local\" time, but pass the timezone information on to rdiff-backup, so",
            "    it can restore to the correct state\"\"\"",
            "",
            "    def __init__(self, value=None, tz_offset=None):",
            "        assert value is None or isinstance(value, int) or isinstance(value, str)",
            "        if value is None:",
            "            # Get GMT time.",
            "            self._time_seconds = int(time.time())",
            "            self._tz_offset = 0",
            "        elif isinstance(value, int):",
            "            self._time_seconds = value",
            "            self._tz_offset = tz_offset or 0",
            "        else:",
            "            self._from_str(value)",
            "",
            "    def _from_str(self, time_string):",
            "        if time_string[10] != 'T':",
            "            raise ValueError('missing date time separator (T): ' + time_string)",
            "        if time_string[19] not in ['-', '+', 'Z']:",
            "            raise ValueError('missing timezone info (-, + or Z): ' + time_string)",
            "        if time_string[4] != '-' or time_string[7] != '-':",
            "            raise ValueError('missing date separator (-): ' + time_string)",
            "        if not (time_string[13] in [':', '-'] and time_string[16] in [':', '-']):",
            "            raise ValueError('missing date separator (-): ' + time_string)",
            "        try:",
            "            year = int(time_string[0:4])",
            "            if not (1900 < year < 2200):",
            "                raise ValueError('unexpected year value between 1900 and 2200: ' + str(year))",
            "            month = int(time_string[5:7])",
            "            if not (1 <= month <= 12):",
            "                raise ValueError('unexpected month value between 1 and 12: ' + str(month))",
            "            day = int(time_string[8:10])",
            "            if not (1 <= day <= 31):",
            "                raise ValueError('unexpected day value between 1 and 31: ' + str(day))",
            "            hour = int(time_string[11:13])",
            "            if not (0 <= hour <= 23):",
            "                raise ValueError('unexpected hour value between 1 and 23: ' + str(hour))",
            "            minute = int(time_string[14:16])",
            "            if not (0 <= minute <= 60):",
            "                raise ValueError('unexpected minute value between 1 and 60: ' + str(minute))",
            "            second = int(time_string[17:19])",
            "            if not (0 <= second <= 61):  # leap seconds",
            "                raise ValueError('unexpected second value between 1 and 61: ' + str(second))",
            "            timetuple = (year, month, day, hour, minute, second, -1, -1, 0)",
            "            self._time_seconds = calendar.timegm(timetuple)",
            "            self._tz_offset = self._tzdtoseconds(time_string[19:])",
            "            self._tz_str()  # to get assertions there",
            "        except (TypeError, ValueError, AssertionError):",
            "            raise ValueError(time_string)",
            "",
            "    def epoch(self):",
            "        return self._time_seconds - self._tz_offset",
            "",
            "    def _tz_str(self):",
            "        if self._tz_offset:",
            "            hours, minutes = divmod(abs(self._tz_offset) // 60, 60)",
            "            assert 0 <= hours <= 23",
            "            assert 0 <= minutes <= 59",
            "            if self._tz_offset > 0:",
            "                plus_minus = \"+\"",
            "            else:",
            "                plus_minus = \"-\"",
            "            return \"%s%s:%s\" % (plus_minus, \"%02d\" % hours, \"%02d\" % minutes)",
            "        else:",
            "            return \"Z\"",
            "",
            "    def set_time(self, hour, minute, second):",
            "        year = time.gmtime(self._time_seconds)[0]",
            "        month = time.gmtime(self._time_seconds)[1]",
            "        day = time.gmtime(self._time_seconds)[2]",
            "        _time_seconds = calendar.timegm((year, month, day, hour, minute, second, -1, -1, 0))",
            "        return RdiffTime(_time_seconds, self._tz_offset)",
            "",
            "    def _tzdtoseconds(self, tzd):",
            "        \"\"\"Given w3 compliant TZD, converts it to number of seconds from UTC\"\"\"",
            "        if tzd == \"Z\":",
            "            return 0",
            "        assert len(tzd) == 6  # only accept forms like +08:00 or +08-00 for now",
            "        assert (tzd[0] == \"-\" or tzd[0] == \"+\") and tzd[3] in [\":\", '-']",
            "        if tzd[0] == \"+\":",
            "            plus_minus = 1",
            "        else:",
            "            plus_minus = -1",
            "        return plus_minus * 60 * (60 * int(tzd[1:3]) + int(tzd[4:]))",
            "",
            "    def __add__(self, other):",
            "        \"\"\"Support plus (+) timedelta\"\"\"",
            "        assert isinstance(other, timedelta)",
            "        return RdiffTime(self._time_seconds + int(other.total_seconds()), self._tz_offset)",
            "",
            "    def __sub__(self, other):",
            "        \"\"\"Support minus (-) timedelta\"\"\"",
            "        assert isinstance(other, timedelta) or isinstance(other, RdiffTime)",
            "        # Sub with timedelta, return RdiffTime",
            "        if isinstance(other, timedelta):",
            "            return RdiffTime(self._time_seconds - int(other.total_seconds()), self._tz_offset)",
            "",
            "        # Sub with RdiffTime, return timedelta",
            "        if isinstance(other, RdiffTime):",
            "            return timedelta(seconds=self._time_seconds - other._time_seconds)",
            "",
            "    def __int__(self):",
            "        \"\"\"Return this date as seconds since epoch.\"\"\"",
            "        return self.epoch()",
            "",
            "    def __lt__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() < other.epoch()",
            "",
            "    def __le__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() <= other.epoch()",
            "",
            "    def __gt__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() > other.epoch()",
            "",
            "    def __ge__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() >= other.epoch()",
            "",
            "    def __eq__(self, other):",
            "        return isinstance(other, RdiffTime) and self.epoch() == other.epoch()",
            "",
            "    def __hash__(self):",
            "        return hash(self.epoch())",
            "",
            "    def __str__(self):",
            "        \"\"\"return utf-8 string\"\"\"",
            "        value = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(self._time_seconds))",
            "        return value + self._tz_str()",
            "",
            "    def __repr__(self):",
            "        \"\"\"return second since epoch\"\"\"",
            "        return \"RdiffTime('\" + str(self) + \"')\"",
            "",
            "",
            "class RdiffDirEntry(object):",
            "    \"\"\"",
            "    Includes name, isdir, file_size, exists, and dict (change_dates) of sorted",
            "    local dates when backed up.",
            "    \"\"\"",
            "",
            "    def __init__(self, repo, path, exists, increments):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert isinstance(path, bytes)",
            "        # Keep reference to the path and repo object.",
            "        self._repo = repo",
            "        self.path = path",
            "        # Absolute path to the directory",
            "        if self.isroot:",
            "            self.full_path = self._repo.full_path",
            "        else:",
            "            self.full_path = os.path.join(self._repo.full_path, self.path)",
            "        # May need to compute our own state if not provided.",
            "        self.exists = exists",
            "        # Store the increments sorted by date.",
            "        # See self.last_change_date()",
            "        self._increments = sorted(increments, key=lambda x: x.date)",
            "",
            "    @property",
            "    def display_name(self):",
            "        \"\"\"Return the most human readable filename. Without quote.\"\"\"",
            "        return self._repo.get_display_name(self.path)",
            "",
            "    @property",
            "    def isroot(self):",
            "        \"\"\"",
            "        Check if the directory entry represent the root of the repository.",
            "        Return True when path is empty.",
            "        \"\"\"",
            "        return self.path == b''",
            "",
            "    @cached_property",
            "    def isdir(self):",
            "        \"\"\"Lazy check if entry is a directory\"\"\"",
            "        if self.exists:",
            "            # If the entry exists, check if it's a directory",
            "            return os.path.isdir(self.full_path)",
            "        # Check if increments is a directory",
            "        for increment in self._increments:",
            "            if increment.is_missing:",
            "                # Ignore missing increment...",
            "                continue",
            "            return increment.isdir",
            "",
            "    @cached_property",
            "    def file_size(self):",
            "        \"\"\"",
            "        Return the current file size in bytes.",
            "        Return negative value (-1) for folder and deleted files.",
            "        \"\"\"",
            "        if self.isdir or not self.exists:",
            "            return -1",
            "        else:",
            "            try:",
            "                return os.lstat(self.full_path).st_size",
            "            except Exception:",
            "                logger.warning(\"cannot lstat on file [%s]\", self.full_path, exc_info=1)",
            "                return 0",
            "",
            "    def get_file_size(self, date=None):",
            "        # A viable place to get the filesize of a deleted entry",
            "        # it to get it from file_statistics",
            "        try:",
            "            stats = self._repo.file_statistics[date]",
            "            # File stats uses unquoted name.",
            "            unquote_path = unquote(self.path)",
            "            return stats.get_source_size(unquote_path)",
            "        except Exception:",
            "            logger.warning(\"cannot find file statistic [%s]\", self.last_change_date, exc_info=1)",
            "        return -1",
            "",
            "    @cached_property",
            "    def change_dates(self):",
            "        \"\"\"",
            "        Return a list of dates when this item has changes. Represent the",
            "        previous revision. From old to new.",
            "        \"\"\"",
            "        # Exception for root path, use backups dates.",
            "        if self.isroot:",
            "            return self._repo.backup_dates",
            "",
            "        # Compute the dates",
            "        change_dates = set()",
            "        for increment in self._increments:",
            "            # Get date of the increment as reference",
            "            change_date = increment.date",
            "            # If the increment is a \"missing\" increment, need to get the date",
            "            # before the folder was removed.",
            "            if increment.is_missing:",
            "                change_date = self._get_previous_backup_date(change_date)",
            "",
            "            if change_date:",
            "                change_dates.add(change_date)",
            "",
            "        # If the directory exists, add the last known backup date.",
            "        if self.exists and self._repo.last_backup_date:",
            "            change_dates.add(self._repo.last_backup_date)",
            "",
            "        # Return the list of dates.",
            "        return sorted(change_dates)",
            "",
            "    def _get_previous_backup_date(self, date):",
            "        \"\"\"Return the previous backup date.\"\"\"",
            "        index = bisect.bisect_left(self._repo.backup_dates, date)",
            "        if index == 0:",
            "            return None",
            "        return self._repo.backup_dates[index - 1]",
            "",
            "    @cached_property",
            "    def last_change_date(self):",
            "        \"\"\"Return last change date or False.\"\"\"",
            "        return self.change_dates and self.change_dates[-1]",
            "",
            "",
            "class AbstractEntry:",
            "    SUFFIXES = None",
            "",
            "    @classmethod",
            "    def _extract_date(cls, filename, onerror=None):",
            "        \"\"\"",
            "        Extract date from rdiff-backup filenames.",
            "        \"\"\"",
            "        # Extract suffix",
            "        suffix = None",
            "        for s in cls.SUFFIXES:",
            "            if filename.endswith(s):",
            "                suffix = s",
            "                break",
            "        if not suffix:",
            "            raise ValueError(filename)",
            "        # Parse date",
            "        filename_without_suffix = filename[: -len(suffix)]",
            "        parts = filename_without_suffix.rsplit(b'.', 1)",
            "        if len(parts) != 2:",
            "            return onerror(ValueError(''))",
            "        date_string = unquote(parts[1]).decode('ascii')",
            "        try:",
            "            return RdiffTime(date_string)",
            "        except Exception as e:",
            "            if onerror is None:",
            "                raise",
            "            return onerror(e)",
            "",
            "",
            "class MetadataEntry(AbstractEntry):",
            "    PREFIX = None",
            "    SUFFIXES = None",
            "    on_date_error = None",
            "",
            "    def __init__(self, repo, name):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert isinstance(name, bytes)",
            "        assert name.startswith(self.PREFIX)",
            "        assert any(name.endswith(s) for s in self.SUFFIXES), 'name %s should ends with: %s' % (name, self.SUFFIXES)",
            "        self.repo = repo",
            "        self.name = name",
            "        self.path = os.path.join(self.repo._data_path, self.name)",
            "        self.date = self._extract_date(name, onerror=self.on_date_error)",
            "",
            "    def _open(self):",
            "        \"\"\"",
            "        Should be used to open the increment file. This method handle",
            "        compressed vs not-compressed file.",
            "        \"\"\"",
            "        if self._is_compressed:",
            "            return popen(['zcat', self.path])",
            "        return open(self.path, 'rb')",
            "",
            "    @property",
            "    def _is_compressed(self):",
            "        return self.name.endswith(b\".gz\")",
            "",
            "",
            "class MirrorMetadataEntry(MetadataEntry):",
            "    PREFIX = b'mirror_metadata.'",
            "    SUFFIXES = [",
            "        b'.diff',",
            "        b'.diff.gz',",
            "        b\".snapshot.gz\",",
            "        b\".snapshot\",",
            "    ]",
            "",
            "",
            "class IncrementEntry(AbstractEntry):",
            "",
            "    \"\"\"Instance of the class represent one increment at a specific date for one",
            "    repository. The base repository is provided in the default constructor",
            "    and the date is provided using an error_log.* file\"\"\"",
            "",
            "    SUFFIXES = [",
            "        b\".missing\",",
            "        b\".snapshot.gz\",",
            "        b\".snapshot\",",
            "        b\".diff\",",
            "        b\".diff.gz\",",
            "        b\".dir\",",
            "    ]",
            "",
            "    def __init__(self, name):",
            "        \"\"\"Default constructor for an increment entry. User must provide the",
            "        repository directory and an entry name. The entry name correspond",
            "        to an error_log.* filename.\"\"\"",
            "        self.name, self.date, self.suffix = IncrementEntry._split(name)",
            "",
            "    @property",
            "    def isdir(self):",
            "        return self.suffix == b\".dir\"",
            "",
            "    @property",
            "    def is_missing(self):",
            "        \"\"\"Check if the curent entry is a missing increment.\"\"\"",
            "        return self.suffix == b\".missing\"",
            "",
            "    @property",
            "    def is_snapshot(self):",
            "        \"\"\"Check if the current entry is a snapshot increment.\"\"\"",
            "        return self.suffix in [b\".snapshot.gz\", b\".snapshot\"]",
            "",
            "    @classmethod",
            "    def _split(cls, filename):",
            "        \"\"\"Return tuple with filename, date, suffix\"\"\"",
            "        assert isinstance(filename, bytes)",
            "        # Extract suffix",
            "        suffix = None",
            "        for s in cls.SUFFIXES:",
            "            if filename.endswith(s):",
            "                suffix = s",
            "                break",
            "        if not suffix:",
            "            raise ValueError(filename)",
            "        # Parse date and raise error on failure",
            "        filename_without_suffix = filename[: -len(suffix)]",
            "        name, date_string = filename_without_suffix.rsplit(b'.', 1)",
            "        date_string = unquote(date_string).decode('ascii')",
            "        date = RdiffTime(date_string)",
            "        return (name, date, suffix)",
            "",
            "    def __gt__(self, other):",
            "        return self.date.__gt__(other.date)",
            "",
            "    def __lt__(self, other):",
            "        return self.date.__lt__(other.date)",
            "",
            "",
            "class FileStatisticsEntry(MetadataEntry):",
            "",
            "    \"\"\"",
            "    Represent a single file_statistics.",
            "",
            "    File Statistics contains different information related to each file of",
            "    the backup. This class provide a simple and easy way to access this",
            "    data.",
            "    \"\"\"",
            "",
            "    PREFIX = b'file_statistics.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    def get_mirror_size(self, path):",
            "        \"\"\"Return the value of MirrorSize for the given file.",
            "        path is the relative path from repo root.\"\"\"",
            "        try:",
            "            return int(self._search(path)[\"mirror_size\"])",
            "        except ValueError:",
            "            logger.warning(\"mirror size not found for [%r]\", path, exc_info=1)",
            "            return 0",
            "",
            "    def get_source_size(self, path):",
            "        \"\"\"Return the value of SourceSize for the given file.",
            "        path is the relative path from repo root.\"\"\"",
            "        try:",
            "            return int(self._search(path)[\"source_size\"])",
            "        except ValueError:",
            "            logger.warning(\"source size not found for [%r]\", path, exc_info=1)",
            "            return 0",
            "",
            "    def _search(self, path):",
            "        \"\"\"",
            "        This function search for a file entry in the file_statistics compress",
            "        file. Since python gzip.open() seams to be 2 time slower, we directly use",
            "        zlib library on python2.",
            "        \"\"\"",
            "        logger.debug(\"read file_statistics [%r]\", self.name)",
            "",
            "        path += b' '",
            "",
            "        with self._open() as f:",
            "            for line in f:",
            "                if not line.startswith(path):",
            "                    continue",
            "                break",
            "",
            "        # Split the line into array",
            "        data = line.rstrip(b'\\r\\n').rsplit(b' ', 4)",
            "        # From array create an entry",
            "        return {'changed': data[1], 'source_size': data[2], 'mirror_size': data[3], 'increment_size': data[4]}",
            "",
            "",
            "class SessionStatisticsEntry(MetadataEntry):",
            "    \"\"\"Represent a single session_statistics.\"\"\"",
            "",
            "    PREFIX = b'session_statistics.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    ATTRS = [",
            "        'starttime',",
            "        'endtime',",
            "        'elapsedtime',",
            "        'sourcefiles',",
            "        'sourcefilesize',",
            "        'mirrorfiles',",
            "        'mirrorfilesize',",
            "        'newfiles',",
            "        'newfilesize',",
            "        'deletedfiles',",
            "        'deletedfilesize',",
            "        'changedfiles',",
            "        'changedsourcesize',",
            "        'changedmirrorsize',",
            "        'incrementfiles',",
            "        'incrementfilesize',",
            "        'totaldestinationsizechange',",
            "        'errors',",
            "    ]",
            "",
            "    def _load(self):",
            "        \"\"\"This method is used to read the session_statistics and create the",
            "        appropriate structure to quickly get the data.",
            "",
            "        File Statistics contains different information related to each file of",
            "        the backup. This class provide a simple and easy way to access this",
            "        data.\"\"\"",
            "",
            "        with self._open() as f:",
            "            for line in f.readlines():",
            "                # Read the line into array",
            "                line = line.rstrip(b'\\r\\n')",
            "                data_line = line.split(b\" \", 2)",
            "                # Read line into tuple",
            "                (key, value) = tuple(data_line)[0:2]",
            "                if b'.' in value:",
            "                    value = float(value)",
            "                else:",
            "                    value = int(value)",
            "                setattr(self, key.lower().decode('ascii'), value)",
            "",
            "    def __getattr__(self, name):",
            "        \"\"\"",
            "        Intercept attribute getter to load the file.",
            "        \"\"\"",
            "        if name in self.ATTRS:",
            "            self._load()",
            "        return self.__dict__[name]",
            "",
            "",
            "class CurrentMirrorEntry(MetadataEntry):",
            "    PID_RE = re.compile(b\"^PID\\\\s*([0-9]+)\", re.I | re.M)",
            "",
            "    PREFIX = b'current_mirror.'",
            "    SUFFIXES = [b'.data']",
            "",
            "    def extract_pid(self):",
            "        \"\"\"",
            "        Return process ID from a current mirror marker, if any",
            "        \"\"\"",
            "        with open(self.path, 'rb') as f:",
            "            match = self.PID_RE.search(f.read())",
            "        if not match:",
            "            return None",
            "        return int(match.group(1))",
            "",
            "",
            "class LogEntry(MetadataEntry):",
            "    PREFIX = b'error_log.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    @cached_property",
            "    def is_empty(self):",
            "        \"\"\"",
            "        Check if the increment entry is empty.",
            "        \"\"\"",
            "        return os.path.getsize(self.path) == 0",
            "",
            "    def read(self):",
            "        \"\"\"Read the error file and return it's content. Raise exception if the",
            "        file can't be read.\"\"\"",
            "        # To avoid opening empty file, check the file size first.",
            "        if self.is_empty:",
            "            return \"\"",
            "        encoding = self.repo._encoding.name",
            "        if self._is_compressed:",
            "            return subprocess.check_output(",
            "                ['zcat', self.path],",
            "                stdout=subprocess.PIPE,",
            "                stderr=subprocess.STDOUT,",
            "                encoding=encoding,",
            "                errors='replace',",
            "            )",
            "        with open(self.path, 'r', encoding=encoding, errors='replace') as f:",
            "            return f.read()",
            "",
            "    def tail(self, num=2000):",
            "        \"\"\"",
            "        Tail content of the file. This is used for logs.",
            "        \"\"\"",
            "        # To avoid opening empty file, check the file size first.",
            "        if self.is_empty:",
            "            return b''",
            "        encoding = self.repo._encoding.name",
            "        if self._is_compressed:",
            "            zcat = subprocess.Popen([b'zcat', self.path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)",
            "            return subprocess.check_output(",
            "                ['tail', '-n', str(num)],",
            "                stdin=zcat.stdout,",
            "                stderr=subprocess.STDOUT,",
            "                encoding=encoding,",
            "                errors='replace',",
            "            )",
            "        return subprocess.check_output(",
            "            ['tail', '-n', str(num), self.path], stderr=subprocess.STDOUT, encoding=encoding, errors='replace'",
            "        )",
            "",
            "",
            "class RestoreLogEntry(LogEntry):",
            "    PREFIX = b'restore.'",
            "    SUFFIXES = [b'.log']",
            "",
            "    @staticmethod",
            "    def on_date_error(e):",
            "        return None",
            "",
            "",
            "class BackupLogEntry(LogEntry):",
            "    PREFIX = b'backup.'",
            "    SUFFIXES = [b'.log']",
            "",
            "    @staticmethod",
            "    def on_date_error(e):",
            "        return None",
            "",
            "",
            "class MetadataKeys:",
            "    \"\"\"",
            "    Provide a view on metadata dict keys. See MetadataDict#keys()",
            "    \"\"\"",
            "",
            "    def __init__(self, function, sequence):",
            "        self._f = function",
            "        self._sequence = sequence",
            "",
            "    def __iter__(self):",
            "        return map(self._f, self._sequence)",
            "",
            "    def __getitem__(self, i):",
            "        if isinstance(i, slice):",
            "            return list(map(self._f, self._sequence[i]))",
            "        else:",
            "            return self._f(self._sequence[i])",
            "",
            "    def __len__(self):",
            "        return len(self._sequence)",
            "",
            "",
            "class MetadataDict(object):",
            "    \"\"\"",
            "    This is used to access repository metadata quickly in a pythonic way. It",
            "    make an abstraction to access a range of increment entries using index and",
            "    date while also supporting slice to get a range of entries.",
            "    \"\"\"",
            "",
            "    def __init__(self, repo, cls):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert hasattr(cls, '__call__')",
            "        self._repo = repo",
            "        assert cls.PREFIX",
            "        self._prefix = cls.PREFIX",
            "        self._cls = cls",
            "",
            "    @cached_property",
            "    def _entries(self):",
            "        return [e for e in self._repo._entries if e.startswith(self._prefix)]",
            "",
            "    def __getitem__(self, key):",
            "        if isinstance(key, RdiffTime):",
            "            idx = bisect.bisect_left(self.keys(), key)",
            "            if idx < len(self._entries):",
            "                item = self._cls(self._repo, self._entries[idx])",
            "                if item.date == key:",
            "                    return item",
            "            raise KeyError(key)",
            "        elif isinstance(key, slice):",
            "            if isinstance(key.start, RdiffTime):",
            "                idx = bisect.bisect_left(self.keys(), key.start)",
            "                key = slice(idx, key.stop, key.step)",
            "            if isinstance(key.stop, RdiffTime):",
            "                idx = bisect.bisect_right(self.keys(), key.stop)",
            "                key = slice(key.start, idx, key.step)",
            "            return [self._cls(self._repo, e) for e in self._entries[key]]",
            "        elif isinstance(key, int):",
            "            try:",
            "                return self._cls(self._repo, self._entries[key])",
            "            except IndexError:",
            "                raise KeyError(key)",
            "        else:",
            "            raise KeyError(key)",
            "",
            "    def __iter__(self):",
            "        for e in self._entries:",
            "            yield self._cls(self._repo, e)",
            "",
            "    def __len__(self):",
            "        return len(self._entries)",
            "",
            "    def keys(self):",
            "        return MetadataKeys(lambda e: self._cls._extract_date(e), self._entries)",
            "",
            "",
            "class RdiffRepo(object):",
            "",
            "    \"\"\"Represent one rdiff-backup repository.\"\"\"",
            "",
            "    def __init__(self, user_root, path, encoding):",
            "        if isinstance(user_root, str):",
            "            user_root = os.fsencode(user_root)",
            "        if isinstance(path, str):",
            "            path = os.fsencode(path)",
            "        assert isinstance(user_root, bytes)",
            "        assert isinstance(path, bytes)",
            "        assert encoding",
            "        self._encoding = encodings.search_function(encoding)",
            "        assert self._encoding",
            "        self.path = path.strip(b\"/\")",
            "        if self.path:",
            "            self.full_path = os.path.normpath(os.path.join(user_root, self.path))",
            "        else:",
            "            self.full_path = os.path.normpath(user_root)",
            "",
            "        # The location of rdiff-backup-data directory.",
            "        self._data_path = os.path.join(self.full_path, RDIFF_BACKUP_DATA)",
            "        assert isinstance(self._data_path, bytes)",
            "        self._increment_path = os.path.join(self._data_path, INCREMENTS)",
            "        self.current_mirror = MetadataDict(self, CurrentMirrorEntry)",
            "        self.error_log = MetadataDict(self, LogEntry)",
            "        self.mirror_metadata = MetadataDict(self, MirrorMetadataEntry)",
            "        self.file_statistics = MetadataDict(self, FileStatisticsEntry)",
            "        self.session_statistics = MetadataDict(self, SessionStatisticsEntry)",
            "",
            "    @property",
            "    def backup_dates(self):",
            "        \"\"\"Return a list of dates when backup was executed. This list is",
            "        sorted from old to new (ascending order). To identify dates,",
            "        'mirror_metadata' file located in rdiff-backup-data are used.\"\"\"",
            "        return self.mirror_metadata.keys()",
            "",
            "    @property",
            "    def backup_log(self):",
            "        \"\"\"",
            "        Return the location of the backup log.",
            "        \"\"\"",
            "        return BackupLogEntry(self, b'backup.log')",
            "",
            "    def delete(self, path):",
            "        \"\"\"",
            "        Delete this entry from the repository history using rdiff-backup-delete.",
            "        \"\"\"",
            "        path_obj = self.fstat(path)",
            "        if path_obj.isroot:",
            "            return self.delete_repo()",
            "",
            "        rdiff_backup_delete = find_rdiff_backup_delete()",
            "        cmdline = [rdiff_backup_delete, path_obj.full_path]",
            "        logger.info('executing: %r' % cmdline)",
            "        process = subprocess.Popen(cmdline, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env={'LANG': LANG})",
            "        for line in process.stdout:",
            "            line = line.rstrip(b'\\n').decode('utf-8', errors='replace')",
            "            logger.info('rdiff-backup-delete: %s' % line)",
            "        retcode = process.wait()",
            "        if retcode:",
            "            raise CalledProcessError(retcode, cmdline)",
            "",
            "    def delete_repo(self):",
            "        \"\"\"Delete the repository permanently.\"\"\"",
            "        # Try to change the permissions of the file or directory to delete",
            "        # them.",
            "        def handle_error(func, path, exc_info):",
            "            if exc_info[0] == PermissionError:",
            "                # Parent directory must allow rwx",
            "                if not os.access(os.path.dirname(path), os.W_OK | os.R_OK | os.X_OK):",
            "                    os.chmod(os.path.dirname(path), 0o0700)",
            "                if not os.access(path, os.W_OK | os.R_OK):",
            "                    os.chmod(path, 0o0600)",
            "                if os.path.isdir(path):",
            "                    return shutil.rmtree(path, onerror=handle_error)",
            "                else:",
            "                    return os.unlink(path)",
            "            raise",
            "",
            "        try:",
            "            shutil.rmtree(self.full_path, onerror=handle_error)",
            "        except Exception:",
            "            logger.warning('fail to delete repo', exc_info=1)",
            "",
            "    @property",
            "    def display_name(self):",
            "        \"\"\"Return the most human representation of the repository name.\"\"\"",
            "        return self.get_display_name(b'')",
            "",
            "    def _decode(self, value, errors='replace'):",
            "        \"\"\"Used to decode a repository path into unicode.\"\"\"",
            "        assert isinstance(value, bytes)",
            "        return self._encoding.decode(value, errors)[0]",
            "",
            "    @cached_property",
            "    def _entries(self):",
            "        return sorted(os.listdir(self._data_path))",
            "",
            "    def expire(self):",
            "        \"\"\"",
            "        Clear the cache to refresh metadata.",
            "        \"\"\"",
            "        cached_properties = [",
            "            (self, '_entries'),",
            "            (self, 'status'),",
            "            (self.current_mirror, '_entries'),",
            "            (self.error_log, '_entries'),",
            "            (self.mirror_metadata, '_entries'),",
            "            (self.file_statistics, '_entries'),",
            "            (self.session_statistics, '_entries'),",
            "        ]",
            "        for obj, attr in cached_properties:",
            "            if attr in obj.__dict__:",
            "                del obj.__dict__[attr]",
            "",
            "    def listdir(self, path):",
            "        \"\"\"",
            "        Return a list of RdiffDirEntry each representing a file or a folder in the given path.",
            "        \"\"\"",
            "        # Compute increment directory location.",
            "        full_path = os.path.realpath(os.path.join(self.full_path, path.strip(b'/')))",
            "        relative_path = os.path.relpath(full_path, self.full_path)",
            "        if relative_path.startswith(RDIFF_BACKUP_DATA):",
            "            raise DoesNotExistError(path)",
            "        increment_path = os.path.normpath(os.path.join(self._increment_path, relative_path))",
            "        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):",
            "            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))",
            "",
            "        # Get list of all increments and existing file and folder",
            "        try:",
            "            existing_items = os.listdir(full_path)",
            "            if relative_path == b'.':",
            "                existing_items.remove(RDIFF_BACKUP_DATA)",
            "        except (NotADirectoryError, FileNotFoundError):",
            "            existing_items = None",
            "        except OSError:",
            "            raise AccessDeniedError(path)",
            "        try:",
            "            increment_items = os.listdir(increment_path)",
            "        except (NotADirectoryError, FileNotFoundError):",
            "            increment_items = None",
            "        except OSError:",
            "            raise AccessDeniedError(path)",
            "        # Raise error if nothing is found",
            "        if existing_items is None and increment_items is None:",
            "            raise DoesNotExistError(path)",
            "",
            "        # Merge information from both location",
            "        # Regroup all information into RdiffDirEntry",
            "        entries = {}",
            "        for name in existing_items or []:",
            "            entries[name] = RdiffDirEntry(",
            "                self,",
            "                os.path.normpath(os.path.join(relative_path, name)),",
            "                exists=True,",
            "                increments=[],",
            "            )",
            "        for item in increment_items or []:",
            "            try:",
            "                increment = IncrementEntry(item)",
            "            except ValueError:",
            "                # Ignore any increment that cannot be parsed",
            "                continue",
            "            entry = entries.get(increment.name, None)",
            "            if not entry:",
            "                # Create a new Direntry",
            "                entry = entries[increment.name] = RdiffDirEntry(",
            "                    self,",
            "                    os.path.normpath(os.path.join(relative_path, increment.name)),",
            "                    exists=False,",
            "                    increments=[increment] if increment else [],",
            "                )",
            "            else:",
            "                # Add increment to dir entry",
            "                bisect.insort_left(entry._increments, increment)",
            "        return sorted(list(entries.values()), key=lambda e: e.path)",
            "",
            "    def fstat(self, path):",
            "        \"\"\"Return a new instance of DirEntry to represent the given path.\"\"\"",
            "        # Compute increment directory location.",
            "        assert isinstance(path, bytes)",
            "        full_path = os.path.normpath(os.path.join(self.full_path, path.strip(b'/')))",
            "        increment_path = os.path.normpath(os.path.join(self._increment_path, path.strip(b'/'), b'..'))",
            "        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):",
            "            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))",
            "        relative_path = os.path.relpath(full_path, self.full_path)",
            "        if relative_path.startswith(RDIFF_BACKUP_DATA):",
            "            raise DoesNotExistError(path)",
            "        # Get if the path request is the root path.",
            "        if relative_path == b'.':",
            "            return RdiffDirEntry(self, b'', True, [])",
            "",
            "        # Check if path exists",
            "        try:",
            "            os.lstat(full_path)",
            "            exists = True",
            "        except (OSError, ValueError):",
            "            exists = False",
            "",
            "        # Get incrmement data",
            "        increment_items = os.listdir(increment_path)",
            "",
            "        # Create dir entry",
            "        prefix = os.path.basename(full_path)",
            "        entry = RdiffDirEntry(self, relative_path, exists, [])",
            "        for item in increment_items:",
            "            if not item.startswith(prefix):",
            "                # Ignore increment not matching our path",
            "                continue",
            "            try:",
            "                increment = IncrementEntry(item)",
            "            except ValueError:",
            "                # Ignore any increment that cannot be parsed",
            "                continue",
            "            if increment.name != prefix:",
            "                # Ignore increment not matching our path",
            "                continue",
            "            # Add increment to dir entry",
            "            bisect.insort_left(entry._increments, increment)",
            "",
            "        # Check if path exists or has increment. If not raise an exception.",
            "        if not exists and not entry._increments:",
            "            logger.error(\"path [%r] doesn't exists\", path)",
            "            raise DoesNotExistError(path)",
            "",
            "        # Create a directory entry.",
            "        return entry",
            "",
            "    @property",
            "    def last_backup_date(self):",
            "        \"\"\"Return the last known backup dates.\"\"\"",
            "        try:",
            "            if len(self.current_mirror) > 0:",
            "                return self.current_mirror[-1].date",
            "            return None",
            "        except (PermissionError, FileNotFoundError):",
            "            return None",
            "",
            "    def get_display_name(self, path):",
            "        \"\"\"",
            "        Return proper display name of the given path according to repository encoding and quoted characters.",
            "        \"\"\"",
            "        assert isinstance(path, bytes)",
            "        path = path.strip(b'/')",
            "        if path in [b'.', b'']:",
            "            # For repository we use either path if defined or the directory base name",
            "            if not self.path:",
            "                return self._decode(unquote(os.path.basename(self.full_path)))",
            "            return self._decode(unquote(self.path))",
            "        else:",
            "            # For path, we use the dir name",
            "            return self._decode(unquote(os.path.basename(path)))",
            "",
            "    def remove_older(self, remove_older_than):",
            "        assert type(remove_older_than) is int, 'invalid remove_older_than, expect an integer: ' + remove_older_than",
            "        logger.info(",
            "            \"execute rdiff-backup --force --remove-older-than=%sD %r\",",
            "            remove_older_than,",
            "            self.full_path.decode(sys.getfilesystemencoding(), 'replace'),",
            "        )",
            "        subprocess.check_output(",
            "            [",
            "                b'rdiff-backup',",
            "                b'--force',",
            "                b'--remove-older-than=' + str(remove_older_than).encode(encoding='latin1') + b'D',",
            "                self.full_path,",
            "            ]",
            "        )",
            "        self.expire()",
            "",
            "    def restore(self, path, restore_as_of, kind=None):",
            "        \"\"\"",
            "        Restore the current directory entry into a fileobj containing the",
            "        file content of the directory compressed into an archive.",
            "",
            "        `kind` must be one of the supported archive type or none to use `zip` for folder and `raw` for file.",
            "",
            "        Return a filename and a fileobj.",
            "        \"\"\"",
            "        assert isinstance(path, bytes)",
            "        assert restore_as_of, \"restore_as_of must be defined\"",
            "        assert kind in ['tar', 'tar.bz2', 'tar.gz', 'tbz2', 'tgz', 'zip', 'raw', None]",
            "",
            "        # Define proper kind according to path type.",
            "        path_obj = self.fstat(path)",
            "        if path_obj.isdir:",
            "            if kind == 'raw':",
            "                raise ValueError('raw type not supported for directory')",
            "            kind = kind or 'zip'",
            "        else:",
            "            kind = kind or 'raw'",
            "",
            "        # Define proper filename according to the path",
            "        if kind == 'raw':",
            "            filename = path_obj.display_name",
            "        else:",
            "            filename = \"%s.%s\" % (path_obj.display_name, kind)",
            "",
            "        # Call external process to offload processing.",
            "        # python -m rdiffweb.core.restore --restore-as-of 123456 --encoding utf-8 --kind zip -",
            "        cmdline = [",
            "            os.fsencode(sys.executable),",
            "            b'-m',",
            "            b'rdiffweb.core.restore',",
            "            b'--restore-as-of',",
            "            str(restore_as_of).encode('latin'),",
            "            b'--encoding',",
            "            self._encoding.name.encode('latin'),",
            "            b'--kind',",
            "            kind.encode('latin'),",
            "            os.path.join(self.full_path, unquote(path_obj.path)),",
            "            b'-',",
            "        ]",
            "        proc = subprocess.Popen(",
            "            cmdline,",
            "            shell=False,",
            "            stdout=subprocess.PIPE,",
            "            stderr=subprocess.PIPE,",
            "            env=None,",
            "        )",
            "        # Check if the restore process is properly starting",
            "        # Read the first 100 line until \"Processing changed file\"",
            "        max_line = 100",
            "        output = b''",
            "        success = False",
            "        line = proc.stderr.readline()",
            "        while max_line > 0 and line:",
            "            max_line -= 1",
            "            output += line",
            "            if b'Processing changed file' in line:",
            "                success = True",
            "                break",
            "            line = proc.stderr.readline()",
            "        if not success:",
            "            raise CalledProcessError(1, cmdline, output)",
            "        # Start a Thread to pipe the rest of the stream to the log",
            "        t = threading.Thread(target=_readerthread, args=(proc.stderr, logger.debug))",
            "        t.daemon = True",
            "        t.start()",
            "        return filename, _wrap_close(proc.stdout, proc)",
            "",
            "    @property",
            "    def restore_log(self):",
            "        \"\"\"",
            "        Return the location of the restore log.",
            "        \"\"\"",
            "        return RestoreLogEntry(self, b'restore.log')",
            "",
            "    @cached_property",
            "    def status(self):",
            "        \"\"\"Check if a backup is in progress for the current repo.\"\"\"",
            "",
            "        # Read content of the file and check if pid still exists",
            "        try:",
            "            # Make sure repoRoot is a valid rdiff-backup repository",
            "            for current_mirror in self.current_mirror:",
            "                pid = current_mirror.extract_pid()",
            "                try:",
            "                    p = psutil.Process(pid)",
            "                    if any('rdiff-backup' in c for c in p.cmdline()):",
            "                        return ('in_progress', _('A backup is currently in progress to this repository.'))",
            "                except psutil.NoSuchProcess:",
            "                    logger.debug('pid [%s] does not exists', pid)",
            "",
            "            # If multiple current_mirror file exists and none of them are associated to a PID, this mean the last backup was interrupted.",
            "            # Also, if the last backup date is undefined, this mean the first",
            "            # initial backup was interrupted.",
            "            if len(self.current_mirror) > 1 or len(self.current_mirror) == 0:",
            "                return ('interrupted', _('The previous backup seams to have failed.'))",
            "        except FileNotFoundError:",
            "            self._entries = []",
            "            return ('failed', _('The repository cannot be found or is badly damaged.'))",
            "        except PermissionError:",
            "            self._entries = []",
            "            logger.warning('error reading current_mirror files', exc_info=1)",
            "            return ('failed', _(\"Permissions denied. Contact administrator to check repository's permissions.\"))",
            "",
            "        return ('ok', '')"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import bisect",
            "import calendar",
            "import encodings",
            "import logging",
            "import os",
            "import re",
            "import shutil",
            "import subprocess",
            "import sys",
            "import threading",
            "import time",
            "from datetime import timedelta",
            "from subprocess import CalledProcessError",
            "",
            "import psutil",
            "from cached_property import cached_property",
            "",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "# Define the logger",
            "logger = logging.getLogger(__name__)",
            "",
            "# Constant for the rdiff-backup-data folder name.",
            "RDIFF_BACKUP_DATA = b\"rdiff-backup-data\"",
            "",
            "# Increment folder name.",
            "INCREMENTS = b\"increments\"",
            "",
            "# Define the default LANG environment variable to be passed to rdiff-backup",
            "# restore command line to make sure the binary output stdout as utf8 otherwise",
            "# we end up with \\x encoded characters.",
            "STDOUT_ENCODING = 'utf-8'",
            "LANG = \"en_US.\" + STDOUT_ENCODING",
            "",
            "",
            "def rdiff_backup_version():",
            "    \"\"\"",
            "    Get rdiff-backup version",
            "    \"\"\"",
            "    try:",
            "        output = subprocess.check_output([find_rdiff_backup(), '--version'])",
            "        m = re.search(b'([0-9]+).([0-9]+).([0-9]+)', output)",
            "        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))",
            "    except Exception:",
            "        return (0, 0, 0)",
            "",
            "",
            "def find_rdiff_backup():",
            "    \"\"\"",
            "    Lookup for `rdiff-backup` executable. Raise an exception if not found.",
            "    \"\"\"",
            "    cmd = shutil.which('rdiff-backup')",
            "    if not cmd:",
            "        raise FileNotFoundError(\"can't find `rdiff-backup` executable in PATH: %s\" % os.environ['PATH'])",
            "    return os.fsencode(cmd)",
            "",
            "",
            "def find_rdiff_backup_delete():",
            "    \"\"\"",
            "    Lookup for `rdiff-backup-delete` executable. Raise an exception if not found.",
            "    \"\"\"",
            "    cmd = shutil.which('rdiff-backup-delete')",
            "    if not cmd:",
            "        raise FileNotFoundError(",
            "            \"can't find `rdiff-backup-delete` executable in PATH: %s, make sure you have rdiff-backup >= 2.0.1 installed\"",
            "            % os.environ['PATH']",
            "        )",
            "    return os.fsencode(cmd)",
            "",
            "",
            "def unquote(name):",
            "    \"\"\"Remove quote from the given name.\"\"\"",
            "    assert isinstance(name, bytes)",
            "",
            "    # This function just gives back the original text if it can decode it",
            "    def unquoted_char(match):",
            "        \"\"\"For each ;000 return the corresponding byte.\"\"\"",
            "        if len(match.group()) != 4:",
            "            return match.group",
            "        try:",
            "            return bytes([int(match.group()[1:])])",
            "        except ValueError:",
            "            return match.group",
            "",
            "    # Remove quote using regex",
            "    return re.sub(b\";[0-9]{3}\", unquoted_char, name, re.S)",
            "",
            "",
            "def popen(cmd, stderr=None, env=None):",
            "    \"\"\"",
            "    Alternative to os.popen() to support a `cmd` with a list of arguments and",
            "    return a file object that return bytes instead of string.",
            "",
            "    `stderr` could be subprocess.STDOUT or subprocess.DEVNULL or a function.",
            "    Otherwise, the error is redirect to logger.",
            "    \"\"\"",
            "    # Check if stderr should be pipe.",
            "    pipe_stderr = stderr == subprocess.PIPE or hasattr(stderr, '__call__') or stderr is None",
            "    proc = subprocess.Popen(",
            "        cmd,",
            "        shell=False,",
            "        stdout=subprocess.PIPE,",
            "        stderr=subprocess.PIPE if pipe_stderr else stderr,",
            "        env=env,",
            "    )",
            "    if pipe_stderr:",
            "        t = threading.Thread(target=_readerthread, args=(proc.stderr, stderr))",
            "        t.daemon = True",
            "        t.start()",
            "    return _wrap_close(proc.stdout, proc)",
            "",
            "",
            "# Helper for popen() to redirect stderr to a logger.",
            "",
            "",
            "def _readerthread(stream, func):",
            "    \"\"\"",
            "    Read stderr and pipe each line to logger.",
            "    \"\"\"",
            "    func = func or logger.debug",
            "    for line in stream:",
            "        func(line.decode(STDOUT_ENCODING, 'replace').strip('\\n'))",
            "    stream.close()",
            "",
            "",
            "# Helper for popen() to close process when the pipe is closed.",
            "",
            "",
            "class _wrap_close:",
            "    def __init__(self, stream, proc):",
            "        self._stream = stream",
            "        self._proc = proc",
            "",
            "    def close(self):",
            "        self._stream.close()",
            "        returncode = self._proc.wait()",
            "        if returncode == 0:",
            "            return None",
            "        return returncode",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    def __getattr__(self, name):",
            "        return getattr(self._stream, name)",
            "",
            "    def __iter__(self):",
            "        return iter(self._stream)",
            "",
            "",
            "class AccessDeniedError(Exception):",
            "    pass",
            "",
            "",
            "class DoesNotExistError(Exception):",
            "    pass",
            "",
            "",
            "class RdiffTime(object):",
            "",
            "    \"\"\"Time information has two components: the local time, stored in GMT as",
            "    seconds since Epoch, and the timezone, stored as a seconds offset. Since",
            "    the server may not be in the same timezone as the user, we cannot rely on",
            "    the built-in localtime() functions, but look at the rdiff-backup string",
            "    for timezone information.  As a general rule, we always display the",
            "    \"local\" time, but pass the timezone information on to rdiff-backup, so",
            "    it can restore to the correct state\"\"\"",
            "",
            "    def __init__(self, value=None, tz_offset=None):",
            "        assert value is None or isinstance(value, int) or isinstance(value, str)",
            "        if value is None:",
            "            # Get GMT time.",
            "            self._time_seconds = int(time.time())",
            "            self._tz_offset = 0",
            "        elif isinstance(value, int):",
            "            self._time_seconds = value",
            "            self._tz_offset = tz_offset or 0",
            "        else:",
            "            self._from_str(value)",
            "",
            "    def _from_str(self, time_string):",
            "        if time_string[10] != 'T':",
            "            raise ValueError('missing date time separator (T): ' + time_string)",
            "        if time_string[19] not in ['-', '+', 'Z']:",
            "            raise ValueError('missing timezone info (-, + or Z): ' + time_string)",
            "        if time_string[4] != '-' or time_string[7] != '-':",
            "            raise ValueError('missing date separator (-): ' + time_string)",
            "        if not (time_string[13] in [':', '-'] and time_string[16] in [':', '-']):",
            "            raise ValueError('missing date separator (-): ' + time_string)",
            "        try:",
            "            year = int(time_string[0:4])",
            "            if not (1900 < year < 2200):",
            "                raise ValueError('unexpected year value between 1900 and 2200: ' + str(year))",
            "            month = int(time_string[5:7])",
            "            if not (1 <= month <= 12):",
            "                raise ValueError('unexpected month value between 1 and 12: ' + str(month))",
            "            day = int(time_string[8:10])",
            "            if not (1 <= day <= 31):",
            "                raise ValueError('unexpected day value between 1 and 31: ' + str(day))",
            "            hour = int(time_string[11:13])",
            "            if not (0 <= hour <= 23):",
            "                raise ValueError('unexpected hour value between 1 and 23: ' + str(hour))",
            "            minute = int(time_string[14:16])",
            "            if not (0 <= minute <= 60):",
            "                raise ValueError('unexpected minute value between 1 and 60: ' + str(minute))",
            "            second = int(time_string[17:19])",
            "            if not (0 <= second <= 61):  # leap seconds",
            "                raise ValueError('unexpected second value between 1 and 61: ' + str(second))",
            "            timetuple = (year, month, day, hour, minute, second, -1, -1, 0)",
            "            self._time_seconds = calendar.timegm(timetuple)",
            "            self._tz_offset = self._tzdtoseconds(time_string[19:])",
            "            self._tz_str()  # to get assertions there",
            "        except (TypeError, ValueError, AssertionError):",
            "            raise ValueError(time_string)",
            "",
            "    def epoch(self):",
            "        return self._time_seconds - self._tz_offset",
            "",
            "    def _tz_str(self):",
            "        if self._tz_offset:",
            "            hours, minutes = divmod(abs(self._tz_offset) // 60, 60)",
            "            assert 0 <= hours <= 23",
            "            assert 0 <= minutes <= 59",
            "            if self._tz_offset > 0:",
            "                plus_minus = \"+\"",
            "            else:",
            "                plus_minus = \"-\"",
            "            return \"%s%s:%s\" % (plus_minus, \"%02d\" % hours, \"%02d\" % minutes)",
            "        else:",
            "            return \"Z\"",
            "",
            "    def set_time(self, hour, minute, second):",
            "        year = time.gmtime(self._time_seconds)[0]",
            "        month = time.gmtime(self._time_seconds)[1]",
            "        day = time.gmtime(self._time_seconds)[2]",
            "        _time_seconds = calendar.timegm((year, month, day, hour, minute, second, -1, -1, 0))",
            "        return RdiffTime(_time_seconds, self._tz_offset)",
            "",
            "    def _tzdtoseconds(self, tzd):",
            "        \"\"\"Given w3 compliant TZD, converts it to number of seconds from UTC\"\"\"",
            "        if tzd == \"Z\":",
            "            return 0",
            "        assert len(tzd) == 6  # only accept forms like +08:00 or +08-00 for now",
            "        assert (tzd[0] == \"-\" or tzd[0] == \"+\") and tzd[3] in [\":\", '-']",
            "        if tzd[0] == \"+\":",
            "            plus_minus = 1",
            "        else:",
            "            plus_minus = -1",
            "        return plus_minus * 60 * (60 * int(tzd[1:3]) + int(tzd[4:]))",
            "",
            "    def __add__(self, other):",
            "        \"\"\"Support plus (+) timedelta\"\"\"",
            "        assert isinstance(other, timedelta)",
            "        return RdiffTime(self._time_seconds + int(other.total_seconds()), self._tz_offset)",
            "",
            "    def __sub__(self, other):",
            "        \"\"\"Support minus (-) timedelta\"\"\"",
            "        assert isinstance(other, timedelta) or isinstance(other, RdiffTime)",
            "        # Sub with timedelta, return RdiffTime",
            "        if isinstance(other, timedelta):",
            "            return RdiffTime(self._time_seconds - int(other.total_seconds()), self._tz_offset)",
            "",
            "        # Sub with RdiffTime, return timedelta",
            "        if isinstance(other, RdiffTime):",
            "            return timedelta(seconds=self._time_seconds - other._time_seconds)",
            "",
            "    def __int__(self):",
            "        \"\"\"Return this date as seconds since epoch.\"\"\"",
            "        return self.epoch()",
            "",
            "    def __lt__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() < other.epoch()",
            "",
            "    def __le__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() <= other.epoch()",
            "",
            "    def __gt__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() > other.epoch()",
            "",
            "    def __ge__(self, other):",
            "        assert isinstance(other, RdiffTime)",
            "        return self.epoch() >= other.epoch()",
            "",
            "    def __eq__(self, other):",
            "        return isinstance(other, RdiffTime) and self.epoch() == other.epoch()",
            "",
            "    def __hash__(self):",
            "        return hash(self.epoch())",
            "",
            "    def __str__(self):",
            "        \"\"\"return utf-8 string\"\"\"",
            "        value = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(self._time_seconds))",
            "        return value + self._tz_str()",
            "",
            "    def __repr__(self):",
            "        \"\"\"return second since epoch\"\"\"",
            "        return \"RdiffTime('\" + str(self) + \"')\"",
            "",
            "",
            "class RdiffDirEntry(object):",
            "    \"\"\"",
            "    Includes name, isdir, file_size, exists, and dict (change_dates) of sorted",
            "    local dates when backed up.",
            "    \"\"\"",
            "",
            "    def __init__(self, repo, path, exists, increments):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert isinstance(path, bytes)",
            "        # Keep reference to the path and repo object.",
            "        self._repo = repo",
            "        self.path = path",
            "        # Absolute path to the directory",
            "        if self.isroot:",
            "            self.full_path = self._repo.full_path",
            "        else:",
            "            self.full_path = os.path.join(self._repo.full_path, self.path)",
            "        # May need to compute our own state if not provided.",
            "        self.exists = exists",
            "        # Store the increments sorted by date.",
            "        # See self.last_change_date()",
            "        self._increments = sorted(increments, key=lambda x: x.date)",
            "",
            "    @property",
            "    def display_name(self):",
            "        \"\"\"Return the most human readable filename. Without quote.\"\"\"",
            "        return self._repo.get_display_name(self.path)",
            "",
            "    @property",
            "    def isroot(self):",
            "        \"\"\"",
            "        Check if the directory entry represent the root of the repository.",
            "        Return True when path is empty.",
            "        \"\"\"",
            "        return self.path == b''",
            "",
            "    @cached_property",
            "    def isdir(self):",
            "        \"\"\"Lazy check if entry is a directory\"\"\"",
            "        if self.exists:",
            "            # If the entry exists, check if it's a directory",
            "            return os.path.isdir(self.full_path)",
            "        # Check if increments is a directory",
            "        for increment in self._increments:",
            "            if increment.is_missing:",
            "                # Ignore missing increment...",
            "                continue",
            "            return increment.isdir",
            "",
            "    @cached_property",
            "    def file_size(self):",
            "        \"\"\"",
            "        Return the current file size in bytes.",
            "        Return negative value (-1) for folder and deleted files.",
            "        \"\"\"",
            "        if self.isdir or not self.exists:",
            "            return -1",
            "        else:",
            "            try:",
            "                return os.lstat(self.full_path).st_size",
            "            except Exception:",
            "                logger.warning(\"cannot lstat on file [%s]\", self.full_path, exc_info=1)",
            "                return 0",
            "",
            "    def get_file_size(self, date=None):",
            "        # A viable place to get the filesize of a deleted entry",
            "        # it to get it from file_statistics",
            "        try:",
            "            stats = self._repo.file_statistics[date]",
            "            # File stats uses unquoted name.",
            "            unquote_path = unquote(self.path)",
            "            return stats.get_source_size(unquote_path)",
            "        except Exception:",
            "            logger.warning(\"cannot find file statistic [%s]\", self.last_change_date, exc_info=1)",
            "        return -1",
            "",
            "    @cached_property",
            "    def change_dates(self):",
            "        \"\"\"",
            "        Return a list of dates when this item has changes. Represent the",
            "        previous revision. From old to new.",
            "        \"\"\"",
            "        # Exception for root path, use backups dates.",
            "        if self.isroot:",
            "            return self._repo.backup_dates",
            "",
            "        # Compute the dates",
            "        change_dates = set()",
            "        for increment in self._increments:",
            "            # Get date of the increment as reference",
            "            change_date = increment.date",
            "            # If the increment is a \"missing\" increment, need to get the date",
            "            # before the folder was removed.",
            "            if increment.is_missing:",
            "                change_date = self._get_previous_backup_date(change_date)",
            "",
            "            if change_date:",
            "                change_dates.add(change_date)",
            "",
            "        # If the directory exists, add the last known backup date.",
            "        if self.exists and self._repo.last_backup_date:",
            "            change_dates.add(self._repo.last_backup_date)",
            "",
            "        # Return the list of dates.",
            "        return sorted(change_dates)",
            "",
            "    def _get_previous_backup_date(self, date):",
            "        \"\"\"Return the previous backup date.\"\"\"",
            "        index = bisect.bisect_left(self._repo.backup_dates, date)",
            "        if index == 0:",
            "            return None",
            "        return self._repo.backup_dates[index - 1]",
            "",
            "    @cached_property",
            "    def last_change_date(self):",
            "        \"\"\"Return last change date or False.\"\"\"",
            "        return self.change_dates and self.change_dates[-1]",
            "",
            "",
            "class AbstractEntry:",
            "    SUFFIXES = None",
            "",
            "    @classmethod",
            "    def _extract_date(cls, filename, onerror=None):",
            "        \"\"\"",
            "        Extract date from rdiff-backup filenames.",
            "        \"\"\"",
            "        # Extract suffix",
            "        suffix = None",
            "        for s in cls.SUFFIXES:",
            "            if filename.endswith(s):",
            "                suffix = s",
            "                break",
            "        if not suffix:",
            "            raise ValueError(filename)",
            "        # Parse date",
            "        filename_without_suffix = filename[: -len(suffix)]",
            "        parts = filename_without_suffix.rsplit(b'.', 1)",
            "        if len(parts) != 2:",
            "            return onerror(ValueError(''))",
            "        date_string = unquote(parts[1]).decode('ascii')",
            "        try:",
            "            return RdiffTime(date_string)",
            "        except Exception as e:",
            "            if onerror is None:",
            "                raise",
            "            return onerror(e)",
            "",
            "",
            "class MetadataEntry(AbstractEntry):",
            "    PREFIX = None",
            "    SUFFIXES = None",
            "    on_date_error = None",
            "",
            "    def __init__(self, repo, name):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert isinstance(name, bytes)",
            "        assert name.startswith(self.PREFIX)",
            "        assert any(name.endswith(s) for s in self.SUFFIXES), 'name %s should ends with: %s' % (name, self.SUFFIXES)",
            "        self.repo = repo",
            "        self.name = name",
            "        self.path = os.path.join(self.repo._data_path, self.name)",
            "        self.date = self._extract_date(name, onerror=self.on_date_error)",
            "",
            "    def _open(self):",
            "        \"\"\"",
            "        Should be used to open the increment file. This method handle",
            "        compressed vs not-compressed file.",
            "        \"\"\"",
            "        if self._is_compressed:",
            "            return popen(['zcat', self.path])",
            "        return open(self.path, 'rb')",
            "",
            "    @property",
            "    def _is_compressed(self):",
            "        return self.name.endswith(b\".gz\")",
            "",
            "",
            "class MirrorMetadataEntry(MetadataEntry):",
            "    PREFIX = b'mirror_metadata.'",
            "    SUFFIXES = [",
            "        b'.diff',",
            "        b'.diff.gz',",
            "        b\".snapshot.gz\",",
            "        b\".snapshot\",",
            "    ]",
            "",
            "",
            "class IncrementEntry(AbstractEntry):",
            "",
            "    \"\"\"Instance of the class represent one increment at a specific date for one",
            "    repository. The base repository is provided in the default constructor",
            "    and the date is provided using an error_log.* file\"\"\"",
            "",
            "    SUFFIXES = [",
            "        b\".missing\",",
            "        b\".snapshot.gz\",",
            "        b\".snapshot\",",
            "        b\".diff\",",
            "        b\".diff.gz\",",
            "        b\".dir\",",
            "    ]",
            "",
            "    def __init__(self, name):",
            "        \"\"\"Default constructor for an increment entry. User must provide the",
            "        repository directory and an entry name. The entry name correspond",
            "        to an error_log.* filename.\"\"\"",
            "        self.name, self.date, self.suffix = IncrementEntry._split(name)",
            "",
            "    @property",
            "    def isdir(self):",
            "        return self.suffix == b\".dir\"",
            "",
            "    @property",
            "    def is_missing(self):",
            "        \"\"\"Check if the curent entry is a missing increment.\"\"\"",
            "        return self.suffix == b\".missing\"",
            "",
            "    @property",
            "    def is_snapshot(self):",
            "        \"\"\"Check if the current entry is a snapshot increment.\"\"\"",
            "        return self.suffix in [b\".snapshot.gz\", b\".snapshot\"]",
            "",
            "    @classmethod",
            "    def _split(cls, filename):",
            "        \"\"\"Return tuple with filename, date, suffix\"\"\"",
            "        assert isinstance(filename, bytes)",
            "        # Extract suffix",
            "        suffix = None",
            "        for s in cls.SUFFIXES:",
            "            if filename.endswith(s):",
            "                suffix = s",
            "                break",
            "        if not suffix:",
            "            raise ValueError(filename)",
            "        # Parse date and raise error on failure",
            "        filename_without_suffix = filename[: -len(suffix)]",
            "        name, date_string = filename_without_suffix.rsplit(b'.', 1)",
            "        date_string = unquote(date_string).decode('ascii')",
            "        date = RdiffTime(date_string)",
            "        return (name, date, suffix)",
            "",
            "    def __gt__(self, other):",
            "        return self.date.__gt__(other.date)",
            "",
            "    def __lt__(self, other):",
            "        return self.date.__lt__(other.date)",
            "",
            "",
            "class FileStatisticsEntry(MetadataEntry):",
            "",
            "    \"\"\"",
            "    Represent a single file_statistics.",
            "",
            "    File Statistics contains different information related to each file of",
            "    the backup. This class provide a simple and easy way to access this",
            "    data.",
            "    \"\"\"",
            "",
            "    PREFIX = b'file_statistics.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    def get_mirror_size(self, path):",
            "        \"\"\"Return the value of MirrorSize for the given file.",
            "        path is the relative path from repo root.\"\"\"",
            "        try:",
            "            return int(self._search(path)[\"mirror_size\"])",
            "        except ValueError:",
            "            logger.warning(\"mirror size not found for [%r]\", path, exc_info=1)",
            "            return 0",
            "",
            "    def get_source_size(self, path):",
            "        \"\"\"Return the value of SourceSize for the given file.",
            "        path is the relative path from repo root.\"\"\"",
            "        try:",
            "            return int(self._search(path)[\"source_size\"])",
            "        except ValueError:",
            "            logger.warning(\"source size not found for [%r]\", path, exc_info=1)",
            "            return 0",
            "",
            "    def _search(self, path):",
            "        \"\"\"",
            "        This function search for a file entry in the file_statistics compress",
            "        file. Since python gzip.open() seams to be 2 time slower, we directly use",
            "        zlib library on python2.",
            "        \"\"\"",
            "        logger.debug(\"read file_statistics [%r]\", self.name)",
            "",
            "        path += b' '",
            "",
            "        with self._open() as f:",
            "            for line in f:",
            "                if not line.startswith(path):",
            "                    continue",
            "                break",
            "",
            "        # Split the line into array",
            "        data = line.rstrip(b'\\r\\n').rsplit(b' ', 4)",
            "        # From array create an entry",
            "        return {'changed': data[1], 'source_size': data[2], 'mirror_size': data[3], 'increment_size': data[4]}",
            "",
            "",
            "class SessionStatisticsEntry(MetadataEntry):",
            "    \"\"\"Represent a single session_statistics.\"\"\"",
            "",
            "    PREFIX = b'session_statistics.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    ATTRS = [",
            "        'starttime',",
            "        'endtime',",
            "        'elapsedtime',",
            "        'sourcefiles',",
            "        'sourcefilesize',",
            "        'mirrorfiles',",
            "        'mirrorfilesize',",
            "        'newfiles',",
            "        'newfilesize',",
            "        'deletedfiles',",
            "        'deletedfilesize',",
            "        'changedfiles',",
            "        'changedsourcesize',",
            "        'changedmirrorsize',",
            "        'incrementfiles',",
            "        'incrementfilesize',",
            "        'totaldestinationsizechange',",
            "        'errors',",
            "    ]",
            "",
            "    def _load(self):",
            "        \"\"\"This method is used to read the session_statistics and create the",
            "        appropriate structure to quickly get the data.",
            "",
            "        File Statistics contains different information related to each file of",
            "        the backup. This class provide a simple and easy way to access this",
            "        data.\"\"\"",
            "",
            "        with self._open() as f:",
            "            for line in f.readlines():",
            "                # Read the line into array",
            "                line = line.rstrip(b'\\r\\n')",
            "                data_line = line.split(b\" \", 2)",
            "                # Read line into tuple",
            "                (key, value) = tuple(data_line)[0:2]",
            "                if b'.' in value:",
            "                    value = float(value)",
            "                else:",
            "                    value = int(value)",
            "                setattr(self, key.lower().decode('ascii'), value)",
            "",
            "    def __getattr__(self, name):",
            "        \"\"\"",
            "        Intercept attribute getter to load the file.",
            "        \"\"\"",
            "        if name in self.ATTRS:",
            "            self._load()",
            "        return self.__dict__[name]",
            "",
            "",
            "class CurrentMirrorEntry(MetadataEntry):",
            "    PID_RE = re.compile(b\"^PID\\\\s*([0-9]+)\", re.I | re.M)",
            "",
            "    PREFIX = b'current_mirror.'",
            "    SUFFIXES = [b'.data']",
            "",
            "    def extract_pid(self):",
            "        \"\"\"",
            "        Return process ID from a current mirror marker, if any",
            "        \"\"\"",
            "        with open(self.path, 'rb') as f:",
            "            match = self.PID_RE.search(f.read())",
            "        if not match:",
            "            return None",
            "        return int(match.group(1))",
            "",
            "",
            "class LogEntry(MetadataEntry):",
            "    PREFIX = b'error_log.'",
            "    SUFFIXES = [b'.data', b'.data.gz']",
            "",
            "    @cached_property",
            "    def is_empty(self):",
            "        \"\"\"",
            "        Check if the increment entry is empty.",
            "        \"\"\"",
            "        return os.path.getsize(self.path) == 0",
            "",
            "    def read(self):",
            "        \"\"\"Read the error file and return it's content. Raise exception if the",
            "        file can't be read.\"\"\"",
            "        # To avoid opening empty file, check the file size first.",
            "        if self.is_empty:",
            "            return \"\"",
            "        encoding = self.repo._encoding.name",
            "        if self._is_compressed:",
            "            return subprocess.check_output(",
            "                ['zcat', self.path],",
            "                stdout=subprocess.PIPE,",
            "                stderr=subprocess.STDOUT,",
            "                encoding=encoding,",
            "                errors='replace',",
            "            )",
            "        with open(self.path, 'r', encoding=encoding, errors='replace') as f:",
            "            return f.read()",
            "",
            "    def tail(self, num=2000):",
            "        \"\"\"",
            "        Tail content of the file. This is used for logs.",
            "        \"\"\"",
            "        # To avoid opening empty file, check the file size first.",
            "        if self.is_empty:",
            "            return b''",
            "        encoding = self.repo._encoding.name",
            "        if self._is_compressed:",
            "            zcat = subprocess.Popen([b'zcat', self.path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)",
            "            return subprocess.check_output(",
            "                ['tail', '-n', str(num)],",
            "                stdin=zcat.stdout,",
            "                stderr=subprocess.STDOUT,",
            "                encoding=encoding,",
            "                errors='replace',",
            "            )",
            "        return subprocess.check_output(",
            "            ['tail', '-n', str(num), self.path], stderr=subprocess.STDOUT, encoding=encoding, errors='replace'",
            "        )",
            "",
            "",
            "class RestoreLogEntry(LogEntry):",
            "    PREFIX = b'restore.'",
            "    SUFFIXES = [b'.log']",
            "",
            "    @staticmethod",
            "    def on_date_error(e):",
            "        return None",
            "",
            "",
            "class BackupLogEntry(LogEntry):",
            "    PREFIX = b'backup.'",
            "    SUFFIXES = [b'.log']",
            "",
            "    @staticmethod",
            "    def on_date_error(e):",
            "        return None",
            "",
            "",
            "class MetadataKeys:",
            "    \"\"\"",
            "    Provide a view on metadata dict keys. See MetadataDict#keys()",
            "    \"\"\"",
            "",
            "    def __init__(self, function, sequence):",
            "        self._f = function",
            "        self._sequence = sequence",
            "",
            "    def __iter__(self):",
            "        return map(self._f, self._sequence)",
            "",
            "    def __getitem__(self, i):",
            "        if isinstance(i, slice):",
            "            return list(map(self._f, self._sequence[i]))",
            "        else:",
            "            return self._f(self._sequence[i])",
            "",
            "    def __len__(self):",
            "        return len(self._sequence)",
            "",
            "",
            "class MetadataDict(object):",
            "    \"\"\"",
            "    This is used to access repository metadata quickly in a pythonic way. It",
            "    make an abstraction to access a range of increment entries using index and",
            "    date while also supporting slice to get a range of entries.",
            "    \"\"\"",
            "",
            "    def __init__(self, repo, cls):",
            "        assert isinstance(repo, RdiffRepo)",
            "        assert hasattr(cls, '__call__')",
            "        self._repo = repo",
            "        assert cls.PREFIX",
            "        self._prefix = cls.PREFIX",
            "        self._cls = cls",
            "",
            "    @cached_property",
            "    def _entries(self):",
            "        return [e for e in self._repo._entries if e.startswith(self._prefix)]",
            "",
            "    def __getitem__(self, key):",
            "        if isinstance(key, RdiffTime):",
            "            idx = bisect.bisect_left(self.keys(), key)",
            "            if idx < len(self._entries):",
            "                item = self._cls(self._repo, self._entries[idx])",
            "                if item.date == key:",
            "                    return item",
            "            raise KeyError(key)",
            "        elif isinstance(key, slice):",
            "            if isinstance(key.start, RdiffTime):",
            "                idx = bisect.bisect_left(self.keys(), key.start)",
            "                key = slice(idx, key.stop, key.step)",
            "            if isinstance(key.stop, RdiffTime):",
            "                idx = bisect.bisect_right(self.keys(), key.stop)",
            "                key = slice(key.start, idx, key.step)",
            "            return [self._cls(self._repo, e) for e in self._entries[key]]",
            "        elif isinstance(key, int):",
            "            try:",
            "                return self._cls(self._repo, self._entries[key])",
            "            except IndexError:",
            "                raise KeyError(key)",
            "        else:",
            "            raise KeyError(key)",
            "",
            "    def __iter__(self):",
            "        for e in self._entries:",
            "            yield self._cls(self._repo, e)",
            "",
            "    def __len__(self):",
            "        return len(self._entries)",
            "",
            "    def keys(self):",
            "        return MetadataKeys(lambda e: self._cls._extract_date(e), self._entries)",
            "",
            "",
            "class RdiffRepo(object):",
            "",
            "    \"\"\"Represent one rdiff-backup repository.\"\"\"",
            "",
            "    def __init__(self, full_path, encoding):",
            "        assert encoding, 'encoding is required'",
            "        self._encoding = encodings.search_function(encoding)",
            "        assert self._encoding, 'encoding must be a valid charset'",
            "",
            "        # Validate and sanitize the full_path",
            "        assert full_path, 'full path is required'",
            "        self.full_path = os.fsencode(full_path) if isinstance(full_path, str) else full_path",
            "        assert os.path.isabs(self.full_path), 'full_path must be absolute path'",
            "        self.full_path = os.path.normpath(self.full_path)",
            "",
            "        # The location of rdiff-backup-data directory.",
            "        self._data_path = os.path.join(self.full_path, RDIFF_BACKUP_DATA)",
            "        assert isinstance(self._data_path, bytes)",
            "        self._increment_path = os.path.join(self._data_path, INCREMENTS)",
            "        self.current_mirror = MetadataDict(self, CurrentMirrorEntry)",
            "        self.error_log = MetadataDict(self, LogEntry)",
            "        self.mirror_metadata = MetadataDict(self, MirrorMetadataEntry)",
            "        self.file_statistics = MetadataDict(self, FileStatisticsEntry)",
            "        self.session_statistics = MetadataDict(self, SessionStatisticsEntry)",
            "",
            "    @property",
            "    def backup_dates(self):",
            "        \"\"\"Return a list of dates when backup was executed. This list is",
            "        sorted from old to new (ascending order). To identify dates,",
            "        'mirror_metadata' file located in rdiff-backup-data are used.\"\"\"",
            "        return self.mirror_metadata.keys()",
            "",
            "    @property",
            "    def backup_log(self):",
            "        \"\"\"",
            "        Return the location of the backup log.",
            "        \"\"\"",
            "        return BackupLogEntry(self, b'backup.log')",
            "",
            "    def delete(self, path):",
            "        \"\"\"",
            "        Delete this entry from the repository history using rdiff-backup-delete.",
            "        \"\"\"",
            "        path_obj = self.fstat(path)",
            "        if path_obj.isroot:",
            "            return self.delete_repo()",
            "",
            "        rdiff_backup_delete = find_rdiff_backup_delete()",
            "        cmdline = [rdiff_backup_delete, path_obj.full_path]",
            "        logger.info('executing: %r' % cmdline)",
            "        process = subprocess.Popen(cmdline, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env={'LANG': LANG})",
            "        for line in process.stdout:",
            "            line = line.rstrip(b'\\n').decode('utf-8', errors='replace')",
            "            logger.info('rdiff-backup-delete: %s' % line)",
            "        retcode = process.wait()",
            "        if retcode:",
            "            raise CalledProcessError(retcode, cmdline)",
            "",
            "    def delete_repo(self):",
            "        \"\"\"Delete the repository permanently.\"\"\"",
            "        # Try to change the permissions of the file or directory to delete",
            "        # them.",
            "        def handle_error(func, path, exc_info):",
            "            if exc_info[0] == PermissionError:",
            "                # Parent directory must allow rwx",
            "                if not os.access(os.path.dirname(path), os.W_OK | os.R_OK | os.X_OK):",
            "                    os.chmod(os.path.dirname(path), 0o0700)",
            "                if not os.access(path, os.W_OK | os.R_OK):",
            "                    os.chmod(path, 0o0600)",
            "                if os.path.isdir(path):",
            "                    return shutil.rmtree(path, onerror=handle_error)",
            "                else:",
            "                    return os.unlink(path)",
            "            raise",
            "",
            "        try:",
            "            shutil.rmtree(self.full_path, onerror=handle_error)",
            "        except Exception:",
            "            logger.warning('fail to delete repo', exc_info=1)",
            "",
            "    @property",
            "    def display_name(self):",
            "        \"\"\"Return the most human representation of the repository name.\"\"\"",
            "        return self.get_display_name(b'')",
            "",
            "    def _decode(self, value, errors='replace'):",
            "        \"\"\"Used to decode a repository path into unicode.\"\"\"",
            "        assert isinstance(value, bytes)",
            "        return self._encoding.decode(value, errors)[0]",
            "",
            "    @cached_property",
            "    def _entries(self):",
            "        return sorted(os.listdir(self._data_path))",
            "",
            "    def expire(self):",
            "        \"\"\"",
            "        Clear the cache to refresh metadata.",
            "        \"\"\"",
            "        cached_properties = [",
            "            (self, '_entries'),",
            "            (self, 'status'),",
            "            (self.current_mirror, '_entries'),",
            "            (self.error_log, '_entries'),",
            "            (self.mirror_metadata, '_entries'),",
            "            (self.file_statistics, '_entries'),",
            "            (self.session_statistics, '_entries'),",
            "        ]",
            "        for obj, attr in cached_properties:",
            "            if attr in obj.__dict__:",
            "                del obj.__dict__[attr]",
            "",
            "    def listdir(self, path):",
            "        \"\"\"",
            "        Return a list of RdiffDirEntry each representing a file or a folder in the given path.",
            "        \"\"\"",
            "        # Compute increment directory location.",
            "        full_path = os.path.realpath(os.path.join(self.full_path, path.strip(b'/')))",
            "        relative_path = os.path.relpath(full_path, self.full_path)",
            "        if relative_path.startswith(RDIFF_BACKUP_DATA):",
            "            raise DoesNotExistError(path)",
            "        increment_path = os.path.normpath(os.path.join(self._increment_path, relative_path))",
            "        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):",
            "            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))",
            "",
            "        # Get list of all increments and existing file and folder",
            "        try:",
            "            existing_items = os.listdir(full_path)",
            "            if relative_path == b'.':",
            "                existing_items.remove(RDIFF_BACKUP_DATA)",
            "        except (NotADirectoryError, FileNotFoundError):",
            "            existing_items = None",
            "        except OSError:",
            "            raise AccessDeniedError(path)",
            "        try:",
            "            increment_items = os.listdir(increment_path)",
            "        except (NotADirectoryError, FileNotFoundError):",
            "            increment_items = None",
            "        except OSError:",
            "            raise AccessDeniedError(path)",
            "        # Raise error if nothing is found",
            "        if existing_items is None and increment_items is None:",
            "            raise DoesNotExistError(path)",
            "",
            "        # Merge information from both location",
            "        # Regroup all information into RdiffDirEntry",
            "        entries = {}",
            "        for name in existing_items or []:",
            "            entries[name] = RdiffDirEntry(",
            "                self,",
            "                os.path.normpath(os.path.join(relative_path, name)),",
            "                exists=True,",
            "                increments=[],",
            "            )",
            "        for item in increment_items or []:",
            "            try:",
            "                increment = IncrementEntry(item)",
            "            except ValueError:",
            "                # Ignore any increment that cannot be parsed",
            "                continue",
            "            entry = entries.get(increment.name, None)",
            "            if not entry:",
            "                # Create a new Direntry",
            "                entry = entries[increment.name] = RdiffDirEntry(",
            "                    self,",
            "                    os.path.normpath(os.path.join(relative_path, increment.name)),",
            "                    exists=False,",
            "                    increments=[increment] if increment else [],",
            "                )",
            "            else:",
            "                # Add increment to dir entry",
            "                bisect.insort_left(entry._increments, increment)",
            "        return sorted(list(entries.values()), key=lambda e: e.path)",
            "",
            "    def fstat(self, path):",
            "        \"\"\"Return a new instance of DirEntry to represent the given path.\"\"\"",
            "        # Compute increment directory location.",
            "        assert isinstance(path, bytes)",
            "        full_path = os.path.normpath(os.path.join(self.full_path, path.strip(b'/')))",
            "        increment_path = os.path.normpath(os.path.join(self._increment_path, path.strip(b'/'), b'..'))",
            "        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):",
            "            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))",
            "        relative_path = os.path.relpath(full_path, self.full_path)",
            "        if relative_path.startswith(RDIFF_BACKUP_DATA):",
            "            raise DoesNotExistError(path)",
            "        # Get if the path request is the root path.",
            "        if relative_path == b'.':",
            "            return RdiffDirEntry(self, b'', True, [])",
            "",
            "        # Check if path exists",
            "        try:",
            "            os.lstat(full_path)",
            "            exists = True",
            "        except (OSError, ValueError):",
            "            exists = False",
            "",
            "        # Get incrmement data",
            "        increment_items = os.listdir(increment_path)",
            "",
            "        # Create dir entry",
            "        prefix = os.path.basename(full_path)",
            "        entry = RdiffDirEntry(self, relative_path, exists, [])",
            "        for item in increment_items:",
            "            if not item.startswith(prefix):",
            "                # Ignore increment not matching our path",
            "                continue",
            "            try:",
            "                increment = IncrementEntry(item)",
            "            except ValueError:",
            "                # Ignore any increment that cannot be parsed",
            "                continue",
            "            if increment.name != prefix:",
            "                # Ignore increment not matching our path",
            "                continue",
            "            # Add increment to dir entry",
            "            bisect.insort_left(entry._increments, increment)",
            "",
            "        # Check if path exists or has increment. If not raise an exception.",
            "        if not exists and not entry._increments:",
            "            logger.error(\"path [%r] doesn't exists\", path)",
            "            raise DoesNotExistError(path)",
            "",
            "        # Create a directory entry.",
            "        return entry",
            "",
            "    @property",
            "    def last_backup_date(self):",
            "        \"\"\"Return the last known backup dates.\"\"\"",
            "        try:",
            "            if len(self.current_mirror) > 0:",
            "                return self.current_mirror[-1].date",
            "            return None",
            "        except (PermissionError, FileNotFoundError):",
            "            return None",
            "",
            "    def get_display_name(self, path):",
            "        \"\"\"",
            "        Return proper display name of the given path according to repository encoding and quoted characters.",
            "        \"\"\"",
            "        assert isinstance(path, bytes)",
            "        path = path.strip(b'/')",
            "        if path in [b'.', b'']:",
            "            # For repository the directory base name",
            "            return self._decode(unquote(os.path.basename(self.full_path)))",
            "        else:",
            "            # For path, we use the dir name",
            "            return self._decode(unquote(os.path.basename(path)))",
            "",
            "    def remove_older(self, remove_older_than):",
            "        assert type(remove_older_than) is int, 'invalid remove_older_than, expect an integer: ' + remove_older_than",
            "        logger.info(",
            "            \"execute rdiff-backup --force --remove-older-than=%sD %r\",",
            "            remove_older_than,",
            "            self.full_path.decode(sys.getfilesystemencoding(), 'replace'),",
            "        )",
            "        subprocess.check_output(",
            "            [",
            "                b'rdiff-backup',",
            "                b'--force',",
            "                b'--remove-older-than=' + str(remove_older_than).encode(encoding='latin1') + b'D',",
            "                self.full_path,",
            "            ]",
            "        )",
            "        self.expire()",
            "",
            "    def restore(self, path, restore_as_of, kind=None):",
            "        \"\"\"",
            "        Restore the current directory entry into a fileobj containing the",
            "        file content of the directory compressed into an archive.",
            "",
            "        `kind` must be one of the supported archive type or none to use `zip` for folder and `raw` for file.",
            "",
            "        Return a filename and a fileobj.",
            "        \"\"\"",
            "        assert isinstance(path, bytes)",
            "        assert restore_as_of, \"restore_as_of must be defined\"",
            "        assert kind in ['tar', 'tar.bz2', 'tar.gz', 'tbz2', 'tgz', 'zip', 'raw', None]",
            "",
            "        # Define proper kind according to path type.",
            "        path_obj = self.fstat(path)",
            "        if path_obj.isdir:",
            "            if kind == 'raw':",
            "                raise ValueError('raw type not supported for directory')",
            "            kind = kind or 'zip'",
            "        else:",
            "            kind = kind or 'raw'",
            "",
            "        # Define proper filename according to the path",
            "        if kind == 'raw':",
            "            filename = path_obj.display_name",
            "        else:",
            "            filename = \"%s.%s\" % (path_obj.display_name, kind)",
            "",
            "        # Call external process to offload processing.",
            "        # python -m rdiffweb.core.restore --restore-as-of 123456 --encoding utf-8 --kind zip -",
            "        cmdline = [",
            "            os.fsencode(sys.executable),",
            "            b'-m',",
            "            b'rdiffweb.core.restore',",
            "            b'--restore-as-of',",
            "            str(restore_as_of).encode('latin'),",
            "            b'--encoding',",
            "            self._encoding.name.encode('latin'),",
            "            b'--kind',",
            "            kind.encode('latin'),",
            "            os.path.join(self.full_path, unquote(path_obj.path)),",
            "            b'-',",
            "        ]",
            "        proc = subprocess.Popen(",
            "            cmdline,",
            "            shell=False,",
            "            stdout=subprocess.PIPE,",
            "            stderr=subprocess.PIPE,",
            "            env=None,",
            "        )",
            "        # Check if the restore process is properly starting",
            "        # Read the first 100 line until \"Processing changed file\"",
            "        max_line = 100",
            "        output = b''",
            "        success = False",
            "        line = proc.stderr.readline()",
            "        while max_line > 0 and line:",
            "            max_line -= 1",
            "            output += line",
            "            if b'Processing changed file' in line:",
            "                success = True",
            "                break",
            "            line = proc.stderr.readline()",
            "        if not success:",
            "            raise CalledProcessError(1, cmdline, output)",
            "        # Start a Thread to pipe the rest of the stream to the log",
            "        t = threading.Thread(target=_readerthread, args=(proc.stderr, logger.debug))",
            "        t.daemon = True",
            "        t.start()",
            "        return filename, _wrap_close(proc.stdout, proc)",
            "",
            "    @property",
            "    def restore_log(self):",
            "        \"\"\"",
            "        Return the location of the restore log.",
            "        \"\"\"",
            "        return RestoreLogEntry(self, b'restore.log')",
            "",
            "    @cached_property",
            "    def status(self):",
            "        \"\"\"Check if a backup is in progress for the current repo.\"\"\"",
            "",
            "        # Read content of the file and check if pid still exists",
            "        try:",
            "            # Make sure repoRoot is a valid rdiff-backup repository",
            "            for current_mirror in self.current_mirror:",
            "                pid = current_mirror.extract_pid()",
            "                try:",
            "                    p = psutil.Process(pid)",
            "                    if any('rdiff-backup' in c for c in p.cmdline()):",
            "                        return ('in_progress', _('A backup is currently in progress to this repository.'))",
            "                except psutil.NoSuchProcess:",
            "                    logger.debug('pid [%s] does not exists', pid)",
            "",
            "            # If multiple current_mirror file exists and none of them are associated to a PID, this mean the last backup was interrupted.",
            "            # Also, if the last backup date is undefined, this mean the first",
            "            # initial backup was interrupted.",
            "            if len(self.current_mirror) > 1 or len(self.current_mirror) == 0:",
            "                return ('interrupted', _('The previous backup seams to have failed.'))",
            "        except FileNotFoundError:",
            "            self._entries = []",
            "            return ('failed', _('The repository cannot be found or is badly damaged.'))",
            "        except PermissionError:",
            "            self._entries = []",
            "            logger.warning('error reading current_mirror files', exc_info=1)",
            "            return ('failed', _(\"Permissions denied. Contact administrator to check repository's permissions.\"))",
            "",
            "        return ('ok', '')"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "848": [
                "RdiffRepo",
                "__init__"
            ],
            "849": [
                "RdiffRepo",
                "__init__"
            ],
            "850": [
                "RdiffRepo",
                "__init__"
            ],
            "851": [
                "RdiffRepo",
                "__init__"
            ],
            "852": [
                "RdiffRepo",
                "__init__"
            ],
            "853": [
                "RdiffRepo",
                "__init__"
            ],
            "854": [
                "RdiffRepo",
                "__init__"
            ],
            "855": [
                "RdiffRepo",
                "__init__"
            ],
            "857": [
                "RdiffRepo",
                "__init__"
            ],
            "858": [
                "RdiffRepo",
                "__init__"
            ],
            "859": [
                "RdiffRepo",
                "__init__"
            ],
            "860": [
                "RdiffRepo",
                "__init__"
            ],
            "861": [
                "RdiffRepo",
                "__init__"
            ],
            "862": [
                "RdiffRepo",
                "__init__"
            ],
            "1090": [
                "RdiffRepo",
                "get_display_name"
            ],
            "1091": [
                "RdiffRepo",
                "get_display_name"
            ],
            "1092": [
                "RdiffRepo",
                "get_display_name"
            ],
            "1093": [
                "RdiffRepo",
                "get_display_name"
            ]
        },
        "addLocation": []
    },
    "rdiffweb/core/model/_repo.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 133,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "     @orm.reconstructor"
            },
            "2": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "     def __init_on_load__(self):"
            },
            "3": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        RdiffRepo.__init__("
            },
            "4": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self, self.user.user_root, self.repopath, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING"
            },
            "5": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "6": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "7": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    @property"
            },
            "8": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def displayname(self):"
            },
            "9": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Repository displayName is the \"repopath\" too."
            },
            "10": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return self.repopath.strip('/')"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+        # RdiffRepo required an absolute full path, When the user_root is invalid, let generate an invalid full path."
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+        if not self.user.user_root:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+            full_path = os.path.join('/user_has_an_empty_user_root/', self.repopath.strip('/'))"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+        elif not os.path.isabs(self.user.user_root):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+            full_path = os.path.join('/user_has_a_relative_user_root/', self.repopath.strip('/'))"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+        else:"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+            full_path = os.path.join(self.user.user_root, self.repopath.strip('/'))"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+        RdiffRepo.__init__(self, full_path, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING)"
            },
            "19": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 144,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "     @property"
            },
            "21": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "     def name(self):"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import codecs",
            "import encodings",
            "import logging",
            "import os",
            "import sys",
            "",
            "import cherrypy",
            "from sqlalchemy import Column, Integer, SmallInteger, String, and_, case, event, orm",
            "from sqlalchemy.ext.hybrid import hybrid_property",
            "from sqlalchemy.orm import relationship, validates",
            "",
            "import rdiffweb.tools.db  # noqa",
            "from rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError, RdiffRepo",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "Base = cherrypy.tools.db.get_base()",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def _split_path(path):",
            "    \"\"\"",
            "    Split the given path into <username as str> / <path as bytes>",
            "    \"\"\"",
            "    # First part is the username",
            "    assert path",
            "    if isinstance(path, str):",
            "        path = os.fsencode(path)",
            "    path = path.strip(b'/')",
            "    if b'/' in path:",
            "        username, path = path.split(b'/', 1)",
            "        return username.decode('utf-8'), path",
            "    else:",
            "        return path.decode('utf-8'), b''",
            "",
            "",
            "class RepoObject(Base, RdiffRepo):",
            "    DEFAULT_REPO_ENCODING = codecs.lookup((sys.getfilesystemencoding() or 'utf-8').lower()).name",
            "",
            "    __tablename__ = 'repos'",
            "    __table_args__ = {'sqlite_autoincrement': True}",
            "",
            "    repoid = Column('RepoID', Integer, primary_key=True, autoincrement=True)",
            "    userid = Column('UserID', Integer, nullable=False)",
            "    user = relationship(",
            "        'UserObject',",
            "        foreign_keys=[userid],",
            "        primaryjoin='UserObject.userid == RepoObject.userid',",
            "        uselist=False,",
            "        lazy=True,",
            "    )",
            "    repopath = Column('RepoPath', String, nullable=False, default='')",
            "    maxage = Column('MaxAge', SmallInteger, nullable=False, server_default=\"0\")",
            "    encoding = Column('Encoding', String, default=DEFAULT_REPO_ENCODING)",
            "    _keepdays = Column('keepdays', String, nullable=False, default=\"-1\")",
            "",
            "    @classmethod",
            "    def get_repo(cls, name, as_user=None, refresh=False):",
            "        \"\"\"",
            "        Return the repository identified as `name`.",
            "        `name` should be <username>/<repopath>",
            "        \"\"\"",
            "        from ._user import UserObject",
            "",
            "        username, repopath = _split_path(name)",
            "        repopath = os.fsdecode(repopath).strip('/')",
            "",
            "        # Check permissions",
            "        as_user = as_user or cherrypy.tree.apps[''].currentuser",
            "        if not as_user:",
            "            raise AccessDeniedError(\"as_user or current user must be defined\")",
            "        if username != as_user.username and not as_user.is_admin:",
            "            raise AccessDeniedError(name)",
            "",
            "        # Search the repo in database",
            "        query = RepoObject.query.join(UserObject, UserObject.userid == RepoObject.userid).filter(",
            "            and_(UserObject.username == username, RepoObject.repopath == repopath)",
            "        )",
            "        record = query.first()",
            "        # If the repo is not found but refresh is requested",
            "        if refresh and not record:",
            "            if as_user.refresh_repos():",
            "                as_user.commit()",
            "            record = query.first()",
            "        # If repo is not found, raise an error",
            "        if not record:",
            "            raise DoesNotExistError(username, repopath)",
            "        return record",
            "",
            "    @classmethod",
            "    def get_repo_path(cls, path, as_user=None, refresh=False):",
            "        \"\"\"",
            "        Return a the repository identified by the given `path`.",
            "        `path` should be <username>/<repopath>/<subdir>",
            "        \"\"\"",
            "        assert isinstance(path, bytes) or isinstance(path, str)",
            "        sep = b'/' if isinstance(path, bytes) else '/'",
            "        path = path.strip(sep) + sep",
            "",
            "        # Since we don't know which part of the \"path\" is the repopath,",
            "        # we need to do multiple search.",
            "        try:",
            "            startpos = 0",
            "            while True:",
            "                pos = path.index(sep, startpos)",
            "                try:",
            "                    # Run refresh only on first run.",
            "                    repo_obj = cls.get_repo(path[:pos], as_user, refresh=refresh and startpos == 0)",
            "                    break",
            "                except DoesNotExistError:",
            "                    # Raised when repo doesn't exists",
            "                    startpos = pos + 1",
            "            return repo_obj, path[pos + 1 :]",
            "        except ValueError:",
            "            raise DoesNotExistError(path)",
            "",
            "    @orm.reconstructor",
            "    def __init_on_load__(self):",
            "        RdiffRepo.__init__(",
            "            self, self.user.user_root, self.repopath, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING",
            "        )",
            "",
            "    @property",
            "    def displayname(self):",
            "        # Repository displayName is the \"repopath\" too.",
            "        return self.repopath.strip('/')",
            "",
            "    @property",
            "    def name(self):",
            "        # Repository name is the \"repopath\"",
            "        return self.repopath",
            "",
            "    @property",
            "    def owner(self):",
            "        return self.user.username",
            "",
            "    @hybrid_property",
            "    def keepdays(self):",
            "        try:",
            "            return int(self._keepdays) if self._keepdays else -1",
            "        except ValueError:",
            "            return -1",
            "",
            "    @keepdays.expression",
            "    def keepdays(cls):",
            "        return case(",
            "            (cls._keepdays.is_(None), -1),",
            "            (cls._keepdays == '', -1),",
            "            else_=cls._keepdays.cast(Integer),",
            "        )",
            "",
            "    @keepdays.setter",
            "    def keepdays(self, value):",
            "        self._keepdays = value",
            "",
            "    def delete(self, path=b''):",
            "        \"\"\"Properly remove the given repository by updating the user's repositories.\"\"\"",
            "        logger.info(\"deleting repository %s\", self)",
            "        # Remove data from disk",
            "        RdiffRepo.delete(self, path=path)",
            "        # Remove entry from database after deleting files.",
            "        # Otherwise, refresh will add this repo back.",
            "        return super().delete()",
            "",
            "    @validates('encoding')",
            "    def validate_encoding(self, key, value):",
            "        codec = encodings.search_function(value.lower())",
            "        if not codec:",
            "            raise ValueError(_('invalid encoding %s') % value)",
            "        return codec.name",
            "",
            "    @validates('maxage')",
            "    def validate_maxage(self, key, value):",
            "        int(value)",
            "        return value",
            "",
            "    @validates('_keepdays')",
            "    def validate_keepdays(self, key, value):",
            "        int(value)",
            "        return value",
            "",
            "    def __str__(self):",
            "        return \"RepoObject[%s, %s]\" % (self.userid, self.repopath)",
            "",
            "",
            "@event.listens_for(RepoObject.encoding, \"set\")",
            "def encoding_set(target, value, oldvalue, initiator):",
            "    codec = encodings.search_function(value)",
            "    if codec:",
            "        target._encoding = codec"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import codecs",
            "import encodings",
            "import logging",
            "import os",
            "import sys",
            "",
            "import cherrypy",
            "from sqlalchemy import Column, Integer, SmallInteger, String, and_, case, event, orm",
            "from sqlalchemy.ext.hybrid import hybrid_property",
            "from sqlalchemy.orm import relationship, validates",
            "",
            "import rdiffweb.tools.db  # noqa",
            "from rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError, RdiffRepo",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "Base = cherrypy.tools.db.get_base()",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def _split_path(path):",
            "    \"\"\"",
            "    Split the given path into <username as str> / <path as bytes>",
            "    \"\"\"",
            "    # First part is the username",
            "    assert path",
            "    if isinstance(path, str):",
            "        path = os.fsencode(path)",
            "    path = path.strip(b'/')",
            "    if b'/' in path:",
            "        username, path = path.split(b'/', 1)",
            "        return username.decode('utf-8'), path",
            "    else:",
            "        return path.decode('utf-8'), b''",
            "",
            "",
            "class RepoObject(Base, RdiffRepo):",
            "    DEFAULT_REPO_ENCODING = codecs.lookup((sys.getfilesystemencoding() or 'utf-8').lower()).name",
            "",
            "    __tablename__ = 'repos'",
            "    __table_args__ = {'sqlite_autoincrement': True}",
            "",
            "    repoid = Column('RepoID', Integer, primary_key=True, autoincrement=True)",
            "    userid = Column('UserID', Integer, nullable=False)",
            "    user = relationship(",
            "        'UserObject',",
            "        foreign_keys=[userid],",
            "        primaryjoin='UserObject.userid == RepoObject.userid',",
            "        uselist=False,",
            "        lazy=True,",
            "    )",
            "    repopath = Column('RepoPath', String, nullable=False, default='')",
            "    maxage = Column('MaxAge', SmallInteger, nullable=False, server_default=\"0\")",
            "    encoding = Column('Encoding', String, default=DEFAULT_REPO_ENCODING)",
            "    _keepdays = Column('keepdays', String, nullable=False, default=\"-1\")",
            "",
            "    @classmethod",
            "    def get_repo(cls, name, as_user=None, refresh=False):",
            "        \"\"\"",
            "        Return the repository identified as `name`.",
            "        `name` should be <username>/<repopath>",
            "        \"\"\"",
            "        from ._user import UserObject",
            "",
            "        username, repopath = _split_path(name)",
            "        repopath = os.fsdecode(repopath).strip('/')",
            "",
            "        # Check permissions",
            "        as_user = as_user or cherrypy.tree.apps[''].currentuser",
            "        if not as_user:",
            "            raise AccessDeniedError(\"as_user or current user must be defined\")",
            "        if username != as_user.username and not as_user.is_admin:",
            "            raise AccessDeniedError(name)",
            "",
            "        # Search the repo in database",
            "        query = RepoObject.query.join(UserObject, UserObject.userid == RepoObject.userid).filter(",
            "            and_(UserObject.username == username, RepoObject.repopath == repopath)",
            "        )",
            "        record = query.first()",
            "        # If the repo is not found but refresh is requested",
            "        if refresh and not record:",
            "            if as_user.refresh_repos():",
            "                as_user.commit()",
            "            record = query.first()",
            "        # If repo is not found, raise an error",
            "        if not record:",
            "            raise DoesNotExistError(username, repopath)",
            "        return record",
            "",
            "    @classmethod",
            "    def get_repo_path(cls, path, as_user=None, refresh=False):",
            "        \"\"\"",
            "        Return a the repository identified by the given `path`.",
            "        `path` should be <username>/<repopath>/<subdir>",
            "        \"\"\"",
            "        assert isinstance(path, bytes) or isinstance(path, str)",
            "        sep = b'/' if isinstance(path, bytes) else '/'",
            "        path = path.strip(sep) + sep",
            "",
            "        # Since we don't know which part of the \"path\" is the repopath,",
            "        # we need to do multiple search.",
            "        try:",
            "            startpos = 0",
            "            while True:",
            "                pos = path.index(sep, startpos)",
            "                try:",
            "                    # Run refresh only on first run.",
            "                    repo_obj = cls.get_repo(path[:pos], as_user, refresh=refresh and startpos == 0)",
            "                    break",
            "                except DoesNotExistError:",
            "                    # Raised when repo doesn't exists",
            "                    startpos = pos + 1",
            "            return repo_obj, path[pos + 1 :]",
            "        except ValueError:",
            "            raise DoesNotExistError(path)",
            "",
            "    @orm.reconstructor",
            "    def __init_on_load__(self):",
            "        # RdiffRepo required an absolute full path, When the user_root is invalid, let generate an invalid full path.",
            "        if not self.user.user_root:",
            "            full_path = os.path.join('/user_has_an_empty_user_root/', self.repopath.strip('/'))",
            "        elif not os.path.isabs(self.user.user_root):",
            "            full_path = os.path.join('/user_has_a_relative_user_root/', self.repopath.strip('/'))",
            "        else:",
            "            full_path = os.path.join(self.user.user_root, self.repopath.strip('/'))",
            "        RdiffRepo.__init__(self, full_path, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING)",
            "",
            "    @property",
            "    def name(self):",
            "        # Repository name is the \"repopath\"",
            "        return self.repopath",
            "",
            "    @property",
            "    def owner(self):",
            "        return self.user.username",
            "",
            "    @hybrid_property",
            "    def keepdays(self):",
            "        try:",
            "            return int(self._keepdays) if self._keepdays else -1",
            "        except ValueError:",
            "            return -1",
            "",
            "    @keepdays.expression",
            "    def keepdays(cls):",
            "        return case(",
            "            (cls._keepdays.is_(None), -1),",
            "            (cls._keepdays == '', -1),",
            "            else_=cls._keepdays.cast(Integer),",
            "        )",
            "",
            "    @keepdays.setter",
            "    def keepdays(self, value):",
            "        self._keepdays = value",
            "",
            "    def delete(self, path=b''):",
            "        \"\"\"Properly remove the given repository by updating the user's repositories.\"\"\"",
            "        logger.info(\"deleting repository %s\", self)",
            "        # Remove data from disk",
            "        RdiffRepo.delete(self, path=path)",
            "        # Remove entry from database after deleting files.",
            "        # Otherwise, refresh will add this repo back.",
            "        return super().delete()",
            "",
            "    @validates('encoding')",
            "    def validate_encoding(self, key, value):",
            "        codec = encodings.search_function(value.lower())",
            "        if not codec:",
            "            raise ValueError(_('invalid encoding %s') % value)",
            "        return codec.name",
            "",
            "    @validates('maxage')",
            "    def validate_maxage(self, key, value):",
            "        int(value)",
            "        return value",
            "",
            "    @validates('_keepdays')",
            "    def validate_keepdays(self, key, value):",
            "        int(value)",
            "        return value",
            "",
            "    def __str__(self):",
            "        return \"RepoObject[%s, %s]\" % (self.userid, self.repopath)",
            "",
            "",
            "@event.listens_for(RepoObject.encoding, \"set\")",
            "def encoding_set(target, value, oldvalue, initiator):",
            "    codec = encodings.search_function(value)",
            "    if codec:",
            "        target._encoding = codec"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "136": [
                "RepoObject",
                "__init_on_load__"
            ],
            "137": [
                "RepoObject",
                "__init_on_load__"
            ],
            "138": [
                "RepoObject",
                "__init_on_load__"
            ],
            "139": [
                "RepoObject"
            ],
            "140": [
                "RepoObject"
            ],
            "141": [
                "RepoObject",
                "displayname"
            ],
            "142": [
                "RepoObject",
                "displayname"
            ],
            "143": [
                "RepoObject",
                "displayname"
            ]
        },
        "addLocation": []
    },
    "rdiffweb/core/model/tests/test_user.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 433,
                "afterPatchRowNumber": 433,
                "PatchRowcode": "         userobj.expire()"
            },
            "1": {
                "beforePatchRowNumber": 434,
                "afterPatchRowNumber": 434,
                "PatchRowcode": "         self.assertEqual([''], sorted([r.name for r in userobj.repo_objs]))"
            },
            "2": {
                "beforePatchRowNumber": 435,
                "afterPatchRowNumber": 435,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 436,
                "PatchRowcode": "+    def test_refresh_repos_with_empty_userroot(self):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 437,
                "PatchRowcode": "+        # Given a user with valid repositories relative to root"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 438,
                "PatchRowcode": "+        userobj = UserObject.get_user(self.USERNAME)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 439,
                "PatchRowcode": "+        for repo in userobj.repo_objs:"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 440,
                "PatchRowcode": "+            repo.repopath = self.testcases[1:] + '/' + repo.repopath"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 441,
                "PatchRowcode": "+            repo.add().commit()"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 442,
                "PatchRowcode": "+        userobj.user_root = '/'"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 443,
                "PatchRowcode": "+        userobj.add().commit()"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 444,
                "PatchRowcode": "+        self.assertEqual(['interrupted', 'ok'], sorted([r.status[0] for r in userobj.repo_objs]))"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 445,
                "PatchRowcode": "+        # When updating it's userroot directory to an empty value"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 446,
                "PatchRowcode": "+        userobj.user_root = ''"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 447,
                "PatchRowcode": "+        userobj.add().commit()"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 448,
                "PatchRowcode": "+        UserObject.session.expire_all()"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 449,
                "PatchRowcode": "+        # Then close session"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 450,
                "PatchRowcode": "+        cherrypy.tools.db.on_end_resource()"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 451,
                "PatchRowcode": "+        # Then repo status is \"broken\""
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 452,
                "PatchRowcode": "+        userobj = UserObject.get_user(self.USERNAME)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 453,
                "PatchRowcode": "+        self.assertFalse(userobj.valid_user_root())"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 454,
                "PatchRowcode": "+        self.assertEqual(['failed', 'failed'], [r.status[0] for r in userobj.repo_objs])"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 455,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": 436,
                "afterPatchRowNumber": 456,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 437,
                "afterPatchRowNumber": 457,
                "PatchRowcode": " class UserObjectWithAdminPassword(rdiffweb.test.WebCase):"
            },
            "25": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": 458,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "\"\"\"",
            "Created on June 30, 2022",
            "",
            "Module to test `user` model.",
            "",
            "@author: Patrik Dufresne <patrik@ikus-soft.com>",
            "\"\"\"",
            "import os",
            "from io import StringIO, open",
            "from unittest.mock import MagicMock",
            "",
            "import cherrypy",
            "import pkg_resources",
            "from parameterized import parameterized",
            "",
            "import rdiffweb.test",
            "from rdiffweb.core import authorizedkeys",
            "from rdiffweb.core.model import DuplicateSSHKeyError, RepoObject, UserObject",
            "from rdiffweb.core.passwd import check_password",
            "",
            "",
            "class UserObjectTest(rdiffweb.test.WebCase):",
            "    def _read_ssh_key(self):",
            "        \"\"\"Readthe pub key from test packages\"\"\"",
            "        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_publickey_ssh_rsa.pub')",
            "        with open(filename, 'r', encoding='utf8') as f:",
            "            return f.readline()",
            "",
            "    def _read_authorized_keys(self):",
            "        \"\"\"Read the content of test_authorized_keys\"\"\"",
            "        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_authorized_keys')",
            "        with open(filename, 'r', encoding='utf8') as f:",
            "            return f.read()",
            "",
            "    def setUp(self):",
            "        super().setUp()",
            "        self.listener = MagicMock()",
            "        cherrypy.engine.subscribe('access_token_added', self.listener.access_token_added, priority=50)",
            "        cherrypy.engine.subscribe('queue_mail', self.listener.queue_mail, priority=50)",
            "        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)",
            "        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)",
            "        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)",
            "        cherrypy.engine.subscribe('user_login', self.listener.user_login, priority=50)",
            "        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)",
            "",
            "    def tearDown(self):",
            "        cherrypy.engine.unsubscribe('access_token_added', self.listener.access_token_added)",
            "        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_mail)",
            "        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)",
            "        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)",
            "        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)",
            "        cherrypy.engine.unsubscribe('user_login', self.listener.user_login)",
            "        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)",
            "        return super().tearDown()",
            "",
            "    def test_add_user(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        userobj = UserObject.add_user('joe')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('joe'))",
            "        # Check if listener called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_add_user_updated_by_listener(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        # Given a listener with side effet",
            "        def change_user_obj(userobj):",
            "            userobj.user_root = '/new/value'",
            "",
            "        self.listener.user_added.side_effect = change_user_obj",
            "        # When adding user",
            "        userobj = UserObject.add_user('joe')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('joe'))",
            "        # Then lister get called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "        # Then object was updated by listener",
            "        self.assertEqual('/new/value', userobj.user_root)",
            "",
            "    def test_add_user_with_duplicate(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        user = UserObject.add_user('denise')",
            "        user.commit()",
            "        self.listener.user_added.reset_mock()",
            "        with self.assertRaises(ValueError):",
            "            UserObject.add_user('denise')",
            "        # Check if listener called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "    def test_add_user_with_password(self):",
            "        \"\"\"Add user to database with password.\"\"\"",
            "        userobj = UserObject.add_user('jo', 'password')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('jo'))",
            "        # Check if listener called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_delete_admin_user(self):",
            "        # Trying to delete admin user should raise an error.",
            "        userobj = UserObject.get_user('admin')",
            "        with self.assertRaises(ValueError):",
            "            userobj.delete()",
            "",
            "    def test_users(self):",
            "        # Check admin exists",
            "        self.assertEqual(1, UserObject.query.count())",
            "        # Create user.",
            "        user = UserObject.add_user('annik')",
            "        user.commit()",
            "        users = UserObject.query.all()",
            "        self.assertEqual(2, len(users))",
            "        self.assertEqual('annik', users[1].username)",
            "        # Then 2 user exists",
            "        self.assertEqual(2, UserObject.query.count())",
            "",
            "    def test_get_user(self):",
            "        # Create new user",
            "        user = UserObject.add_user('bernie', 'my-password')",
            "        user.user_root = self.testcases",
            "        user.role = UserObject.ADMIN_ROLE",
            "        user.email = 'bernie@gmail.com'",
            "        user.refresh_repos()",
            "        user.commit()",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))",
            "        user.repo_objs[0].maxage = -1",
            "        user.repo_objs[1].maxage = 3",
            "        user.commit()",
            "",
            "        # Get user record.",
            "        obj = UserObject.get_user('bernie')",
            "        self.assertIsNotNone(obj)",
            "        self.assertEqual('bernie', obj.username)",
            "        self.assertEqual('bernie@gmail.com', obj.email)",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in obj.repo_objs]))",
            "        self.assertEqual(self.testcases, obj.user_root)",
            "        self.assertEqual(True, obj.is_admin)",
            "        self.assertEqual(UserObject.ADMIN_ROLE, obj.role)",
            "",
            "        # Get repo object",
            "        self.assertEqual('broker-repo', obj.repo_objs[0].name)",
            "        self.assertEqual(-1, obj.repo_objs[0].maxage)",
            "        self.assertEqual('testcases', obj.repo_objs[1].name)",
            "        self.assertEqual(3, obj.repo_objs[1].maxage)",
            "",
            "    def test_get_user_with_invalid_user(self):",
            "        self.assertIsNone(UserObject.get_user('invalid'))",
            "",
            "    def test_get_set(self):",
            "        user = UserObject.add_user('larry', 'password')",
            "        user.add().commit()",
            "",
            "        self.assertEqual('', user.email)",
            "        self.assertEqual([], user.repo_objs)",
            "        self.assertEqual('', user.user_root)",
            "        self.assertEqual(False, user.is_admin)",
            "        self.assertEqual(UserObject.USER_ROLE, user.role)",
            "",
            "        user.user_root = self.testcases",
            "        user.refresh_repos()",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(user, {'user_root': ('', self.testcases)})",
            "        self.listener.user_attr_changed.reset_mock()",
            "        user = UserObject.get_user('larry')",
            "        user.role = UserObject.ADMIN_ROLE",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(",
            "            user, {'role': (UserObject.USER_ROLE, UserObject.ADMIN_ROLE)}",
            "        )",
            "        self.listener.user_attr_changed.reset_mock()",
            "        user = UserObject.get_user('larry')",
            "        user.email = 'larry@gmail.com'",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(user, {'email': ('', 'larry@gmail.com')})",
            "        self.listener.user_attr_changed.reset_mock()",
            "",
            "        self.assertEqual('larry@gmail.com', user.email)",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))",
            "        self.assertEqual(self.testcases, user.user_root)",
            "        self.assertEqual(True, user.is_admin)",
            "        self.assertEqual(UserObject.ADMIN_ROLE, user.role)",
            "",
            "    def test_set_role_null(self):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        user.add().commit()",
            "        # When trying to set the role to null",
            "        user.role = None",
            "        # Then an exception is raised",
            "        with self.assertRaises(Exception):",
            "            user.add().commit()",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (-1, True),",
            "            (0, True),",
            "            (5, False),",
            "            (10, False),",
            "            (15, False),",
            "        ]",
            "    )",
            "    def test_is_admin(self, role, expected_is_admin):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        # When setting the role value",
            "        user.role = role",
            "        user.commit()",
            "        # Then the is_admin value get updated too",
            "        self.assertEqual(expected_is_admin, user.is_admin)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (-1, True),",
            "            (0, True),",
            "            (5, True),",
            "            (10, False),",
            "            (15, False),",
            "        ]",
            "    )",
            "    def test_is_maintainer(self, role, expected_is_maintainer):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        # When setting the role value",
            "        user.role = role",
            "        user.commit()",
            "        # Then the is_admin value get updated too",
            "        self.assertEqual(expected_is_maintainer, user.is_maintainer)",
            "",
            "    def test_set_password_update(self):",
            "        # Given a user in database with a password",
            "        userobj = UserObject.add_user('annik', 'password')",
            "        userobj.commit()",
            "        self.listener.user_password_changed.reset_mock()",
            "        # When updating the user's password",
            "        userobj.set_password('new_password')",
            "        userobj.commit()",
            "        # Then password is SSHA",
            "        self.assertTrue(check_password('new_password', userobj.hash_password))",
            "        # Check if listener called",
            "        self.listener.user_password_changed.assert_called_once_with(userobj)",
            "",
            "    def test_delete_user(self):",
            "        # Given an existing user in database",
            "        userobj = UserObject.add_user('vicky')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('vicky'))",
            "        # When deleting that user",
            "        userobj.delete()",
            "        userobj.commit()",
            "        # Then user it no longer in database",
            "        self.assertIsNone(UserObject.get_user('vicky'))",
            "        # Then listner was called",
            "        self.listener.user_deleted.assert_called_once_with('vicky')",
            "",
            "    def test_set_password_empty(self):",
            "        \"\"\"Expect error when trying to update password of invalid user.\"\"\"",
            "        userobj = UserObject.add_user('john')",
            "        userobj.commit()",
            "        with self.assertRaises(ValueError):",
            "            self.assertFalse(userobj.set_password(''))",
            "",
            "    def test_disk_quota(self):",
            "        \"\"\"",
            "        Just make a call to the function.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.disk_quota",
            "",
            "    def test_disk_usage(self):",
            "        \"\"\"",
            "        Just make a call to the function.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        disk_usage = userobj.disk_usage",
            "        self.assertIsInstance(disk_usage, int)",
            "",
            "    def test_add_authorizedkey_without_file(self):",
            "        \"\"\"",
            "        Add an ssh key for a user without an authorizedkey file.",
            "        \"\"\"",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        # Add the key to the user",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "",
            "        # validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(1, len(keys), \"expecting one key\")",
            "        self.assertEqual(\"3c:99:ed:a7:82:a8:71:09:2c:15:3d:78:4a:8c:11:99\", keys[0].fingerprint)",
            "",
            "    def test_add_authorizedkey_duplicate(self):",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        # Add the key to the user",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "        # Add the same key",
            "        with self.assertRaises(DuplicateSSHKeyError):",
            "            userobj.add_authorizedkey(key)",
            "            userobj.commit()",
            "",
            "    def test_add_authorizedkey_with_file(self):",
            "        \"\"\"",
            "        Add an ssh key for a user with an authorizedkey file.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "",
            "        # Create empty authorized_keys file",
            "        os.mkdir(os.path.join(userobj.user_root, '.ssh'))",
            "        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')",
            "        open(filename, 'a').close()",
            "",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "",
            "        # Validate",
            "        with open(filename, 'r') as fh:",
            "            self.assertEqual(key, fh.read())",
            "",
            "    def test_delete_authorizedkey_without_file(self):",
            "        \"\"\"",
            "        Remove an ssh key for a user without authorizedkey file.",
            "        \"\"\"",
            "        # Update user with ssh keys.",
            "        data = self._read_authorized_keys()",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        for k in authorizedkeys.read(StringIO(data)):",
            "            try:",
            "                userobj.add_authorizedkey(k.getvalue())",
            "            except ValueError:",
            "                # Some ssh key in the testing file are not valid.",
            "                pass",
            "",
            "        # Get the keys",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(2, len(keys))",
            "",
            "        # Remove a key",
            "        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")",
            "        userobj.commit()",
            "",
            "        # Validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(1, len(keys))",
            "",
            "    def test_delete_authorizedkey_with_file(self):",
            "        \"\"\"",
            "        Remove an ssh key for a user with authorizedkey file.",
            "        \"\"\"",
            "        # Create authorized_keys file",
            "        data = self._read_authorized_keys()",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        os.mkdir(os.path.join(userobj.user_root, '.ssh'))",
            "        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')",
            "        with open(filename, 'w') as f:",
            "            f.write(data)",
            "",
            "        # Get the keys",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(5, len(keys))",
            "",
            "        # Remove a key",
            "        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")",
            "",
            "        # Validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(4, len(keys))",
            "",
            "    def test_repo_objs(self):",
            "        # Given a user with a list of repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        repos = sorted(userobj.repo_objs, key=lambda r: r.name)",
            "        self.assertEqual(['broker-repo', 'testcases'], [r.name for r in repos])",
            "        # When deleting a repository empty list",
            "        repos[1].delete()",
            "        repos[1].commit()",
            "        # Then the repository is removed from the list.",
            "        self.assertEqual(['broker-repo'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_without_delete(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        RepoObject.query.delete()",
            "        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()",
            "        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos()",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_with_delete(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        RepoObject.query.delete()",
            "        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()",
            "        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos(delete=True)",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        userobj.expire()",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_with_single_repo(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.user_root = os.path.join(self.testcases, 'testcases')",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos(delete=True)",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        userobj.expire()",
            "        self.assertEqual([''], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "",
            "class UserObjectWithAdminPassword(rdiffweb.test.WebCase):",
            "",
            "    # password: test",
            "    default_config = {'admin-password': '{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e'}",
            "",
            "    def setUp(self):",
            "        # Do nothing - We need to skip the default setup to avoid deleting the records.",
            "        pass",
            "",
            "    def test_create_admin_user(self):",
            "        # Given admin-password is configure",
            "        # When database get created",
            "        # Then admin user get created with 'test' password",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        self.assertIsNotNone(userobj)",
            "        self.assertEqual('{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e', userobj.hash_password)",
            "        self.assertTrue(check_password('test', userobj.hash_password))",
            "",
            "        # Given admin-password is configure",
            "        # When trying to update admin password",
            "        # Then an exception is raised",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        with self.assertRaises(ValueError):",
            "            userobj.set_password('newpassword')"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "\"\"\"",
            "Created on June 30, 2022",
            "",
            "Module to test `user` model.",
            "",
            "@author: Patrik Dufresne <patrik@ikus-soft.com>",
            "\"\"\"",
            "import os",
            "from io import StringIO, open",
            "from unittest.mock import MagicMock",
            "",
            "import cherrypy",
            "import pkg_resources",
            "from parameterized import parameterized",
            "",
            "import rdiffweb.test",
            "from rdiffweb.core import authorizedkeys",
            "from rdiffweb.core.model import DuplicateSSHKeyError, RepoObject, UserObject",
            "from rdiffweb.core.passwd import check_password",
            "",
            "",
            "class UserObjectTest(rdiffweb.test.WebCase):",
            "    def _read_ssh_key(self):",
            "        \"\"\"Readthe pub key from test packages\"\"\"",
            "        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_publickey_ssh_rsa.pub')",
            "        with open(filename, 'r', encoding='utf8') as f:",
            "            return f.readline()",
            "",
            "    def _read_authorized_keys(self):",
            "        \"\"\"Read the content of test_authorized_keys\"\"\"",
            "        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_authorized_keys')",
            "        with open(filename, 'r', encoding='utf8') as f:",
            "            return f.read()",
            "",
            "    def setUp(self):",
            "        super().setUp()",
            "        self.listener = MagicMock()",
            "        cherrypy.engine.subscribe('access_token_added', self.listener.access_token_added, priority=50)",
            "        cherrypy.engine.subscribe('queue_mail', self.listener.queue_mail, priority=50)",
            "        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)",
            "        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)",
            "        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)",
            "        cherrypy.engine.subscribe('user_login', self.listener.user_login, priority=50)",
            "        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)",
            "",
            "    def tearDown(self):",
            "        cherrypy.engine.unsubscribe('access_token_added', self.listener.access_token_added)",
            "        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_mail)",
            "        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)",
            "        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)",
            "        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)",
            "        cherrypy.engine.unsubscribe('user_login', self.listener.user_login)",
            "        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)",
            "        return super().tearDown()",
            "",
            "    def test_add_user(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        userobj = UserObject.add_user('joe')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('joe'))",
            "        # Check if listener called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_add_user_updated_by_listener(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        # Given a listener with side effet",
            "        def change_user_obj(userobj):",
            "            userobj.user_root = '/new/value'",
            "",
            "        self.listener.user_added.side_effect = change_user_obj",
            "        # When adding user",
            "        userobj = UserObject.add_user('joe')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('joe'))",
            "        # Then lister get called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "        # Then object was updated by listener",
            "        self.assertEqual('/new/value', userobj.user_root)",
            "",
            "    def test_add_user_with_duplicate(self):",
            "        \"\"\"Add user to database.\"\"\"",
            "        user = UserObject.add_user('denise')",
            "        user.commit()",
            "        self.listener.user_added.reset_mock()",
            "        with self.assertRaises(ValueError):",
            "            UserObject.add_user('denise')",
            "        # Check if listener called",
            "        self.listener.user_added.assert_not_called()",
            "",
            "    def test_add_user_with_password(self):",
            "        \"\"\"Add user to database with password.\"\"\"",
            "        userobj = UserObject.add_user('jo', 'password')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('jo'))",
            "        # Check if listener called",
            "        self.listener.user_added.assert_called_once_with(userobj)",
            "",
            "    def test_delete_admin_user(self):",
            "        # Trying to delete admin user should raise an error.",
            "        userobj = UserObject.get_user('admin')",
            "        with self.assertRaises(ValueError):",
            "            userobj.delete()",
            "",
            "    def test_users(self):",
            "        # Check admin exists",
            "        self.assertEqual(1, UserObject.query.count())",
            "        # Create user.",
            "        user = UserObject.add_user('annik')",
            "        user.commit()",
            "        users = UserObject.query.all()",
            "        self.assertEqual(2, len(users))",
            "        self.assertEqual('annik', users[1].username)",
            "        # Then 2 user exists",
            "        self.assertEqual(2, UserObject.query.count())",
            "",
            "    def test_get_user(self):",
            "        # Create new user",
            "        user = UserObject.add_user('bernie', 'my-password')",
            "        user.user_root = self.testcases",
            "        user.role = UserObject.ADMIN_ROLE",
            "        user.email = 'bernie@gmail.com'",
            "        user.refresh_repos()",
            "        user.commit()",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))",
            "        user.repo_objs[0].maxage = -1",
            "        user.repo_objs[1].maxage = 3",
            "        user.commit()",
            "",
            "        # Get user record.",
            "        obj = UserObject.get_user('bernie')",
            "        self.assertIsNotNone(obj)",
            "        self.assertEqual('bernie', obj.username)",
            "        self.assertEqual('bernie@gmail.com', obj.email)",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in obj.repo_objs]))",
            "        self.assertEqual(self.testcases, obj.user_root)",
            "        self.assertEqual(True, obj.is_admin)",
            "        self.assertEqual(UserObject.ADMIN_ROLE, obj.role)",
            "",
            "        # Get repo object",
            "        self.assertEqual('broker-repo', obj.repo_objs[0].name)",
            "        self.assertEqual(-1, obj.repo_objs[0].maxage)",
            "        self.assertEqual('testcases', obj.repo_objs[1].name)",
            "        self.assertEqual(3, obj.repo_objs[1].maxage)",
            "",
            "    def test_get_user_with_invalid_user(self):",
            "        self.assertIsNone(UserObject.get_user('invalid'))",
            "",
            "    def test_get_set(self):",
            "        user = UserObject.add_user('larry', 'password')",
            "        user.add().commit()",
            "",
            "        self.assertEqual('', user.email)",
            "        self.assertEqual([], user.repo_objs)",
            "        self.assertEqual('', user.user_root)",
            "        self.assertEqual(False, user.is_admin)",
            "        self.assertEqual(UserObject.USER_ROLE, user.role)",
            "",
            "        user.user_root = self.testcases",
            "        user.refresh_repos()",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(user, {'user_root': ('', self.testcases)})",
            "        self.listener.user_attr_changed.reset_mock()",
            "        user = UserObject.get_user('larry')",
            "        user.role = UserObject.ADMIN_ROLE",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(",
            "            user, {'role': (UserObject.USER_ROLE, UserObject.ADMIN_ROLE)}",
            "        )",
            "        self.listener.user_attr_changed.reset_mock()",
            "        user = UserObject.get_user('larry')",
            "        user.email = 'larry@gmail.com'",
            "        user.commit()",
            "        self.listener.user_attr_changed.assert_called_with(user, {'email': ('', 'larry@gmail.com')})",
            "        self.listener.user_attr_changed.reset_mock()",
            "",
            "        self.assertEqual('larry@gmail.com', user.email)",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))",
            "        self.assertEqual(self.testcases, user.user_root)",
            "        self.assertEqual(True, user.is_admin)",
            "        self.assertEqual(UserObject.ADMIN_ROLE, user.role)",
            "",
            "    def test_set_role_null(self):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        user.add().commit()",
            "        # When trying to set the role to null",
            "        user.role = None",
            "        # Then an exception is raised",
            "        with self.assertRaises(Exception):",
            "            user.add().commit()",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (-1, True),",
            "            (0, True),",
            "            (5, False),",
            "            (10, False),",
            "            (15, False),",
            "        ]",
            "    )",
            "    def test_is_admin(self, role, expected_is_admin):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        # When setting the role value",
            "        user.role = role",
            "        user.commit()",
            "        # Then the is_admin value get updated too",
            "        self.assertEqual(expected_is_admin, user.is_admin)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (-1, True),",
            "            (0, True),",
            "            (5, True),",
            "            (10, False),",
            "            (15, False),",
            "        ]",
            "    )",
            "    def test_is_maintainer(self, role, expected_is_maintainer):",
            "        # Given a user",
            "        user = UserObject.add_user('annik', 'password')",
            "        # When setting the role value",
            "        user.role = role",
            "        user.commit()",
            "        # Then the is_admin value get updated too",
            "        self.assertEqual(expected_is_maintainer, user.is_maintainer)",
            "",
            "    def test_set_password_update(self):",
            "        # Given a user in database with a password",
            "        userobj = UserObject.add_user('annik', 'password')",
            "        userobj.commit()",
            "        self.listener.user_password_changed.reset_mock()",
            "        # When updating the user's password",
            "        userobj.set_password('new_password')",
            "        userobj.commit()",
            "        # Then password is SSHA",
            "        self.assertTrue(check_password('new_password', userobj.hash_password))",
            "        # Check if listener called",
            "        self.listener.user_password_changed.assert_called_once_with(userobj)",
            "",
            "    def test_delete_user(self):",
            "        # Given an existing user in database",
            "        userobj = UserObject.add_user('vicky')",
            "        userobj.commit()",
            "        self.assertIsNotNone(UserObject.get_user('vicky'))",
            "        # When deleting that user",
            "        userobj.delete()",
            "        userobj.commit()",
            "        # Then user it no longer in database",
            "        self.assertIsNone(UserObject.get_user('vicky'))",
            "        # Then listner was called",
            "        self.listener.user_deleted.assert_called_once_with('vicky')",
            "",
            "    def test_set_password_empty(self):",
            "        \"\"\"Expect error when trying to update password of invalid user.\"\"\"",
            "        userobj = UserObject.add_user('john')",
            "        userobj.commit()",
            "        with self.assertRaises(ValueError):",
            "            self.assertFalse(userobj.set_password(''))",
            "",
            "    def test_disk_quota(self):",
            "        \"\"\"",
            "        Just make a call to the function.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.disk_quota",
            "",
            "    def test_disk_usage(self):",
            "        \"\"\"",
            "        Just make a call to the function.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        disk_usage = userobj.disk_usage",
            "        self.assertIsInstance(disk_usage, int)",
            "",
            "    def test_add_authorizedkey_without_file(self):",
            "        \"\"\"",
            "        Add an ssh key for a user without an authorizedkey file.",
            "        \"\"\"",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        # Add the key to the user",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "",
            "        # validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(1, len(keys), \"expecting one key\")",
            "        self.assertEqual(\"3c:99:ed:a7:82:a8:71:09:2c:15:3d:78:4a:8c:11:99\", keys[0].fingerprint)",
            "",
            "    def test_add_authorizedkey_duplicate(self):",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        # Add the key to the user",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "        # Add the same key",
            "        with self.assertRaises(DuplicateSSHKeyError):",
            "            userobj.add_authorizedkey(key)",
            "            userobj.commit()",
            "",
            "    def test_add_authorizedkey_with_file(self):",
            "        \"\"\"",
            "        Add an ssh key for a user with an authorizedkey file.",
            "        \"\"\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "",
            "        # Create empty authorized_keys file",
            "        os.mkdir(os.path.join(userobj.user_root, '.ssh'))",
            "        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')",
            "        open(filename, 'a').close()",
            "",
            "        # Read the pub key",
            "        key = self._read_ssh_key()",
            "        userobj.add_authorizedkey(key)",
            "        userobj.commit()",
            "",
            "        # Validate",
            "        with open(filename, 'r') as fh:",
            "            self.assertEqual(key, fh.read())",
            "",
            "    def test_delete_authorizedkey_without_file(self):",
            "        \"\"\"",
            "        Remove an ssh key for a user without authorizedkey file.",
            "        \"\"\"",
            "        # Update user with ssh keys.",
            "        data = self._read_authorized_keys()",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        for k in authorizedkeys.read(StringIO(data)):",
            "            try:",
            "                userobj.add_authorizedkey(k.getvalue())",
            "            except ValueError:",
            "                # Some ssh key in the testing file are not valid.",
            "                pass",
            "",
            "        # Get the keys",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(2, len(keys))",
            "",
            "        # Remove a key",
            "        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")",
            "        userobj.commit()",
            "",
            "        # Validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(1, len(keys))",
            "",
            "    def test_delete_authorizedkey_with_file(self):",
            "        \"\"\"",
            "        Remove an ssh key for a user with authorizedkey file.",
            "        \"\"\"",
            "        # Create authorized_keys file",
            "        data = self._read_authorized_keys()",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        os.mkdir(os.path.join(userobj.user_root, '.ssh'))",
            "        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')",
            "        with open(filename, 'w') as f:",
            "            f.write(data)",
            "",
            "        # Get the keys",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(5, len(keys))",
            "",
            "        # Remove a key",
            "        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")",
            "",
            "        # Validate",
            "        keys = list(userobj.authorizedkeys)",
            "        self.assertEqual(4, len(keys))",
            "",
            "    def test_repo_objs(self):",
            "        # Given a user with a list of repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        repos = sorted(userobj.repo_objs, key=lambda r: r.name)",
            "        self.assertEqual(['broker-repo', 'testcases'], [r.name for r in repos])",
            "        # When deleting a repository empty list",
            "        repos[1].delete()",
            "        repos[1].commit()",
            "        # Then the repository is removed from the list.",
            "        self.assertEqual(['broker-repo'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_without_delete(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        RepoObject.query.delete()",
            "        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()",
            "        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos()",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_with_delete(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        RepoObject.query.delete()",
            "        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()",
            "        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos(delete=True)",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        userobj.expire()",
            "        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_with_single_repo(self):",
            "        # Given a user with invalid repositories",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        userobj.user_root = os.path.join(self.testcases, 'testcases')",
            "        # When updating the repository list without deletion",
            "        userobj.refresh_repos(delete=True)",
            "        userobj.commit()",
            "        # Then the list invlaid the invalid repo and new repos",
            "        userobj.expire()",
            "        self.assertEqual([''], sorted([r.name for r in userobj.repo_objs]))",
            "",
            "    def test_refresh_repos_with_empty_userroot(self):",
            "        # Given a user with valid repositories relative to root",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        for repo in userobj.repo_objs:",
            "            repo.repopath = self.testcases[1:] + '/' + repo.repopath",
            "            repo.add().commit()",
            "        userobj.user_root = '/'",
            "        userobj.add().commit()",
            "        self.assertEqual(['interrupted', 'ok'], sorted([r.status[0] for r in userobj.repo_objs]))",
            "        # When updating it's userroot directory to an empty value",
            "        userobj.user_root = ''",
            "        userobj.add().commit()",
            "        UserObject.session.expire_all()",
            "        # Then close session",
            "        cherrypy.tools.db.on_end_resource()",
            "        # Then repo status is \"broken\"",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        self.assertFalse(userobj.valid_user_root())",
            "        self.assertEqual(['failed', 'failed'], [r.status[0] for r in userobj.repo_objs])",
            "",
            "",
            "class UserObjectWithAdminPassword(rdiffweb.test.WebCase):",
            "",
            "    # password: test",
            "    default_config = {'admin-password': '{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e'}",
            "",
            "    def setUp(self):",
            "        # Do nothing - We need to skip the default setup to avoid deleting the records.",
            "        pass",
            "",
            "    def test_create_admin_user(self):",
            "        # Given admin-password is configure",
            "        # When database get created",
            "        # Then admin user get created with 'test' password",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        self.assertIsNotNone(userobj)",
            "        self.assertEqual('{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e', userobj.hash_password)",
            "        self.assertTrue(check_password('test', userobj.hash_password))",
            "",
            "        # Given admin-password is configure",
            "        # When trying to update admin password",
            "        # Then an exception is raised",
            "        userobj = UserObject.get_user(self.USERNAME)",
            "        with self.assertRaises(ValueError):",
            "            userobj.set_password('newpassword')"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "litellm.utils.exception_type"
        ]
    },
    "rdiffweb/core/rdw_templating.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "     for chunk in args:"
            },
            "1": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "         if not chunk:"
            },
            "2": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "             continue"
            },
            "3": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if hasattr(chunk, 'owner') and hasattr(chunk, 'path'):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+        if hasattr(chunk, 'owner') and hasattr(chunk, 'repopath'):"
            },
            "5": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "             # This is a RepoObject"
            },
            "6": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "             path += \"/\""
            },
            "7": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "             path += chunk.owner"
            },
            "8": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "             path += \"/\""
            },
            "9": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+            path += rdw_helpers.quote_url(chunk.repopath.strip(\"/\"))"
            },
            "11": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "         elif hasattr(chunk, 'path'):"
            },
            "12": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "             # This is a DirEntry"
            },
            "13": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "             if chunk.path:"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import datetime",
            "import logging",
            "import os",
            "from collections import OrderedDict, namedtuple",
            "from io import StringIO",
            "",
            "import cherrypy",
            "import humanfriendly",
            "import jinja2",
            "from jinja2 import Environment, PackageLoader",
            "from jinja2.filters import do_mark_safe",
            "from jinja2.loaders import ChoiceLoader",
            "",
            "from rdiffweb.core import librdiff, rdw_helpers",
            "from rdiffweb.core.model import RepoObject",
            "from rdiffweb.tools import i18n",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "# Define the logger",
            "logger = logging.getLogger(__name__)",
            "",
            "_ParentEntry = namedtuple(\"_ParentEntry\", 'path,display_name')",
            "",
            "",
            "def attrib(**kwargs):",
            "    \"\"\"Generate an attribute list from the keyword argument.\"\"\"",
            "",
            "    def _escape(text):",
            "        if isinstance(text, bytes):",
            "            text = text.decode('ascii', 'replace')",
            "        text = str(text)",
            "        if \"&\" in text:",
            "            text = text.replace(\"&\", \"&amp;\")",
            "        if \"<\" in text:",
            "            text = text.replace(\"<\", \"&lt;\")",
            "        if \">\" in text:",
            "            text = text.replace(\">\", \"&gt;\")",
            "        if \"\\\"\" in text:",
            "            text = text.replace(\"\\\"\", \"&quot;\")",
            "        return text",
            "",
            "    def _format(key, val):",
            "        # Don't write the attribute if value is False",
            "        if val is False:",
            "            return",
            "        if val is True:",
            "            yield str(key)",
            "            return",
            "        if isinstance(val, list):",
            "            val = ' '.join([_escape(v) for v in val if v])",
            "        else:",
            "            val = _escape(val)",
            "        if not val:",
            "            return",
            "        yield '%s=\"%s\"' % (str(key), val)",
            "",
            "    first = True",
            "    buf = StringIO()",
            "    for key, val in sorted(kwargs.items()):",
            "        for t in _format(key, val):",
            "            if not first:",
            "                buf.write(' ')",
            "            first = False",
            "            buf.write(t)",
            "    data = buf.getvalue()",
            "    buf.close()",
            "    return do_mark_safe(data)",
            "",
            "",
            "def do_filter(sequence, attribute_name):",
            "    \"\"\"Filter sequence of objects.\"\"\"",
            "    return [",
            "        x",
            "        for x in sequence",
            "        if (isinstance(x, dict) and attribute_name in x and x[attribute_name])",
            "        or (hasattr(x, attribute_name) and getattr(x, attribute_name))",
            "    ]",
            "",
            "",
            "def do_format_lastupdated(value, now=None):",
            "    \"\"\"",
            "    Used to format date as \"Updated 10 minutes ago\".",
            "",
            "    Value could be a RdiffTime or an epoch as int.",
            "    \"\"\"",
            "    if not value:",
            "        return \"\"",
            "    now = librdiff.RdiffTime(now)",
            "    if isinstance(value, librdiff.RdiffTime):",
            "        delta = now.epoch() - value.epoch()",
            "    elif isinstance(value, datetime.datetime):",
            "        delta = now.epoch() - value.timestamp()",
            "    else:",
            "        delta = now.epoch() - value",
            "    delta = datetime.timedelta(seconds=delta)",
            "    if delta.days > 365:",
            "        return _('%d years ago') % (delta.days / 365)",
            "    if delta.days > 60:",
            "        return _('%d months ago') % (delta.days / 30)",
            "    if delta.days > 7:",
            "        return _('%d weeks ago') % (delta.days / 7)",
            "    elif delta.days > 1:",
            "        return _('%d days ago') % delta.days",
            "    elif delta.seconds > 3600:",
            "        return _('%d hours ago') % (delta.seconds / 3600)",
            "    elif delta.seconds > 60:",
            "        return _('%d minutes ago') % (delta.seconds / 60)",
            "    return _('%d seconds ago') % delta.seconds",
            "",
            "",
            "def create_repo_tree(repos):",
            "    \"\"\"",
            "    Organise the repositories into a tree.",
            "    \"\"\"",
            "    repos = sorted(repos, key=lambda r: r.display_name)",
            "    repo_tree = OrderedDict()",
            "    for repo in repos:",
            "        h = repo_tree",
            "        key = repo.display_name.strip('/').split('/')",
            "        for p in key[:-1]:",
            "            if p in h and isinstance(h[p], RepoObject):",
            "                h[p] = {'.': h[p]}",
            "            h = h.setdefault(p, {})",
            "        h[key[-1]] = repo",
            "    return repo_tree",
            "",
            "",
            "def list_parents(repo, path):",
            "    assert isinstance(path, bytes)",
            "    # Build the parameters",
            "    # Build \"parent directories\" links",
            "    parents = [_ParentEntry(b'', repo.display_name)]",
            "    parent_path_b = b''",
            "    for part_b in path.split(b'/'):",
            "        if part_b:",
            "            parent_path_b = os.path.join(parent_path_b, part_b)",
            "            display_name = repo._decode(librdiff.unquote(part_b))",
            "            parents.append(_ParentEntry(parent_path_b, display_name))",
            "    return parents",
            "",
            "",
            "def url_for(*args, **kwargs):",
            "    \"\"\"",
            "    Generate a url for the given endpoint, path (*args) with parameters (**kwargs)",
            "",
            "    This could be used to generate a path with userobject and repo object",
            "",
            "    \"\"\"",
            "    path = \"\"",
            "    for chunk in args:",
            "        if not chunk:",
            "            continue",
            "        if hasattr(chunk, 'owner') and hasattr(chunk, 'path'):",
            "            # This is a RepoObject",
            "            path += \"/\"",
            "            path += chunk.owner",
            "            path += \"/\"",
            "            path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))",
            "        elif hasattr(chunk, 'path'):",
            "            # This is a DirEntry",
            "            if chunk.path:",
            "                path += \"/\"",
            "                path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))",
            "        elif chunk and isinstance(chunk, bytes):",
            "            path += \"/\"",
            "            path += rdw_helpers.quote_url(chunk.strip(b\"/\"))",
            "        elif chunk and isinstance(chunk, str):",
            "            path += \"/\"",
            "            path += chunk.strip(\"/\")",
            "        else:",
            "            raise ValueError('invalid positional arguments, url_for accept str, bytes or RepoPath: %r' % chunk)",
            "    # Sort the arguments to have predictable results.",
            "    qs = [(k, v.epoch() if hasattr(v, 'epoch') else v) for k, v in sorted(kwargs.items()) if v is not None]",
            "    return cherrypy.url(path=path, qs=qs)",
            "",
            "",
            "class TemplateManager(object):",
            "    \"\"\"",
            "    Uses to generate HTML page from template using Jinja2 templating.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        # Load all the templates from /templates directory",
            "        loader = ChoiceLoader([PackageLoader('rdiffweb', 'templates')])",
            "",
            "        # With and autoescape are included by dfault in Jinja2>=3",
            "        extensions = ['jinja2.ext.i18n']",
            "        if jinja2.__version__[0] <= '2':",
            "            extensions.extend(['jinja2.ext.with_', 'jinja2.ext.autoescape'])",
            "        self.jinja_env = Environment(",
            "            loader=loader,",
            "            auto_reload=True,",
            "            autoescape=True,",
            "            extensions=extensions,",
            "        )",
            "",
            "        # Register filters",
            "        self.jinja_env.filters['filter'] = do_filter",
            "        self.jinja_env.filters['lastupdated'] = do_format_lastupdated",
            "        self.jinja_env.filters['filesize'] = lambda x: humanfriendly.format_size(x, binary=True)",
            "",
            "        # Register method",
            "        self.jinja_env.globals['attrib'] = attrib",
            "        self.jinja_env.globals['create_repo_tree'] = create_repo_tree",
            "        self.jinja_env.globals['list_parents'] = list_parents",
            "        self.jinja_env.globals['url_for'] = url_for",
            "",
            "    def compile_template(self, template_name, **kwargs):",
            "        \"\"\"Very simple implementation to render template using jinja2.",
            "        `templateName`",
            "            The filename to be used as template.",
            "        `kwargs`",
            "            The arguments to be passed to the template.",
            "        \"\"\"",
            "        logger.log(1, \"compiling template [%s]\", template_name)",
            "        self.jinja_env.install_gettext_callables(i18n.ugettext, i18n.ungettext, newstyle=True)",
            "        template = self.jinja_env.get_template(template_name)",
            "        data = template.render(kwargs)",
            "        logger.log(1, \"template [%s] compiled\", template_name)",
            "        return data"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "import datetime",
            "import logging",
            "import os",
            "from collections import OrderedDict, namedtuple",
            "from io import StringIO",
            "",
            "import cherrypy",
            "import humanfriendly",
            "import jinja2",
            "from jinja2 import Environment, PackageLoader",
            "from jinja2.filters import do_mark_safe",
            "from jinja2.loaders import ChoiceLoader",
            "",
            "from rdiffweb.core import librdiff, rdw_helpers",
            "from rdiffweb.core.model import RepoObject",
            "from rdiffweb.tools import i18n",
            "from rdiffweb.tools.i18n import ugettext as _",
            "",
            "# Define the logger",
            "logger = logging.getLogger(__name__)",
            "",
            "_ParentEntry = namedtuple(\"_ParentEntry\", 'path,display_name')",
            "",
            "",
            "def attrib(**kwargs):",
            "    \"\"\"Generate an attribute list from the keyword argument.\"\"\"",
            "",
            "    def _escape(text):",
            "        if isinstance(text, bytes):",
            "            text = text.decode('ascii', 'replace')",
            "        text = str(text)",
            "        if \"&\" in text:",
            "            text = text.replace(\"&\", \"&amp;\")",
            "        if \"<\" in text:",
            "            text = text.replace(\"<\", \"&lt;\")",
            "        if \">\" in text:",
            "            text = text.replace(\">\", \"&gt;\")",
            "        if \"\\\"\" in text:",
            "            text = text.replace(\"\\\"\", \"&quot;\")",
            "        return text",
            "",
            "    def _format(key, val):",
            "        # Don't write the attribute if value is False",
            "        if val is False:",
            "            return",
            "        if val is True:",
            "            yield str(key)",
            "            return",
            "        if isinstance(val, list):",
            "            val = ' '.join([_escape(v) for v in val if v])",
            "        else:",
            "            val = _escape(val)",
            "        if not val:",
            "            return",
            "        yield '%s=\"%s\"' % (str(key), val)",
            "",
            "    first = True",
            "    buf = StringIO()",
            "    for key, val in sorted(kwargs.items()):",
            "        for t in _format(key, val):",
            "            if not first:",
            "                buf.write(' ')",
            "            first = False",
            "            buf.write(t)",
            "    data = buf.getvalue()",
            "    buf.close()",
            "    return do_mark_safe(data)",
            "",
            "",
            "def do_filter(sequence, attribute_name):",
            "    \"\"\"Filter sequence of objects.\"\"\"",
            "    return [",
            "        x",
            "        for x in sequence",
            "        if (isinstance(x, dict) and attribute_name in x and x[attribute_name])",
            "        or (hasattr(x, attribute_name) and getattr(x, attribute_name))",
            "    ]",
            "",
            "",
            "def do_format_lastupdated(value, now=None):",
            "    \"\"\"",
            "    Used to format date as \"Updated 10 minutes ago\".",
            "",
            "    Value could be a RdiffTime or an epoch as int.",
            "    \"\"\"",
            "    if not value:",
            "        return \"\"",
            "    now = librdiff.RdiffTime(now)",
            "    if isinstance(value, librdiff.RdiffTime):",
            "        delta = now.epoch() - value.epoch()",
            "    elif isinstance(value, datetime.datetime):",
            "        delta = now.epoch() - value.timestamp()",
            "    else:",
            "        delta = now.epoch() - value",
            "    delta = datetime.timedelta(seconds=delta)",
            "    if delta.days > 365:",
            "        return _('%d years ago') % (delta.days / 365)",
            "    if delta.days > 60:",
            "        return _('%d months ago') % (delta.days / 30)",
            "    if delta.days > 7:",
            "        return _('%d weeks ago') % (delta.days / 7)",
            "    elif delta.days > 1:",
            "        return _('%d days ago') % delta.days",
            "    elif delta.seconds > 3600:",
            "        return _('%d hours ago') % (delta.seconds / 3600)",
            "    elif delta.seconds > 60:",
            "        return _('%d minutes ago') % (delta.seconds / 60)",
            "    return _('%d seconds ago') % delta.seconds",
            "",
            "",
            "def create_repo_tree(repos):",
            "    \"\"\"",
            "    Organise the repositories into a tree.",
            "    \"\"\"",
            "    repos = sorted(repos, key=lambda r: r.display_name)",
            "    repo_tree = OrderedDict()",
            "    for repo in repos:",
            "        h = repo_tree",
            "        key = repo.display_name.strip('/').split('/')",
            "        for p in key[:-1]:",
            "            if p in h and isinstance(h[p], RepoObject):",
            "                h[p] = {'.': h[p]}",
            "            h = h.setdefault(p, {})",
            "        h[key[-1]] = repo",
            "    return repo_tree",
            "",
            "",
            "def list_parents(repo, path):",
            "    assert isinstance(path, bytes)",
            "    # Build the parameters",
            "    # Build \"parent directories\" links",
            "    parents = [_ParentEntry(b'', repo.display_name)]",
            "    parent_path_b = b''",
            "    for part_b in path.split(b'/'):",
            "        if part_b:",
            "            parent_path_b = os.path.join(parent_path_b, part_b)",
            "            display_name = repo._decode(librdiff.unquote(part_b))",
            "            parents.append(_ParentEntry(parent_path_b, display_name))",
            "    return parents",
            "",
            "",
            "def url_for(*args, **kwargs):",
            "    \"\"\"",
            "    Generate a url for the given endpoint, path (*args) with parameters (**kwargs)",
            "",
            "    This could be used to generate a path with userobject and repo object",
            "",
            "    \"\"\"",
            "    path = \"\"",
            "    for chunk in args:",
            "        if not chunk:",
            "            continue",
            "        if hasattr(chunk, 'owner') and hasattr(chunk, 'repopath'):",
            "            # This is a RepoObject",
            "            path += \"/\"",
            "            path += chunk.owner",
            "            path += \"/\"",
            "            path += rdw_helpers.quote_url(chunk.repopath.strip(\"/\"))",
            "        elif hasattr(chunk, 'path'):",
            "            # This is a DirEntry",
            "            if chunk.path:",
            "                path += \"/\"",
            "                path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))",
            "        elif chunk and isinstance(chunk, bytes):",
            "            path += \"/\"",
            "            path += rdw_helpers.quote_url(chunk.strip(b\"/\"))",
            "        elif chunk and isinstance(chunk, str):",
            "            path += \"/\"",
            "            path += chunk.strip(\"/\")",
            "        else:",
            "            raise ValueError('invalid positional arguments, url_for accept str, bytes or RepoPath: %r' % chunk)",
            "    # Sort the arguments to have predictable results.",
            "    qs = [(k, v.epoch() if hasattr(v, 'epoch') else v) for k, v in sorted(kwargs.items()) if v is not None]",
            "    return cherrypy.url(path=path, qs=qs)",
            "",
            "",
            "class TemplateManager(object):",
            "    \"\"\"",
            "    Uses to generate HTML page from template using Jinja2 templating.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        # Load all the templates from /templates directory",
            "        loader = ChoiceLoader([PackageLoader('rdiffweb', 'templates')])",
            "",
            "        # With and autoescape are included by dfault in Jinja2>=3",
            "        extensions = ['jinja2.ext.i18n']",
            "        if jinja2.__version__[0] <= '2':",
            "            extensions.extend(['jinja2.ext.with_', 'jinja2.ext.autoescape'])",
            "        self.jinja_env = Environment(",
            "            loader=loader,",
            "            auto_reload=True,",
            "            autoescape=True,",
            "            extensions=extensions,",
            "        )",
            "",
            "        # Register filters",
            "        self.jinja_env.filters['filter'] = do_filter",
            "        self.jinja_env.filters['lastupdated'] = do_format_lastupdated",
            "        self.jinja_env.filters['filesize'] = lambda x: humanfriendly.format_size(x, binary=True)",
            "",
            "        # Register method",
            "        self.jinja_env.globals['attrib'] = attrib",
            "        self.jinja_env.globals['create_repo_tree'] = create_repo_tree",
            "        self.jinja_env.globals['list_parents'] = list_parents",
            "        self.jinja_env.globals['url_for'] = url_for",
            "",
            "    def compile_template(self, template_name, **kwargs):",
            "        \"\"\"Very simple implementation to render template using jinja2.",
            "        `templateName`",
            "            The filename to be used as template.",
            "        `kwargs`",
            "            The arguments to be passed to the template.",
            "        \"\"\"",
            "        logger.log(1, \"compiling template [%s]\", template_name)",
            "        self.jinja_env.install_gettext_callables(i18n.ugettext, i18n.ungettext, newstyle=True)",
            "        template = self.jinja_env.get_template(template_name)",
            "        data = template.render(kwargs)",
            "        logger.log(1, \"template [%s] compiled\", template_name)",
            "        return data"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "170": [
                "url_for"
            ],
            "175": [
                "url_for"
            ]
        },
        "addLocation": []
    },
    "rdiffweb/core/tests/test_librdiff.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 52,
                "PatchRowcode": " class MockRdiffRepo(RdiffRepo):"
            },
            "1": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     def __init__(self):"
            },
            "2": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "         p = bytes(pkg_resources.resource_filename('rdiffweb.core', 'tests'), encoding='utf-8')  # @UndefinedVariable"
            },
            "3": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        RdiffRepo.__init__(self, os.path.dirname(p), os.path.basename(p), encoding='utf-8')"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+        RdiffRepo.__init__(self, p, encoding='utf-8')"
            },
            "5": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "         self.root_path = MockDirEntry(self)"
            },
            "6": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": 221,
                "PatchRowcode": "         # Define location of testcases"
            },
            "9": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": 222,
                "PatchRowcode": "         self.testcases_dir = os.path.normpath(os.path.join(self.temp_dir, 'testcases'))"
            },
            "10": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": 223,
                "PatchRowcode": "         self.testcases_dir = self.testcases_dir.encode('utf8')"
            },
            "11": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 224,
                "PatchRowcode": "+        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')"
            },
            "13": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 225,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 226,
                "PatchRowcode": "     def tearDown(self):"
            },
            "15": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 227,
                "PatchRowcode": "         shutil.rmtree(self.temp_dir.encode('utf8'), True)"
            },
            "16": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 230,
                "PatchRowcode": "         self.assertEqual('testcases', self.repo.display_name)"
            },
            "17": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 231,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "     def test_init_with_absolute(self):"
            },
            "19": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.repo = RdiffRepo(self.temp_dir, '/testcases', encoding='utf-8')"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+        self.repo = RdiffRepo(os.path.join(self.temp_dir, '/testcases'), encoding='utf-8')"
            },
            "21": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "         self.assertEqual('testcases', self.repo.display_name)"
            },
            "22": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 235,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "     def test_init_with_invalid(self):"
            },
            "24": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.repo = RdiffRepo(self.temp_dir, 'invalid', encoding='utf-8')"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'invalid'), encoding='utf-8')"
            },
            "26": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         self.assertEqual('failed', self.repo.status[0])"
            },
            "27": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 239,
                "PatchRowcode": "         self.assertEqual(None, self.repo.last_backup_date)"
            },
            "28": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.assertEqual(b'invalid', self.repo.path)"
            },
            "29": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         self.assertEqual('invalid', self.repo.display_name)"
            },
            "30": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 241,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "     @parameterized.expand("
            },
            "32": {
                "beforePatchRowNumber": 534,
                "afterPatchRowNumber": 533,
                "PatchRowcode": "             0000,"
            },
            "33": {
                "beforePatchRowNumber": 535,
                "afterPatchRowNumber": 534,
                "PatchRowcode": "         )"
            },
            "34": {
                "beforePatchRowNumber": 536,
                "afterPatchRowNumber": 535,
                "PatchRowcode": "         # Create repo again to query status"
            },
            "35": {
                "beforePatchRowNumber": 537,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 536,
                "PatchRowcode": "+        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')"
            },
            "37": {
                "beforePatchRowNumber": 538,
                "afterPatchRowNumber": 537,
                "PatchRowcode": "         status = self.repo.status"
            },
            "38": {
                "beforePatchRowNumber": 539,
                "afterPatchRowNumber": 538,
                "PatchRowcode": "         self.assertEqual('failed', status[0])"
            },
            "39": {
                "beforePatchRowNumber": 540,
                "afterPatchRowNumber": 539,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 545,
                "afterPatchRowNumber": 544,
                "PatchRowcode": "         # Change the permissions of the files."
            },
            "41": {
                "beforePatchRowNumber": 546,
                "afterPatchRowNumber": 545,
                "PatchRowcode": "         os.chmod(os.path.join(self.testcases_dir, b'rdiff-backup-data'), 0000)"
            },
            "42": {
                "beforePatchRowNumber": 547,
                "afterPatchRowNumber": 546,
                "PatchRowcode": "         # Query status."
            },
            "43": {
                "beforePatchRowNumber": 548,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 547,
                "PatchRowcode": "+        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')"
            },
            "45": {
                "beforePatchRowNumber": 549,
                "afterPatchRowNumber": 548,
                "PatchRowcode": "         status = self.repo.status"
            },
            "46": {
                "beforePatchRowNumber": 550,
                "afterPatchRowNumber": 549,
                "PatchRowcode": "         self.assertEqual('failed', status[0])"
            },
            "47": {
                "beforePatchRowNumber": 551,
                "afterPatchRowNumber": 550,
                "PatchRowcode": "         # Make sure history entry doesn't raise error"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "\"\"\"",
            "Created on Oct 3, 2015",
            "",
            "Module used to test the librdiff.",
            "",
            "@author: Patrik Dufresne",
            "\"\"\"",
            "import datetime",
            "import os",
            "import shutil",
            "import tarfile",
            "import tempfile",
            "import time",
            "import unittest",
            "from inspect import isclass",
            "from unittest.case import skipIf",
            "",
            "import pkg_resources",
            "from parameterized import parameterized",
            "",
            "from rdiffweb.core.librdiff import (",
            "    AccessDeniedError,",
            "    DoesNotExistError,",
            "    FileStatisticsEntry,",
            "    IncrementEntry,",
            "    RdiffDirEntry,",
            "    RdiffRepo,",
            "    RdiffTime,",
            "    SessionStatisticsEntry,",
            "    rdiff_backup_version,",
            "    unquote,",
            ")",
            "",
            "",
            "class MockRdiffRepo(RdiffRepo):",
            "    def __init__(self):",
            "        p = bytes(pkg_resources.resource_filename('rdiffweb.core', 'tests'), encoding='utf-8')  # @UndefinedVariable",
            "        RdiffRepo.__init__(self, os.path.dirname(p), os.path.basename(p), encoding='utf-8')",
            "        self.root_path = MockDirEntry(self)",
            "",
            "",
            "class MockDirEntry(RdiffDirEntry):",
            "    def __init__(self, repo):",
            "        self._repo = repo",
            "        self.path = b''",
            "",
            "",
            "class IncrementEntryTest(unittest.TestCase):",
            "    def test_init(self):",
            "        increment = IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')",
            "        self.assertEqual(b'my_filename.txt', increment.name)",
            "        self.assertEqual(RdiffTime(1414967021), increment.date)",
            "        self.assertEqual(b'.diff.gz', increment.suffix)",
            "",
            "    def test_extract_date(self):",
            "        self.assertEqual(",
            "            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')",
            "        )",
            "        self.assertEqual(",
            "            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17-23-41-05-00.diff.gz')",
            "        )",
            "        # Check if date with quoted characther are proerply parsed.",
            "        # On NTFS, colon (:) are not supported.",
            "        self.assertEqual(",
            "            RdiffTime(1483443123),",
            "            IncrementEntry._extract_date(b'my_filename.txt.2017-01-03T06;05832;05803-05;05800.diff.gz'),",
            "        )",
            "",
            "",
            "class RdiffDirEntryTest(unittest.TestCase):",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "",
            "    def test_init(self):",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, [])",
            "        self.assertFalse(entry.isdir)",
            "        self.assertFalse(entry.exists)",
            "        self.assertEqual(os.path.join(b'my_filename.txt'), entry.path)",
            "        self.assertEqual(os.path.join(self.repo.full_path, b'my_filename.txt'), entry.full_path)",
            "",
            "    def test_change_dates(self):",
            "        \"\"\"Check if dates are properly sorted.\"\"\"",
            "        increments = [",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),",
            "        ]",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, increments)",
            "",
            "        self.assertEqual(",
            "            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates",
            "        )",
            "",
            "    def test_change_dates_with_exists(self):",
            "        \"\"\"Check if dates are properly sorted.\"\"\"",
            "        increments = [",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),",
            "        ]",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', True, increments)",
            "",
            "        self.assertEqual(",
            "            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates",
            "        )",
            "",
            "    def test_display_name(self):",
            "        \"\"\"Check if display name is unquoted and unicode.\"\"\"",
            "        entry = RdiffDirEntry(self.repo, b'my_dir', True, [])",
            "        self.assertEqual('my_dir', entry.display_name)",
            "",
            "        entry = RdiffDirEntry(self.repo, b'my;090dir', True, [])",
            "        self.assertEqual('myZdir', entry.display_name)",
            "",
            "    def test_file_size(self):",
            "        # Given a dir increment",
            "        increments = [",
            "            IncrementEntry(",
            "                bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial.2014-11-05T16:05:07-05:00.dir', encoding='utf-8'),",
            "            )",
            "        ]",
            "        entry = RdiffDirEntry(",
            "            self.repo, bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'), False, increments",
            "        )",
            "        # When getting the file_size",
            "        # Then the size is 0",
            "        self.assertEqual(-1, entry.file_size)",
            "",
            "    def test_file_size_without_stats(self):",
            "        increments = [IncrementEntry(b'my_file.2014-11-05T16:04:30-05:00.dir')]",
            "        entry = RdiffDirEntry(self.repo, b'my_file', False, increments)",
            "        self.assertEqual(-1, entry.file_size)",
            "",
            "",
            "class FileErrorTest(unittest.TestCase):",
            "    def test_init(self):",
            "        e = DoesNotExistError('some/path')",
            "        self.assertEqual('some/path', str(e))",
            "",
            "        e = AccessDeniedError('some/path')",
            "        self.assertEqual('some/path', str(e))",
            "",
            "",
            "class FileStatisticsEntryTest(unittest.TestCase):",
            "    \"\"\"",
            "    Test the file statistics entry.",
            "    \"\"\"",
            "",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "",
            "    def test_get_mirror_size(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')",
            "        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(143, size)",
            "",
            "    def test_get_source_size(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')",
            "        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(286, size)",
            "",
            "    def test_get_mirror_size_gzip(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')",
            "        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(143, size)",
            "",
            "    def test_get_source_size_gzip(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')",
            "        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(286, size)",
            "",
            "",
            "class LogEntryTest(unittest.TestCase):",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "        self.root_path = self.repo.root_path",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                'with_uncompress',",
            "                '2015-11-19T07:27:46-05:00',",
            "                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',",
            "            ),",
            "            (",
            "                'with_compress',",
            "                '2015-11-20T07:27:46-05:00',",
            "                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',",
            "            ),",
            "        ]",
            "    )",
            "    def test_errors_tail(self, unused, date, expected_content):",
            "        entry = self.repo.error_log[RdiffTime(date)]",
            "        self.assertIsNotNone(entry)",
            "        self.assertEqual(entry.tail(), expected_content)",
            "",
            "",
            "class RdiffRepoTest(unittest.TestCase):",
            "    def setUp(self):",
            "        # Extract 'testcases.tar.gz'",
            "        testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable",
            "        self.temp_dir = tempfile.mkdtemp(prefix='rdiffweb_tests_')",
            "        tarfile.open(testcases).extractall(self.temp_dir)",
            "        # Define location of testcases",
            "        self.testcases_dir = os.path.normpath(os.path.join(self.temp_dir, 'testcases'))",
            "        self.testcases_dir = self.testcases_dir.encode('utf8')",
            "        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')",
            "",
            "    def tearDown(self):",
            "        shutil.rmtree(self.temp_dir.encode('utf8'), True)",
            "",
            "    def test_init(self):",
            "        self.assertEqual('testcases', self.repo.display_name)",
            "",
            "    def test_init_with_absolute(self):",
            "        self.repo = RdiffRepo(self.temp_dir, '/testcases', encoding='utf-8')",
            "        self.assertEqual('testcases', self.repo.display_name)",
            "",
            "    def test_init_with_invalid(self):",
            "        self.repo = RdiffRepo(self.temp_dir, 'invalid', encoding='utf-8')",
            "        self.assertEqual('failed', self.repo.status[0])",
            "        self.assertEqual(None, self.repo.last_backup_date)",
            "        self.assertEqual(b'invalid', self.repo.path)",
            "        self.assertEqual('invalid', self.repo.display_name)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_root\",",
            "                b\"/\",",
            "                'testcases',",
            "                b'',",
            "                True,",
            "                True,",
            "                True,",
            "                -1,",
            "                [",
            "                    '2014-11-01T15:49:47-04:00',",
            "                    '2014-11-01T15:50:26-04:00',",
            "                    '2014-11-01T15:50:48-04:00',",
            "                    '2014-11-01T15:51:15-04:00',",
            "                    '2014-11-01T15:51:29-04:00',",
            "                    '2014-11-01T16:30:22-04:00',",
            "                    '2014-11-01T16:30:50-04:00',",
            "                    '2014-11-01T18:07:19-04:00',",
            "                    '2014-11-01T20:12:45-04:00',",
            "                    '2014-11-01T20:18:11-04:00',",
            "                    '2014-11-01T20:51:18-04:00',",
            "                    '2014-11-02T09:16:43-05:00',",
            "                    '2014-11-02T09:50:53-05:00',",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:01:02-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-01-20T10:42:21-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_dir\",",
            "                b\"Subdirectory\",",
            "                'Subdirectory',",
            "                b'Subdirectory',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                [",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2016-01-20T10:42:21-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_dir_utf8_char\",",
            "                b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\",",
            "                'Fold\u00e8r with \u00e9ncod\u00efng',",
            "                b'Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:04:55-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_dir\",",
            "                b\"Revisions\",",
            "                'Revisions',",
            "                b'Revisions',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                [",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_file\",",
            "                b'Revisions/Data',",
            "                'Data',",
            "                b'Revisions/Data',",
            "                True,",
            "                False,",
            "                False,",
            "                9,",
            "                [",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_broken_symlink\",",
            "                b'BrokenSymlink',",
            "                'BrokenSymlink',",
            "                b'BrokenSymlink',",
            "                True,",
            "                False,",
            "                False,",
            "                7,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;090 to quote',",
            "                'Char Z to quote',",
            "                b'Char ;090 to quote',",
            "                False,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-01T18:07:19-04:00', '2014-11-01T20:18:11-04:00', '2014-11-03T19:04:57-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;059090 to quote',",
            "                'Char ;090 to quote',",
            "                b'Char ;059090 to quote',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-03T15:46:47-05:00', '2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;059059090 to quote',",
            "                'Char ;059090 to quote',",
            "                b'Char ;059059090 to quote',",
            "                False,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:04:55-05:00', '2016-01-20T10:42:21-05:00'],",
            "            ),",
            "            (",
            "                \"with_loop_symlink\",",
            "                b'Subdirectory/LoopSymlink',",
            "                'LoopSymlink',",
            "                b'Subdirectory/LoopSymlink',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_subdir_symlink\",",
            "                b'SymlinkToSubdirectory',",
            "                'SymlinkToSubdirectory',",
            "                b'SymlinkToSubdirectory',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "        ]",
            "    )",
            "    def test_fstat(self, unused, input, display_name, path, exists, isdir, isroot, file_size, change_dates):",
            "        dir_entry = self.repo.fstat(input)",
            "        self.assertEqual(display_name, dir_entry.display_name)",
            "        self.assertEqual(path, dir_entry.path)",
            "        self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)",
            "        self.assertEqual(exists, dir_entry.exists)",
            "        self.assertEqual(isdir, dir_entry.isdir)",
            "        self.assertEqual(isroot, dir_entry.isroot)",
            "        self.assertEqual(file_size, dir_entry.file_size)",
            "        self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))",
            "        # For consistency, check if the same value are retreived using listdir",
            "        if not isroot:",
            "            parent_dir = os.path.dirname(input)",
            "            children = self.repo.listdir(parent_dir)",
            "            dir_entry = next(c for c in children if c.path == input)",
            "            self.assertEqual(display_name, dir_entry.display_name)",
            "            self.assertEqual(path, dir_entry.path)",
            "            self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)",
            "            self.assertEqual(exists, dir_entry.exists)",
            "            self.assertEqual(isdir, dir_entry.isdir)",
            "            self.assertEqual(isroot, dir_entry.isroot)",
            "            self.assertEqual(file_size, dir_entry.file_size)",
            "            self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))",
            "",
            "    def test_fstat_outside_repo(self):",
            "        with self.assertRaises(AccessDeniedError):",
            "            self.repo.fstat(b\"../\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_root\",",
            "                b\"\",",
            "                [",
            "                    '<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',",
            "                    'BrokenSymlink',",
            "                    'Char ;059090 to quote',",
            "                    'Char ;090 to quote',",
            "                    'Char Z to quote',",
            "                    'DIR\ufffd',",
            "                    'Fichier @ <root>',",
            "                    'Fichier avec non asci char \ufffdvelyne M\ufffdre.txt',",
            "                    'Revisions',",
            "                    'R\u00e9pertoire (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',",
            "                    'R\u00e9pertoire Existant',",
            "                    'R\u00e9pertoire Supprim\u00e9',",
            "                    'Subdirectory',",
            "                    'SymlinkToSubdirectory',",
            "                    'test\\\\test',",
            "                    '\uc774\ub8e8\ub9c8 YIRUMA - River Flows in You.mp3',",
            "                ],",
            "            ),",
            "            (\"with_children utf8_char\", b\"Subdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\", ['my file']),",
            "            (\"with_dir\", b\"Revisions\", ['Data']),",
            "            (\"with_file\", b\"Revisions/Data\", DoesNotExistError),",
            "            (\"with_broken_symlink\", b\"BrokenSymlink\", DoesNotExistError),",
            "            (\"with_loop_symlink\", b\"Subdirectory/LoopSymlink\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "            (\"with_subdir_symlink\", b\"SymlinkToSubdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "        ]",
            "    )",
            "    def test_listdir(self, unused, path, listdir):",
            "        if isclass(listdir) and issubclass(listdir, Exception):",
            "            with self.assertRaises(listdir):",
            "                self.repo.listdir(path)",
            "            return",
            "        self.assertEqual(listdir, sorted([d.display_name for d in self.repo.listdir(path)]))",
            "",
            "    def test_listdir_outside_repo(self):",
            "        with self.assertRaises(AccessDeniedError):",
            "            self.repo.listdir(b\"../\")",
            "",
            "    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")",
            "    def test_listdir_empty_folder(self):",
            "        # Given a folder without data",
            "        self.repo.delete(b\"Revisions/Data\")",
            "        # When listing entries",
            "        entries = self.repo.listdir(b\"Revisions\")",
            "        # Then the list is empty.",
            "        self.assertEqual([], entries)",
            "",
            "    def test_listdir_attributes(self):",
            "        children = self.repo.listdir(b\"Revisions\")",
            "        self.assertEqual(1, len(children))",
            "        dir_entry = children[0]",
            "        self.assertEqual('Data', dir_entry.display_name)",
            "        self.assertEqual(b'Revisions/Data', dir_entry.path)",
            "        self.assertEqual(os.path.join(self.testcases_dir, b'Revisions/Data'), dir_entry.full_path)",
            "        self.assertEqual(True, dir_entry.exists)",
            "        self.assertEqual(False, dir_entry.isdir)",
            "        self.assertEqual(False, dir_entry.isroot)",
            "        self.assertEqual(9, dir_entry.file_size)",
            "        self.assertEqual(",
            "            [",
            "                RdiffTime('2014-11-03T19:04:57-05:00'),",
            "                RdiffTime('2014-11-05T16:04:30-05:00'),",
            "                RdiffTime('2014-11-05T16:04:55-05:00'),",
            "                RdiffTime('2014-11-05T16:05:07-05:00'),",
            "                RdiffTime('2016-02-02T16:30:40-05:00'),",
            "            ],",
            "            list(dir_entry.change_dates),",
            "        )",
            "",
            "    def test_with_rdiff_backup_data(self):",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(b'rdiff-backup-data')",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.listdir(b'rdiff-backup-data')",
            "",
            "    def test_with_invalid(self):",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(b'invalid')",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.listdir(b'invalid')",
            "",
            "    def test_status(self):",
            "        status = self.repo.status",
            "        self.assertEqual('ok', status[0])",
            "        self.assertEqual('', status[1])",
            "",
            "    def test_status_access_denied_current_mirror(self):",
            "        # Skip test if running as root. Because root as access to everything.",
            "        if os.geteuid() == 0:",
            "            return",
            "        # Change the permissions of the files.",
            "        os.chmod(",
            "            os.path.join(self.testcases_dir, b'rdiff-backup-data', b'current_mirror.2016-02-02T16:30:40-05:00.data'),",
            "            0000,",
            "        )",
            "        # Create repo again to query status",
            "        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')",
            "        status = self.repo.status",
            "        self.assertEqual('failed', status[0])",
            "",
            "    def test_status_access_denied_rdiff_backup_data(self):",
            "        # Skip test if running as root. Because root as access to everything.",
            "        if os.geteuid() == 0:",
            "            return",
            "        # Change the permissions of the files.",
            "        os.chmod(os.path.join(self.testcases_dir, b'rdiff-backup-data'), 0000)",
            "        # Query status.",
            "        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')",
            "        status = self.repo.status",
            "        self.assertEqual('failed', status[0])",
            "        # Make sure history entry doesn't raise error",
            "        list(self.repo.mirror_metadata)",
            "",
            "    def test_remove_older(self):",
            "        # Given a repository with history",
            "        self.assertEqual(22, len(self.repo.mirror_metadata))",
            "        # When removing older then 1D",
            "        self.repo.remove_older(1)",
            "        # Then all history get deleted up to one",
            "        self.assertEqual(1, len(self.repo.mirror_metadata))",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (\"with_root\", b'/', 1454448640, 'zip', 'testcases.zip', b'PK\\x03\\x04'),",
            "            (\"with_zip\", b'Revisions', 1454448640, 'zip', 'Revisions.zip', b'PK\\x03\\x04'),",
            "            (\"with_tar\", b'Revisions', 1454448640, 'tar', 'Revisions.tar', b'././@PaxHeader'),",
            "            (\"with_tar_gz\", b'Revisions', 1454448640, 'tar.gz', 'Revisions.tar.gz', b'\\x1f\\x8b'),",
            "            (\"with_tar_bz2\", b'Revisions', 1454448640, 'tar.bz2', 'Revisions.tar.bz2', b'BZh'),",
            "            (\"with_none_file\", b'Revisions/Data', 1454448640, None, 'Data', b'Version3\\n'),",
            "            (\"with_raw_file\", b'Revisions/Data', 1454448640, 'raw', 'Data', b'Version3\\n'),",
            "            (\"with_zip_file\", b'Revisions/Data', 1454448640, 'zip', 'Data.zip', b'PK\\x03\\x04'),",
            "        ]",
            "    )",
            "    def test_restore(self, unused, path, restore_as_of, kind, expected_filename, expected_startswith):",
            "        filename, stream = self.repo.restore(path, restore_as_of=restore_as_of, kind=kind)",
            "        self.assertEqual(expected_filename, filename)",
            "        data = stream.read()",
            "        self.assertTrue(data.startswith(expected_startswith))",
            "",
            "    def test_unquote(self):",
            "        self.assertEqual(b'Char ;090 to quote', unquote(b'Char ;059090 to quote'))",
            "",
            "    def test_error_log_range(self):",
            "        logs = self.repo.error_log[0:1]",
            "        self.assertEqual(1, len(logs))",
            "        self.assertEqual(\"\", self.repo.error_log[0].read())",
            "",
            "    def test_backup_log(self):",
            "        self.assertEqual(\"\", self.repo.backup_log.read())",
            "",
            "    def test_restore_log(self):",
            "        self.assertEqual(",
            "            self.repo.restore_log.read(),",
            "            \"\"\"Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpKDNO4t/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpnG33kc/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpGUEHJC/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBlFPsW/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpkfCejo/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmphXpFnS as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_udS97a/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_LL4rCm/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_zpYgT3/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_7H93yy/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_Xe2CfG/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_rHFERA/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpF7rSar/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpgHTL2j/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpVo1u4Z/root as it was as of Wed Jan 20 10:42:21 2016.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBRxRxe/root as it was as of Wed Jan 20 10:42:21 2016.",
            "\"\"\",",
            "        )",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_idx_1\",",
            "                1,",
            "                '2014-11-01T15:50:26-04:00',",
            "            ),",
            "            (",
            "                \"with_idx_2\",",
            "                2,",
            "                '2014-11-01T15:50:48-04:00',",
            "            ),",
            "            (",
            "                \"with_idx_3\",",
            "                3,",
            "                '2014-11-01T15:51:15-04:00',",
            "            ),",
            "            (",
            "                \"with_neg_idx_1\",",
            "                -1,",
            "                '2016-02-02T16:30:40-05:00',",
            "            ),",
            "            (",
            "                \"with_date\",",
            "                RdiffTime('2016-02-02T16:30:40-05:00'),",
            "                '2016-02-02T16:30:40-05:00',",
            "            ),",
            "            (",
            "                \"with_slice_idx\",",
            "                slice(0, 2),",
            "                [",
            "                    '2014-11-01T15:49:47-04:00',",
            "                    '2014-11-01T15:50:26-04:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_date_start\",",
            "                slice(RdiffTime('2016-01-20T10:42:21-05:00'), None),",
            "                ['2016-01-20T10:42:21-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_slice_date_start_stop\",",
            "                slice(",
            "                    RdiffTime('2014-11-02T17:00:00-05:00'),",
            "                    RdiffTime('2014-11-04T00:00:00-05:00'),",
            "                ),",
            "                [",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_date_start_stop_exact_match\",",
            "                slice(RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')),",
            "                [",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_invalid_idx\",",
            "                slice(100, 120),",
            "                [],",
            "            ),",
            "            (",
            "                \"with_keyerror_date\",",
            "                RdiffTime('2022-11-03T15:46:47-05:00'),",
            "                KeyError,",
            "            ),",
            "            (",
            "                \"with_keyerror_int\",",
            "                1024,",
            "                KeyError,",
            "            ),",
            "        ]",
            "    )",
            "    def test_session_statistics(self, unsed, value, expected_value):",
            "        if isinstance(expected_value, list):",
            "            self.assertEqual(expected_value, [str(o.date) for o in self.repo.session_statistics[value]])",
            "        elif isclass(expected_value) and issubclass(expected_value, Exception):",
            "            with self.assertRaises(expected_value):",
            "                self.repo.session_statistics[value]",
            "        else:",
            "            self.assertEqual(expected_value, str(self.repo.session_statistics[value].date))",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (\"with_file\", b'Revisions/Data'),",
            "            (\"with_folder\", b'Subdirectory'),",
            "            (\"with_folder_ending_slash\", b'Subdirectory/'),",
            "            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\"),",
            "            (\"with_broken_symlink\", b'BrokenSymlink'),",
            "        ]",
            "    )",
            "    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")",
            "    def test_delete_file(self, unused, path):",
            "        # Delete a file",
            "        self.repo.delete(path)",
            "        # Check file is deleted",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(path)",
            "",
            "",
            "class SessionStatisticsEntryTest(unittest.TestCase):",
            "    def test_getattr(self):",
            "        \"\"\"",
            "        Check how a session statistic is read.",
            "        \"\"\"",
            "        entry = SessionStatisticsEntry(MockRdiffRepo(), b'session_statistics.2014-11-02T09:16:43-05:00.data')",
            "        self.assertEqual(1414937803.00, entry.starttime)",
            "        self.assertEqual(1414937764.82, entry.endtime)",
            "        self.assertAlmostEqual(-38.18, entry.elapsedtime, delta=-0.01)",
            "        self.assertEqual(14, entry.sourcefiles)",
            "        self.assertEqual(3666973, entry.sourcefilesize)",
            "        self.assertEqual(13, entry.mirrorfiles)",
            "        self.assertEqual(30242, entry.mirrorfilesize)",
            "        self.assertEqual(1, entry.newfiles)",
            "        self.assertEqual(3636731, entry.newfilesize)",
            "        self.assertEqual(0, entry.deletedfiles)",
            "        self.assertEqual(0, entry.deletedfilesize)",
            "        self.assertEqual(1, entry.changedfiles)",
            "        self.assertEqual(0, entry.changedsourcesize)",
            "        self.assertEqual(0, entry.changedmirrorsize)",
            "        self.assertEqual(2, entry.incrementfiles)",
            "        self.assertEqual(0, entry.incrementfilesize)",
            "        self.assertEqual(3636731, entry.totaldestinationsizechange)",
            "        self.assertEqual(0, entry.errors)",
            "",
            "",
            "class RdiffTimeTest(unittest.TestCase):",
            "    def test_add(self):",
            "        \"\"\"Check if addition with timedelta is working as expected.\"\"\"",
            "        # Without timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-08T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') + datetime.timedelta(days=3)",
            "        )",
            "        # With timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-08T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') + datetime.timedelta(days=3)",
            "        )",
            "",
            "    def test_compare(self):",
            "        \"\"\"Check behaviour of comparison operator operator.\"\"\"",
            "",
            "        self.assertTrue(RdiffTime('2014-11-07T21:04:30-04:00') < RdiffTime('2014-11-08T21:04:30Z'))",
            "        self.assertTrue(RdiffTime('2014-11-08T21:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))",
            "        self.assertFalse(RdiffTime('2014-11-08T22:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))",
            "",
            "        self.assertFalse(RdiffTime('2014-11-07T21:04:30-04:00') > RdiffTime('2014-11-08T21:04:30Z'))",
            "        self.assertFalse(RdiffTime('2014-11-08T21:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))",
            "        self.assertTrue(RdiffTime('2014-11-08T22:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))",
            "",
            "    def test_init_now(self):",
            "        t0 = RdiffTime()",
            "        self.assertAlmostEqual(int(time.time()), t0.epoch(), delta=5000)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (1415221470, 1415221470),",
            "            ('2014-11-05T21:04:30Z', 1415221470),",
            "            ('2014-11-05T16:04:30-05:00', 1415221470),",
            "            ('2014-11-05T23:04:30+02:00', 1415221470),",
            "            ('2014-11-05T23-04-30+02-00', 1415221470),",
            "        ]",
            "    )",
            "    def test_init(self, value, expected_epoch):",
            "        t1 = RdiffTime(value)",
            "        self.assertEqual(expected_epoch, t1.epoch())",
            "",
            "    def test_int(self):",
            "        \"\"\"Check if int(RdiffTime) return expected value.\"\"\"",
            "        self.assertEqual(1415221470, int(RdiffTime(1415221470)))",
            "        self.assertEqual(1415217870, int(RdiffTime(1415221470, 3600)))",
            "",
            "    def test_str(self):",
            "        \"\"\"Check if __str__ is working.\"\"\"",
            "        self.assertEqual('2014-11-05T21:04:30Z', str(RdiffTime(1415221470)))",
            "        self.assertEqual('2014-11-05T21:04:30+01:00', str(RdiffTime(1415221470, 3600)))",
            "",
            "    def test_sub(self):",
            "        \"\"\"Check if addition with timedelta is working as expected.\"\"\"",
            "        # Without timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') - datetime.timedelta(days=3)",
            "        )",
            "        # With timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') - datetime.timedelta(days=3)",
            "        )",
            "",
            "        # With datetime",
            "        self.assertTrue((RdiffTime('2014-11-02T21:04:30Z') - RdiffTime()).days < 0)",
            "        self.assertTrue((RdiffTime() - RdiffTime('2014-11-02T21:04:30Z')).days > 0)",
            "",
            "    def test_set_time(self):",
            "        self.assertEqual(RdiffTime('2014-11-05T00:00:00Z'), RdiffTime('2014-11-05T21:04:30Z').set_time(0, 0, 0))",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T00:00:00-04:00'), RdiffTime('2014-11-02T21:04:30-04:00').set_time(0, 0, 0)",
            "        )"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "# rdiffweb, A web interface to rdiff-backup repositories",
            "# Copyright (C) 2012-2021 rdiffweb contributors",
            "#",
            "# This program is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "\"\"\"",
            "Created on Oct 3, 2015",
            "",
            "Module used to test the librdiff.",
            "",
            "@author: Patrik Dufresne",
            "\"\"\"",
            "import datetime",
            "import os",
            "import shutil",
            "import tarfile",
            "import tempfile",
            "import time",
            "import unittest",
            "from inspect import isclass",
            "from unittest.case import skipIf",
            "",
            "import pkg_resources",
            "from parameterized import parameterized",
            "",
            "from rdiffweb.core.librdiff import (",
            "    AccessDeniedError,",
            "    DoesNotExistError,",
            "    FileStatisticsEntry,",
            "    IncrementEntry,",
            "    RdiffDirEntry,",
            "    RdiffRepo,",
            "    RdiffTime,",
            "    SessionStatisticsEntry,",
            "    rdiff_backup_version,",
            "    unquote,",
            ")",
            "",
            "",
            "class MockRdiffRepo(RdiffRepo):",
            "    def __init__(self):",
            "        p = bytes(pkg_resources.resource_filename('rdiffweb.core', 'tests'), encoding='utf-8')  # @UndefinedVariable",
            "        RdiffRepo.__init__(self, p, encoding='utf-8')",
            "        self.root_path = MockDirEntry(self)",
            "",
            "",
            "class MockDirEntry(RdiffDirEntry):",
            "    def __init__(self, repo):",
            "        self._repo = repo",
            "        self.path = b''",
            "",
            "",
            "class IncrementEntryTest(unittest.TestCase):",
            "    def test_init(self):",
            "        increment = IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')",
            "        self.assertEqual(b'my_filename.txt', increment.name)",
            "        self.assertEqual(RdiffTime(1414967021), increment.date)",
            "        self.assertEqual(b'.diff.gz', increment.suffix)",
            "",
            "    def test_extract_date(self):",
            "        self.assertEqual(",
            "            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')",
            "        )",
            "        self.assertEqual(",
            "            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17-23-41-05-00.diff.gz')",
            "        )",
            "        # Check if date with quoted characther are proerply parsed.",
            "        # On NTFS, colon (:) are not supported.",
            "        self.assertEqual(",
            "            RdiffTime(1483443123),",
            "            IncrementEntry._extract_date(b'my_filename.txt.2017-01-03T06;05832;05803-05;05800.diff.gz'),",
            "        )",
            "",
            "",
            "class RdiffDirEntryTest(unittest.TestCase):",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "",
            "    def test_init(self):",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, [])",
            "        self.assertFalse(entry.isdir)",
            "        self.assertFalse(entry.exists)",
            "        self.assertEqual(os.path.join(b'my_filename.txt'), entry.path)",
            "        self.assertEqual(os.path.join(self.repo.full_path, b'my_filename.txt'), entry.full_path)",
            "",
            "    def test_change_dates(self):",
            "        \"\"\"Check if dates are properly sorted.\"\"\"",
            "        increments = [",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),",
            "        ]",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, increments)",
            "",
            "        self.assertEqual(",
            "            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates",
            "        )",
            "",
            "    def test_change_dates_with_exists(self):",
            "        \"\"\"Check if dates are properly sorted.\"\"\"",
            "        increments = [",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),",
            "            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),",
            "        ]",
            "        entry = RdiffDirEntry(self.repo, b'my_filename.txt', True, increments)",
            "",
            "        self.assertEqual(",
            "            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates",
            "        )",
            "",
            "    def test_display_name(self):",
            "        \"\"\"Check if display name is unquoted and unicode.\"\"\"",
            "        entry = RdiffDirEntry(self.repo, b'my_dir', True, [])",
            "        self.assertEqual('my_dir', entry.display_name)",
            "",
            "        entry = RdiffDirEntry(self.repo, b'my;090dir', True, [])",
            "        self.assertEqual('myZdir', entry.display_name)",
            "",
            "    def test_file_size(self):",
            "        # Given a dir increment",
            "        increments = [",
            "            IncrementEntry(",
            "                bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial.2014-11-05T16:05:07-05:00.dir', encoding='utf-8'),",
            "            )",
            "        ]",
            "        entry = RdiffDirEntry(",
            "            self.repo, bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'), False, increments",
            "        )",
            "        # When getting the file_size",
            "        # Then the size is 0",
            "        self.assertEqual(-1, entry.file_size)",
            "",
            "    def test_file_size_without_stats(self):",
            "        increments = [IncrementEntry(b'my_file.2014-11-05T16:04:30-05:00.dir')]",
            "        entry = RdiffDirEntry(self.repo, b'my_file', False, increments)",
            "        self.assertEqual(-1, entry.file_size)",
            "",
            "",
            "class FileErrorTest(unittest.TestCase):",
            "    def test_init(self):",
            "        e = DoesNotExistError('some/path')",
            "        self.assertEqual('some/path', str(e))",
            "",
            "        e = AccessDeniedError('some/path')",
            "        self.assertEqual('some/path', str(e))",
            "",
            "",
            "class FileStatisticsEntryTest(unittest.TestCase):",
            "    \"\"\"",
            "    Test the file statistics entry.",
            "    \"\"\"",
            "",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "",
            "    def test_get_mirror_size(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')",
            "        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(143, size)",
            "",
            "    def test_get_source_size(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')",
            "        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(286, size)",
            "",
            "    def test_get_mirror_size_gzip(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')",
            "        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(143, size)",
            "",
            "    def test_get_source_size_gzip(self):",
            "        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')",
            "        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))",
            "        self.assertEqual(286, size)",
            "",
            "",
            "class LogEntryTest(unittest.TestCase):",
            "    def setUp(self):",
            "        self.repo = MockRdiffRepo()",
            "        self.root_path = self.repo.root_path",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                'with_uncompress',",
            "                '2015-11-19T07:27:46-05:00',",
            "                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',",
            "            ),",
            "            (",
            "                'with_compress',",
            "                '2015-11-20T07:27:46-05:00',",
            "                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',",
            "            ),",
            "        ]",
            "    )",
            "    def test_errors_tail(self, unused, date, expected_content):",
            "        entry = self.repo.error_log[RdiffTime(date)]",
            "        self.assertIsNotNone(entry)",
            "        self.assertEqual(entry.tail(), expected_content)",
            "",
            "",
            "class RdiffRepoTest(unittest.TestCase):",
            "    def setUp(self):",
            "        # Extract 'testcases.tar.gz'",
            "        testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable",
            "        self.temp_dir = tempfile.mkdtemp(prefix='rdiffweb_tests_')",
            "        tarfile.open(testcases).extractall(self.temp_dir)",
            "        # Define location of testcases",
            "        self.testcases_dir = os.path.normpath(os.path.join(self.temp_dir, 'testcases'))",
            "        self.testcases_dir = self.testcases_dir.encode('utf8')",
            "        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')",
            "",
            "    def tearDown(self):",
            "        shutil.rmtree(self.temp_dir.encode('utf8'), True)",
            "",
            "    def test_init(self):",
            "        self.assertEqual('testcases', self.repo.display_name)",
            "",
            "    def test_init_with_absolute(self):",
            "        self.repo = RdiffRepo(os.path.join(self.temp_dir, '/testcases'), encoding='utf-8')",
            "        self.assertEqual('testcases', self.repo.display_name)",
            "",
            "    def test_init_with_invalid(self):",
            "        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'invalid'), encoding='utf-8')",
            "        self.assertEqual('failed', self.repo.status[0])",
            "        self.assertEqual(None, self.repo.last_backup_date)",
            "        self.assertEqual('invalid', self.repo.display_name)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_root\",",
            "                b\"/\",",
            "                'testcases',",
            "                b'',",
            "                True,",
            "                True,",
            "                True,",
            "                -1,",
            "                [",
            "                    '2014-11-01T15:49:47-04:00',",
            "                    '2014-11-01T15:50:26-04:00',",
            "                    '2014-11-01T15:50:48-04:00',",
            "                    '2014-11-01T15:51:15-04:00',",
            "                    '2014-11-01T15:51:29-04:00',",
            "                    '2014-11-01T16:30:22-04:00',",
            "                    '2014-11-01T16:30:50-04:00',",
            "                    '2014-11-01T18:07:19-04:00',",
            "                    '2014-11-01T20:12:45-04:00',",
            "                    '2014-11-01T20:18:11-04:00',",
            "                    '2014-11-01T20:51:18-04:00',",
            "                    '2014-11-02T09:16:43-05:00',",
            "                    '2014-11-02T09:50:53-05:00',",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:01:02-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-01-20T10:42:21-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_dir\",",
            "                b\"Subdirectory\",",
            "                'Subdirectory',",
            "                b'Subdirectory',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                [",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2016-01-20T10:42:21-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_dir_utf8_char\",",
            "                b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\",",
            "                'Fold\u00e8r with \u00e9ncod\u00efng',",
            "                b'Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:04:55-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_dir\",",
            "                b\"Revisions\",",
            "                'Revisions',",
            "                b'Revisions',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                [",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_file\",",
            "                b'Revisions/Data',",
            "                'Data',",
            "                b'Revisions/Data',",
            "                True,",
            "                False,",
            "                False,",
            "                9,",
            "                [",
            "                    '2014-11-03T19:04:57-05:00',",
            "                    '2014-11-05T16:04:30-05:00',",
            "                    '2014-11-05T16:04:55-05:00',",
            "                    '2014-11-05T16:05:07-05:00',",
            "                    '2016-02-02T16:30:40-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_broken_symlink\",",
            "                b'BrokenSymlink',",
            "                'BrokenSymlink',",
            "                b'BrokenSymlink',",
            "                True,",
            "                False,",
            "                False,",
            "                7,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;090 to quote',",
            "                'Char Z to quote',",
            "                b'Char ;090 to quote',",
            "                False,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-01T18:07:19-04:00', '2014-11-01T20:18:11-04:00', '2014-11-03T19:04:57-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;059090 to quote',",
            "                'Char ;090 to quote',",
            "                b'Char ;059090 to quote',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-03T15:46:47-05:00', '2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_char_to_quote\",",
            "                b'Char ;059059090 to quote',",
            "                'Char ;059090 to quote',",
            "                b'Char ;059059090 to quote',",
            "                False,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:04:55-05:00', '2016-01-20T10:42:21-05:00'],",
            "            ),",
            "            (",
            "                \"with_loop_symlink\",",
            "                b'Subdirectory/LoopSymlink',",
            "                'LoopSymlink',",
            "                b'Subdirectory/LoopSymlink',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_subdir_symlink\",",
            "                b'SymlinkToSubdirectory',",
            "                'SymlinkToSubdirectory',",
            "                b'SymlinkToSubdirectory',",
            "                True,",
            "                True,",
            "                False,",
            "                -1,",
            "                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "        ]",
            "    )",
            "    def test_fstat(self, unused, input, display_name, path, exists, isdir, isroot, file_size, change_dates):",
            "        dir_entry = self.repo.fstat(input)",
            "        self.assertEqual(display_name, dir_entry.display_name)",
            "        self.assertEqual(path, dir_entry.path)",
            "        self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)",
            "        self.assertEqual(exists, dir_entry.exists)",
            "        self.assertEqual(isdir, dir_entry.isdir)",
            "        self.assertEqual(isroot, dir_entry.isroot)",
            "        self.assertEqual(file_size, dir_entry.file_size)",
            "        self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))",
            "        # For consistency, check if the same value are retreived using listdir",
            "        if not isroot:",
            "            parent_dir = os.path.dirname(input)",
            "            children = self.repo.listdir(parent_dir)",
            "            dir_entry = next(c for c in children if c.path == input)",
            "            self.assertEqual(display_name, dir_entry.display_name)",
            "            self.assertEqual(path, dir_entry.path)",
            "            self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)",
            "            self.assertEqual(exists, dir_entry.exists)",
            "            self.assertEqual(isdir, dir_entry.isdir)",
            "            self.assertEqual(isroot, dir_entry.isroot)",
            "            self.assertEqual(file_size, dir_entry.file_size)",
            "            self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))",
            "",
            "    def test_fstat_outside_repo(self):",
            "        with self.assertRaises(AccessDeniedError):",
            "            self.repo.fstat(b\"../\")",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_root\",",
            "                b\"\",",
            "                [",
            "                    '<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',",
            "                    'BrokenSymlink',",
            "                    'Char ;059090 to quote',",
            "                    'Char ;090 to quote',",
            "                    'Char Z to quote',",
            "                    'DIR\ufffd',",
            "                    'Fichier @ <root>',",
            "                    'Fichier avec non asci char \ufffdvelyne M\ufffdre.txt',",
            "                    'Revisions',",
            "                    'R\u00e9pertoire (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',",
            "                    'R\u00e9pertoire Existant',",
            "                    'R\u00e9pertoire Supprim\u00e9',",
            "                    'Subdirectory',",
            "                    'SymlinkToSubdirectory',",
            "                    'test\\\\test',",
            "                    '\uc774\ub8e8\ub9c8 YIRUMA - River Flows in You.mp3',",
            "                ],",
            "            ),",
            "            (\"with_children utf8_char\", b\"Subdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\", ['my file']),",
            "            (\"with_dir\", b\"Revisions\", ['Data']),",
            "            (\"with_file\", b\"Revisions/Data\", DoesNotExistError),",
            "            (\"with_broken_symlink\", b\"BrokenSymlink\", DoesNotExistError),",
            "            (\"with_loop_symlink\", b\"Subdirectory/LoopSymlink\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "            (\"with_subdir_symlink\", b\"SymlinkToSubdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),",
            "        ]",
            "    )",
            "    def test_listdir(self, unused, path, listdir):",
            "        if isclass(listdir) and issubclass(listdir, Exception):",
            "            with self.assertRaises(listdir):",
            "                self.repo.listdir(path)",
            "            return",
            "        self.assertEqual(listdir, sorted([d.display_name for d in self.repo.listdir(path)]))",
            "",
            "    def test_listdir_outside_repo(self):",
            "        with self.assertRaises(AccessDeniedError):",
            "            self.repo.listdir(b\"../\")",
            "",
            "    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")",
            "    def test_listdir_empty_folder(self):",
            "        # Given a folder without data",
            "        self.repo.delete(b\"Revisions/Data\")",
            "        # When listing entries",
            "        entries = self.repo.listdir(b\"Revisions\")",
            "        # Then the list is empty.",
            "        self.assertEqual([], entries)",
            "",
            "    def test_listdir_attributes(self):",
            "        children = self.repo.listdir(b\"Revisions\")",
            "        self.assertEqual(1, len(children))",
            "        dir_entry = children[0]",
            "        self.assertEqual('Data', dir_entry.display_name)",
            "        self.assertEqual(b'Revisions/Data', dir_entry.path)",
            "        self.assertEqual(os.path.join(self.testcases_dir, b'Revisions/Data'), dir_entry.full_path)",
            "        self.assertEqual(True, dir_entry.exists)",
            "        self.assertEqual(False, dir_entry.isdir)",
            "        self.assertEqual(False, dir_entry.isroot)",
            "        self.assertEqual(9, dir_entry.file_size)",
            "        self.assertEqual(",
            "            [",
            "                RdiffTime('2014-11-03T19:04:57-05:00'),",
            "                RdiffTime('2014-11-05T16:04:30-05:00'),",
            "                RdiffTime('2014-11-05T16:04:55-05:00'),",
            "                RdiffTime('2014-11-05T16:05:07-05:00'),",
            "                RdiffTime('2016-02-02T16:30:40-05:00'),",
            "            ],",
            "            list(dir_entry.change_dates),",
            "        )",
            "",
            "    def test_with_rdiff_backup_data(self):",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(b'rdiff-backup-data')",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.listdir(b'rdiff-backup-data')",
            "",
            "    def test_with_invalid(self):",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(b'invalid')",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.listdir(b'invalid')",
            "",
            "    def test_status(self):",
            "        status = self.repo.status",
            "        self.assertEqual('ok', status[0])",
            "        self.assertEqual('', status[1])",
            "",
            "    def test_status_access_denied_current_mirror(self):",
            "        # Skip test if running as root. Because root as access to everything.",
            "        if os.geteuid() == 0:",
            "            return",
            "        # Change the permissions of the files.",
            "        os.chmod(",
            "            os.path.join(self.testcases_dir, b'rdiff-backup-data', b'current_mirror.2016-02-02T16:30:40-05:00.data'),",
            "            0000,",
            "        )",
            "        # Create repo again to query status",
            "        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')",
            "        status = self.repo.status",
            "        self.assertEqual('failed', status[0])",
            "",
            "    def test_status_access_denied_rdiff_backup_data(self):",
            "        # Skip test if running as root. Because root as access to everything.",
            "        if os.geteuid() == 0:",
            "            return",
            "        # Change the permissions of the files.",
            "        os.chmod(os.path.join(self.testcases_dir, b'rdiff-backup-data'), 0000)",
            "        # Query status.",
            "        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')",
            "        status = self.repo.status",
            "        self.assertEqual('failed', status[0])",
            "        # Make sure history entry doesn't raise error",
            "        list(self.repo.mirror_metadata)",
            "",
            "    def test_remove_older(self):",
            "        # Given a repository with history",
            "        self.assertEqual(22, len(self.repo.mirror_metadata))",
            "        # When removing older then 1D",
            "        self.repo.remove_older(1)",
            "        # Then all history get deleted up to one",
            "        self.assertEqual(1, len(self.repo.mirror_metadata))",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (\"with_root\", b'/', 1454448640, 'zip', 'testcases.zip', b'PK\\x03\\x04'),",
            "            (\"with_zip\", b'Revisions', 1454448640, 'zip', 'Revisions.zip', b'PK\\x03\\x04'),",
            "            (\"with_tar\", b'Revisions', 1454448640, 'tar', 'Revisions.tar', b'././@PaxHeader'),",
            "            (\"with_tar_gz\", b'Revisions', 1454448640, 'tar.gz', 'Revisions.tar.gz', b'\\x1f\\x8b'),",
            "            (\"with_tar_bz2\", b'Revisions', 1454448640, 'tar.bz2', 'Revisions.tar.bz2', b'BZh'),",
            "            (\"with_none_file\", b'Revisions/Data', 1454448640, None, 'Data', b'Version3\\n'),",
            "            (\"with_raw_file\", b'Revisions/Data', 1454448640, 'raw', 'Data', b'Version3\\n'),",
            "            (\"with_zip_file\", b'Revisions/Data', 1454448640, 'zip', 'Data.zip', b'PK\\x03\\x04'),",
            "        ]",
            "    )",
            "    def test_restore(self, unused, path, restore_as_of, kind, expected_filename, expected_startswith):",
            "        filename, stream = self.repo.restore(path, restore_as_of=restore_as_of, kind=kind)",
            "        self.assertEqual(expected_filename, filename)",
            "        data = stream.read()",
            "        self.assertTrue(data.startswith(expected_startswith))",
            "",
            "    def test_unquote(self):",
            "        self.assertEqual(b'Char ;090 to quote', unquote(b'Char ;059090 to quote'))",
            "",
            "    def test_error_log_range(self):",
            "        logs = self.repo.error_log[0:1]",
            "        self.assertEqual(1, len(logs))",
            "        self.assertEqual(\"\", self.repo.error_log[0].read())",
            "",
            "    def test_backup_log(self):",
            "        self.assertEqual(\"\", self.repo.backup_log.read())",
            "",
            "    def test_restore_log(self):",
            "        self.assertEqual(",
            "            self.repo.restore_log.read(),",
            "            \"\"\"Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpKDNO4t/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpnG33kc/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpGUEHJC/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBlFPsW/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpkfCejo/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmphXpFnS as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_udS97a/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_LL4rCm/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_zpYgT3/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_7H93yy/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_Xe2CfG/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_rHFERA/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpF7rSar/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpgHTL2j/root as it was as of Wed Nov  5 16:05:07 2014.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpVo1u4Z/root as it was as of Wed Jan 20 10:42:21 2016.",
            "Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBRxRxe/root as it was as of Wed Jan 20 10:42:21 2016.",
            "\"\"\",",
            "        )",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (",
            "                \"with_idx_1\",",
            "                1,",
            "                '2014-11-01T15:50:26-04:00',",
            "            ),",
            "            (",
            "                \"with_idx_2\",",
            "                2,",
            "                '2014-11-01T15:50:48-04:00',",
            "            ),",
            "            (",
            "                \"with_idx_3\",",
            "                3,",
            "                '2014-11-01T15:51:15-04:00',",
            "            ),",
            "            (",
            "                \"with_neg_idx_1\",",
            "                -1,",
            "                '2016-02-02T16:30:40-05:00',",
            "            ),",
            "            (",
            "                \"with_date\",",
            "                RdiffTime('2016-02-02T16:30:40-05:00'),",
            "                '2016-02-02T16:30:40-05:00',",
            "            ),",
            "            (",
            "                \"with_slice_idx\",",
            "                slice(0, 2),",
            "                [",
            "                    '2014-11-01T15:49:47-04:00',",
            "                    '2014-11-01T15:50:26-04:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_date_start\",",
            "                slice(RdiffTime('2016-01-20T10:42:21-05:00'), None),",
            "                ['2016-01-20T10:42:21-05:00', '2016-02-02T16:30:40-05:00'],",
            "            ),",
            "            (",
            "                \"with_slice_date_start_stop\",",
            "                slice(",
            "                    RdiffTime('2014-11-02T17:00:00-05:00'),",
            "                    RdiffTime('2014-11-04T00:00:00-05:00'),",
            "                ),",
            "                [",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_date_start_stop_exact_match\",",
            "                slice(RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')),",
            "                [",
            "                    '2014-11-02T17:23:41-05:00',",
            "                    '2014-11-03T15:46:47-05:00',",
            "                    '2014-11-03T19:04:57-05:00',",
            "                ],",
            "            ),",
            "            (",
            "                \"with_slice_invalid_idx\",",
            "                slice(100, 120),",
            "                [],",
            "            ),",
            "            (",
            "                \"with_keyerror_date\",",
            "                RdiffTime('2022-11-03T15:46:47-05:00'),",
            "                KeyError,",
            "            ),",
            "            (",
            "                \"with_keyerror_int\",",
            "                1024,",
            "                KeyError,",
            "            ),",
            "        ]",
            "    )",
            "    def test_session_statistics(self, unsed, value, expected_value):",
            "        if isinstance(expected_value, list):",
            "            self.assertEqual(expected_value, [str(o.date) for o in self.repo.session_statistics[value]])",
            "        elif isclass(expected_value) and issubclass(expected_value, Exception):",
            "            with self.assertRaises(expected_value):",
            "                self.repo.session_statistics[value]",
            "        else:",
            "            self.assertEqual(expected_value, str(self.repo.session_statistics[value].date))",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (\"with_file\", b'Revisions/Data'),",
            "            (\"with_folder\", b'Subdirectory'),",
            "            (\"with_folder_ending_slash\", b'Subdirectory/'),",
            "            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\"),",
            "            (\"with_broken_symlink\", b'BrokenSymlink'),",
            "        ]",
            "    )",
            "    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")",
            "    def test_delete_file(self, unused, path):",
            "        # Delete a file",
            "        self.repo.delete(path)",
            "        # Check file is deleted",
            "        with self.assertRaises(DoesNotExistError):",
            "            self.repo.fstat(path)",
            "",
            "",
            "class SessionStatisticsEntryTest(unittest.TestCase):",
            "    def test_getattr(self):",
            "        \"\"\"",
            "        Check how a session statistic is read.",
            "        \"\"\"",
            "        entry = SessionStatisticsEntry(MockRdiffRepo(), b'session_statistics.2014-11-02T09:16:43-05:00.data')",
            "        self.assertEqual(1414937803.00, entry.starttime)",
            "        self.assertEqual(1414937764.82, entry.endtime)",
            "        self.assertAlmostEqual(-38.18, entry.elapsedtime, delta=-0.01)",
            "        self.assertEqual(14, entry.sourcefiles)",
            "        self.assertEqual(3666973, entry.sourcefilesize)",
            "        self.assertEqual(13, entry.mirrorfiles)",
            "        self.assertEqual(30242, entry.mirrorfilesize)",
            "        self.assertEqual(1, entry.newfiles)",
            "        self.assertEqual(3636731, entry.newfilesize)",
            "        self.assertEqual(0, entry.deletedfiles)",
            "        self.assertEqual(0, entry.deletedfilesize)",
            "        self.assertEqual(1, entry.changedfiles)",
            "        self.assertEqual(0, entry.changedsourcesize)",
            "        self.assertEqual(0, entry.changedmirrorsize)",
            "        self.assertEqual(2, entry.incrementfiles)",
            "        self.assertEqual(0, entry.incrementfilesize)",
            "        self.assertEqual(3636731, entry.totaldestinationsizechange)",
            "        self.assertEqual(0, entry.errors)",
            "",
            "",
            "class RdiffTimeTest(unittest.TestCase):",
            "    def test_add(self):",
            "        \"\"\"Check if addition with timedelta is working as expected.\"\"\"",
            "        # Without timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-08T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') + datetime.timedelta(days=3)",
            "        )",
            "        # With timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-08T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') + datetime.timedelta(days=3)",
            "        )",
            "",
            "    def test_compare(self):",
            "        \"\"\"Check behaviour of comparison operator operator.\"\"\"",
            "",
            "        self.assertTrue(RdiffTime('2014-11-07T21:04:30-04:00') < RdiffTime('2014-11-08T21:04:30Z'))",
            "        self.assertTrue(RdiffTime('2014-11-08T21:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))",
            "        self.assertFalse(RdiffTime('2014-11-08T22:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))",
            "",
            "        self.assertFalse(RdiffTime('2014-11-07T21:04:30-04:00') > RdiffTime('2014-11-08T21:04:30Z'))",
            "        self.assertFalse(RdiffTime('2014-11-08T21:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))",
            "        self.assertTrue(RdiffTime('2014-11-08T22:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))",
            "",
            "    def test_init_now(self):",
            "        t0 = RdiffTime()",
            "        self.assertAlmostEqual(int(time.time()), t0.epoch(), delta=5000)",
            "",
            "    @parameterized.expand(",
            "        [",
            "            (1415221470, 1415221470),",
            "            ('2014-11-05T21:04:30Z', 1415221470),",
            "            ('2014-11-05T16:04:30-05:00', 1415221470),",
            "            ('2014-11-05T23:04:30+02:00', 1415221470),",
            "            ('2014-11-05T23-04-30+02-00', 1415221470),",
            "        ]",
            "    )",
            "    def test_init(self, value, expected_epoch):",
            "        t1 = RdiffTime(value)",
            "        self.assertEqual(expected_epoch, t1.epoch())",
            "",
            "    def test_int(self):",
            "        \"\"\"Check if int(RdiffTime) return expected value.\"\"\"",
            "        self.assertEqual(1415221470, int(RdiffTime(1415221470)))",
            "        self.assertEqual(1415217870, int(RdiffTime(1415221470, 3600)))",
            "",
            "    def test_str(self):",
            "        \"\"\"Check if __str__ is working.\"\"\"",
            "        self.assertEqual('2014-11-05T21:04:30Z', str(RdiffTime(1415221470)))",
            "        self.assertEqual('2014-11-05T21:04:30+01:00', str(RdiffTime(1415221470, 3600)))",
            "",
            "    def test_sub(self):",
            "        \"\"\"Check if addition with timedelta is working as expected.\"\"\"",
            "        # Without timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') - datetime.timedelta(days=3)",
            "        )",
            "        # With timezone",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') - datetime.timedelta(days=3)",
            "        )",
            "",
            "        # With datetime",
            "        self.assertTrue((RdiffTime('2014-11-02T21:04:30Z') - RdiffTime()).days < 0)",
            "        self.assertTrue((RdiffTime() - RdiffTime('2014-11-02T21:04:30Z')).days > 0)",
            "",
            "    def test_set_time(self):",
            "        self.assertEqual(RdiffTime('2014-11-05T00:00:00Z'), RdiffTime('2014-11-05T21:04:30Z').set_time(0, 0, 0))",
            "        self.assertEqual(",
            "            RdiffTime('2014-11-02T00:00:00-04:00'), RdiffTime('2014-11-02T21:04:30-04:00').set_time(0, 0, 0)",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "55": [
                "MockRdiffRepo",
                "__init__"
            ],
            "224": [
                "RdiffRepoTest",
                "setUp"
            ],
            "233": [
                "RdiffRepoTest",
                "test_init_with_absolute"
            ],
            "237": [
                "RdiffRepoTest",
                "test_init_with_invalid"
            ],
            "240": [
                "RdiffRepoTest",
                "test_init_with_invalid"
            ],
            "537": [
                "RdiffRepoTest",
                "test_status_access_denied_current_mirror"
            ],
            "548": [
                "RdiffRepoTest",
                "test_status_access_denied_rdiff_backup_data"
            ]
        },
        "addLocation": []
    }
}